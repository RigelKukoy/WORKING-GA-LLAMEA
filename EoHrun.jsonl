{"id": "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "parents": [], "algorithm": "A population-based algorithm that combines exploration and exploitation by iteratively moving particles towards the best solution found so far, while also considering the average position of the population.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n\n            velocities = (self.inertia * velocities\n                          + self.cognitive_coeff * r1 * (personal_best_positions - population)\n                          + self.social_coeff * r2 * (global_best_position - population))\n\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.population_size\n\n            # Update personal best positions and fitnesses\n            for i in range(self.population_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "545bfcbf-8d4a-498b-bcb8-e7622d986f4e", "parents": [], "algorithm": "# Description: This algorithm combines a Gaussian mutation hill-climbing strategy with a shrinking search space based on the best solutions found so far.\n# Code:\n```", "code": "import numpy as np\n\nclass GaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_sigma=1.0, sigma_decay=0.99, search_space_shrink=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma_decay = sigma_decay\n        self.search_space_shrink = search_space_shrink\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        x = np.random.uniform(lb, ub, self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        sigma = self.initial_sigma\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, sigma, self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f:\n                f = f_new\n                x = x_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    \n                    #Shrink Search Space\n                    center = self.x_opt\n                    width = (ub - lb) * self.search_space_shrink / 2\n                    lb = np.maximum(func.bounds.lb, center - width)\n                    ub = np.minimum(func.bounds.ub, center + width)\n\n            sigma *= self.sigma_decay\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "5fb87562-19c3-480e-a911-b9db30b53874", "parents": [], "algorithm": "A population-based algorithm using a combination of differential evolution, local search, and adaptive parameter control to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, f=0.5, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = f  # Mutation factor\n        self.CR = cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Adaptive Parameter Control\n        f_history = [self.F]\n        cr_history = [self.CR]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                    \n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Adaptive Parameter Update\n            self.F = np.mean(f_history[-10:]) if len(f_history) > 10 else self.F + np.random.normal(0, 0.01)\n            self.CR = np.mean(cr_history[-10:]) if len(cr_history) > 10 else self.CR + np.random.normal(0, 0.01)\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n            f_history.append(self.F)\n            cr_history.append(self.CR)\n            \n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "5becb908-f00e-4da6-92f9-76c5ad961f8d", "parents": [], "algorithm": "Simulated Annealing with adaptive temperature and step size, coupled with random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Random Restart\n            x_current = np.random.uniform(self.lb, self.ub, self.dim)\n            f_current = func(x_current)\n            eval_count += 1\n\n            if f_current < self.f_opt:\n                self.f_opt = f_current\n                self.x_opt = x_current.copy()\n                \n            temp = self.initial_temp\n            \n            while eval_count < self.budget and temp > 1e-5: #Stopping criteria based on budget and low temperature\n                \n                x_new = x_current + np.random.normal(0, self.step_size, self.dim)\n                x_new = np.clip(x_new, self.lb, self.ub) #Clip the value to the boundaries\n                f_new = func(x_new)\n                eval_count += 1\n                \n                delta_e = f_new - f_current\n                \n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                    x_current = x_new.copy()\n                    f_current = f_new\n                    \n                    if f_current < self.f_opt:\n                        self.f_opt = f_current\n                        self.x_opt = x_current.copy()\n                \n                temp *= self.cooling_rate\n                self.step_size *= 0.995 # Adapt step size\n        \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "4fd9cd7d-502e-4c77-ab92-414b8ceba374", "parents": [], "algorithm": "A population-based algorithm that evolves solutions through a combination of global exploration and local refinement using differential evolution operators and a restart mechanism.", "code": "import numpy as np\n\nclass DifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, CR=0.9, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                mask = np.random.rand(self.dim) < self.CR\n                trial[mask] = mutant[mask]\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            #Restart Mechanism\n            if np.random.rand() < self.restart_prob:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "8bf133d0-6806-42b0-9a7e-3163b7790923", "parents": [], "algorithm": "Evolves a population of solutions using differential evolution with a restart mechanism triggered by stagnation, and incorporates a local search to refine promising solutions.", "code": "import numpy as np\n\nclass DifferentialEvolutionWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_factor=0.5, crossover_rate=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_iterations = local_search_iterations\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        stagnation_counter = 0\n        max_stagnation = self.budget // (self.pop_size * 10) # Adjust based on budget\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        stagnation_counter = 0  # Reset stagnation counter\n                    \n                    # Local Search around the improved solution\n                    for _ in range(self.local_search_iterations):\n                        if self.eval_count >= self.budget:\n                            break\n\n                        perturbation = np.random.normal(0, 0.05, size=self.dim) #Small perturbation\n                        local_x = np.clip(trial + perturbation, self.lb, self.ub)\n                        local_f = func(local_x)\n                        self.eval_count += 1\n\n                        if local_f < f:\n                            f = local_f\n                            trial = local_x\n                            fitness[i] = f\n                            population[i] = trial\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = trial\n                                stagnation_counter = 0\n\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Stagnation Check & Restart\n            best_index = np.argmin(fitness)\n            if fitness[best_index] >= self.f_opt:\n                stagnation_counter += 1\n            else:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                stagnation_counter = 0\n\n            if stagnation_counter > max_stagnation:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                stagnation_counter = 0\n                \n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "8653c3e0-2afb-412b-b5ed-81c2214d1594", "parents": [], "algorithm": "'maxfev': self.budget - eval_count,\n                                    'xatol': 1e-4, 'fatol': 1e-4", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexSearch:\n    def __init__(self, budget=10000, dim=10, restart_prob = 0.05):\n        self.budget = budget\n        self.dim = dim\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Global search\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            \n            # Local search with Nelder-Mead\n            res = minimize(func, x0, method='Nelder-Mead',\n                           options={'maxfev': self.budget - eval_count,\n                                    'xatol': 1e-4, 'fatol': 1e-4})\n            \n            eval_count += res.nfev\n            \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n            \n            if np.random.rand() < self.restart_prob:\n                continue\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "ba69aadf-6d03-4360-9722-61b7328009d3", "parents": [], "algorithm": "Adaptive Differential Evolution with a dynamically adjusted mutation factor and crossover rate based on the success of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n\n        history_F = []\n        history_CR = []\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Adaptation of F and CR (example: based on success history)\n            successful_mutations = self.fitness < np.array([func(x) for x in self.population])\n            if np.any(successful_mutations):\n                indices = np.where(successful_mutations)[0]\n                if len(history_F) > 0:\n                    self.F = 0.5 * self.F + 0.5 * np.mean(history_F)\n                    self.CR = 0.5 * self.CR + 0.5 * np.mean(history_CR)\n                history_F.append(self.F)\n                history_CR.append(self.CR)\n                \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "de8b854b-03df-4ff3-9eed-1b8efd32b0c7", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "'maxfev': max(1, int((self.budget - evals) / (self.pop_size * 2)))", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridEvolutionaryLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7, local_search_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        while evals < self.budget:\n            new_population = []\n            for i in range(self.pop_size):\n                # Selection (Tournament selection)\n                idx1 = np.random.randint(0, self.pop_size)\n                idx2 = np.random.randint(0, self.pop_size)\n                parent1 = population[idx1] if fitness[idx1] < fitness[idx2] else population[idx2]\n\n                idx1 = np.random.randint(0, self.pop_size)\n                idx2 = np.random.randint(0, self.pop_size)\n                parent2 = population[idx1] if fitness[idx1] < fitness[idx2] else population[idx2]\n                \n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                    cross_points = np.random.rand(self.dim) < 0.5\n                    child = np.where(cross_points, parent1, parent2)\n                else:\n                    child = parent1.copy()\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        child[j] = np.random.uniform(self.lb, self.ub)\n                \n                child = np.clip(child, self.lb, self.ub)\n\n                # Local Search (Nelder-Mead)\n                if np.random.rand() < self.local_search_prob:\n                    res = minimize(func, child, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': max(1, int((self.budget - evals) / (self.pop_size * 2)))}) # Reduce maxfev\n                    \n                    if res.success:\n                        child = res.x\n                        f_child = func(child)\n                        evals += res.nfev\n                    else:\n                        f_child = func(child)\n                        evals += 1\n                else:\n                    f_child = func(child)\n                    evals += 1\n                \n                if f_child < f_opt:\n                    f_opt = f_child\n                    x_opt = child\n                    \n                new_population.append(child)\n\n            population = np.array(new_population)\n            fitness = np.array([func(x) for x in population])\n        self.f_opt = f_opt\n        self.x_opt = x_opt\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "83411f7a-fbec-4612-807d-1853781202b9", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rate.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, min_temp=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        evals = 1\n        acceptance_count = 0\n        iteration = 0\n\n        while evals < self.budget and temp > self.min_temp:\n            iteration += 1\n            x_new = x + np.random.normal(0, temp**0.5, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                acceptance_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            if iteration % 100 == 0:  # Adjust temperature every 100 iterations\n                acceptance_rate = acceptance_count / 100\n                if acceptance_rate > 0.5:\n                    temp *= 0.9  # Reduce temperature more slowly if acceptance rate is high\n                else:\n                    temp *= 0.99  # Reduce temperature faster if acceptance rate is low\n                acceptance_count = 0 #reset acceptance count\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "3edfed6c-7448-40aa-b5a7-81eb6f2b4763", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An iterative algorithm that samples points using a Gaussian distribution, adapting the mean and standard deviation based on the best-performing samples to converge towards the optimum.", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, initial_std=1.0, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_std = initial_std\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        std = np.full(self.dim, self.initial_std)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        evals = 0\n        while evals < self.budget:\n            x = np.random.normal(mean, std)\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = func(x)\n            evals += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            # Adaptation\n            if f < func(mean):\n                mean = (1 - self.adaptation_rate) * mean + self.adaptation_rate * x\n                std = std * np.exp(self.adaptation_rate * (f - func(mean)))\n                std = np.clip(std, 0.01, 2.0)\n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "48c708bd-e648-4be8-983b-08a3fe0e13e4", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Simulated Annealing with adaptive temperature schedule and occasional random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=100.0, alpha=0.99, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f_current = func(x)\n        self.f_opt = f_current\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            if np.random.rand() < self.restart_prob:\n                x_new = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f_new = func(x_new)\n                evals += 1\n            else:\n                x_new = x + np.random.normal(0, 0.1, size=self.dim)\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                evals += 1\n\n            delta_f = f_new - f_current\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new\n                f_current = f_new\n\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x\n\n            self.temp *= self.alpha\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "9d45e4f3-7d7a-41ec-99dc-34f109cb58f3", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "A gradient-free optimization algorithm that combines a stochastic line search with a shrinking trust region to balance exploration and exploitation.", "code": "import numpy as np\n\nclass TrustRegionLineSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, shrink_factor=0.5, expand_factor=2.0, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f_current = func(x)\n        self.budget -= 1\n        self.f_opt = f_current\n        self.x_opt = x\n        step_size = self.initial_step_size\n\n        while self.budget > 0:\n            # Generate a random direction\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n\n            # Line search\n            x_new = x + step_size * direction\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                # Successful step\n                x = x_new\n                f_current = f_new\n\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x\n\n                # Adapt step size\n                if f_new < f_current - self.success_threshold * step_size: #significant improvement\n                    step_size *= self.expand_factor\n                else:\n                     step_size *= 1.1 #mild improvement\n            else:\n                # Unsuccessful step, shrink the trust region\n                step_size *= self.shrink_factor\n\n            step_size = np.clip(step_size, 1e-8, 10)  # Ensure step size remains within reasonable bounds\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "292c4e7d-456d-4a5f-b01f-c1ed916b9f3e", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the function evaluation history to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        current_x = np.random.uniform(self.lb, self.ub, self.dim)\n        current_f = func(current_x)\n        self.f_opt = current_f\n        self.x_opt = current_x\n        temp = self.initial_temp\n        evals = 1\n        \n        history_f = [current_f]\n\n        while evals < self.budget:\n            # Generate a new solution by perturbing the current one\n            new_x = current_x + np.random.normal(0, temp, self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            evals += 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                current_x = new_x\n                current_f = new_f\n                \n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n                    \n            history_f.append(current_f)\n            \n            # Adaptive temperature adjustment\n            if len(history_f) > 100:\n                std_dev = np.std(history_f[-100:])\n                temp = self.initial_temp * np.exp(-evals / (self.budget * std_dev))\n                #temp *= self.cooling_rate #original cooling rate\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "325a60bc-1eb9-46a5-bd96-9abc52929c3f", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "An evolutionary algorithm that adapts its search strategy by probabilistically combining elements from the best-performing solutions and randomly sampled solutions, focusing on areas with high potential.", "code": "import numpy as np\n\nclass AdaptiveMixEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, elite_fraction=0.1, mix_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_fraction = elite_fraction\n        self.mix_prob = mix_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        elite_count = int(self.elite_fraction * self.pop_size)\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            new_population = np.zeros_like(population)\n\n            # Elitism: Keep the best individuals\n            elite_indices = np.argsort(fitness)[:elite_count]\n            new_population[:elite_count] = population[elite_indices]\n            \n            for i in range(elite_count, self.pop_size):\n                # Select parent 1 from the elite\n                parent1_index = np.random.choice(elite_indices)\n                parent1 = population[parent1_index]\n\n                # Select parent 2 randomly\n                parent2 = population[np.random.randint(0, self.pop_size)]\n                \n                child = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.mix_prob:\n                        child[j] = parent1[j]\n                    else:\n                        child[j] = parent2[j]\n\n                # Mutation (small random change)\n                mutation_strength = 0.1 * (self.ub - self.lb)\n                mutation = np.random.uniform(-mutation_strength, mutation_strength, size=self.dim)\n                child = np.clip(child + mutation, self.lb, self.ub)\n                \n                new_population[i] = child\n            \n            population = new_population\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size - elite_count\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "aff6fd3a-645f-4cff-8e3f-7a1cafa1aeda", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "This algorithm iteratively refines the search space by focusing on promising regions identified by a Gaussian process surrogate model, balancing exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.exploration_weight = exploration_weight\n\n        self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=9)\n\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - self.exploration_weight * sigma\n\n    def __call__(self, func):\n        # Initial sampling\n        X_initial = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n        self.budget -= self.n_initial_samples\n        \n        self.X = X_initial\n        self.y = y_initial\n        \n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit Gaussian process to data\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            x_next = self.find_next_point()\n\n            # Evaluate function at new point\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            \n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self):\n        from scipy.optimize import minimize\n\n        def neg_acquisition(x):\n            return -self.acquisition_function(x)\n\n        # Start optimization from multiple random points\n        x0 = np.random.uniform(self.lb, self.ub, size=(10, self.dim))\n        \n        best_x = None\n        best_acq = np.inf\n\n        for start_point in x0:\n            res = minimize(neg_acquisition, start_point, bounds=[(self.lb, self.ub)] * self.dim, method='L-BFGS-B')\n            if res.fun < best_acq:\n                best_acq = res.fun\n                best_x = res.x\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "fb36a120-3179-481e-b393-94eb9af290a4", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An enhanced particle swarm optimization algorithm that incorporates a constriction factor to control particle velocities and adaptive parameters to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.k = 1  # Constriction factor parameter\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        iteration = 0\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (iteration / (self.budget / self.population_size + iteration))\n\n            # Constriction factor\n            phi = self.cognitive_coeff + self.social_coeff\n            constriction_factor = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi)) if phi > 4 else 1\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n\n            velocities = constriction_factor * (inertia * velocities\n                          + self.cognitive_coeff * r1 * (personal_best_positions - population)\n                          + self.social_coeff * r2 * (global_best_position - population))\n\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate new population\n            eval_num = min(self.population_size, self.budget)\n            new_fitness = np.array([func(x) for x in population[:eval_num]])\n            self.budget -= eval_num\n            \n            # Pad fitness if necessary\n            if eval_num < self.population_size:\n                padding = np.full(self.population_size - eval_num, np.inf)\n                new_fitness = np.concatenate([new_fitness, padding])\n\n            # Update personal best positions and fitnesses\n            for i in range(self.population_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n            \n            iteration += 1\n            if self.budget <= 0:\n                break\n\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "53fb614c-58c3-479f-a4a0-e84ebbf6670a", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "This algorithm employs a modified particle swarm optimization with velocity clamping and dynamic inertia weight adjustment to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        iteration = 0\n        while self.budget > 0:\n            # Dynamic inertia weight\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (iteration / (self.budget / self.population_size))\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n\n            velocities = (inertia * velocities\n                          + self.cognitive_coeff * r1 * (personal_best_positions - population)\n                          + self.social_coeff * r2 * (global_best_position - population))\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (self.ub - self.lb), self.velocity_clamp * (self.ub - self.lb))\n\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate new population\n            num_evals = min(self.population_size, self.budget)\n            new_fitness = np.array([func(x) for x in population[:num_evals]])\n            self.budget -= num_evals\n\n            # Update personal best positions and fitnesses\n            for i in range(num_evals):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n\n            iteration += 1\n\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c807fd5e-167d-4585-ac4e-7ed3594ff8c7", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with rank-one update and restarts.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = int(self.pop_size * mu_ratio)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.mu / (dim + 5))\n        self.c_c = (self.4 / (dim + 4))\n        self.c_mu = (self.mu / dim**2)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (dim + 1)) - 1)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            # Sampling\n            z = np.random.randn(self.pop_size, self.dim)\n            x = self.m + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, self.lb, self.ub)\n            f = np.array([func(xi) for xi in x])\n            self.evals += self.pop_size\n            if np.any(f < self.f_opt):\n                best_idx = np.argmin(f)\n                if f[best_idx] < self.f_opt:\n                   self.f_opt = f[best_idx]\n                   self.x_opt = x[best_idx]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n\n            # Update Evolution Path and Covariance Matrix\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu) * (self.m - m_old) / self.sigma @ np.linalg.inv(np.linalg.cholesky(self.C)).T\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c) * self.mu) * (self.m - m_old) / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.evals / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            self.C = (1 - self.c_mu) * self.C + self.c_mu * (self.weights @ (z_mu.T * z_mu))\n            self.C = (1 - self.c_c) * self.C + self.c_c * (self.pc[:, None] * self.pc[None, :]) * hsig\n\n            # Update Step Size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Handle Covariance Matrix becoming ill-conditioned\n            if np.min(np.linalg.eigvalsh(self.C)) < 1e-16:\n                self.C += 1e-10 * np.eye(self.dim)\n\n            # Restart if step size is too small or too large\n            if self.sigma < 1e-8 or self.sigma > 1e3:\n                self.m = np.random.uniform(self.lb, self.ub, self.dim)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma = 0.3\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "de1a634b-5c52-481c-9409-d4b6c9f904d3", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An adaptive particle swarm optimization algorithm that adjusts inertia weight based on the population's diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Calculate diversity (standard deviation of population)\n            diversity = np.mean(np.std(population, axis=0))\n\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (diversity / (self.ub - self.lb))\n            inertia = np.clip(inertia, self.inertia_min, self.inertia_max)\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n\n            velocities = (inertia * velocities\n                          + self.cognitive_coeff * r1 * (personal_best_positions - population)\n                          + self.social_coeff * r2 * (global_best_position - population))\n\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.population_size\n\n            # Update personal best positions and fitnesses\n            for i in range(self.population_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n        \n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b953818d-d7fe-4390-a050-576b9dbc8c34", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov_mu=0.1, c_cov_one=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_one = c_cov_one\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.eigen_decomposition_needed = True\n        self.B = None\n        self.D = None\n        self.mueff = self.pop_size / 4\n\n    def __call__(self, func):\n        evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while evals < self.budget:\n            # Sample population\n            if self.eigen_decomposition_needed:\n                self.D, self.B = np.linalg.eig(self.C)\n                self.D = np.sqrt(np.abs(self.D))\n                self.eigen_decomposition_needed = False\n\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = self.B @ np.diag(self.D) @ z.T\n            x = self.mean + self.sigma * y.T\n            x = np.clip(x, self.lb, self.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:int(self.mueff)].T * (1/int(self.mueff)), axis=1)\n            ymean = xmean - self.mean\n            ymean = ymean / self.sigma\n\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ z[idx[0]].T)\n            \n            self.mean = xmean\n                \n            # Update covariance matrix\n            self.p_c = (1-self.cs) * self.p_c + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * ymean / self.sigma\n                \n            self.C = (1-self.c_cov_one-self.c_cov_mu) * self.C + self.c_cov_one * np.outer(self.p_c,self.p_c) + self.c_cov_mu * (self.B @ np.diag(self.D) @ z[idx[0]].T) @ (self.B @ np.diag(self.D) @ z[idx[0]].T).T\n                \n            self.sigma = self.sigma * np.exp((self.cs/self.damps)*(np.linalg.norm(self.p_sigma)/np.sqrt(self.dim) - 1))\n            self.C = np.triu(self.C) + np.triu(self.C,1).T\n            self.C = self.C / np.linalg.norm(self.C)\n\n            self.eigen_decomposition_needed = True\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c676eaab-29e4-4f18-8c41-707b18fbca49", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "A differential evolution strategy that evolves a population of solutions by mutation, crossover, and selection, adapting mutation strength based on performance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, population_size=50, F=0.5, CR=0.7, F_adapt_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F_adapt_prob = F_adapt_prob\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.population_size):\n                # Mutation\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial.copy()\n\n                    # Adaptive F update (only when improvement)\n                    if np.random.rand() < self.F_adapt_prob:\n                      self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b5f78885-0777-4f43-b577-cb5f2f78eaba", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "Simulated Annealing with adaptive temperature schedule and occasional random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, temp**(1/2), self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f or np.random.rand() < np.exp((f - f_new) / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(self.lb, self.ub, self.dim)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            temp *= self.cooling_rate\n            if self.budget <= 0:\n                break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "e32d2011-e2ef-4c81-b8a1-4bf6f7ab067c", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step-size adaptation strategy.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        sigma = self.initial_step_size\n        C = np.eye(self.dim)\n        \n        eigen_decomposition = np.linalg.eigh(C)\n        B = eigen_decomposition[1]\n        D = np.sqrt(eigen_decomposition[0])\n\n        c_sigma = (np.sqrt(self.pop_size) * (np.sqrt(np.mean(D**2)))/ np.linalg.norm(D) )\n        c_c = 4 / (self.dim + 4)\n        c_mu = 2 / ((self.dim + np.sqrt(2))**2)\n        c_1 = c_mu\n        \n        mu = self.pop_size // 2 \n        \n        path_sigma = np.zeros(self.dim)\n        path_c = np.zeros(self.dim)\n        \n        evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        weights = np.log(mu+1/2) - np.log(np.arange(1,mu+1))\n        weights = weights / np.sum(weights)\n\n        while evals < self.budget:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = mean + sigma * (B @ (D * z.T)).T\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n            \n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            f_sorted = f[idx]\n\n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[0]\n\n            mean_diff = np.sum(weights.reshape(-1,1) * (x_sorted[:mu] - mean), axis=0)\n            mean = mean + c_mu * mean_diff\n\n            z_mean = np.sum(weights.reshape(-1,1) * z[idx[:mu]], axis=0)\n\n            path_sigma = (1 - c_sigma) * path_sigma + np.sqrt(c_sigma*(2-c_sigma)) * (B @ z_mean)\n            \n            hsig = np.linalg.norm(path_sigma) / np.sqrt(1-(1-c_sigma)**(2*(evals/self.pop_size))) < (1.4 + 2/(self.dim+1))\n            \n            path_c = (1-c_c) * path_c + hsig * np.sqrt(c_c * (2-c_c)) * mean_diff/sigma\n\n            C = (1-c_1-c_mu) * C + c_1 * (path_c.reshape(-1,1) @ path_c.reshape(1,-1)) + c_mu * (B @ (weights.reshape(-1,1) * z[idx[:mu]].T) @ (weights.reshape(-1,1) * z[idx[:mu]].T).T @ B.T)\n            \n            C = np.triu(C) + np.triu(C, 1).T \n            \n            eigen_decomposition = np.linalg.eigh(C)\n            B = eigen_decomposition[1]\n            D = np.sqrt(eigen_decomposition[0])\n           \n            sigma *= np.exp((c_sigma/0.8)*(np.linalg.norm(path_sigma)/np.sqrt(self.dim)-1))\n            \n            sigma = np.clip(sigma, 1e-10, 5.0)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "f83a3ea5-8ff6-41b7-a1a7-ca3d0d8fe1b9", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: An Enhanced Random Search algorithm that combines random exploration with local refinement steps around the best-found solutions, gradually decreasing the step size for finer local search.\n# Code: \n```", "code": "import numpy as np\n\nclass EnhancedRandomSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, reduction_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.reduction_factor = reduction_factor\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            f = func(x)\n            evals += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            # Local Refinement around the best solution\n            for _ in range(5):  # Perform a few local refinements\n                if evals >= self.budget:\n                    break\n                \n                new_x = self.x_opt + np.random.uniform(-step_size, step_size, size=self.dim)\n                new_x = np.clip(new_x, self.lb, self.ub)\n                new_f = func(new_x)\n                evals += 1\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n\n            step_size *= self.reduction_factor  # Reduce step size\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c209e657-365f-41e4-b355-0d9a8b6dad2f", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Simulated Annealing with adaptive temperature decay based on acceptance rate.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n        accept_rate = 0.0\n\n        while evals < self.budget:\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new\n                f = f_new\n                accept_rate +=1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            self.temp *= self.alpha\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c6ac7c08-8589-4742-9398-110c2b0145b8", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by sampling from the posterior distribution and updating the model with new observations.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Lower Confidence Bound\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.evals += self.n_initial_samples\n        self.X = X_init\n        self.y = y_init\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n\n        # Optimization loop\n        while self.evals < self.budget:\n            # Fit Gaussian Process\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            x_next = self.find_next_point()\n\n            # Evaluate function at new point\n            f_next = func(x_next)\n            self.evals += 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update optimal solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self):\n        # Simple random search for next point (can be replaced with more sophisticated optimization)\n        best_x = None\n        best_acq = np.inf\n        for _ in range(100):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition_function(x)\n            if acq < best_acq:\n                best_acq = acq\n                best_x = x\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "6911d403-5fc8-49d1-b101-ee71f7e66606", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "This algorithm combines a global random search with a local search around the best solutions found so far, adaptively adjusting the local search radius based on success.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=1.0, radius_reduction_factor=0.9, radius_increase_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_radius = initial_radius\n        self.radius_reduction_factor = radius_reduction_factor\n        self.radius_increase_factor = radius_increase_factor\n        self.success_threshold = success_threshold\n        self.radius = initial_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initial random search\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f = func(x)\n        self.budget -= 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        num_success = 0\n        while self.budget > 0:\n            # Local search around best solution\n            x_new = self.x_opt + np.random.uniform(-self.radius, self.radius, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                num_success += 1\n\n            #Adaptive Radius adjustment\n            if num_success > self.success_threshold * self.budget:\n                self.radius *= self.radius_increase_factor\n                num_success = 0\n            elif self.budget > 0:\n                x_rand = np.random.uniform(self.lb, self.ub, self.dim)\n                f_rand = func(x_rand)\n                self.budget -= 1\n                if f_rand < self.f_opt:\n                    self.f_opt = f_rand\n                    self.x_opt = x_rand\n                else:\n                    self.radius *= self.radius_reduction_factor\n                    num_success = 0 #Reset the successes\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b120f75c-2eea-40a2-ac8b-d5a31fe7497c", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Simulated Annealing with adaptive temperature adjustment based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n        temp = self.initial_temp\n        acceptance_history = []\n\n        while evals < self.budget:\n            x_new = x + np.random.normal(0, temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                acceptance_history.append(1)\n            else:\n                 acceptance_history.append(0)\n            \n            if len(acceptance_history) > 50:\n              acceptance_rate = np.mean(acceptance_history[-50:])\n              if acceptance_rate > 0.95:\n                  temp *= 1.1  # Increase temperature if too many acceptances\n              elif acceptance_rate < 0.05:\n                  temp *= 0.9 # Decrease temperature if too few acceptances\n              temp = np.clip(temp, 1e-6, self.initial_temp) # bound temperature\n\n            temp *= self.cooling_rate  # Cool down the temperature\n        \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "4ae8933f-3e61-4554-9b4f-9e925f79d633", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "An adaptive population-based search algorithm inspired by the hunting behavior of wolves, where individuals adjust their positions based on the distance to the best solution and a randomly selected individual, promoting exploration and exploitation.", "code": "import numpy as np\n\nclass WolfPackOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=40, alpha=0.1, beta=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.alpha = alpha\n        self.beta = beta\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Select a random individual\n                j = np.random.randint(0, self.pop_size)\n                \n                # Calculate distance to best and random individual\n                dist_best = np.linalg.norm(self.population[i] - self.x_opt)\n                dist_rand = np.linalg.norm(self.population[i] - self.population[j])\n\n                # Update position based on distances\n                new_pos = self.population[i] + self.alpha * (self.x_opt - self.population[i]) + self.beta * (self.population[j] - self.population[i])\n                new_pos = np.clip(new_pos, self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(new_pos)\n                evals += 1\n\n                # Update if better\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = new_pos\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_pos\n            \n            self.alpha = 0.99 * self.alpha\n            self.beta = 0.99 * self.beta\n            self.alpha = np.clip(self.alpha, 0.001, 0.1)\n            self.beta = np.clip(self.beta, 0.001, 0.1)\n\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "78e908dc-639a-4f07-a03f-6d3e21f7c31b", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Simulated Annealing with adaptive temperature decay based on acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n        temp = self.initial_temp\n\n        while evals < self.budget:\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Explore neighborhood\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_prob = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_prob:\n                    x = x_new\n                    f = f_new\n\n            # Adaptive temperature adjustment based on acceptance ratio\n            if evals % 100 == 0:\n                num_accept = 0\n                for i in range(100):\n                    x_test = x + np.random.normal(0, 0.1, size=self.dim)\n                    x_test = np.clip(x_test, self.lb, self.ub)\n                    f_test = func(x_test)\n                    delta_f_test = f_test - f\n                    if delta_f_test < 0 or np.random.rand() < np.exp(-delta_f_test / temp):\n                        num_accept += 1\n\n                acceptance_ratio = num_accept / 100.0\n                if acceptance_ratio > 0.5:\n                    temp *= 0.99 # Adjust cooling_rate based on the acceptance\n                elif acceptance_ratio < 0.1:\n                    temp *= 0.9\n\n            temp *= self.cooling_rate # Default Cooling\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "b391d2ac-f559-475e-be68-fbc51ddcc454", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Evolves a population of solutions using a combination of differential evolution mutation, a Gaussian local search around the best solution, and a worst-solution replacement strategy to maintain diversity.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Local Search around best solution\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    #Worst solution replacement\n                    if evals < self.budget:\n                        worst_index = np.argmax(self.fitness)\n                        if f < self.fitness[worst_index]:\n                            self.fitness[worst_index] = f\n                            self.population[worst_index] = trial\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = trial\n\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "8bf0cec5-ddab-4d35-82b8-5595a3350e01", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget management, adapting the step size and covariance matrix of a multivariate normal distribution to sample new candidate solutions.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))  # default CMA-ES pop size\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.ccov1 = (1/self.mueff) * ((self.mueff + 2) / (self.dim + 3))\n        self.ccovmu = (2/((self.dim+2)**2 + self.mueff))\n        self.ccovsep = 0.1 + self.ccov1\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        evals = 0\n        f_opt = np.inf\n        x_opt = None\n        \n        while evals < self.budget:\n            # Initialization\n            m = np.random.uniform(self.lb, self.ub, self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            B = np.eye(self.dim)\n            D = np.ones(self.dim)\n            C_eig = 0\n            \n            while evals < self.budget:\n                # Sample population\n                z = np.random.randn(self.dim, self.pop_size)\n                y = B @ (D * z)\n                x = m + sigma * y\n                x = np.clip(x, self.lb, self.ub)\n                \n                # Evaluate population\n                fitness = np.array([func(xi) for xi in x.T])\n                evals += self.pop_size\n                if evals > self.budget:\n                    evals = self.budget\n                    fitness = fitness[:self.pop_size-(evals - (evals - self.pop_size))]\n                \n                # Sort population\n                idx = np.argsort(fitness)\n                fitness = fitness[idx]\n                x = x[:, idx]\n                \n                # Update optimal solution\n                if fitness[0] < f_opt:\n                    f_opt = fitness[0]\n                    x_opt = x[:, 0]\n\n                # Update mean\n                m_old = m.copy()\n                m = np.sum(self.weights * x[:, :self.mu], axis=1)\n                y_mean = m - m_old\n                \n                # Update evolution paths\n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ z[:, :self.mu] @ self.weights)\n                hsig = (np.linalg.norm(ps)/np.sqrt(1-(1-self.cs)**(2*(evals/self.pop_size)))/self.chiN < 1.4 + 2/(self.dim+1))\n                pc = (1-1) * pc + hsig * np.sqrt(1 - 1) * y_mean\n                \n                # Update covariance matrix\n                artmp = (1/sigma) * (x[:, :self.mu] - m_old[:, np.newaxis])\n                C = (1-1) * C + self.ccov1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) + self.ccovmu * artmp @ np.diag(self.weights) @ artmp.T\n                \n                # Adapt step size\n                sigma = sigma * np.exp((self.cs/self.damps)*(np.linalg.norm(ps)/self.chiN - 1))\n                \n                sigma = np.clip(sigma, 1e-10, 5)\n                \n                # Eigen decomposition\n                if evals - C_eig > self.pop_size/(self.ccov1 + self.ccovmu + 1e-8)/self.dim/10:\n                    C_eig = evals\n                    C = np.triu(C) + np.triu(C, 1).T # enforce symmetry\n                    try:\n                        D, B = np.linalg.eig(C)\n                        D = np.sqrt(np.abs(D))\n                        B = np.real(B)\n                    except np.linalg.LinAlgError:\n                        D = np.ones(self.dim)\n                        B = np.eye(self.dim)\n                    D = np.real(D)\n                if np.any(D<0):\n                    D=np.abs(D)\n                    \n                if np.any(np.isnan(m)) or np.any(np.isnan(sigma)) or np.any(np.isnan(C)):\n                    break\n\n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "1714bc72-8876-4186-becf-0d0d15f86ba5", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired approach with simplified adaptation rules and a focus on budget management to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.mean = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.evals = 0\n        self.c_sigma = 0.5\n        self.d_sigma = 1\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.evals < self.budget:\n            population = []\n            fitness = []\n\n            for _ in range(self.pop_size):\n                z = np.random.randn(self.dim)\n                x = self.mean + self.sigma * z\n                x = np.clip(x, self.lb, self.ub)\n                f = func(x)\n                self.evals += 1\n                \n                population.append(x)\n                fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                if self.evals >= self.budget:\n                    break\n\n            if not population:\n                break  # Break if the inner loop didn't execute even once\n\n            population = np.array(population)\n            fitness = np.array(fitness)\n            \n            # Selection and update (simplified)\n            elite_indices = np.argsort(fitness)[:self.pop_size // 2]  # Select top half\n            elite_population = population[elite_indices]\n            \n            old_mean = self.mean.copy()\n            self.mean = np.mean(elite_population, axis=0)\n            \n            # Sigma adaptation (simplified)\n            sigma_change = np.linalg.norm(self.mean - old_mean) / self.sigma\n            self.sigma *= np.exp(self.c_sigma / self.d_sigma * (sigma_change - 1))\n            self.sigma = max(self.sigma, 1e-8) \n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "23f7573f-5027-4390-b65d-9c99209c5394", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restart mechanism and budget-aware adaptation of population size.\n# Code:\n```", "code": "import numpy as np\nimport cma\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n\n    def __call__(self, func):\n        opts = cma.CMAOptions()\n        opts['bounds'] = [self.lb, self.ub]\n        opts['verbose'] = -9 # disable output\n        opts['popsize'] = min(4 + int(3 * np.log(self.dim)), self.budget // 10) # Budget-aware initial population\n        es = cma.CMAEvolutionStrategy(self.x0, self.initial_sigma, opts)\n\n        evals = 0\n        restarts = 0\n        f_opt = np.inf\n        x_opt = None\n\n        while evals < self.budget:\n            solutions = []\n            for x in es.ask():\n                f = func(x)\n                solutions.append(f)\n                evals += 1\n                if f < f_opt:\n                    f_opt = f\n                    x_opt = x\n                if evals >= self.budget:\n                    break\n\n            es.tell(es.ask(), solutions)\n            es.logger.add()  # write data to disc to be readable afterwards\n            es.disp()\n\n            if es.stop():\n                restarts += 1\n                self.x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                opts['popsize'] = min(4 + int(3 * np.log(self.dim)), (self.budget - evals) // 10) # Reduce Popsize\n                es = cma.CMAEvolutionStrategy(self.x0, self.initial_sigma, opts) # restart with new initial point\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "a668c6d0-224e-4554-bd58-e29233e393a3", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "# Description: This algorithm adapts the velocity update in PSO by introducing a constriction factor to dampen oscillations and enhance convergence, while also incorporating a mutation operator to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass ConstrictionParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, constriction_factor=0.729, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.constriction_factor = constriction_factor\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n\n            velocities = self.constriction_factor * (self.inertia * velocities\n                          + self.cognitive_coeff * r1 * (personal_best_positions - population)\n                          + self.social_coeff * r2 * (global_best_position - population))\n\n            population = population + velocities\n\n            # Clip positions to bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            population[mutation_mask] = np.random.uniform(self.lb, self.ub, size=np.sum(mutation_mask))\n\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.population_size\n\n            # Update personal best positions and fitnesses\n            for i in range(self.population_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "24a62eeb-f1f9-4374-94b9-3ed7756dc96f", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_fitness = fitness[best_index]\n        best_solution = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros((self.pop_size, self.dim))\n            new_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                new_population[i] = trial\n                new_fitness[i] = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if new_fitness[i] < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = new_fitness[i]\n\n                    if new_fitness[i] < best_fitness:\n                        best_fitness = new_fitness[i]\n                        best_solution = trial.copy()\n\n            # Adaptive parameter adjustment (example: simple random adjustment)\n            if generation % 10 == 0:\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n            if self.budget <=0:\n                break\n\n        self.f_opt = best_fitness\n        self.x_opt = best_solution\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "24c1ed14-1641-48b4-ad86-233331e83f9d", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware adaptation of the step size.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1 / self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        evals = 0\n        while evals < self.budget:\n            z = np.random.randn(self.dim, self.pop_size)\n            \n            try:\n                L = np.linalg.cholesky(self.C)\n                x = self.m[:, np.newaxis] + self.sigma * L @ z\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                w, V = np.linalg.eig(self.C)\n                w[w < 0] = 1e-8  # Replace negative eigenvalues with a small positive value\n                self.C = V @ np.diag(w) @ V.T\n                L = np.linalg.cholesky(self.C)\n                x = self.m[:, np.newaxis] + self.sigma * L @ z\n\n            x = np.clip(x, self.lb, self.ub)\n\n            fitness = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[:, np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n            self.m = np.sum(x_mu * self.weights, axis=1)\n            z_w = np.sum(z_mu * self.weights, axis=1)\n\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (L @ z_w)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma) / self.chiN - 1))\n\n            h_sigma = int((np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2 * evals / self.pop_size)) / self.chiN) < (1.4 + 2 / (self.dim + 1)))\n            self.p_c = (1 - self.c_c) * self.p_c + h_sigma * np.sqrt(self.c_c * (2 - self.c_c)) * z_w\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.p_c, self.p_c) + self.c_mu * (x_mu - self.m[:, np.newaxis]) @ np.diag(self.weights) @ (x_mu - self.m[:, np.newaxis]).T / self.sigma**2\n\n            # Budget aware step size adjustment\n            remaining_budget = self.budget - evals\n            if remaining_budget < self.pop_size:\n                self.sigma *= 0.5\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b4dc9125-518e-490b-a59a-6f42fa5aa945", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success of previous generations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, population_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_rate = 0.1\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        best_solution = population[best_index].copy()\n        best_fitness = fitness[best_index]\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.population_size):\n                # Mutation\n                indices = [j for j in range(self.population_size) if j != i]\n                if len(indices) < 3:\n                  continue # prevent errors due to small populationsize\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                \n                # Clip mutant to bounds\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluate trial vector\n                f = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Selection\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    \n                    # Update archive with unsuccessful solutions (exploration)\n                    if np.random.rand() < self.archive_rate:\n                      self.archive.append(population[i].copy())\n                      if len(self.archive) > self.population_size: #limit archive size\n                        self.archive.pop(0)\n                else:\n                    new_population[i] = population[i].copy()\n                    new_fitness[i] = fitness[i]\n\n            population = new_population.copy()\n            fitness = new_fitness.copy()\n            \n            # Find best solution in current generation\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < best_fitness:\n                best_fitness = fitness[best_index]\n                best_solution = population[best_index].copy()\n\n            # Adaptive parameter control (example: adjusting F)\n            success_indices = fitness < fitness # Check if comparison is correct with previous fitness\n            if np.any(success_indices):\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)  # Adjust F stochastically\n\n        self.f_opt = best_fitness\n        self.x_opt = best_solution\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "7e9f6f28-5ccf-424c-9c73-d6c3ca79c9b2", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success rate of previous generations, balancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, population_size=50, F=0.5, CR=0.9, F_adapt=0.1, CR_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Find the best initial solution\n        best_index = np.argmin(fitness)\n        best_fitness = fitness[best_index]\n        best_solution = population[best_index].copy()\n        \n        archive = []\n\n        # Optimization loop\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.population_size):\n                # Mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                \n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, self.lb, self.ub)  # Clip to bounds\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial_vector[j] = mutant[j]\n                    else:\n                        trial_vector[j] = population[i][j]\n                \n                new_population[i] = trial_vector\n                new_fitness[i] = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n            \n            if self.budget <= 0:\n                break\n            \n            # Selection\n            for i in range(self.population_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n                    archive.append(new_fitness[i] - fitness[i])\n\n                if fitness[i] < best_fitness:\n                    best_fitness = fitness[i]\n                    best_solution = population[i].copy()\n\n            if len(archive) > 10:\n                archive = archive[-10:]\n\n            if len(archive) > 0:\n                success_rate = sum(1 for x in archive if x < 0) / len(archive)\n                self.F = np.clip(self.F + self.F_adapt * (success_rate - 0.5), 0.1, 1.0)\n                self.CR = np.clip(self.CR + self.CR_adapt * (success_rate - 0.5), 0.1, 1.0)\n\n        self.f_opt = best_fitness\n        self.x_opt = best_solution\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "dee1d75b-27c9-405c-8589-ad36a81579c8", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) iteratively updates a population of candidate solutions, adapting the covariance matrix of a multivariate normal distribution to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = (1 / self.mueff) * min(1, (self.mueff + 2) / (self.dim + self.mueff + 5))\n        self.ccovmu = (2 / (self.mueff**2 + self.dim)) * min(1, (self.mueff + 2) / (self.dim + self.mueff + 5))\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, self.lb, self.ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            y = x[:self.mu] - self.mean\n            z = z[idx[:self.mu]]\n\n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.mean - self.mean) / self.sigma # Simplified\n            self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * np.outer(self.ps, self.ps) + self.ccovmu * np.sum(self.weights[:,None,None] * y[:,:,None] * y[:,None,:], axis=0)\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "f2cbbfd0-d991-4ff0-8f9d-e3b2d1cceafe", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "This algorithm uses a Gaussian process to model the objective function and an acquisition function (Expected Improvement) to balance exploration and exploitation when selecting points to evaluate.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel='RBF'):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X = None\n        self.y = None\n        self.gpr = None\n        if kernel == 'RBF':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        elif kernel == 'Matern':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * Matern(length_scale=1.0, length_scale_bounds=\"fixed\", nu=1.5) # or nu=2.5\n\n    def expected_improvement(self, x, gpr, xi=0.01):\n        mu, sigma = gpr.predict(x.reshape(1, -1), return_std=True)\n        mu_sample_opt = np.max(self.y)\n\n        with np.errstate(divide='warn'):\n            imp = mu - mu_sample_opt - xi\n            Z = imp / sigma\n            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return -ei\n\n    def propose_location(self, gpr, n_restarts=25):\n        # Find the best point to sample by maximizing acquisition function.\n        dim = self.dim\n        lb = self.lb\n        ub = self.ub\n\n        best_location = None\n        best_acquisition_value = 1\n        for iteration in range(n_restarts):\n            start_point = np.random.uniform(lb, ub, size=dim)\n            bounds = [(lb, ub)] * dim\n            result = minimize(self.expected_improvement, start_point, args=(gpr,), method='L-BFGS-B', bounds=bounds) #Changed method\n            if -result.fun < best_acquisition_value:\n                best_acquisition_value = -result.fun\n                best_location = result.x\n        return best_location\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n\n        # Gaussian process regression\n        self.gpr = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5, alpha=1e-5) #Added restart optimizer and regularization\n        self.gpr.fit(self.X, self.y)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Find next point to sample\n            x_next = self.propose_location(self.gpr)\n\n            # Sample the objective function\n            y_next = func(x_next)\n            self.budget -= 1\n\n            # Append data and update model\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, y_next)\n            self.gpr.fit(self.X, self.y)\n\n        # Best found solution\n        best_index = np.argmin(self.y)\n        self.x_opt = self.X[best_index]\n        self.f_opt = self.y[best_index]\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "ba913884-04cb-4649-8ab6-4868a3ebd3c9", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "# Description: This algorithm uses a Gaussian process to model the objective function and an acquisition function to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass BayesianOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_points=10, exploration_noise=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = n_initial_points\n        self.exploration_noise = exploration_noise\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x):\n        x = x.reshape(1, -1)\n        mu, sigma = self.gp.predict(x, return_std=True)\n        return mu - self.exploration_noise * sigma\n\n    def __call__(self, func):\n        # Initial exploration\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_points, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        evals = self.n_initial_points\n\n        self.gp.fit(self.X, self.y)\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n\n        while evals < self.budget:\n            # Find the next point to evaluate\n            from scipy.optimize import minimize\n            \n            def objective(x):\n                return -self.acquisition_function(x)\n            \n            bounds = [(self.lb, self.ub)] * self.dim\n            \n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            \n            res = minimize(objective, x0, method='L-BFGS-B', bounds=bounds)\n            x_next = res.x\n\n            # Evaluate the function at the new point\n            f_next = func(x_next)\n            evals += 1\n\n            # Update the Gaussian process\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            self.gp.fit(self.X, self.y)\n\n            # Update the best solution found so far\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "0d09aab3-bf59-4e05-b04f-09c3ccb04c68", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: This algorithm uses a Gaussian process to model the objective function and iteratively samples new points based on the upper confidence bound (UCB) acquisition function.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass BayesianOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def acquisition_function(self, x, gp, xi=0.05):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        mu = mu[0]\n        sigma = sigma[0]\n        return mu + xi * sigma\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.evals += self.n_initial_samples\n\n        self.X = X_init\n        self.y = y_init\n        \n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n\n        while self.evals < self.budget:\n            # Fit Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to sample (maximize acquisition function)\n            x_next = self.find_next_sample()\n\n            # Evaluate function at new point\n            f_next = func(x_next)\n            self.evals += 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update optimal solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n            \n\n        return self.f_opt, self.x_opt\n\n    def find_next_sample(self):\n        # Simple grid search for demonstration purposes. In practice, use a more sophisticated optimization method.\n        n_candidates = 1000\n        X_cand = np.random.uniform(self.lb, self.ub, size=(n_candidates, self.dim))\n        \n        acq_values = np.array([self.acquisition_function(x, self.gp) for x in X_cand])\n        \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "744a6279-4d2e-45bf-8c62-28c5b79188d6", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "A population-based algorithm that iteratively evolves solutions by stochastically sampling from a distribution centered around the current best and a diversification strategy based on orthogonal learning.", "code": "import numpy as np\n\nclass OrthogonalSamplingOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, sample_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sample_size = sample_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Sampling around the best\n                idxs = np.random.choice(self.pop_size, self.sample_size, replace=False)\n                sample = population[idxs]\n                best_idx = np.argmin(fitness[idxs])\n                best_sample = sample[best_idx]\n\n                # Create a new solution by sampling around the best\n                new_solution = np.random.normal(loc=best_sample, scale=0.5, size=self.dim)\n                new_solution = np.clip(new_solution, self.lb, self.ub)\n\n                # Orthogonal Diversification\n                orthogonal_vector = np.random.normal(0, 1, self.dim)\n                orthogonal_vector /= np.linalg.norm(orthogonal_vector)  # Normalize\n\n                # Project new_solution onto the hyperplane orthogonal to orthogonal_vector\n                projection = np.dot(new_solution, orthogonal_vector)\n                new_solution -= projection * orthogonal_vector\n\n                new_solution = np.clip(new_solution, self.lb, self.ub)\n\n\n                f = func(new_solution)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_solution\n\n                if evals >= self.budget:\n                    break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "e08ae69d-96be-40d7-bef3-02d06610c053", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Simultaneous perturbation stochastic approximation (SPSA) optimizes a function by estimating the gradient using only two function evaluations, making it suitable for high-dimensional problems with limited budget.", "code": "import numpy as np\n\nclass SPSA:\n    def __init__(self, budget=10000, dim=10, a=0.01, c=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.a = a\n        self.c = c\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f_val = func(x)\n        self.f_opt = f_val\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a random perturbation vector\n            delta = np.random.choice([-1, 1], size=self.dim)\n\n            # Calculate a_k and c_k (SPSA parameters)\n            a_k = self.a / (evals**0.602)\n            c_k = self.c / (evals**0.101)\n            \n            # Perturb the current solution in both directions\n            x_plus = x + c_k * delta\n            x_minus = x - c_k * delta\n\n            # Clip to boundaries\n            x_plus = np.clip(x_plus, self.lb, self.ub)\n            x_minus = np.clip(x_minus, self.lb, self.ub)\n\n            # Evaluate the function at the perturbed points\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            evals += 2\n\n            # Estimate the gradient\n            grad_est = (f_plus - f_minus) / (2 * c_k * delta)\n\n            # Update the solution\n            x = x - a_k * grad_est\n\n            # Clip to boundaries\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate function at new x\n            f_val = func(x)\n            evals +=1 \n\n            # Update the best solution if necessary\n            if f_val < self.f_opt:\n                self.f_opt = f_val\n                self.x_opt = x\n\n            if evals >= self.budget:\n                evals -= 1 #correct the over-budgeting error\n                break\n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "e1036d58-223d-4307-ae68-5be9694ffa56", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3", "ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d"], "algorithm": "Simulated Annealing with adaptive temperature schedule, focusing on intensifying the search around the best-so-far solution.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        evals = 1\n\n        while evals < self.budget:\n            # Generate neighbor\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Acceptance probability\n            delta_e = f_new - f\n\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Adaptive temperature schedule\n            temp *= self.cooling_rate\n            self.step_size *= 0.99 \n            self.step_size = np.clip(self.step_size, 0.001, 0.1)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "bb03e959-ced9-42ae-b2ef-9083d09523d2", "parents": ["ab7ba4a0-44cc-49b1-b7ca-a1ea53edb69d", "ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "Evolves a population by blending the best individual with randomly selected individuals, adapting the blending strength based on success.", "code": "import numpy as np\n\nclass BlendedDifferenceEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, blend_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.blend_rate = blend_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Find best individual\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                # Select a random individual to blend with\n                random_idx = np.random.randint(0, self.pop_size)\n                while random_idx == i:\n                    random_idx = np.random.randint(0, self.pop_size)\n                random_individual = population[random_idx]\n\n                # Blend the best individual with the random individual\n                blended = self.blend_rate * best_individual + (1 - self.blend_rate) * random_individual\n\n                # Add a difference vector from another random individual\n                diff_idx1 = np.random.randint(0, self.pop_size)\n                while diff_idx1 == i or diff_idx1 == random_idx:\n                    diff_idx1 = np.random.randint(0, self.pop_size)\n                diff_idx2 = np.random.randint(0, self.pop_size)\n                while diff_idx2 == i or diff_idx2 == random_idx or diff_idx2 == diff_idx1:\n                    diff_idx2 = np.random.randint(0, self.pop_size)\n                \n                blended += 0.1 * (population[diff_idx1] - population[diff_idx2])\n                \n                blended = np.clip(blended, self.lb, self.ub)\n\n                # Evaluate the blended individual\n                f = func(blended)\n                evals += 1\n\n                # Update population if the blended individual is better\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = blended\n                    if f < f_opt:\n                        f_opt = f\n                        x_opt = blended\n            self.blend_rate = np.clip(self.blend_rate + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        self.f_opt = f_opt\n        self.x_opt = x_opt\n        return f_opt, x_opt", "objective": -0.26569, "other_inf": null}
{"id": "41d3f311-41a8-4a4b-958b-d58067654a83", "parents": ["bb03e959-ced9-42ae-b2ef-9083d09523d2"], "algorithm": "# Description: Population-based algorithm using a combination of differential evolution mutation and local search, adapting the mutation strength and step size based on success.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.5, local_search_prob=0.1, local_search_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.local_search_prob = local_search_prob\n        self.local_search_step = local_search_step\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        f_opt = np.min(fitness)\n        x_opt = population[np.argmin(fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                mutated = population[i] + self.mutation_rate * (x_r1 - x_r2) + self.mutation_rate * (x_r3 - population[i])\n                mutated = np.clip(mutated, self.lb, self.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    direction /= np.linalg.norm(direction)\n                    local_point = population[i] + self.local_search_step * direction\n                    local_point = np.clip(local_point, self.lb, self.ub)\n                    \n                    f_local = func(local_point)\n                    evals += 1\n\n                    if f_local < fitness[i]:\n                        fitness[i] = f_local\n                        population[i] = local_point\n                        if f_local < f_opt:\n                            f_opt = f_local\n                            x_opt = local_point\n                        self.local_search_step *= 1.05 #Increase local search step if it finds better values\n                    else:\n                        self.local_search_step *= 0.95 #Reduce local search step if it doesn't find better values\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < 0.9\n                trial_vector = np.where(crossover_mask, mutated, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    if f < f_opt:\n                        f_opt = f\n                        x_opt = trial_vector\n                    self.mutation_rate *= 0.95 # Decrease the mutation rate if finding good solutions\n                else:\n                     self.mutation_rate *= 1.05 # Increase the mutation rate if not finding good solutions\n                self.mutation_rate = np.clip(self.mutation_rate, 0.1, 0.9)\n\n        self.f_opt = f_opt\n        self.x_opt = x_opt\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "ae58a798-b484-453a-8797-eec00017fd5e", "parents": ["ba69aadf-6d03-4360-9722-61b7328009d3"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, mu_eff=None):\n        self.budget = budget\n        self.dim = dim\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2) if mu_eff is None else mu_eff\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.cs if damps is None else damps\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff) if ccov1 is None else ccov1\n        self.ccovmu = 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff)\n        self.cc = (4 + self.mu_eff/self.dim) / (self.dim + 4 + 2*self.mu_eff/self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n\n    def __call__(self, func):\n        evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while evals < self.budget:\n            Z = np.random.randn(self.dim, self.pop_size)\n            X = self.mean[:, None] + self.sigma * np.dot(np.linalg.cholesky(self.C), Z)\n            X = np.clip(X, self.lb, self.ub)\n            fitness = np.array([func(x) for x in X.T])\n            evals += self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = X[:, np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            X_mu = X[:, idx[:self.mu]]\n            z_mu = Z[:, idx[:self.mu]]\n\n            self.mean = np.dot(X_mu, self.weights)\n\n            ps_temp = np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), np.dot(z_mu, self.weights))))\n            self.ps = (1 - self.cs) * self.ps + ps_temp\n\n            norm_ps = np.linalg.norm(self.ps)\n            \n            hsig = norm_ps / np.sqrt(1 - (1 - self.cs)**(2 * (evals / self.pop_size))) < (2 + self.mu_eff) / (self.dim + 2)\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mu_eff) * (self.mean - (self.mean - self.sigma * np.dot(np.linalg.cholesky(self.C), np.dot(z_mu, self.weights))))\n            \n            artmp = (1/self.sigma) * (X_mu - self.mean[:,None])\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                + self.ccovmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n\n            self.sigma *= np.exp((self.cs / self.damps) * (norm_ps/self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = np.linalg.eigvalsh(self.C).clip(1e-10, None) * np.eye(self.dim)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "parents": [], "algorithm": "This algorithm employs a differential evolution strategy with a dynamically adjusted crossover probability based on fitness improvements.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n            else:\n                break\n        return self.f_opt, self.x_opt\n\n    def generate_trial_vectors(self):\n        trial_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n            v = x_r1 + self.F * (x_r2 - x_r3)\n            \n            trial_vector = np.zeros(self.dim)\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    trial_vector[j] = v[j]\n                else:\n                    trial_vector[j] = self.pop[i][j]\n            \n            trial_vector = np.clip(trial_vector, self.lb, self.ub)  # Keep within bounds\n            trial_pop[i] = trial_vector\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        improved = False\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_pop[i])\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial_pop[i]\n                    self.fitness[i] = f_trial\n                    improved = True\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i]\n\n        if improved:\n            self.cr = min(1.0, self.cr + 0.1)\n        else:\n             self.cr = max(0.1, self.cr - 0.1)\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            trial_pop = self.generate_trial_vectors()\n            self.f_opt, self.x_opt = self.selection(func, trial_pop)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "5abdda99-136f-4735-bfc8-d96bb12bc335", "parents": [], "algorithm": "# Description: This algorithm combines a global random search with a local search around the best-found solution, dynamically adjusting the local search radius based on the success rate.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5, reduction_factor=0.9, expansion_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.reduction_factor = reduction_factor\n        self.expansion_factor = expansion_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        success_count = 0\n\n        # Initial random search\n        for i in range(min(1000, self.budget)):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            f = func(x)\n            eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                success_count += 1\n\n        # Adaptive local search\n        while eval_count < self.budget:\n            x_new = np.clip(self.x_opt + np.random.normal(0, self.radius, size=self.dim), self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                success_count += 1\n\n            # Adjust radius\n            if eval_count % 100 == 0:\n                success_rate = success_count / 100\n                success_count = 0\n\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expansion_factor\n                else:\n                    self.radius *= self.reduction_factor\n                \n                self.radius = np.clip(self.radius, 1e-6, (self.ub - self.lb)/2)  # Prevent radius from becoming too small or large\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b425da58-8737-4fd4-9f67-c3bd59b2f28c", "parents": [], "algorithm": "A population-based algorithm that combines exploration and exploitation by updating particles' positions based on their own best position, the global best position, and a random component to avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = particles.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = particles[global_best_index].copy()\n        self.f_opt = fitness[global_best_index].copy()\n        self.x_opt = particles[global_best_index].copy()\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = self.w * velocities + \\\n                         self.c1 * r1 * (personal_best_positions - particles) + \\\n                         self.c2 * r2 * (global_best_position - particles)\n\n            particles = particles + velocities\n\n            # Clip positions to bounds\n            particles = np.clip(particles, self.lb, self.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in particles])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal best positions and fitnesses\n            improved = new_fitness < personal_best_fitnesses\n            personal_best_positions[improved] = particles[improved].copy()\n            personal_best_fitnesses[improved] = new_fitness[improved].copy()\n\n            # Update global best position and fitness\n            current_best_index = np.argmin(new_fitness)\n            if new_fitness[current_best_index] < self.f_opt:\n                self.f_opt = new_fitness[current_best_index].copy()\n                self.x_opt = particles[current_best_index].copy()\n                global_best_position = particles[current_best_index].copy()\n\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "fa406f8b-503f-4167-82fd-4c94b992d76a", "parents": [], "algorithm": "Evolves a population of solutions using differential evolution with adaptive parameters and a local search component.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_mask = self.rng.random(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Adaptive F and CR (simple version)\n                if evals % (self.budget // 10) == 0:\n                    self.F = 0.5 + self.rng.normal(0, 0.1)\n                    self.CR = 0.7 + self.rng.normal(0, 0.1)\n                    self.F = np.clip(self.F, 0.1, 0.9)\n                    self.CR = np.clip(self.CR, 0.1, 0.9)\n\n                if evals >= self.budget:\n                  break\n\n            # Local Search (occasionally improve the best solution)\n            if evals % (self.budget // 20) == 0:\n                # Simple local search around x_opt\n                local_search_radius = 0.1 * (self.ub - self.lb)\n                x_local = self.x_opt + self.rng.uniform(-local_search_radius, local_search_radius, self.dim)\n                x_local = np.clip(x_local, self.lb, self.ub)\n\n                f_local = func(x_local)\n                evals += 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "7eff71d5-1558-483a-9218-f4670a95079a", "parents": [], "algorithm": "Simulated Annealing with adaptive temperature schedule based on function evaluation feedback.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        eval_count = 1\n\n        while eval_count < self.budget:\n            x_new = x + np.random.normal(0, temp, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                probability = np.exp(-delta_f / temp)\n                if np.random.rand() < probability:\n                    x = x_new\n                    f = f_new\n\n            # Adaptive temperature update\n            if eval_count % (self.dim * 5) == 0:\n                temp = self.cooling_rate * temp \n                if temp < 1e-6:\n                    temp = 1e-6\n        \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "646650a7-1e00-49f3-a0bc-efb307e07e55", "parents": [], "algorithm": "Adaptive Differential Evolution with shrinking population size and restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5*dim\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_trigger = 0.1 * budget\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        generation = 0\n        stagnation_counter = 0\n        last_improvement = 0\n\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, self.pop[i])\n                f = func(trial)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        stagnation_counter = 0\n                        last_improvement = generation\n                else:\n                    stagnation_counter += 1\n            \n            if stagnation_counter > self.restart_trigger:\n                self.pop_size = max(int(self.pop_size * 0.8), 10)  # Shrink population size\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n                stagnation_counter = 0\n                last_improvement = generation  # Reset last improvement tracker\n            \n            if self.pop_size < 10:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(5*self.dim, self.dim))\n                self.pop_size = 5*self.dim\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n                stagnation_counter = 0\n                last_improvement = generation  # Reset last improvement tracker\n\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "25905352-106d-4e0d-99af-8fe4825a3248", "parents": [], "algorithm": "Adaptive Differential Evolution with stochastic ranking, population size adaptation and restart mechanism to diversify the search.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5*dim\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.nevals = self.pop_size\n        self.min_history = [np.min(self.fitness)]\n        self.restart_counter = 0\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                if self.nevals >= self.budget:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.pop[idxs]\n                x_mutated = self.pop[i] + self.F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                # Selection\n                f_trial = func(x_trial)\n                self.nevals += 1\n\n                # Stochastic Ranking\n                if (self.fitness[i] <= 0 and f_trial <= 0) or (self.fitness[i] > 0 and f_trial > 0):\n                    if f_trial < self.fitness[i]:\n                        self.pop[i] = x_trial\n                        self.fitness[i] = f_trial\n                else:\n                     if f_trial < self.fitness[i]:\n                         self.pop[i] = x_trial\n                         self.fitness[i] = f_trial\n                    \n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            self.min_history.append(np.min(self.fitness))\n\n            # Population size adaptation\n            if len(self.min_history) > 10 and np.std(self.min_history[-10:]) < 1e-6:\n                self.pop_size = int(self.pop_size * 1.1)  # Increase pop size\n                self.pop_size = min(self.pop_size, 20 * self.dim) # cap it\n                new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                self.pop = np.concatenate((self.pop, new_pop))\n                self.fitness = np.concatenate((self.fitness, np.array([func(x) for x in new_pop])))\n                self.nevals += len(new_pop)\n            elif len(self.min_history) > 10 and np.std(self.min_history[-10:]) > 1e-3:\n                self.pop_size = int(self.pop_size * 0.9) # Decrease Pop size\n                self.pop_size = max(self.pop_size, self.dim) # At least be dim\n\n                sorted_indices = np.argsort(self.fitness)\n                self.pop = self.pop[sorted_indices[:self.pop_size]]\n                self.fitness = self.fitness[sorted_indices[:self.pop_size]]\n            \n            # Restart mechanism\n            if len(self.min_history) > 50 and np.std(self.min_history[-50:]) < 1e-8:\n                self.restart_counter += 1\n                if self.restart_counter >= 5:  # restart after stagnation\n                    self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.pop])\n                    self.nevals += self.pop_size\n                    self.min_history = [np.min(self.fitness)]\n                    self.restart_counter = 0\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "fabff8fc-40a7-4497-b43f-0c3e10d40e26", "parents": [], "algorithm": "A population-based algorithm with adaptive step size and local search to explore the search space efficiently and converge towards the optimum.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        while evals < self.budget:\n            # Select best individual\n            best_idx = np.argmin(fitness)\n            best_x = population[best_idx]\n            best_f = fitness[best_idx]\n            \n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Generate new individuals through mutation and crossover (simplified)\n            new_population = np.copy(population)\n            for i in range(self.pop_size):\n                # Mutation (adaptive step size)\n                mutation_direction = np.random.randn(self.dim)\n                new_x = population[i] + self.step_size * mutation_direction\n                new_x = np.clip(new_x, self.lb, self.ub) # Clip values\n                \n                # Evaluate new individual\n                new_f = func(new_x)\n                evals += 1\n                \n                if new_f < fitness[i]:\n                    new_population[i] = new_x\n                    fitness[i] = new_f\n                else:\n                    # Local search around the current individual if mutation fails\n                    local_x = population[i] + self.step_size * np.random.randn(self.dim) * 0.1\n                    local_x = np.clip(local_x, self.lb, self.ub)\n                    local_f = func(local_x)\n                    evals += 1\n\n                    if local_f < fitness[i]:\n                        new_population[i] = local_x\n                        fitness[i] = local_f\n\n\n                if evals >= self.budget:\n                    break # Break if we exceed the budget\n                \n            population = new_population\n\n            # Adapt step size (simple rule: decrease if no improvement, increase otherwise)\n            if np.min(fitness) >= best_f:\n              self.step_size *= 0.9\n            else:\n                self.step_size *= 1.1\n                self.step_size = min(self.step_size, 1.0) # Cap the step size\n\n        # Final check for the best individual\n        best_idx = np.argmin(fitness)\n        best_x = population[best_idx]\n        best_f = fitness[best_idx]\n        \n        if best_f < self.f_opt:\n            self.f_opt = best_f\n            self.x_opt = best_x\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "eb9a9304-7ccd-4b7a-9263-a0304b24f092", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and adaptive population sizing to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_percentage=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_percentage = mu_percentage\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        \n        while self.evals < self.budget:\n            # --- Initialization ---\n            mean = self.lb + self.rng.random(self.dim) * (self.ub - self.lb)\n            sigma = self.initial_sigma\n            pop_size = 4 + int(3 * np.log(self.dim))\n            mu = int(pop_size * self.mu_percentage)\n\n            C = np.eye(self.dim)  # Covariance matrix\n            pc = np.zeros(self.dim)  # Evolution path for C\n            ps = np.zeros(self.dim)  # Evolution path for sigma\n\n            # --- Parameters ---\n            c_sigma = (mu / pop_size) / (2 + mu / pop_size)\n            d_sigma = 1 + 2 * max(0, np.sqrt((mu / pop_size - 1) / (self.dim + 5)) - 1)\n            c_c = (4 + mu / self.dim) / (self.dim + 4 + 2 * mu / self.dim)\n            c_1 = 2 / ((self.dim + 1.3)**2 + mu)\n            c_mu = min(1 - c_1, 2 * (mu - 1 + 1 / mu) / ((self.dim + 2)**2 + mu))\n            \n            eigen_decomposition_required = 10 #How many iterations to wait before updating B and D\n            \n            while self.evals < self.budget:\n                # --- Sample population ---\n                z = self.rng.normal(0, 1, size=(pop_size, self.dim))\n                \n                if eigen_decomposition_required > 0:\n                   y = np.real(z @ np.linalg.cholesky(C).T)\n                   eigen_decomposition_required -= 1\n                else:\n                   eigen_decomposition_required = 10\n                   C = np.triu(C) + np.triu(C, k=1).T\n                   D, B = np.linalg.eigh(C)\n                   D = np.sqrt(D)\n                   y = (z * D) @ B.T\n                x = mean + sigma * y\n                x = np.clip(x, self.lb, self.ub)\n\n                # --- Evaluate population ---\n                fitness = np.array([func(xi) for xi in x])\n                self.evals += pop_size\n                \n                # --- Sort population ---\n                idx = np.argsort(fitness)\n                fitness = fitness[idx]\n                x = x[idx]\n                y = y[idx]\n\n                # --- Update best solution ---\n                if fitness[0] < self.f_opt:\n                    self.f_opt = fitness[0]\n                    self.x_opt = x[0]\n                \n                # --- Update CMA parameters ---\n                mean_old = mean.copy()\n                mean = np.mean(x[:mu], axis=0)\n                y_w = mean - mean_old\n                y_w = y_w / sigma #Re-scale the difference in means. \n                \n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * y_w\n                \n                norm_ps = np.linalg.norm(ps)\n                \n                sigma = sigma * np.exp(c_sigma / d_sigma * (norm_ps / (np.sqrt(self.dim)) - 1))\n                sigma = min(sigma, (self.ub-self.lb)/2)\n                sigma = max(sigma, (self.ub-self.lb)/2000)\n\n                pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * np.sqrt(mu / pop_size) * (mean - mean_old) / sigma\n                \n                C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n                \n                for k in range(mu):\n                   C = C + c_mu * (y[k,:][:, None] @ y[k,:][None, :])\n                   \n                C = np.triu(C) + np.triu(C, k=1).T\n\n                C = np.clip(C, -1, 1)\n\n                if self.evals >= self.budget:\n                    break\n\n            if self.f_opt == np.inf:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "72ff30c9-3259-4b96-8638-4cca224ac60e", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: Employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation through an acquisition function based on the upper confidence bound.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.rng = np.random.default_rng()\n        self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x, gp, xi=0.05):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu + xi * sigma\n\n    def propose_location(self, gp, n_iter=5):\n        best_x = None\n        best_acq = -np.inf\n        for _ in range(n_iter):\n            x = self.lb + self.rng.random(self.dim) * (self.ub - self.lb)\n            acq = self.acquisition_function(x, gp)\n            if acq > best_acq:\n                best_acq = acq\n                best_x = x\n        return best_x\n    \n    def initialize(self, func):\n        self.X = self.lb + self.rng.random((self.n_initial_samples, self.dim)) * (self.ub - self.lb)\n        self.y = np.array([func(x) for x in self.X])\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        return self.n_initial_samples\n    \n    def __call__(self, func):\n        evals = self.initialize(func)\n        while evals < self.budget:\n            self.gp.fit(self.X, self.y)\n            x_next = self.propose_location(self.gp)\n            f_next = func(x_next)\n            evals += 1\n            \n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "910adcec-8bc4-44ac-b041-6818e020f124", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm performs a spiral optimization, contracting around the best solution found so far while exploring new regions in a spiral pattern.\n# Code:\n```", "code": "import numpy as np\n\nclass SpiralOptimization:\n    def __init__(self, budget=10000, dim=10, spiral_param=0.1, pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.spiral_param = spiral_param\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Spiral movement around the best solution\n                r = np.linalg.norm(population[i] - self.x_opt)\n                theta = self.rng.random(self.dim) * 2 * np.pi\n                \n                new_x = self.x_opt + r * np.exp(-self.spiral_param * theta) * np.cos(theta) + self.rng.normal(0, 0.01, self.dim)\n\n                new_x = np.clip(new_x, self.lb, self.ub)\n                \n                f = func(new_x)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_x\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n                if evals >= self.budget:\n                    break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "dd013a35-383c-4538-b0b6-6fa756a10ea1", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "A population-based algorithm using Gaussian mutation and a selection mechanism based on fitness rank and distance to the best solution.", "code": "import numpy as np\n\nclass GaussianRankDistanceAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            # Rank the population based on fitness\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                mutant = population[i] + self.mutation_rate * self.rng.normal(0, 1, self.dim)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Evaluate mutant\n                f_mutant = func(mutant)\n                evals += 1\n\n                # Selection: Based on rank and distance to best\n                rank_i = np.where(ranked_indices == i)[0][0]  # Find rank of current individual\n\n                # Distance to best solution\n                distance_i = np.linalg.norm(population[i] - self.x_opt)\n                distance_mutant = np.linalg.norm(mutant - self.x_opt)\n\n                if f_mutant < fitness[i]:\n                    fitness[i] = f_mutant\n                    population[i] = mutant\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n                elif rank_i > self.pop_size // 2 and distance_mutant < distance_i:\n                    # Replace if low rank and closer to the best\n                    fitness[i] = f_mutant\n                    population[i] = mutant\n                \n                if evals >= self.budget:\n                  break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "311e24df-7da5-48cd-928f-9a17c81bfccb", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: This algorithm iteratively refines a population of solutions by applying a Gaussian mutation with a dynamically adjusted standard deviation, favoring exploration in early stages and exploitation in later stages.\n# Code:\n```", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, sigma_init=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.rng = np.random.default_rng()\n\n    def initialize_population(self):\n        self.pop = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n            else:\n                break\n        return self.f_opt, self.x_opt\n\n    def generate_mutations(self):\n        mutated_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            mutation = self.rng.normal(0, self.sigma, self.dim)\n            mutated_vector = self.pop[i] + mutation\n            mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n            mutated_pop[i] = mutated_vector\n        return mutated_pop\n\n    def selection(self, func, mutated_pop):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_mutated = func(mutated_pop[i])\n                self.eval_count += 1\n                if f_mutated < self.fitness[i]:\n                    self.pop[i] = mutated_pop[i]\n                    self.fitness[i] = f_mutated\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = self.pop[i]\n\n        #Adapt sigma\n        self.sigma *= np.exp(0.1 * (np.mean(self.fitness) - self.f_opt) / np.abs(self.f_opt + 1e-8))\n        self.sigma = max(self.sigma, 1e-6) #Avoid sigma becoming zero.\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            mutated_pop = self.generate_mutations()\n            self.f_opt, self.x_opt = self.selection(func, mutated_pop)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "489a4f28-d87d-4494-9550-895df304452f", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "Evolves a population by stochastically perturbing the best solution found so far, then applies an adaptive radius local search focused on improving near the best solution.", "code": "import numpy as np\n\nclass PerturbedBestLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=10, search_radius_init=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.search_radius = search_radius_init\n\n    def __call__(self, func):\n        evals = 0\n        #Initial population and evaluation\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitnesses = np.array([func(x) for x in population])\n        evals += self.pop_size\n\n        best_idx = np.argmin(fitnesses)\n        self.f_opt = fitnesses[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Perturb best solution to create a new population\n            perturbed_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                perturbation = self.rng.normal(0, self.search_radius, self.dim)\n                perturbed_x = self.x_opt + perturbation\n                perturbed_x = np.clip(perturbed_x, self.lb, self.ub)\n                perturbed_population[i] = perturbed_x\n\n            # Evaluate perturbed population\n            perturbed_fitnesses = np.array([func(x) for x in perturbed_population])\n            evals += self.pop_size\n\n            #Update best solution\n            for i in range(self.pop_size):\n                if perturbed_fitnesses[i] < self.f_opt:\n                    self.f_opt = perturbed_fitnesses[i]\n                    self.x_opt = perturbed_population[i]\n            \n            # Local Search\n            local_search_radius = self.search_radius * 0.5\n            x_local = self.x_opt + self.rng.uniform(-local_search_radius, local_search_radius, self.dim)\n            x_local = np.clip(x_local, self.lb, self.ub)\n            \n            f_local = func(x_local)\n            evals +=1\n\n            if f_local < self.f_opt:\n                self.f_opt = f_local\n                self.x_opt = x_local\n                self.search_radius *= 0.9 #Reduce search radius if find better\n            else:\n                self.search_radius *= 1.1 #Else increase search radius\n                self.search_radius = np.clip(self.search_radius, 0.001, (self.ub - self.lb)/2)\n\n            if evals >= self.budget:\n                break\n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "8c12e5e2-7370-4d77-bc02-5b184ffdc754", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "This algorithm combines a simplified particle swarm optimization with a Nelder-Mead simplex search to balance global exploration and local exploitation.", "code": "import numpy as np\n\nclass PSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.4, c2=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.pop = None\n        self.v = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_index = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.pop = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        self.v = self.rng.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f = func(self.pop[i])\n                self.eval_count += 1\n                if f < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = f\n                    self.pbest_pop[i] = self.pop[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.pop[i].copy()\n            else:\n                break\n\n        self.gbest_index = np.argmin(self.pbest_fitness)\n        return self.f_opt, self.x_opt\n\n    def update_particles(self):\n        for i in range(self.pop_size):\n            r1 = self.rng.random(self.dim)\n            r2 = self.rng.random(self.dim)\n            self.v[i] = self.w * self.v[i] + \\\n                         self.c1 * r1 * (self.pbest_pop[i] - self.pop[i]) + \\\n                         self.c2 * r2 * (self.pbest_pop[self.gbest_index] - self.pop[i])\n\n            self.pop[i] = np.clip(self.pop[i] + self.v[i], self.lb, self.ub)\n\n    def nelder_mead(self, func, x0, max_evals=50):\n        # Simplified Nelder-Mead implementation\n        n = len(x0)\n        simplex = np.zeros((n + 1, n))\n        simplex[0] = x0\n        for i in range(1, n + 1):\n            simplex[i] = x0.copy()\n            simplex[i, i - 1] += 0.1  # Small perturbation\n            simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n\n        evals = 0\n        fitness = np.array([func(x) for x in simplex])\n        evals += n + 1\n        \n        while evals < max_evals and self.eval_count + evals < self.budget:\n            # Order the vertices by fitness\n            order = np.argsort(fitness)\n            simplex = simplex[order]\n            fitness = fitness[order]\n\n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            xr = centroid + 1.0 * (centroid - simplex[-1])\n            xr = np.clip(xr, self.lb, self.ub)\n            fr = func(xr)\n            evals += 1\n\n            if fr < fitness[0]:\n                # Expansion\n                xe = centroid + 2.0 * (centroid - simplex[-1])\n                xe = np.clip(xe, self.lb, self.ub)\n                fe = func(xe)\n                evals += 1\n\n                if fe < fr:\n                    simplex[-1] = xe\n                    fitness[-1] = fe\n                else:\n                    simplex[-1] = xr\n                    fitness[-1] = fr\n            elif fr < fitness[-2]:\n                simplex[-1] = xr\n                fitness[-1] = fr\n            else:\n                # Contraction\n                xc = centroid + 0.5 * (simplex[-1] - centroid)\n                xc = np.clip(xc, self.lb, self.ub)\n                fc = func(xc)\n                evals += 1\n\n                if fc < fitness[-1]:\n                    simplex[-1] = xc\n                    fitness[-1] = fc\n                else:\n                    # Shrink\n                    for i in range(1, n + 1):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n                        fitness[i] = func(simplex[i])\n                        evals += 1\n        self.eval_count += evals\n        best_index = np.argmin(fitness)\n        return fitness[best_index], simplex[best_index]\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            self.update_particles()\n            self.f_opt, self.x_opt = self.evaluate_population(func)\n\n            # Apply Nelder-Mead to the best particle every few iterations\n            if self.eval_count < self.budget and self.eval_count % (self.budget // 10) == 0:\n                nm_f_opt, nm_x_opt = self.nelder_mead(func, self.x_opt, max_evals=50)\n                if nm_f_opt < self.f_opt:\n                    self.f_opt = nm_f_opt\n                    self.x_opt = nm_x_opt\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c1482324-3058-4f0a-8663-39d44abfcc29", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Implements a covariance matrix adaptation evolution strategy (CMA-ES) with restarts and budget management.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma_init=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.sigma = sigma_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for restart in range(self.restarts):\n            mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            \n            mu = self.pop_size // 2\n            \n            c_sigma = (mu / (self.dim + 5)) if (mu / (self.dim + 5)) <= 1 else 1\n            d_sigma = 1 + 2 * max(0, np.sqrt((mu - 1) / (self.dim + 1)) - 1) + c_sigma\n            c_c = (4 + mu / self.dim) / (self.dim + 4 + 2 * mu / self.dim)\n            c_mu = min(1 - c_c, mu / (self.dim**2 + 2 * mu))\n            \n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights /= np.sum(weights)\n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n            c_1 = 2 / ((self.dim + np.sqrt(2))**2 + mueff)\n            c_mu = min(1 - c_1, 2 * (mueff - 2 + 1 / mueff) / ((self.dim + 2)**2 + mueff))\n\n\n            while eval_count < self.budget / self.restarts:\n                \n                z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n                B, s, _ = np.linalg.svd(C)\n                sqrt_C = B @ np.diag(np.sqrt(s)) @ B.T\n                \n                x = mean + self.sigma * z @ sqrt_C.T\n                x = np.clip(x, self.lb, self.ub)\n\n                f = np.array([func(xi) if eval_count + i < self.budget else np.inf for i, xi in enumerate(x)])\n                eval_count += self.pop_size\n\n                if np.any(np.isinf(f)):\n                    f[np.isinf(f)] = np.inf\n                    x = x[~np.isinf(f)]\n                \n                idx = np.argsort(f)\n                x = x[idx[:mu]]\n                f = f[idx[:mu]]\n                \n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[0]\n\n                z = z[idx[:mu]]\n\n                mean_diff = np.sum(weights[:, None] * z, axis=0)\n\n                pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c) * mueff) * mean_diff\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mueff) * (sqrt_C @ mean_diff)\n\n                norm_ps = np.linalg.norm(ps)\n                self.sigma *= np.exp((c_sigma / d_sigma) * (norm_ps / np.sqrt(self.dim) - 1))\n                self.sigma = np.clip(self.sigma, 1e-10, 10)\n\n                mean += c_c * pc\n                mean = np.clip(mean, self.lb, self.ub)\n\n                C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :]) + c_mu * np.sum(weights[:, None, None] * (z[:, :, None] @ z[:, None, :]), axis=0)\n                C = np.triu(C) + np.triu(C, 1).T  # Enforce symmetry\n                C = C / np.linalg.norm(C) #Rescale C to prevent divergence\n                try:\n                   np.linalg.cholesky(C)\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim) * 1e-6  # Restart covariance if becomes non-positive definite\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "3a910ad8-e4f6-4178-b29e-d9770d2cb0c1", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm combines differential evolution with a restart mechanism triggered by stagnation, aiming to escape local optima.\n# Code: \n```", "code": "import numpy as np\n\nclass RestartDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.7, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = stagnation_threshold\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n                    self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                break\n        return self.f_opt, self.x_opt\n\n    def generate_trial_vectors(self):\n        trial_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n            v = x_r1 + self.F * (x_r2 - x_r3)\n            \n            trial_vector = np.zeros(self.dim)\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    trial_vector[j] = v[j]\n                else:\n                    trial_vector[j] = self.pop[i][j]\n            \n            trial_vector = np.clip(trial_vector, self.lb, self.ub)  # Keep within bounds\n            trial_pop[i] = trial_vector\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        improved = False\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_pop[i])\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial_pop[i]\n                    self.fitness[i] = f_trial\n                    improved = True\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i]\n                        self.stagnation_counter = 0  # Reset stagnation counter\n\n        return self.f_opt, self.x_opt\n\n    def restart_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.evaluate_population(func)  # Evaluate new population\n        self.stagnation_counter = 0 # Reset stagnation counter\n        print(\"Restarting population\")\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n        \n        while self.eval_count < self.budget:\n            trial_pop = self.generate_trial_vectors()\n            self.f_opt, self.x_opt = self.selection(func, trial_pop)\n            \n            self.stagnation_counter += self.pop_size # since each selection calls the function once for each member\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                self.restart_population()\n        \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "47569ff8-a785-4fc6-a60d-17ae38149863", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm uses a self-adaptive differential evolution with a decaying mutation factor and a restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, cr=0.9, decay_rate=0.99, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.cr = cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.decay_rate = decay_rate\n        self.restart_prob = restart_prob\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n            else:\n                break\n        return self.f_opt, self.x_opt\n\n    def generate_trial_vectors(self):\n        trial_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n            v = x_r1 + self.F * (x_r2 - x_r3)\n\n            trial_vector = np.zeros(self.dim)\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    trial_vector[j] = v[j]\n                else:\n                    trial_vector[j] = self.pop[i][j]\n\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n            trial_pop[i] = trial_vector\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_pop[i])\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial_pop[i]\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i]\n                elif np.random.rand() < self.restart_prob:\n                    self.pop[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n        self.F *= self.decay_rate\n\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            trial_pop = self.generate_trial_vectors()\n            self.f_opt, self.x_opt = self.selection(func, trial_pop)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "2e23d04e-e3b4-47c2-a57f-4a4cf583c24d", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: Implements a self-adaptive Differential Evolution (SaDE) algorithm where mutation and crossover strategies are probabilistically chosen based on their past success.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, num_strategies=4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.num_strategies = num_strategies\n        self.success_rates = np.ones(num_strategies) / num_strategies\n        self.memory_size = 100\n        self.memory_F = np.zeros(self.memory_size)\n        self.memory_CR = np.zeros(self.memory_size)\n        self.memory_idx = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        strategy_success_counts = np.zeros(self.num_strategies)\n        strategy_attempt_counts = np.zeros(self.num_strategies)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_idx = self.rng.choice(self.num_strategies, p=self.success_rates)\n                strategy_attempt_counts[strategy_idx] += 1\n\n                # Parameter generation for chosen strategy\n                if strategy_idx == 0:\n                  F = 0.5 + 0.3 * self.rng.normal()\n                  CR = 0.7 + 0.1 * self.rng.normal()\n                elif strategy_idx == 1:\n                  F = 0.8 + 0.2 * self.rng.normal()\n                  CR = 0.3 + 0.1 * self.rng.normal()\n                elif strategy_idx == 2:\n                  F = 0.9 + 0.1 * self.rng.normal()\n                  CR = 0.9 + 0.1 * self.rng.normal()\n                else:\n                  F = self.rng.uniform(0.1, 0.9)\n                  CR = self.rng.uniform(0.1, 0.9)\n                F = np.clip(F, 0.1, 0.9)\n                CR = np.clip(CR, 0.1, 0.9)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_mask = self.rng.random(self.dim) < CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    strategy_success_counts[strategy_idx] += 1 # Count strategy success\n\n                if evals >= self.budget:\n                  break\n\n            # Update success rates every generation\n            if (evals // self.pop_size) % 1 == 0:\n              for k in range(self.num_strategies):\n                if strategy_attempt_counts[k] > 0:\n                  self.success_rates[k] = strategy_success_counts[k] / strategy_attempt_counts[k]\n                else:\n                  self.success_rates[k] = 1e-6 # Small value to avoid zero probability\n\n              self.success_rates /= np.sum(self.success_rates) # Normalize to probabilities\n              strategy_success_counts[:] = 0\n              strategy_attempt_counts[:] = 0\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "132ec52e-7c4d-40e4-bd05-5f8fceac87a1", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm employs a modified differential evolution strategy with a self-adaptive mutation factor and a tournament selection scheme.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_init = F_init\n        self.cr = cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.F = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.F = np.full(self.pop_size, self.F_init)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n            else:\n                break\n        return self.f_opt, self.x_opt\n\n    def generate_trial_vectors(self):\n        trial_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs[0]], self.pop[idxs[1]], self.pop[idxs[2]]\n\n            # Self-adaptive mutation factor\n            self.F[i] = np.clip(np.random.normal(self.F_init, 0.1), 0.1, 1.0)\n            v = x_r1 + self.F[i] * (x_r2 - x_r3)\n            \n            trial_vector = np.zeros(self.dim)\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() <= self.cr or j == j_rand:\n                    trial_vector[j] = v[j]\n                else:\n                    trial_vector[j] = self.pop[i][j]\n            \n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n            trial_pop[i] = trial_vector\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_pop[i])\n                self.eval_count += 1\n                \n                # Tournament selection: compare trial vector with current vector\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial_pop[i]\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i]\n                # If the trial vector is worse, keep the original and possibly adjust F_init\n                else:\n                    self.F_init = max(0.1, self.F_init - 0.01)\n\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt, self.x_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            trial_pop = self.generate_trial_vectors()\n            self.f_opt, self.x_opt = self.selection(func, trial_pop)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "1572709e-89f8-42df-969e-24ed5da79a49", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and constriction factor to control exploration and exploitation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.constriction_factor = 0.72984  # Standard constriction factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        velocities = self.rng.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        # Initialize personal best positions and values\n        personal_best_positions = population.copy()\n        personal_best_values = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize global best position and value\n        global_best_index = np.argmin(personal_best_values)\n        self.f_opt = personal_best_values[global_best_index]\n        self.x_opt = personal_best_positions[global_best_index]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = self.rng.random(self.dim)\n                r2 = self.rng.random(self.dim)\n                velocities[i] = self.constriction_factor * (self.inertia * velocities[i] +\n                                   self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                   self.c2 * r2 * (self.x_opt - population[i]))\n\n                # Velocity clamping (optional, but can help stability)\n                v_max = 0.2 * (self.ub - self.lb)  # Maximum velocity (e.g., 20% of the search space)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n\n                # Boundary handling (clip to bounds)\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f < personal_best_values[i]:\n                    personal_best_values[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                if evals >= self.budget:\n                  break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "d2cb1a3b-f25a-49b3-917a-45664f128eee", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware adaptation of the step size.\n# Code: \n```", "code": "import numpy as np\n\nclass BudgetCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma_init\n        self.mean = np.random.uniform(-5.0, 5.0, size=dim)\n        self.C = np.eye(dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_s = (self.budget/1e4)**0.1/10\n        self.d_s = 1 + 2*max(0, np.sqrt((self.dim-1)/(self.dim+1)) -1) + self.c_s\n        self.c_cov = (self.budget/1e4)**0.1/10\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+0.5) - np.log(np.arange(1, self.mu+1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_m = 1\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        return self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T, z\n\n    def evaluate_population(self, func, pop):\n        fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                x = np.clip(pop[i], self.lb, self.ub)\n                fitness[i] = func(x)\n                self.eval_count += 1\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = x\n            else:\n                fitness[i] = np.inf\n        return fitness\n\n    def update_parameters(self, fitness, pop, z):\n        idx = np.argsort(fitness)\n        best_pop = pop[idx[:self.mu]]\n        best_z = z[idx[:self.mu]]\n        \n        delta_mean = np.sum(self.weights[:, None] * best_z, axis=0)\n        self.mean = self.mean + self.c_m*self.sigma * delta_mean\n        \n        s = (1-self.c_s) + np.sqrt(self.c_s*(2-self.c_s)*self.mueff) * delta_mean/np.linalg.norm(delta_mean)\n\n        p_sigma = np.linalg.norm(s)/self.chiN\n        self.sigma *= np.exp(self.c_s/self.d_s * (p_sigma - 1))\n        self.sigma = min(5, max(1e-10, self.sigma)) #bound sigma\n\n        delta_C = np.sum(self.weights[:, None, None] * best_z[:, :, None] * best_z[:, None, :], axis=0)\n        self.C = (1-self.c_cov) * self.C + self.c_cov * delta_C\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            pop, z = self.sample_population()\n            fitness = self.evaluate_population(func, pop)\n            self.update_parameters(fitness, pop, z)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "d939a43e-94ea-4234-a6a8-8e85aacf7ca7", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm employs a particle swarm optimization strategy with velocity clamping and dynamic inertia weight adjustment for enhanced exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass ClampedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1=2.0, c2=2.0, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_final = 0.4\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.velocities = None\n        self.fitness = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_fitness = np.inf\n        self.gbest_pos = None\n        self.eval_count = 0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.pbest_pop = np.copy(self.pop)\n        self.pbest_fitness = np.full(self.pop_size, np.inf)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n\n                if self.fitness[i] < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = self.fitness[i]\n                    self.pbest_pop[i] = np.copy(self.pop[i])\n\n                if self.fitness[i] < self.gbest_fitness:\n                    self.gbest_fitness = self.fitness[i]\n                    self.gbest_pos = np.copy(self.pop[i])\n            else:\n                break\n        return self.gbest_fitness, self.gbest_pos\n\n    def update_particles(self, iteration):\n        w = self.w_init - (self.w_init - self.w_final) * (iteration / self.budget)\n\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            cognitive_component = self.c1 * r1 * (self.pbest_pop[i] - self.pop[i])\n            social_component = self.c2 * r2 * (self.gbest_pos - self.pop[i])\n\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n\n            self.pop[i] = self.pop[i] + self.velocities[i]\n            self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.gbest_fitness, self.gbest_pos = self.evaluate_population(func)\n        iteration = self.pop_size\n\n        while self.eval_count < self.budget:\n            self.update_particles(iteration)\n            iteration += self.pop_size\n            self.gbest_fitness, self.gbest_pos = self.evaluate_population(func)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "5af34885-0de9-4b1a-a145-70a25c6455ed", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Implements a self-adaptive Differential Evolution algorithm with a dynamically adjusted population size and mutation/crossover parameters based on the success of previous generations.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.F = 0.5\n        self.CR = 0.7\n        self.archive_F = []\n        self.archive_CR = []\n\n    def __call__(self, func):\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        success_count = 0\n        adaptation_period = self.budget // 10\n\n        while evals < self.budget:\n            new_population = []\n            new_fitness = []\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                cross_mask = self.rng.random(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    new_fitness.append(f)\n                    new_population.append(trial)\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                else:\n                    new_fitness.append(fitness[i])\n                    new_population.append(population[i])\n\n                if evals >= self.budget:\n                    break\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n            if evals % adaptation_period == 0:\n                if successful_F:\n                    self.F = np.mean(successful_F)\n                    self.CR = np.mean(successful_CR)\n\n                self.F = np.clip(self.F + self.rng.normal(0, 0.1), 0.1, 0.9)\n                self.CR = np.clip(self.CR + self.rng.normal(0, 0.1), 0.1, 0.9)\n\n                if len(successful_F) > 0:\n                    self.archive_F.extend(successful_F)\n                    self.archive_CR.extend(successful_CR)\n\n                if len(self.archive_F) > 10 * self.pop_size:\n                    self.archive_F = self.archive_F[-10 * self.pop_size:]\n                    self.archive_CR = self.archive_CR[-10 * self.pop_size:]\n\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "bd9aacab-2534-40fb-a6d2-9b97016f4e43", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and constriction factor to control exploration and exploitation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, phi_p=1.49445, phi_g=1.49445):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega  # Inertia weight\n        self.phi_p = phi_p  # Cognitive coefficient\n        self.phi_g = phi_g  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.v_max = (self.ub - self.lb) * 0.1  # Velocity clamping\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        velocities = self.rng.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and values\n        pbest_positions = population.copy()\n        pbest_values = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize global best position and value\n        best_index = np.argmin(pbest_values)\n        gbest_position = pbest_positions[best_index]\n        self.f_opt = pbest_values[best_index]\n        self.x_opt = gbest_position\n\n        # Constriction factor\n        phi = self.phi_p + self.phi_g\n        if phi > 4:\n            k = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n        else:\n            k = 1\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r_p = self.rng.random(self.dim)\n                r_g = self.rng.random(self.dim)\n\n                velocities[i] = self.omega * velocities[i] + \\\n                                 self.phi_p * r_p * (pbest_positions[i] - population[i]) + \\\n                                 self.phi_g * r_g * (gbest_position - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f < pbest_values[i]:\n                    pbest_values[i] = f\n                    pbest_positions[i] = population[i]\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i]\n                \n                if evals >= self.budget:\n                  break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "1c7b9248-6602-46d4-b40f-a1c3c7202dde", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: Implements a variant of Particle Swarm Optimization (PSO) with velocity clamping and adaptive inertia weight.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.2, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.v_max = (self.ub - self.lb) * 0.1  # Velocity clamping\n        self.v_min = -self.v_max\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        velocities = self.v_min + self.rng.random((self.pop_size, self.dim)) * (self.v_max - self.v_min)\n        fitness = np.array([func(x) for x in particles])\n        evals = self.pop_size\n\n        # Initialize personal best positions and global best position\n        personal_best_positions = particles.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        # PSO iterations\n        while evals < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = self.rng.random(self.dim)\n                r2 = self.rng.random(self.dim)\n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - particles[i]) + \\\n                                self.c2 * r2 * (global_best_position - particles[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], self.v_min, self.v_max)\n\n                # Update particle position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(particles[i])\n                evals += 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = particles[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = particles[i].copy()\n                        global_best_position = particles[i].copy() # Update global best position\n\n                if evals >= self.budget:\n                  break\n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "73f7a6fb-89f9-455a-804b-199a5e8f32d1", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified adaptation rules for exploration and exploitation.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n        self.mean = np.zeros(dim)\n        self.C = np.eye(dim) # Covariance matrix\n\n    def __call__(self, func):\n        evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while evals < self.budget:\n            # Generate population\n            z = self.rng.normal(0, 1, size=(self.pop_size, self.dim))\n            population = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n            if evals > self.budget:\n                fitness = fitness[:self.pop_size - (evals - self.budget)]\n                population = population[:self.pop_size - (evals - self.budget)]\n                evals = self.budget\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adaptation (simplified)\n            weights = np.log(self.pop_size+1) - np.log(np.arange(1, self.pop_size+1))\n            weights /= np.sum(weights)\n            \n            sorted_indices = np.argsort(fitness)\n            \n            delta_mean = np.sum(weights.reshape(-1,1) * (population[sorted_indices] - self.mean), axis=0)\n\n            self.mean += delta_mean\n\n            # Rank-one update of covariance matrix\n            self.C = (1 - 0.1) * self.C + 0.1 * delta_mean.reshape(-1,1) @ delta_mean.reshape(1,-1)\n\n            # Adjust step size (simplified)\n            self.sigma *= np.exp(0.2 * (np.mean(fitness) - self.f_opt) / abs(self.f_opt)) #try dividing by fitness of mean rather than f_opt\n            self.sigma = np.clip(self.sigma, 1e-6, 1)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "baa1c0cb-00f8-4c97-8be1-7cbbd76ae210", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "# Description: This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adapt the search distribution based on successful steps, aiming to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))  # Default pop size\n        else:\n            self.pop_size = pop_size\n        \n        self.mu = int(self.pop_size * mu_ratio)  # Number of parents/selected solutions\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Adaptation parameters\n        self.cs = cs # Learning rate for cumulation for the step-size\n        self.damps = damps * (1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)) # Damping for step-size\n        if c_cov_mean is None:\n            self.c_cov_mean = self.cs\n        else:\n            self.c_cov_mean = c_cov_mean\n        if c_cov_rank_one is None:\n            self.c_cov_rank_one = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.c_cov_rank_one = c_cov_rank_one\n            \n        if c_cov_rank_mu is None:\n            self.c_cov_rank_mu = min(1 - self.c_cov_rank_one, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        else:\n             self.c_cov_rank_mu = c_cov_rank_mu\n\n        # Initialize mean, covariance matrix, and evolution path\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)  # Initialize mean within bounds\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.p_sigma = np.zeros(self.dim)  # Evolution path for step size\n        self.p_c = np.zeros(self.dim)  # Evolution path for covariance matrix\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self):\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n        x = self.mean + self.sigma * z\n        x = np.clip(x, self.lb, self.ub)  # Clip to bounds\n        return x, z\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            pop, z = self.sample_population()\n            fitness = np.zeros(self.pop_size)\n            \n            # Evaluate population\n            for i in range(self.pop_size):\n                if self.eval_count < self.budget:\n                    fitness[i] = func(pop[i])\n                    self.eval_count += 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n                else:\n                    break\n            \n            if self.eval_count >= self.budget:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            pop = pop[idx]\n            z = z[idx]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean += self.c_cov_mean * self.sigma * np.sum(self.weights[:, None] * z[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.mean - mean_old) / self.sigma\n            \n            C_temp = np.sqrt(np.sum(self.p_sigma**2)) / np.sqrt(self.dim) / (1.4 + 2 / (self.dim + 1))\n            \n            self.sigma *= np.exp((self.cs / self.damps) * (C_temp - 1))\n            \n            # Update covariance matrix\n            self.p_c = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.p_c + np.sqrt(self.c_cov_rank_one * self.mueff) * (self.mean - mean_old) / self.sigma\n            \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + self.c_cov_rank_one * np.outer(self.p_c, self.p_c) + self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * np.array([np.outer(z[i], z[i]) for i in range(self.mu)]), axis=0)\n            \n            # Repair covariance matrix\n            if np.min(np.linalg.eigvalsh(self.C)) <= 0:\n                self.C += 1e-8 * np.eye(self.dim)\n            \n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "c51ba5e5-72ab-486b-98b4-2324a45bd0a6", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Iteratively refines a population of solutions by stochastically perturbing the best solution found so far, and shrinking the perturbation range over time.", "code": "import numpy as np\n\nclass StochasticPerturbation:\n    def __init__(self, budget=10000, dim=10, pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize\n        x_opt = self.lb + self.rng.random(self.dim) * (self.ub - self.lb)\n        f_opt = func(x_opt)\n        evals = 1\n\n        search_range = (self.ub - self.lb)\n\n        while evals < self.budget:\n            # Generate a population around the best solution\n            population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                perturbation = self.rng.uniform(-search_range / 2, search_range / 2, self.dim)\n                x = x_opt + perturbation\n                x = np.clip(x, self.lb, self.ub)\n                population[i] = x\n\n            # Evaluate the population\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n\n            # Update the best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < f_opt:\n                f_opt = fitness[best_index]\n                x_opt = population[best_index]\n\n            # Shrink the search range\n            search_range *= 0.995 # Reduce search range gradually\n\n            if evals >= self.budget:\n              break\n\n        return f_opt, x_opt", "objective": -0.0, "other_inf": null}
{"id": "d8d3271e-57b9-4245-8569-e248bc35d41b", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Iteratively refines promising regions of the search space using Gaussian perturbations and focuses the search based on the best-performing samples.", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_std=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_std = initial_std\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        mean = self.x_opt.copy()\n        std = np.full(self.dim, self.initial_std)\n\n        while evals < self.budget:\n            # Generate samples around the mean with the current standard deviation\n            samples = self.rng.normal(loc=mean, scale=std, size=(self.pop_size, self.dim))\n            samples = np.clip(samples, self.lb, self.ub)\n\n            # Evaluate samples\n            sample_fitness = np.array([func(x) for x in samples])\n            evals += self.pop_size\n\n            # Update best solution\n            best_sample_index = np.argmin(sample_fitness)\n            if sample_fitness[best_sample_index] < self.f_opt:\n                self.f_opt = sample_fitness[best_sample_index]\n                self.x_opt = samples[best_sample_index]\n\n            # Adapt mean and standard deviation\n            weights = np.exp(-0.5 * (sample_fitness - np.mean(sample_fitness)) / np.std(sample_fitness))\n            weights /= np.sum(weights)\n\n            mean = np.sum(samples * weights[:, np.newaxis], axis=0)\n            mean = np.clip(mean, self.lb, self.ub) # Keep within bounds.\n\n            std = np.sqrt(np.sum(weights[:, np.newaxis] * (samples - mean)**2, axis=0))\n            std = np.clip(std, 0.01, self.initial_std) # Prevent std from collapsing too quickly.\n\n            if evals >= self.budget:\n                break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "230671e9-4ead-402e-9f2d-9db7c19ea1c0", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "Evolves a single solution by repeatedly perturbing it in a direction estimated from past successful steps, adapting the step size based on success rates.", "code": "import numpy as np\n\nclass StepwiseAdaptation:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 10\n        self.direction = np.zeros(dim)\n\n    def __call__(self, func):\n        x = self.lb + self.rng.random(self.dim) * (self.ub - self.lb)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Perturb the solution\n            x_new = x + self.step_size * self.direction + self.rng.normal(0, self.step_size, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < self.f_opt:\n                # Successful step\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_rate = 1.0\n                self.direction = (x - self.x_opt) / (np.linalg.norm(x - self.x_opt) + 1e-8) # Normalize direction\n                self.success_history.append(1)\n            else:\n                self.success_rate = 0.0\n                self.success_history.append(0)\n\n            # Adapt step size based on success rate history\n            if len(self.success_history) > self.history_length:\n                self.success_history.pop(0)\n                avg_success = np.mean(self.success_history)\n\n                if avg_success > 0.6:\n                    self.step_size *= 1.1  # Increase step size\n                elif avg_success < 0.4:\n                    self.step_size *= 0.9  # Decrease step size\n                self.step_size = np.clip(self.step_size, 1e-6, (self.ub - self.lb))\n\n            if evals >= self.budget:\n                break\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "80143907-5506-4509-ac83-4978ba28b73f", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56", "fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "This algorithm combines a simplified Particle Swarm Optimization (PSO) with a Nelder-Mead simplex search to balance global exploration and local refinement.", "code": "import numpy as np\n\nclass PSO_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, simplex_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.simplex_iters = simplex_iters # Number of Nelder-Mead iterations\n\n    def initialize_population(self):\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        velocities = self.rng.uniform(-1, 1, size=(self.pop_size, self.dim)) # Initialize velocities\n        fitness = np.zeros(self.pop_size)\n        return population, velocities, fitness\n\n    def __call__(self, func):\n        population, velocities, fitness = self.initialize_population()\n        evals = 0\n        \n        # Evaluate initial population\n        for i in range(self.pop_size):\n            if evals < self.budget:\n                fitness[i] = func(population[i])\n                evals += 1\n            else:\n                break\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_position = self.x_opt.copy()\n\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = self.rng.random(self.dim)\n                r2 = self.rng.random(self.dim)\n\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n\n                velocities[i] = self.w * velocities[i] + cognitive_component + social_component\n                population[i] = population[i] + velocities[i]\n\n                # Clip to bounds\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate\n                if evals < self.budget:\n                    f = func(population[i])\n                    evals += 1\n\n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                        global_best_position = self.x_opt.copy()\n                else:\n                    break\n            \n            # Nelder-Mead on best solution every few iterations\n            if evals % (self.budget // 10) == 0:\n                self.x_opt, self.f_opt, simplex_evals = self.nelder_mead(func, self.x_opt, evals, self.budget)\n                evals += simplex_evals\n                global_best_position = self.x_opt.copy() # Update global best from Nelder-Mead\n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def nelder_mead(self, func, x_start, evals, budget, alpha=1, beta=0.5, gamma=2):\n        \"\"\"Simple Nelder-Mead implementation.\"\"\"\n        n = self.dim\n        simplex = np.zeros((n + 1, n))\n        simplex[0] = x_start\n        \n        for i in range(1, n + 1):\n            simplex[i] = x_start.copy()\n            simplex[i][i-1] += 0.1  # Perturb each dimension\n            simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n\n        fitness = np.zeros(n + 1)\n        simplex_evals = 0\n\n        for i in range(n + 1):\n            if evals + simplex_evals < budget:\n                fitness[i] = func(simplex[i])\n                simplex_evals += 1\n            else:\n                break\n\n        for _ in range(self.simplex_iters):  # Iterate for a fixed number of steps\n            if evals + simplex_evals >= budget:\n                break\n            \n            fitness_indices = np.argsort(fitness)\n            fitness = fitness[fitness_indices]\n            simplex = simplex[fitness_indices]\n            \n            best = simplex[0]\n            worst = simplex[-1]\n\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected = centroid + alpha * (centroid - worst)\n            reflected = np.clip(reflected, self.lb, self.ub)\n            f_reflected = func(reflected)\n            simplex_evals += 1\n\n            if f_reflected < fitness[-2] and f_reflected >= fitness[0]:\n                simplex[-1] = reflected\n                fitness[-1] = f_reflected\n                continue\n\n            # Expansion\n            if f_reflected < fitness[0]:\n                expanded = centroid + gamma * (reflected - centroid)\n                expanded = np.clip(expanded, self.lb, self.ub)\n                f_expanded = func(expanded)\n                simplex_evals += 1\n\n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded\n                    fitness[-1] = f_expanded\n                else:\n                    simplex[-1] = reflected\n                    fitness[-1] = f_reflected\n                continue\n\n            # Contraction\n            contracted = centroid + beta * (worst - centroid)\n            contracted = np.clip(contracted, self.lb, self.ub)\n            f_contracted = func(contracted)\n            simplex_evals += 1\n            simplex[-1] = contracted\n            fitness[-1] = f_contracted\n\n        best_index = np.argmin(fitness)\n        best_fitness = fitness[best_index]\n        best_position = simplex[best_index]\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "b44a4c75-d790-4a23-9726-43c55af0b6ef", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: Implements a hybrid optimization strategy combining differential evolution with a covariance matrix adaptation evolution strategy (CMA-ES) to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        # Initialize population (DE)\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # CMA-ES initialization\n        mean = self.x_opt.copy()\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        damps = 1 + (self.dim/2)  # Damping factor\n\n        while evals < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                cross_mask = self.rng.random(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, population[i])\n\n                f = func(trial)\n                evals += 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # CMA-ES Step (applied probabilistically)\n            if self.rng.random() < 0.5: # Probabilistically engage CMA-ES\n                if evals >= self.budget:\n                    break\n                z = self.rng.normal(0, 1, self.dim)\n                sample = mean + self.sigma0 * np.dot(np.linalg.cholesky(C), z)\n                sample = np.clip(sample, self.lb, self.ub)\n\n                f_sample = func(sample)\n                evals += 1\n\n                if f_sample < self.f_opt:\n                    self.f_opt = f_sample\n                    self.x_opt = sample\n                    mean = sample # Update mean\n\n                # Update CMA-ES parameters\n                ps = (1-0.1) * ps + np.sqrt(0.1*(2-0.1)) * z\n                pc = (1-0.1) * pc + np.sqrt(0.1*(2-0.1)) * np.linalg.solve(np.linalg.cholesky(C), z)\n\n                C = (1-0.01) * C + 0.01 * (np.outer(pc, pc) + 0.1 * np.eye(self.dim) )\n                self.sigma0 = self.sigma0 * np.exp((0.1/damps)*(np.linalg.norm(ps)-np.sqrt(self.dim)))\n\n                # Ensure C remains positive definite\n                try:\n                    np.linalg.cholesky(C) # Check if positive definite\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim) # Reset if not\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "9cc13fe1-bed3-4646-9f7c-0952bdc2da55", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: Employs a population-based approach with velocity updates inspired by particle swarm optimization, combined with differential evolution operators and adaptive parameter control.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.5, phi_p=0.5, phi_g=0.5, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega\n        self.phi_p = phi_p\n        self.phi_g = phi_g\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.velocity = None\n\n    def __call__(self, func):\n        # Initialize population and velocity\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        self.velocity = np.zeros_like(population)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # PSO Velocity Update\n                r_p = self.rng.random(self.dim)\n                r_g = self.rng.random(self.dim)\n                self.velocity[i] = (self.omega * self.velocity[i] +\n                                  self.phi_p * r_p * (personal_best_positions[i] - population[i]) +\n                                  self.phi_g * r_g * (self.x_opt - population[i]))\n                \n                # Mutation (DE component)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Apply Velocity\n                trial = np.clip(population[i] + self.velocity[i], self.lb, self.ub)\n                \n                # Crossover\n                cross_mask = self.rng.random(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, trial)\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                # Evaluation\n                f = func(trial)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if evals >= self.budget:\n                    break\n        \n            return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "891ac6ce-a855-40d0-9d3e-8088b11a95c1", "parents": ["fa406f8b-503f-4167-82fd-4c94b992d76a"], "algorithm": "# Description: Implements a self-adaptive Differential Evolution with a restart mechanism and orthogonal array-based crossover to enhance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.rng = np.random.default_rng()\n        self.restart_trigger = restart_trigger # Fraction of budget when restart might happen.\n\n    def __call__(self, func):\n        # Initialize population\n        population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Orthogonal Array for Crossover:  A simple example (you can use a library for larger arrays)\n        oa = np.array([[1, 1], [1, 2], [2, 1], [2, 2]]) # L4 Orthogonal Array\n        oa_index = 0\n        oa_len = len(oa)\n\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[self.rng.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Orthogonal Array-Based Crossover\n                trial = population[i].copy()\n                for j in range(self.dim):\n                    if oa[oa_index % oa_len][(j % 2)] == 1: # simple cycling through oa columns based on index\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                oa_index += 1\n\n\n                # Adaptive F and CR\n                self.F = 0.5 + 0.3 * self.rng.normal(0, 0.1)\n                self.CR = 0.7 + 0.2 * self.rng.normal(0, 0.1)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n\n                if evals >= self.budget:\n                    break\n\n            # Restart mechanism (diversification)\n            if evals > self.restart_trigger * self.budget:\n                if np.std(fitness) < 1e-6:  # If population has converged (low diversity)\n                    population = self.lb + self.rng.random((self.pop_size, self.dim)) * (self.ub - self.lb)\n                    fitness = np.array([func(x) for x in population])\n                    evals += self.pop_size\n\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.restart_trigger += 0.1 # increase trigger to reduce restarts\n                    \n                    oa_index = 0\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "e0354281-ac9f-4848-a679-7d98817697db", "parents": ["0e163a54-c7ad-4ba9-a8e5-ec640a046a56"], "algorithm": "This algorithm implements a variant of Differential Evolution with a simplified update rule and random parameter selection to enhance exploration.", "code": "import numpy as np\n\nclass SimplifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n            else:\n                break\n        return self.f_opt\n\n    def generate_trial_vectors(self):\n        trial_pop = np.zeros_like(self.pop)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r1, x_r2 = self.pop[idxs[0]], self.pop[idxs[1]]\n            \n            trial_vector = self.pop[i] + self.F * (x_r1 - x_r2)\n            trial_vector = np.clip(trial_vector, self.lb, self.ub)\n            trial_pop[i] = trial_vector\n        return trial_pop\n\n    def selection(self, func, trial_pop):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                f_trial = func(trial_pop[i])\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial_pop[i]\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = self.pop[i]\n        return self.f_opt\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.f_opt = self.evaluate_population(func)\n\n        while self.eval_count < self.budget:\n            trial_pop = self.generate_trial_vectors()\n            self.f_opt = self.selection(func, trial_pop)\n\n        return f_opt, x_opt", "objective": Infinity, "other_inf": null}
{"id": "f659e321-e6f5-4964-ab12-49220ed2332f", "parents": [], "algorithm": "Adaptive Differential Evolution with stochastic ranking and local search refinement after stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        stagnation_counter = 0\n        best_fitness_history = [self.f_opt]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[idxs]\n                \n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.pop[i])\n                trial[cross_mask] = mutant[cross_mask]\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            if self.f_opt <= min(best_fitness_history):\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 100:\n                best_fitness_history.pop(0)\n\n            if stagnation_counter > 50:\n                # Local Search on the best solution\n                for _ in range(min(self.local_search_iterations, self.budget)):\n                    if self.budget <= 0:\n                        break\n                    \n                    perturbation = np.random.normal(0, 0.1, size=self.dim)\n                    x_local = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local\n                stagnation_counter = 0\n        return self.f_opt, self.x_opt", "objective": -0.69919, "other_inf": null}
{"id": "d302892c-c556-44ac-a477-2e4d712a5352", "parents": [], "algorithm": "Adaptive Differential Evolution with archive and self-adaptation of parameters, focusing on exploration in early stages and exploitation later.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.archive = []\n        self.eval_count = self.pop_size\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                \n                # Adaptive F and CR\n                if np.random.rand() < 0.1:\n                  self.F = np.random.uniform(0.1, 0.9)\n                if np.random.rand() < 0.1:\n                  self.CR = np.random.uniform(0.1, 0.9)\n\n                # Mutation\n                idx = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idx]\n\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    xa = self.archive[np.random.randint(len(self.archive))]\n                    v = x1 + self.F * (xa - x3)\n                else:\n                    v = x1 + self.F * (x2 - x3)\n                \n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.eval_count += 1\n                \n                if f_u < self.fitness[i]:\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = self.population[i].copy()\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n        \n        return self.f_opt, self.x_opt", "objective": -0.60869, "other_inf": null}
{"id": "128e3e1a-f0a9-4a95-8b76-f4f4b6e2a2e5", "parents": [], "algorithm": "A population-based algorithm that combines exploration and exploitation by iteratively updating positions based on global best, local best, and random movements, while also incorporating a decaying step size to promote convergence.", "code": "import numpy as np\n\nclass AdaptiveExplorationOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, alpha=0.9, beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.alpha = alpha  # Weight for global best\n        self.beta = beta    # Weight for local best\n        self.step_size = 1.0 # Initial step size, decays over time\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        global_best_x = population[best_index]\n        global_best_f = fitness[best_index]\n        \n        if global_best_f < self.f_opt:\n                self.f_opt = global_best_f\n                self.x_opt = global_best_x\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Local search: find the best neighbor\n                neighbor_index = np.random.choice(self.pop_size)\n                if fitness[neighbor_index] < fitness[i]:\n                    local_best_x = population[neighbor_index]\n                else:\n                    local_best_x = population[i]\n\n                # Update position based on global best, local best, and random movement\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                new_position = population[i] + self.step_size * (\n                    self.alpha * r1 * (global_best_x - population[i]) +\n                    self.beta * r2 * (local_best_x - population[i]) +\n                    0.1 * np.random.uniform(-1, 1, self.dim) # Random exploration\n                )\n\n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                # Update global best\n                if new_fitness < global_best_f:\n                    global_best_f = new_fitness\n                    global_best_x = new_position\n                    if global_best_f < self.f_opt:\n                        self.f_opt = global_best_f\n                        self.x_opt = global_best_x\n            \n            # Decay step size\n            self.step_size *= 0.99\n            \n        return self.f_opt, self.x_opt", "objective": -0.32893, "other_inf": null}
{"id": "678bf125-f44b-4326-a9e4-7f6cb1be48ba", "parents": [], "algorithm": "A population-based algorithm that iteratively samples promising regions in the search space, focusing exploration around the best-performing solutions and diversifying the search with a Cauchy mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        step_size = self.initial_step_size\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation around the best solution\n                cauchy_vector = step_size * np.random.standard_cauchy(size=self.dim)\n                new_x = population[best_index] + cauchy_vector\n                \n                # Clip to bounds\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                new_f = func(new_x)\n                self.eval_count += 1\n\n                if new_f < fitness[i]:\n                    new_population[i] = new_x\n                    new_fitness[i] = new_f\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n\n                if self.eval_count >= self.budget:\n                    break\n\n\n            population = new_population\n            fitness = new_fitness\n\n            best_index = np.argmin(fitness)\n            \n            # Adapt step size\n            if np.std(fitness) < 1e-6:\n                step_size *= 0.9\n            else:\n                step_size *= 1.1\n\n\n        return self.f_opt, self.x_opt", "objective": -0.27938, "other_inf": null}
{"id": "72b37bf4-da60-4983-823d-733cdbfca9c5", "parents": [], "algorithm": "Adaptive Differential Evolution with a population that is re-initialized based on promising regions discovered during the search, adjusting mutation and crossover rates based on performance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.5, cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n            else:\n                return False #budget exceeded\n        return True\n    \n    def reinitialize_population(self, top_individuals, num_new_individuals=5):\n        \"\"\"Re-initializes a portion of the population around the best individuals.\"\"\"\n        new_population = np.copy(self.population)  # Start with the existing population\n        \n        for i in range(num_new_individuals):\n            # Select a random top individual\n            idx = np.random.randint(0, len(top_individuals))\n            best_x = top_individuals[idx]\n            \n            # Generate a new individual around this best individual\n            new_x = best_x + np.random.normal(0, 0.5, size=self.dim)  # Gaussian perturbation\n            new_x = np.clip(new_x, self.lb, self.ub)  # Clip to bounds\n            \n            # Replace a random individual in the population\n            replace_idx = np.random.randint(0, self.pop_size)\n            new_population[replace_idx] = new_x\n        \n        self.population = new_population\n        \n\n    def __call__(self, func):\n        self.initialize_population()\n        \n        if not self.evaluate_population(func):\n            return self.f_opt, self.x_opt\n        \n        generations = 0\n        while self.eval_count < self.budget:\n            generations += 1\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.f * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n                \n                # Crossover\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                        x_trial[j] = x_mutated[j]\n                \n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adaptive F and CR (simple version)\n            self.f = 0.5 + 0.2 * np.random.randn()\n            self.cr = 0.7 + 0.1 * np.random.randn()\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Re-initialize the population based on top individuals\n            num_top = int(self.pop_size * 0.2)  # e.g., top 20%\n            top_indices = np.argsort(self.fitness)[:num_top]\n            top_individuals = self.population[top_indices]\n            self.reinitialize_population(top_individuals)\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.3514, "other_inf": null}
{"id": "ab82a821-7634-4a23-bc35-231a7c79121f", "parents": [], "algorithm": "A population-based algorithm that evolves a population of solutions by combining differential mutation, crossover, and selection, adapting mutation strength based on success.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Adapt F\n                if evals % (self.pop_size * 5) == 0:\n                    success_indices = self.fitness < np.mean(self.fitness)\n                    if np.sum(success_indices) > 0:\n                        self.f = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n\n                if evals >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt", "objective": -0.59595, "other_inf": null}
{"id": "8c0a8d80-ea72-41ad-b9aa-701c19391b29", "parents": [], "algorithm": "Adaptive Differential Evolution with Archive and stochastic ranking to handle constraints based on function evaluations", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.nevals = self.pop_size  # account for initial population evaluations\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                if self.nevals >= self.budget:\n                    break\n\n                # Mutation\n                a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n\n                # Add archive vector to the choice of parents\n                if np.random.rand() < 0.1:\n                    d = np.random.choice(self.archive_size, 1, replace=False)[0]\n                    mutant = self.pop[a] + self.F * (self.pop[b] - self.archive[d])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.nevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    # Update archive: random replacement\n                    idx = np.random.randint(self.archive_size)\n                    self.archive[idx] = trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n\n\n        return self.f_opt, self.x_opt", "objective": -0.71352, "other_inf": null}
{"id": "e7c6ba11-dd4f-4159-9125-d077cc67df00", "parents": [], "algorithm": "A population-based algorithm that combines differential evolution with a local search based on Nelder-Mead simplex method to exploit promising regions.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        # Main loop\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n                \n                # Selection\n                f = func(trial)\n                evals += 1\n                \n                if f < fitness[i]:\n                    # Local Search with Nelder-Mead on improved solution\n                    res = minimize(func, trial, method='Nelder-Mead',\n                                   bounds=[(self.lb, self.ub)] * self.dim,\n                                   options={'maxfev': max(1, int((self.budget - evals) / (self.pop_size - i)))", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        # Main loop\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.where(cross_mask, mutant, population[i])\n                \n                # Selection\n                f = func(trial)\n                evals += 1\n                \n                if f < fitness[i]:\n                    # Local Search with Nelder-Mead on improved solution\n                    res = minimize(func, trial, method='Nelder-Mead',\n                                   bounds=[(self.lb, self.ub)] * self.dim,\n                                   options={'maxfev': max(1, int((self.budget - evals) / (self.pop_size - i)))}\n                                  )\n                    \n                    if res.fun < f:\n                        trial = res.x\n                        f = res.fun\n                        evals += res.nfev\n                    \n                    population[i] = trial\n                    fitness[i] = f\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e4438af6-c2ab-479b-a981-19fe191760c0", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "Simulated Annealing with adaptive temperature schedule and perturbation size.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n\n        while self.budget > 0:\n            # Adaptive perturbation size\n            perturbation_size = 0.1 * self.temp  # Perturbation scales with temperature\n            \n            x_new = x + np.random.normal(0, perturbation_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            delta_e = f_new - f\n\n            if delta_e < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_probability = np.exp(-delta_e / self.temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n\n            # Adaptive temperature schedule\n            self.temp *= self.cooling_rate\n            if self.temp < 1e-5: # prevent temperature collapse\n              self.temp = self.initial_temp \n\n        return self.f_opt, self.x_opt", "objective": -0.1422, "other_inf": null}
{"id": "6b959095-c2d9-442f-943a-b15fc92245a9", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29", "ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A population-based algorithm that uses a Gaussian Mixture Model (GMM) to learn the distribution of promising solutions and samples new solutions from this learned distribution.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimisation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, n_components=5, lb=-5.0, ub=5.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.lb = lb\n        self.ub = ub\n        self.gmm = None\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.nevals = self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.nevals < self.budget:\n            # Fit GMM to the best solutions\n            num_elites = min(self.pop_size // 2, self.nevals // 10)\n            elite_indices = np.argsort(self.fitness)[:num_elites]\n            elite_solutions = self.population[elite_indices]\n\n            if len(elite_solutions) > 1:\n                self.gmm = GaussianMixture(n_components=min(self.n_components, len(elite_solutions)), covariance_type='full', random_state=0, max_iter=100, n_init=1)\n                try:\n                    self.gmm.fit(elite_solutions)\n                except:\n                    self.gmm = None\n\n            # Sample new solutions from GMM\n            new_solutions = []\n            if self.gmm is not None:\n                try:\n                    new_solutions = self.gmm.sample(n_samples=self.pop_size)[0]\n                    new_solutions = np.clip(new_solutions, self.lb, self.ub)\n                except:\n                    new_solutions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n            else:\n                 new_solutions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_solutions])\n            self.nevals += self.pop_size\n\n            # Replace old population with new solutions based on fitness\n            combined_population = np.concatenate((self.population, new_solutions))\n            combined_fitness = np.concatenate((self.fitness, new_fitness))\n            \n            sorted_indices = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[sorted_indices]\n            self.fitness = combined_fitness[sorted_indices]\n\n            # Update optimal solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            if self.nevals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4a3f9e82-c4f8-4d94-9819-06d6232c8e4b", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts upon stagnation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, min_temp=1e-5, restart_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n        self.restart_patience = restart_patience\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        temp = self.initial_temp\n        stagnation_counter = 0\n        \n        while self.budget > 0 and temp > self.min_temp:\n            x_new = x + np.random.normal(0, temp**(1/self.dim), size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f or np.random.rand() < np.exp((f - f_new) / temp):\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n            \n            temp *= self.cooling_rate\n\n            if stagnation_counter > self.restart_patience:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                temp = self.initial_temp\n                stagnation_counter = 0\n        \n        return self.f_opt, self.x_opt", "objective": -0.35212, "other_inf": null}
{"id": "265470dd-c4df-47a3-a347-15cdb65437a7", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and inertia weight adaptation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_max=0.9, inertia_min=0.4, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.nevals = self.pop_size\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = np.copy(self.particles[self.global_best_index])\n        self.global_best_fitness = self.fitness[self.global_best_index]\n\n        while self.nevals < self.budget:\n            # Adapt inertia weight linearly\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.nevals / self.budget)\n\n            for i in range(self.pop_size):\n                if self.nevals >= self.budget:\n                    break\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Velocity clamping\n                v_max = (func.bounds.ub - func.bounds.lb) * 0.1  # Example clamping value\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.nevals += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                # Update global best\n                if fitness < self.global_best_fitness:\n                    self.global_best_fitness = fitness\n                    self.global_best_position = np.copy(self.particles[i])\n                    self.global_best_index = i\n\n                if fitness < self.f_opt:\n                    self.f_opt = fitness\n                    self.x_opt = self.particles[i]\n\n\n        return self.f_opt, self.x_opt", "objective": -0.49911, "other_inf": null}
{"id": "b1ac2129-28d4-49d2-9965-310806f7b548", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "Evolves a population using a simplified PSO variant with velocity clamping and constriction, perturbed by occasional random restarts to escape local optima.", "code": "import numpy as np\n\nclass PerturbedParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.constriction_factor = 1 # 2 / abs(2 - (cognitive_coeff + social_coeff) - np.sqrt((cognitive_coeff + social_coeff)**2 - 4*(cognitive_coeff + social_coeff))) if (cognitive_coeff + social_coeff) > 4 else 1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.evals = self.pop_size\n\n        if np.min(self.personal_best_fitness) < self.f_opt:\n            self.f_opt = np.min(self.personal_best_fitness)\n            self.x_opt = self.personal_best_positions[np.argmin(self.personal_best_fitness)]\n\n        while self.evals < self.budget:\n            global_best_index = np.argmin(self.personal_best_fitness)\n            global_best_position = self.personal_best_positions[global_best_index]\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coeff * r2 * (global_best_position - self.particles[i])\n                \n                self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_velocity + social_velocity)\n\n                # Clamp velocity\n                v_max = (self.ub - self.lb) / 2\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n                \n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n                \n                # Evaluate new position\n                f = func(self.particles[i])\n                self.evals += 1\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.particles[i].copy()\n\n                # Random Restart\n                if np.random.rand() < self.restart_prob:\n                    self.particles[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.velocities[i] = np.random.uniform(-1, 1, size=self.dim)\n                    f = func(self.particles[i])\n                    self.evals += 1\n\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.particles[i].copy()\n\n                if self.evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.59275, "other_inf": null}
{"id": "62984357-4a3a-494b-9dc1-44746091c7f2", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "Employ a swarm of particles that adjust their positions based on a combination of their own best historical position, the swarm's best historical position, and a diversity-promoting random vector, with adaptive inertia and velocity clamping.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarm\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitnesses = np.array([func(x) for x in self.swarm])\n        self.budget -= self.swarm_size\n\n        if np.min(self.personal_best_fitnesses) < self.f_opt:\n            self.f_opt = np.min(self.personal_best_fitnesses)\n            self.x_opt = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)]\n        \n        global_best_index = np.argmin(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[global_best_index].copy()\n\n        while self.budget > 0:\n            # Update velocities and positions\n            inertia_weight = self.inertia + (1.0 - self.inertia) * (self.budget / 10000) # Adaptive inertia\n            for i in range(self.swarm_size):\n                if self.budget <= 0:\n                    break\n\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                r3 = np.random.rand(self.dim) #Diversity promoting\n\n                self.velocities[i] = (inertia_weight * self.velocities[i] +\n                                     self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                     self.social_coeff * r2 * (self.global_best_position - self.swarm[i]) +\n                                     0.1 * r3 * (np.random.uniform(func.bounds.lb, func.bounds.ub) - self.swarm[i]))\n                \n                # Velocity Clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n                \n                self.swarm[i] += self.velocities[i]\n                self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n                \n                fitness = func(self.swarm[i])\n                self.budget -= 1\n\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.swarm[i].copy()\n\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = self.swarm[i].copy()\n\n                        \n            global_best_index = np.argmin(self.personal_best_fitnesses)\n            self.global_best_position = self.personal_best_positions[global_best_index].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.35478, "other_inf": null}
{"id": "41e51f44-cc4a-4fc9-ba21-b23c0c09af24", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "Simulated Annealing with adaptive temperature and step size, focusing on intensification around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = 1.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        evals = 1\n        temp = self.initial_temp\n\n        while evals < self.budget:\n            # Generate neighbor\n            x_new = self.x_opt + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            evals += 1\n\n            # Acceptance probability\n            delta_e = f_new - self.f_opt\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                self.x_opt = x_new\n                self.f_opt = f_new\n                \n                #Increase step size if improvement\n                self.step_size *= 1.05\n\n            else:\n                #Decrease step size if no improvement\n                self.step_size *= 0.95\n            \n            self.step_size = np.clip(self.step_size, 0.01, 2.0) # Limit step size\n            temp *= self.cooling_rate  #Cooling\n            \n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.32191, "other_inf": null}
{"id": "18443ca2-e17e-4d8f-800a-060ec4b490c4", "parents": ["d302892c-c556-44ac-a477-2e4d712a5352", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "Evolving a population of solutions using a combination of particle swarm optimization (PSO) for global search and Nelder-Mead simplex method for local refinement.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass PSOSimplex:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, simplex_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.simplex_iterations = simplex_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        # Initialize global best\n        self.global_best_index = np.argmin(self.personal_best_fitness)\n        self.global_best_position = self.personal_best_positions[self.global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[self.global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Update velocity and position\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                      self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(self.population[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = self.population[i].copy()\n                        self.global_best_position = self.population[i].copy()\n\n            # Local search with Nelder-Mead on global best\n            if self.eval_count + self.simplex_iterations * (self.dim + 1) <= self.budget:\n                res = minimize(func, self.global_best_position, method='Nelder-Mead',\n                               options={'maxfev': self.simplex_iterations * (self.dim + 1)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSOSimplex:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, simplex_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.simplex_iterations = simplex_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        # Initialize global best\n        self.global_best_index = np.argmin(self.personal_best_fitness)\n        self.global_best_position = self.personal_best_positions[self.global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[self.global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Update velocity and position\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                      self.social_coeff * r2 * (self.global_best_position - self.population[i]))\n                self.population[i] = np.clip(self.population[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(self.population[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = self.population[i].copy()\n                        self.global_best_position = self.population[i].copy()\n\n            # Local search with Nelder-Mead on global best\n            if self.eval_count + self.simplex_iterations * (self.dim + 1) <= self.budget:\n                res = minimize(func, self.global_best_position, method='Nelder-Mead',\n                               options={'maxfev': self.simplex_iterations * (self.dim + 1)})\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.global_best_position = res.x\n                self.eval_count += res.nfev\n            \n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "af68869c-25eb-4b70-9bbb-7907769b862a", "parents": ["d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget-aware adaptation of parameters.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, cs=0.3, damps=1.0, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.pop_size * mu_factor)\n        self.sigma = sigma0\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.cs = cs\n        self.damps = damps + 2 * max(0, np.sqrt((self.mu / self.pop_size) - 1))\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu) if ccov1 is None else ccov1\n        self.ccovmu = 2 * (self.mu / self.pop_size) / ((self.dim + 2)**2 + self.mu) if ccovmu is None else ccovmu\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.restart_trigger = 1000  # Initial restart trigger\n        self.restart_count = 0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        while self.eval_count < self.budget:\n            if self.eval_count + self.pop_size > self.budget:\n                self.pop_size = self.budget - self.eval_count\n                if self.pop_size <= 0:\n                    break\n\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            \n            idx = np.argsort(fitness)\n            x_sorted = x[idx]\n            fitness_sorted = fitness[idx]\n\n            if fitness_sorted[0] < self.f_opt:\n                self.f_opt = fitness_sorted[0]\n                self.x_opt = x_sorted[0]\n            \n            x_mu = x_sorted[:self.mu]\n            weights = np.log(self.pop_size + 1) - np.log(1 + np.arange(self.mu))\n            weights /= np.sum(weights)\n            \n            old_mean = self.mean.copy()\n            self.mean += self.sigma * np.sum(weights[:, None] * z[idx[:self.mu]], axis=0)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * (self.mean - old_mean) / self.sigma\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) < (1.4 + (2 / (self.dim + 1))) * self.chiN\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu) * ((self.mean - old_mean) / self.sigma)\n\n            artmp = (1 / self.sigma) * (x_mu - old_mean).T\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * np.sum(self.pc[:, None] * self.pc[None, :])) * self.C + self.ccovmu * artmp @ np.diag(weights) @ artmp.T\n            \n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n            # Budget-aware adaptation of restart trigger\n            if self.eval_count > self.restart_trigger:\n              self.restart_count += 1\n              self.restart_trigger += 1000 * (1 + self.restart_count)\n              self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n              self.sigma = 0.5  # Reset sigma\n              self.C = np.eye(self.dim)\n              self.pc = np.zeros(self.dim)\n              self.ps = np.zeros(self.dim)\n              \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "8a31bf4d-cd99-4b7c-8410-b9f548bc33c8", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A population-based algorithm that uses a combination of differential evolution and covariance matrix adaptation to evolve a population, adapting both mutation strength and search direction based on the population's covariance matrix.", "code": "import numpy as np\n\nclass CmaDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Covariance matrix\n\n    def __call__(self, func):\n        self.population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.pop_size)\n        self.population = np.clip(self.population, self.lb, self.ub)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            offspring = []\n            offspring_fitness = []\n\n            for i in range(self.pop_size):\n                # Differential Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.sigma * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n                \n                # Evaluate\n                f = func(trial)\n                evals += 1\n                offspring.append(trial)\n                offspring_fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n\n                if evals >= self.budget:\n                    break\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array(offspring_fitness)\n\n            # Selection: Replace the worst individuals in the population with the best offspring\n            for i in np.argsort(self.fitness)[::-1]:\n                j = np.argmin(offspring_fitness)\n                if offspring_fitness[j] < self.fitness[i]:\n                    self.fitness[i] = offspring_fitness[j]\n                    self.population[i] = offspring[j]\n                    offspring_fitness = np.delete(offspring_fitness, j)\n                    offspring = np.delete(offspring, obj=j, axis=0)\n                    if offspring.size == 0:\n                        break\n            \n            # CMA-ES-like Adaptation\n            self.mean = np.mean(self.population, axis=0)\n            diff = self.population - self.mean\n            self.C = np.cov(diff.T) + 1e-8 * np.eye(self.dim) # Add a small value to avoid singular matrix\n            self.sigma *= np.exp(0.1 * (np.mean(self.fitness) - np.mean(offspring_fitness)) / self.f_opt)\n\n        return self.f_opt, self.x_opt", "objective": -0.13812, "other_inf": null}
{"id": "6ba50c25-674c-4319-934a-bca440f01765", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "# Description: Enhanced Differential Evolution with dynamic parameter adaptation and a restart mechanism to avoid stagnation.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.nevals = self.pop_size\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                if self.nevals >= self.budget:\n                    break\n\n                # Mutation\n                a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                f_trial = func(trial)\n                self.nevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    # Parameter Adaptation (adjust F and CR based on success)\n                    if np.random.rand() < 0.1:\n                        self.F = np.clip(np.random.normal(self.F, 0.1), 0.1, 0.9)\n                        self.CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 0.9)\n\n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    idx = np.random.randint(self.pop_size)\n                    self.pop[idx] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                    self.fitness[idx] = func(self.pop[idx])\n                    self.nevals += 1\n\n                    if self.fitness[idx] < self.f_opt:\n                        self.f_opt = self.fitness[idx]\n                        self.x_opt = self.pop[idx]\n\n        return self.f_opt, self.x_opt", "objective": -0.37693, "other_inf": null}
{"id": "335a184e-c3e6-4737-b935-63c1651dc75b", "parents": ["d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "Self-adaptive Differential Evolution with a dynamic population size and a learning strategy based on successful parameter settings.", "code": "import numpy as np\n\nclass DynamicAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_min=10, pop_size_max=100, archive_size=20, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_min = pop_size_min\n        self.pop_size_max = pop_size_max\n        self.pop_size = pop_size_max # Start with larger population for exploration\n        self.archive_size = archive_size\n        self.learning_rate = learning_rate\n        self.F = 0.5\n        self.CR = 0.7\n        self.successful_F = []\n        self.successful_CR = []\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        while self.eval_count < self.budget:\n            # Dynamically adjust population size\n            if self.eval_count > self.budget * 0.7:\n                self.pop_size = max(self.pop_size_min, int(self.pop_size * 0.95)) # Reduce population size near the end for exploitation\n            else:\n                self.pop_size = min(self.pop_size_max, self.pop_size)\n\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                \n                # Mutation\n                idx = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idx]\n\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    xa = self.archive[np.random.randint(len(self.archive))]\n                    v = x1 + self.F * (xa - x3)\n                else:\n                    v = x1 + self.F * (x2 - x3)\n                \n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.eval_count += 1\n                \n                if f_u < self.fitness[i]:\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = self.population[i].copy()\n                    \n                    # Store successful parameters\n                    self.successful_F.append(self.F)\n                    self.successful_CR.append(self.CR)\n\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n            # Update F and CR based on successful values\n            if len(self.successful_F) > 0:\n                self.F = (1 - self.learning_rate) * self.F + self.learning_rate * np.mean(self.successful_F)\n                self.CR = (1 - self.learning_rate) * self.CR + self.learning_rate * np.mean(self.successful_CR)\n                self.successful_F = []\n                self.successful_CR = []\n\n        return self.f_opt, self.x_opt", "objective": -0.50187, "other_inf": null}
{"id": "71fb0f58-6602-4737-8da9-1995ea863679", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with budget-aware adaptation of population size.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, cs=0.3, damps=1, ccov1=0.1, ccovmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(np.floor(self.dim / 2))\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.pop_size = self.initial_pop_size\n\n        self.m = np.zeros(self.dim)\n        self.sigma = 0.2\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1 / (self.dim + 1)\n        self.ccovmu = ccovmu / (self.dim + 1)\n\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu * self.mueff)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.budget > 0:\n            if self.budget < self.pop_size:\n                self.pop_size = self.budget\n                self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.ccovmu = min(1-self.ccov1, self.ccovmu * self.mueff)\n\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x[:,i]) for i in range(self.pop_size)])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[:, np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            x_sorted = x[:, idx]\n\n            m_old = self.m.copy()\n            self.m = np.dot(x_sorted[:, :self.mu], self.weights[:self.mu])\n\n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs) * self.mueff)**0.5 * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.m - m_old)) / self.sigma\n            hsig = (np.sum(self.ps**2) / (self.dim * (1 - self.cs)**(2 * (self.budget / self.pop_size))) < 2 + 4/(self.dim + 1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * (self.ccov1 * (2 - self.ccov1) * self.mueff)**0.5 * (self.m - m_old) / self.sigma\n\n            artmp = (1/self.sigma) * (x_sorted[:, :self.mu] - m_old[:, np.newaxis])\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1/self.mueff)) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.dot(artmp, np.diag(self.weights[:self.mu])).dot(artmp.T)\n\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = self.C + 1e-8 * np.eye(self.dim)\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c1e94fe6-1d91-4e2f-aaab-d9c441186350", "parents": ["d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "A variant of the Differential Evolution algorithm that employs a larger population size, a higher mutation factor, and a lower crossover rate to enhance exploration, and periodically restarts the population to avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=100, restart_interval=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_interval = restart_interval\n        self.F = 0.9\n        self.CR = 0.3\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            # Restart population periodically\n            if self.eval_count % self.restart_interval < self.pop_size and self.eval_count > 0:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                if self.eval_count >= self.budget:\n                  break\n\n\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Mutation\n                idx = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idx]\n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Selection\n                f_u = func(u)\n                self.eval_count += 1\n\n                if f_u < self.fitness[i]:\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n\n        return self.f_opt, self.x_opt", "objective": -0.30954, "other_inf": null}
{"id": "0e33d065-1664-49f7-ba72-a6897fce269e", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A population-based algorithm using a velocity update rule inspired by Particle Swarm Optimization (PSO) combined with differential evolution mutation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.9, f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr\n        self.f = f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position.copy()\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # PSO Velocity Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n                \n                # Update position with velocity\n                trial = self.population[i] + self.velocities[i]\n                trial = np.clip(trial, self.lb, self.ub)\n\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = trial.copy()\n\n\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = trial.copy()\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        \n                if evals >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "objective": -0.37477, "other_inf": null}
{"id": "f7ad5592-3729-4979-b293-a68f3c229fde", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space, promoting faster convergence towards the optimum.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.nevals = 0\n\n        while self.nevals < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.nevals += self.pop_size\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            f_sorted = f[idx]\n            \n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            \n            z_sorted = z[idx]\n            z_mean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n            \n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * z_mean\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.nevals / self.pop_size)) / self.chiN) < (1.4 + 2/(self.dim+1))\n            dhsig = (1-hsig) * self.cs * (2-self.cs)\n            \n            self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1) * (self.m - m_old) / self.sigma\n            \n            artmp = (1 / self.sigma) * (x_sorted[:self.mu] - m_old)\n            self.C = (1-self.ccov1-self.ccovmu+self.ccov1*dhsig) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                        + self.ccovmu * artmp.T @ np.diag(self.weights) @ artmp\n            \n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[0]\n\n        return self.f_opt, self.x_opt", "objective": -0.28675, "other_inf": null}
{"id": "18f95982-5f26-4189-a463-b261bb0ccd8e", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified adaptation rules and restart mechanism.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = max(1, int(self.pop_size * mu_factor))\n        self.weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.C = np.eye(dim)\n        self.m = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.cc = 4/(dim + 4)\n        self.cs = (self.cc + (budget/self.pop_size))/ (dim + (budget/self.pop_size))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mu/self.pop_size) - 1)) + self.cs\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nevals = 0\n        self.restart_criterion = 1e-12  # added restart criterion\n        self.restart_iterations = 50  # added restart iterations\n\n    def __call__(self, func):\n        iteration = 0\n        while self.nevals < self.budget:\n            iteration += 1\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.m + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.nevals += self.pop_size\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n            \n            m_old = self.m\n            self.m = np.sum(x[:self.mu].T * self.weights[:self.mu], axis=1)\n            \n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ (self.m - m_old)) / self.sigma\n            \n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (self.m - m_old) / self.sigma\n            \n            self.C = (1 - self.cc) * self.C + self.cc * (np.outer(self.pc, self.pc) + (self.cc/(2-self.cc)) * self.C) \n\n            self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/self.chiN - 1))\n            \n            # Restart mechanism\n            if np.min(np.diag(self.C)) < self.restart_criterion or iteration > self.restart_iterations:  \n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma = 0.5  # Reset sigma\n                iteration = 0\n                \n        return self.f_opt, self.x_opt", "objective": -0.15341, "other_inf": null}
{"id": "00a5497c-6c10-469f-8b7b-08e15829cc6a", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "# Description: This algorithm uses a covariance matrix adaptation evolution strategy (CMA-ES) to adapt the search distribution during the optimization process.\n# Code:\n```", "code": "import numpy as np\nfrom scipy.linalg import sqrtm\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.sigma = sigma\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.cs\n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else 1\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 2 * (self.mu - 1) / ((self.dim + 2)**2 + self.mu)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.nevals = 0\n        while self.nevals < self.budget:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.m + self.sigma * (sqrtm(self.C) @ z.T).T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = np.array([func(xi) for xi in x])\n            self.nevals += self.pop_size\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n\n            y_w = np.sum(self.weights[:, None] * z_mu, axis=0)\n            m_new = np.sum(self.weights[:, None] * x_mu, axis=0)\n            \n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * y_w\n            self.p_c = (1 - self.c_cov_mean) * self.p_c + np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean)) * np.sqrt(self.mu) * (m_new - self.m) / self.sigma\n            \n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + \\\n                     self.c_cov_rank_one * np.outer(self.p_c, self.p_c) + \\\n                     self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * np.array([np.outer(z_mu[i], z_mu[i]) for i in range(self.mu)]), axis=0)\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n            self.m = m_new\n            \n            if self.nevals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "685ce09f-d67d-45b2-928e-e5e87dc0e44c", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy with resampling and step size adaptation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, c1=None, cmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.c1 = c1 if c1 is not None else 2 / ((dim + 1.3)**2 + 1)\n        self.cmu = cmu if cmu is not None else min(1 - self.c1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((dim + 2)**2 + 1))\n        self.mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = 1 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mu + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n              f = f[:self.pop_size+self.budget]\n              x = x[:self.pop_size+self.budget]\n              self.pop_size = len(x)\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n            \n            z = z[idx]\n            z = z[:self.pop_size]\n            x = x[:self.pop_size]\n            f = f[:self.pop_size]\n\n            delta_mu = np.sum(self.weights[:, None] * z[:self.pop_size], axis=0)\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * delta_mu\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.linalg.inv(np.linalg.cholesky(self.C)) @ delta_mu\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.cmu * np.sum(self.weights[:, None, None] * (z[:, :, None] @ z[:, None, :]), axis=0)\n            self.mu = self.mu + self.sigma * np.sum(self.weights[:, None] * z[:self.pop_size], axis=0)\n            self.sigma = self.sigma * np.exp((self.cs / self.dim) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "68a9dcd6-4eb1-44d5-882e-075193c490e4", "parents": ["d302892c-c556-44ac-a477-2e4d712a5352", "d302892c-c556-44ac-a477-2e4d712a5352"], "algorithm": "# Description: An algorithm that combines aspects of particle swarm optimization with a shrinking search space to focus on promising regions.\n# Code:\n```", "code": "import numpy as np\n\nclass ShrinkingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, shrinkage_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.shrinkage_rate = shrinkage_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.global_best_index].copy()\n\n        self.eval_count = self.pop_size\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Update velocity\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.population[i]) +\n                                      self.social_coeff * np.random.rand() * (self.global_best_position - self.population[i]))\n\n                # Update position\n                new_position = self.population[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Evaluate new position\n                f_new = func(new_position)\n                self.eval_count += 1\n                \n\n                # Update personal best\n                if f_new < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_new\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position.copy()\n                        self.global_best_position = new_position.copy()\n                        self.global_best_index = i\n\n                self.population[i] = new_position\n\n            # Shrink the search space around the global best\n            center = self.global_best_position\n            range_val = (ub - lb) / 2.0 * self.shrinkage_rate\n            lb = np.maximum(func.bounds.lb, center - range_val)\n            ub = np.minimum(func.bounds.ub, center + range_val)\n            self.population = np.clip(self.population, lb, ub)\n            \n        return self.f_opt, self.x_opt", "objective": -0.42184, "other_inf": null}
{"id": "bd3079bd-1c79-48e8-8174-2395dcc46936", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "Employ a population-based approach with Gaussian mutation and adaptive step size control based on the success rate of mutations, coupled with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_step_size=1.0, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n        self.restart_trigger = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        iteration = 0\n        stagnation_counter = 0\n        best_fitness_history = [self.f_opt]\n\n        while self.budget > 0:\n            iteration += 1\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                mutant = np.clip(self.pop[i] + self.step_size * np.random.normal(0, 1, size=self.dim), func.bounds.lb, func.bounds.ub)\n\n                f_mutant = func(mutant)\n                self.budget -= 1\n\n                if f_mutant < self.fitness[i]:\n                    self.pop[i] = mutant\n                    self.fitness[i] = f_mutant\n                    successful_mutations += 1\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n            success_rate = successful_mutations / self.pop_size if self.pop_size > 0 else 0.0\n            self.success_history.append(success_rate)\n            if len(self.success_history) > self.success_rate_memory:\n                self.success_history.pop(0)\n\n            avg_success_rate = np.mean(self.success_history) if self.success_history else 0.0\n            if avg_success_rate > 0.2:\n                self.step_size *= 1.1\n            else:\n                self.step_size *= 0.9\n\n            if self.f_opt <= min(best_fitness_history):\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 100:\n                best_fitness_history.pop(0)\n            \n            if stagnation_counter > self.restart_trigger:\n                self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.budget -= self.pop_size\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.pop[np.argmin(self.fitness)]\n                stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.4046, "other_inf": null}
{"id": "04465b8b-22fa-43fb-9522-eacaa2c84917", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "'type': 'ineq', 'fun': lambda x: x - bounds.lb},\n                {'type': 'ineq', 'fun': lambda x: bounds.ub - x", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass BayesianOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_points=10, n_iter=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = min(n_initial_points, budget // 2)\n        self.n_iter = n_iter\n        self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nevals = 0\n\n    def acquisition_function(self, x, gp, bounds):\n        x = x.reshape(-1, self.dim)\n        mu, sigma = gp.predict(x, return_std=True)\n        \n        # Ensure sigma is not zero to avoid division by zero\n        sigma = np.maximum(sigma, 1e-9)\n        \n        best = self.y.min()\n        z = (best - mu) / sigma\n        return - (mu - best) - sigma * norm.pdf(z)\n    \n    def propose_location(self, gp, bounds, n_restarts=25):\n        \"\"\"Proposes the next sampling point by optimizing the acquisition function.\"\"\"\n        \n        def min_obj(x):\n            \"\"\"Returns the value of the acquisition function at x.\"\"\"\n            return self.acquisition_function(x.reshape(-1, self.dim), gp, bounds)\n\n        # Start with bounds on x\n        cons = ({'type': 'ineq', 'fun': lambda x: x - bounds.lb},\n                {'type': 'ineq', 'fun': lambda x: bounds.ub - x})\n\n        # Run local search n_restarts times\n        x_starts = []\n        f_values = []\n        for x0 in np.random.uniform(bounds.lb, bounds.ub, size=(n_restarts, self.dim)):\n            res = minimize(min_obj, x0=x0, bounds=bounds, method='L-BFGS-B', constraints=cons)\n            x_starts.append(res.x.reshape(-1, self.dim))\n            f_values.append(res.fun)\n\n        # Pick the best among all local search results\n        ind = np.argmin(f_values)\n        return x_starts[ind].reshape(-1, self.dim)\n    \n    def __call__(self, func):\n        # Initial exploration\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_points, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.nevals = self.n_initial_points\n\n        if np.min(self.y) < self.f_opt:\n            self.f_opt = np.min(self.y)\n            self.x_opt = self.X[np.argmin(self.y)]\n\n        # Bayesian optimization loop\n        for i in range(self.n_iter):\n            if self.nevals >= self.budget:\n                break\n\n            self.gp.fit(self.X, self.y)\n\n            # Propose the next location\n            x_new = self.propose_location(self.gp, func.bounds)\n\n            # Evaluate the function at the new location\n            f_new = func(x_new)\n            self.nevals += 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "86e44d19-cea0-4c70-ab04-53e5d419108e", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "# Description: Population-based algorithm using a covariance matrix adaptation strategy with a restart mechanism based on fitness improvements.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, restart_factor=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.restart_factor = restart_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.count_evals = 0\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        best_fitness_history = []\n        stagnation_counter = 0\n\n        while self.count_evals < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            samples = self.mean + self.sigma * z\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x) for x in samples])\n            self.count_evals += self.pop_size\n            if self.count_evals > self.budget:\n                fitness = fitness[:self.pop_size - (self.count_evals - self.budget)]\n                samples = samples[:self.pop_size - (self.count_evals - self.budget)]\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            samples = samples[idx]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = samples[0]\n\n            delta_mean = np.sum(self.weights[:, None] * z[idx[:self.mu]], axis=0)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * delta_mean\n            hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*(self.budget/self.pop_size)))/self.chiN < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * self.sigma**-1 * (self.mean - samples[0])\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] * self.pc) + self.cmu * np.sum(self.weights[:, None, None] * (z[idx[:self.mu], :, None] * z[idx[:self.mu], None, :]), axis=0)\n\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            self.mean = np.sum(self.weights[:, None] * samples[:self.mu], axis=0)\n\n            if np.any(np.linalg.eigvalsh(self.C) < 0):\n                self.C = np.eye(self.dim)\n\n            if self.f_opt <= min(best_fitness_history + [np.inf]):\n              stagnation_counter = 0\n            else:\n                stagnation_counter +=1\n\n            best_fitness_history.append(self.f_opt)\n            if len(best_fitness_history) > 50:\n              best_fitness_history.pop(0)\n\n            if stagnation_counter > 25:\n              self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n              self.C = np.eye(self.dim)\n              self.pc = np.zeros(self.dim)\n              self.ps = np.zeros(self.dim)\n              stagnation_counter = 0\n        return self.f_opt, self.x_opt", "objective": -0.57117, "other_inf": null}
{"id": "0dc3f85c-3c35-4efe-9cbb-11d2edf3ddf2", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rate and a perturbation scheme using Cauchy distribution to allow for larger jumps.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, perturbation_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.perturbation_scale = perturbation_scale\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_current = func(self.x)\n        self.f_opt = self.f_current\n        self.x_opt = self.x.copy()\n        self.temp = self.initial_temp\n        evals = 1\n        acceptance_rate = 0.0\n\n        while evals < self.budget:\n            # Perturbation using Cauchy distribution\n            x_new = self.x + self.perturbation_scale * self.temp * np.random.standard_cauchy(size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            delta_f = f_new - self.f_current\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.x = x_new\n                self.f_current = f_new\n                acceptance_rate += 1.0\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new.copy()\n\n            # Adaptive temperature adjustment\n            if evals % 100 == 0:\n                acceptance_ratio = acceptance_rate / 100.0\n                if acceptance_ratio > 0.5:\n                    self.temp *= 0.95\n                elif acceptance_ratio < 0.1:\n                    self.temp *= 1.05\n                acceptance_rate = 0.0\n            else:\n                self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.29636, "other_inf": null}
{"id": "95a6d408-caa4-4d39-8163-ed50b9c3eb88", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "A self-adaptive Differential Evolution with a Cauchy mutation operator and a learning strategy to adapt the scaling factor F and crossover rate CR.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.F_history = []\n        self.CR_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.nevals = self.pop_size\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                if self.nevals >= self.budget:\n                    break\n\n                # Mutation using Cauchy distribution\n                a, b, c = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c]) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.nevals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    \n                    # Adapt F and CR\n                    if len(self.F_history) > 10:\n                        self.F = np.mean(self.F_history[-10:])\n                        self.CR = np.mean(self.CR_history[-10:])\n\n                    self.F = np.clip(self.F + 0.1 * np.random.normal(), 0.1, 1.0)\n                    self.CR = np.clip(self.CR + 0.1 * np.random.normal(), 0.1, 1.0)\n                    self.F_history.append(self.F)\n                    self.CR_history.append(self.CR)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.49061, "other_inf": null}
{"id": "76b03944-119a-4e0a-97fa-439557e5c8a3", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a limited budget for function evaluations.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.mu = mu if mu is not None else self.pop_size // 2\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mu - 1 + 1e-8) / ((self.dim + 2)**2 + self.mu)\n        self.ccovmu = min(1 - self.ccov1, self.ccovmu)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nevals = 0\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n        while self.nevals < self.budget:\n            z = np.random.normal(size=(self.dim, self.pop_size))\n            y = np.linalg.cholesky(self.C) @ z\n            x = self.m + self.sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(xi) for xi in x.T])\n            self.nevals += self.pop_size\n\n            if self.nevals > self.budget:\n                fitness = fitness[:self.budget - (self.nevals - self.pop_size)]\n                x = x[:, :self.budget - (self.nevals - self.pop_size)]\n                self.nevals = self.budget\n\n            idx = np.argsort(fitness)\n            x = x[:, idx]\n            fitness = fitness[idx]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n\n            m_old = self.m.copy()\n            self.m = x[:, :self.mu] @ self.weights\n\n            y_mean = self.m - m_old\n            self.ps = (1 - self.cs) * self.ps + (np.sqrt(self.cs * (2 - self.cs) * self.mu) / self.sigma) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ y_mean)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.nevals / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1))\n\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu) * y_mean / self.sigma\n\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * (x[:, :self.mu] - m_old) @ np.diag(self.weights) @ (x[:, :self.mu] - m_old).T / self.sigma**2\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = np.linalg.cholesky(self.C @ self.C.T) # Repair C if it's close to singular\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "3cb5815a-5926-4868-b7ee-0ab49939a224", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step size adaptation.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.initial_step_size = initial_step_size\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2 * max(0, ((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_cov = (1 / (self.mu * (self.dim + 1.3)**2 + 0.1 * (budget/dim) ) )\n        self.c_m = 1\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.sigma = None\n        self.C = None\n        self.P_sigma = None\n        self.eigen_decomposition = None\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        self.nevals = 0\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.initial_step_size\n        self.C = np.eye(self.dim)\n        self.P_sigma = np.zeros(self.dim)\n\n        while self.nevals < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = np.array([func(xi) for xi in x])\n            self.nevals += self.pop_size\n            \n            if self.nevals > self.budget:\n                f = f[:self.pop_size - (self.nevals-self.budget)]\n                x = x[:self.pop_size - (self.nevals-self.budget)]\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            m_old = self.m\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            z_m = (self.m - m_old) / self.sigma\n\n            self.P_sigma = (1 - self.c_sigma) * self.P_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_m\n\n            norm_P_sigma = np.linalg.norm(self.P_sigma)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_P_sigma / (np.sqrt(self.dim)) - 1))\n\n            if self.sigma < 1e-10:\n                self.sigma = 1e-10\n\n            C_tmp = (x[:self.mu] - m_old).T @ (x[:self.mu] - m_old)\n            \n            self.C = (1 - self.c_cov) * self.C + self.c_cov * C_tmp / (self.sigma**2 * self.mu)\n            \n            if np.linalg.det(self.C) <= 0:\n                self.C = np.eye(self.dim) # Restart Covariance Matrix when it is no longer positive definite\n                self.P_sigma = np.zeros(self.dim)\n                self.sigma = self.initial_step_size # Reset step-size\n            \n        return self.f_opt, self.x_opt", "objective": -0.41944, "other_inf": null}
{"id": "fe05a20f-b3fb-4c66-b33c-3e2bd42c5ddb", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A variant of Differential Evolution that incorporates a local search component using Nelder-Mead simplex method to refine promising solutions.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f=0.5, local_search_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_interval = local_search_interval\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Local Search\n            if evals % self.local_search_interval == 0:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index].copy()\n\n                def local_func(x):\n                    return func(x)\n                \n                local_result = minimize(local_func, x_best, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': self.local_search_interval // 2", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f=0.5, local_search_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_interval = local_search_interval\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Local Search\n            if evals % self.local_search_interval == 0:\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index].copy()\n\n                def local_func(x):\n                    return func(x)\n                \n                local_result = minimize(local_func, x_best, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': self.local_search_interval // 2})\n                \n                if local_result.fun < self.f_opt:\n                    self.f_opt = local_result.fun\n                    self.x_opt = local_result.x\n                    self.fitness[best_index] = local_result.fun\n                    self.population[best_index] = local_result.x\n                evals += local_result.nfev\n\n                \n            if evals >= self.budget:\n                break\n                    \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2774d972-3b3a-48a9-969b-f899cae2ad0d", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rate and memory of previous moves.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.99, temp_adjust_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adjust_freq = temp_adjust_freq\n        self.lb = -5.0\n        self.ub = 5.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        self.current_x = self.x_opt.copy()\n        self.current_f = self.f_opt\n        self.temperature = self.initial_temp\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a neighbor\n            neighbor_x = self.current_x + np.random.normal(0, 0.1, size=self.dim)\n            neighbor_x = np.clip(neighbor_x, self.lb, self.ub)\n            neighbor_f = func(neighbor_x)\n            evals += 1\n\n            # Acceptance probability\n            delta_f = neighbor_f - self.current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temperature):\n                self.current_x = neighbor_x\n                self.current_f = neighbor_f\n                self.acceptance_history.append(1)\n                if neighbor_f < self.f_opt:\n                    self.f_opt = neighbor_f\n                    self.x_opt = neighbor_x\n            else:\n                 self.acceptance_history.append(0)\n            # Temperature update\n            if evals % self.temp_adjust_freq == 0:\n                acceptance_rate = np.mean(self.acceptance_history[-self.temp_adjust_freq:]) if len(self.acceptance_history) >= self.temp_adjust_freq else np.mean(self.acceptance_history) if len(self.acceptance_history)>0 else 0.5\n                if acceptance_rate > 0.7:\n                    self.temperature *= 1.1\n                elif acceptance_rate < 0.3:\n                    self.temperature *= 0.9\n                else:\n                    self.temperature *= self.cooling_rate\n                self.temperature = max(self.temperature, 1e-6)\n                \n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.1553, "other_inf": null}
{"id": "920d89ad-fe5d-4955-aade-236beb146efa", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "# Description: Implement a Self-Adaptive Differential Evolution algorithm with dynamic parameter adaptation and archive to improve exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.Cr = 0.9\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Parameter Adaptation\n                self.F = np.random.normal(0.5, 0.33)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.Cr = np.random.normal(0.9, 0.1)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[idxs]\n\n                # Use archive with a small probability\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    c = self.archive[arc_idx]\n\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                cross_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.pop[i])\n                trial[cross_mask] = mutant[cross_mask]\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Update population\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.pop[i])\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.pop[i]\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.71792, "other_inf": null}
{"id": "245f5e7e-f956-489f-a796-04f56dc9205d", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A self-adaptive Differential Evolution algorithm that adjusts both the crossover rate and the mutation factor based on the success rate of previous generations.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cr_memory = np.ones(self.pop_size) * self.cr_init\n        self.f_memory = np.ones(self.pop_size) * self.f_init\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and CR\n                self.cr = np.random.normal(self.cr_memory[i], 0.1)\n                self.cr = np.clip(self.cr, 0.0, 1.0)\n                self.f = np.random.normal(self.f_memory[i], 0.3)\n                self.f = np.clip(self.f, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    delta_fitness = self.fitness[i] - f\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    \n                    # Update memory of F and CR based on success\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * self.cr\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * self.f\n                else:\n                    # Even if selection fails, slightly perturb the CR and F\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * np.random.rand()\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * np.random.rand()\n\n                if evals >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt", "objective": -0.75694, "other_inf": null}
{"id": "b9ab7bd6-ba19-4949-a082-b94cfe3a20ff", "parents": ["ab82a821-7634-4a23-bc35-231a7c79121f"], "algorithm": "A particle swarm optimization (PSO) algorithm that updates particle positions based on their own best known position and the swarm's best known position, incorporating velocity clamping and inertia weight decay.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)  # Initialize with infinity\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size) # Initialize with infinity\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if self.fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = self.fitness[i]\n                    self.global_best_position = self.population[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                fitness = func(self.population[i])\n                evals += 1\n\n                # Update personal and global best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.population[i].copy()\n                        self.f_opt = self.global_best_fitness\n                        self.x_opt = self.global_best_position\n\n                if evals >= self.budget:\n                    break\n\n            # Decay inertia weight (optional)\n            self.w *= 0.99\n\n        return self.f_opt, self.x_opt", "objective": -0.614, "other_inf": null}
{"id": "c5cda5c9-4d4d-44f6-bcf5-ab990cc8b03a", "parents": ["920d89ad-fe5d-4955-aade-236beb146efa", "245f5e7e-f956-489f-a796-04f56dc9205d"], "algorithm": "Implement a Gaussian Process-based Bayesian Optimization algorithm with Expected Improvement acquisition function, dynamically adapting the exploration-exploitation trade-off.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass BayesianOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_points=10, exploration_factor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = n_initial_points\n        self.exploration_factor = exploration_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X_samples = []\n        self.Y_samples = []\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        best = np.min(self.Y_samples)\n        imp = best - mu\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def __call__(self, func):\n        from scipy.stats import norm\n        from scipy.optimize import minimize\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_points, self.dim))\n        Y_init = np.array([func(x) for x in X_init])\n        self.X_samples = X_init.tolist()\n        self.Y_samples = Y_init.tolist()\n        \n        self.budget -= self.n_initial_points\n        \n        if np.min(Y_init) < self.f_opt:\n            self.f_opt = np.min(Y_init)\n            self.x_opt = X_init[np.argmin(Y_init)]\n\n        # Define Gaussian Process\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while self.budget > 0:\n            # Fit GP model\n            gp.fit(self.X_samples, self.Y_samples)\n\n            # Find next point to evaluate using Expected Improvement\n            def neg_ei(x):\n                return -self.acquisition_function(x, gp)\n\n            bounds = [(self.lb, self.ub)] * self.dim\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim) # Initial guess\n            res = minimize(neg_ei, x0, method='L-BFGS-B', bounds=bounds)\n            x_next = res.x\n\n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n            \n            # Append sample\n            self.X_samples.append(x_next)\n            self.Y_samples.append(f_next)\n\n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "8a58543e-cbfa-4ea5-9f88-cd8a404cdf89", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "A population-based algorithm that combines particle swarm optimization with a Gaussian mutation strategy, periodically re-initializing a portion of the population to maintain diversity and escape local optima.", "code": "import numpy as np\n\nclass PSO_GM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, mutation_rate=0.05, reset_ratio=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.mutation_rate = mutation_rate\n        self.reset_ratio = reset_ratio\n        self.pop = None\n        self.velocity = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        self.personal_best_positions = np.copy(self.pop)\n        self.personal_best_fitness = np.copy(self.fitness)\n        self.global_best_position = self.pop[np.argmin(self.fitness)]\n        self.global_best_fitness = np.min(self.fitness)\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n        \n    def gaussian_mutation(self, x, func):\n        mask = np.random.rand(self.dim) < self.mutation_rate\n        x[mask] = np.clip(x[mask] + np.random.normal(0, 0.1, size=np.sum(mask)), func.bounds.lb, func.bounds.ub)\n        return x\n    \n    def reset_population_subset(self, func):\n        num_reset = int(self.pop_size * self.reset_ratio)\n        indices = np.random.choice(self.pop_size, num_reset, replace=False)\n        self.pop[indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reset, self.dim))\n        self.velocity[indices] = np.random.uniform(-1, 1, size=(num_reset, self.dim))\n        self.fitness[indices] = np.array([func(x) for x in self.pop[indices]])\n        self.budget -= num_reset\n        \n        for i in indices:\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.pop[i]\n            \n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.pop[i]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.pop[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.pop[i])\n                self.velocity[i] = self.w * self.velocity[i] + cognitive_component + social_component\n                \n                # Update position\n                self.pop[i] = np.clip(self.pop[i] + self.velocity[i], func.bounds.lb, func.bounds.ub)\n                \n                # Gaussian Mutation\n                self.pop[i] = self.gaussian_mutation(self.pop[i], func)\n\n                # Evaluate fitness\n                f = func(self.pop[i])\n                self.budget -= 1\n                self.fitness[i] = f\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.pop[i]\n\n                # Update global best\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.pop[i]\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n            \n            if generation % 50 == 0:\n                self.reset_population_subset(func)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a54453b4-734a-459f-9112-d999b07079f5", "parents": ["245f5e7e-f956-489f-a796-04f56dc9205d", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "An evolutionary strategy with covariance matrix adaptation (CMA-ES) that learns and adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mu = (self.ub + self.lb) / 2 * np.ones(self.dim)  # Mean value\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.p_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        self.p_c = np.zeros(self.dim)  # Evolution path for covariance\n\n        self.cs = cs\n        self.damps = damps\n        self.c_cov = c_cov\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2)) # expectation of ||N(0,I)||\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        \n        while evals < self.budget:\n            # Generate population\n            z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.pop_size)\n            y = np.dot(z, np.linalg.cholesky(self.C).T)\n            x = self.mu + self.sigma * y\n            x = np.clip(x, self.lb, self.ub)  # clip to bounds\n\n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            # Sort by fitness\n            idx_sort = np.argsort(fitness)\n            x = x[idx_sort]\n\n            # Update mean\n            x_mean = np.mean(x[:self.pop_size//2], axis=0)\n            y_mean = (x_mean - self.mu) / self.sigma\n            self.mu = x_mean\n\n            # Update evolution paths\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * y_mean\n            self.p_c = (1 - self.c_cov) * self.p_c + np.sqrt(self.c_cov * (2 - self.c_cov)) * np.sqrt(self.pop_size//2) * (x_mean - self.mu) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.p_c, self.p_c) + self.c_cov * (1 - self.c_cov) * np.eye(self.dim)\n\n            # Update sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / self.chiN - 1))\n            self.sigma = max(self.sigma, 1e-10)\n\n            if evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.1954, "other_inf": null}
{"id": "72f9e778-ec4b-499d-b9c8-d68d401bcf3d", "parents": ["920d89ad-fe5d-4955-aade-236beb146efa", "245f5e7e-f956-489f-a796-04f56dc9205d"], "algorithm": "Implementation of a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix to guide the search towards promising regions.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma_init=0.5, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma_init\n        self.mean = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.randn(self.pop_size, self.dim)\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n            if evals > self.budget:\n                fitness = fitness[:self.pop_size - (evals - self.budget)]\n                x = x[:self.pop_size - (evals - self.budget)]\n                evals = self.budget\n                self.pop_size = self.pop_size - (evals - self.budget)\n                \n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            x_sorted = x[idx[:self.mu]]\n            z_sorted = z[idx[:self.mu]]\n\n            mean_old = self.mean.copy()\n            self.mean += self.sigma * np.sum(self.weights[:, None] * z_sorted, axis=0)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.mean - mean_old) / self.sigma\n            self.pc = (1 - self.c_cov) * self.pc + np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * (self.mean - mean_old) / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * evals / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            dhsig = (1 - hsig) * self.c_cov * (2 - self.c_cov)\n\n            self.C = (1 - self.c_cov) * self.C + dhsig * self.pc[:, None] @ self.pc[None, :]\n            for i in range(self.mu):\n                self.C += self.c_cov * self.weights[i] * ((z_sorted[i] -0)[:, None] @ (z_sorted[i]-0)[None, :])\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "objective": -0.57379, "other_inf": null}
{"id": "3bcea428-c757-4b78-8250-b6c81907f58e", "parents": ["920d89ad-fe5d-4955-aade-236beb146efa", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "# Description: Implement a Population-Based Annealing algorithm that combines global exploration through population-based search with local refinement inspired by simulated annealing.\n# Code:\n```", "code": "import numpy as np\n\nclass PopulationBasedAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=50, temp_init=1.0, temp_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.temp = temp_init\n        self.temp_decay = temp_decay\n        self.f_opt = np.inf\n        self.x_opt = None\n    def __call__(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        \n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Generate a candidate solution by perturbing the current solution\n                perturbation = np.random.normal(0, self.temp, size=self.dim)\n                candidate = np.clip(self.pop[i] + perturbation, func.bounds.lb, func.bounds.ub)\n                f_candidate = func(candidate)\n                self.budget -= 1\n\n                # Acceptance criterion (Metropolis criterion)\n                delta_f = f_candidate - self.fitness[i]\n                if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                    self.pop[i] = candidate\n                    self.fitness[i] = f_candidate\n\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n\n            self.temp *= self.temp_decay  # Cool down the temperature\n\n        return self.f_opt, self.x_opt", "objective": -0.31794, "other_inf": null}
{"id": "f2a2b8e1-ef8b-4b9c-b9dc-6ef6d2651fe5", "parents": ["245f5e7e-f956-489f-a796-04f56dc9205d", "920d89ad-fe5d-4955-aade-236beb146efa"], "algorithm": "# Description: Implement a population-based algorithm that dynamically allocates function evaluations to promising regions of the search space using a Gaussian Mixture Model (GMM) to adapt the sampling distribution.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GMMAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.lb = -5.0\n        self.ub = 5.0\n        self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initial population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while evals < self.budget:\n            # Learn GMM from the best individuals\n            num_elites = min(self.pop_size // 2, population.shape[0]) #ensure no index out of bounds\n            elites_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elites_indices]\n\n            try:\n                self.gmm.fit(elites)\n            except:\n                # Handle the case where GMM fitting fails, e.g., due to insufficient data or singular covariance\n                # Re-initialize GMM or skip the adaptation step\n                self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size # update evaluation counts\n\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n                continue\n            \n            # Sample new individuals from GMM\n            n_samples = min(self.budget - evals, self.pop_size)\n            new_samples = self.gmm.sample(n_samples)[0]\n            new_samples = np.clip(new_samples, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_samples])\n            evals += n_samples\n            \n            # Update population\n            worst_idx = np.argmax(fitness)\n            for i in range(n_samples):\n                if new_fitness[i] < fitness[worst_idx]:\n                    fitness[worst_idx] = new_fitness[i]\n                    population[worst_idx] = new_samples[i]\n                    worst_idx = np.argmax(fitness) #Recalculate index of worst\n                \n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_samples[i]\n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "91109d76-ff2b-4e40-a7d1-03189372f163", "parents": ["920d89ad-fe5d-4955-aade-236beb146efa", "f659e321-e6f5-4964-ab12-49220ed2332f"], "algorithm": "# Description: Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restart mechanism and active population size adaptation for enhanced global exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(self.dim))\n        self.sigma0 = sigma0\n        self.mean = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n        self.restart_trigger = restart_trigger\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize()\n\n    def initialize(self):\n        self.mean = np.random.uniform(-1, 1, self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n    def __call__(self, func):\n        self.initialize()\n        c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        c_mu = min(1 - c_1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n\n        B = None\n        D = None\n        eigen_updated = 0\n\n        while self.budget > 0:\n            if eigen_updated > self.pop_size // 2:\n                eigen_updated = 0\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                D, B = np.linalg.eigh(self.C)\n                D = np.sqrt(D)\n                if np.min(D) < self.restart_trigger or np.max(D) > 1/self.restart_trigger:\n                   self.initialize()\n                   continue\n\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = B @ (D[:, None] * z.T)\n            x = self.mean + self.sigma * y.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            x_sorted = x[idx]\n\n            y_mean = np.sum(self.weights[:, None] * (x_sorted[:self.mu] - self.mean), axis=0)\n\n            self.ps = (1 - c_sigma) * self.ps + np.sqrt(c_sigma * (2 - c_sigma) * self.mueff) * (B @ y[:, :self.mu] @ self.weights)\n            self.pc = (1 - c_c) * self.pc + np.sqrt(c_c * (2 - c_c) * self.mueff) * y_mean / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - c_sigma)**(self.budget / self.pop_size)) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.C = (1 - c_1 - c_mu) * self.C + c_1 * (self.pc[:, None] @ self.pc[None, :]) + c_mu * (B @ (y[:, :self.mu] * self.weights) @ (y[:, :self.mu] @ self.weights).T @ B.T)\n\n            self.sigma *= np.exp((c_sigma / damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean = x_sorted[0]\n            eigen_updated += 1\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d3a1a184-dae5-4816-b10c-36619c7ee303", "parents": ["f659e321-e6f5-4964-ab12-49220ed2332f", "920d89ad-fe5d-4955-aade-236beb146efa"], "algorithm": "# Description: Implement a Population-Based Iterated Local Search, which evolves a population of solutions and iteratively refines them using a local search operator, periodically re-initializing poorly performing individuals to enhance exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass PopulationIteratedLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=10, reinit_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.reinit_threshold = reinit_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # Local Search\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                for _ in range(min(self.local_search_iterations, self.budget)):\n                    if self.budget <= 0:\n                        break\n                    perturbation = np.random.normal(0, 0.05, size=self.dim)\n                    x_local = np.clip(self.pop[i] + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < self.fitness[i]:\n                        self.pop[i] = x_local\n                        self.fitness[i] = f_local\n\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n\n            # Re-initialization\n            fitness_threshold = np.mean(self.fitness) + self.reinit_threshold * np.std(self.fitness)\n            for i in range(self.pop_size):\n                if self.fitness[i] > fitness_threshold:\n                    self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.pop[i])\n                    self.budget -= 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "8819dcf5-33ad-4040-9927-7206770eb74b", "parents": ["245f5e7e-f956-489f-a796-04f56dc9205d"], "algorithm": "# Description: This algorithm uses a self-adaptive Differential Evolution with a Cauchy mutation operator and an archive to improve exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolutionCauchyArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_fitness = []\n        self.cr = 0.5\n        self.f = 0.5\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = self.population[np.random.choice(idxs, 2, replace=False)]\n                mutant = self.population[i] + self.f * (a - b) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    #Update CR and F\n                    self.cr = 0.9 * self.cr + 0.1 * np.random.rand()\n                    self.f = 0.9 * self.f + 0.1 * np.random.rand()\n\n                    # Add to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        # Replace random element in archive\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.population[i].copy()\n                elif len(self.archive) > 0:\n                    # Mutation using archive\n                    arch_idx = np.random.randint(0, len(self.archive))\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a = self.population[np.random.choice(idxs, 1, replace=False)][0]\n                    mutant = self.population[i] + self.f * (self.archive[arch_idx] - a) * np.random.standard_cauchy(size=self.dim)\n                    mutant = np.clip(mutant, self.lb, self.ub)\n                    \n                    # Crossover\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, self.population[i])\n                    \n                    f = func(trial)\n                    evals += 1\n\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial\n                        #Update CR and F\n                        self.cr = 0.9 * self.cr + 0.1 * np.random.rand()\n                        self.f = 0.9 * self.f + 0.1 * np.random.rand()\n\n                        # Add to archive\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(self.population[i].copy())\n                        else:\n                            # Replace random element in archive\n                            idx_to_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_to_replace] = self.population[i].copy()\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.07302, "other_inf": null}
{"id": "1653f210-5371-4e62-9cdd-2a9d5de231bd", "parents": ["8c0a8d80-ea72-41ad-b9aa-701c19391b29"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy with a decaying learning rate and boundary handling.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.learning_rate = 1.0\n\n    def initialize(self):\n        self.m = np.random.uniform(-1, 1, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_sigma\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.pop_size + 3) / (5 * self.dim**0.5)\n        self.d_sigma = 1 + 2 * max(0, ((np.sum(self.weights) * self.chiN / self.sigma) - 1)) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.learning_rate = 1.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nevals = 0\n        self.initialize()\n\n        while self.nevals < self.budget:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = np.dot(z, np.linalg.cholesky(self.C).T)\n            x = self.m + self.sigma * y\n            \n            # Boundary Handling (clipping)\n            for i in range(self.pop_size):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            self.nevals += self.pop_size\n            \n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path for C\n            y_mean = np.mean(y[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + (self.c_sigma * (2 - self.c_sigma))**0.5 * (np.linalg.inv(np.linalg.cholesky(self.C)) @ y_mean)\n            self.pc = (1 - self.c_c) * self.pc + (self.c_c * (2 - self.c_c))**0.5 * y_mean\n\n            # Update covariance matrix C\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            self.C += self.c_mu * np.sum(self.weights[:, None, None] * (y[:self.mu, :, None] @ y[:self.mu, None, :]), axis=0)\n\n            # Update step size sigma\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = max(self.sigma, 1e-10)  # Prevent sigma from becoming too small\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            self.learning_rate *= 0.995 # Decaying learning rate\n\n            self.c_sigma *= self.learning_rate\n            self.c_c *= self.learning_rate\n            self.c_1 *= self.learning_rate\n            self.c_mu *= self.learning_rate\n\n\n        return self.f_opt, self.x_opt", "objective": -0.38953, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "f8166c6f-0bf6-4540-b602-a82177c23723", "parents": [], "algorithm": "A population-based algorithm that combines particle swarm optimization (PSO) with a differential evolution (DE) mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f  # Mutation factor\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            global_best_position = self.x_opt \n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n\n            population = population + velocities\n            population = np.clip(population, self.lb, self.ub)\n            \n            # DE mutation\n            for i in range(self.pop_size):\n                # Select three random individuals (excluding the current one)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    \n                x_r1, x_r2, x_r3 = population[indices]\n                \n                # Mutation\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                v_mutation = np.clip(v_mutation, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.random.rand(self.dim)\n                mask = (u <= self.cr) | (np.arange(self.dim) == j_rand)\n                u_crossover = np.where(mask, v_mutation, population[i])\n                \n                # Evaluation\n                f_trial = func(u_crossover)\n                eval_count += 1\n                \n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = u_crossover\n                    fitness[i] = f_trial\n                    \n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_positions[i] = u_crossover\n                        personal_best_fitness[i] = f_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = u_crossover.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.61545, "other_inf": null}
{"id": "3d5061dc-26d8-4ea1-ae93-533315476070", "parents": [], "algorithm": "Adaptive Differential Evolution with population restart and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n\n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx]\n\n    def mutate(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n            mutant = a + self.F * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n            yield mutant\n\n    def crossover(self, mutant, i):\n        trial = np.copy(self.population[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == np.random.randint(self.dim):\n                trial[j] = mutant[j]\n        return trial\n    \n    def local_search(self, x, func):\n        # Simple local search around x\n        delta = np.random.uniform(-0.1, 0.1, size=self.dim)\n        x_new = np.clip(x + delta, self.lb, self.ub)\n        f_new = func(x_new)\n        self.evals += 1\n        if f_new < func(x):\n            return x_new, f_new\n        else:\n            return x, func(x)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        \n        self.initialize_population(func)\n        \n        generation = 0\n        stagnation_counter = 0\n        last_improvement = 0\n\n        while self.evals < self.budget:\n            \n            new_population = []\n            new_fitness = []\n            \n            for i, mutant in enumerate(self.mutate()):\n                trial = self.crossover(mutant, i)\n                \n                f_trial = func(trial)\n                self.evals += 1\n                \n                if np.random.rand() < self.local_search_prob:\n                  trial, f_trial = self.local_search(trial, func)\n                \n                if f_trial < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f_trial)\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n                    \n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n                    last_improvement = generation\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n\n            generation += 1\n            \n            if generation - last_improvement > 50:\n              stagnation_counter +=1\n            else:\n              stagnation_counter = 0\n\n            if stagnation_counter > 2:\n                self.initialize_population(func)  # Restart population\n                stagnation_counter = 0\n                last_improvement = generation\n        \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "bee4c29f-a580-4dd0-a569-dca209aa3459", "parents": [], "algorithm": "Adaptive Differential Evolution with archive and parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.archive = []\n        self.success_F = []\n        self.success_CR = []\n        self.success_fitness_diff = []\n        self.mu_F = 0.5\n        self.mu_CR = 0.9\n        self.func_evals = self.pop_size\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                if indices[0] < self.pop_size:\n                    a = self.pop[indices[0]]\n                else:\n                    a = self.archive[indices[0] - self.pop_size]\n                if indices[1] < self.pop_size:\n                    b = self.pop[indices[1]]\n                else:\n                    b = self.archive[indices[1] - self.pop_size]\n                if indices[2] < self.pop_size:\n                    c = self.pop[indices[2]]\n                else:\n                    c = self.archive[indices[2] - self.pop_size]\n\n                mutant = self.pop[i] + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.archive.append(self.pop[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    self.success_fitness_diff.append(abs(f - self.fitness[i]))\n\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Parameter Adaptation\n            if self.success_F:\n                self.mu_F = sum(f**2 for f in self.success_F) / sum(self.success_F)\n                self.mu_CR = np.mean(self.success_CR)\n\n            self.F = np.clip(np.random.normal(self.mu_F, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(self.mu_CR, 0.1), 0.1, 1.0)\n            \n            self.success_F = []\n            self.success_CR = []\n            self.success_fitness_diff = []\n\n        return self.f_opt, self.x_opt", "objective": -0.51664, "other_inf": null}
{"id": "1312025f-4e89-45ae-8ebc-048c0986dc3b", "parents": [], "algorithm": "This algorithm combines a simplified covariance matrix adaptation evolution strategy (CMA-ES) with a local search component based on gradient estimation to efficiently explore the search space and refine promising solutions.", "code": "import numpy as np\n\nclass GradientCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, step_size=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.step_size = step_size\n        self.local_search_iterations = local_search_iterations\n\n        self.mean = None\n        self.C = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        \n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.step_size * z\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Update best solution\n            best_idx = np.argmin(f)\n            if f[best_idx] < self.f_opt:\n                self.f_opt = f[best_idx]\n                self.x_opt = x[best_idx]\n\n            # Update mean\n            weights = np.exp(-self.pop_size * f / np.sum(f))\n            weights /= np.sum(weights) # Normalize\n\n            self.mean = np.sum(x * weights[:, None], axis=0)\n            \n            # Update covariance matrix (simplified)\n            self.C = np.cov(x.T) #Covariance matrix of the population\n        \n            # Local search around the best solution\n            if self.x_opt is not None:\n                x_local = self.x_opt.copy()\n                for _ in range(self.local_search_iterations):\n                    # Estimate gradient using finite differences\n                    gradient = np.zeros(self.dim)\n                    delta = 1e-3  # Small perturbation\n                    for i in range(self.dim):\n                        x_plus = x_local.copy()\n                        x_minus = x_local.copy()\n                        x_plus[i] += delta\n                        x_minus[i] -= delta\n\n                        x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                        x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        \n                        self.eval_count += 2 #Accounting for function evaluations for gradient estimation\n                        \n                        gradient[i] = (f_plus - f_minus) / (2 * delta)\n                    \n                    # Update position based on gradient\n                    x_local -= 0.01 * gradient  # Small step along the negative gradient\n                    x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                    \n                    f_local = func(x_local)\n                    self.eval_count += 1\n                    \n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local.copy()\n                        \n                    if self.eval_count >= self.budget:\n                        break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "67e9860f-a18f-4c92-b7bc-235606125ec9", "parents": [], "algorithm": "Adaptive Differential Evolution with a dynamically adjusted population size and mutation/crossover rates based on recent search success.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.7, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 10 * dim # Default population size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.history_length = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Store history of fitness improvements to adjust F and CR\n        fitness_history = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Dynamic Adjustment of F and CR (example: based on success history)\n            fitness_history.append(np.min(fitness))\n            if len(fitness_history) > self.history_length:\n                fitness_history.pop(0)\n                \n                # Example: Decrease F if little improvement\n                if fitness_history[-1] >= fitness_history[0]:\n                    self.F = max(0.1, self.F * 0.9)\n                else:\n                    self.F = min(0.9, self.F * 1.1)\n\n                # Example: Increase CR if improvement\n                if fitness_history[-1] < fitness_history[0]:\n                    self.CR = min(0.99, self.CR * 1.1)\n                else:\n                    self.CR = max(0.1, self.CR * 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.48626, "other_inf": null}
{"id": "53032444-626f-404a-972f-2b306d62ec71", "parents": [], "algorithm": "This algorithm uses a population-based approach with differential evolution operators for exploration and exploitation, combined with a local search strategy around the best individual to refine the solution.", "code": "import numpy as np\n\nclass DifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, CR=0.9, local_search_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_iters = local_search_iters\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial individual\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            #Local Search around current best solution\n            for _ in range(min(self.local_search_iters, self.budget)):\n                step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n                x_neighbor = np.clip(self.x_opt + np.random.normal(0, step_size, self.dim), func.bounds.lb, func.bounds.ub)\n                f_neighbor = func(x_neighbor)\n                self.budget -= 1\n\n                if f_neighbor < self.f_opt:\n                    self.f_opt = f_neighbor\n                    self.x_opt = x_neighbor\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "29bf8bad-d807-45ae-80ef-7bfdfffe7bda", "parents": [], "algorithm": "Simulated Annealing with adaptive temperature schedule and restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        eval_count = 1\n\n        while eval_count < self.budget:\n            x_new = x + np.random.normal(0, temp, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_prob = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_prob:\n                    x = x_new\n                    f = f_new\n\n            temp *= self.cooling_rate\n\n            if np.random.rand() < self.restart_prob:\n                 x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                 f = func(x)\n                 eval_count +=1\n                 if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n        return self.f_opt, self.x_opt", "objective": -0.16092, "other_inf": null}
{"id": "7ff69140-92e2-464a-ba39-271994cb1b1b", "parents": [], "algorithm": "An adaptive Differential Evolution algorithm that adjusts its parameters based on the success rate of generating better solutions and includes a local search operator for exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        # Find best initial solution\n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.f_opt:\n            self.f_opt = fitness[best_idx]\n            self.x_opt = self.population[best_idx]\n\n        success_count = 0\n        eval_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Clip to bounds\n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    x_trial += np.random.uniform(-step_size, step_size, size=self.dim)\n                    x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                eval_count += 1\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    success_count += 1\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Adaptive parameter control\n            if success_count > 0:\n                success_rate = success_count / self.pop_size\n                self.F = np.clip(self.F * (1 + 0.2 * (success_rate - 0.5)), 0.1, 1.0)\n                self.CR = np.clip(self.CR * (1 + 0.2 * (success_rate - 0.5)), 0.1, 0.9)\n            success_count = 0 # Reset success_count\n\n        return self.f_opt, self.x_opt", "objective": -0.43218, "other_inf": null}
{"id": "0819bca8-6e67-4c9a-90e5-e6f2f1b61f89", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459", "67e9860f-a18f-4c92-b7bc-235606125ec9"], "algorithm": "A swarm-based approach where particles adjust their positions based on their own best found solution and the best solution found by any particle in their neighborhood, with velocity clamping and dynamic neighborhood size adaptation.", "code": "import numpy as np\n\nclass NeighborhoodParticleSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, neighborhood_size=5, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.neighborhood_size = neighborhood_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.swarm_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitnesses = np.array([func(x) for x in particles])\n        self.budget -= self.swarm_size\n\n        # Initialize global best\n        best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[best_index].copy()\n        self.f_opt = personal_best_fitnesses[best_index]\n        self.x_opt = global_best_position.copy()\n        \n\n        while self.budget > 0:\n            for i in range(self.swarm_size):\n                # Determine neighborhood\n                neighborhood_indices = list(range(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1)))\n\n                # Find best particle in neighborhood\n                neighborhood_best_index = neighborhood_indices[np.argmin(personal_best_fitnesses[neighborhood_indices])]\n                neighborhood_best_position = personal_best_positions[neighborhood_best_index]\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i]\n                                 + self.cognitive_coeff * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.social_coeff * r2 * (neighborhood_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                new_position = particles[i] + velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n                \n                particles[i] = new_position\n\n            # Adapt neighborhood size (example: shrink if no improvement)\n            if np.min(personal_best_fitnesses) >= self.f_opt:\n                self.neighborhood_size = max(1, self.neighborhood_size - 1)\n            else:\n                self.neighborhood_size = min(self.swarm_size, self.neighborhood_size + 1)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "39c66dcf-34df-44e4-b41e-027714638e92", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "7ff69140-92e2-464a-ba39-271994cb1b1b"], "algorithm": "A gradient-free optimization algorithm that iteratively refines a single solution using a combination of random perturbations and adaptive step size control based on past success.", "code": "import numpy as np\n\nclass AdaptiveStepSizeRandomSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.4, step_size_multiplier=1.2, step_size_divisor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.step_size_multiplier = step_size_multiplier\n        self.step_size_divisor = step_size_divisor\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x.copy()\n        step_size = self.initial_step_size\n        successes = 0\n        iterations = 0\n        eval_count = 1\n\n        while eval_count < self.budget:\n            iterations += 1\n            x_new = x + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                x = x_new.copy()\n                successes += 1\n\n            if iterations % 10 == 0:\n                success_rate = successes / 10\n                if success_rate > self.success_rate_threshold:\n                    step_size *= self.step_size_multiplier\n                else:\n                    step_size /= self.step_size_divisor\n                successes = 0\n                step_size = min(max(step_size, 1e-6), (self.ub - self.lb)/2)\n\n        return self.f_opt, self.x_opt", "objective": -0.12076, "other_inf": null}
{"id": "bf672ada-2169-42ec-b661-0edd232a5b92", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459", "67e9860f-a18f-4c92-b7bc-235606125ec9"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware adaptation of the covariance matrix and step size.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mean = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n        self.ccov1 = (1 / self.mueff) * min(1, (self.mueff + 2) / (self.dim + self.mueff + 5))\n        self.ccovmu = min(1 - self.ccov1, (2 * (self.mueff - 2 + 1/self.mueff)) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.B = None\n        self.D = None\n        self.C_updated = 0\n        \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        while self.budget > 0:\n            # Sample population\n            if self.C_updated == 0:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D)\n                self.C_updated = 1\n            \n            z = np.random.normal(0, 1, size=(self.dim, self.pop_size))\n            y = self.B @ np.diag(self.D) @ z\n            x = self.mean[:, np.newaxis] + self.sigma * y\n            x = np.clip(x, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n            \n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n            \n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n            \n            # Update CMA-ES parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            y_mean = xmean - self.mean\n            y_mean = y_mean / self.sigma\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ z[:, :self.mu] @ self.weights)\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            hsig = norm_ps / np.sqrt(1 - (1 - self.cs)**2 * self.budget / self.budget) < (1.4 + 2 / (self.dim + 1)) * self.chiN\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mueff) * y_mean\n            \n            artmp = (x[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (self.ccovmu/self.ccov1) * hsig**2) * self.C + self.ccov1 * self.pc[:, np.newaxis] @ self.pc[np.newaxis, :] + self.ccovmu * artmp @ np.diag(self.weights) @ artmp.T\n            \n            self.mean = xmean\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = self.C / np.linalg.norm(self.C)\n            self.C_updated = 0\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "1addf0bb-9535-442b-bc11-66743f1918bd", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "Simulated Annealing with adaptive step size control based on acceptance rate.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=100.0, alpha=0.99, step_init=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.step_size = step_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.acceptance_rate = 0.0\n        self.acceptance_count = 0\n        self.iteration = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x.copy()\n        eval_count = 1\n\n        while eval_count < self.budget:\n            self.iteration += 1\n            x_new = x + np.random.normal(0, self.step_size, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new.copy()\n                self.f_opt = f_new\n                if f_new < self.f_opt:\n                    self.x_opt = x_new.copy()\n                self.acceptance_count += 1\n\n            # Temperature update\n            self.temp *= self.alpha\n\n            # Step size adaptation\n            if self.iteration % 100 == 0:\n                self.acceptance_rate = self.acceptance_count / 100\n                self.acceptance_count = 0\n\n                if self.acceptance_rate > 0.6:\n                    self.step_size *= 1.2\n                elif self.acceptance_rate < 0.4:\n                    self.step_size *= 0.8\n                self.step_size = np.clip(self.step_size, 0.01, 2.0)\n\n        return self.f_opt, self.x_opt", "objective": -0.49814, "other_inf": null}
{"id": "f7e94b3e-82e3-4700-9c43-309fa3c8ae97", "parents": ["67e9860f-a18f-4c92-b7bc-235606125ec9", "bee4c29f-a580-4dd0-a569-dca209aa3459"], "algorithm": "Initialize a harmony memory with random solutions, then iteratively improvise new harmonies by considering memory, pitch adjustment, and randomization, accepting better harmonies and updating parameters dynamically.", "code": "import numpy as np\n\nclass HarmonySearch:\n    def __init__(self, budget=10000, dim=10, HMS=10, HMCR=0.9, PAR=0.3, BW=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.HMS = HMS  # Harmony Memory Size\n        self.HMCR = HMCR # Harmony Memory Consideration Rate\n        self.PAR = PAR   # Pitch Adjusting Rate\n        self.BW = BW     # Bandwidth\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # {Initialize a harmony memory with random solutions, then iteratively improvise new harmonies by considering memory, pitch adjustment, and randomization, accepting better harmonies and updating parameters dynamically.}\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize Harmony Memory\n        HM = np.random.uniform(self.lb, self.ub, size=(self.HMS, self.dim))\n        HM_fitness = np.array([func(x) for x in HM])\n        self.budget -= self.HMS\n        \n        # Find the best harmony in the initial HM\n        best_index = np.argmin(HM_fitness)\n        if HM_fitness[best_index] < self.f_opt:\n            self.f_opt = HM_fitness[best_index]\n            self.x_opt = HM[best_index]\n\n        while self.budget > 0:\n            # Improvise a new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.HMCR:\n                    # Memory Consideration\n                    new_harmony[i] = HM[np.random.randint(0, self.HMS), i]\n                    # Pitch Adjustment\n                    if np.random.rand() < self.PAR:\n                        new_harmony[i] += np.random.uniform(-self.BW, self.BW)\n                        new_harmony[i] = np.clip(new_harmony[i], self.lb, self.ub)\n                else:\n                    # Random Selection\n                    new_harmony[i] = np.random.uniform(self.lb, self.ub)\n            \n            # Evaluate the new harmony\n            new_fitness = func(new_harmony)\n            self.budget -= 1\n            \n            # Replace the worst harmony in HM if the new harmony is better\n            worst_index = np.argmax(HM_fitness)\n            if new_fitness < HM_fitness[worst_index]:\n                HM[worst_index] = new_harmony\n                HM_fitness[worst_index] = new_fitness\n                \n                # Update the best harmony found so far\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_harmony\n\n            # Adaptive bandwidth adjustment\n            if np.random.rand() < 0.1: # Adjust BW with 10% probability\n                self.BW *= np.random.uniform(0.9, 1.1) # Reduce or increase BW by 10%\n                self.BW = np.clip(self.BW, 0.0001, 0.1)  # Keep BW within reasonable bounds\n        \n        return self.f_opt, self.x_opt", "objective": -0.41572, "other_inf": null}
{"id": "981304a8-96e0-4118-a1ab-96b026d58b93", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459", "1addf0bb-9535-442b-bc11-66743f1918bd"], "algorithm": "Evolve a population of solutions using a combination of differential evolution mutation, a local search, and a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_prob=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_prob = local_search_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n        self.stagnation_counter = 0\n\n        while self.func_evals < self.budget:\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index].copy()\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.func_evals += self.pop_size\n                self.stagnation_counter = 0\n                continue\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = self.pop[i] + 0.5 * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < 0.9\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.58357, "other_inf": null}
{"id": "3f141e78-5f51-4dae-b0f6-e1d7c56f4cf4", "parents": ["67e9860f-a18f-4c92-b7bc-235606125ec9", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "# Description: Evolutionary algorithm that uses a combination of global and local search strategies, switching dynamically based on the observed fitness landscape characteristics.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_ratio=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_ratio = local_ratio\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def global_search(self, func):\n        # Implement a simple DE mutation strategy for global exploration\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + 0.7 * (b - c), self.lb, self.ub)\n\n            f_mutant = func(mutant)\n            self.budget -= 1\n            if f_mutant < self.fitness[i]:\n                self.population[i] = mutant\n                self.fitness[i] = f_mutant\n                if f_mutant < self.f_opt:\n                    self.f_opt = f_mutant\n                    self.x_opt = mutant.copy()\n        return\n\n    def local_search(self, func):\n        # Implement a simple gradient-based local search\n        step_size = 0.1\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n            x = self.population[i].copy()\n            for j in range(self.dim):\n                delta = np.zeros(self.dim)\n                delta[j] = step_size\n                x_plus = np.clip(x + delta, self.lb, self.ub)\n                f_plus = func(x_plus)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_plus < self.fitness[i]:\n                    x = x_plus\n                    self.fitness[i] = f_plus\n                    self.population[i] = x\n                    if f_plus < self.f_opt:\n                        self.f_opt = f_plus\n                        self.x_opt = x.copy()\n                \n                delta[j] = -step_size\n                x_minus = np.clip(x + delta, self.lb, self.ub)\n                f_minus = func(x_minus)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break\n\n                if f_minus < self.fitness[i]:\n                    x = x_minus\n                    self.fitness[i] = f_minus\n                    self.population[i] = x\n                    if f_minus < self.f_opt:\n                        self.f_opt = f_minus\n                        self.x_opt = x.copy()\n                \n                if self.budget <= 0:\n                  break\n\n        return\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            if np.random.rand() < self.local_ratio:\n                self.local_search(func)\n            else:\n                self.global_search(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.49922, "other_inf": null}
{"id": "fa62da00-38c5-4f17-b825-38d40cbfcb83", "parents": ["1addf0bb-9535-442b-bc11-66743f1918bd", "bee4c29f-a580-4dd0-a569-dca209aa3459"], "algorithm": "Evolving a population of solutions using a combination of global exploration and local refinement, guided by a fitness-weighted probability distribution to sample new candidate solutions.", "code": "import numpy as np\n\nclass FitnessWeightedSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sample_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sample_size = sample_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            # Calculate fitness weights\n            fitness_min = np.min(self.fitness)\n            fitness_max = np.max(self.fitness)\n\n            if fitness_max == fitness_min:\n                weights = np.ones(self.pop_size) / self.pop_size\n            else:\n                # Scale fitness to be between 0 and 1, higher fitness gets higher weight\n                weights = (fitness_max - self.fitness) / (fitness_max - fitness_min)\n                weights = weights / np.sum(weights)  # Normalize to sum to 1\n\n            # Generate new solutions by sampling from the population\n            new_pop = []\n            for _ in range(self.pop_size):\n                # Sample indices based on fitness weights\n                indices = np.random.choice(self.pop_size, self.sample_size, replace=False, p=weights)\n                sample = self.pop[indices]\n                \n                # Create a new solution by averaging the sampled solutions and adding noise\n                new_x = np.mean(sample, axis=0) + np.random.normal(0, 0.5, self.dim)  # Adjust noise scale as needed\n                new_x = np.clip(new_x, self.lb, self.ub)\n                new_pop.append(new_x)\n\n            new_pop = np.array(new_pop)\n            new_fitness = np.array([func(x) for x in new_pop])\n            self.eval_count += self.pop_size\n\n            # Update the population\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.pop[i] = new_pop[i]\n                    self.fitness[i] = new_fitness[i]\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_pop[i]\n\n        return self.f_opt, self.x_opt", "objective": -0.37626, "other_inf": null}
{"id": "255e917b-8f6a-4d66-ba3f-ef5e22930f2c", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware population size and restarts.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, restart_factor=3):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(dim))\n        self.restart_factor = restart_factor\n        self.x_mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n        self.cc = None\n        self.cs = None\n        self.damps = None\n        self.ccov1 = None\n        self.ccovmu = None\n        self.pop_size = self.initial_pop_size\n        self.func_evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restarts = 0\n\n    def initialize(self, func):\n        self.x_mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = 0.3\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = (1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs)\n        self.ccov1 = 2 / ((self.dim+1.3)**2 + self.mueff)\n        self.ccovmu = 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2)**2 + self.mueff)\n        self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.func_evals < self.budget:\n            try:\n                z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n                B = None\n                D = None\n                C = self.C\n                eigen_decomposition = np.linalg.eigh(C)\n                D = np.diag(np.sqrt(eigen_decomposition[0]))\n                B = eigen_decomposition[1]\n                x = self.x_mean + self.sigma * np.dot(z, np.dot(B, D))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                f = np.array([func(xi) for xi in x])\n                self.func_evals += self.pop_size\n\n                if np.any(f < self.f_opt):\n                    best_index = np.argmin(f)\n                    if f[best_index] < self.f_opt:\n                        self.f_opt = f[best_index]\n                        self.x_opt = x[best_index]\n\n                idx = np.argsort(f)\n                x_best = x[idx[:self.mu]]\n                z_best = z[idx[:self.mu]]\n\n                x_mean_old = self.x_mean.copy()\n                self.x_mean = np.sum(x_best * self.weights[:, None], axis=0)\n\n                self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(B, z_best[0].T) #z_best weighted sum removed\n                hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*(self.budget/self.pop_size)))/self.chiN < 1.4 + 2/(self.dim+1))\n                self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc*(2-self.cc)*self.mueff) * (self.x_mean - x_mean_old) / self.sigma\n\n                self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.dot(z_best.T, np.dot(np.diag(self.weights), z_best))\n                self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            except np.linalg.LinAlgError:\n                self.restarts += 1\n                self.initialize(func)\n                self.pop_size = min(self.initial_pop_size * self.restart_factor, self.budget - self.func_evals)\n                if self.pop_size <= 0:\n                    break\n                self.mu = self.pop_size // 2\n                self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.damps = (1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs)\n                self.ccov1 = 2 / ((self.dim+1.3)**2 + self.mueff)\n                self.ccovmu = 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2)**2 + self.mueff)\n                self.ccovmu = min(1-self.ccov1, self.ccovmu)\n\n        return self.f_opt, self.x_opt", "objective": -0.27036, "other_inf": null}
{"id": "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "parents": ["3f141e78-5f51-4dae-b0f6-e1d7c56f4cf4"], "algorithm": "# Description: An adaptive Differential Evolution (DE) algorithm with a self-adjusting mutation factor and population size reduction.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_factor=0.5, crossover_rate=0.7, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.reduction_factor = reduction_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n\n            # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n\n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector.copy()\n\n        self.population = new_population\n        self.fitness = new_fitness\n        \n        # Population size reduction (optional)\n        if self.budget > 0 and len(self.population) > 10 and np.random.rand() < 0.1:\n            indices = np.argsort(self.fitness)[::-1] #sort from worst to best\n            remove_count = int(len(self.population) * (1 - self.reduction_factor))\n            indices_to_keep = indices[:-remove_count] #indices of the best solutions\n            \n            self.population = self.population[indices_to_keep]\n            self.fitness = self.fitness[indices_to_keep]\n            self.pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n            # Adapt mutation factor\n            if np.random.rand() < 0.2:\n                self.mutation_factor = np.random.uniform(0.3, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.67292, "other_inf": null}
{"id": "5c230311-33d3-4152-b491-b52954a88cb7", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "A self-adaptive differential evolution algorithm with a decaying population size and parameter adaptation based on successful search steps.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lb=-5.0, ub=5.0, shrink_factor = 0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f = 0.5\n        self.cr = 0.7\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        eval_count = self.pop_size\n\n        successful_mutations = 0\n\n        while eval_count < self.budget and self.pop_size > 2:\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                v_mutation = np.clip(v_mutation, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.random.rand(self.dim)\n                mask = (u <= self.cr) | (np.arange(self.dim) == j_rand)\n                u_crossover = np.where(mask, v_mutation, population[i])\n\n                # Evaluation\n                f_trial = func(u_crossover)\n                eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = u_crossover\n                    fitness[i] = f_trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = u_crossover.copy()\n\n                if eval_count >= self.budget:\n                    break\n\n            # Parameter Adaptation\n            if successful_mutations / self.pop_size < 0.1:\n                self.f *= 1.1\n            elif successful_mutations / self.pop_size > 0.9:\n                self.f *= 0.9\n            self.f = np.clip(self.f, 0.1, 1.0)\n            \n            successful_mutations = 0 # Reset counter\n\n            # Population size reduction\n            if eval_count > self.budget * 0.7:\n                 self.pop_size = int(self.pop_size * self.shrink_factor)\n                 if self.pop_size < 2:\n                     self.pop_size = 2\n\n                 population = population[:self.pop_size]\n                 fitness = fitness[:self.pop_size]\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c2480d24-fe4a-44b9-ab87-2473ad632c00", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459"], "algorithm": "'bounds': [func.bounds.lb, func.bounds.ub],\n                               'popsize': self.pop_size", "code": "import numpy as np\nimport cma\n\nclass CMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10, cmaes_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.cmaes_sigma = cmaes_sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n        # Initialize CMA-ES\n        es = cma.purecma.CMAES(np.zeros(self.dim), self.cmaes_sigma,\n                              {'bounds': [func.bounds.lb, func.bounds.ub],\n                               'popsize': self.pop_size})\n\n        while self.func_evals < self.budget and not es.stop():\n            # Ask CMA-ES for new points\n            solutions = es.ask()\n            \n            # Evaluate solutions from CMA-ES\n            fitness = np.array([func(x) for x in solutions])\n            self.func_evals += self.pop_size\n            \n            # Update CMA-ES\n            es.tell(solutions, fitness)\n\n            # Differential Evolution refinement\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = solutions[indices]\n                mutant = solutions[i] + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, solutions[i])\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < fitness[i]:\n                    solutions[i] = trial\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = solutions[best_index]\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "795c5c75-cd94-4f45-90d8-759517521a07", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "An adaptive Differential Evolution (DE) algorithm that adjusts its parameters (crossover rate and mutation factor) based on the success rate of previous generations.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr_init  # Initial crossover rate\n        self.f = f_init  # Initial mutation factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cr_memory = []\n        self.f_memory = []\n        self.memory_size = 10\n        self.success_rate = 0.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            success_count = 0\n\n            for i in range(self.pop_size):\n                # Select three random individuals (excluding the current one)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Mutation\n                v_mutation = x_r1 + self.f * (x_r2 - x_r3)\n                v_mutation = np.clip(v_mutation, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.random.rand(self.dim)\n                mask = (u <= self.cr) | (np.arange(self.dim) == j_rand)\n                u_crossover = np.where(mask, v_mutation, population[i])\n\n                # Evaluation\n                f_trial = func(u_crossover)\n                eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    new_population[i] = u_crossover\n                    new_fitness[i] = f_trial\n                    success_count += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = u_crossover.copy()\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adaptive parameter control\n            self.success_rate = success_count / self.pop_size\n            self.cr = np.clip(self.cr + 0.1 * (self.success_rate - 0.5), 0.1, 0.9) # Adjust CR\n            self.f = np.clip(self.f + 0.1 * (self.success_rate - 0.5), 0.3, 1.0)   # Adjust F\n\n\n        return self.f_opt, self.x_opt", "objective": -0.59923, "other_inf": null}
{"id": "83a31c78-a395-4a1b-a0c6-a99061163c0f", "parents": ["981304a8-96e0-4118-a1ab-96b026d58b93"], "algorithm": "Adaptively adjusts mutation strength and crossover probability in differential evolution based on the success rate of previous generations, incorporating a restart strategy and a small population size to promote diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n\n        while self.func_evals < self.budget:\n            \n            if np.random.rand() < self.restart_prob:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.func_evals += self.pop_size\n                continue\n            \n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = self.pop[i] + self.mutation_factor * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.success_history.append(1)\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Adaptive Parameter Control\n            if len(self.success_history) > self.pop_size:\n                success_rate = np.mean(self.success_history[-self.pop_size:])\n                self.mutation_factor = np.clip(self.mutation_factor + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n                self.crossover_prob = np.clip(self.crossover_prob + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "1c0ef5ad-8a8d-41ca-b97c-556e3b500af0", "parents": ["bee4c29f-a580-4dd0-a569-dca209aa3459"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step size adaptation.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.sigma = initial_step_size\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1 / self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        while self.func_evals < self.budget:\n            z = np.random.randn(self.dim)\n            try:\n                A = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                A = np.eye(self.dim)\n                self.C = np.eye(self.dim)\n\n            x = self.m + self.sigma * A @ z\n\n            x = np.clip(x, self.lb, self.ub)\n            f = func(x)\n            self.func_evals += 1\n            \n            X = np.zeros((self.pop_size, self.dim))\n            F = np.zeros(self.pop_size)\n\n            for k in range(self.pop_size):\n                z = np.random.randn(self.dim)\n                x = self.m + self.sigma * A @ z\n                x = np.clip(x, self.lb, self.ub)\n                X[k, :] = x\n                F[k] = func(x)\n                self.func_evals += 1\n                if self.func_evals >= self.budget:\n                    break\n                    \n            if self.func_evals >= self.budget:\n                break\n            \n            idx = np.argsort(F)\n            X = X[idx]\n            F = F[idx]\n\n            if F[0] < self.f_opt:\n                self.f_opt = F[0]\n                self.x_opt = X[0]\n            \n            xmean = np.sum(self.weights[:, None] * X[:self.mu], axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (A @ ((xmean - self.m) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((xmean - self.m) / self.sigma) * (np.linalg.norm(self.ps) < (1.4 + 2 / (self.dim + 1)) * self.chiN)\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n            \n            for k in range(self.mu):\n                y = (X[k] - self.m) / self.sigma\n                self.C += self.c_mu * self.weights[k] * np.outer(y, y)\n\n            self.m = xmean\n            \n            # Budget-aware step size adaptation\n            fraction_spent = self.func_evals / self.budget\n            target_sigma = 1.0  # Example target, can be adjusted\n            self.sigma *= np.exp(self.c_sigma / self.d_sigma * ((np.linalg.norm(self.ps) / self.chiN) - 1))\n            self.sigma = min(self.sigma, (1 - fraction_spent) * 2.0) # Reduce step size as budget is used\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "e2d52fa1-d186-40aa-9298-cdf85fb93d27", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "An adaptive Differential Evolution (DE) algorithm with a self-adjusting population size, mutation factor, and crossover rate, guided by a success-history based adaptation (SHADE) mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE_SHADE:\n    def __init__(self, budget=10000, dim=10, pop_size=100, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.memory_cr = np.full(self.memory_size, 0.5)\n        self.memory_f = np.full(self.memory_size, 0.5)\n        self.archive = []\n        self.p = 0.1  # Percentile value for selecting p-best solutions\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        success_cr = []\n        success_f = []\n        \n        ranked_indices = np.argsort(self.fitness)\n        p_best_count = max(1, int(self.p * self.pop_size))\n        p_best_indices = ranked_indices[:p_best_count]\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n            \n            # Select memory index\n            memory_index = np.random.randint(self.memory_size)\n            \n            # Sample CR and F\n            cr = np.random.normal(self.memory_cr[memory_index], 0.1)\n            cr = np.clip(cr, 0, 1)\n            \n            f = np.random.normal(self.memory_f[memory_index], 0.1)\n            while f <= 0:\n                f = np.random.normal(self.memory_f[memory_index], 0.1)\n            f = np.clip(f, 0.00001, 1.0)\n\n            # Selection of p-best individual\n            p_best_idx = np.random.choice(p_best_indices)\n            \n            # Selection of random individuals\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            r1_idx = np.random.choice(idxs)\n            \n            archive_size = len(self.archive)\n            if archive_size > 0:\n                r2_idx = np.random.randint(archive_size)\n                mutant = np.clip(self.population[i] + f * (self.population[p_best_idx] - self.population[i]) + f * (self.population[r1_idx] - self.archive[r2_idx]), self.lb, self.ub)\n            else:\n                 mutant = np.clip(self.population[i] + f * (self.population[p_best_idx] - self.population[i]) + f * (self.population[r1_idx] - self.population[np.random.choice(idxs)]), self.lb, self.ub)\n\n            # Crossover\n            cross_points = np.random.rand(self.dim) < cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector.copy()\n                success_cr.append(cr)\n                success_f.append(f)\n                self.archive.append(self.population[i].copy())\n                if len(self.archive) > self.pop_size:\n                    self.archive.pop(0)\n\n        self.population = new_population\n        self.fitness = new_fitness\n        \n        # Update memory\n        if success_cr:\n            self.memory_cr[memory_index] = np.mean(success_cr)\n        if success_f:\n            self.memory_f[memory_index] = np.mean(success_f)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "objective": -0.48995, "other_inf": null}
{"id": "f22c2aba-ecdf-4b76-b399-48d3be33963b", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "An algorithm that combines aspects of Simulated Annealing with a local search strategy based on gradient estimation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass GradientAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.001, step_size=0.1, num_neighbors=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.num_neighbors = num_neighbors\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def estimate_gradient(self, func, x, num_neighbors):\n        gradient = np.zeros(self.dim)\n        for _ in range(num_neighbors):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n            x_plus = np.clip(x + self.step_size * direction, self.lb, self.ub)\n            x_minus = np.clip(x - self.step_size * direction, self.lb, self.ub)\n\n            if self.budget >= 2:\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                self.budget -= 2\n                gradient += (f_plus - f_minus) * direction\n            else:\n                break #if budget runs out, return zero gradient\n            \n        return gradient\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x.copy()\n        self.budget -= 1\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            gradient = self.estimate_gradient(func, x, self.num_neighbors)\n            \n            if self.budget <= 0:\n                break\n\n            #move against gradient, with annealing\n            x_new = x - temperature * self.step_size * gradient\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_f = f_new - self.f_opt\n\n            if delta_f < 0:\n                x = x_new.copy()\n                self.f_opt = f_new\n                self.x_opt = x.copy()\n            else:\n                # Simulated annealing acceptance probability\n                acceptance_prob = np.exp(-delta_f / temperature)\n                if np.random.rand() < acceptance_prob:\n                    x = x_new.copy()\n\n            temperature *= (1 - self.cooling_rate)\n\n        return self.f_opt, self.x_opt", "objective": -0.18125, "other_inf": null}
{"id": "c8071553-755c-4995-83ba-05b416003220", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "An algorithm that iteratively refines a Gaussian distribution over the search space, sampling from it and updating the distribution parameters based on the best-performing samples.", "code": "import numpy as np\nfrom scipy.stats import truncnorm\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, selection_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.selection_threshold = selection_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.zeros(dim)\n        self.sigma = np.ones(dim) * 2  # Initial standard deviation\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample(self):\n        samples = np.zeros((self.pop_size, self.dim))\n        for i in range(self.dim):\n            lower = (self.lb - self.mean[i]) / self.sigma[i]\n            upper = (self.ub - self.mean[i]) / self.sigma[i]\n            samples[:, i] = truncnorm.rvs(lower, upper, loc=self.mean[i], scale=self.sigma[i], size=self.pop_size)\n        return samples\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            samples = self.sample()\n            fitness = np.array([func(x) for x in samples])\n            eval_count += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[np.argmin(fitness)].copy()\n\n            # Select top samples\n            threshold = np.quantile(fitness, self.selection_threshold)\n            selected_samples = samples[fitness <= threshold]\n\n            if len(selected_samples) > 0:\n                self.mean = np.mean(selected_samples, axis=0)\n                self.sigma = np.std(selected_samples, axis=0) + 1e-8 #avoid zero std\n            else:\n                # If no samples are selected, re-initialize the mean\n                self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n                self.sigma = np.ones(self.dim) * 2  # Reset standard deviation\n\n            # Ensure sigma stays within reasonable bounds\n            self.sigma = np.clip(self.sigma, 0.1, 5)\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9fc81fdc-0a69-4bb6-9941-cd8b90e2d5f9", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "A niching algorithm that maintains diversity by clustering solutions and focusing search within promising niches.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass NicheClearing:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_clusters=5, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_clusters = n_clusters\n        self.niche_radius = niche_radius\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Clustering\n            kmeans = KMeans(n_clusters=self.n_clusters, n_init=1, random_state=0)\n            clusters = kmeans.fit_predict(population)\n\n            # Niche Clearing\n            for i in range(self.n_clusters):\n                cluster_indices = np.where(clusters == i)[0]\n                if len(cluster_indices) > 0:\n                    # Find the best individual in the niche\n                    best_index = cluster_indices[np.argmin(fitness[cluster_indices])]\n                    best_individual = population[best_index]\n\n                    # Sample new solutions around the best individual in the niche\n                    for _ in range(len(cluster_indices)):\n                        if eval_count >= self.budget:\n                            break\n\n                        new_solution = best_individual + np.random.normal(0, self.niche_radius, self.dim)\n                        new_solution = np.clip(new_solution, self.lb, self.ub)\n                        new_fitness = func(new_solution)\n                        eval_count += 1\n\n                        # Replace a random member of the niche if the new solution is better\n                        replace_index = np.random.choice(cluster_indices)\n                        if new_fitness < fitness[replace_index]:\n                            population[replace_index] = new_solution\n                            fitness[replace_index] = new_fitness\n\n                            if new_fitness < self.f_opt:\n                                self.f_opt = new_fitness\n                                self.x_opt = new_solution.copy()\n            \n            #Global Search\n            if eval_count < self.budget and np.random.rand() < 0.1:\n                new_x = np.random.uniform(self.lb, self.ub, self.dim)\n                new_f = func(new_x)\n                eval_count+=1\n\n                worst_index = np.argmax(fitness)\n                if new_f < fitness[worst_index]:\n                    population[worst_index] = new_x\n                    fitness[worst_index] = new_f\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x.copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "21fabf82-6745-4232-a9cd-de05da7e63bb", "parents": ["795c5c75-cd94-4f45-90d8-759517521a07", "795c5c75-cd94-4f45-90d8-759517521a07"], "algorithm": "A Population-based algorithm with a probabilistic approach that samples new candidate solutions based on a combination of the best solution found so far, a weighted average of the population, and random exploration within the search space, adapting the weights over time based on success.", "code": "import numpy as np\n\nclass ProbabilisticSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=20, alpha=0.1, beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.alpha = alpha  # Weight for the best solution\n        self.beta = beta    # Weight for the population average\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        return self.pop_size\n\n    def __call__(self, func):\n        eval_count = 0\n        eval_count += self.initialize_population(func)\n        \n        while eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # Find the best solution\n                best_index = np.argmin(self.fitness)\n                x_best = self.population[best_index]\n\n                # Calculate the weighted average of the population\n                x_avg = np.mean(self.population, axis=0)\n\n                # Generate a random vector for exploration\n                x_rand = np.random.uniform(self.lb, self.ub, self.dim)\n\n                # Create a new candidate solution by combining the best solution, population average, and random exploration\n                new_x = (\n                    self.alpha * x_best\n                    + self.beta * x_avg\n                    + (1 - self.alpha - self.beta) * x_rand\n                )\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Evaluate the new solution\n                f_trial = func(new_x)\n                eval_count += 1\n\n                # Selection: replace the old solution if the new one is better\n                if f_trial < self.fitness[i]:\n                    new_population[i] = new_x\n                    new_fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = new_x.copy()\n                else:\n                    new_population[i] = self.population[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Adapt the weights (optional)\n            self.alpha = np.clip(self.alpha + 0.01 * np.random.randn(), 0.05, 0.2)\n            self.beta = np.clip(self.beta + 0.01 * np.random.randn(), 0.05, 0.2)\n\n        return self.f_opt, self.x_opt", "objective": -0.30017, "other_inf": null}
{"id": "a9f51718-469a-49b0-89cb-33b1b0272203", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "A gradient-free optimization algorithm that iteratively refines a population of solutions by sampling new points around the best-performing individuals, adapting the sampling variance based on the success rate of previous iterations.", "code": "import numpy as np\n\nclass AdaptiveVarianceSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_variance=1.0, success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_variance = initial_variance\n        self.success_rate_threshold = success_rate_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        variance = np.full(self.dim, self.initial_variance)\n        eval_count = self.pop_size\n        successes = 0\n        iterations = 0\n\n        while eval_count < self.budget:\n            iterations += 1\n            # Sample new points around the best individual\n            new_points = np.random.normal(loc=self.x_opt, scale=np.sqrt(variance), size=(self.pop_size, self.dim))\n            new_points = np.clip(new_points, self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_points])\n            eval_count += self.pop_size\n\n            # Update the best solution\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_points[i].copy()\n                    successes += 1\n\n            # Adapt the variance\n            success_rate = successes / iterations\n            if success_rate > self.success_rate_threshold:\n                variance *= 1.1  # Increase variance\n            else:\n                variance *= 0.9  # Decrease variance\n            \n            variance = np.clip(variance, 1e-6, (self.ub - self.lb)**2) # Ensure variance stays reasonable\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.50083, "other_inf": null}
{"id": "ccc8b55a-88e6-43fb-b756-c8671715b5fd", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "# Description: An algorithm that iteratively refines a population by stochastically sampling and averaging the best-performing individuals with adaptive step sizes based on fitness variance.\n# Code:\n```", "code": "import numpy as np\n\nclass StochasticAveraging:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, sample_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.sample_size = sample_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def refine_population(self, func):\n        new_population = np.zeros_like(self.population)\n        new_fitness = np.zeros_like(self.fitness)\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Sample best individuals\n            indices = np.argsort(self.fitness)[:self.sample_size]\n            best_samples = self.population[indices]\n\n            # Calculate average position\n            average_position = np.mean(best_samples, axis=0)\n\n            # Adaptive step size based on fitness variance\n            fitness_variance = np.var(self.fitness[indices])\n            adaptive_step_size = self.step_size / (1 + fitness_variance) # Lower variance means smaller step size.\n            \n            # Generate new solution\n            new_solution = average_position + adaptive_step_size * np.random.normal(0, 1, self.dim)\n            new_solution = np.clip(new_solution, self.lb, self.ub)\n\n            # Evaluate new solution\n            f_new = func(new_solution)\n            self.budget -= 1\n\n            # Acceptance criterion: Always accept.\n            new_population[i] = new_solution\n            new_fitness[i] = f_new\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_solution.copy()\n\n        self.population = new_population\n        self.fitness = new_fitness\n        \n        # Replace worst with best\n        worst_index = np.argmax(self.fitness)\n        best_index = np.argmin(self.fitness)\n        if self.fitness[worst_index] > self.fitness[best_index]:\n            self.population[worst_index] = self.population[best_index].copy()\n            self.fitness[worst_index] = self.fitness[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.refine_population(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.34603, "other_inf": null}
{"id": "7d4a3a32-5740-4984-a0dd-b7f7d9fa1de3", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: An Extremal Optimization algorithm that iteratively improves solutions by randomly selecting and optimizing poorly performing components.\n# Code:\n```", "code": "import numpy as np\n\nclass ExtremalOptimization:\n    def __init__(self, budget=10000, dim=10, tau=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.tau = tau\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x.copy()\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Evaluate each component of the solution\n            component_fitness = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_temp = x.copy()\n                x_temp[i] = np.random.uniform(self.lb, self.ub)\n                component_fitness[i] = func(x_temp)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count >= self.budget:\n                break\n            \n            # Rank components based on fitness\n            ranking = np.argsort(component_fitness)\n\n            # Select the worst component with probability based on rank\n            probabilities = (np.arange(1, self.dim + 1) / self.dim) ** self.tau\n            probabilities /= np.sum(probabilities)\n            \n            selected_component = np.random.choice(self.dim, p=probabilities)\n\n            # Optimize the selected component\n            x[selected_component] = np.random.uniform(self.lb, self.ub)\n            f = func(x)\n            eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.28584, "other_inf": null}
{"id": "2e6f206e-da09-49b3-8a31-9300d23485da", "parents": ["981304a8-96e0-4118-a1ab-96b026d58b93", "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: Evolve a population by selecting parents based on fitness rank and perturbing offspring towards the population centroid, with dynamic population sizing.\n# Code:\n```", "code": "import numpy as np\n\nclass RankCentroidDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, centroid_learning_rate=0.1, rank_selection_pressure=2.0, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.centroid_learning_rate = centroid_learning_rate\n        self.rank_selection_pressure = rank_selection_pressure\n        self.reduction_factor = reduction_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        # Rank-based selection probabilities\n        ranked_indices = np.argsort(self.fitness)\n        selection_probs = np.power(np.arange(1, self.pop_size + 1), -self.rank_selection_pressure)\n        selection_probs /= np.sum(selection_probs)\n\n        centroid = np.mean(self.population, axis=0)\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Parent selection\n            parent_indices = np.random.choice(self.pop_size, 2, replace=False, p=selection_probs)\n            parent1, parent2 = self.population[parent_indices]\n\n            # Offspring generation towards centroid\n            offspring = parent1 + 0.5 * (parent2 - parent1) + self.centroid_learning_rate * (centroid - parent1)\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            f_offspring = func(offspring)\n            self.budget -= 1\n\n            if f_offspring < self.fitness[i]:\n                new_population[i] = offspring\n                new_fitness[i] = f_offspring\n                if f_offspring < self.f_opt:\n                    self.f_opt = f_offspring\n                    self.x_opt = offspring.copy()\n\n        self.population = new_population\n        self.fitness = new_fitness\n\n        # Dynamic population size reduction\n        if self.budget > 0 and len(self.population) > 10 and np.random.rand() < 0.1:\n            indices = np.argsort(self.fitness)[::-1]\n            remove_count = int(len(self.population) * (1 - self.reduction_factor))\n            indices_to_keep = indices[:-remove_count]\n\n            self.population = self.population[indices_to_keep]\n            self.fitness = self.fitness[indices_to_keep]\n            self.pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.22075, "other_inf": null}
{"id": "f1359edd-738d-43ab-bbef-d2703ba9a6a9", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: An adaptive Differential Evolution algorithm with covariance matrix adaptation for better exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.sigma = initial_sigma\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for C\n        self.ps = np.zeros(dim) # Evolution path for sigma\n        self.damps = 1 + (dim / 2)\n        self.cs = (self.damps - 1) / (np.linalg.norm(self.ps)**2 + self.damps)\n        self.cc = (4 + (dim / 3)) / (dim + 4)\n        self.mu = self.pop_size // 2 # Number of parents\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + (1/(21 * dim**2)))\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        if self.budget <= 0:\n            return\n\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n        new_population = self.x_opt + self.sigma * z\n        new_population = np.clip(new_population, self.lb, self.ub)\n        new_fitness = np.array([func(x) for x in new_population])\n        self.budget -= self.pop_size\n\n        if self.budget <= 0:\n            return\n\n        indices = np.argsort(new_fitness)\n        best_individuals = new_population[indices[:self.mu]]\n        best_fitnesses = new_fitness[indices[:self.mu]]\n\n        # Update optimal solution\n        if np.min(best_fitnesses) < self.f_opt:\n            self.f_opt = np.min(best_fitnesses)\n            self.x_opt = best_individuals[np.argmin(best_fitnesses)].copy()\n        \n        # CMA-ES update\n        y = (best_individuals - self.x_opt) / self.sigma\n        self.ps = (1-self.cs) * self.ps + (self.cs**0.5) * (np.linalg.norm(self.ps)/self.chiN)**-1 * ((best_individuals[0] - self.x_opt) / self.sigma)\n        hsig = int(np.linalg.norm(self.ps)/((1-self.cs)**(self.budget/self.budget))) < (2+self.dim/3)**0.5\n        self.pc = (1-self.cc) * self.pc + hsig*(self.cc*(2-self.cc))**0.5 * np.sum(self.weights[:, None] * y, axis=0)\n        \n        C_temp = np.sum(self.weights[:,None,None] * y[:,:,None] * y[:, None,:], axis=0)\n\n        self.C = (1 - self.cc) * self.C + self.cc * C_temp + self.cc * self.pc[:,None] * self.pc[None,:]\n\n        self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n        \n        self.population = new_population\n        self.fitness = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > self.pop_size:\n            self.evolve(func)\n\n        # Final refinement (optional, if budget remains)\n        if self.budget > 0:\n            final_pop = np.random.uniform(self.lb, self.ub, size=(min(self.budget, self.pop_size), self.dim))\n            final_fitness = np.array([func(x) for x in final_pop])\n            self.budget -= len(final_pop)\n            if np.min(final_fitness) < self.f_opt:\n                self.f_opt = np.min(final_fitness)\n                self.x_opt = final_pop[np.argmin(final_fitness)].copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "3fb4d026-a3d6-4159-8bf6-92e964f26a0d", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: An enhanced Differential Evolution (DE) with a dynamically adjusted population size, a self-adapting mutation factor based on fitness improvement, and a local search component utilizing a shrinking neighborhood around the best solution.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_factor=0.5, crossover_rate=0.7, reduction_factor=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.reduction_factor = reduction_factor\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        improvements = 0\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n\n            # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n\n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = f_trial\n                improvements +=1\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector.copy()\n            elif np.random.rand() < self.local_search_prob:\n                # Local search around the best solution\n                scale = 0.1 * (self.ub - self.lb)\n                x_local = np.clip(self.x_opt + np.random.normal(0, scale, size=self.dim), self.lb, self.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n                    \n        if improvements > 0:\n             self.mutation_factor = min(0.9, self.mutation_factor * 1.1)\n        else:\n             self.mutation_factor = max(0.1, self.mutation_factor * 0.9)\n\n        self.population = new_population\n        self.fitness = new_fitness\n\n        # Population size reduction (optional)\n        if self.budget > 0 and len(self.population) > 10 and np.random.rand() < 0.1:\n            indices = np.argsort(self.fitness)[::-1] #sort from worst to best\n            remove_count = int(len(self.population) * (1 - self.reduction_factor))\n            indices_to_keep = indices[:-remove_count] #indices of the best solutions\n\n            self.population = self.population[indices_to_keep]\n            self.fitness = self.fitness[indices_to_keep]\n            self.pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.56815, "other_inf": null}
{"id": "8cff4e03-b3ae-4e48-9f9d-9fbd9a586d96", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: A self-adaptive Differential Evolution strategy with ensemble mutation operators and a restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, crossover_rate=0.7, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.crossover_rate = crossover_rate\n        self.restart_probability = restart_probability\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_factors = [0.5, 0.7, 0.9] # Ensemble of mutation factors\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n\n            # Ensemble of mutation strategies\n            mutation_factor = np.random.choice(self.mutation_factors)\n            mutant = np.clip(a + mutation_factor * (b - c), self.lb, self.ub)\n\n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector.copy()\n\n        self.population = new_population\n        self.fitness = new_fitness\n\n    def restart(self, func):\n        # Restart population if stagnation is detected\n        if np.random.rand() < self.restart_probability:\n            self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                 self.f_opt = self.fitness[best_index]\n                 self.x_opt = self.population[best_index].copy()\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n            self.restart(func) #apply the restart mechanism\n        return self.f_opt, self.x_opt", "objective": -0.19269, "other_inf": null}
{"id": "d104dd0b-75f4-4c86-9a76-f402a78ea0da", "parents": ["981304a8-96e0-4118-a1ab-96b026d58b93"], "algorithm": "Implements a self-adaptive differential evolution with a repair mechanism for handling boundary violations and a simplified local search strategy.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = self.pop[i] + self.F * (b - c)\n\n                # Repair mechanism\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Simplified Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + 0.01 * np.random.randn(self.dim)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.58947, "other_inf": null}
{"id": "d7ffd200-fe1c-4a14-a094-8e9b088574b0", "parents": ["d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "Implements a variant of differential evolution with adaptive parameters, including population size adjustment and a distance-based mutation strategy to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, pop_size_adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate\n        self.min_pop_size = 4\n        self.max_pop_size = 100\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation based on distance to nearest neighbor\n                distances = np.linalg.norm(self.pop - self.pop[i], axis=1)\n                distances[i] = np.inf  # Exclude itself\n                nearest_neighbor_idx = np.argmin(distances)\n\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                a, b = self.pop[indices]\n\n                mutant = self.pop[i] + self.F * (self.pop[nearest_neighbor_idx] - self.pop[i]) + self.F * (a - b)\n\n                # Repair mechanism\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n            # Adapt population size\n            if self.func_evals / self.budget > 0.5:  # Adapt after a certain point\n                success_rate = np.sum(self.fitness < np.mean(self.fitness)) / self.pop_size\n                if success_rate > 0.2:\n                    self.pop_size = min(self.max_pop_size, int(self.pop_size * (1 + self.pop_size_adaptation_rate)))\n                elif success_rate < 0.1:\n                    self.pop_size = max(self.min_pop_size, int(self.pop_size * (1 - self.pop_size_adaptation_rate)))\n                \n                self.pop_size = int(self.pop_size)\n                \n                if self.pop_size != self.pop.shape[0]:\n\n                    #resize population\n                    if self.pop_size > self.pop.shape[0]:\n                         new_individuals = np.random.uniform(self.lb, self.ub, size=(self.pop_size-self.pop.shape[0], self.dim))\n                         self.pop = np.vstack((self.pop,new_individuals))\n                         new_fitness = np.array([func(x) for x in new_individuals])\n                         self.fitness = np.concatenate((self.fitness,new_fitness))\n                         self.func_evals += new_individuals.shape[0]\n                    else:\n\n                         indices_to_keep = np.argsort(self.fitness)[:self.pop_size]\n                         self.pop = self.pop[indices_to_keep]\n                         self.fitness = self.fitness[indices_to_keep]\n\n\n        return self.f_opt, self.x_opt", "objective": -0.27808, "other_inf": null}
{"id": "5cf258e8-e51c-4f8b-8b2a-dabd449f8572", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "A population-based algorithm that uses a simplified PSO update rule with adaptive inertia weight and velocity clamping for exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveClampingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2.0, c2=2.0, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Max inertia weight\n        self.w_min = w_min  # Min inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max_ratio = v_max_ratio\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        v_max = self.v_max_ratio * (self.ub - self.lb)\n        velocities = np.random.uniform(-v_max, v_max, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # PSO update\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            global_best_position = self.x_opt\n\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            population = population + velocities\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluation\n            new_fitness = np.array([func(x) for x in population])\n            eval_count += self.pop_size\n            fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitness[i] = fitness[i]\n\n                    # Update global best\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n\n            if eval_count >= self.budget:\n                eval_count = self.budget #correction\n\n        return self.f_opt, self.x_opt", "objective": -0.47913, "other_inf": null}
{"id": "02f52fa0-68ed-4635-ac46-0334e9cc1054", "parents": ["d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "Implements a variant of Differential Evolution with a larger population size, reduced mutation factor, increased crossover rate, and a more aggressive local search, aiming for better exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.3, CR=0.95, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = self.pop[i] + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Aggressive Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial = trial + 0.1 * np.random.randn(self.dim)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.41045, "other_inf": null}
{"id": "7653de49-aa4b-4c2b-9b7a-0f36145e23c3", "parents": ["d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "Implements a variant of Differential Evolution with adaptive parameters, including population size reduction and a learning rate that scales with fitness improvement, combined with a restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.8, stagnation_threshold=0.0001, stagnation_iters=500, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iters = stagnation_iters\n        self.reduction_factor = reduction_factor\n        self.best_fitness_history = []\n        self.learning_rate = 0.1\n        self.restart_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals = self.pop_size\n        self.best_fitness_history.append(np.min(self.fitness))\n\n        while self.func_evals < self.budget:\n            prev_best_fitness = self.f_opt\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.pop[indices]\n                mutant = self.pop[i] + self.F * (b - c)\n\n                # Repair mechanism\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        # Adaptive Learning Rate based on improvement\n                        improvement = prev_best_fitness - self.f_opt\n                        self.learning_rate = min(0.1 + improvement, 1.0)\n\n            self.best_fitness_history.append(np.min(self.fitness))\n            \n            #Stagnation Check and Restart/Reduction\n            if len(self.best_fitness_history) > self.stagnation_iters:\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.stagnation_iters]) < self.stagnation_threshold:\n                    self.restart_counter += 1\n                    if self.restart_counter < 3:\n                        # Reduce population size\n                        self.pop_size = int(self.pop_size * self.reduction_factor)\n                        self.pop_size = max(10, self.pop_size) #Ensure minimum pop size\n                        self.pop = self.pop[np.argsort(self.fitness)[:self.pop_size]]  # Keep best individuals\n                        self.fitness = self.fitness[np.argsort(self.fitness)[:self.pop_size]]\n                        \n                        # Repopulate with random individuals\n                        num_new = 50 - self.pop_size if 50 - self.pop_size > 0 else 0\n                        if num_new > 0:\n                            new_pop = np.random.uniform(self.lb, self.ub, size=(num_new, self.dim))\n                            new_fitness = np.array([func(x) for x in new_pop])\n                            self.func_evals += num_new\n                            self.pop = np.concatenate((self.pop, new_pop))\n                            self.fitness = np.concatenate((self.fitness, new_fitness))\n                        self.pop_size = 50\n\n\n                    else:\n                        #Restart with new random population\n                        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                        self.fitness = np.array([func(x) for x in self.pop])\n                        self.func_evals += self.pop_size\n                        self.restart_counter = 0\n\n                    self.best_fitness_history = [np.min(self.fitness)] #Reset history after restart.\n                    \n        return self.f_opt, self.x_opt", "objective": -0.4009, "other_inf": null}
{"id": "5a79a3fd-dcb9-4d17-9aab-339c567f36d8", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "Simulated Annealing with adaptive temperature and step size, focusing on intensifying the search around promising regions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.temp = initial_temp\n        self.step_size = 1.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x.copy()\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate neighbor\n            x_new = x + np.random.normal(0, self.step_size, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluate neighbor\n            f_new = func(x_new)\n            eval_count += 1\n\n            # Acceptance probability\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new.copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new.copy()\n                    #Increase step size if improving\n                    self.step_size *= 1.1\n                else:\n                    #Decrease step size if not improving\n                    self.step_size *= 0.9\n\n            #Cooling Schedule\n            self.temp *= self.cooling_rate\n            self.step_size = np.clip(self.step_size, 0.01, 2.0)\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.13776, "other_inf": null}
{"id": "2bbb6fad-ce06-433d-9ca8-f6af463e0b37", "parents": ["d104dd0b-75f4-4c86-9a76-f402a78ea0da", "795c5c75-cd94-4f45-90d8-759517521a07"], "algorithm": "Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified update strategy for the covariance matrix and step size, and a hard restart mechanism.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.mean = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_trigger = 100 * self.dim # Trigger restart after this many evaluations without improvement\n        self.no_improvement_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n\n            # Find best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = x[best_idx].copy()\n                self.no_improvement_count = 0\n            else:\n                self.no_improvement_count += self.pop_size\n\n            # Update mean\n            weights = np.zeros(self.pop_size)\n            weights[best_idx] = 1.0  # Give all weight to the best individual\n            delta_mean = np.sum(weights[:, None] * (x - self.mean), axis=0)\n            self.mean += delta_mean\n\n            # Simplified Covariance Matrix Adaptation\n            self.C = (1 - 0.1) * self.C + 0.1 * np.outer(delta_mean / self.sigma, delta_mean / self.sigma)\n            self.sigma *= np.exp(0.2 * (self.success_rate(fitness) - 0.2)) # adapt step size\n\n            # Hard Restart mechanism\n            if self.no_improvement_count > self.restart_trigger or not np.all(np.isfinite(self.C)):\n                self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = 0.2\n                self.no_improvement_count = 0\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def success_rate(self, fitness):\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7f6ded8b-0100-405c-aaac-43e2cb0bc036", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified adaptation rules and restarts to maintain diversity.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_factor=0.25, restart_factor=0.75):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = max(1, int(self.pop_size * mu_factor))\n        self.weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mean = np.random.uniform(-5, 5, size=dim)\n        self.C = np.eye(dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_factor = restart_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            population = self.sample_population()\n            population = np.clip(population, self.lb, self.ub)\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n            if self.eval_count > self.budget:\n                fitness = fitness[:self.budget - (self.eval_count - self.pop_size)]\n                population = population[:self.budget - (self.eval_count - self.pop_size)]\n                \n            indices = np.argsort(fitness)\n            best_indices = indices[:self.mu]\n\n            best_population = population[best_indices]\n            best_fitness = fitness[best_indices]\n            \n            if np.min(best_fitness) < self.f_opt:\n                self.f_opt = np.min(best_fitness)\n                self.x_opt = best_population[np.argmin(best_fitness)].copy()\n\n            # Update mean\n            self.mean = np.sum(self.weights[:, None] * best_population, axis=0)\n\n            # Rank-one update of covariance matrix\n            y = best_population - self.mean\n            C_update = np.sum(self.weights[:, None, None] * y[:, :, None] * y[:, None, :], axis=0)\n            self.C = (1 - self.restart_factor) * self.C + self.restart_factor * C_update\n\n            # Keep C positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, k=1).T\n\n            #Simple check for positive definiteness and fix\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n            # Adjust step size\n            self.sigma *= np.exp(0.5 * (np.mean(best_fitness) - np.mean(fitness)) / self.dim)\n            if self.sigma < 1e-6:\n                self.sigma = 0.5 #Reset sigma if too small\n\n        return self.f_opt, self.x_opt", "objective": -0.09174, "other_inf": null}
{"id": "b902dd1d-83df-4fee-990d-a527a519b7d5", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "A gradient-free optimization algorithm that iteratively improves solutions by perturbing them based on estimated local gradients using random sampling and updating step sizes adaptively.", "code": "import numpy as np\n\nclass AdaptivePerturbation:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, num_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.num_samples = num_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        \n        while eval_count < self.budget:\n            # Estimate local gradient\n            perturbations = np.random.normal(0, self.step_size, size=(self.num_samples, self.dim))\n            \n            # Evaluate perturbed points\n            perturbed_points = np.clip(self.x_opt + perturbations, self.lb, self.ub)\n            fitness_values = np.array([func(x) for x in perturbed_points])\n            eval_count += self.num_samples\n            \n            if eval_count > self.budget:\n                fitness_values = fitness_values[:self.budget - (eval_count - self.num_samples)]\n                perturbed_points = perturbed_points[:self.budget - (eval_count - self.num_samples)]\n                \n            # Calculate fitness differences\n            fitness_diffs = fitness_values - self.f_opt\n            \n            # Update solution based on fitness differences and perturbations\n            if np.any(fitness_diffs < 0):\n                best_index = np.argmin(fitness_diffs)\n                if fitness_values[best_index] < self.f_opt:\n                  self.f_opt = fitness_values[best_index]\n                  self.x_opt = perturbed_points[best_index].copy()\n\n                # Adapt step size\n                self.step_size *= 0.95 # Reduce step size if improvement\n            else:\n                # Adapt step size\n                self.step_size *= 1.05 # Increase step size if no improvement\n                self.step_size = min(self.step_size, 1.0) # limit to 1.0\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "369ab5e6-80df-4c48-b634-a8e3a4874a7b", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "Simulated annealing with adaptive temperature updates based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, temp_adjust_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adjust_freq = temp_adjust_freq\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x.copy()\n\n        temp = self.initial_temp\n        eval_count = 1\n        accept_count = 0\n\n        while eval_count < self.budget:\n            x_new = x + np.random.normal(0, 0.1, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                accept_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n\n            if eval_count % self.temp_adjust_freq == 0:\n                if accept_count / self.temp_adjust_freq > 0.6:\n                    temp *= 1.1  # Increase temp if accepting too many\n                elif accept_count / self.temp_adjust_freq < 0.4:\n                    temp *= 0.9  # Decrease temp if accepting too few\n                else:\n                    temp *= self.cooling_rate # default cooling\n\n                accept_count = 0\n            \n        return self.f_opt, self.x_opt", "objective": -0.16035, "other_inf": null}
{"id": "95f4241d-9efb-4193-b49c-82ca34d1b42c", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "# Description: An evolutionary algorithm that combines a simplified differential evolution with a tournament selection and a self-adaptive step size control.\n# Code: \n```", "code": "import numpy as np\n\nclass SimplifiedEvolutionaryAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=40, mutation_rate=0.1, tournament_size=4, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.tournament_size = tournament_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = initial_step_size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def tournament_selection(self):\n        participants = np.random.choice(self.pop_size, self.tournament_size, replace=False)\n        winner = participants[np.argmin(self.fitness[participants])]\n        return winner\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Selection\n            parent_idx = self.tournament_selection()\n            parent = self.population[parent_idx]\n\n            # Mutation with self-adaptive step size\n            mutation = np.random.normal(0, self.step_size, self.dim) * np.random.binomial(1, self.mutation_rate, self.dim)\n            child = np.clip(parent + mutation, self.lb, self.ub)\n           \n            f_child = func(child)\n            self.budget -= 1\n\n            # Replacement - replace the worst in the population\n            worst_idx = np.argmax(self.fitness) \n            if f_child < self.fitness[worst_idx]:\n                new_population[worst_idx] = child\n                new_fitness[worst_idx] = f_child\n\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child.copy()\n        \n        # Adapt step size\n        if np.random.rand() < 0.1:\n            if np.mean(new_fitness) < np.mean(self.fitness):\n                self.step_size *= 1.1\n            else:\n                self.step_size *= 0.9\n            self.step_size = np.clip(self.step_size, 0.01, 1.5)\n        \n        self.population = new_population\n        self.fitness = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.27468, "other_inf": null}
{"id": "467663f9-de66-46c6-b354-a1fc0a7d99f3", "parents": ["f8166c6f-0bf6-4540-b602-a82177c23723", "d104dd0b-75f4-4c86-9a76-f402a78ea0da"], "algorithm": "Adaptively samples new points based on the fitness landscape's estimated gradient direction, using a dynamically adjusted step size and a momentum-like term to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, momentum=0.9, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.momentum = momentum\n        self.exploration_rate = exploration_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.velocity = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        fx = func(x)\n        self.f_opt = fx\n        self.x_opt = x.copy()\n        \n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Estimate gradient (using finite differences)\n            gradient = np.zeros(self.dim)\n            delta = 1e-6\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_plus[i] += delta\n                x_plus = np.clip(x_plus, self.lb, self.ub)\n                f_plus = func(x_plus)\n                eval_count += 1\n                if eval_count >= self.budget:\n                  break\n                \n                x_minus = x.copy()\n                x_minus[i] -= delta\n                x_minus = np.clip(x_minus, self.lb, self.ub)\n                f_minus = func(x_minus)\n                eval_count += 1\n                if eval_count >= self.budget:\n                  break\n                \n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n            # Update velocity with momentum\n            self.velocity = self.momentum * self.velocity - self.step_size * gradient\n\n            # Update position\n            x_new = x + self.velocity\n            x_new = np.clip(x_new, self.lb, self.ub)\n            \n\n            # Exploration: Random jump with probability exploration_rate\n            if np.random.rand() < self.exploration_rate:\n                x_new = np.random.uniform(self.lb, self.ub, self.dim)\n\n            f_new = func(x_new)\n            eval_count += 1\n\n            if f_new < fx:\n                x = x_new\n                fx = f_new\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x.copy()\n            \n            #Adaptive step size update\n            if eval_count % 100 == 0:\n              if f_new > fx:\n                self.step_size *= 0.9\n              else:\n                self.step_size *= 1.1\n              self.step_size = np.clip(self.step_size, 1e-6, 0.5)\n\n            if eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": -0.25962, "other_inf": null}
{"id": "6f2f1b6c-365c-4789-979b-2dc97f4e225e", "parents": ["d104dd0b-75f4-4c86-9a76-f402a78ea0da", "f8166c6f-0bf6-4540-b602-a82177c23723"], "algorithm": "An evolutionary strategy that uses a Gaussian mutation with adaptive step sizes for each dimension, and a selection mechanism based on comparing the parent and offspring fitness.", "code": "import numpy as np\n\nclass AdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, tau=None, tau_prime=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        if tau is None:\n            self.tau = 1 / np.sqrt(2 * self.dim)\n        else:\n            self.tau = tau\n        if tau_prime is None:\n            self.tau_prime = 1 / np.sqrt(2 * np.sqrt(self.dim))\n        else:\n            self.tau_prime = tau_prime\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and step sizes\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.full((self.pop_size, self.dim), self.initial_step_size)\n\n        fitness = np.array([func(x) for x in population])\n        self.func_evals = self.pop_size\n        \n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutate step sizes\n                global_factor = np.exp(self.tau_prime * np.random.normal(0, 1))\n                local_factors = np.exp(self.tau * np.random.normal(0, 1, size=self.dim))\n                mutated_step_sizes = step_sizes[i] * global_factor * local_factors\n                \n                # Mutate individual\n                mutated_individual = population[i] + mutated_step_sizes * np.random.normal(0, 1, size=self.dim)\n                mutated_individual = np.clip(mutated_individual, self.lb, self.ub)\n\n                # Evaluate offspring\n                f = func(mutated_individual)\n                self.func_evals += 1\n\n                # Selection: compare parent and offspring\n                if f < fitness[i]:\n                    population[i] = mutated_individual\n                    fitness[i] = f\n                    step_sizes[i] = mutated_step_sizes\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = mutated_individual.copy()\n                \n                if self.func_evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.32825, "other_inf": null}
{"id": "8bc0d720-fecc-418b-8722-089460d4cbd0", "parents": ["b2bc3d63-3400-476d-bb4b-9fe20d1a69a2"], "algorithm": "# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix, step size, and mean of a multivariate normal distribution to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mean=None, c_cov_sigma=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mean = np.random.uniform(-5, 5, size=dim)\n        self.C = np.eye(dim)\n        self.ps = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (dim + 1)) - 1) + self.cs\n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else 2 / ((dim + np.sqrt(2))**2)\n        self.c_cov_sigma = c_cov_sigma if c_cov_sigma is not None else 2 / ((dim + np.sqrt(2))**2) + (1 - 2 / ((dim + np.sqrt(2))**2)) * min(1, (2 * self.mu_eff - 1) / ((dim + 2)**2 + self.mu_eff))\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T), z\n\n    def update_parameters(self, solutions, z):\n        fitness_values = np.array([f for f, _ in solutions])\n        indices = np.argsort(fitness_values)\n        solutions = [solutions[i][1] for i in indices]\n\n        y = solutions[:self.mu] - self.mean\n        z = z[indices[:self.mu]]\n\n        self.mean = np.sum(self.weights[:, None] * solutions[:self.mu], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.mean)) / self.sigma\n        self.pc = (1 - self.c_cov_mean) * self.pc + np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean) * self.mu_eff) * y.sum(axis=0)\n\n        delta_hsigma = (np.linalg.norm(self.ps) / self.chiN - 1)\n        self.sigma *= np.exp((self.cs / self.damps) * delta_hsigma)\n\n        C_temp = (1 - self.c_cov_sigma) * self.C + self.c_cov_sigma * (self.pc[:, None] @ self.pc[None, :])\n\n        for i in range(self.mu):\n            C_temp += self.c_cov_sigma * self.weights[i] * y[i][:, None] @ y[i][None, :]\n\n        self.C = np.triu(C_temp) + np.triu(C_temp, 1).T  # Ensure symmetry\n\n    def __call__(self, func):\n        while self.budget > 0:\n            population, z = self.sample_population()\n            \n            # Clip the population within bounds\n            population = np.clip(population, self.lb, self.ub)\n\n            fitness_values = []\n            for i in range(len(population)):\n              if self.budget > 0:\n                f = func(population[i])\n                self.budget -= 1\n                fitness_values.append((f, population[i]))\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i].copy()\n              else:\n                break\n            \n            if len(fitness_values) > 0:\n              self.update_parameters(fitness_values, z)\n            else:\n              break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2bfba7de-59a8-49ee-aa75-9b869fac72e9", "parents": ["795c5c75-cd94-4f45-90d8-759517521a07"], "algorithm": "Implements a Differential Evolution (DE) algorithm with a self-adaptive mutation strategy, adjusting the mutation factor based on the improvement in fitness achieved by the population.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f_init  # Initial mutation factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        eval_count = self.pop_size\n\n        mutation_factors = np.full(self.pop_size, self.f)\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Select three random individuals (excluding the current one)\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Mutation: Use individual-specific mutation factor\n                v_mutation = x_r1 + mutation_factors[i] * (x_r2 - x_r3)\n                v_mutation = np.clip(v_mutation, self.lb, self.ub)\n\n                # Crossover (Binomial)\n                j_rand = np.random.randint(self.dim)\n                u = np.random.rand(self.dim)\n                mask = (u <= 0.9) | (np.arange(self.dim) == j_rand)  # Fixed CR = 0.9\n                u_crossover = np.where(mask, v_mutation, population[i])\n\n                # Evaluation\n                f_trial = func(u_crossover)\n                eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Success! Update individual and adjust mutation factor\n                    fitness_improvement = fitness[i] - f_trial\n                    population[i] = u_crossover\n                    fitness[i] = f_trial\n                    mutation_factors[i] = np.clip(mutation_factors[i] * (1 + 0.2 * fitness_improvement / abs(fitness[i])), 0.1, 1.0) #Adaptive F\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = u_crossover.copy()\n                else:\n                    # Failure: Reduce mutation factor slightly\n                    mutation_factors[i] = np.clip(mutation_factors[i] * 0.95, 0.1, 1.0)\n\n\n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "objective": -0.63405, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "37be6844-6e71-4cd9-99c6-1a6cfc7ddfbd", "parents": [], "algorithm": "Adaptive Differential Evolution with exploration and exploitation phases, adjusting parameters based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        success_count = 0\n        F_history = []\n        CR_history = []\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    indices2 = np.random.choice(len(self.archive), 1, replace=False).tolist()\n                    indices.append(self.archive[indices2[0]])\n                \n                indices = np.random.choice(indices, 3, replace=False)\n                x1, x2, x3 = self.population[indices[0]], self.population[indices[1]], self.population[indices[2]]\n                \n                mutant = self.population[i] + self.F * (x2 - x3)\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.copy(self.population[i])\n                trial_vector[crossover_mask] = mutant[crossover_mask]\n                trial_vector = np.clip(trial_vector, self.lb, self.ub) # Keep within bounds\n                \n                # Selection\n                f_trial = func(trial_vector)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n                    success_count += 1\n\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        idx_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_replace] = self.population[i].copy()\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.evals >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "0a6d4fa6-7706-41ec-ab07-2c0ee48fbb46", "parents": [], "algorithm": "Adaptively samples points based on the fitness landscape's estimated gradient direction, focusing exploration in promising regions.", "code": "import numpy as np\n\nclass AdaptiveGradientSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, exploration_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = learning_rate\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        for i in range(self.budget-1):\n            \n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            delta = 1e-3  # Step size for gradient estimation\n\n            for j in range(self.dim):\n                x_plus = x.copy()\n                x_plus[j] += delta\n                x_minus = x.copy()\n                x_minus[j] -= delta\n\n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                \n                gradient[j] = (func(x_plus) - func(x_minus)) / (2 * delta)\n            \n            # Update position based on gradient and exploration\n            if np.random.rand() < self.exploration_rate:\n                # Exploration: Randomly sample\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            else:\n                # Exploitation: Move along the negative gradient\n                x_new = x - self.learning_rate * gradient\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # Keep in bounds\n            \n            f_new = func(x_new)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            \n            x = x_new  # Update current position\n            f = f_new\n            \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "4ccfe366-0b91-4a11-9649-dbc583023511", "parents": [], "algorithm": "This algorithm employs a population-based approach with differential evolution operators for exploration and exploitation, adaptively adjusting the mutation factor based on the success rate of previous generations to balance exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Crossover rate\n        self.F_history = []\n        self.success_rate_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < new_fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f\n                    successful_mutations += 1\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            success_rate = successful_mutations / self.pop_size if self.pop_size > 0 else 0\n\n            # Adaptive F\n            self.success_rate_history.append(success_rate)\n            self.F_history.append(self.F)\n\n            if len(self.success_rate_history) > 5:  # Using a window of 5 generations\n                recent_success_rates = self.success_rate_history[-5:]\n                recent_F_values = self.F_history[-5:]\n                \n                if np.mean(recent_success_rates) > 0.3:  # High success rate, reduce exploration\n                    self.F = max(0.1, self.F * 0.9)\n                elif np.mean(recent_success_rates) < 0.1:  # Low success rate, increase exploration\n                    self.F = min(0.9, self.F * 1.1)\n\n        return self.f_opt, self.x_opt", "objective": -0.44152, "other_inf": null}
{"id": "71e67893-950d-4a57-8d3a-7eb007e1cd65", "parents": [], "algorithm": "Adaptive Differential Evolution with ensemble mutation strategies and dynamic parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_rate = 0.1 # Archive size relative to population\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Initialize archive\n        archive = [] \n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation Strategies\n                if np.random.rand() < 0.33: #DE/rand/1\n                  indices = np.random.choice(self.pop_size, 5, replace=False)\n                  x1, x2, x3, x4, x5 = population[indices]\n                  mutant = x1 + self.F * (x2 - x3)\n                elif np.random.rand() < 0.66: #DE/best/1\n                  indices = np.random.choice(self.pop_size, 3, replace=False)\n                  x1, x2, x3 = population[indices]\n                  mutant = self.x_opt + self.F * (x1 - x2)\n                else: #DE/current-to-rand/1\n                    indices = np.random.choice(self.pop_size + len(archive), 3, replace=False)\n                    x_current = population[i]\n                    \n                    archive_pop = np.concatenate((population, np.array(archive)))\n                    \n                    x1, x2, x3 = archive_pop[indices]\n                    \n                    mutant = x_current + np.random.rand() * (x1 - x_current) + np.random.rand() * (x2 - x3)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant, population[i])\n\n                # Repair\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                    # Update archive\n                    if len(archive) < int(self.archive_rate * self.pop_size):\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            best_index = np.argmin(fitness)\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            \n            # Adaptation of F and CR (simple version)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 1.0) # small adjustment\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 1.0) # small adjustment\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "738881a0-e577-4dd5-afb1-3bafd575fd0d", "parents": [], "algorithm": "Simulated Annealing with adaptive temperature schedule, based on the observed function values.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        \n        f_vals = []\n\n        for i in range(self.budget):\n            x_new = x + np.random.normal(0, temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            \n            f_vals.append(f_new)\n\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_probability = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n            \n            # Adaptive temperature adjustment\n            if len(f_vals) > 100:  # Start adapting after initial exploration\n                std_dev = np.std(f_vals[-100:])\n                temp = max(0.0001, std_dev * self.cooling_rate) # Ensure temp doesn't go to zero too fast\n            else:\n                temp *= self.cooling_rate\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "1d996494-7f41-40d9-a25e-145108ac4ec2", "parents": [], "algorithm": "This algorithm combines a population-based approach with adaptive step size and local search to explore the search space effectively and refine promising solutions.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, local_search_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for step size adaptation\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def local_search(self, func, x):\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n        if best_f < self.f_opt:\n            self.f_opt = best_f\n            self.x_opt = x\n        \n        for _ in range(5): # Small budget for local search\n            x_new = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new\n                if best_f < self.f_opt:\n                    self.f_opt = best_f\n                    self.x_opt = x_new\n\n        return best_x, best_f\n    \n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Select parents based on fitness (e.g., tournament selection)\n            indices = np.random.choice(self.pop_size, size=2, replace=False)\n            if self.fitness[indices[0]] < self.fitness[indices[1]]:\n                parent = self.population[indices[0]]\n            else:\n                parent = self.population[indices[1]]\n\n            # Create offspring by adding a random step with adaptive step size\n            step = self.lr * np.random.normal(0, 1, size=self.dim)\n            offspring = parent + step\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Local search around offspring\n            offspring, offspring_fitness = self.local_search(func, offspring)\n\n            # Update population (replace worst individual if offspring is better)\n            worst_index = np.argmax(self.fitness)\n            if offspring_fitness < self.fitness[worst_index]:\n                self.population[worst_index] = offspring\n                self.fitness[worst_index] = offspring_fitness\n\n                if offspring_fitness < self.f_opt:\n                    self.f_opt = offspring_fitness\n                    self.x_opt = offspring\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "1e46c6bf-6ff2-49a2-a750-6eb5a0094afd", "parents": [], "algorithm": "Adaptive Differential Evolution with a dynamically adjusted mutation factor and crossover rate based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_rate = 0.1\n        self.archive = []\n        \n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update F and CR based on success\n                    self.update_parameters(self.population[i], trial, f, self.fitness[i])\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "397587cf-941c-4ce8-9204-3e5b1d4e683d", "parents": [], "algorithm": "An adaptive Differential Evolution strategy that adjusts its parameters (mutation factor and crossover rate) based on the success rate of generating better solutions.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Adaptive parameter control (simple adaptation)\n            if np.random.rand() < 0.1: #Small probability for faster convergence in some cases\n                self.F = np.clip(self.F + np.random.normal(0, 0.1), 0.1, 0.9)  # Adjust mutation factor\n                self.CR = np.clip(self.CR + np.random.normal(0, 0.1), 0.1, 0.9)  # Adjust crossover rate\n\n        return self.f_opt, self.x_opt", "objective": -0.61, "other_inf": null}
{"id": "a669f869-2c81-4837-b2a8-1edf2b80959e", "parents": ["4ccfe366-0b91-4a11-9649-dbc583023511", "0a6d4fa6-7706-41ec-ab07-2c0ee48fbb46"], "algorithm": "This algorithm iteratively refines a population of solutions by stochastically selecting parents based on their fitness and creating offspring through recombination and mutation, focusing search efforts around promising areas of the search space.", "code": "import numpy as np\n\nclass StochasticRankingEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, selection_pressure=2, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.selection_pressure = selection_pressure  # Higher value favors better individuals\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            # Selection: Tournament selection\n            selected_indices = []\n            for _ in range(self.pop_size):\n                tournament_indices = np.random.choice(self.pop_size, self.selection_pressure, replace=False)\n                winner_index = tournament_indices[np.argmin(self.fitness[tournament_indices])]\n                selected_indices.append(winner_index)\n\n            selected_population = self.population[selected_indices]\n\n            # Recombination (Crossover): Create offspring\n            offspring = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                parent1 = selected_population[i]\n                parent2 = selected_population[np.random.randint(self.pop_size)] # Select another parent\n                \n                # Recombine using a simple average\n                offspring[i] = (parent1 + parent2) / 2\n\n            # Mutation: Randomly perturb offspring\n            for i in range(self.pop_size):\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        offspring[i, j] += np.random.normal(0, 0.1)  # Small random perturbation\n                        offspring[i, j] = np.clip(offspring[i, j], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluation: Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            if self.budget <=0:\n                offspring_fitness = offspring_fitness[:self.pop_size+self.budget]\n                offspring = offspring[:self.pop_size+self.budget]\n\n            # Replacement: Replace the worst individuals in the population\n            worst_indices = np.argsort(self.fitness)[-len(offspring_fitness):]  # Indices of worst individuals\n            self.population[worst_indices] = offspring\n            self.fitness[worst_indices] = offspring_fitness\n\n            # Update best solution found so far\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n                \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "dbee7c3d-09f5-4dc1-a600-3dac463ad5e5", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "37be6844-6e71-4cd9-99c6-1a6cfc7ddfbd"], "algorithm": "# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to efficiently sample promising regions of the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = (self.lb + self.ub) / 2 * np.ones(self.dim)  # Initialize mean to the center of the search space\n        self.C = np.eye(self.dim)  # Initialize covariance matrix to identity\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n        if damps is None:\n            self.damps = 1 + 2*max(0, np.sqrt((self.mu_eff - 1)/(self.dim+1)) - 1) + self.cs\n        else:\n            self.damps = damps\n\n        self.mu_weights = np.log(self.pop_size+1) - np.log(np.arange(1, self.pop_size+1))\n        self.mu_weights = self.mu_weights / np.sum(self.mu_weights)\n        self.mu_eff = np.sum(self.mu_weights)**2 / np.sum(self.mu_weights**2)\n        \n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = min(1-self.ccov1, 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim+2)**2 + self.mu_eff))\n        else:\n            self.ccovmu = ccovmu\n\n        self.cs = cs\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mu + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            # Sort population\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n\n            # Update mean\n            xmean = np.sum(x[:self.pop_size] * self.mu_weights[:, np.newaxis], axis=0)\n            zmean = np.sum(z[:self.pop_size] * self.mu_weights[:, np.newaxis], axis=0)\n\n            y = xmean - self.mu\n            self.mu = xmean\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ y) / self.sigma\n            self.pc = (1 - self.ccov1) * self.pc + np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mu_eff) * y / self.sigma\n\n            # Update covariance matrix\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) < self.chiN * (1.4 + 2/(self.dim+1))\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + self.ccov1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.ccov1 * self.C) + self.ccovmu * np.sum(self.mu_weights[:, np.newaxis, np.newaxis] * (z[:self.pop_size, :, np.newaxis] @ z[:self.pop_size, np.newaxis, :]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # Check termination\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ff130c4f-0ee4-4d89-8c5b-5799279139dc", "parents": ["4ccfe366-0b91-4a11-9649-dbc583023511", "0a6d4fa6-7706-41ec-ab07-2c0ee48fbb46"], "algorithm": "Simulated Annealing with adaptive temperature reduction and occasional restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n\n        for i in range(self.budget - 1):\n            if np.random.rand() < self.restart_prob:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            else:\n                x_new = x + np.random.normal(0, temp**(1/self.dim), size=self.dim) # Dim scaling\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            temp *= self.cooling_rate\n\n        return self.f_opt, self.x_opt", "objective": -0.51578, "other_inf": null}
{"id": "94b5e1c5-9973-47b1-8e4c-65d70e13c4a1", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) adapts a multivariate normal distribution to sample new candidate solutions, learning the covariance matrix to capture correlations between variables and improve search efficiency.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mean = np.random.uniform(-5, 5, dim)\n        self.C = np.eye(dim)  # Covariance matrix\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n\n        # Adaptive parameters (as recommended in CMA-ES literature)\n        self.cs = cs\n        self.damps = damps if damps else 1 + 2*max(0, (np.sqrt((self.pop_size-1)/(self.dim+1))-1)) + self.cs\n        self.ccov1 = ccov1 if ccov1 else 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.ccovmu = ccovmu if ccovmu else 2 * (self.pop_size - 2 + 1/self.pop_size) / ((self.dim + 2)**2 + 2 * self.pop_size/2)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.bounds = [-5, 5]\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, (self.pop_size, self.dim))\n            y = np.dot(z, np.linalg.cholesky(self.C).T)\n            x = self.mean + self.sigma * y\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            y_mean = np.sum(self.weights[:, None] * y[:self.mu], axis=0)\n            self.mean = self.mean + self.sigma * y_mean\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * y_mean / np.linalg.norm(y_mean) if np.linalg.norm(y_mean) > 0 else (1 - self.cs) * self.ps\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.damps) * self.pc + hsig * np.sqrt(self.damps * (2 - self.damps)) * y_mean\n\n            # Update covariance matrix\n            artmp = (1 / self.sigma) * (x[:self.mu] - self.mean)\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (1-hsig) * self.ccovmu) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.dot(artmp.T, np.diag(self.weights) @ artmp)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Repair covariance matrix (ensure positive definite)\n            if np.any(np.isnan(self.C)) or np.any(np.isinf(self.C)):\n                self.C = np.eye(self.dim)\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": -0.09699, "other_inf": null}
{"id": "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a", "parents": ["94b5e1c5-9973-47b1-8e4c-65d70e13c4a1", "ff130c4f-0ee4-4d89-8c5b-5799279139dc"], "algorithm": "A population-based algorithm that combines particle swarm optimization (PSO) principles with a shrinking search space and adaptive velocity clamping to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ShrinkingPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, clamp_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.clamp_factor = clamp_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.v = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * self.clamp_factor\n        self.pbest_x = self.x.copy()\n        self.pbest_f = np.full(self.pop_size, np.inf)\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            fitness = np.array([func(xi) for xi in self.x])\n            self.eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if fitness[i] < self.pbest_f[i]:\n                    self.pbest_f[i] = fitness[i]\n                    self.pbest_x[i] = self.x[i].copy()\n\n                    if fitness[i] < self.gbest_f:\n                        self.gbest_f = fitness[i]\n                        self.gbest_x = self.x[i].copy()\n\n            if self.gbest_f < self.f_opt:\n                self.f_opt = self.gbest_f\n                self.x_opt = self.gbest_x\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.v = self.w * self.v + self.c1 * r1 * (self.pbest_x - self.x) + self.c2 * r2 * (self.gbest_x - self.x)\n\n            # Adaptive velocity clamping to control exploration\n            v_max = (self.ub - self.lb) * self.clamp_factor\n            self.v = np.clip(self.v, -v_max, v_max)\n            self.x = self.x + self.v\n\n            # Shrinking search space\n            center = self.gbest_x\n            shrink_factor = 0.995  # Tune this parameter for search space shrinkage\n            self.lb = center - (self.ub - self.lb) * shrink_factor / 2\n            self.ub = center + (self.ub - self.lb) * shrink_factor / 2\n            self.lb = np.clip(self.lb, -5.0, 5.0)\n            self.ub = np.clip(self.ub, -5.0, 5.0)\n\n            self.x = np.clip(self.x, self.lb, self.ub) # Clip position\n\n        return self.f_opt, self.x_opt", "objective": -0.60105, "other_inf": null}
{"id": "32e341a6-45d1-4883-b33a-2cd1343534c7", "parents": ["ff130c4f-0ee4-4d89-8c5b-5799279139dc", "4ccfe366-0b91-4a11-9649-dbc583023511"], "algorithm": "An algorithm that combines the explorative power of random search with a localized search strategy based on Gaussian perturbations, adaptively adjusting the perturbation size based on the observed improvement rate.", "code": "import numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, initial_std=1.0, adaptation_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_std = initial_std\n        self.adaptation_rate = adaptation_rate\n        self.std = initial_std\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        for i in range(self.budget - 1):\n            x_new = x + np.random.normal(0, self.std, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            \n            if f_new < f:\n                x = x_new\n                f = f_new\n                self.success_history.append(1)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                self.success_history.append(0)\n\n            # Adapt std\n            if len(self.success_history) > 10:\n                recent_success = self.success_history[-10:]\n                success_rate = np.mean(recent_success)\n                if success_rate > 0.4:\n                    self.std *= self.adaptation_rate # Reduce std if doing well\n                elif success_rate < 0.1:\n                    self.std /= self.adaptation_rate # Increase std if doing poorly\n                    self.std = min(self.std, self.initial_std*2)\n            \n        return self.f_opt, self.x_opt", "objective": -0.32363, "other_inf": null}
{"id": "5d57229e-aded-4399-8ad4-64d25e0e1ce2", "parents": ["94b5e1c5-9973-47b1-8e4c-65d70e13c4a1", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "An Iterated Local Search algorithm perturbs the current best solution and accepts the new solution if it's better, or probabilistically accepts it if it's worse, to escape local optima, using a temperature schedule inspired by simulated annealing.", "code": "import numpy as np\n\nclass IteratedLocalSearch:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, temp_min=0.001, perturbation_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.temp_min = temp_min\n        self.perturbation_size = perturbation_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        self.eval_count += 1\n\n        temperature = self.temp_init\n\n        while self.eval_count < self.budget:\n            # Perturbation\n            x_new = self.x_opt + np.random.normal(0, self.perturbation_size, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluation\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance criterion (Simulated Annealing)\n            delta = f_new - self.f_opt\n            if delta < 0:\n                self.x_opt = x_new\n                self.f_opt = f_new\n            else:\n                acceptance_prob = np.exp(-delta / temperature)\n                if np.random.rand() < acceptance_prob:\n                    self.x_opt = x_new\n                    self.f_opt = f_new\n\n            # Temperature update (cooling schedule)\n            temperature = max(self.temp_min, temperature * 0.99)\n\n        return self.f_opt, self.x_opt", "objective": -0.36692, "other_inf": null}
{"id": "da46b601-46b4-452b-aa16-01216e93694d", "parents": ["4ccfe366-0b91-4a11-9649-dbc583023511", "ff130c4f-0ee4-4d89-8c5b-5799279139dc"], "algorithm": "A population-based algorithm where individuals stochastically migrate towards better solutions found so far, with migration probabilities dynamically adjusted based on individual and population performance.", "code": "import numpy as np\n\nclass StochasticMigration:\n    def __init__(self, budget=10000, dim=10, pop_size=20, migration_prob=0.1, adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.migration_prob = migration_prob\n        self.adaptation_rate = adaptation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.migration_prob:\n                    # Select a random individual to migrate towards (excluding itself)\n                    other_indices = [j for j in range(self.pop_size) if j != i]\n                    if other_indices:\n                        target_index = np.random.choice(other_indices)\n\n                        # Move towards the target, with some random perturbation\n                        step_size = np.random.uniform(0, 0.1) * (self.population[target_index] - self.population[i]) + np.random.normal(0, 0.01, self.dim)\n                        new_x = np.clip(self.population[i] + step_size, func.bounds.lb, func.bounds.ub)\n                        new_f = func(new_x)\n                        self.budget -= 1\n\n                        if new_f < self.fitness[i]:\n                            self.population[i] = new_x\n                            self.fitness[i] = new_f\n\n                            if new_f < self.f_opt:\n                                self.f_opt = new_f\n                                self.x_opt = new_x\n                \n                #Adaptation of migration probability\n                if self.fitness[i] < np.mean(self.fitness):\n                    self.migration_prob = min(1.0, self.migration_prob * (1 + self.adaptation_rate)) # increase prob if better than mean\n                else:\n                    self.migration_prob = max(0.01, self.migration_prob * (1 - self.adaptation_rate)) # decrease prob if worse than mean\n                \n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.20523, "other_inf": null}
{"id": "66711799-ebb2-4e6a-bdf8-f9311f55b4fa", "parents": ["ff130c4f-0ee4-4d89-8c5b-5799279139dc"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified update rules and budget-aware adaptation.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.alpha_cov = 2\n        self.c_cov = (1 / self.mueff) * (self.alpha_cov / ((self.dim + 1.3)**2 + self.mueff)) + (1 - (1 / self.mueff)) * min(1, self.alpha_cov * ((self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.alpha_cov * self.mueff / 2)))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)\n        p_sigma = np.zeros(self.dim)\n\n        evals = 0\n        while evals < self.budget:\n            z = np.random.randn(self.dim, self.pop_size)\n            x = mean[:, None] + sigma * np.dot(C, z)\n\n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n            f_sorted = f[idx]\n\n            if f_sorted[0] < self.f_opt:\n                self.f_opt = f_sorted[0]\n                self.x_opt = x_sorted[:, 0]\n\n            mean_new = np.sum(x_sorted[:, :self.mu] * self.weights, axis=1)\n\n            p_sigma = (1 - self.cs) * p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean_new - mean) / sigma\n            sigma *= np.exp(self.cs / self.damps * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n\n            C = (1-self.c_cov) * C + self.c_cov * (1/self.mueff) * np.dot((x_sorted[:, :self.mu] - mean) / sigma * self.weights, ((x_sorted[:, :self.mu] - mean) / sigma).T)\n\n            mean = mean_new\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "cba8b940-caf8-4f97-bf72-32d313b0e8c3", "parents": ["4ccfe366-0b91-4a11-9649-dbc583023511"], "algorithm": "# Description: This algorithm uses a simplified particle swarm optimization (PSO) with velocity clamping and inertia weight adaptation based on the fitness improvement rate, aiming for a balance between exploration and exploitation.\n# Code: \n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_ratio = v_max_ratio  # Ratio of search space range for max velocity\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.velocity = np.random.uniform(-(ub - lb) * self.v_max_ratio, (ub - lb) * self.v_max_ratio, size=(self.pop_size, self.dim))\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_fitness = np.copy(self.fitness)\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        self.global_best_position = np.copy(self.x_opt)\n\n        while self.budget > 0:\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            # Update velocities\n            self.velocity = self.inertia * self.velocity + \\\n                            self.c1 * r1 * (self.personal_best_positions - self.population) + \\\n                            self.c2 * r2 * (self.global_best_position - self.population)\n\n            # Velocity clamping\n            v_max = (ub - lb) * self.v_max_ratio\n            self.velocity = np.clip(self.velocity, -v_max, v_max)\n\n            # Update positions\n            self.population += self.velocity\n            self.population = np.clip(self.population, lb, ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in self.population])\n            self.budget -= self.pop_size\n\n            # Update personal bests\n            improvement = new_fitness < self.personal_best_fitness\n            self.personal_best_positions[improvement] = self.population[improvement]\n            self.personal_best_fitness[improvement] = new_fitness[improvement]\n\n            # Update global best\n            best_index = np.argmin(self.personal_best_fitness)\n            if self.personal_best_fitness[best_index] < self.f_opt:\n                self.f_opt = self.personal_best_fitness[best_index]\n                self.x_opt = self.personal_best_positions[best_index]\n                self.global_best_position = np.copy(self.x_opt)\n            \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Adapt inertia weight (simple version based on stagnation)\n            if len(self.best_fitness_history) > 10:\n                recent_fitness = self.best_fitness_history[-10:]\n                if np.std(recent_fitness) < 1e-6:\n                    self.inertia *= 0.95  # Reduce inertia if stagnant\n                else:\n                    self.inertia = min(0.7, self.inertia * 1.05)  # Increase slightly if improving\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.59124, "other_inf": null}
{"id": "47c858ad-7cdb-4da8-8734-8b6ae60c780e", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "# Description: A variant of Differential Evolution incorporating a restart mechanism and a scaling factor that decreases with the budget usage, combined with a local search strategy.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        eval_count = self.pop_size\n        restart_counter = 0\n\n        while eval_count < self.budget:\n            # Budget-aware scaling factor\n            remaining_budget_ratio = (self.budget - eval_count) / self.budget\n            current_F = self.F * remaining_budget_ratio\n            current_CR = self.CR * remaining_budget_ratio\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + current_F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < current_CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Local search with small probability\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.1 * (self.ub - self.lb) * remaining_budget_ratio\n                    trial = trial + np.random.normal(0, step_size, self.dim)\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Restart Mechanism\n            if eval_count > (restart_counter + 1) * (self.budget // 5) and restart_counter < 4:  # Restart every 20% of the budget\n                self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                restart_counter += 1\n                \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "cbb335ff-6cb0-4b31-8c75-aea0cd479dcc", "parents": ["ff130c4f-0ee4-4d89-8c5b-5799279139dc"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget-aware adaptation of parameters.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, sigma=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        for restart in range(self.restarts):\n            # Initialization\n            mu = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            C = np.eye(self.dim)  # Covariance matrix\n            pc = np.zeros(self.dim) # Evolution path for C\n            ps = np.zeros(self.dim) # Evolution path for sigma\n            \n            # CMA-ES parameters\n            lambda_ = int(4 + np.floor(3 * np.log(self.dim)))  # Population size\n            mu_eff = lambda_ / 2\n\n            # Adaptation parameters\n            c_sigma = (mu_eff + 2) / (self.dim + mu_eff + 5)\n            d_sigma = 1 + 2 * max(0, np.sqrt((mu_eff - 1) / (self.dim + 1)) - 1) + c_sigma\n            c_c = (4 + mu_eff / self.dim) / (self.dim + 4 + 2 * mu_eff / self.dim)\n            c_1 = 2 / ((self.dim + 1.3)**2 + mu_eff)\n            c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1 / mu_eff) / ((self.dim + 2)**2 + mu_eff))\n            \n            weights = np.log(mu_eff + 0.5) - np.log(np.arange(1, lambda_ + 1))\n            weights = weights / np.sum(weights)\n\n            B = None\n            D = None\n            \n            eval_count = 0\n            \n            while eval_count < self.budget // self.restarts:\n                # Sample population\n                z = np.random.randn(self.dim, lambda_)\n                if B is None or D is None: # First time\n                    x = mu.reshape(-1, 1) + self.sigma * z\n                else:\n                    x = mu.reshape(-1, 1) + self.sigma * B @ (D * z)\n                \n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = np.array([func(x[:, i]) for i in range(lambda_)])\n                eval_count += lambda_\n                \n                # Sort by fitness\n                idx = np.argsort(f)\n                x = x[:, idx]\n                f = f[idx]\n                \n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[:, 0]\n\n                # Update distribution parameters\n                mu_old = mu.copy()\n                mu = np.sum(weights.reshape(-1, 1) * x[:, :lambda_], axis=1)\n\n                z = (mu - mu_old) / self.sigma\n\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mu_eff) * B @ z\n                \n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * eval_count / lambda_)) < (1.4 + 2 / (self.dim + 1))\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c) * mu_eff) * z\n\n                C = (1 - c_1 - c_mu) * C + c_1 * (pc.reshape(-1, 1) @ pc.reshape(1, -1) + (1 - hsig) * c_1 * C)\n                C += c_mu * np.sum(weights.reshape(-1, 1, 1) * (x[:, :lambda_] - mu_old.reshape(-1, 1)).reshape(self.dim, lambda_, 1) @ (x[:, :lambda_] - mu_old.reshape(-1, 1)).reshape(self.dim, lambda_, 1).transpose(0, 2, 1), axis=0)\n\n                self.sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps) / np.sqrt(self.dim) - 1))\n\n                # Eigen decomposition to update B and D\n                C = np.triu(C) + np.triu(C, 1).T  # Enforce symmetry\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(np.maximum(D, 1e-16)) # Avoid negative or zero eigenvalues\n\n                if eval_count >= self.budget // self.restarts:\n                  break\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ce334088-2525-47e8-9d6a-fed143f5f8cd", "parents": ["03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "An evolutionary strategy with self-adaptive step sizes, combined with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, tau=None, tau_prime=None, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.tau = tau or (1 / np.sqrt(2 * self.dim))\n        self.tau_prime = tau_prime or (1 / np.sqrt(2 * np.sqrt(self.dim)))\n        self.restart_trigger = restart_trigger\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.individuals = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.sigmas = np.random.uniform(0.1, 1.0, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n        self.restart_counter = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.pop_size):\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.individuals[i])\n                    self.eval_count += 1\n                else:\n                    break\n\n            # Update best solution\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.individuals[i].copy()\n                    self.restart_counter = 0 # Reset counter after improvement\n\n            # Check for restart condition\n            self.restart_counter += 1\n            if self.restart_counter > self.restart_trigger:\n                # Restart: Reinitialize population\n                self.individuals = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.sigmas = np.random.uniform(0.1, 1.0, size=(self.pop_size, self.dim))\n                self.fitness = np.full(self.pop_size, np.inf)\n                self.restart_counter = 0\n\n            # Create offspring\n            offsprings = self.individuals.copy()\n            offspring_sigmas = self.sigmas.copy()\n\n            for i in range(self.pop_size):\n                # Mutate step sizes\n                global_mutation = np.exp(self.tau_prime * np.random.normal(0, 1))\n                local_mutation = np.exp(self.tau * np.random.normal(0, 1, size=self.dim))\n                offspring_sigmas[i] = self.sigmas[i] * global_mutation * local_mutation\n                offspring_sigmas[i] = np.clip(offspring_sigmas[i], 0.0001, 1.0) # Prevent sigma from being too small\n\n                # Mutate individuals\n                offsprings[i] = self.individuals[i] + offspring_sigmas[i] * np.random.normal(0, 1, size=self.dim)\n                offsprings[i] = np.clip(offsprings[i], self.lb, self.ub)\n\n            # Selection: Replace parents with offspring\n            self.individuals = offsprings\n            self.sigmas = offspring_sigmas\n\n        return self.f_opt, self.x_opt", "objective": -0.25478, "other_inf": null}
{"id": "c9e5fbe6-3783-4767-be4e-f2d0b89c8509", "parents": ["cba8b940-caf8-4f97-bf72-32d313b0e8c3"], "algorithm": "This algorithm employs a differential evolution strategy with a self-adaptive mutation factor and a population-wide archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, cr=0.9, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.archive_size = archive_size\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                        if np.random.rand() < 0.1:\n                            idx_to_replace = np.random.randint(self.archive_size)\n                            self.archive[idx_to_replace] = self.population[i]\n\n            # Adapt mutation factor (simple adaptation)\n            if np.random.rand() < 0.1:\n                self.F = np.random.uniform(0.3, 0.7)  # Adjust F stochastically\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.59269, "other_inf": null}
{"id": "839abc27-a9c2-48b5-9940-82cc031b8c6a", "parents": ["ff130c4f-0ee4-4d89-8c5b-5799279139dc"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget adaptation to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.2, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        self.mu = int(dim / 2)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (dim + self.mueff + 5)\n        self.damps = 1 + 2*np.max([0, np.sqrt((self.mueff-1)/(dim+1)) - 1]) + self.cs\n        self.ccov1 = (1/self.mueff) * np.min([1, (2*(self.mueff-2+1/self.mueff)) / ((dim+2.3)**2 + self.mueff-2+1/self.mueff)])\n        self.ccovmu = np.min([1-self.ccov1, 2 * (self.mueff-2+1/self.mueff) / ((dim+2.0)**2 + self.mueff)])\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        used_budget = 0\n\n        for restart in range(self.restarts):\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            B = np.eye(self.dim)\n            D = np.ones(self.dim)\n            C = B @ np.diag(D**2) @ B.T\n\n            while used_budget < self.budget:\n                N = self.mu * 4\n                z = np.random.normal(0, 1, size=(self.dim, N))\n                x = mean[:, None] + sigma * (B @ (D * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                f = np.array([func(x[:, i]) for i in range(N)])\n                used_budget += N\n\n                idx = np.argsort(f)\n                x_sorted = x[:, idx]\n                f_sorted = f[idx]\n\n                mean_new = x_sorted[:, :self.mu] @ self.weights\n                z_mean = np.mean(z[:, idx[:self.mu]], axis=1)\n                ps = (1-self.cs) * ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * (B @ z_mean)\n                hsig = (np.linalg.norm(ps)/np.sqrt(1-(1-self.cs)**(2*(used_budget/N))) / self.chiN) < (1.4 + 2/(self.dim+1))\n                pc = (1-1) * pc + hsig * np.sqrt(1) * (mean_new - mean) / sigma\n\n                artmp = (1/sigma) * ((x_sorted[:, :self.mu] - mean) @ np.diag(self.weights))\n                C = (1-self.ccov1-self.ccovmu) * C + self.ccov1 * (pc[:,None] @ pc[None,:]) + self.ccovmu * artmp @ artmp.T\n\n                mean = mean_new\n                sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(ps)/self.chiN - 1))\n\n                try:\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(np.real(D))\n                    C = B @ np.diag(D**2) @ B.T\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim)  # Reset C if it becomes ill-conditioned\n                    D = np.ones(self.dim)\n                    B = np.eye(self.dim)\n                    sigma = self.sigma0\n\n                if f_sorted[0] < self.f_opt:\n                    self.f_opt = f_sorted[0]\n                    self.x_opt = x_sorted[:, 0]\n                if used_budget >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4cddecc7-dfe4-4f4c-b15f-4e56c0e7ce51", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to generate new candidate solutions, aiming to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, c_s=0.3, d_s=1.0, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma  # Step size\n        self.c_s = c_s      # Learning rate for cumulation for step size\n        self.d_s = d_s      # Damping for step size\n        self.c_cov = c_cov  # Learning rate for covariance matrix adaptation\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.p_s = np.zeros(self.dim)  # Evolution path for step size\n        self.p_c = np.zeros(self.dim)  # Evolution path for covariance matrix\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate lambda offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.mean(x[:self.pop_size // 2], axis=0)\n            \n            # Update evolution path for step size\n            self.p_s = (1 - self.c_s) * self.p_s + np.sqrt(self.c_s * (2 - self.c_s)) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ (self.mean - mean_old)) / self.sigma\n            \n            # Update step size\n            self.sigma *= np.exp((self.c_s / self.d_s) * (np.linalg.norm(self.p_s) / np.sqrt(self.dim) - 1))\n\n            # Update evolution path for covariance matrix\n            self.p_c = (1 - self.c_cov) * self.p_c + np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.mean - mean_old) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (np.outer(self.p_c, self.p_c) + self.c_cov * np.eye(self.dim))\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fe114544-bad2-4b10-a7b0-23c8bb32b635", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "A gradient-free optimization algorithm that estimates the gradient using simplex-based exploration and adapts the step size based on the estimated gradient norm and function value changes.", "code": "import numpy as np\n\nclass SimplexGradientDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, simplex_size=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.simplex_size = simplex_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f_x = func(x)\n        self.f_opt = f_x\n        self.x_opt = x\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Create simplex\n            simplex_points = [x]\n            for i in range(self.dim):\n                d = np.zeros(self.dim)\n                d[i] = self.simplex_size\n                x_new = x + d\n                x_new = np.clip(x_new, self.lb, self.ub)\n                simplex_points.append(x_new)\n\n            # Evaluate simplex points\n            simplex_values = []\n            for p in simplex_points:\n                simplex_values.append(func(p))\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            if eval_count >= self.budget:\n                break\n\n            # Estimate gradient\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                gradient[i] = (simplex_values[i+1] - simplex_values[0]) / self.simplex_size\n\n            # Update position\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                x_new = x - self.step_size * gradient / gradient_norm\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                eval_count += 1\n\n                if f_new < f_x:\n                    x = x_new\n                    f_x = f_new\n                    self.step_size *= 1.1  # Increase step size if successful\n                else:\n                    self.step_size *= 0.5  # Decrease step size if unsuccessful\n\n                if f_x < self.f_opt:\n                    self.f_opt = f_x\n                    self.x_opt = x\n\n                if eval_count >= self.budget:\n                    break\n            else:\n                #Randomly move the current x\n                x_new = x + np.random.uniform(-self.step_size, self.step_size, self.dim)\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                eval_count += 1\n                if f_new < f_x:\n                    x = x_new\n                    f_x = f_new\n                \n                if f_x < self.f_opt:\n                    self.f_opt = f_x\n                    self.x_opt = x\n\n\n        return self.f_opt, self.x_opt", "objective": -0.18057, "other_inf": null}
{"id": "b4662b83-7dfd-48fc-aa61-20a3d1143824", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "An algorithm employing a Gaussian process surrogate model to guide the search, iteratively identifying promising regions and refining the model with new function evaluations.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n\n        self.X = np.random.uniform(self.lb, self.ub, size=(n_initial, dim))\n        self.y = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n    def acquisition(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - self.exploration_weight * sigma\n\n    def __call__(self, func):\n        self.y = np.array([func(xi) for xi in self.X])\n        self.eval_count += self.n_initial\n        \n        best_idx = np.argmin(self.y)\n        if self.y[best_idx] < self.f_opt:\n            self.f_opt = self.y[best_idx]\n            self.x_opt = self.X[best_idx]\n\n        while self.eval_count < self.budget:\n            self.gp.fit(self.X, self.y)\n            \n            # Generate candidate points (simple random sampling)\n            X_candidate = np.random.uniform(self.lb, self.ub, size=(100, self.dim))\n            \n            # Select the best candidate based on acquisition function\n            acquisitions = np.array([self.acquisition(x, self.gp) for x in X_candidate])\n            best_candidate_idx = np.argmin(acquisitions)\n            x_new = X_candidate[best_candidate_idx]\n\n            # Evaluate the new point\n            y_new = func(x_new)\n            self.eval_count += 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, y_new)\n\n            if y_new < self.f_opt:\n                self.f_opt = y_new\n                self.x_opt = x_new\n                \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4e261841-457e-4d6d-821c-e900f1b077ae", "parents": ["03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "A single-point search algorithm that combines a Gaussian mutation with a step size adaptation based on a success rate, and restarts the search when it stagnates.", "code": "import numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_threshold=0.2, stagnation_tolerance=1000):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = initial_step_size\n        self.success_threshold = success_threshold\n        self.stagnation_tolerance = stagnation_tolerance\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = np.inf\n        self.eval_count = 0\n        self.success_count = 0\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        self.f_opt = func(self.x_opt)\n        self.eval_count += 1\n\n        while self.eval_count < self.budget:\n            # Generate a mutated candidate using Gaussian mutation\n            x_candidate = self.x_opt + self.step_size * np.random.normal(0, 1, self.dim)\n            x_candidate = np.clip(x_candidate, self.lb, self.ub)\n            \n            f_candidate = func(x_candidate)\n            self.eval_count += 1\n\n            if f_candidate < self.f_opt:\n                self.f_opt = f_candidate\n                self.x_opt = x_candidate\n                self.success_count += 1\n                self.stagnation_count = 0  # Reset stagnation counter\n            else:\n                self.stagnation_count += 1\n\n            # Adjust step size based on success rate\n            if self.eval_count % 100 == 0:\n                success_rate = self.success_count / 100\n                if success_rate > self.success_threshold:\n                    self.step_size *= 1.1  # Increase step size if success rate is high\n                else:\n                    self.step_size *= 0.9  # Decrease step size if success rate is low\n                self.success_count = 0  # Reset success counter\n                self.step_size = np.clip(self.step_size, 1e-6, 1.0)  # Ensure step size stays within reasonable bounds\n\n            # Restart search if stagnated\n            if self.stagnation_count > self.stagnation_tolerance:\n                self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n                self.f_opt = func(self.x_opt)\n                self.eval_count += 1\n                self.stagnation_count = 0  # Reset stagnation counter\n                self.step_size = 1.0\n\n        return self.f_opt, self.x_opt", "objective": -0.52118, "other_inf": null}
{"id": "5af3be26-93bc-49ff-8c12-f40e43a86323", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509", "c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_factor=0.95, temp_adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_factor = cooling_factor\n        self.temp_adaptation_rate = temp_adaptation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n        temperature = self.initial_temp\n        acceptance_rate = 0.0\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n            x_new = np.clip(x_new, lb, ub)  # Clip to bounds\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                x = x_new\n                f = f_new\n                acceptance_rate +=1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Adaptive temperature schedule\n            if self.budget % 100 == 0:\n              acceptance_rate = acceptance_rate / 100.0\n              if acceptance_rate > 0.6:\n                  temperature *= (1 + self.temp_adaptation_rate)\n              elif acceptance_rate < 0.4:\n                  temperature *= (1 - self.temp_adaptation_rate)\n              temperature = max(1e-6, temperature * self.cooling_factor)\n              acceptance_rate = 0.0\n\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.25663, "other_inf": null}
{"id": "a9551d61-ce54-4f92-898f-b86debe3a642", "parents": ["03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a", "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "Evolves a population of solutions using differential evolution principles, incorporating a restart mechanism to escape local optima and enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.x[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.x[i].copy()\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.x[a] + self.F * (self.x[b] - self.x[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = self.x[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.x[i] = trial.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n            # Restart mechanism\n            for i in range(self.pop_size):\n                if np.random.rand() < self.restart_prob:\n                    self.x[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    self.fitness[i] = func(self.x[i])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.x[i].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "10bee58a-0f24-49c2-8ce4-3d29f1d85ffc", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "Simulated Annealing with adaptive temperature and re-annealing based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, min_temp=1e-5, step_size=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n        self.step_size = step_size\n        self.stagnation_threshold = stagnation_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        self.eval_count = 1\n        self.current_x = self.x_opt.copy()\n        self.current_f = self.f_opt\n        self.temperature = self.initial_temp\n        self.stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            neighbor_x = self.current_x + np.random.normal(0, self.step_size, self.dim)\n            neighbor_x = np.clip(neighbor_x, self.lb, self.ub)\n            neighbor_f = func(neighbor_x)\n            self.eval_count += 1\n\n            # Acceptance probability\n            delta_f = neighbor_f - self.current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temperature):\n                self.current_x = neighbor_x\n                self.current_f = neighbor_f\n\n                if neighbor_f < self.f_opt:\n                    self.f_opt = neighbor_f\n                    self.x_opt = neighbor_x\n                    self.stagnation_counter = 0 # Reset stagnation counter\n\n            else:\n                self.stagnation_counter += 1\n\n            # Temperature update\n            self.temperature *= self.cooling_rate\n            self.temperature = max(self.temperature, self.min_temp)\n\n            # Re-annealing if stagnated\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.temperature = self.initial_temp  # Reset temperature\n                self.current_x = np.random.uniform(self.lb, self.ub, self.dim)  # Restart from a new random point\n                self.current_f = func(self.current_x)\n                self.eval_count += 1\n                self.stagnation_counter = 0\n                if self.current_f < self.f_opt:\n                  self.f_opt = self.current_f\n                  self.x_opt = self.current_x\n        return self.f_opt, self.x_opt", "objective": -0.30902, "other_inf": null}
{"id": "b599afa5-dbdd-4871-a2f7-b6538bcd0a65", "parents": ["03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "A gradient-free optimization algorithm that uses a simplex of points which iteratively adapts its shape and size based on the function values at the vertices, converging towards the optimum by reflecting, expanding, contracting, or shrinking the simplex.", "code": "import numpy as np\n\nclass NelderMead:\n    def __init__(self, budget=10000, dim=10, alpha=1, beta=0.5, gamma=2):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha  # Reflection coefficient\n        self.beta = beta    # Contraction coefficient\n        self.gamma = gamma   # Expansion coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize simplex\n        simplex = np.random.uniform(self.lb, self.ub, size=(self.dim + 1, self.dim))\n        fitness = np.array([func(x) for x in simplex])\n        self.eval_count += self.dim + 1\n\n        while self.eval_count < self.budget:\n            # Order the simplex points by fitness\n            order = np.argsort(fitness)\n            simplex = simplex[order]\n            fitness = fitness[order]\n\n            best_x = simplex[0]\n            best_f = fitness[0]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected_point = centroid + self.alpha * (centroid - simplex[-1])\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            reflected_f = func(reflected_point)\n            self.eval_count += 1\n\n            if reflected_f < fitness[0]:\n                # Expansion\n                expanded_point = centroid + self.gamma * (reflected_point - centroid)\n                expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                expanded_f = func(expanded_point)\n                self.eval_count += 1\n\n                if expanded_f < reflected_f:\n                    simplex[-1] = expanded_point\n                    fitness[-1] = expanded_f\n                else:\n                    simplex[-1] = reflected_point\n                    fitness[-1] = reflected_f\n\n            elif reflected_f < fitness[-2]:\n                simplex[-1] = reflected_point\n                fitness[-1] = reflected_f\n            else:\n                # Contraction\n                contracted_point = centroid + self.beta * (simplex[-1] - centroid)\n                contracted_point = np.clip(contracted_point, self.lb, self.ub)\n                contracted_f = func(contracted_point)\n                self.eval_count += 1\n\n                if contracted_f < fitness[-1]:\n                    simplex[-1] = contracted_point\n                    fitness[-1] = contracted_f\n                else:\n                    # Shrink\n                    for i in range(1, self.dim + 1):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n                        fitness[i] = func(simplex[i])\n                        self.eval_count += 1\n                        \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "df11253d-441f-4907-9da1-0a30c27864af", "parents": ["cba8b940-caf8-4f97-bf72-32d313b0e8c3", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "# Description: This algorithm uses a population-based approach with a combination of global and local search strategies, employing a Cauchy mutation for exploration and a gradient-based step for exploitation, adaptively adjusting their contributions.\n# Code: \n```", "code": "import numpy as np\n\nclass HybridCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, cauchy_scale=1.0, grad_step_size=0.01, local_search_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cauchy_scale = cauchy_scale\n        self.grad_step_size = grad_step_size\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Global Search (Cauchy Mutation)\n                cauchy_step = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = self.population[i] + cauchy_step\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Local Search (Gradient-based step)\n                if np.random.rand() < self.local_search_prob:\n                    # Estimate Gradient (simple finite difference)\n                    grad = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus = self.population[i].copy()\n                        x_minus = self.population[i].copy()\n                        delta = 1e-4\n                        x_plus[j] += delta\n                        x_minus[j] -= delta\n                        x_plus = np.clip(x_plus, self.lb, self.ub)\n                        x_minus = np.clip(x_minus, self.lb, self.ub)\n\n                        grad[j] = (func(x_plus) - func(x_minus)) / (2 * delta)\n                        eval_count += 2 # account for extra function evaluations in gradient estimation\n                        if eval_count >= self.budget:\n                            break\n\n                    if eval_count >= self.budget:\n                        break\n\n                    mutant = self.population[i] - self.grad_step_size * grad\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n\n                # Selection\n                f = func(mutant)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = mutant\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = mutant\n\n            # Adaptive Cauchy Scale (adjusting exploration)\n            if np.random.rand() < 0.1:\n                 self.cauchy_scale = np.clip(self.cauchy_scale * np.random.uniform(0.8, 1.2), 0.1, 2.0)\n\n            if eval_count >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "220ebf8f-d620-4295-944e-d1fb44e2bfd3", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "# Description: An enhanced Differential Evolution strategy incorporating a self-adaptive mutation factor based on the ranking of solutions and a probabilistic crossover to improve exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass RankAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Rank the population based on fitness\n            ranked_indices = np.argsort(self.fitness)\n            ranked_population = self.population[ranked_indices]\n\n            for i in range(self.pop_size):\n                # Adaptive Mutation Factor based on rank\n                rank = np.where(ranked_indices == i)[0][0]\n                F = 0.1 + 0.9 * (rank / (self.pop_size - 1))  # F scales linearly with rank\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = ranked_population[a] + F * (ranked_population[b] - ranked_population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.54622, "other_inf": null}
{"id": "8cabe369-559b-425e-88cb-7de5d1f75ea4", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "# Description: This algorithm employs a self-adaptive Differential Evolution with a pool of mutation strategies and adaptive selection probabilities based on their recent performance.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n        # Mutation strategies pool\n        self.mutation_strategies = [\n            lambda a, b, c: a + F * (b - c),\n            lambda a, b, c, d, e: a + F * (b - c) + F * (d - e),\n            lambda x_best, a, x: x_best + F * (a - x)\n        ]\n        self.num_strategies = len(self.mutation_strategies)\n        self.selection_probabilities = np.ones(self.num_strategies) / self.num_strategies\n        self.memory_F = np.ones(self.num_strategies) * F\n        self.memory_CR = np.ones(self.num_strategies) * CR\n        self.success_history_F = []\n        self.success_history_CR = []\n        self.archive = []\n        self.archive_size = int(self.pop_size*0.2)\n\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Strategy Selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.selection_probabilities)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n\n                # Parameter Adaptation\n                F = np.random.normal(self.memory_F[strategy_index], 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.random.normal(self.memory_CR[strategy_index], 0.1)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                np.random.shuffle(idxs)\n                if strategy_index == 0:\n                    a, b, c = idxs[:3]\n                    mutant = mutation_strategy(self.population[a], self.population[b], self.population[c])\n                elif strategy_index == 1:\n                    a, b, c, d, e = idxs[:5]\n                    mutant = mutation_strategy(self.population[a], self.population[b], self.population[c], self.population[d], self.population[e])\n                else:\n                    x_best_idx = np.argmin(self.fitness)\n                    a, x = idxs[:2]\n                    mutant = mutation_strategy(self.population[x_best_idx], self.population[a], self.population[i])\n\n                if len(self.archive) > 0:\n                   a = np.random.randint(0, len(self.archive))\n                   mutant = self.population[i] + F * (self.x_opt - self.population[i]) + F * (self.population[a] - self.population[i])\n                \n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    delta_f = abs(f - self.fitness[i])\n                    self.success_history_F.append(F)\n                    self.success_history_CR.append(CR)\n\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                        rand_idx = np.random.randint(0, self.archive_size)\n                        self.archive[rand_idx] = self.population[i]\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n\n            # Update Selection Probabilities (only after a few iterations)\n            if len(self.success_history_F) > self.pop_size :\n                if np.std(self.success_history_F) > 0 and np.std(self.success_history_CR) > 0 :\n                    self.memory_F[strategy_index] = np.mean(self.success_history_F)\n                    self.memory_CR[strategy_index] = np.mean(self.success_history_CR)\n\n                    success_counts = np.zeros(self.num_strategies)\n                    for k in range(len(self.mutation_strategies)):\n                         success_counts[k] = len([i for i in range(len(self.success_history_F)) if (self.success_history_F[i] == self.memory_F[k]) and  (self.success_history_CR[i] == self.memory_CR[k]) ])\n\n                    sum_success = np.sum(success_counts)\n                    if sum_success > 0:\n                        self.selection_probabilities = success_counts / sum_success\n                    else:\n                        self.selection_probabilities = np.ones(self.num_strategies) / self.num_strategies\n\n                self.success_history_F = []\n                self.success_history_CR = []\n        return self.f_opt, self.x_opt", "objective": -0.33029, "other_inf": null}
{"id": "3960957a-d1d6-4784-8e35-cc43cff7e3d2", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "'maxiter': self.nm_iterations, 'maxfev': self.budget - eval_count, 'xatol': 1e-4, 'fatol': 1e-4, 'adaptive':True, 'initial_simplex': np.random.uniform(self.lb, self.ub, (self.dim + 1, self.dim))", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, nm_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.nm_iterations = nm_iterations\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    # Nelder-Mead refinement\n                    result = minimize(func, trial, method='Nelder-Mead',\n                                    options={'maxiter': self.nm_iterations, 'maxfev': self.budget - eval_count, 'xatol': 1e-4, 'fatol': 1e-4, 'adaptive':True, 'initial_simplex': np.random.uniform(self.lb, self.ub, (self.dim + 1, self.dim))}) # Adding initial simplex\n                    \n                    if result.success:\n                        f_nm = result.fun\n                        x_nm = result.x\n                        \n                        eval_count += result.nfev # Account for NM function evaluations\n\n                        if f_nm < self.fitness[i]:\n                            self.fitness[i] = f_nm\n                            self.population[i] = x_nm\n                            \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "5a48bc5b-9ca0-4c87-9808-08ce234d6af8", "parents": ["cba8b940-caf8-4f97-bf72-32d313b0e8c3"], "algorithm": "This algorithm uses a differential evolution strategy with adaptive mutation and crossover rates based on the success rate of previous generations, aiming for a self-adjusting balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = [F] * 10\n        self.memory_CR = [CR] * 10\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Adaptive F and CR\n                F = self.memory_F[self.memory_index]\n                CR = self.memory_CR[self.memory_index]\n                \n                mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, lb, ub)\n                \n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_CR.append(CR)\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Update memory of F and CR\n            if self.success_F:\n                self.memory_F[self.memory_index] = np.mean(self.success_F)\n                self.memory_CR[self.memory_index] = np.mean(self.success_CR)\n                self.success_F = []\n                self.success_CR = []\n            \n            self.memory_index = (self.memory_index + 1) % 10\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.73603, "other_inf": null}
{"id": "bc85a84c-5a60-4d8c-b870-3ba2061cc767", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "This algorithm uses a variant of particle swarm optimization (PSO) with velocity clamping and constriction factor to balance exploration and exploitation, and adaptive inertia weight adjustment based on swarm diversity.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.2, c1=2.0, c2=2.0, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_ratio = v_max_ratio\n        self.global_best_fitness = np.inf\n        self.global_best_position = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        v_max = self.v_max_ratio * (ub - lb)\n        self.velocities = np.random.uniform(-v_max, v_max, size=(self.pop_size, self.dim))\n\n        # Initialize personal best positions and fitnesses\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_fitnesses = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        best_index = np.argmin(self.personal_best_fitnesses)\n        self.global_best_fitness = self.personal_best_fitnesses[best_index]\n        self.global_best_position = np.copy(self.personal_best_positions[best_index])\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        # Constriction factor\n        phi = self.c1 + self.c2\n        if phi > 4:\n            K = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n        else:\n            K = 1  # No constriction\n\n        while self.budget > 0:\n            # Calculate swarm diversity (variance of positions)\n            diversity = np.mean(np.var(self.population, axis=0))\n\n            # Adjust inertia weight based on diversity\n            w = self.w_max - (self.w_max - self.w_min) * diversity\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = K * (w * self.velocities[i] +\n                                           self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                                           self.c2 * r2 * (self.global_best_position - self.population[i]))\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], lb, ub)\n\n                # Evaluate fitness\n                fitness = func(self.population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = np.copy(self.population[i])\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.population[i])\n                        self.f_opt = self.global_best_fitness\n                        self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.45477, "other_inf": null}
{"id": "297bec98-85c0-470c-96e4-0ff41a41a6f5", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, c_cov_rank_one=None, c_cov_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n        # Strategy parameter setting: Adaptation\n        self.cs = cs  # Cumulation for sigma (damping)\n        self.damps = damps  # Damping for sigma usually close to 1\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / (self.dim + 1.4)**2\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else min(1, 2 * (self.pop_size - 2 + 1) / (self.dim + 2)**2)  # Assuming mu = pop_size/2\n\n        # Initialize dynamic (internal) strategy parameters and constants\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_cov = (1 / self.mueff) * (self.c_cov_rank_one + (1 - self.c_cov_rank_one) * self.c_cov_mu)\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n        self.chiN = self.dim**0.5 * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Generate and evaluate lambda offspring\n            z = np.random.randn(self.dim, self.pop_size)\n            y = self.B.dot(self.D * z)\n            x = self.m + self.sigma * y\n            x = np.clip(x, self.lb, self.ub)\n            fitness = np.array([func(xi) for xi in x.T])\n            eval_count += self.pop_size\n\n            # Sort by fitness and update mean\n            arindex = np.argsort(fitness)\n            fitness = fitness[arindex]\n            x = x[:, arindex]\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n\n            # Cumulation\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * self.invsqrtC.dot(xmean - self.m) / self.sigma\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * eval_count / self.pop_size)) < (2 + self.mueff) / (self.dim + 2)\n            self.pc = (1 - self.c_sigma) * self.pc + hsig * np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (xmean - self.m) / self.sigma\n\n            # Adapt covariance matrix\n            artmp = (1 / self.sigma) * (x[:, :self.mu] - self.m[:, np.newaxis])\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_mu) * self.C + self.c_cov_rank_one * (self.pc[:, np.newaxis].dot(self.pc[np.newaxis, :])) + self.c_cov_mu * artmp.dot(np.diag(self.weights)).dot(artmp.T)\n\n            # Adapt step size sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Update B and D from C\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.D, self.B = np.linalg.eig(self.C)\n            self.D = np.sqrt(self.D.real)\n            self.B = np.real(self.B)\n\n            self.invsqrtC = np.dot(self.B, np.dot(np.diag(self.D**-1), self.B.T))\n\n            # Update mean value\n            self.m = xmean\n\n            # Track best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "be976120-ebb7-41d1-9eb6-508d0c477bf9", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adapt the search distribution and efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, ccov=0.1, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.ccov = ccov\n        self.mu = int(self.pop_size * mu_ratio)\n        self.weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = self.ccov * (self.mueff + 2) / ((self.dim + 2)**2 + self.mueff)\n        self.cmu = min(1-self.c1, self.ccov * (self.mueff - 1) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            Z = np.random.normal(0, 1, size=(self.dim, self.pop_size))\n            X = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), Z)\n            X = np.clip(X, lb, ub)\n            \n            fitness = np.array([func(x) for x in X.T])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[:, idx]\n            \n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[:, 0]\n\n            # Update CMA-ES parameters\n            xmean = np.sum(X[:, :self.mu] * self.weights[np.newaxis, :self.mu], axis=1)\n            y = (xmean - self.mean) / self.sigma\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), y)\n            self.mean = xmean\n            \n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.cs)**(2*self.budget/self.pop_size))/self.chiN < 1.4 + 2/(self.dim+1)\n            self.p_c = (1 - self.cc) * self.p_c + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y\n            \n            artmp = (1/self.sigma) * (X[:, :self.mu] - self.mean[:, np.newaxis])\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.p_c, self.p_c) + (1-hsig) * self.cc*(2-self.cc) * self.C) + self.cmu * np.dot(artmp, np.dot(np.diag(self.weights[:self.mu]), artmp.T))\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n\n            # Repair covariance matrix\n            if np.any(np.isnan(self.C)) or np.any(np.isinf(self.C)):\n                self.C = np.eye(self.dim)\n            \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "364fba0c-48ef-498d-88ba-d6b13b7d588a", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "This algorithm implements a variant of Particle Swarm Optimization (PSO) with velocity clamping and dynamic inertia weight adjustment to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2, c2=2, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight maximum\n        self.w_min = w_min  # Inertia weight minimum\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max # Velocity clamping\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.personal_best_fitness)\n        self.f_opt = self.personal_best_fitness[best_index]\n        self.x_opt = self.personal_best_positions[best_index]\n        self.global_best_position = np.copy(self.personal_best_positions[best_index])\n\n        while self.budget > 0:\n            # Dynamic inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / (self.budget + self.pop_size))  # Linearly decreasing\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)  # Clamp velocity\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n                # Evaluate fitness\n                f = func(self.particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.particles[i]\n                        self.global_best_position = np.copy(self.particles[i])\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.56558, "other_inf": null}
{"id": "11d13ee6-c768-4705-91d5-40d61bbfcd8b", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "5a48bc5b-9ca0-4c87-9808-08ce234d6af8"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random perturbation of the current solution.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, perturbation_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.perturbation_scale = perturbation_scale\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        temp = self.initial_temp\n\n        while eval_count < self.budget:\n            # Generate a neighbor by perturbing the current solution\n            x_new = self.x_opt + np.random.normal(0, self.perturbation_scale, self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            # Acceptance criterion\n            delta_e = f_new - self.f_opt\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                self.x_opt = x_new\n                self.f_opt = f_new\n                # Adjust perturbation scale if improvement is consistent\n                if delta_e < 0:\n                    self.perturbation_scale *= 1.05  # Increase for faster exploration\n            else:\n                self.perturbation_scale *= 0.95 #Decrease when there is no good exploration\n\n            #Cooling Schedule\n            temp *= self.cooling_rate\n\n            self.perturbation_scale = np.clip(self.perturbation_scale, 0.01, 1.0)\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.3228, "other_inf": null}
{"id": "68fc618a-9f0d-4a18-ada7-d365c368aff4", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509", "03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "This algorithm employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by predicting promising regions and adaptively updating the model with new evaluations.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X = None\n        self.y = None\n        self.gp = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def acquisition_function(self, x, xi=1.0):\n        \"\"\"Exploration-exploitation balance.\"\"\"\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - xi * sigma\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.eval_count += self.n_initial_samples\n        \n        best_index = np.argmin(y_init)\n        if y_init[best_index] < self.f_opt:\n            self.f_opt = y_init[best_index]\n            self.x_opt = X_init[best_index]\n            \n        self.X = X_init\n        self.y = y_init\n\n        # Gaussian process regression\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n        self.gp.fit(self.X, self.y)\n\n        # Optimization loop\n        while self.eval_count < self.budget:\n            # Find next point to evaluate using acquisition function\n            from scipy.optimize import minimize\n            \n            def acquisition(x):\n                return self.acquisition_function(x)\n            \n            bounds = [(self.lb, self.ub)] * self.dim\n            \n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            res = minimize(acquisition, x0, method=\"L-BFGS-B\", bounds=bounds) # L-BFGS-B or SLSQP or trust-constr\n            x_new = res.x\n                \n            # Evaluate the function at the new point\n            f_new = func(x_new)\n            self.eval_count += 1\n            \n            #Update best solution found so far\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            # Update the Gaussian process model\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n            self.gp.fit(self.X, self.y)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c7ee837c-0e7d-4a8d-925f-55d91db52402", "parents": ["5a48bc5b-9ca0-4c87-9808-08ce234d6af8", "c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "Simulated Annealing with adaptive temperature based on the acceptance rate of new solutions, promoting exploration at higher temperatures and exploitation at lower temperatures.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp = initial_temp\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.x_opt = x\n        self.f_opt = f\n\n        acceptance_rate = 0.0\n        num_accepted = 0\n\n        while self.budget > 0 and self.temp > 1e-6:\n            x_new = x + np.random.normal(0, 0.1, self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                num_accepted += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                probability = np.exp(-delta_f / self.temp)\n                if np.random.rand() < probability:\n                    x = x_new\n                    f = f_new\n                    num_accepted += 1\n\n            acceptance_rate = num_accepted / (100) if self.budget % 100 == 0 else acceptance_rate #update acceptance rate every 100 iterations\n\n\n            if self.budget % 100 == 0: # Adjust cooling rate\n                if acceptance_rate > 0.7:\n                    self.cooling_rate *= 0.99  # Reduce cooling if accepting too much\n                elif acceptance_rate < 0.3:\n                    self.cooling_rate /= 0.99  # Increase cooling if accepting too little\n\n                self.temp *= self.cooling_rate\n                num_accepted = 0\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.32137, "other_inf": null}
{"id": "92c2eebf-5836-4c26-8fbf-e985a42969a5", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "5a48bc5b-9ca0-4c87-9808-08ce234d6af8"], "algorithm": "A population-based algorithm that uses a Gaussian Mixture Model (GMM) to learn the distribution of promising solutions and samples new solutions from the learned GMM.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GMMOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Select top performers\n            top_indices = np.argsort(self.fitness)[:self.pop_size // 2]\n            top_solutions = self.population[top_indices]\n\n            # Learn GMM from top solutions\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)\n            gmm.fit(top_solutions)\n\n            # Sample new solutions from GMM\n            new_solutions = gmm.sample(self.pop_size)[0]\n            new_solutions = np.clip(new_solutions, self.lb, self.ub)\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in new_solutions])\n            eval_count += self.pop_size\n\n            # Update population\n            worst_index = np.argmax(self.fitness)\n            self.population[worst_index] = new_solutions[np.argmin(new_fitness)]\n            self.fitness[worst_index] = np.min(new_fitness)\n\n            # Update optimal solution\n            if np.min(new_fitness) < self.f_opt:\n                self.f_opt = np.min(new_fitness)\n                self.x_opt = new_solutions[np.argmin(new_fitness)]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9bf81b80-ad1a-4113-bdfd-1d426101aff6", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "# Description: A population-based search algorithm that combines elements of particle swarm optimization and covariance matrix adaptation evolution strategy, adaptively adjusting search parameters based on the population's diversity and fitness improvements.\n# Code:\n```", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.5, c2=1.5, cs=0.3, damps=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.cs = cs\n        self.damps = damps\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n        self.mu_eff = self.pop_size / 4\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Generate new population using PSO and CMA-ES inspired components\n            for i in range(self.pop_size):\n                # PSO Component\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                personal_best = self.population[np.argmin(self.fitness)] #Simple Personal Best\n                global_best = self.x_opt\n                \n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                      self.c1 * r1 * (personal_best - self.population[i]) +\n                                      self.c2 * r2 * (global_best - self.population[i]))\n                \n                self.population[i] += self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n            #CMA-ES component\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, self.pop_size)\n            for i in range(self.pop_size):\n                self.population[i] = self.mean + self.sigma * z[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n            new_fitness = np.array([func(x) for x in self.population])\n            eval_count += self.pop_size\n            \n            if eval_count > self.budget:\n                self.population = self.population[:self.budget - (eval_count - self.pop_size)]\n                new_fitness = new_fitness[:self.budget - (eval_count - self.pop_size)]\n                eval_count = self.budget\n            \n            # Selection and Update\n            for i in range(len(new_fitness)):\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    #self.population[i] = trial\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = self.population[i]\n\n            # CMA-ES Adaptation (Simplified)\n            delta = (self.x_opt - self.mean) / self.sigma\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * delta\n            self.C = (1 - self.cs) * self.C + self.cs * np.outer(self.p_sigma, self.p_sigma)\n\n            self.mean = self.x_opt\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n            self.sigma = np.clip(self.sigma, 1e-6, 1)\n\n            # Adaptive Inertia (PSO)\n            if np.random.rand() < 0.1:\n              self.inertia = np.clip(self.inertia + np.random.normal(0,0.05), 0.4, 0.9)\n              self.c1 = np.clip(self.c1 + np.random.normal(0,0.05), 1.0, 2.0)\n              self.c2 = np.clip(self.c2 + np.random.normal(0,0.05), 1.0, 2.0)\n\n        return self.f_opt, self.x_opt", "objective": -0.16463, "other_inf": null}
{"id": "77a2909b-0f1e-456d-b028-7aadedeb1a81", "parents": ["5a48bc5b-9ca0-4c87-9808-08ce234d6af8", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "Employing a population-based approach with Gaussian mutation and adaptive step size, this algorithm explores the search space while gradually refining its solutions based on the fitness landscape.", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                mutant = self.population[i] + self.step_size * np.random.normal(0, 1, self.dim)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Evaluate Mutant\n                f_mutant = func(mutant)\n                eval_count += 1\n\n                # Selection: Accept if better\n                if f_mutant < self.fitness[i]:\n                    self.fitness[i] = f_mutant\n                    self.population[i] = mutant\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n            # Adaptive Step Size Control\n            if np.random.rand() < 0.2:\n                if np.random.rand() < 0.5:\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n                self.step_size = np.clip(self.step_size, 0.001, 2.0)\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.33199, "other_inf": null}
{"id": "c273f179-3630-45fd-a1a8-a9411423e6f8", "parents": ["397587cf-941c-4ce8-9204-3e5b1d4e683d", "c9e5fbe6-3783-4767-be4e-f2d0b89c8509"], "algorithm": "# Description: An evolutionary algorithm that evolves a population of solutions using a combination of differential evolution-inspired mutation and a gradient-based local search to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridDEGradient:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.step_size = step_size\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Local search with probability\n                if np.random.rand() < self.local_search_prob:\n                    # Estimate gradient (crude approximation)\n                    gradient = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus = np.copy(trial)\n                        x_minus = np.copy(trial)\n                        x_plus[j] += self.step_size\n                        x_minus[j] -= self.step_size\n                        x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n                        x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        eval_count += 2\n                        gradient[j] = (f_plus - f_minus) / (2 * self.step_size)\n\n                    # Move in the opposite direction of the gradient\n                    trial = trial - self.step_size * gradient\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7b089453-d051-4130-874f-67bfb3a54dcb", "parents": ["c9e5fbe6-3783-4767-be4e-f2d0b89c8509", "397587cf-941c-4ce8-9204-3e5b1d4e683d"], "algorithm": "# Description: This algorithm combines the exploration of a particle swarm with the local refinement of a Nelder-Mead simplex search, adaptively switching between them based on performance.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, pso_weight=0.7, nm_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.nm_freq = nm_freq\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        self.global_best_position = self.population[best_index].copy()\n\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO update\n                inertia = self.pso_weight * self.velocities[i]\n                cognitive = np.random.rand() * (self.personal_best_positions[i] - self.population[i])\n                social = np.random.rand() * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.population[i] += self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)  # Clip values\n\n                f = func(self.population[i])\n                eval_count += 1\n                \n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.population[i].copy()\n                        self.global_best_position = self.population[i].copy()\n\n                # Nelder-Mead local search (adaptive frequency)\n                if np.random.rand() < self.nm_freq:\n                    # Select a simplex around the current particle\n                    simplex = self.population[np.random.choice(self.pop_size, size=self.dim + 1, replace=False)]\n                    simplex_fitness = np.array([func(x) for x in simplex])\n                    eval_count += self.dim + 1\n\n                    # Nelder-Mead iteration (simplified)\n                    sorted_indices = np.argsort(simplex_fitness)\n                    best = simplex[sorted_indices[0]]\n                    worst = simplex[sorted_indices[-1]]\n                    centroid = np.mean(simplex[sorted_indices[:-1]], axis=0)\n                    reflection = centroid + (centroid - worst)\n                    reflection = np.clip(reflection, self.lb, self.ub)\n                    f_reflection = func(reflection)\n                    eval_count += 1\n\n                    if f_reflection < simplex_fitness[sorted_indices[-2]]:\n                        simplex[sorted_indices[-1]] = reflection\n                        simplex_fitness[sorted_indices[-1]] = f_reflection\n                    \n                    #Update particle based on NM outcome\n                    best_index_simplex = np.argmin(simplex_fitness)\n                    if simplex_fitness[best_index_simplex] < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = simplex_fitness[best_index_simplex]\n                        self.personal_best_positions[i] = simplex[best_index_simplex].copy()\n                        self.population[i] = simplex[best_index_simplex].copy()\n\n                        if simplex_fitness[best_index_simplex] < self.f_opt:\n                            self.f_opt = simplex_fitness[best_index_simplex]\n                            self.x_opt = simplex[best_index_simplex].copy()\n                            self.global_best_position = simplex[best_index_simplex].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.25808, "other_inf": null}
{"id": "c7f16f8b-a7a7-4475-bb5b-3769203de08a", "parents": ["5a48bc5b-9ca0-4c87-9808-08ce234d6af8"], "algorithm": "# Description: This algorithm uses a modified differential evolution strategy with a self-adaptive population size and a Cauchy mutation operator, adjusting both to enhance exploration and exploitation during the optimization process.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_F=0.5, initial_CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = initial_F\n        self.CR = initial_CR\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = None\n        self.ub = None\n        self.success_count = 0\n        self.adaptation_rate = 0.1\n        self.min_pop_size = 10\n\n    def initialize_population(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.lb = lb\n        self.ub = ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                # Cauchy mutation\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    self.success_count += 1\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Adjust population size\n            success_rate = self.success_count / self.pop_size\n            if success_rate > 0.2 and self.pop_size < 2 * self.dim:\n                 self.pop_size = min(2 * self.dim, self.pop_size + 1)\n                 new_individual = np.random.uniform(self.lb, self.ub, size=(1, self.dim))\n                 new_fitness = func(new_individual[0])\n                 self.budget -= 1\n\n                 if new_fitness < self.f_opt:\n                     self.f_opt = new_fitness\n                     self.x_opt = new_individual[0]\n\n                 self.population = np.vstack((self.population, new_individual))\n                 self.fitness = np.append(self.fitness, new_fitness)\n\n\n            elif success_rate < 0.05 and self.pop_size > self.min_pop_size:\n                worst_index = np.argmax(self.fitness)\n                self.population = np.delete(self.population, worst_index, axis=0)\n                self.fitness = np.delete(self.fitness, worst_index)\n                self.pop_size -= 1\n\n            self.success_count = 0\n            # Adaptive F and CR\n            self.F = np.clip(self.F * (1 + self.adaptation_rate * np.random.normal(0, 1)), 0.1, 1.0)\n            self.CR = np.clip(self.CR * (1 + self.adaptation_rate * np.random.normal(0, 1)), 0.1, 1.0)\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "edd77fb3-8434-4adf-b870-c3e05f7df9b4", "parents": ["03ff5a8e-3f88-4e35-ab10-a074fbc2fa3a"], "algorithm": "A modified PSO algorithm that incorporates a mutation operator and dynamic parameter adjustments for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass ModifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_start=0.9, w_end=0.4, c1=2.0, c2=2.0, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.v = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1\n        self.pbest_x = self.x.copy()\n        self.pbest_f = np.full(self.pop_size, np.inf)\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            fitness = np.array([func(xi) for xi in self.x])\n            self.eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if fitness[i] < self.pbest_f[i]:\n                    self.pbest_f[i] = fitness[i]\n                    self.pbest_x[i] = self.x[i].copy()\n\n                    if fitness[i] < self.gbest_f:\n                        self.gbest_f = fitness[i]\n                        self.gbest_x = self.x[i].copy()\n\n            if self.gbest_f < self.f_opt:\n                self.f_opt = self.gbest_f\n                self.x_opt = self.gbest_x\n\n            # Update inertia weight dynamically\n            w = self.w_start - (self.w_start - self.w_end) * (self.eval_count / self.budget)\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.v = w * self.v + self.c1 * r1 * (self.pbest_x - self.x) + self.c2 * r2 * (self.gbest_x - self.x)\n            self.x = self.x + self.v\n\n            # Mutation operator\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < self.mutation_rate\n            self.x[mutation_mask] = np.random.uniform(self.lb, self.ub, size=np.sum(mutation_mask))\n\n            # Clipping\n            self.x = np.clip(self.x, self.lb, self.ub)\n        return self.f_opt, self.x_opt", "objective": -0.42114, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "37e2d90b-d895-4348-9e6e-63ab7300e20e", "parents": [], "algorithm": "Adaptive Differential Evolution with a dynamically adjusted crossover rate and mutation factor based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.7 # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n\n        success_F = []\n        success_CR = []\n        success_count = 0\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.population[i] + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    \n                    success_count +=1\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n            # Adapt F and CR\n            if success_count > 0:\n                self.F = np.mean(success_F) if success_F else 0.5\n                self.CR = np.mean(success_CR) if success_CR else 0.7\n                \n                success_F = []\n                success_CR = []\n                success_count = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.38198, "other_inf": null}
{"id": "0c228231-79b0-4554-a96c-c677a4905fc5", "parents": [], "algorithm": "Adaptive Differential Evolution with a restart strategy based on stagnation detection, dynamically adjusting crossover rate and mutation factor, and periodically re-initializing the population to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr_init=0.5, f_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = 200 # Number of iterations without improvement before restart\n        self.stagnation_counter = 0\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = self.initialize_population()\n        self.fitness = np.array([func(x) for x in self.population])\n        self.nevals = self.pop_size  # Initial population evaluation\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        \n        cr = self.cr_init\n        f = self.f_init\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                x_mutated = self.population[i] + f * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Ensure bounds\n                x_trial = np.clip(x_trial, self.lb, self.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.nevals += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset counter if improvement found\n                else:\n                    self.stagnation_counter += 1\n\n            # Adaptive parameter control (adjust CR and F)\n            cr = np.clip(np.random.normal(self.cr_init, 0.1), 0.0, 1.0)\n            f = np.clip(np.random.normal(self.f_init, 0.1), 0.1, 1.0)\n\n            # Restart strategy\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = self.initialize_population() # Re-initialize population\n                self.fitness = np.array([func(x) for x in self.population])\n                self.nevals += self.pop_size\n                \n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.population[best_index]\n                \n                self.stagnation_counter = 0  # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "objective": -0.15129, "other_inf": null}
{"id": "b93bc56c-2261-4b72-ba0f-8e6cd4ef0a1f", "parents": [], "algorithm": "This algorithm combines a Nelder-Mead simplex method with a random restart strategy to escape local optima and explore the search space effectively.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexRestart:\n    def __init__(self, budget=10000, dim=10, num_restarts=5, simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_restarts = num_restarts\n        self.simplex_size = simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for i in range(self.num_restarts):\n            if eval_count >= self.budget:\n                break\n\n            # Initial guess: random point within bounds\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            # Define a callback to track function evaluations\n            def callback(xk):\n                nonlocal eval_count\n                eval_count += 1\n                return eval_count >= self.budget\n\n            # Run Nelder-Mead simplex algorithm\n            res = minimize(func, x0, method='Nelder-Mead',\n                           options={'maxiter': (self.budget - eval_count) // self.num_restarts if self.num_restarts > 0 else self.budget - eval_count,\n                                    'maxfev': self.budget - eval_count, 'xatol': 1e-8, 'fatol': 1e-8", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexRestart:\n    def __init__(self, budget=10000, dim=10, num_restarts=5, simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_restarts = num_restarts\n        self.simplex_size = simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for i in range(self.num_restarts):\n            if eval_count >= self.budget:\n                break\n\n            # Initial guess: random point within bounds\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            # Define a callback to track function evaluations\n            def callback(xk):\n                nonlocal eval_count\n                eval_count += 1\n                return eval_count >= self.budget\n\n            # Run Nelder-Mead simplex algorithm\n            res = minimize(func, x0, method='Nelder-Mead',\n                           options={'maxiter': (self.budget - eval_count) // self.num_restarts if self.num_restarts > 0 else self.budget - eval_count,\n                                    'maxfev': self.budget - eval_count, 'xatol': 1e-8, 'fatol': 1e-8},\n                           callback=callback)\n            \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a078a3ec-0a4e-48da-8fd2-2c435172d1fd", "parents": [], "algorithm": "Simulated Annealing with adaptive temperature schedule and local search based on gradient estimation to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, perturbation_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.perturbation_size = perturbation_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        eval_count = 1\n\n        while eval_count < self.budget:\n            x_new = x + np.random.normal(0, self.perturbation_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_probability = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n            \n            # Adaptive temperature and perturbation size\n            if eval_count % (self.dim * 5) == 0:\n                temp *= self.cooling_rate\n                self.perturbation_size *= self.cooling_rate\n\n            # Local search to escape local optima (gradient estimation)\n            if eval_count % (self.dim * 10) == 0:\n                gradient = np.zeros(self.dim)\n                for i in range(self.dim):\n                    x_plus = x.copy()\n                    x_minus = x.copy()\n                    delta = 0.001\n                    x_plus[i] += delta\n                    x_minus[i] -= delta\n                    x_plus = np.clip(x_plus, self.lb, self.ub)\n                    x_minus = np.clip(x_minus, self.lb, self.ub)\n                    f_plus = func(x_plus)\n                    eval_count += 1\n                    if eval_count >= self.budget:\n                        break\n                    f_minus = func(x_minus)\n                    eval_count += 1\n                    if eval_count >= self.budget:\n                        break\n\n                    gradient[i] = (f_plus - f_minus) / (2 * delta)\n                \n                if eval_count >= self.budget:\n                    break\n                \n                x_local = x - 0.01 * gradient # Small step against the gradient\n                x_local = np.clip(x_local, self.lb, self.ub)\n                f_local = func(x_local)\n                eval_count += 1\n\n                if f_local < f:\n                    x = x_local\n                    f = f_local\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "94ef7a17-6d5b-4dc1-b8e4-8f43740f6936", "parents": [], "algorithm": "This algorithm combines a simplified CMA-ES-like adaptation of the step size with a local search component that leverages multiple restarts around the best-so-far solution to intensify the search.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, local_search_restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.local_search_restarts = local_search_restarts\n\n    def local_search(self, func, x_center, num_evals):\n        f_best_local = np.inf\n        x_best_local = None\n        for _ in range(num_evals):\n            x = x_center + self.step_size * np.random.normal(0, 1, self.dim)\n            x = np.clip(x, self.lb, self.ub)\n\n            f = func(x)\n            self.eval_count += 1\n\n            if f < f_best_local:\n                f_best_local = f\n                x_best_local = x\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n        \n        return f_best_local, x_best_local\n\n    def __call__(self, func):\n        # Initialization\n        x = np.random.uniform(self.lb, self.ub, self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n\n        while self.eval_count < self.budget:\n            # Adaptive Step Size (simplified CMA-ES)\n            success_rate = 0.0\n            num_successes = 0\n\n            for _ in range(min(100, self.budget - self.eval_count)):\n              x_new = self.x_opt + self.step_size * np.random.normal(0, 1, self.dim)\n              x_new = np.clip(x_new, self.lb, self.ub)\n              f_new = func(x_new)\n              self.eval_count += 1\n              if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                num_successes +=1\n\n            success_rate = num_successes / min(100, self.budget - self.eval_count)\n            if success_rate > 0.2:\n                self.step_size *= 1.2\n            elif success_rate < 0.1:\n                self.step_size *= 0.8\n            self.step_size = min(self.step_size, (self.ub - self.lb) / 2) # prevent step size from becoming too large\n\n            # Local Search around best-so-far\n            num_local_evals = (self.budget - self.eval_count) // self.local_search_restarts if self.local_search_restarts > 0 else 0\n            \n            for _ in range(self.local_search_restarts):\n                if self.eval_count >= self.budget:\n                  break\n\n                f_local, x_local = self.local_search(func, self.x_opt, num_local_evals)\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7141fb71-b17d-4d11-b7ce-32c17a7d0c33", "parents": [], "algorithm": "A population-based algorithm that iteratively refines solutions by combining aspects of particle swarm optimization and differential evolution, adaptively adjusting parameters based on the fitness landscape.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        velocity = np.zeros_like(population)\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity[i] = self.w * velocity[i] + self.c1 * r1 * (personal_best_positions[i] - population[i]) + self.c2 * r2 * (global_best_position - population[i])\n                \n                # DE mutation and crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                mutant = population[a] + self.f * (population[b] - population[c])\n                \n                trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Combined update\n                new_position = population[i] + velocity[i]\n                \n                # Boundary handling\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                f = func(new_position)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = f\n                    \n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = new_position.copy()\n                        \n                        if f < global_best_fitness:\n                            global_best_fitness = f\n                            global_best_position = new_position.copy()\n                            \n\n                if self.budget <= 0:\n                    break\n                    \n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n\n        return self.f_opt, self.x_opt", "objective": -0.3211, "other_inf": null}
{"id": "9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "parents": [], "algorithm": "Adaptive Differential Evolution with dynamically adjusted parameters and a repair mechanism to stay within bounds.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.repair(a + self.F * (b - c))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                # Adaptive F and CR (optional, but can improve performance)\n                self.F = np.random.normal(0.5, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.random.normal(0.9, 0.1)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n                \n                if self.eval_count >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "objective": -0.6989, "other_inf": null}
{"id": "2f2a1776-aa48-498e-8338-20b09ade7cfa", "parents": [], "algorithm": "A population-based algorithm that uses a combination of global exploration and local exploitation, with adaptive step size and differential mutation to efficiently search the solution space.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]    \n        return self.f_opt, self.x_opt", "objective": -0.62923, "other_inf": null}
{"id": "958a205d-a336-4107-968d-7a2a0adb105c", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "37e2d90b-d895-4348-9e6e-63ab7300e20e"], "algorithm": "# Description: This algorithm uses a Gaussian process to model the objective function and an acquisition function to balance exploration and exploitation.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize data\n        X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        y = np.array([func(x) for x in X])\n        self.budget -= self.n_initial\n\n        # Gaussian process model\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit Gaussian process to data\n            gp.fit(X, y)\n\n            # Define acquisition function (Upper Confidence Bound)\n            def acquisition(x, xi=0.1):\n                x = x.reshape(1, -1)\n                mu, sigma = gp.predict(x, return_std=True)\n                return -mu[0] + xi * sigma[0]\n\n            # Optimize acquisition function\n            x0 = np.random.uniform(self.lb, self.ub, size=(1, self.dim))\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(acquisition, x0, method='L-BFGS-B', bounds=bounds)\n            x_new = res.x\n\n            # Evaluate objective function\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Add new data to training set\n            X = np.vstack((X, x_new))\n            y = np.append(y, f_new)\n\n        # Best observed value\n        self.f_opt = np.min(y)\n        self.x_opt = X[np.argmin(y)]\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "5d0f378b-7b54-4b47-b198-2f37b97cd239", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "7141fb71-b17d-4d11-b7ce-32c17a7d0c33"], "algorithm": "Simulated Annealing with adaptive temperature schedule and perturbation based on fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n\n        while self.eval_count < self.budget and temp > self.temp_min:\n            # Adaptive perturbation based on fitness landscape\n            std_dev = 0.1 * (self.ub - self.lb) #Base std dev\n            if self.f_opt != np.inf:\n                std_dev = min(std_dev, abs(self.f_opt)) #Scale down the std dev if the f_opt is small\n            x_new = x + np.random.normal(0, std_dev, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            \n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_probability = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n                    \n            #Adaptive temperature schedule based on the number of accepted solutions\n            if delta_f < 0:\n                temp *= self.cooling_rate #Cool down the temperature as usual\n            else: \n                temp *= (1 + 0.01) #Warm up the temperature slightly if a worse solution is accepted\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.29074, "other_inf": null}
{"id": "04db49ba-edf9-419a-80a5-d7c225b48edc", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "37e2d90b-d895-4348-9e6e-63ab7300e20e"], "algorithm": "# Description: This algorithm utilizes a Gaussian process to model the objective function and uses an acquisition function (Upper Confidence Bound) to balance exploration and exploitation.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessUCB:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10, alpha=1e-7)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.beta = 2.0 #Exploration-exploitation trade-off parameter\n\n    def acquisition_function(self, x):\n        \"\"\"Upper Confidence Bound acquisition function.\"\"\"\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - self.beta * sigma\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.budget -= self.n_initial_samples\n        \n        self.X = X_init\n        self.y = y_init\n        \n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        self.gp.fit(self.X, self.y)\n\n        while self.budget > 0:\n            # Find the next point to evaluate by maximizing the acquisition function\n            x_next = self.find_next_point()\n\n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update the best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            # Update the Gaussian process model\n            self.gp.fit(self.X, self.y)\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self):\n        \"\"\"Find the next point to evaluate by maximizing the acquisition function.\"\"\"\n        # Simple grid search for demonstration, can be replaced with more sophisticated optimization\n        x_candidates = np.random.uniform(self.lb, self.ub, size=(100, self.dim))\n        acq_values = np.array([self.acquisition_function(x) for x in x_candidates])\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "db3c9f97-af58-48bf-8629-9b017ac28749", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Simulated Annealing with adaptive temperature decay based on acceptance rate, aiming to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, min_temp=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n        self.current_x = None\n        self.current_f = None\n        self.temp = initial_temp\n        self.acceptance_rate = 0.0\n        self.acceptance_history = []\n\n    def initialize(self, func):\n        self.current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.current_f = func(self.current_x)\n        self.eval_count += 1\n        self.x_opt = self.current_x\n        self.f_opt = self.current_f\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate a new solution by adding a small random displacement\n            new_x = self.current_x + np.random.normal(0, 0.1, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)  # Keep within bounds\n\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            # Calculate the change in energy\n            delta_f = new_f - self.current_f\n\n            # Acceptance probability\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.current_x = new_x\n                self.current_f = new_f\n                self.acceptance_rate += 1\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n\n            # Adaptive Temperature Schedule\n            self.acceptance_history.append(self.acceptance_rate)\n            if len(self.acceptance_history) > 100:\n                self.acceptance_history.pop(0)\n            \n            # Adjust cooling rate dynamically based on acceptance rate\n            if len(self.acceptance_history) == 100:\n                avg_acceptance_rate = sum(self.acceptance_history) / 100\n                if avg_acceptance_rate > 50:\n                    self.cooling_rate = min(0.99, self.cooling_rate + 0.001)\n                else:\n                    self.cooling_rate = max(0.8, self.cooling_rate - 0.001)\n                self.acceptance_rate = 0.0 \n                \n            # Cool the temperature\n            self.temp *= self.cooling_rate\n            self.temp = max(self.temp, self.min_temp)\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.27443, "other_inf": null}
{"id": "ee3d500c-3322-4470-8d86-0a43c5a29f52", "parents": ["7141fb71-b17d-4d11-b7ce-32c17a7d0c33", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A single-solution based algorithm that iteratively refines a candidate solution by perturbing it with a decaying step size, accepting moves based on the Metropolis criterion to escape local optima.", "code": "import numpy as np\n\nclass SimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        f = func(x)\n        self.budget -= 1\n        \n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.temp_init\n        \n        while self.budget > 0:\n            # Generate neighbor\n            x_new = x + np.random.normal(0, temp, self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Metropolis acceptance criterion\n            if f_new < f or np.random.rand() < np.exp((f - f_new) / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Cooling\n            temp *= self.cooling_rate\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.31104, "other_inf": null}
{"id": "4d4824b5-79de-47de-901a-f36046cf0acc", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "37e2d90b-d895-4348-9e6e-63ab7300e20e"], "algorithm": "A population-based algorithm that utilizes a simplified particle swarm optimization (PSO) approach with velocity clamping and adaptive inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = 0.2 * (self.ub - self.lb)\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index]\n\n        iteration = 0\n        while self.budget > 0:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (iteration / (self.budget / self.pop_size))\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (pbest_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (self.x_opt - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling\n                population[i] = np.clip(population[i], self.lb, self.ub)\n                \n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = population[i].copy()\n                \n                # Update global best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i].copy()\n            \n            iteration += 1\n            \n        return self.f_opt, self.x_opt", "objective": -0.50114, "other_inf": null}
{"id": "1ccc0448-6228-486c-892a-3f0cb33334b6", "parents": ["7141fb71-b17d-4d11-b7ce-32c17a7d0c33", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "This algorithm combines a simplified covariance matrix adaptation evolution strategy (CMA-ES) with a local search based on gradient estimation, leveraging the exploration of CMA-ES and the exploitation of local search to find optima efficiently.", "code": "import numpy as np\n\nclass CMAES_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        mean = np.random.uniform(self.lb, self.ub, self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)  # Covariance matrix\n        \n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), C, self.pop_size)\n            population = mean + sigma * z\n            \n            # Boundary handling\n            population = np.clip(population, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            eval_count += self.pop_size\n            \n            # Sort population\n            indices = np.argsort(fitness)\n            population = population[indices]\n            fitness = fitness[indices]\n            \n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n                \n            # Update mean\n            mean = np.mean(population[:self.pop_size // 2], axis=0)\n\n            # Simplified CMA-ES update (no rank-mu update for simplicity)\n            C = np.cov(population.T)\n            \n            # Update step size\n            sigma *= np.exp(0.5/self.dim * (np.mean(fitness) - self.f_opt)/np.abs(self.f_opt+1e-8))\n\n            # Local search around the best solution\n            x_local = self.x_opt.copy()\n            f_local = self.f_opt\n            \n            for _ in range(self.local_search_iterations):\n                # Estimate gradient (simplified finite differences)\n                gradient = np.zeros(self.dim)\n                delta = 1e-3\n                for j in range(self.dim):\n                    x_plus = x_local.copy()\n                    x_plus[j] += delta\n                    x_plus = np.clip(x_plus, self.lb, self.ub)\n                    f_plus = func(x_plus)\n                    eval_count += 1\n                    \n                    x_minus = x_local.copy()\n                    x_minus[j] -= delta\n                    x_minus = np.clip(x_minus, self.lb, self.ub)\n                    f_minus = func(x_minus)\n                    eval_count += 1\n\n                    gradient[j] = (f_plus - f_minus) / (2 * delta)\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count >= self.budget:\n                    break\n\n                # Gradient descent step\n                step_size = 0.01\n                x_new = x_local - step_size * gradient\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                eval_count += 1\n                \n                if f_new < f_local:\n                    f_local = f_new\n                    x_local = x_new.copy()\n                    \n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = x_local.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "5c5e5b22-e5a1-49fa-9b1c-ce42be96aea5", "parents": ["37e2d90b-d895-4348-9e6e-63ab7300e20e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "'maxfev': self.budget - evals, 'initial_simplex': initial_simplex", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexRestart:\n    def __init__(self, budget=10000, dim=10, simplex_size=1.0, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = simplex_size\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            # Initialize simplex\n            initial_simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n            \n            # Nelder-Mead optimization\n            res = minimize(func, initial_simplex[0], method='Nelder-Mead',\n                           options={'maxfev': self.budget - evals, 'initial_simplex': initial_simplex})\n            \n            evals += res.nfev\n            \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n\n            # Probabilistic restart\n            if np.random.rand() < self.restart_prob:\n                continue\n            else:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ab6e8dc8-3c31-4bc6-85db-532ed5427770", "parents": ["4d4824b5-79de-47de-901a-f36046cf0acc"], "algorithm": "A modified PSO algorithm with a linearly decreasing inertia weight, a mutation operator to increase diversity, and a selection mechanism based on fitness to maintain promising solutions.", "code": "import numpy as np\n\nclass ModifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=2, c2=2, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = 0.2 * (self.ub - self.lb)\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index]\n\n        iteration = 0\n        while self.budget > 0:\n            # Linearly decreasing inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (iteration / (self.budget / self.pop_size))\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (pbest_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (self.x_opt - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation_indices = np.random.choice(self.dim, size=int(self.dim * self.mutation_rate), replace=False)\n                    population[i, mutation_indices] = np.random.uniform(self.lb, self.ub, size=len(mutation_indices))\n                \n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = population[i].copy()\n                \n                # Update global best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i].copy()\n            \n            # Selection: Keep the best half of the population\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices[:self.pop_size//2]]\n            pbest_positions = pbest_positions[sorted_indices[:self.pop_size//2]]\n            pbest_fitness = pbest_fitness[sorted_indices[:self.pop_size//2]]\n            \n            # Repopulate the other half randomly\n            new_population = np.random.uniform(self.lb, self.ub, size=(self.pop_size - self.pop_size//2, self.dim))\n            population = np.concatenate((population, new_population))\n            velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim)) # Reinitialize velocities\n\n            # Evaluate newly populated individuals\n            new_fitness = np.array([func(x) for x in population[self.pop_size//2:]])\n            self.budget -= len(new_fitness)\n            fitness = np.concatenate((fitness[sorted_indices[:self.pop_size//2]], new_fitness))\n            \n            new_pbest_positions = population[self.pop_size//2:].copy()\n            new_pbest_fitness = fitness[self.pop_size//2:].copy()\n            pbest_positions = np.concatenate((pbest_positions, new_pbest_positions))\n            pbest_fitness = np.concatenate((pbest_fitness, new_pbest_fitness))\n\n            # Update global best after repopulation\n            global_best_index = np.argmin(fitness)\n            self.f_opt = fitness[global_best_index]\n            self.x_opt = population[global_best_index]\n            \n            iteration += 1\n            \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "1d917774-6ebd-4c69-a02e-ef5905616bbb", "parents": ["37e2d90b-d895-4348-9e6e-63ab7300e20e"], "algorithm": "# Description: Adaptive Differential Evolution with archive and periodic restart to enhance exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDEArchiveRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.7 # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.restart_interval = 500 # Function evaluations between restarts\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        evals = self.pop_size\n        restart_counter = 0\n\n        success_F = []\n        success_CR = []\n        success_count = 0\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # Use archive occasionally\n                    archive_idx = np.random.randint(0, len(self.archive))\n                    a = self.archive[archive_idx]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = self.population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = self.population[i] + self.F * (a - b) + self.F * (c-self.population[i])\n                else:\n                    a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = self.population[i] + self.F * (b - c)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    \n                    success_count +=1\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial)\n                    else:\n                        self.archive[np.random.randint(0, self.archive_size)] = trial\n\n            # Adapt F and CR\n            if success_count > 0:\n                self.F = np.mean(success_F) if success_F else 0.5\n                self.CR = np.mean(success_CR) if success_CR else 0.7\n                \n                success_F = []\n                success_CR = []\n                success_count = 0\n\n            restart_counter += self.pop_size\n            if restart_counter >= self.restart_interval:\n                self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                best_idx = np.argmin(self.fitness)\n                if self.fitness[best_idx] < self.f_opt:\n                    self.f_opt = self.fitness[best_idx]\n                    self.x_opt = self.population[best_idx]\n                restart_counter = 0 # reset counter\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "be896aa2-6728-4895-9762-4694d189baa6", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: An enhanced Differential Evolution algorithm using a modified mutation strategy based on ranking the population and dynamically adapting the mutation factor, alongside a Cauchy-based local search to fine-tune the best solution.\n# Code:\n```", "code": "import numpy as np\n\nclass RankDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def local_search(self, func, x):\n        # Cauchy-based local search\n        for _ in range(5):  # Perform a few local search steps\n            step = np.random.standard_cauchy(size=self.dim) * 0.01  # Smaller step size\n            new_x = self.repair(x + step)\n            f = func(new_x)\n            self.eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = new_x\n            if f < func(x):\n                x = new_x  # Move to the better solution\n        return x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Rank the population\n            ranked_indices = np.argsort(self.fitness)\n            ranked_pop = self.pop[ranked_indices]\n\n            for i in range(self.pop_size):\n                # Mutation - Use rank-based mutation\n                pbest = ranked_pop[0] # Best individual\n                prand = ranked_pop[np.random.randint(1, self.pop_size)]  # Random individual from ranked population\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = self.pop[np.random.choice(idxs, 2, replace=False)]\n\n                mutant = self.repair(self.pop[i] + self.F * (pbest - self.pop[i]) + self.F * (a - b))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Adaptive F\n                self.F = np.random.normal(0.5, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                \n                # Local Search (Cauchy)\n                if np.random.rand() < self.local_search_prob:\n                    self.pop[i] = self.local_search(func, self.pop[i].copy()) # ensure not changing x_opt accidentally\n                    self.fitness[i] = func(self.pop[i])\n                    self.eval_count += 1  # Account for local search eval\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.pop[i]\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "b793d185-f8a5-4e3e-a103-5e3a7667f8df", "parents": ["4d4824b5-79de-47de-901a-f36046cf0acc"], "algorithm": "A population-based algorithm employing differential evolution (DE) with a dynamically adjusted mutation factor to enhance exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_max=1.2, F_min=0.2, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_max = F_max\n        self.F_min = F_min\n        self.cr = cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            # Adaptive mutation factor\n            F = self.F_max - (self.F_max - self.F_min) * (generation / (self.budget / self.pop_size))\n            \n            for i in range(self.pop_size):\n                # Choose three random indices, distinct from each other and i\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Mutation\n                mutant = population[a] + F * (population[b] - population[c])\n                \n                # Crossover\n                trial = population[i].copy()\n                cross_points = np.random.rand(self.dim) < self.cr\n                trial[cross_points] = mutant[cross_points]\n                \n                # Boundary handling\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                # Evaluate trial vector\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial.copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            generation += 1\n            \n        return self.f_opt, self.x_opt", "objective": -0.52663, "other_inf": null}
{"id": "621c7521-3599-4e51-b808-1c20ead456a4", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A variant of Differential Evolution with a smaller population size, increased mutation factor, and adaptive crossover rate to promote more aggressive exploration and faster convergence.", "code": "import numpy as np\n\nclass AggressiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.9, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover - Adaptive CR\n                cr = self.CR * np.random.rand() # Adaptive Crossover Rate\n                cross_points = np.random.rand(self.dim) < cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]    \n        return self.f_opt, self.x_opt", "objective": -0.60196, "other_inf": null}
{"id": "cb245dce-3862-49de-98be-85258212a739", "parents": ["b793d185-f8a5-4e3e-a103-5e3a7667f8df"], "algorithm": "A self-adaptive differential evolution algorithm with a modified mutation strategy and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, cr_init=0.9, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init * np.ones(pop_size)  # Initialize F for each individual\n        self.cr = cr_init * np.ones(pop_size)  # Initialize CR for each individual\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize best position and fitness\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Self-adaptive parameters\n                self.F[i] = np.clip(np.random.normal(0.5, 0.3), 0.0, 1.0)\n                self.cr[i] = np.clip(np.random.normal(0.9, 0.2), 0.0, 1.0)\n\n                # Choose three random indices, distinct from each other and i\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Mutation with current-to-best/1\n                mutant = population[i] + self.F[i] * (self.x_opt - population[i]) + self.F[i] * (population[a] - population[b])\n                \n                # Crossover\n                trial = population[i].copy()\n                cross_points = np.random.rand(self.dim) < self.cr[i]\n                trial[cross_points] = mutant[cross_points]\n                \n                # Boundary handling\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                # Evaluate trial vector\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial.copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        self.stagnation_counter = 0 # Reset counter\n                    else:\n                        self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_trigger * self.budget / self.pop_size:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                self.stagnation_counter = 0 # Reset counter\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "88d89356-fa75-4860-ada6-942bb1d9470f", "parents": ["4d4824b5-79de-47de-901a-f36046cf0acc"], "algorithm": "A differential evolution algorithm with a dynamically adjusted mutation rate based on population diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            # Adjust mutation factor based on diversity\n            adaptive_F = self.F * (1 + diversity)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + adaptive_F * (population[b] - population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial[cross_points] = mutant[cross_points]\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial.copy()\n\n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.30285, "other_inf": null}
{"id": "715155ce-ee6e-42f1-90d4-73ff533b74ee", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "An enhanced Differential Evolution strategy using a larger population size, reduced mutation factor, increased crossover rate, and periodic population rejuvenation to promote exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=100, F=0.3, CR=0.95, rejuvenation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.rejuvenation_rate = rejuvenation_rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def rejuvenate_population(self):\n      # Replace a fraction of the population with new random individuals\n      num_rejuvenated = int(self.rejuvenation_rate * self.pop_size)\n      indices_to_rejuvenate = np.random.choice(self.pop_size, num_rejuvenated, replace=False)\n      self.pop[indices_to_rejuvenate] = np.random.uniform(self.lb, self.ub, size=(num_rejuvenated, self.dim))\n      self.fitness[indices_to_rejuvenate] = np.array([np.inf]*num_rejuvenated) # Reset fitness of rejuvenated individuals\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.repair(a + self.F * (b - c))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                  break\n            \n            # Rejuvenate the population periodically\n            if (self.eval_count / self.pop_size) % 10 == 0 and self.eval_count < self.budget:\n                self.rejuvenate_population()\n                #Evaluate the fitness for new individuals.\n                for i in range(self.pop_size):\n                  if self.fitness[i] == np.inf:\n                    self.fitness[i] = func(self.pop[i])\n                    self.eval_count +=1\n                    if self.fitness[i] < self.f_opt:\n                      self.f_opt = self.fitness[i]\n                      self.x_opt = self.pop[i]\n                    if self.eval_count >= self.budget:\n                      break\n\n        return self.f_opt, self.x_opt", "objective": -0.61682, "other_inf": null}
{"id": "b141c120-00f5-4504-931e-f6d5af159fa0", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.99, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.alpha = alpha\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for restart in range(self.restarts):\n            temp = self.temp_init\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            f = func(x)\n            eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            while eval_count < self.budget:\n                x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Small random step\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                f_new = func(x_new)\n                eval_count += 1\n\n                delta_f = f_new - f\n                if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                    f = f_new\n                    x = x_new\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n                temp *= self.alpha # Temperature decreases\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "9f17a52c-8b03-4f4e-bdae-cd6f8bd34634", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "Simulated Annealing with adaptive temperature schedule, periodically re-initialized to explore diverse regions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, reset_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.reset_prob = reset_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        \n        for i in range(self.budget):\n            x_new = x + np.random.normal(0, temp**0.5, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)  # Keep within bounds\n            f_new = func(x_new)\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                f = f_new\n                x = x_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            temp *= self.cooling_rate\n\n            # Periodic reset to explore different regions\n            if np.random.rand() < self.reset_prob:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "154dd434-6c1b-4a9d-ab69-880a8318de12", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.95, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.step_size = step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.acceptance_rate = 0.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.eval_count += 1\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance criterion\n            delta_f = f_new - self.f_opt\n            if delta_f < 0:\n                x = x_new\n                self.f_opt = f_new\n                self.x_opt = x_new\n                self.acceptance_rate = 1.0\n            else:\n                prob = np.exp(-delta_f / self.temp)\n                if np.random.rand() < prob:\n                    x = x_new\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                    self.acceptance_rate = 1.0\n                else:\n                    self.acceptance_rate = 0.0\n\n            self.acceptance_history.append(self.acceptance_rate)\n\n            # Adaptive temperature schedule\n            if len(self.acceptance_history) > 100:\n                avg_acceptance = np.mean(self.acceptance_history[-100:])\n                if avg_acceptance > 0.8:\n                    self.step_size *= 1.05 #Exploration\n                elif avg_acceptance < 0.2:\n                    self.step_size *= 0.95 #Exploitation\n                self.temp *= self.alpha\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.31244, "other_inf": null}
{"id": "7e7a8011-7583-48b9-b7e5-729cf08f7e59", "parents": ["715155ce-ee6e-42f1-90d4-73ff533b74ee", "715155ce-ee6e-42f1-90d4-73ff533b74ee"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space, combined with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n        # Initialize strategy parameters\n        self.mu = (self.ub + self.lb) / 2 * np.ones(self.dim)  # Mean value\n        self.lambda_ = self.pop_size\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff)\n        self.ccov1sep = min(1, self.ccov1 * (self.dim + 1.5) / 3)\n        self.ccovmusep = min(1, self.ccovmu * (self.dim + 1.5) / 3)\n\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.C = self.B @ np.diag(self.D**2) @ self.B.T\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.hist = []\n        self.tolx = 1e-12 * self.sigma\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.lambda_)\n        y = self.B @ np.diag(self.D) @ z\n        x = self.mu.reshape(-1, 1) + self.sigma * y\n        x = np.clip(x, self.lb, self.ub)\n        return x.T, y\n\n    def update_distribution(self, x, y, fitness):\n        xmean = np.sum(x * self.weights.reshape(-1, 1), axis=0)\n        y_mean = np.sum(y * self.weights.reshape(-1, 1), axis=0)\n\n        ps_norm = np.linalg.norm(self.ps) / self.chiN\n        self.sigma *= np.exp((self.cs / self.damps) * (ps_norm - 1))\n        self.sigma = min(self.sigma, 5)\n        \n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ y_mean)\n        self.pc = (1 - self.ccov1) * self.pc + np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mueff) * (xmean - self.mu) / self.sigma\n\n        artmp = (1/self.sigma) * (x - self.mu)\n        self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * (self.pc[:,None] @ self.pc[None,:]) + self.ccovmu * artmp.T @ np.diag(self.weights) @ artmp\n        \n        self.mu = xmean\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(self.D)\n    \n\n    def __call__(self, func):\n        for _ in range(self.restarts):\n            self.mu = (self.ub + self.lb) / 2 * np.ones(self.dim)\n            self.sigma = 0.5\n            self.C = np.eye(self.dim)\n            self.pc = np.zeros(self.dim)\n            self.ps = np.zeros(self.dim)\n            self.B = np.eye(self.dim)\n            self.D = np.ones(self.dim)\n            \n            while self.eval_count < self.budget:\n                x, y = self.sample_population()\n                fitness = np.array([func(xi) for xi in x])\n                self.eval_count += self.lambda_\n                \n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = x[np.argmin(fitness)]\n\n                idx = np.argsort(fitness)\n                x = x[idx]\n                y = y[idx]\n\n                self.update_distribution(x, y, fitness)\n\n                if self.sigma < self.tolx:\n                  break\n\n                if self.eval_count >= self.budget:\n                  break\n            if self.eval_count >= self.budget:\n                  break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "3d5b5d11-23f2-4aaf-b3d9-a6254c3b509e", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "An iterative algorithm that focuses on perturbing the best solution found so far by sampling from a decreasing radius around it, intensifying the search in promising regions.", "code": "import numpy as np\n\nclass FocusedPerturbation:\n    def __init__(self, budget=10000, dim=10, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial random solution\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n        \n        radius = self.initial_radius\n\n        while self.budget > 0:\n            # Perturb the current best solution\n            perturbation = np.random.uniform(-radius, radius, size=self.dim)\n            x_new = self.x_opt + perturbation\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            else:\n                # Reduce the radius if no improvement\n                radius *= 0.99  # Reduce radius gradually\n        \n        return self.f_opt, self.x_opt", "objective": -0.37512, "other_inf": null}
{"id": "82c89846-256a-4cff-a890-88b7667c4eea", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A swarm-based optimization algorithm where particles adjust their positions based on both their personal best and the swarm's best, while also incorporating a velocity clamping mechanism to prevent excessive exploration.", "code": "import numpy as np\n\nclass ClampedPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, w=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(self.lb, self.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.swarm])\n        self.eval_count += self.swarm_size\n        best_index = np.argmin(self.personal_best_fitness)\n        self.global_best_fitness = self.personal_best_fitness[best_index]\n        self.global_best_position = self.personal_best_positions[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.swarm[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.swarm[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                self.swarm[i] += self.velocities[i]\n                self.swarm[i] = np.clip(self.swarm[i], self.lb, self.ub)  # Ensure bounds\n\n                # Evaluate fitness\n                fitness = func(self.swarm[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.swarm[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.swarm[i].copy()\n                if self.eval_count >= self.budget:\n                  break\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n        return self.f_opt, self.x_opt", "objective": -0.61837, "other_inf": null}
{"id": "302770bd-84c0-4c4a-9699-65c6c7888f02", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A gradient-free optimization algorithm that iteratively improves solutions by perturbing them in random directions, adapting the step size based on the success rate of previous perturbations.", "code": "import numpy as np\n\nclass AdaptiveRandomSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_rate_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.budget -= 1\n        \n        successes = 0\n        iterations = 0\n\n        while self.budget > 0:\n            iterations += 1\n            # Perturb the current solution\n            direction = np.random.normal(0, 1, size=self.dim)\n            x_new = x + self.step_size * direction\n            x_new = np.clip(x_new, self.lb, self.ub)  # Ensure bounds are respected\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                successes += 1\n\n            # Adapt step size based on success rate\n            if iterations % 100 == 0:\n                success_rate = successes / iterations\n                if success_rate > self.success_rate_threshold:\n                    self.step_size *= 1.1  # Increase step size if successful\n                else:\n                    self.step_size *= 0.9  # Decrease step size if unsuccessful\n                successes = 0\n                iterations = 0\n            if self.budget <= 0:\n                break\n            \n        return self.f_opt, self.x_opt", "objective": -0.50148, "other_inf": null}
{"id": "93047ae7-a6e9-42e5-bc5d-db2cb4f578ff", "parents": ["621c7521-3599-4e51-b808-1c20ead456a4", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A population-based algorithm that uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by sampling promising regions of the search space.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X = None\n        self.y = None\n        self.gp = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.eval_count += self.n_initial\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n    def acquisition(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - self.exploration_weight * sigma\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n        self.gp.fit(self.X, self.y)\n\n        while self.eval_count < self.budget:\n            # Sample a new point using the acquisition function\n            x_new = None\n            best_acq = np.inf\n\n            for _ in range(100):\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq = self.acquisition(x_candidate, self.gp)\n                if acq < best_acq:\n                    best_acq = acq\n                    x_new = x_candidate\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            self.gp.fit(self.X, self.y)\n            \n            if self.eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4fe98b08-c932-40bc-a696-343df508d316", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restart mechanism and boundary handling.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_percentage=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = int(self.pop_size * mu_percentage)\n        self.weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.c_cov = (1 / self.mu_eff) * ((self.mu_eff + 2) / (self.dim - 2 + (self.mu_eff+2)**2))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.m = None\n        self.C = None\n        self.p_sigma = None\n        self.p_c = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_trigger = False\n        self.restart_threshold = 1e-12\n\n    def initialize(self):\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        try:\n            A = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ A.T\n        except np.linalg.LinAlgError:\n            # Handle non-positive definite covariance matrix\n            self.C = self.C + 1e-6 * np.eye(self.dim)\n            A = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ A.T\n        return x\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def restart(self):\n        self.initialize()\n        self.sigma = 0.5\n        self.restart_trigger = False\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            x = np.array([self.repair(xi) for xi in x])  # Apply boundary repair\n            \n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Check for stagnation and trigger restart\n            if np.abs(self.f_opt) < self.restart_threshold:\n                self.restart_trigger = True\n\n            if self.restart_trigger:\n                self.restart()\n                continue\n\n            z = (x[:self.mu] - self.m) / self.sigma\n            \n            # Update CMA-ES parameters\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu_eff) * (z[:self.mu] @ self.weights[:self.mu])\n            ps_norm = np.linalg.norm(self.p_sigma)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (ps_norm / np.sqrt(self.dim) - 1))\n            \n            h_sigma = 1.0 if (ps_norm / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.eval_count / self.pop_size)) < (1.4 + 2 / (self.dim + 1))) else 0.0\n\n            self.p_c = (1 - self.c_c) * self.p_c + h_sigma * np.sqrt(self.c_c * (2 - self.c_c) * self.mu_eff) * ((x[:self.mu] - self.m) @ self.weights[:self.mu]) / self.sigma\n            \n            self.m = (x[:self.mu] @ self.weights[:self.mu])\n            \n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (1 / self.mu_eff) * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_cov * (1 - h_sigma) * (z[:self.mu].T @ np.diag(self.weights[:self.mu]) @ z[:self.mu])\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "558446e8-56e9-484b-aa62-44ccc03463fe", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware adaptation of the population size and a restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_mean = None\n        self.sigma = None\n        self.C = None\n        self.pop_size = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n        self.c_sigma = None\n        self.c_c = None\n        self.c_cov = None\n        self.D = None\n        self.B = None\n        self.pc = None\n        self.ps = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.restart_trigger = 100  # Restart after this many iterations without improvement\n        self.no_improvement_count = 0\n        self.last_f_opt = np.inf\n        self.min_pop_size = 4 # Minimum allowed population size\n\n    def initialize(self):\n        self.x_mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pop_size = self.initial_pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_c = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c_cov = (1 / self.mueff) * (self.mueff + 1) / ((self.dim + 2) * (self.dim + 2) + self.mueff / 2)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(self.D)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        x = self.x_mean + self.sigma * (self.B @ (self.D * z.T)).T\n        return np.clip(x, self.lb, self.ub)\n\n    def update_parameters(self, x, fitness):\n        x_old = self.x_mean\n        x_sorted = x[np.argsort(fitness)]\n        self.x_mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n        \n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (self.x_mean - x_old) / self.sigma\n        self.hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.eval_count / self.pop_size))) < (1.4 + 2 / (self.dim + 1))\n\n        self.pc = (1 - self.c_c) * self.pc + self.hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (self.x_mean - x_old) / self.sigma\n\n        artmp = (x_sorted[:self.mu] - x_old).T / self.sigma\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :]) + self.c_cov * np.sum(self.weights[:, None, None] * (artmp[:, :, None] @ artmp[:, None, :]), axis=0)\n\n        self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(self.D)\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                self.no_improvement_count = 0\n            else:\n                self.no_improvement_count += 1\n\n            self.update_parameters(x, fitness)\n\n            # Budget-aware population size adaptation\n            remaining_budget = self.budget - self.eval_count\n            \n            # Adjust pop_size based on remaining budget and performance\n            if remaining_budget > 10 * self.dim:\n                self.pop_size = min(self.initial_pop_size + int(np.log(remaining_budget)), 2 * self.initial_pop_size)  # Increase pop_size if budget allows\n            else:\n                self.pop_size = max(self.min_pop_size, int(self.initial_pop_size * remaining_budget / (10 * self.dim))) # Reduce pop_size if budget is tight\n            \n            self.mu = max(1, self.pop_size // 2)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n            # Restart mechanism\n            if self.no_improvement_count > self.restart_trigger:\n                self.initialize()  # Restart CMA-ES\n                self.no_improvement_count = 0\n            \n            if self.eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7cdbae45-0d47-4b52-9be2-1f7e381431f1", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: An Enhanced Differential Evolution strategy with a self-adaptive population size and a neighborhood-based mutation operator to improve exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F=0.5, CR=0.9, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.pop_size = pop_size_init\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.neighborhood_size = neighborhood_size\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Neighborhood-based Mutation\n                neighborhood_indices = np.random.choice(self.pop_size, self.neighborhood_size, replace=False)\n                a = self.pop[np.random.choice(neighborhood_indices)]\n                b = self.pop[np.random.choice(neighborhood_indices)]\n                c = self.pop[np.random.choice(neighborhood_indices)]\n                mutant = self.repair(a + self.F * (b - c))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Adaptive F and CR (optional, but can improve performance)\n                self.F = np.random.normal(0.5, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.random.normal(0.9, 0.1)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                # Adaptive Population Size (example: reduce if no improvement)\n                if self.eval_count % (self.pop_size * 2) == 0:\n                    if self.f_opt == np.min(self.fitness):\n                        self.pop_size = max(10, int(self.pop_size * 0.9))  # Reduce pop size\n                        self.pop = self.pop[np.argsort(self.fitness)[:self.pop_size]]\n                        self.fitness = self.fitness[np.argsort(self.fitness)[:self.pop_size]]\n                    else:\n                        self.pop_size = min(self.pop_size_init, int(self.pop_size * 1.1))\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e6ef0e65-de86-474e-9063-932b25a949ff", "parents": ["715155ce-ee6e-42f1-90d4-73ff533b74ee"], "algorithm": "A self-adaptive Differential Evolution algorithm using a dynamic mutation factor and crossover rate, combined with a local search strategy to refine promising solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, CR_initial=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Initial mutation factor\n        self.CR = CR_initial  # Initial crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def local_search(self, func, x, radius=0.1):\n        # Perform a simple local search around x\n        best_x = x\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(5):  # Limited local search evaluations\n            new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n            new_x = self.repair(new_x)\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        \n        return best_f, best_x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.repair(a + self.F * (b - c))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    f_local, x_local = self.local_search(func, self.pop[i])\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.pop[i] = x_local\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n\n                # Adaptive F and CR (simple adaptation)\n                if self.eval_count % 100 == 0:\n                  self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n                  self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 0.99)\n                \n                if self.eval_count >= self.budget:\n                  break\n        return self.f_opt, self.x_opt", "objective": -0.31119, "other_inf": null}
{"id": "1842c92f-f330-47c6-b06f-a50eb2adb1ba", "parents": ["715155ce-ee6e-42f1-90d4-73ff533b74ee"], "algorithm": "A hybrid algorithm combining Differential Evolution with a Nelder-Mead simplex search to refine promising solutions found by DE.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, nm_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.nm_iterations = nm_iterations #Number of Nelder-Mead iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def nelder_mead_refinement(self, func, x):\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.nm_iterations, 'maxfev': self.budget - self.eval_count", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, nm_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.nm_iterations = nm_iterations #Number of Nelder-Mead iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def nelder_mead_refinement(self, func, x):\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.nm_iterations, 'maxfev': self.budget - self.eval_count})\n        self.eval_count += result.nfev\n        return result.fun, result.x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.repair(a + self.F * (b - c))\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n\n                    #Refine with Nelder-Mead\n                    f_refined, x_refined = self.nelder_mead_refinement(func, trial)\n                    if f_refined < self.fitness[i]:\n                        self.fitness[i] = f_refined\n                        self.pop[i] = x_refined\n                    f = self.fitness[i] #Update f with refined fitness\n\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ab0edf48-1ea2-44e1-a68e-0c1394a78d88", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A self-adaptive Differential Evolution algorithm that adjusts its mutation factor F and crossover rate CR based on the success of previous generations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init * np.ones(pop_size)\n        self.CR = CR_init * np.ones(pop_size)\n        self.F_init = F_init\n        self.CR_init = CR_init\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        success_F = []\n        success_CR = []\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F[i] * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    success_F.append(self.F[i])\n                    success_CR.append(self.CR[i])\n\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adapt F and CR\n            if success_F:\n                self.F = 0.9 * self.F + 0.1 * np.mean(success_F) * np.ones(self.pop_size)\n                self.CR = 0.9 * self.CR + 0.1 * np.mean(success_CR) * np.ones(self.pop_size)\n            else:\n                self.F = self.F_init * np.ones(self.pop_size)\n                self.CR = self.CR_init * np.ones(self.pop_size)\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            success_F = []\n            success_CR = []\n\n        return self.f_opt, self.x_opt", "objective": -0.62177, "other_inf": null}
{"id": "ed9a5bfc-c9c4-4ead-a51b-35539d93d8dc", "parents": ["715155ce-ee6e-42f1-90d4-73ff533b74ee"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with adaptive step size control and restarts to enhance exploration and exploitation in continuous optimization problems.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=None, c_1=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n\n        self.mu = self.pop_size // 2\n\n        if damps is None:\n          self.damps = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + cs\n\n        if c_cov is None:\n            self.c_cov = (1 / self.mu) * (2 / ((self.dim+1.3)**2 + self.mu)) + (1 - 1/self.mu) * (0.3 / ((self.dim+1.3)**2 + self.mu))\n        if c_1 is None:\n            self.c_1 = 2 / ((self.dim+1.3)**2 + self.mu)\n        if c_mu is None:\n            self.c_mu = (1 / self.mu) * (2 / ((self.dim+1.3)**2 + self.mu))\n\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = False\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def update_distribution(self, pop, fitness):\n        idx = np.argsort(fitness)\n        elite_indices = idx[:self.mu]\n        elite_pop = pop[elite_indices]\n\n        self.mean = np.mean(elite_pop, axis=0)\n\n        z = (elite_pop - self.mean) / self.sigma\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.mean) / self.sigma)\n        self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/self.chiN - 1))\n        \n        self.pc = (1 - self.c_1) * self.pc + np.sqrt(self.c_1 * (2 - self.c_1)) * (self.mean - self.mean)/self.sigma\n        \n        self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.pc, self.pc) + self.c_mu * np.mean([np.outer(z[i], z[i]) for i in range(self.mu)], axis=0)\n\n        if np.any(np.diag(self.C) <= 0):\n            self.C = np.eye(self.dim)\n            self.sigma = 0.5\n            self.pc = np.zeros(self.dim)\n\n    def check_restart(self):\n      if self.sigma < 1e-8 or self.sigma > 1e8:\n        self.restart_trigger = True\n      else:\n        self.restart_trigger = False\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            pop = self.sample_population()\n            pop = np.array([self.repair(x) for x in pop])\n            fitness = np.array([func(x) for x in pop])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = pop[best_index]\n            \n            self.update_distribution(pop, fitness)\n            self.check_restart()\n\n            if self.restart_trigger and self.eval_count < self.budget:\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma = 0.5\n\n            if self.eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "31154b8e-06f8-4cc4-aff3-1230543586a0", "parents": ["715155ce-ee6e-42f1-90d4-73ff533b74ee"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is implemented, focusing on adapting the covariance matrix of a multivariate normal distribution to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Strategy parameter setting: Selection\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Strategy parameter setting: Adaptation\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2.0)**2 + self.mueff)\n        self.ccov1 = min(1, self.ccov1 * (self.dim + 1.3)**2 / (self.mueff + 2))\n        self.ccovmu = min(1, self.ccovmu * (self.dim + 2)**2 / (self.mueff))\n\n        # Initialize dynamic (internal) strategy parameters and constants\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.C = self.B @ np.diag(self.D**2) @ self.B.T\n        self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.pop_size)\n        y = self.B @ (self.D * z)\n        x = self.mean[:, np.newaxis] + self.sigma * y\n        x = np.clip(x, self.lb, self.ub)\n        return x.T\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate and evaluate lambda offspring\n            x = self.sample_population()\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort by fitness and update mean\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            xmean = np.sum(self.weights[:, np.newaxis] * x[:self.mu], axis=0)\n\n            # Update optimal value\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n                \n            if self.eval_count >= self.budget:\n              break\n\n            # Cumulation: Update evolution paths\n            y = (xmean - self.mean) / self.sigma\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * self.invsqrtC @ y\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) / np.sqrt(self.dim + (self.dim))) < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - 1) * self.pc + hsig * np.sqrt(1 - 1) * y\n            # Adapt covariance matrix C\n            z = (x[:self.mu] - self.mean) / self.sigma\n            self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis,:]) + self.ccovmu * z.T @ np.diag(self.weights) @ z\n            # Update step size sigma\n            self.mean = xmean\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D.real)\n                self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-8 * np.eye(self.dim)\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D.real)\n                self.invsqrtC = self.B @ np.diag(self.D**-1) @ self.B.T\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "76c8188c-adfb-4017-97d4-3442a3f319a4", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A swarm-based optimization algorithm that uses a velocity update rule inspired by both particle swarm optimization and gravitational search, balancing exploration and exploitation by dynamically adjusting inertia and gravitational constants.", "code": "import numpy as np\n\nclass GravitationalParticleSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, w_max=0.9, w_min=0.2, c1=2, c2=2, G0=100):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.G0 = G0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize swarm\n        swarm = np.random.uniform(self.lb, self.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n        \n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = swarm[best_index]\n        global_best_position = swarm[best_index].copy()\n        \n        iteration = 0\n        while self.budget > 0:\n            # Update inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * iteration / (self.budget / self.swarm_size)\n            \n            # Calculate gravitational constant\n            G = self.G0 * np.exp(-20 * iteration / (self.budget / self.swarm_size))\n            \n            # Calculate total mass of each particle (proportional to fitness)\n            mass = np.exp(-fitness / np.mean(fitness))\n            mass = mass / np.sum(mass)\n            \n            for i in range(self.swarm_size):\n                # Calculate gravitational force\n                force = np.zeros(self.dim)\n                for j in range(self.swarm_size):\n                    if i != j:\n                        R = np.linalg.norm(swarm[j] - swarm[i])\n                        if R == 0:\n                            R = 1e-6 \n                        force += mass[j] * (swarm[j] - swarm[i]) / (R + 1e-6)\n                \n                # Update velocity\n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]) + \\\n                                G * force\n                \n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n                \n                # Evaluate fitness\n                f = func(swarm[i])\n                self.budget -= 1\n                \n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = swarm[i].copy()\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = swarm[i].copy()\n                        global_best_position = swarm[i].copy()\n            \n            iteration += 1\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": -0.42248, "other_inf": null}
{"id": "f48a26ba-322f-4078-a4ad-6f159baace95", "parents": ["82c89846-256a-4cff-a890-88b7667c4eea", "ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on function evaluation changes.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.9, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n        \n        while self.budget > 0 and temp > self.temp_min:\n            \n            # Generate neighbor\n            x_new = x + np.random.normal(0, temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluate neighbor\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            delta_e = f_new - f\n\n            # Acceptance probability\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adaptive temperature schedule\n            if delta_e > 0:\n                temp *= self.cooling_rate\n            else:\n                temp = self.initial_temp\n        \n        return self.f_opt, self.x_opt", "objective": -0.31883, "other_inf": null}
{"id": "df3d8958-794c-4282-afe2-c534e4ee483c", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "82c89846-256a-4cff-a890-88b7667c4eea"], "algorithm": "# Description: A gradient-free optimization method that iteratively refines a population of candidate solutions by sampling new points around the best-performing individuals, adapting the sampling radius based on success rate.\n# Code: \n```", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=0.5, shrink_factor=0.9, expand_factor=1.1, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        success_count = 0\n\n        while self.eval_count < self.budget:\n            best_index = np.argmin(self.fitness)\n            best_x = self.pop[best_index]\n\n            for i in range(self.pop_size):\n                # Sample new point from neighborhood of best solution\n                new_x = best_x + np.random.normal(0, self.radius, self.dim)\n                new_x = self.repair(new_x)\n\n                f = func(new_x)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = new_x\n                    success_count += 1\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Adjust radius based on success rate\n            success_rate = success_count / self.pop_size\n            if success_rate > self.success_threshold:\n                self.radius *= self.expand_factor\n            else:\n                self.radius *= self.shrink_factor\n            \n            self.radius = np.clip(self.radius, 1e-6, (self.ub - self.lb)/2) #prevent radius from becoming too small or too big\n            success_count = 0\n        return self.f_opt, self.x_opt", "objective": -0.59696, "other_inf": null}
{"id": "b8ec20da-09ce-40e1-b313-2bad77c47ced", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Simulated Annealing with adaptive temperature schedule and neighborhood search.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n        \n        self.f_opt = current_f\n        self.x_opt = current_x\n        \n        temp = self.initial_temp\n\n        while self.budget > 0:\n            # Generate neighbor\n            neighbor_x = current_x + np.random.normal(0, temp/self.initial_temp, size=self.dim)\n            neighbor_x = np.clip(neighbor_x, func.bounds.lb, func.bounds.ub)\n            \n            neighbor_f = func(neighbor_x)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = neighbor_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                current_x = neighbor_x\n                current_f = neighbor_f\n                \n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n\n            # Cool down\n            temp *= self.cooling_rate\n\n        return self.f_opt, self.x_opt", "objective": -0.17771, "other_inf": null}
{"id": "7d20a7cc-7793-4985-8048-2d13c938d0c2", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "82c89846-256a-4cff-a890-88b7667c4eea"], "algorithm": "An algorithm that combines elements of both evolutionary and swarm-based approaches by having a population of particles that update their positions based on a combination of differential evolution mutation and a social learning component influenced by the population's best performing members.", "code": "import numpy as np\n\nclass HybridEvolutionarySwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, c1=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.c1 = c1\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Social Learning\n                r = np.random.rand(self.dim)\n                trial = trial + self.c1 * r * (self.x_opt - trial)\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]    \n        return self.f_opt, self.x_opt", "objective": -0.45462, "other_inf": null}
{"id": "f0be2108-af4a-4f1a-b009-7fde648327f0", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the function evaluations and a memory of the best solutions found so far.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.temp = initial_temp\n        self.memory_size = memory_size\n        self.memory = []\n        self.memory_fitness = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def acceptance_probability(self, old_cost, new_cost, temp):\n        if new_cost < old_cost:\n            return 1.0\n        else:\n            return np.exp((old_cost - new_cost) / temp)\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        current_cost = func(x)\n        self.eval_count += 1\n        self.f_opt = current_cost\n        self.x_opt = x\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            neighbor = x + np.random.normal(0, 0.1, size=self.dim)\n            neighbor = np.clip(neighbor, self.lb, self.ub)\n\n            # Evaluate neighbor\n            new_cost = func(neighbor)\n            self.eval_count += 1\n\n            # Acceptance criterion\n            ap = self.acceptance_probability(current_cost, new_cost, self.temp)\n\n            if ap > np.random.rand():\n                x = neighbor\n                current_cost = new_cost\n\n                if current_cost < self.f_opt:\n                    self.f_opt = current_cost\n                    self.x_opt = x\n                    \n                    if len(self.memory) < self.memory_size:\n                        self.memory.append(x.copy())\n                        self.memory_fitness.append(current_cost)\n                    else:\n                        max_fit_idx = np.argmax(self.memory_fitness)\n                        if current_cost < self.memory_fitness[max_fit_idx]:\n                            self.memory[max_fit_idx] = x.copy()\n                            self.memory_fitness[max_fit_idx] = current_cost\n\n            #Adaptive Temperature Schedule\n            if self.eval_count % 100 == 0: # Adjust temperature every 100 evaluations\n                if len(self.memory) > 0:\n                    self.temp = self.initial_temp * np.mean(self.memory_fitness) / self.f_opt\n                else:\n                     self.temp *= self.cooling_rate\n            \n            if self.temp < 1e-6:\n                self.temp = 1e-6 # prevent temp from going to 0\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.25083, "other_inf": null}
{"id": "3c82f2de-7d4a-4ea8-a640-61a0b60f8d61", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "82c89846-256a-4cff-a890-88b7667c4eea"], "algorithm": "A restart mechanism using fitness-based probabilities and a modified mutation operator to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass FitnessProbabilityRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.6, CR=0.8, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Calculate probabilities based on fitness\n            fitness_normalized = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-8)\n            probabilities = 1 - fitness_normalized\n            probabilities /= np.sum(probabilities)\n\n            for i in range(self.pop_size):\n                # Mutation with fitness-based modification\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False, p=probabilities[idxs])]\n                mutant = a + self.F * (b - c) + np.random.normal(0, 0.01, self.dim) # Adding noise\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -=1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n                        \n                if self.budget <= 0:\n                    break\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d3df00d3-207d-43ba-996c-b605228e4e7a", "parents": ["82c89846-256a-4cff-a890-88b7667c4eea", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "This algorithm uses a population-based approach where individuals learn from both their best historical experiences and the experiences of the top individuals in the population, dynamically adjusting their learning rates based on their success.", "code": "import numpy as np\n\nclass TopLeadersEnhancedLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, top_ratio=0.2, initial_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.top_ratio = top_ratio\n        self.initial_lr = initial_lr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.learning_rates = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.learning_rates = np.full(self.pop_size, self.initial_lr)\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Identify top individuals\n            num_top = int(self.pop_size * self.top_ratio)\n            top_indices = np.argsort(self.fitness)[:num_top]\n            top_individuals = self.population[top_indices]\n\n            for i in range(self.pop_size):\n                # Learn from personal best\n                to_personal_best = self.personal_best_positions[i] - self.population[i]\n                \n                # Learn from a randomly selected top individual\n                top_individual = top_individuals[np.random.randint(num_top)]\n                to_top_individual = top_individual - self.population[i]\n\n                # Update position\n                new_position = self.population[i] + self.learning_rates[i] * (to_personal_best + to_top_individual)\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluate fitness\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                # Update personal best and learning rate\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n                    self.learning_rates[i] *= 1.1  # Increase learning rate if successful\n                else:\n                    self.learning_rates[i] *= 0.9  # Decrease learning rate if unsuccessful\n\n                self.learning_rates[i] = np.clip(self.learning_rates[i], 0.01, 0.5)\n\n                # Update population and fitness\n                self.population[i] = new_position\n                self.fitness[i] = new_fitness\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_position.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.25942, "other_inf": null}
{"id": "2b7101cd-86ae-4588-8556-e489e399de3e", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy with a budget-aware step-size adaptation and boundary handling.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, c_mu=0.1, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.c_mu = c_mu\n        self.c_cov = c_cov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = None\n        self.C = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.p_sigma = np.zeros(dim)\n        self.p_c = np.zeros(dim)\n        self.eigenspace = None\n        self.eigenvalues = None\n        self.invsqrtC = None\n        self.mu_eff = None\n\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.mu_eff = self.pop_size / (np.sum(np.arange(1,self.pop_size+1)**-1))\n        \n        weights = np.log(self.pop_size+1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = weights/np.sum(weights)\n        mueff = self.mu_eff\n        self.c_mu = min(1-self.c_cov, mueff/np.linalg.norm(self.C,\"fro\")**2)\n        self.c_cov = min(1 - self.c_mu, (2+(mueff/self.dim))/( (self.dim + (mueff/self.dim)) ))\n\n        self.damps = 1 + 2*max(0, np.sqrt((mueff - 1)/(self.dim + 1)) -1) + self.cs\n    \n    def update_distribution(self, x, fitness):\n        #Sort by fitness\n        idx = np.argsort(fitness)\n        x = x[idx]\n\n        # Weighted recombination\n        delta_mean = np.sum(self.weights[:,None] * (x[:self.pop_size] - self.mean), axis=0)\n        self.mean += self.c_mu * delta_mean\n\n        #Adaptation of stepsize sigma\n        self.p_sigma = (1-self.cs)*self.p_sigma + np.sqrt(self.cs*(2 - self.cs) * self.mu_eff) * (self.invsqrtC @ delta_mean / self.sigma)\n        self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.p_sigma)/ np.sqrt(self.dim) - 1))\n\n        #Adapt covariance matrix C\n        x_i = (x[:self.pop_size] - self.mean)/self.sigma\n        self.p_c = (1-self.c_cov)*self.p_c + np.sqrt(self.c_cov * (2-self.c_cov) * self.mu_eff) * delta_mean/self.sigma\n        self.C = (1-self.c_cov)*self.C + self.c_cov*(self.p_c[:,None] @ self.p_c[None,:])\n        \n        for i in range(self.pop_size):\n            self.C += self.c_mu * self.weights[i] * (x_i[i,:,None] @ x_i[i,None,:])\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def sample(self):\n      z = np.random.normal(0,1, (self.pop_size, self.dim))\n      x = self.mean + self.sigma * (self.eigenspace @ (self.eigenvalues*z.T)).T\n      return x\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            # Sample population\n            self.eigenvalues, self.eigenspace = np.linalg.eigh(self.C)\n            self.eigenvalues = np.sqrt(np.abs(self.eigenvalues))\n            self.invsqrtC = self.eigenspace @ np.diag(self.eigenvalues**-1) @ self.eigenspace.T\n\n            x = self.sample()\n\n            # Evaluate population, repair the boundary\n            fitness = np.zeros(self.pop_size)\n            for i in range(self.pop_size):\n              x[i] = self.repair(x[i])\n              fitness[i] = func(x[i])\n              self.eval_count += 1\n\n              if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = x[i]\n              if self.eval_count >= self.budget:\n                break\n            if self.eval_count >= self.budget:\n              break\n\n            self.update_distribution(x, fitness)\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e4550614-7f1c-4c4e-94d8-be0bdaad68fb", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "A modified Differential Evolution algorithm that incorporates a population-wide learning strategy by updating each individual's position based on the weighted average of the best individuals and a random selection from the population, promoting faster convergence towards promising regions.", "code": "import numpy as np\n\nclass ModifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, top_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.top_ratio = top_ratio\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            top_indices = sorted_indices[:int(self.pop_size * self.top_ratio)]\n            top_population = population[top_indices]\n\n            for i in range(self.pop_size):\n                # Weighted average of top individuals\n                weights = np.random.rand(len(top_indices))\n                weights /= np.sum(weights)\n                weighted_sum = np.sum(top_population * weights[:, np.newaxis], axis=0)\n\n                # Random selection from the population\n                random_index = np.random.randint(self.pop_size)\n                random_individual = population[random_index]\n\n                # Update individual's position\n                mutant = population[i] + 0.5 * (weighted_sum - population[i]) + 0.5 * (random_individual - population[i])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the mutant\n                f = func(mutant)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = mutant\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = mutant\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.24927, "other_inf": null}
{"id": "fe310552-2d87-48e0-b5c6-8151dc8a3256", "parents": ["82c89846-256a-4cff-a890-88b7667c4eea"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the observed fitness landscape, adjusting exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, temp_min=0.0001, alpha=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.temp_min = temp_min\n        self.alpha = alpha\n        self.lb = -5.0\n        self.ub = 5.0\n        self.current_x = None\n        self.current_f = np.inf\n        self.best_x = None\n        self.best_f = np.inf\n        self.eval_count = 0\n        self.temp = initial_temp\n\n    def __call__(self, func):\n        self.current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.current_f = func(self.current_x)\n        self.eval_count += 1\n        self.best_x = self.current_x.copy()\n        self.best_f = self.current_f\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            new_x = self.current_x + np.random.normal(0, 0.1, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n\n            # Evaluate neighbor\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            # Acceptance probability\n            delta_f = new_f - self.current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.current_x = new_x.copy()\n                self.current_f = new_f\n\n                if new_f < self.best_f:\n                    self.best_f = new_f\n                    self.best_x = new_x.copy()\n            \n            # Adaptive temperature schedule\n            if self.eval_count % 100 == 0:\n                if self.temp > self.temp_min:\n                  self.temp *= self.alpha\n                else:\n                  self.temp = self.temp_min\n\n            if self.eval_count >= self.budget:\n              break\n        \n\n        self.f_opt = self.best_f\n        self.x_opt = self.best_x\n        return self.f_opt, self.x_opt", "objective": -0.29309, "other_inf": null}
{"id": "25ddc014-4776-4c99-8b00-dfb67c65af82", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "# Description: This algorithm utilizes a self-adaptive step size and a combination of global and local search strategies inspired by simulated annealing and differential evolution, aiming to balance exploration and exploitation effectively.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_temp=1.0, cooling_rate=0.95, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        temp = self.initial_temp\n        while self.budget > 0 and temp > 1e-5:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection (Simulated Annealing inspired)\n                f = func(trial)\n                self.budget -= 1\n                delta_e = f - fitness[i]\n                if delta_e < 0:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    acceptance_prob = np.exp(-delta_e / temp)\n                    if np.random.rand() < acceptance_prob:\n                        fitness[i] = f\n                        population[i] = trial\n\n            temp *= self.cooling_rate\n        \n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.49579, "other_inf": null}
{"id": "d43490cf-d7c5-4e12-b7bd-1d78bf9a3314", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a repair mechanism to enforce bounds.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        self.ccov1 = min(1, self.ccov1 * (self.dim + 1.3)**2 / (self.mueff + 2))\n        \n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        \n    def initialize(self):\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            Z = np.random.normal(0, 1, size=(self.dim, self.pop_size))\n            Y = np.dot(np.linalg.cholesky(self.C), Z)\n            X = self.m[:, np.newaxis] + self.sigma * Y\n            X = np.clip(X, self.lb, self.ub)\n\n            fitness = np.array([func(x) for x in X.T])\n            self.eval_count += self.pop_size\n\n            idx_sorted = np.argsort(fitness)\n            fitness = fitness[idx_sorted]\n            X = X[:, idx_sorted]\n\n            x_best = X[:, 0]\n            f_best = fitness[0]\n            \n            if f_best < self.f_opt:\n                self.f_opt = f_best\n                self.x_opt = x_best\n\n            m_old = self.m.copy()\n            self.m = np.dot(X[:, :self.mu], self.weights)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.m - m_old)) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1) * self.mueff) * (self.m - m_old) / self.sigma\n\n            artmp = (1 / self.sigma) * (X[:, :self.mu] - m_old[:, np.newaxis])\n            self.C = (1 - self.ccov1 - self.ccovmu * np.sum(self.weights**2)) * self.C + self.ccov1 * np.outer(self.pc, self.pc) + self.ccovmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n            \n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            if np.min(np.diag(self.C)) <= 0:\n                self.C = np.eye(self.dim)\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "909dbec5-5da6-4aed-bcca-ab47fa2b677c", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "A Population-based Simulated Annealing algorithm with adaptive temperature and mutation rate, where the population explores the search space and gradually converges towards the optimum based on acceptance probabilities.", "code": "import numpy as np\n\nclass PopulationBasedSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_temp=100.0, cooling_rate=0.95, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        temperature = self.initial_temp\n        \n        while self.budget > 0 and temperature > 1e-5:\n            for i in range(self.pop_size):\n                # Mutation\n                mutation = np.random.normal(0, self.mutation_rate * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                mutant = population[i] + mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate mutant\n                f_mutant = func(mutant)\n                self.budget -= 1\n\n                # Acceptance probability\n                delta_e = f_mutant - fitness[i]\n                if delta_e < 0:\n                    population[i] = mutant\n                    fitness[i] = f_mutant\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n                else:\n                    acceptance_probability = np.exp(-delta_e / temperature)\n                    if np.random.rand() < acceptance_probability:\n                        population[i] = mutant\n                        fitness[i] = f_mutant\n\n            # Cooling\n            temperature *= self.cooling_rate\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt", "objective": -0.30376, "other_inf": null}
{"id": "03addfc2-b960-4675-854e-019f865866fe", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "An enhanced CMA-ES variant with a population-based approach, restarts based on stagnation detection, and dynamic parameter adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, c_cov=0.05, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.cs = cs\n        self.c_cov = c_cov\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.D = None\n        self.B = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_count = 0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 500\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.sigma0\n        self.C = np.eye(self.dim)\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(self.D)\n        self.stagnation_counter = 0\n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.pop_size)\n        x = self.mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * z))\n        x = np.clip(x, self.lb, self.ub)\n        return x.T\n\n    def update_distribution(self, x, fitness):\n        idx = np.argsort(fitness)\n        x_sorted = x[idx]\n        weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n\n        delta_mean = np.sum(weights[:, np.newaxis] * (x_sorted - self.mean), axis=0)\n        self.mean = self.mean + self.cs * delta_mean\n\n        z = (x_sorted - self.mean) / self.sigma\n        C_update = np.sum(weights[:, np.newaxis, np.newaxis] * z[:, :, np.newaxis] * z[:, np.newaxis, :], axis=0)\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * C_update\n\n        try:\n            self.D, self.B = np.linalg.eig(self.C)\n            self.D = np.sqrt(self.D)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            self.D = np.ones(self.dim)\n            self.B = np.eye(self.dim)\n\n        self.sigma = self.sigma * np.exp(self.cs / 0.414 * (np.linalg.norm(delta_mean / self.sigma) - np.sqrt(self.dim)))\n        self.sigma = min(self.sigma, 5)\n        self.sigma = max(self.sigma, 1e-6)\n        \n        if np.allclose(delta_mean, 0):\n            self.stagnation_counter += 1\n        else:\n            self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n\n            self.update_distribution(x, fitness)\n\n            if self.stagnation_counter > self.stagnation_threshold and self.restart_count < self.restarts:\n                self.initialize()\n                self.restart_count += 1\n                self.stagnation_counter = 0\n                \n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.10305, "other_inf": null}
{"id": "13ad7436-596f-4533-a5aa-c8f443d7076c", "parents": ["82c89846-256a-4cff-a890-88b7667c4eea"], "algorithm": "A differential evolution algorithm with a self-adaptive mutation strategy and a population reduction scheme to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Self-adaptive F\n                F = np.random.normal(self.F, 0.1, 1)[0]\n                F = np.clip(F, 0.1, 1.0)\n\n                mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Population reduction (optional - makes algorithm more complex)\n            if self.pop_size > 10 and self.eval_count > self.budget * 0.75:\n                sorted_indices = np.argsort(self.fitness)[::-1]\n                reduce_amount = max(1, int(0.1 * self.pop_size))\n                self.population = self.population[sorted_indices[:-reduce_amount]]\n                self.fitness = self.fitness[sorted_indices[:-reduce_amount]]\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "objective": -0.70018, "other_inf": null}
{"id": "97ddad6a-382f-43e6-9b7d-29f4fb5ec384", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "Simulated Annealing with adaptive temperature and step size, focusing on balancing exploration and exploitation based on success rate.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, step_size=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.step_size = step_size\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.temp = initial_temp\n        self.success_rate = 0.0\n        self.success_count = 0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        self.eval_count += 1\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            x_new = self.x_opt + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluate neighbor\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance probability\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                if delta_f < 0:\n                    self.success_count += 1\n                self.x_opt = x_new.copy()\n                self.f_opt = f_new\n\n            # Adaptive temperature and step size\n            self.temp *= self.cooling_rate\n            self.success_rate = self.success_count / self.eval_count if self.eval_count > 0 else 0\n            if self.success_rate > 0.15:\n                self.step_size *= 1.05  # Increase step size to explore further\n            elif self.success_rate < 0.01:\n                self.step_size *= 0.95  # Decrease step size to exploit more\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.41477, "other_inf": null}
{"id": "8698ed59-bc67-451c-b696-6337a4411f84", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A single-solution based algorithm that employs a noisy gradient estimation and adaptive step size to iteratively move towards the minimum, escaping local optima using random perturbations.", "code": "import numpy as np\n\nclass NoisyGradientDescent:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, noise_level=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.noise_level = noise_level\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.x_opt = x\n        self.f_opt = func(x)\n        self.budget -= 1\n\n        while self.budget > 0:\n            # Estimate noisy gradient\n            grad = np.zeros(self.dim)\n            num_samples = min(self.dim * 2, self.budget)\n            for _ in range(num_samples):\n                delta = np.random.normal(0, self.noise_level, size=self.dim)\n                x_perturbed = x + delta\n                x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                grad += (f_perturbed - self.f_opt) * delta\n            \n            if num_samples > 0:\n                grad /= num_samples * self.noise_level**2\n            \n            # Update position\n            x_new = x - self.step_size * grad + np.random.normal(0, self.noise_level, size=self.dim) # Add random perturbation\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.step_size *= 1.05 # Adaptive step size\n            else:\n                self.step_size *= 0.95 # Reduce step size\n        \n        return self.f_opt, self.x_opt", "objective": -0.23999, "other_inf": null}
{"id": "509ebf33-aa8e-40b5-a1ac-bb6c086dc101", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restart mechanism and budget-aware adaptation of population size to balance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, c_cov_mean=None, c_cov_rank_one=None, mu_eff=None, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.restarts = restarts\n        \n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n        self.c_cov_mean = 1 / self.c_sigma / self.dim**(0.5) if c_cov_mean is None else c_cov_mean\n        self.c_cov_rank_one = 2 / ((self.dim + 1.3)**2 + self.mu_eff) if c_cov_rank_one is None else c_cov_rank_one\n        self.c_cov_rank_mu = min(1 - self.c_cov_rank_one, 2 * (self.mu_eff - 2 + 1 / self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma if damps is None else damps\n\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self, func):\n        z = np.random.randn(self.dim, self.pop_size)\n        x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        \n        fitness = np.array([func(xi) for xi in x.T])\n        self.eval_count += self.pop_size\n        return x, fitness\n\n    def update_distribution(self, x, fitness):\n        indices = np.argsort(fitness)\n        x_mu = x[:, indices[:self.mu]]\n        \n        m_old = self.m.copy()\n        self.m = np.dot(x_mu, self.weights)\n\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu_eff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.m - m_old)) / self.sigma\n        self.pc = (1 - self.c_cov_mean) * self.pc + np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean) * self.mu_eff) * (self.m - m_old) / self.sigma\n        \n        hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.eval_count / self.pop_size)) / np.sqrt(self.dim) < 1.4 + 2 / (self.dim + 1))\n        self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + self.c_cov_rank_one * np.outer(self.pc, self.pc) + self.c_cov_rank_mu * np.dot(x_mu - m_old[:, np.newaxis], np.dot(np.diag(self.weights), (x_mu - m_old[:, np.newaxis]).T)) / self.sigma**2\n\n        self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        for _ in range(self.restarts):\n            while self.eval_count < self.budget:\n                x, fitness = self.sample_population(func)\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = x[:,best_index].copy()\n                \n                self.update_distribution(x, fitness)\n                \n                if np.linalg.det(self.C) <= 0 or np.isnan(np.linalg.det(self.C)):\n                    self.initialize(func)\n                    break\n                \n                if self.eval_count > self.budget * 0.8 and self.pop_size > 10:\n                     self.pop_size = max(10, self.pop_size // 2)\n                     self.mu = self.pop_size // 2\n                     self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                     self.weights /= np.sum(self.weights)\n                     self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "76043103-8765-4e91-abcf-94fd5516b711", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified adaptation rules and a focus on exploration in early stages to locate promising regions.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=1.0, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.cs = cs\n        self.c_cov = c_cov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.path_s = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            population = self.sample_population()\n            population = np.array([self.repair(x) for x in population])\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n            \n            # Find best individual\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Update mean\n            weights = np.zeros(self.pop_size)\n            weights[best_index] = 1.0  # Only best individual influences the mean\n            delta_mean = np.sum((weights * (population - self.mean).T).T, axis=0)\n            self.mean = self.mean + delta_mean\n\n            # Update evolution path\n            self.path_s = (1 - self.cs) * self.path_s + np.sqrt(self.cs * (2 - self.cs)) * delta_mean / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.path_s, self.path_s)\n            \n            # Ensure C is positive definite (numerical stability)\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp(self.cs/0.881 * (np.linalg.norm(self.path_s)/np.sqrt(self.dim) - 1))\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.33731, "other_inf": null}
{"id": "e2df9196-c219-4692-b48f-9cdcc3094759", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A population-based algorithm that iteratively refines candidate solutions by sampling new points around the best individuals, adapting the sampling radius based on success rate, and focusing on promising regions of the search space.", "code": "import numpy as np\n\nclass AdaptiveSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=1.0, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_radius = initial_radius\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.radii = None\n        self.success_rates = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n        self.radii = np.full(self.pop_size, self.initial_radius)\n        self.success_rates = np.zeros(self.pop_size)\n\n    def sample_around(self, x, radius):\n        sample = x + np.random.normal(0, radius, self.dim)\n        return np.clip(sample, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Sample around the current individual\n                new_x = self.sample_around(self.population[i], self.radii[i])\n                f = func(new_x)\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.success_rates[i] = min(1.0, self.success_rates[i] + 0.1)\n                    self.fitness[i] = f\n                    self.population[i] = new_x.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x.copy()\n                else:\n                    self.success_rates[i] = max(0.0, self.success_rates[i] - 0.1)\n\n                # Adjust the radius based on success rate\n                if self.success_rates[i] > self.success_threshold:\n                    self.radii[i] *= 1.1  # Expand search\n                else:\n                    self.radii[i] *= 0.9  # Narrow search\n                self.radii[i] = np.clip(self.radii[i], 1e-6, self.ub - self.lb)\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.37755, "other_inf": null}
{"id": "8e1c7e2e-2fad-44be-aba7-73b4655d4e49", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "```", "code": "import numpy as np\n\nclass ModifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim / 2\n        self.c_cov = c_cov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n        x = self.mean + self.sigma * z\n        return np.clip(x, self.lb, self.ub)\n\n    def update_parameters(self, x, fitness):\n        best_index = np.argmin(fitness)\n        y = (x[best_index] - self.mean) / self.sigma\n        self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * y\n        self.mean = x[best_index]\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (np.outer(self.pc, self.pc))\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            self.update_parameters(x, fitness)\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt\n# Description: Adapt CMA-ES by simplifying covariance matrix adaptation, focusing on rank-one updates with a dynamically adjusted step size and simplified parameter updates to balance exploration and exploitation more efficiently.\n# Code:\n```python\nimport numpy as np\n\nclass ModifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim / 2\n        self.c_cov = c_cov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n        x = self.mean + self.sigma * z\n        return np.clip(x, self.lb, self.ub)\n\n    def update_parameters(self, x, fitness):\n        best_index = np.argmin(fitness)\n        y = (x[best_index] - self.mean) / self.sigma\n        self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * y\n        self.mean = x[best_index]\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (np.outer(self.pc, self.pc))\n        self.sigma *= np.exp(self.cs/self.damps*(np.linalg.norm(self.pc)/np.sqrt(self.dim)-1))\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            self.update_parameters(x, fitness)\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "71fb98f6-35eb-4cd0-9cae-9e88a49084cc", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the fitness landscape and occasional random restarts.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_x = None\n        self.current_f = None\n        self.temp = initial_temp\n\n    def initialize(self, func):\n        self.current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.current_f = func(self.current_x)\n        self.eval_count += 1\n        self.f_opt = self.current_f\n        self.x_opt = self.current_x.copy()\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate neighbor\n            neighbor_x = self.current_x + np.random.normal(0, self.temp/10, size=self.dim) # Scale perturbation by temperature\n            neighbor_x = np.clip(neighbor_x, self.lb, self.ub)\n            neighbor_f = func(neighbor_x)\n            self.eval_count += 1\n\n            # Acceptance probability\n            delta_f = neighbor_f - self.current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.current_x = neighbor_x\n                self.current_f = neighbor_f\n\n                if neighbor_f < self.f_opt:\n                    self.f_opt = neighbor_f\n                    self.x_opt = neighbor_x.copy()\n\n            # Adaptive Temperature Schedule\n            self.temp *= self.cooling_rate\n\n            #Random Restarts\n            if self.eval_count % (self.budget // 10) == 0:\n                new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                new_f = func(new_x)\n                self.eval_count += 1\n                if new_f < self.f_opt:\n                  self.f_opt = new_f\n                  self.x_opt = new_x.copy()\n                self.current_x = new_x\n                self.current_f = new_f\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "03a73449-0925-46c3-8761-80c74e4d3007", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "Simulated annealing with adaptive temperature and step size, focusing on balancing exploration and exploitation based on the success rate of moves.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_x = None\n        self.current_f = None\n        self.temp = initial_temp\n        self.success_count = 0\n        self.move_count = 0\n\n\n    def initialize(self, func):\n        self.current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.current_f = func(self.current_x)\n        self.eval_count += 1\n        self.f_opt = self.current_f\n        self.x_opt = self.current_x.copy()\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Generate a new candidate solution\n            new_x = self.current_x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            self.eval_count += 1\n\n            # Acceptance probability\n            delta_f = new_f - self.current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.current_x = new_x.copy()\n                self.current_f = new_f\n                self.success_count += 1\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x.copy()\n\n            self.move_count += 1\n\n            # Adaptive temperature and step size\n            self.temp *= self.cooling_rate\n            if self.move_count % 100 == 0:\n                success_rate = self.success_count / self.move_count\n                if success_rate > 0.6:\n                    self.step_size *= 1.1\n                elif success_rate < 0.4:\n                    self.step_size *= 0.9\n                self.success_count = 0\n                self.move_count = 0\n                self.step_size = np.clip(self.step_size, 0.01, 2.0)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.46877, "other_inf": null}
{"id": "208b0491-2174-4cbd-974c-245d52f6657e", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "# Description: This algorithm uses a modified differential evolution strategy with a dynamically adjusted mutation factor and a repair mechanism to enhance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionRepair:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, CR=0.7, F_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init\n        self.CR = CR\n        self.F_adapt = F_adapt\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                \n                # Repair mechanism\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.F = max(0, self.F - self.F_adapt) # Adaptive F\n                else:\n                     self.F = min(1, self.F + self.F_adapt) # Adaptive F\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]    \n        return self.f_opt, self.x_opt", "objective": -0.41431, "other_inf": null}
{"id": "c460300d-7af2-461f-be6e-ec97d4472307", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A hybrid optimization algorithm combining differential evolution with a local search strategy based on Nelder-Mead simplex method to refine promising solutions.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, Cr=0.9, local_search_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_freq = local_search_freq\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       bounds=[(self.lb, self.ub)] * self.dim,\n                       options={'maxiter': 50", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, Cr=0.9, local_search_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_freq = local_search_freq\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead',\n                       bounds=[(self.lb, self.ub)] * self.dim,\n                       options={'maxiter': 50})  # Reduced maxiter to control budget\n        return res.fun, res.x, res.nit #Number of iterations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n\n                # Local Search\n                if np.random.rand() < self.local_search_freq and self.eval_count < self.budget:\n                    f_local, x_local, niter = self.local_search(func, self.population[i])\n                    self.eval_count += niter\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local.copy()\n\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n                            \n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4467b132-6eda-468c-a65a-bf47a926e77e", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A hybrid algorithm combining the exploration of Particle Swarm Optimization (PSO) with the exploitation capabilities of Differential Evolution (DE), using a dynamic switching mechanism based on performance feedback to adaptively balance global and local search.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.8, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.F = F  # Mutation factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.velocity = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.pso_phase = True  # Start with PSO\n        self.switch_threshold = 0.9  # Threshold for switching\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocity\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[best_index].copy()\n        self.global_best_fitness = self.fitness[best_index]\n\n    def update_success_rate(self, success):\n        self.success_history.append(success)\n        if len(self.success_history) > 20:\n            self.success_history = self.success_history[-20:]  # Keep only the last 20 values\n        self.success_rate = np.mean(self.success_history)\n\n\n    def pso_step(self, func):\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocity[i] = (self.w * self.velocity[i]\n                               + self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                               + self.c2 * r2 * (self.global_best_position - self.population[i]))\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n            f = func(self.population[i])\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.population[i].copy()\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.population[i].copy()\n                        self.update_success_rate(1) # Successful update\n            else:\n                self.update_success_rate(0) # Unsuccessful update\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            indices = [j for j in range(self.pop_size) if j != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.Cr\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f = func(trial_vector)\n            self.eval_count += 1\n\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial_vector.copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial_vector.copy()\n                    self.update_success_rate(1)  # Successful update\n            else:\n                self.update_success_rate(0)  # Unsuccessful update\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if self.pso_phase:\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            # Switching mechanism\n            if self.success_rate < self.switch_threshold:\n                self.pso_phase = not self.pso_phase  # Switch phase\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "0c7cd042-f431-4ec8-8d5b-ee990fe0456a", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A hybrid algorithm combining differential evolution with a Nelder-Mead simplex search performed on the best individuals to refine the solution.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, nm_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nm_iterations = nm_iterations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def nelder_mead_refinement(self, func, x):\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.nm_iterations, 'maxfev':self.budget - self.eval_count", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, nm_iterations=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.nm_iterations = nm_iterations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def nelder_mead_refinement(self, func, x):\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(func, x, method='Nelder-Mead', bounds=bounds, options={'maxiter': self.nm_iterations, 'maxfev':self.budget - self.eval_count})\n        \n        return result.fun, result.x, result.nfev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Nelder-Mead on best individual\n            best_index = np.argmin(self.fitness)\n            f_nm, x_nm, nfev = self.nelder_mead_refinement(func, self.population[best_index])\n            self.eval_count += nfev\n            if f_nm < self.f_opt:\n                self.f_opt = f_nm\n                self.x_opt = x_nm.copy()\n            self.fitness[best_index] = f_nm\n            self.population[best_index] = x_nm.copy()\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2c957891-6a47-440b-8303-5055ed859ee5", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "An improved differential evolution algorithm incorporating a larger population size, lower mutation factor, higher crossover rate, and adaptive population reduction triggered earlier in the optimization process, alongside a mirrored sampling technique for better exploration of the search space.", "code": "import numpy as np\n\nclass ImprovedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=100, F=0.3, Cr=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        # Mirrored sampling to enhance coverage\n        mirrored_population = self.lb + self.ub - self.population\n        self.population = np.concatenate((self.population, mirrored_population), axis=0)\n        self.pop_size = len(self.population)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Mutation\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Population reduction triggered earlier\n            if self.pop_size > 10 and self.eval_count > self.budget * 0.5:\n                sorted_indices = np.argsort(self.fitness)[::-1]\n                reduce_amount = max(1, int(0.1 * self.pop_size))\n                self.population = self.population[sorted_indices[:-reduce_amount]]\n                self.fitness = self.fitness[sorted_indices[:-reduce_amount]]\n                self.pop_size = len(self.population)\n\n        return self.f_opt, self.x_opt", "objective": -0.4419, "other_inf": null}
{"id": "ac984bf0-c2a1-46fb-9ac1-49cbe2e7bbf0", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget constraint, evolving a population of solutions using a multivariate normal distribution and adapting the covariance matrix to improve search direction.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mu=0.1, c_cov_one=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = None\n        self.C = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.cs = cs\n\n        if damps is None:\n          self.damps = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.cs\n        else:\n          self.damps = damps\n\n\n        self.c_cov_mu = c_cov_mu\n        self.c_cov_one = c_cov_one\n        self.weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_s = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_cov_mu = min(1 - self.c_s, self.c_cov_mu * (self.mueff / (self.dim + 13)))\n        self.c_cov_one = min(1 - self.c_s, self.c_cov_one * ((1 - self.c_cov_mu) * 2 * (self.mueff - 2 + 1 / self.mueff)) / ((self.dim + 2)**2 + self.mueff))\n\n        self.B = None\n        self.D = None\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        y = np.dot(z, np.diag(self.D))\n        y = np.dot(y, self.B.T)\n        x = self.mu + self.sigma * y\n        return x\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.mu = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            x = np.array([self.repair(xi) for xi in x])\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n              self.f_opt = np.min(fitness)\n              self.x_opt = x[np.argmin(fitness)]\n\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            y = (x - self.mu) / self.sigma\n\n            mu_old = self.mu.copy()\n            self.mu = np.sum(x[:self.pop_size] * self.weights[:, np.newaxis], axis=0)\n\n            ps_temp = np.sqrt(self.c_s * (2 - self.c_s) * self.mueff) * np.dot(self.B, np.dot(np.diag(self.D), np.mean(y[:self.pop_size], axis=0)))\n            self.ps = (1 - self.c_s) * self.ps + ps_temp\n\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_s / self.damps) * (norm_ps / self.chiN - 1))\n\n            pc_temp = np.sqrt(self.c_cov_mu * (2 - self.c_cov_mu) * self.mueff) * (self.mu - mu_old) / self.sigma\n            self.pc = (1 - self.c_cov_mu) * self.pc + pc_temp\n\n            artifical_weights = self.weights.copy()\n            idx_bad_weights = artifical_weights * np.sum(y[:self.pop_size]**2, axis=1) > self.dim\n            artifical_weights[idx_bad_weights] = 0\n            \n            dC = (1-self.c_cov_one-self.c_cov_mu) * self.C\n            dC += self.c_cov_one * (np.outer(self.pc, self.pc) + (1 - self.c_s) * self.C)\n\n            y_weighted = y[:self.pop_size] * artifical_weights[:, np.newaxis]\n\n            dC += self.c_cov_mu * np.dot(y_weighted.T, y[:self.pop_size])\n\n            self.C = dC\n            \n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.30288, "other_inf": null}
{"id": "bbba6e2b-d348-40c4-b358-9c129d68da3b", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a small population size and adaptive step size control to efficiently explore the search space within the given budget.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = (self.ub + self.lb) / 2 * np.ones(self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu)) / 2\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu / (self.dim + self.mu)) * (self.dim - 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1 / self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.m + self.sigma * z @ np.linalg.cholesky(self.C).T\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            population = self.sample_population()\n            population = np.array([self.repair(x) for x in population])\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n            if self.eval_count > self.budget:\n                fitness = fitness[:self.budget - (self.eval_count - self.pop_size)]\n                population = population[:self.budget - (self.eval_count - self.pop_size)]\n                self.pop_size = len(population)\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            population = population[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Update CMA-ES parameters\n            z = (population[:self.mu] - self.m) / self.sigma\n            y = z @ np.linalg.cholesky(self.C).T\n            self.m = np.sum(self.weights[:, None] * population[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.sqrt(self.mu) * (self.m - self.m) / self.sigma  # Using (m - old_m)\n\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * np.sqrt(self.mu) * (self.m - self.m) / self.sigma\n\n            delta = population[:self.mu] - self.m\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for i in range(self.mu):\n                self.C += self.c_mu * self.weights[i] * (delta[i][:, None] @ delta[i][None, :])\n            \n            if np.min(np.diag(self.C)) <= 0:\n                self.C += np.eye(self.dim) * 1e-10\n            \n            self.C = np.triu(self.C) + np.triu(self.C, k=1).T  # Enforce symmetry\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C += np.eye(self.dim) * 1e-8\n        return self.f_opt, self.x_opt", "objective": -0.15012, "other_inf": null}
{"id": "3ebb86a0-3b41-4d24-8f88-34053afc1ea0", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A hybrid algorithm combining the exploration of Particle Swarm Optimization (PSO) with the exploitation of Differential Evolution (DE) using a self-adaptive approach to balance the two.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.6, Cr=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.F = F  # Mutation factor for DE\n        self.Cr = Cr  # Crossover rate for DE\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.de_probability = 0.5 # Probability of applying DE in each iteration\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.eval_count += self.pop_size\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position.copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_probability:\n                    # Differential Evolution\n                    indices = [j for j in range(self.pop_size) if j != i]\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n\n                    mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                    mutant = np.clip(mutant, self.lb, self.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.Cr\n                    trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                    f = func(trial_vector)\n                    self.eval_count += 1\n\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = trial_vector.copy()\n\n                        if f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f\n                            self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = trial_vector.copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position.copy()\n\n                else:\n                    # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n\n                    new_velocity = (self.w * self.velocities[i]\n                                    + self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                                    + self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n                    self.velocities[i] = new_velocity\n                    new_position = self.population[i] + self.velocities[i]\n                    new_position = np.clip(new_position, self.lb, self.ub)\n\n                    f = func(new_position)\n                    self.eval_count += 1\n\n                    if f < self.fitness[i]:\n                        self.fitness[i] = f\n                        self.population[i] = new_position.copy()\n                        if f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f\n                            self.personal_best_positions[i] = new_position.copy()\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = new_position.copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.54897, "other_inf": null}
{"id": "2f457e88-b122-49d7-a253-ca493e5a1833", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, alpha=0.99, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.alpha = alpha\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.current_x = None\n        self.current_f = None\n        self.temp = initial_temp\n        self.acceptance_rate = 0.0\n\n    def initialize(self, func):\n        self.current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.current_f = func(self.current_x)\n        self.eval_count += 1\n        self.f_opt = self.current_f\n        self.x_opt = self.current_x\n\n    def neighbor(self):\n        x_new = self.current_x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n        x_new = np.clip(x_new, self.lb, self.ub)  # Keep within bounds\n        return x_new\n\n    def acceptance_probability(self, delta_e):\n        if delta_e < 0:\n            return 1.0\n        else:\n            return np.exp(-delta_e / self.temp)\n\n    def update_temperature(self):\n        if self.acceptance_rate > 0.96:\n            self.alpha = 0.5\n        elif self.acceptance_rate < 0.04:\n            self.alpha = 0.99\n        else:\n            self.alpha = 0.95\n\n        self.temp = max(self.temp * self.alpha, self.temp_min)\n\n    def __call__(self, func):\n        self.initialize(func)\n        accepted_moves = 0\n        total_moves = 0\n\n        while self.eval_count < self.budget:\n            x_new = self.neighbor()\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_e = f_new - self.current_f\n            if self.acceptance_probability(delta_e) > np.random.rand():\n                self.current_x = x_new\n                self.current_f = f_new\n                accepted_moves += 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n            \n            total_moves +=1\n            self.acceptance_rate = accepted_moves / total_moves\n            self.update_temperature()\n\n        return self.f_opt, self.x_opt", "objective": -0.26672, "other_inf": null}
{"id": "f062b32b-e154-4f90-82aa-5eeecf1e59ec", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "This algorithm uses a Simulated Annealing approach with adaptive temperature adjustment based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, temp_adjust_freq=50):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_adjust_freq = temp_adjust_freq\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        acceptance_history = []\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_f = f_new - f\n            \n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                acceptance_history.append(1)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_history.append(0)\n\n            # Temperature adjustment based on acceptance rate\n            if len(acceptance_history) >= self.temp_adjust_freq:\n                acceptance_rate = np.mean(acceptance_history[-self.temp_adjust_freq:])\n                if acceptance_rate > 0.6:\n                    temp *= 1.1  # Increase temperature if accepting too often\n                elif acceptance_rate < 0.4:\n                    temp *= 0.9  # Decrease temperature if accepting too rarely\n\n            temp *= self.cooling_rate #Gradually reduce temperature\n                \n        return self.f_opt, self.x_opt", "objective": -0.17678, "other_inf": null}
{"id": "4f6cfc86-2019-4052-9545-d585513be398", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "A global optimization algorithm using a population of particles that stochastically explore the search space, guided by their own best-found positions and the swarm's best-found position, while employing a velocity clamping mechanism to prevent divergence.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, v_max=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max # Velocity clamping\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitnesses[global_best_index]\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)  # Keep within bounds\n\n                # Evaluate fitness\n                f = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.30022, "other_inf": null}
{"id": "393750e9-340c-4072-b4bc-9255b5f2692b", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A gradient-free optimization algorithm that adaptively samples points in the search space, focusing on regions with promising function values, and refines the search based on a local approximation of the objective function using radial basis functions.", "code": "import numpy as np\nfrom scipy.interpolate import Rbf\n\nclass AdaptiveSamplingRBF:\n    def __init__(self, budget=10000, dim=10, num_init_samples=50, rbf_epsilon=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_init_samples = num_init_samples\n        self.rbf_epsilon = rbf_epsilon\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initial sampling\n        X = np.random.uniform(self.lb, self.ub, size=(self.num_init_samples, self.dim))\n        y = np.array([func(x) for x in X])\n        self.budget -= self.num_init_samples\n\n        best_index = np.argmin(y)\n        self.f_opt = y[best_index]\n        self.x_opt = X[best_index]\n\n        while self.budget > 0:\n            # Train RBF model\n            rbf = Rbf(X, y, function='gaussian', epsilon=self.rbf_epsilon)\n\n            # Sample new points based on RBF prediction\n            num_new_samples = min(50, self.budget)  # Limit the number of new samples\n            X_new = np.random.uniform(self.lb, self.ub, size=(num_new_samples, self.dim))\n            y_pred = rbf(*X_new.T)\n\n            # Evaluate function at new points\n            y_new = np.array([func(x) for x in X_new])\n            self.budget -= num_new_samples\n\n            # Update the sample set\n            X = np.vstack((X, X_new))\n            y = np.hstack((y, y_new))\n\n            # Update best solution\n            best_index = np.argmin(y)\n            self.f_opt = y[best_index]\n            self.x_opt = X[best_index]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "777efcd1-29f3-4325-ac1f-b7505f6f1ff2", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "# Description: An estimation of distribution algorithm that iteratively learns a multivariate normal distribution from promising solutions and samples new solutions from it.\n# Code:\n```", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\n\nclass EstimationOfDistributionAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, elite_frac=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.elite_frac = elite_frac\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Select elite individuals\n            num_elites = int(self.elite_frac * self.pop_size)\n            elite_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elite_indices]\n\n            # Estimate distribution from elites\n            mean = np.mean(elites, axis=0)\n            covariance = np.cov(elites, rowvar=False)\n            \n            # Add a small constant to the diagonal to ensure positive definiteness\n            covariance += np.eye(self.dim) * 1e-6  \n\n            # Sample new population from the estimated distribution\n            try:\n                new_population = np.random.multivariate_normal(mean, covariance, self.pop_size)\n            except np.linalg.LinAlgError:\n                # If covariance is not positive definite, sample from a uniform distribution\n                new_population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n            \n            new_population = np.clip(new_population, self.lb, self.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.32377, "other_inf": null}
{"id": "7defaad7-bd7a-4fd5-a178-c086a56ac26e", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A gradient-free optimization algorithm that iteratively refines a population of solutions by perturbing them based on their fitness rank and a shrinking perturbation scale.", "code": "import numpy as np\n\nclass RankPerturbation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, perturbation_scale=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.perturbation_scale = perturbation_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Rank the population based on fitness\n            ranked_indices = np.argsort(self.fitness)\n            ranked_population = self.population[ranked_indices]\n\n            for i in range(self.pop_size):\n                # Perturb each solution based on its rank\n                rank = np.where(ranked_indices == i)[0][0]\n                \n                # Scale the perturbation based on rank (better rank, smaller perturbation)\n                scale = self.perturbation_scale * (1 - (rank / self.pop_size))\n                \n                # Generate perturbation\n                perturbation = np.random.normal(0, scale, size=self.dim)\n\n                # Apply perturbation\n                mutant = ranked_population[i] + perturbation\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Evaluate the mutant\n                f = func(mutant)\n                self.eval_count += 1\n\n                # Update the population if the mutant is better\n                if f < self.fitness[ranked_indices[i]]:\n                    self.fitness[ranked_indices[i]] = f\n                    self.population[ranked_indices[i]] = mutant.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = mutant.copy()\n                        \n                if self.eval_count >= self.budget:\n                    break\n            \n            # Reduce perturbation scale\n            self.perturbation_scale *= 0.99\n\n        return self.f_opt, self.x_opt", "objective": -0.32988, "other_inf": null}
{"id": "5a891132-de60-4a37-8649-ff1129312edf", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88", "ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the improvement rate of the objective function.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.x_current = None\n        self.f_current = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        self.x_current = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_current = func(self.x_current)\n        self.budget -= 1\n        self.f_opt = self.f_current\n        self.x_opt = self.x_current\n\n        improvements = 0\n        iterations = 0\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            x_new = self.x_current + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate neighbor solution\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = f_new - self.f_current\n            if delta_f < 0:\n                # Accept better solution\n                self.x_current = x_new\n                self.f_current = f_new\n                improvements += 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n            else:\n                # Accept worse solution with probability\n                prob = np.exp(-delta_f / self.temp)\n                if np.random.rand() < prob:\n                    self.x_current = x_new\n                    self.f_current = f_new\n\n            iterations += 1\n\n            # Adaptive temperature schedule\n            if iterations % 100 == 0:\n                improvement_rate = improvements / 100\n                if improvement_rate > 0.1:\n                    self.temp *= self.alpha # cool down\n                else:\n                    self.temp /= self.alpha #heat up\n                self.temp = np.clip(self.temp, 0.0001, 100)\n                improvements = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.31272, "other_inf": null}
{"id": "0d8e51de-1202-4844-93c1-e1db817e2596", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "# Description: An estimation of distribution algorithm that learns a Gaussian model of promising solutions and samples new candidate solutions from this model.\n# Code:\n```", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass GaussianEstimationOfDistribution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, selection_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.selection_threshold = selection_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Select promising solutions\n            threshold = np.quantile(fitness, self.selection_threshold)\n            selected_indices = np.where(fitness <= threshold)[0]\n            selected_population = population[selected_indices]\n\n            # Estimate mean and standard deviation\n            if len(selected_population) > 0:\n                mean = np.mean(selected_population, axis=0)\n                std = np.std(selected_population, axis=0)\n            else:\n                mean = np.mean(population, axis=0)\n                std = np.std(population, axis=0)\n\n            # Handle zero standard deviation\n            std = np.where(std == 0, 1.0, std)\n\n            # Generate new samples from Gaussian distribution\n            new_population = np.random.normal(mean, std, size=(self.pop_size, self.dim))\n            new_population = np.clip(new_population, self.lb, self.ub)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                \n        return self.f_opt, self.x_opt", "objective": -0.42701, "other_inf": null}
{"id": "1251aee3-adec-4ab2-9eaa-a3cc9d876da7", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, dsigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.cs = cs\n        self.dsigma = dsigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.restart_trigger = self.budget // 5\n\n    def sample_population(self):\n        z = np.random.randn(self.pop_size, self.dim)\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def repair(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            population = self.sample_population()\n            population = np.array([self.repair(x) for x in population])\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n            \n            idx = np.argsort(fitness)\n            best_individuals = population[idx[:self.mu]]\n            \n            y = best_individuals - self.mean\n            delta_mean = np.sum(self.weights[:, None] * y, axis=0)\n\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * delta_mean / self.sigma\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * np.dot(np.random.randn(self.mu, self.dim).T, y).mean(axis=1) / self.sigma\n\n            self.mean += delta_mean\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * np.outer(self.pc, self.pc) + self.cmu * np.dot((self.weights * y).T, y)\n\n            self.sigma *= np.exp((self.cs / self.dsigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            if self.eval_count > self.restart_trigger:\n               self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n               self.C = np.eye(self.dim)\n               self.pc = np.zeros(self.dim)\n               self.ps = np.zeros(self.dim)\n               self.sigma = 0.5\n               self.restart_trigger = self.eval_count + self.budget // 5\n\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7935e338-162e-43d1-98ab-148434d0940d", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A modified differential evolution algorithm with a Cauchy mutation operator, adaptive crossover, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = 0.9 # Trigger for restart mechanism\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        stagnation_counter = 0\n        last_f_opt = self.f_opt\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                #Cauchy Mutation with self adaptive scale\n                scale = np.std(self.population[a] - self.population[b])\n                mutant = self.population[a] + scale * np.random.standard_cauchy(size=self.dim) \n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Adaptive Crossover\n                Cr = np.random.uniform(0, self.Cr) # Adapt crossover rate\n                crossover_mask = np.random.rand(self.dim) < Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        stagnation_counter = 0 # Reset stagnation counter\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Stagnation Check and Restart Mechanism\n            if abs(self.f_opt - last_f_opt) < 1e-6:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            last_f_opt = self.f_opt\n            \n            if stagnation_counter > int(self.budget * self.restart_trigger/self.pop_size):\n                self.initialize_population(func) # Restart population to escape local optima\n                stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "objective": -0.35702, "other_inf": null}
{"id": "0fe1c03c-a09d-442e-8b77-ffc04051096e", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "# Description: This algorithm combines particle swarm optimization with a mutation strategy inspired by differential evolution to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and values\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and value\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        gbest_position = population[best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (pbest_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (gbest_position - population[i])\n                \n                # Mutation using DE inspired strategy\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                #Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                  cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n\n                # Update position\n                trial = np.clip(population[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                f = func(trial)\n                self.budget -= 1\n\n                # Update personal best\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        gbest_position = trial.copy()\n                \n                population[i] = trial.copy()\n\n            \n        return self.f_opt, self.x_opt", "objective": -0.5553, "other_inf": null}
{"id": "a27f2c5b-4117-46de-a588-f998fa988d20", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A modified differential evolution algorithm with a shrinking population size and adaptive mutation factor, focusing on intensifying the search around promising regions.", "code": "import numpy as np\n\nclass ShrinkingAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, shrink_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0 and self.pop_size > 3:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Adaptive F\n                F_adaptive = self.F * np.random.uniform(0.5, 1.5)\n                mutant = a + F_adaptive * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Shrink population\n            sorted_indices = np.argsort(fitness)\n            new_pop_size = int(self.pop_size * self.shrink_factor)\n            population = population[sorted_indices[:new_pop_size]]\n            fitness = fitness[sorted_indices[:new_pop_size]]\n            self.pop_size = new_pop_size\n        \n        # Final refinement with remaining budget using the best individual as the mean\n        if self.budget > 0:\n            std = 0.1 * (func.bounds.ub - func.bounds.lb)\n            for _ in range(self.budget):\n              x = np.random.normal(self.x_opt, std, size=self.dim)\n              x = np.clip(x, func.bounds.lb, func.bounds.ub)\n              f = func(x)\n              if f < self.f_opt:\n                  self.f_opt = f\n                  self.x_opt = x\n        \n        return self.f_opt, self.x_opt", "objective": -0.36402, "other_inf": null}
{"id": "9722a46f-e26c-4e39-b63e-405743e78e9c", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that adjusts its step size and covariance matrix based on the success rate of previous search steps.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, damps=1.0, c_cov_rank_one=None, c_cov_mu=None, mu_eff=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        \n        self.mu = self.pop_size // 2\n\n        if mu_eff is None:\n            self.mu_eff = self.mu\n        else:\n            self.mu_eff = mu_eff\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.cs = cs\n        self.damps = damps  #Damping for step-size\n\n        if c_cov_rank_one is None:\n            self.c_cov_rank_one = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        else:\n            self.c_cov_rank_one = c_cov_rank_one\n            \n        if c_cov_mu is None:\n            self.c_cov_mu = min(1 - self.c_cov_rank_one, 2 * (self.mu_eff - 2 + 1 / self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        else:\n            self.c_cov_mu = c_cov_mu\n\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, self.lb, self.ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index].copy()\n\n            # Selection and Recombination\n            indices = np.argsort(fitness)\n            x_sorted = x[indices]\n            z_sorted = z[indices]\n\n            mean_new = np.sum(self.weights.reshape(-1, 1) * x_sorted[:self.mu], axis=0)\n            zmean = np.sum(self.weights.reshape(-1, 1) * z_sorted[:self.mu], axis=0)\n            \n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + (self.cs * (2 - self.cs))**0.5 * zmean\n            norm_ps = np.linalg.norm(self.ps)\n            self.pc = (1 - self.c_cov_rank_one) * self.pc + (self.c_cov_rank_one * (2 - self.c_cov_rank_one))**0.5 * (mean_new - self.mean) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_mu) * self.C + self.c_cov_rank_one * np.outer(self.pc, self.pc) + self.c_cov_mu * np.sum(self.weights.reshape(-1, 1, 1) * np.array([np.outer(zi, zi) for zi in z_sorted[:self.mu]]), axis=0)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (norm_ps / self.chiN - 1))\n\n            # Update mean\n            self.mean = mean_new\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.2504, "other_inf": null}
{"id": "bf5fb50f-46b6-46fb-8178-fbc5049c6514", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) adjusts the search distribution based on successful steps to efficiently explore the search space.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (100 * self.dim**2)))\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.cs = (np.sqrt(self.mu / np.sum(self.weights**2)) / (self.dim + 5)) if (np.sqrt(self.mu / np.sum(self.weights**2)) / (self.dim + 5)) < 1 else 1\n        self.cc = (4 + (self.mu / self.dim)) / (self.dim + 4 + (2 * self.mu / self.dim))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.cmu = min(1 - self.c1, 2 * (self.mu - 2 + (1 / self.mu)) / ((self.dim + 2)**2 + (self.mu / 2)))\n        self.damps = 1 + (2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1)) + self.cs\n\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, self.lb, self.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort population by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Update CMA-ES parameters\n            y = x[:self.mu] - self.mean\n            z = np.linalg.solve(np.linalg.cholesky(self.C), y.T).T / self.sigma #equivalent to np.dot(y, np.linalg.inv(np.linalg.cholesky(self.C)).T) / self.sigma\n            \n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mu) * np.mean(z, axis=0)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu) * (np.linalg.solve(np.linalg.cholesky(self.C), self.pc))\n            \n            delta_sigma = np.linalg.norm(self.ps) / self.chiN\n            self.sigma *= np.exp((self.cs / self.damps) * (delta_sigma - 1))\n            \n            C1update = self.c1 * (np.outer(self.pc, self.pc) + ((1-self.cc) if delta_sigma > (2 + np.sqrt(self.mu))/self.dim else 0) * self.C)\n            Cmuupdate = self.cmu * np.sum(self.weights[:, None, None] * y[:, :, None] * y[:, None, :], axis=0) / (self.sigma**2)\n            self.C = (1 - self.c1 - self.cmu) * self.C + C1update + Cmuupdate\n            \n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            \n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.23068, "other_inf": null}
{"id": "8cdb98e8-b706-4589-9035-e1a68989f2f0", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A modified CMA-ES algorithm with a reduced population size and adaptive step size based on success rate.", "code": "import numpy as np\n\nclass ModifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu_fraction=0.25, cs=0.3, damps=1, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim)) # Reduced population size\n        else:\n            self.pop_size = pop_size\n        self.mu = int(self.pop_size * mu_fraction)\n        self.mu = max(1, self.mu) # Ensure mu is at least 1\n        self.xmean = np.random.uniform(self.lb, self.ub, self.dim)\n        self.sigma = 0.5  # Initial step size\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.cs = cs\n        self.damps = damps\n        self.c_cov = c_cov\n\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate lambda offsprings\n            arz = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            arx = self.xmean + self.sigma * np.dot(arz, np.linalg.cholesky(self.C).T)\n            arx = np.clip(arx, self.lb, self.ub)\n\n            # Evaluate offsprings\n            arfitness = np.zeros(self.pop_size)\n            for k in range(self.pop_size):\n                arfitness[k] = func(arx[k])\n                self.eval_count += 1\n                if arfitness[k] < self.f_opt:\n                    self.f_opt = arfitness[k]\n                    self.x_opt = arx[k].copy()\n                if self.eval_count >= self.budget:\n                    break\n\n            if self.eval_count >= self.budget:\n                break\n\n            # Sort by fitness and compute weighted mean into xmean\n            arindex = np.argsort(arfitness)\n            arx = arx[arindex]\n            arfitness = arfitness[arindex]\n\n            xold = self.xmean.copy()\n            self.xmean = np.mean(arx[:self.mu], axis=0)\n\n            # Cumulation\n            self.ps = (1 - self.cs) * self.ps + (self.cs**0.5) * (self.xmean - xold) / self.sigma\n            self.pc = (1 - self.c_cov) * self.pc + (self.c_cov**0.5) * (self.xmean - xold) / self.sigma\n            \n            # Adapt covariance matrix C\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (np.outer(self.pc, self.pc) + self.c_cov/self.dim * np.eye(self.dim)) # Simplified rank-one update\n\n            # Adapt step size sigma\n            self.sigma *= np.exp((np.linalg.norm(self.ps) / self.chiN - 1) * self.damps)\n        return self.f_opt, self.x_opt", "objective": -0.22217, "other_inf": null}
{"id": "3d771071-360e-4f00-884b-15c9bb36ca8a", "parents": ["ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "A population-based algorithm that uses a combination of global and local search strategies with adaptive parameter control, focusing on intensifying the search around promising solutions and diversifying when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, local_steps=5, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.stagnation_limit = stagnation_limit\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Local search around best solutions\n            for i in range(min(self.pop_size // 2, self.budget)):  # Limit local searches to avoid over-exploitation\n                x_local = population[i].copy()\n                for _ in range(self.local_steps):\n                    direction = np.random.uniform(-0.1, 0.1, size=self.dim)  # Smaller step size\n                    x_new = x_local + direction\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                    f_new = func(x_new)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if f_new < fitness[i]:\n                        fitness[i] = f_new\n                        population[i] = x_new\n                        x_local = x_new\n\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = x_new\n            if self.budget <=0:\n                break\n\n            # Global search (diversity injection)\n            if fitness[0] == self.f_opt:\n              stagnation_counter +=1\n            else:\n              stagnation_counter = 0\n              self.f_opt = fitness[0]\n              self.x_opt = population[0]\n\n            if stagnation_counter > self.stagnation_limit:\n                # Reset the worst individuals to random positions to encourage exploration.\n                num_to_reset = self.pop_size // 2\n                population[-num_to_reset:] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_reset, self.dim))\n                fitness[-num_to_reset:] = [func(x) for x in population[-num_to_reset:]]\n                self.budget -= num_to_reset\n                stagnation_counter = 0 #reset stagnation counter\n                \n                if self.budget <= 0:\n                  break\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "382395a0-0119-487a-bac3-488e92a66ccf", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "ab0edf48-1ea2-44e1-a68e-0c1394a78d88"], "algorithm": "Simulated Annealing with adaptive temperature decay based on acceptance rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=100.0, alpha=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.acceptance_rate = 0.0\n\n    def initialize(self, func):\n        self.x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x)\n        self.x_opt = self.x\n        self.eval_count += 1\n\n    def __call__(self, func):\n        self.initialize(func)\n        accepted_moves = 0\n\n        while self.eval_count < self.budget:\n            # Generate a new candidate solution\n            x_new = self.x + np.random.normal(0, self.temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)  # Ensure bounds are respected\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            # Acceptance criterion\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.x = x_new\n                self.f_opt = f_new\n                accepted_moves +=1\n                if f_new < self.f_opt:\n                    self.x_opt = x_new\n\n            # Adaptive temperature decay\n            if self.eval_count % (self.dim * 10) == 0:\n                self.acceptance_rate = accepted_moves / (self.dim * 10)\n                if self.acceptance_rate > 0.5:\n                    self.alpha = 0.99\n                elif self.acceptance_rate < 0.1:\n                    self.alpha = 0.8\n                else:\n                    self.alpha = 0.95\n\n                self.temp *= self.alpha\n                accepted_moves = 0\n            \n            if self.eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": -0.25235, "other_inf": null}
{"id": "e07af5e0-ff3c-4212-9d5c-6d292739bd4e", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A single-point search algorithm that adapts its step size based on the success rate of finding better solutions, using a combination of Gaussian and Cauchy mutations for exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveStepSizeSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.1, adaptation_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.adaptation_factor = adaptation_factor\n        self.success_count = 0\n        self.iteration = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.budget -= 1\n\n        while self.budget > 0:\n            self.iteration += 1\n            # Mutation (Cauchy for exploration, Gaussian for exploitation)\n            if np.random.rand() < 0.2:  # Probability of Cauchy mutation\n                mut = self.step_size * np.random.standard_cauchy(size=self.dim)\n            else:\n                mut = self.step_size * np.random.randn(self.dim)\n            x_new = x + mut\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_count += 1\n\n            # Step size adaptation\n            if self.iteration % 100 == 0:\n                success_rate = self.success_count / 100\n                if success_rate < self.success_rate_threshold:\n                    self.step_size *= self.adaptation_factor\n                else:\n                    self.step_size /= self.adaptation_factor\n                self.success_count = 0\n        return self.f_opt, self.x_opt", "objective": -0.40924, "other_inf": null}
{"id": "6cb5f703-c3e2-444d-a9e3-7e8139e8f7fa", "parents": ["9b4b68f3-262f-4e28-9ce7-3e480b8de29e", "9b4b68f3-262f-4e28-9ce7-3e480b8de29e"], "algorithm": "Simulated Annealing with adaptive temperature and step size adjustment.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=100.0, alpha=0.99, step_size_init=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.step_size = step_size_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n        self.x_current = None\n        self.f_current = None\n\n    def initialize(self, func):\n        self.x_current = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_current = func(self.x_current)\n        self.eval_count += 1\n        self.x_opt = self.x_current\n        self.f_opt = self.f_current\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.eval_count < self.budget:\n            # Generate a new candidate solution\n            x_new = self.x_current + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)  # Keep within bounds\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - self.f_current\n\n            # Acceptance probability\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.x_current = x_new\n                self.f_current = f_new\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n\n            # Update temperature and step size\n            self.temp *= self.alpha\n            self.step_size *= 0.99  # Reduce step size gradually\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.13718, "other_inf": null}
{"id": "ebca8413-af3f-4850-8de1-78727db69276", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A Gaussian process-based optimization algorithm with Expected Improvement acquisition function and restarts to handle multi-modality.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, xi=0.01, kernel=None):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.xi = xi\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        if kernel is None:\n             self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.eval_count += self.n_initial\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index].copy()\n        self.gpr = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10, alpha=1e-5)\n\n    def expected_improvement(self, x, gpr, y_max, xi=0.01):\n        mu, sigma = gpr.predict(x.reshape(1, -1), return_std=True)\n        sigma = np.maximum(sigma, 1e-9)\n        imp = mu - y_max - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gpr, y_max, lb, ub, xi, n_restarts=25):\n        def min_obj(x):\n            return -self.expected_improvement(x, gpr, y_max, xi=xi)\n\n        best_x = None\n        best_ei = 1e9\n        for _ in range(n_restarts):\n            x0 = np.random.uniform(lb, ub, size=self.dim)\n            res = minimize(min_obj, x0, bounds=[(lb, ub)] * self.dim, method='L-BFGS-B')\n            if res.fun < best_ei:\n                best_ei = res.fun\n                best_x = res.x\n        return best_x\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            self.gpr.fit(self.X, self.y)\n            \n            # Find next point to evaluate using expected improvement\n            x_next = self.propose_location(self.gpr, self.y.max(), self.lb, self.ub, self.xi)\n            \n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.eval_count += 1\n\n            # Append the new data to our existing data\n            self.X = np.vstack((self.X, x_next.reshape(1, -1)))\n            self.y = np.append(self.y, f_next)\n\n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n                \n            if self.eval_count >= self.budget:\n                break\n            \n            # Restart if stagnated\n            if self.eval_count > self.n_initial * 5 and np.std(self.y[-self.n_initial:]) < 1e-6:\n                self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n                self.y = np.array([func(x) for x in self.X])\n                self.eval_count += self.n_initial\n                best_index = np.argmin(self.y)\n                self.f_opt = self.y[best_index]\n                self.x_opt = self.X[best_index].copy()\n                self.gpr = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10, alpha=1e-5)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f79f2c2f-1b0f-46b1-a1a1-59af29172546", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and inertia weight adaptation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        best_index = np.argmin(self.fitness)\n        self.global_best_fitness = self.fitness[best_index]\n        self.global_best_position = self.particles[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Update inertia weight (linearly decrease)\n            inertia = self.inertia - (self.inertia - 0.4) * (self.eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Velocity clamping\n                v_max = 0.1 * (self.ub - self.lb)\n                self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                # Update global best\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.particles[i].copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n        return self.f_opt, self.x_opt", "objective": -0.57619, "other_inf": null}
{"id": "b68f0e57-9c59-4501-a112-95e03ded0d89", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "A single-solution based metaheuristic that iteratively improves the solution by perturbing it with a decaying step size and accepting the new solution if it's better or with a probability based on the Metropolis criterion.", "code": "import numpy as np\n\nclass SimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, temp/self.initial_temp, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f:\n                f = f_new\n                x = x_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                delta = f_new - f\n                if np.random.rand() < np.exp(-delta / temp):\n                    f = f_new\n                    x = x_new\n            temp *= self.cooling_rate\n\n        return self.f_opt, self.x_opt", "objective": -0.12377, "other_inf": null}
{"id": "407f7388-fef8-4169-923e-bbd0d8d9f961", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) iteratively updates a population of solutions by sampling from a multivariate normal distribution, adapting its mean and covariance matrix based on the success of previous samples.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim / 2\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / (dim + np.sqrt(2))\n        self.ccovmu = ccovmu if ccovmu is not None else 2 / (dim + np.sqrt(2))\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mu = self.pop_size // 2\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def update_distribution(self, population, fitness):\n        # Select best individuals\n        idx = np.argsort(fitness)\n        best_idx = idx[:self.mu]\n        best_individuals = population[best_idx]\n\n        # Update mean\n        old_mean = self.mean.copy()\n        self.mean = np.mean(best_individuals, axis=0)\n\n        # Update evolution path\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.linalg.solve(np.linalg.cholesky(self.C), (self.mean - old_mean) / self.sigma)\n\n        # Update covariance matrix\n        self.pc = (1 - self.ccov1) * self.pc + np.sqrt(self.ccov1 * (2 - self.ccov1)) * (self.mean - old_mean) / self.sigma\n\n        delta = best_individuals - old_mean\n        weights = np.array([np.log(self.mu+1) - np.log(i+1) for i in range(self.mu)])\n        weights = weights / np.sum(weights)\n\n        rank_one = np.outer(self.pc, self.pc)\n        rank_mu = np.sum([weights[i] * np.outer(delta[i], delta[i]) / self.sigma**2 for i in range(self.mu)], axis=0)\n\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < (2 + 4 / (self.dim + 1))\n\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccovmu * np.sum(weights)) * self.C + self.ccov1 * rank_one + self.ccovmu * rank_mu\n\n        # Damp step size\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / (self.dim**0.5) - 1))\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            population = self.sample_population()\n            population = np.clip(population, self.lb, self.ub)\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n            \n            if self.eval_count >= self.budget:\n                break\n            \n            self.update_distribution(population, fitness)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "8ca7d7a0-e92c-4648-8719-b7d1c3cbcf30", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c", "13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts, focusing on intensifying search around promising regions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x.copy()\n        \n        temp = self.initial_temp\n\n        while self.eval_count < self.budget:\n            x_new = x + np.random.normal(0, temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new.copy()\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n\n            temp *= self.cooling_rate\n\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "75926b7a-f732-4d79-9ca8-6e7433230b54", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A modified differential evolution algorithm with a linearly decreasing mutation factor and a rank-based selection scheme for improved exploitation.", "code": "import numpy as np\n\nclass RankBasedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        F_initial = 1.0\n        F_final = 0.1\n\n        while self.eval_count < self.budget:\n            # Linearly decreasing mutation factor\n            F = F_initial - (F_initial - F_final) * (self.eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Rank-based selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Rank individuals and sort\n            ranked_indices = np.argsort(self.fitness)\n            self.population = self.population[ranked_indices]\n            self.fitness = self.fitness[ranked_indices]\n\n        return self.f_opt, self.x_opt", "objective": -0.57345, "other_inf": null}
{"id": "68fe744d-b496-4cbc-8b7c-9891eb676e10", "parents": ["13ad7436-596f-4533-a5aa-c8f443d7076c"], "algorithm": "A hybrid algorithm combining Differential Evolution with a local search strategy using Nelder-Mead simplex method applied periodically to the best individuals to refine the solution.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_frequency=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_frequency = local_search_frequency\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def local_search(self, func, x0):\n        bounds = [(self.lb, self.ub)] * self.dim\n        res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.local_search_frequency", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_frequency=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_frequency = local_search_frequency\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n\n    def local_search(self, func, x0):\n        bounds = [(self.lb, self.ub)] * self.dim\n        res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.local_search_frequency})\n        return res.fun, res.x, res.nfev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                indices = [j for j in range(self.pop_size) if j != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Local Search\n            if self.eval_count % self.local_search_frequency == 0:\n                best_index = np.argmin(self.fitness)\n                x0 = self.population[best_index].copy()\n                f_local, x_local, nfev = self.local_search(func, x0)\n                self.eval_count += nfev\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n                    self.fitness[best_index] = f_local\n                    self.population[best_index] = x_local.copy()\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f7d72810-6703-46eb-aabe-87ba13831559", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "# Description: This algorithm uses a self-adaptive differential evolution strategy with a mirrored sampling technique to enhance exploration and exploitation within the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveMirroredDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.F_list = np.ones(pop_size) * F\n        self.CR_list = np.ones(pop_size) * CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Self-adaptive F and CR\n                F = self.F_list[i] + 0.1 * np.random.normal()\n                F = np.clip(F, 0.1, 0.9)\n                CR = self.CR_list[i] + 0.1 * np.random.normal()\n                CR = np.clip(CR, 0.1, 0.9)\n                \n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Mirrored sampling - create a mirrored individual\n                mirrored_mutant = 2 * func.bounds.ub - mutant\n                mirrored_mutant = np.clip(mirrored_mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                mirrored_trial = np.where(cross_points, mirrored_mutant, population[i])\n                \n                # Selection\n                f = func(trial)\n                f_mirrored = func(mirrored_trial)\n                self.budget -= 2 #two evaluations per loop\n                \n                if f < f_mirrored:\n                    if f < fitness[i]:\n                        fitness[i] = f\n                        population[i] = trial\n                        self.F_list[i] = F\n                        self.CR_list[i] = CR\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial\n                else:\n                    if f_mirrored < fitness[i]:\n                        fitness[i] = f_mirrored\n                        population[i] = mirrored_trial\n                        self.F_list[i] = F\n                        self.CR_list[i] = CR\n\n                        if f_mirrored < self.f_opt:\n                            self.f_opt = f_mirrored\n                            self.x_opt = mirrored_trial\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.44611, "other_inf": null}
{"id": "d6f62013-5978-4566-b3db-b0a9d0770802", "parents": ["2f2a1776-aa48-498e-8338-20b09ade7cfa"], "algorithm": "# Description: This algorithm combines Differential Evolution with a self-adaptive mutation strategy and a local search component based on perturbing the best solution found so far.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        F = np.full(self.pop_size, self.F)\n        CR = np.full(self.pop_size, self.CR)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Self-adaptive parameters\n                F_i = F[i] + 0.1 * np.random.normal(0, 1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = CR[i] + 0.1 * np.random.normal(0, 1)\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + F_i * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR_i\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.x_opt + 0.01 * np.random.normal(0, 1, self.dim)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    F[i] = F_i\n                    CR[i] = CR_i\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]    \n        return self.f_opt, self.x_opt", "objective": -0.56686, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "0e37c006-75c2-4819-ab3c-995567bfbf2c", "parents": [], "algorithm": "Adaptive Coordinate Descent with restart and dynamic step size adjustment based on success rate.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        \n        step_size = np.full(self.dim, self.initial_step_size)\n        success_rate = np.zeros(self.dim)\n        eval_count = 1\n        \n        while eval_count < self.budget:\n            for i in range(self.dim):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Perturb positively\n                x_plus = self.x_opt.copy()\n                x_plus[i] = np.clip(x_plus[i] + step_size[i], self.lb, self.ub)\n                f_plus = func(x_plus)\n                eval_count += 1\n\n                # Perturb negatively\n                x_minus = self.x_opt.copy()\n                x_minus[i] = np.clip(x_minus[i] - step_size[i], self.lb, self.ub)\n                f_minus = func(x_minus)\n                eval_count += 1\n                \n                if eval_count >= self.budget:\n                    f_plus = np.inf\n                    f_minus = np.inf\n\n                if f_plus < self.f_opt and f_plus <= f_minus:\n                    self.x_opt = x_plus\n                    self.f_opt = f_plus\n                    success_rate[i] += 1\n                elif f_minus < self.f_opt:\n                    self.x_opt = x_minus\n                    self.f_opt = f_minus\n                    success_rate[i] += 1\n                \n                # Adjust step size adaptively\n                if success_rate[i] > 5:\n                    step_size[i] *= 1.2\n                    success_rate[i] = 0\n                elif success_rate[i] < -5:\n                    step_size[i] *= 0.8\n                    success_rate[i] = 0\n                    \n                step_size[i] = np.clip(step_size[i], 1e-6, self.ub - self.lb)\n                \n            if eval_count < self.budget and np.random.rand() < 0.05: \n                # Restart with a small probability\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.16963, "other_inf": null}
{"id": "6cffcfc9-ce50-4268-b2b7-7290d6fd3589", "parents": [], "algorithm": "A population-based algorithm that combines aspects of differential evolution and particle swarm optimization with a local search component to explore and exploit the search space.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.9, de_f=0.8, pso_w=0.7, pso_c1=1.5, pso_c2=1.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                if np.random.rand() < 0.5:  # Apply DE with 50% probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    \n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else: # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                    self.pso_c2 * r2 * (global_best_position - population[i]))\n                    trial_vector = population[i] + velocities[i]\n                    \n                trial_vector = np.clip(trial_vector, self.lb, self.ub) # Clip to bounds\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (self.ub - self.lb) # 1% of the range\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    trial_vector = trial_vector + step_size * random_direction\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n                    \n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial_vector.copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n        return self.f_opt, self.x_opt", "objective": -0.59691, "other_inf": null}
{"id": "e83c0a95-568e-4688-a865-cbe648ffe41a", "parents": [], "algorithm": "A population-based algorithm that combines global exploration with local exploitation by adaptively adjusting the search range based on the population's performance.", "code": "import numpy as np\n\nclass AdaptiveRangeSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_range=2.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_range = initial_range\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        range_lb = np.maximum(lb, -self.initial_range)\n        range_ub = np.minimum(ub, self.initial_range)\n        \n        population = np.random.uniform(range_lb, range_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Adaptive range adjustment\n            std = np.std(population, axis=0)\n            adaptive_range = np.mean(std)\n\n            # Generate new solutions around the best solution\n            new_solutions = np.random.normal(loc=self.x_opt, scale=adaptive_range, size=(self.pop_size, self.dim))\n            new_solutions = np.clip(new_solutions, lb, ub)\n\n            new_fitness = np.array([func(x) for x in new_solutions])\n            evals += self.pop_size\n\n            # Update population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_solutions[i]\n                    fitness[i] = new_fitness[i]\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "objective": -0.60811, "other_inf": null}
{"id": "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "parents": [], "algorithm": "Adaptive Differential Evolution with a restart mechanism based on stagnation detection and dynamic parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = budget // 10  # Adjust as needed\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Stagnation Check and Restart\n            if abs(self.f_opt - self.best_fitness_history[-1]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size # update the evaluation count.\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n\n            # Adaptive Parameter Control (Example: Adjust F based on success)\n            if len(self.best_fitness_history) > 1 and self.f_opt < self.best_fitness_history[-1]:\n                self.F = np.clip(self.F * 1.1, 0.1, 0.9) # increase F by 10%\n            else:\n                self.F = np.clip(self.F * 0.9, 0.1, 0.9) # decrease F by 10%\n\n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "objective": -0.59703, "other_inf": null}
{"id": "eb748e33-c34d-4408-a190-c129cb232b0d", "parents": [], "algorithm": "This algorithm combines a global random search with a local search that iteratively refines promising solutions by exploring the neighborhood using Gaussian mutations and a dynamic step size adaptation.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial random search to find a good starting point\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n        \n        step_size = self.initial_step_size\n\n        # Adaptive local search\n        while evals < self.budget:\n            \n            x_new = self.x_opt + np.random.normal(0, step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            evals += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                step_size *= 1.1  # Increase step size if improvement\n            else:\n                step_size *= 0.9  # Decrease step size if no improvement\n                \n            step_size = np.clip(step_size, 1e-6, 1.0) # Prevent step_size from being to large or small\n            \n            if evals + 100 < self.budget:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                evals += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt", "objective": -0.30735, "other_inf": null}
{"id": "ab009f0c-a762-46a9-a502-17539cdcc71e", "parents": [], "algorithm": "Adaptive Differential Evolution with Archive and Random Restart: This algorithm combines differential evolution with an archive to maintain diversity and random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Crossover rate\n        self.CR = 0.7 # Mutation factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        rand_archive_idx = np.random.randint(len(self.archive))\n                        x_r1 = self.archive[rand_archive_idx]\n                    else:\n                        idx_1, idx_2, idx_3 = np.random.choice(candidates, 3, replace=False)\n                        x_r1 = self.population[idx_1]\n                        \n                else:\n                    idx_1, idx_2, idx_3 = np.random.choice(candidates, 3, replace=False)\n                    x_r1 = self.population[idx_1]\n                \n                idx_2, idx_3 = np.random.choice(candidates, 2, replace=False)\n                x_r2 = self.population[idx_2]\n                x_r3 = self.population[idx_3]\n                \n                v = self.population[i] + self.F * (x_r2 - x_r3)\n                \n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < fitness[i]:\n                    fitness[i] = f_u\n                    self.population[i] = u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0) #remove oldest\n                        \n            # Random Restart\n            if np.random.rand() < 0.01:  # 1% chance of restart\n                idx_to_replace = np.random.randint(self.pop_size)\n                self.population[idx_to_replace] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                fitness[idx_to_replace] = func(self.population[idx_to_replace])\n                self.budget -= 1\n                if fitness[idx_to_replace] < self.f_opt:\n                        self.f_opt = fitness[idx_to_replace]\n                        self.x_opt = self.population[idx_to_replace]\n\n        return self.f_opt, self.x_opt", "objective": -0.46381, "other_inf": null}
{"id": "f1f6bd27-f543-487f-89ca-fd472fdeeac5", "parents": [], "algorithm": "This algorithm employs a combination of a Sobol sequence-based initialization for good coverage of the search space, followed by a Nelder-Mead simplex-like search that adapts the simplex based on function evaluations to refine the search.", "code": "import numpy as np\nfrom scipy.stats import qmc\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Sobol sequence for initialization\n        sampler = qmc.Sobol(d=self.dim, scramble=False)\n        sample = sampler.random(n=min(self.dim + 1, self.budget))\n        points = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * sample\n        \n        # Evaluate initial points\n        evaluations = 0\n        fitness = []\n        for x in points:\n            f = func(x)\n            fitness.append(f)\n            evaluations += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        simplex = points.copy()\n        fitness = np.array(fitness)\n\n        while evaluations < self.budget:\n            # Order the vertices\n            idx = np.argsort(fitness)\n            simplex = simplex[idx]\n            fitness = fitness[idx]\n            \n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            xr = centroid + 1.0 * (centroid - simplex[-1])\n            xr = np.clip(xr, func.bounds.lb, func.bounds.ub)\n            fr = func(xr)\n            evaluations += 1\n            if fr < self.f_opt:\n                self.f_opt = fr\n                self.x_opt = xr\n            \n            if fitness[0] <= fr < fitness[-2]:\n                simplex[-1] = xr\n                fitness[-1] = fr\n            else:\n                if fr < fitness[0]:\n                    # Expansion\n                    xe = centroid + 2.0 * (xr - centroid)\n                    xe = np.clip(xe, func.bounds.lb, func.bounds.ub)\n                    fe = func(xe)\n                    evaluations += 1\n                    if fe < self.f_opt:\n                        self.f_opt = fe\n                        self.x_opt = xe\n\n                    if fe < fr:\n                        simplex[-1] = xe\n                        fitness[-1] = fe\n                    else:\n                        simplex[-1] = xr\n                        fitness[-1] = fr\n                else:\n                    # Contraction\n                    xc = centroid + 0.5 * (simplex[-1] - centroid)\n                    xc = np.clip(xc, func.bounds.lb, func.bounds.ub)\n                    fc = func(xc)\n                    evaluations += 1\n                    if fc < self.f_opt:\n                        self.f_opt = fc\n                        self.x_opt = xc\n\n                    if fc < fitness[-1]:\n                        simplex[-1] = xc\n                        fitness[-1] = fc\n                    else:\n                        # Shrink\n                        for i in range(1, len(simplex)):\n                            simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            fitness[i] = func(simplex[i])\n                            evaluations += 1\n                            if fitness[i] < self.f_opt:\n                                self.f_opt = fitness[i]\n                                self.x_opt = simplex[i]\n                            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b9134571-d4ee-40d6-ab3b-510a9381e49f", "parents": [], "algorithm": "A population-based algorithm that combines exploration through random sampling with exploitation through local search around promising solutions, adaptively adjusting the search range based on the performance of individuals.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.f_opt:\n            self.f_opt = fitness[best_idx]\n            self.x_opt = population[best_idx]\n\n        # Main loop\n        while self.budget > 0:\n            # Selection: Select best individuals for local search\n            sorted_idx = np.argsort(fitness)\n            selected_idx = sorted_idx[:self.pop_size // 2]  # Select top half\n            \n            # Local search around selected individuals\n            for idx in selected_idx:\n                x_current = population[idx].copy()\n                f_current = fitness[idx]\n                \n                # Adaptive step size\n                step_size = (self.ub - self.lb) / 10.0\n                \n                for _ in range(self.local_steps):\n                    if self.budget <= 0:\n                        break\n                    \n                    # Generate a random move\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    x_new = x_current + step_size * direction\n                    \n                    # Clip to bounds\n                    x_new = np.clip(x_new, self.lb, self.ub)\n                    \n                    f_new = func(x_new)\n                    self.budget -= 1\n                    \n                    if f_new < f_current:\n                        x_current = x_new\n                        f_current = f_new\n                    \n                    if f_current < self.f_opt:\n                        self.f_opt = f_current\n                        self.x_opt = x_current.copy()\n\n                # Update population with local search result\n                population[idx] = x_current\n                fitness[idx] = f_current\n\n            # Exploration: Replace worst individuals with random samples\n            worst_idx = sorted_idx[self.pop_size // 2:] # Select worst half\n            new_samples = np.random.uniform(self.lb, self.ub, size=(len(worst_idx), self.dim))\n            new_fitness = np.array([func(x) for x in new_samples])\n            self.budget -= len(worst_idx)\n                \n            population[worst_idx] = new_samples\n            fitness[worst_idx] = new_fitness\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "17f2d40f-82d3-4c36-8b1c-aabae9c1fb91", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation using the Upper Confidence Bound (UCB) acquisition function.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogate:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Upper Confidence Bound\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.eval_count += self.n_initial_samples\n\n        self.X = X_init\n        self.y = y_init\n        \n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        while self.eval_count < self.budget:\n            # Fit GP model\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            x_next = self.find_next_point()\n\n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.eval_count += 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self):\n        # Simple random search for the next point (can be replaced with a more sophisticated optimization)\n        best_x = None\n        best_acq = np.inf\n        for _ in range(100):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition_function(x, self.gp)\n            if acq < best_acq:\n                best_acq = acq\n                best_x = x\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "47cfe37b-1f20-4df5-a78c-eced7cb5e14d", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "ab009f0c-a762-46a9-a502-17539cdcc71e"], "algorithm": "A gradient-free optimization algorithm that iteratively samples points, estimates a local quadratic model using a small number of points, and moves to the minimum of the model.", "code": "import numpy as np\n\nclass QuadraticModelSearch:\n    def __init__(self, budget=10000, dim=10, num_points=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_points = num_points\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random solution\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample points around the current best\n            points = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.num_points, self.dim))\n            points = np.clip(points, lb, ub)\n            fitness = np.array([func(p) for p in points])\n            evals += self.num_points\n\n            # Fit a quadratic model\n            try:\n                H = np.zeros((self.dim, self.dim))\n                g = np.zeros(self.dim)\n\n                for i in range(self.num_points):\n                    diff = points[i] - self.x_opt\n                    H += np.outer(diff, diff) * (fitness[i] - f)\n                    g += diff * (fitness[i] - f)\n\n                H = H / self.num_points\n                g = g / self.num_points\n\n                # Move to the minimum of the model\n                if np.linalg.det(H) != 0:\n                    x_new = self.x_opt - np.linalg.solve(H, g) / 2\n                    x_new = np.clip(x_new, lb, ub)\n\n                    f_new = func(x_new)\n                    evals += 1\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                        f = f_new\n                        x = x_new\n                else:\n                    x = np.random.uniform(lb, ub, size=self.dim)\n                    f = func(x)\n                    if f < self.f_opt:\n                      self.f_opt = f\n                      self.x_opt = x\n                    evals += 1\n\n            except np.linalg.LinAlgError:\n                # If the quadratic model is ill-conditioned, sample a new point randomly\n                x = np.random.uniform(lb, ub, size=self.dim)\n                f = func(x)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                evals += 1\n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "5f925406-0b33-4a10-b036-3f212dedb164", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A multi-start local search algorithm with adaptive step size and diversification based on fitness landscape exploration.", "code": "import numpy as np\n\nclass AdaptiveMultiStartLS:\n    def __init__(self, budget=10000, dim=10, num_starts=10, initial_step_size=1.0, step_size_reduction_factor=0.5, diversification_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_starts = num_starts\n        self.initial_step_size = initial_step_size\n        self.step_size_reduction_factor = step_size_reduction_factor\n        self.diversification_threshold = diversification_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for _ in range(self.num_starts):\n            if eval_count >= self.budget:\n                break\n\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            f = func(x)\n            eval_count += 1\n\n            step_size = self.initial_step_size\n\n            while step_size > 1e-6 and eval_count < self.budget:\n                # Generate a random direction\n                direction = np.random.randn(self.dim)\n                direction /= np.linalg.norm(direction)\n\n                # Take a step in that direction\n                x_new = x + step_size * direction\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                eval_count += 1\n                \n                if f_new < f:\n                    x = x_new\n                    f = f_new\n                else:\n                    step_size *= self.step_size_reduction_factor  # Reduce step size if no improvement\n\n            # Diversification: Check if the current solution is too similar to the best solution found so far.\n            if self.x_opt is not None and np.linalg.norm(x - self.x_opt) < self.diversification_threshold:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                eval_count += 1\n                \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        return self.f_opt, self.x_opt", "objective": -0.14995, "other_inf": null}
{"id": "43ff057f-43bd-45c0-804a-e2f165dcce09", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "# Description: This algorithm iteratively refines a single solution by perturbing it with decreasing step sizes, and it incorporates momentum to accelerate convergence and escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass MomentumDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        self.f_opt = f\n        self.x_opt = x\n        \n        velocity = np.zeros(self.dim)\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Calculate gradient approximation (central difference)\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = step_size\n                x_plus[i] = min(ub[i], x[i] + delta)\n                x_minus[i] = max(lb[i], x[i] - delta)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                evals += 2\n                \n                gradient[i] = (f_plus - f_minus) / (x_plus[i] - x_minus[i])\n\n            # Update velocity and position with momentum\n            velocity = self.momentum_factor * velocity - step_size * gradient\n            x = x + velocity\n            x = np.clip(x, lb, ub)\n\n            f = func(x)\n            evals += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                \n            # Reduce step size\n            step_size *= 0.99\n            \n            if evals >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "objective": -0.40025, "other_inf": null}
{"id": "31e4b840-f87a-41a3-8d17-6abc94e77628", "parents": ["ab009f0c-a762-46a9-a502-17539cdcc71e", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "# Description: An evolutionary strategy with covariance matrix adaptation and a decaying step size, combined with a local search operator to refine promising solutions.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAESLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, decay_rate=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.decay_rate = decay_rate\n        self.mean = None\n        self.C = None\n        self.step_size = None\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.bounds_lb, self.bounds_ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.step_size = self.initial_step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate samples\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            samples = self.mean + self.step_size * z\n            samples = np.clip(samples, self.bounds_lb, self.bounds_ub)\n\n            # Evaluate samples\n            fitness = np.array([func(x) for x in samples])\n            eval_count += self.pop_size\n            if eval_count > self.budget:\n                 fitness = fitness[:self.pop_size - (eval_count - self.budget)]\n                 samples = samples[:self.pop_size - (eval_count - self.budget)]\n                 eval_count = self.budget\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = samples[best_idx]\n\n            # Sort samples and fitness\n            sorted_idx = np.argsort(fitness)\n            samples = samples[sorted_idx]\n            fitness = fitness[sorted_idx]\n\n            # Update mean\n            self.mean = np.mean(samples[:self.pop_size // 2], axis=0)\n\n            # Update covariance matrix (simplified)\n            d = samples[:self.pop_size // 2] - self.mean\n            self.C = np.cov(d.T)\n            if np.linalg.det(self.C) <= 0:\n                self.C = np.eye(self.dim)\n\n            # Decay step size\n            self.step_size *= self.decay_rate\n\n            # Local Search (on best solution)\n            if np.random.rand() < 0.1:\n                x_ls = self.local_search(func, samples[0], eval_count, self.budget)\n                f_ls = func(x_ls)\n                eval_count += 1\n\n                if f_ls < self.f_opt:\n                    self.f_opt = f_ls\n                    self.x_opt = x_ls\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x_start, eval_count, budget, radius=0.1, iterations=5):\n        x_best = x_start.copy()\n        f_best = func(x_start)\n        eval_count +=1\n\n        for _ in range(iterations):\n             if eval_count >= budget:\n                 break\n             x_neighbor = x_best + np.random.uniform(-radius, radius, size=self.dim)\n             x_neighbor = np.clip(x_neighbor, self.bounds_lb, self.bounds_ub)\n             f_neighbor = func(x_neighbor)\n             eval_count+=1\n\n             if f_neighbor < f_best:\n                 f_best = f_neighbor\n                 x_best = x_neighbor\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "952e001c-3ece-4b22-b11c-398f09330bbd", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A multi-start approach with a combination of shrinking search space and gradient estimation to intensify search around promising regions.", "code": "import numpy as np\n\nclass GradientShrinkSearch:\n    def __init__(self, budget=10000, dim=10, num_starts=5, shrink_factor=0.9, gradient_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_starts = num_starts\n        self.shrink_factor = shrink_factor\n        self.gradient_samples = gradient_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for _ in range(self.num_starts):\n            lb = np.full(self.dim, self.lb)\n            ub = np.full(self.dim, self.ub)\n            center = np.random.uniform(lb, ub)\n\n            while eval_count < self.budget:\n                # Estimate Gradient\n                gradient = np.zeros(self.dim)\n                for i in range(self.dim):\n                    perturbations = np.random.normal(0, 0.01, size=self.gradient_samples)\n                    fitness_deltas = []\n                    for p in perturbations:\n                        x_perturbed = center.copy()\n                        x_perturbed[i] += p\n                        x_perturbed = np.clip(x_perturbed, lb[i], ub[i])\n                        f_perturbed = func(x_perturbed)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n                        fitness_deltas.append(f_perturbed)\n                    if eval_count >= self.budget:\n                        break\n                    gradient[i] = np.mean(fitness_deltas)\n\n                if eval_count >= self.budget:\n                    break\n                # Move towards the negative gradient direction\n                step = -0.01 * gradient\n                new_center = center + step\n                new_center = np.clip(new_center, lb, ub)\n\n                f = func(new_center)\n                eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_center.copy()\n\n                center = new_center\n\n                # Shrink search space\n                range_width = (ub - lb) * self.shrink_factor\n                lb = np.maximum(self.lb, center - range_width / 2)\n                ub = np.minimum(self.ub, center + range_width / 2)\n\n        return self.f_opt, self.x_opt", "objective": -0.14853, "other_inf": null}
{"id": "bafb6850-ff00-485d-bfe4-993f5d8c815a", "parents": ["ab009f0c-a762-46a9-a502-17539cdcc71e", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "Explore the search space by iteratively refining promising regions using a Gaussian process surrogate model to guide sampling.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, exploration_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.exploration_weight = exploration_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial samples\n        X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        y = np.array([func(x) for x in X])\n        self.budget -= self.n_initial_samples\n\n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n        \n        # Gaussian process model\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while self.budget > 0:\n            # Fit the GP model\n            gp.fit(X, y)\n\n            # Acquisition function (Upper Confidence Bound)\n            def acquisition(x):\n                x = x.reshape(1, -1)\n                mu, sigma = gp.predict(x, return_std=True)\n                return mu - self.exploration_weight * sigma\n\n            # Optimize acquisition function (simple random search within bounds)\n            x_new = None\n            best_acq = np.inf\n            for _ in range(100):\n                x_candidate = np.random.uniform(lb, ub, size=self.dim)\n                acq_value = acquisition(x_candidate)\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    x_new = x_candidate\n            \n            # Evaluate the new point\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            # Update data\n            X = np.vstack((X, x_new))\n            y = np.append(y, f_new)\n\n            # Update best solution\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "507b3613-f0a9-4f13-acbc-a32026937d41", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "An algorithm that uses a population of solutions, evolving them through a combination of global exploration and local refinement phases, adaptively switching between these phases based on performance feedback to efficiently navigate the search space.", "code": "import numpy as np\n\nclass AdaptiveExplorationRefinement:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_prob=0.5, refinement_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_prob = exploration_prob\n        self.refinement_step_size = refinement_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        exploration_success = 0\n        refinement_success = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration phase: Randomly perturb solution\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    new_solution = population[i] + np.random.rand() * (self.ub - self.lb) * random_direction\n                    new_solution = np.clip(new_solution, self.lb, self.ub)\n                else:\n                    # Refinement phase: Local search around the solution\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    new_solution = population[i] + self.refinement_step_size * random_direction\n                    new_solution = np.clip(new_solution, self.lb, self.ub)\n\n                f = func(new_solution)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_solution.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_solution.copy()\n                        if np.random.rand() < 0.5:\n                            exploration_success += 1\n                        else:\n                            refinement_success += 1\n\n\n            # Adjust exploration probability based on success rates\n            total_success = exploration_success + refinement_success\n            if total_success > 0:\n                exploration_rate = exploration_success / total_success\n                self.exploration_prob = 0.5 + 0.3 * (exploration_rate - 0.5)\n            exploration_success = 0\n            refinement_success = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.36603, "other_inf": null}
{"id": "aab9b0a0-6fd9-4b5e-a443-7b5bde12ca6b", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A modified DE algorithm that uses a dynamically adjusted mutation factor based on the success rate of previous mutations and incorporates a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f_initial=0.5, f_adapt_rate=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f_initial\n        self.f_adapt_rate = f_adapt_rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                trial_vector = population[i] + self.f * (x2 - x3)\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    successful_mutations += 1\n                    population[i] = trial_vector\n                    fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n\n            # Adjust mutation factor\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.f *= (1 - self.f_adapt_rate)\n            else:\n                self.f /= (1 - self.f_adapt_rate)\n            self.f = np.clip(self.f, 0.1, 1.0)\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.31891, "other_inf": null}
{"id": "cf858a52-495a-44c4-833f-bc2168cfa6c8", "parents": ["ab009f0c-a762-46a9-a502-17539cdcc71e"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget-aware adaptation of parameters to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.restart_trigger = restart_trigger\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.ccov = (1 / (self.mueff * min(self.dim, self.mueff**2))) * (1 + (2 / 3))\n        self.ccovmu = (2 / ((self.mueff + (self.dim + 1)**2))) * (1 + (2 / 3) * (self.mueff / (self.mueff + self.dim + 5)))\n        self.ccovsep = min(1, self.ccov * (self.dim / np.sqrt(self.mueff)))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            y = (self.mean - mean_old) / self.sigma\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * y\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget / self.pop_size))) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.ccov) * self.pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (z[idx[0:self.mu]] @ self.weights)\n\n            # Update covariance matrix\n            artmp = (1 / self.sigma) * (x[:self.mu] - mean_old)\n            self.C = (1 - self.ccov - self.ccovmu + self.ccov * (1 - hsig) * self.ccovsep) * self.C + self.ccovmu * artmp.T @ np.diag(self.weights) @ artmp + self.ccov * self.pc[:, None] @ self.pc[None, :]\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T  # enforce symmetry\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_trigger:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = self.initial_sigma\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "06a8613d-d6b2-4447-80e1-9733cdf61117", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "This algorithm combines particle swarm optimization with differential evolution strategies for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Differential Evolution Rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        self.f_opt = fitness[best_idx]\n        self.x_opt = global_best_position.copy()\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Differential Evolution\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    F = np.random.uniform(0, 1)\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < F or j == j_rand:\n                            population[i][j] = x_r1[j] + F * (x_r2[j] - x_r3[j])\n                            population[i][j] = np.clip(population[i][j], lb, ub)\n\n                # Evaluate fitness\n                fitness_i = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if fitness_i < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_i\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if fitness_i < self.f_opt:\n                    self.f_opt = fitness_i\n                    self.x_opt = population[i].copy()\n                    global_best_position = population[i].copy()\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a2fb82fc-f29b-4950-be62-0473ecff94e7", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A self-adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success rate of mutation strategies and uses a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.7, lr_cr=0.1, lr_f=0.1, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lr_cr = lr_cr\n        self.lr_f = lr_f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_threshold = restart_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize DE parameters\n        cr = np.full(self.pop_size, self.cr_init)\n        f = np.full(self.pop_size, self.f_init)\n        \n        success_cr = np.zeros(self.pop_size)\n        success_f = np.zeros(self.pop_size)\n        success_count = np.zeros(self.pop_size)\n        \n        no_improvement_count = 0\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                \n                mutated_vector = population[i] + f[i] * (x2 - x3)\n                mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        trial_vector[j] = mutated_vector[j]\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < fitness[i]:\n                    success_cr[i] = cr[i]\n                    success_f[i] = f[i]\n                    success_count[i] += 1\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                \n                # Parameter adaptation\n                if success_count[i] > 0:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.mean(success_cr[success_cr > 0]) if np.any(success_cr > 0) else self.cr_init\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.mean(success_f[success_f > 0]) if np.any(success_f > 0) else self.f_init\n                else:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.random.rand()\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.random.rand()\n                    \n                cr[i] = np.clip(cr[i], 0.1, 0.9)\n                f[i] = np.clip(f[i], 0.1, 0.9)\n            \n            if self.f_opt >= old_f_opt:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n                \n            if no_improvement_count > self.restart_threshold:\n                # Restart mechanism\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                cr = np.full(self.pop_size, self.cr_init)\n                f = np.full(self.pop_size, self.f_init)\n                \n                success_cr = np.zeros(self.pop_size)\n                success_f = np.zeros(self.pop_size)\n                success_count = np.zeros(self.pop_size)\n                \n                no_improvement_count = 0\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.52242, "other_inf": null}
{"id": "c902793d-7480-49be-a94e-10dfb4dad20e", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "e", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else self.cs**2 * (self.mu / (self.dim + np.sqrt(self.mu/2)))\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu)\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.restart_threshold = self.budget // 10\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                D = np.diag(np.sqrt(np.diag(self.C)))\n                x = self.mean + self.sigma * z @ D\n            except Exception as e:\n                print(f\"Error during population generation: {e}\")\n                break\n\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n            self.best_fitness_history.append(self.f_opt)\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            zmean = np.mean(z[:self.mu], axis=0)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (np.linalg.inv(np.diag(np.sqrt(np.diag(self.C)))) @ (self.mean - mean_old)) / self.sigma\n            \n            c_hat = self.c_cov_rank_one #self.c_cov_rank_one*self.budget/self.eval_count\n\n            self.pc = (1 - self.c_cov_mean) * self.pc + np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean)) * (self.mean - mean_old) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - c_hat - self.c_cov_rank_mu) * self.C + c_hat * np.outer(self.pc, self.pc) + self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = self.C / np.linalg.norm(self.C)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = max(self.sigma, 1e-10)\n\n            #Stagnation and Restart\n            if len(self.best_fitness_history) > 1 and abs(self.best_fitness_history[-1] - self.best_fitness_history[-2]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = 0.5\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.stagnation_counter = 0\n        return self.f_opt, self.x_opt", "objective": -0.44847, "other_inf": null}
{"id": "7d89553e-5dfa-4d9c-84c8-0be18e841d65", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A self-adaptive differential evolution algorithm with a mutation strategy that adjusts based on the success rate of previous mutations, combined with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f=0.5, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_success_rate = 0.5\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        success_history = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation strategy adaptation based on success rate\n                if np.random.rand() < self.mutation_success_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    trial_vector = population[i] + self.f * (x2 - x3)\n\n                else:\n                    # Explore more if mutation rate is low\n                    trial_vector = population[i] + self.mutation_scale * np.random.normal(0, 1, self.dim)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    success_history.append(1)\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                else:\n                    success_history.append(0)\n\n                # Update mutation success rate\n                if len(success_history) > 50:\n                    success_rate = np.mean(success_history[-50:])\n                    self.mutation_success_rate = 0.8 * self.mutation_success_rate + 0.2 * success_rate\n                    self.mutation_scale = 0.1 * np.exp(-5 * (1 - self.mutation_success_rate))\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                global_best_index = np.argmin(fitness)\n                if fitness[global_best_index] < self.f_opt:\n                    self.f_opt = fitness[global_best_index]\n                    self.x_opt = population[global_best_index].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.18387, "other_inf": null}
{"id": "d21722cc-1da6-4e82-9e83-45e736179d6c", "parents": ["a2fb82fc-f29b-4950-be62-0473ecff94e7"], "algorithm": "# Description: An improved self-adaptive differential evolution algorithm that uses a larger population size, an archive to store promising solutions, and a more aggressive parameter adaptation scheme with periodic restarts to maintain diversity.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr_init=0.7, f_init=0.5, lr_cr=0.2, lr_f=0.2, archive_size=20, restart_threshold=500, aggressive_f_update=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lr_cr = lr_cr\n        self.lr_f = lr_f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.restart_threshold = restart_threshold\n        self.aggressive_f_update = aggressive_f_update\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize Archive\n        archive = []\n        archive_fitness = []\n\n        # Initialize DE parameters\n        cr = np.full(self.pop_size, self.cr_init)\n        f = np.full(self.pop_size, self.f_init)\n\n        success_cr = np.zeros(self.pop_size)\n        success_f = np.zeros(self.pop_size)\n        success_count = np.zeros(self.pop_size)\n\n        no_improvement_count = 0\n\n        while self.budget > 0:\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = population[idxs]\n\n                if len(archive) > 0 and np.random.rand() < 0.1:\n                    idx_archive = np.random.randint(len(archive))\n                    x3 = archive[idx_archive]\n                else:\n                    idx = np.random.choice(self.pop_size, 1, replace=False)[0]\n                    x3 = population[idx]\n\n                mutated_vector = population[i] + f[i] * (x1 - x2)\n                mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        trial_vector[j] = mutated_vector[j]\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    success_cr[i] = cr[i]\n                    success_f[i] = f[i]\n                    success_count[i] += 1\n\n                    # Update archive\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                        archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(archive_fitness)\n                        if fitness[i] < archive_fitness[worst_archive_idx]:\n                            archive[worst_archive_idx] = population[i].copy()\n                            archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                # Parameter adaptation\n                if success_count[i] > 0:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.mean(success_cr[success_cr > 0]) if np.any(success_cr > 0) else self.cr_init\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.mean(success_f[success_f > 0]) if np.any(success_f > 0) else self.f_init\n                else:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.random.rand()\n                    f[i] = f[i] * self.aggressive_f_update if np.random.rand() < 0.1 else (1 - self.lr_f) * f[i] + self.lr_f * np.random.rand()\n\n                cr[i] = np.clip(cr[i], 0.1, 0.9)\n                f[i] = np.clip(f[i], 0.1, 2.0)\n\n            if self.f_opt >= old_f_opt:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n\n            if no_improvement_count > self.restart_threshold:\n                # Restart mechanism\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                archive = []\n                archive_fitness = []\n\n                cr = np.full(self.pop_size, self.cr_init)\n                f = np.full(self.pop_size, self.f_init)\n\n                success_cr = np.zeros(self.pop_size)\n                success_f = np.zeros(self.pop_size)\n                success_count = np.zeros(self.pop_size)\n\n                no_improvement_count = 0\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.39573, "other_inf": null}
{"id": "99cce847-cc1b-4113-a9d9-4e3c1bc32acd", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A population-based algorithm that uses a combination of differential evolution for exploration and Nelder-Mead simplex for local exploitation, adaptively switching between them based on the population diversity.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.5, de_crossover_rate=0.7, nm_max_iter=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_max_iter = nm_max_iter\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Calculate population diversity\n            diversity = np.std(fitness)\n            \n            # Adaptive switch between DE and NM\n            if diversity > 1e-3:  # High diversity: Exploration using DE\n                for i in range(self.pop_size):\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    \n                    # Mutation\n                    v = population[i] + self.de_mutation_factor * (x_r2 - x_r3)\n                    v = np.clip(v, lb, ub)\n                    \n                    # Crossover\n                    u = np.random.rand(self.dim)\n                    trial_vector = np.where(u <= self.de_crossover_rate, v, population[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    f_trial = func(trial_vector)\n                    evals += 1\n                    \n                    if f_trial < fitness[i]:\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                            \n                    if evals >= self.budget:\n                        break\n\n            else:  # Low diversity: Exploitation using Nelder-Mead\n                for i in range(self.pop_size):\n                    # Nelder-Mead Simplex\n                    res = minimize(func, population[i], method='Nelder-Mead', options={'maxiter': self.nm_max_iter, 'disp': False", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.5, de_crossover_rate=0.7, nm_max_iter=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_max_iter = nm_max_iter\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Calculate population diversity\n            diversity = np.std(fitness)\n            \n            # Adaptive switch between DE and NM\n            if diversity > 1e-3:  # High diversity: Exploration using DE\n                for i in range(self.pop_size):\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    \n                    # Mutation\n                    v = population[i] + self.de_mutation_factor * (x_r2 - x_r3)\n                    v = np.clip(v, lb, ub)\n                    \n                    # Crossover\n                    u = np.random.rand(self.dim)\n                    trial_vector = np.where(u <= self.de_crossover_rate, v, population[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    f_trial = func(trial_vector)\n                    evals += 1\n                    \n                    if f_trial < fitness[i]:\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                            \n                    if evals >= self.budget:\n                        break\n\n            else:  # Low diversity: Exploitation using Nelder-Mead\n                for i in range(self.pop_size):\n                    # Nelder-Mead Simplex\n                    res = minimize(func, population[i], method='Nelder-Mead', options={'maxiter': self.nm_max_iter, 'disp': False})\n                    \n                    if res.success:\n                        x_nm = res.x\n                        f_nm = res.fun\n                        num_func_calls = res.nfev\n                        \n                        evals += num_func_calls\n                        \n                        if f_nm < fitness[i]:\n                            population[i] = x_nm\n                            fitness[i] = f_nm\n                            \n                            if f_nm < self.f_opt:\n                                self.f_opt = f_nm\n                                self.x_opt = x_nm\n                        \n                        if evals >= self.budget:\n                            break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "48b781d3-ef1d-4846-8cb5-54876a0f2fd4", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "A gradient-free optimization algorithm that estimates the gradient using a small set of points and iteratively moves towards the direction of improvement, adaptively adjusting the step size and sampling radius.", "code": "import numpy as np\n\nclass GradientDescentOpt:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, sampling_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.sampling_radius = sampling_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Estimate gradient using finite differences\n            grad = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                x_plus[i] += self.sampling_radius\n                x_minus[i] -= self.sampling_radius\n                x_plus[i] = np.clip(x_plus[i], lb, ub)\n                x_minus[i] = np.clip(x_minus[i], lb, ub)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                evals += 2\n                grad[i] = (f_plus - f_minus) / (2 * self.sampling_radius)\n                if evals >= self.budget:\n                  break\n            if evals >= self.budget:\n                  break\n            # Update solution\n            x_new = x - self.step_size * grad\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Accept new solution if it's better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.step_size *= 1.1  # Increase step size if successful\n            else:\n                self.step_size *= 0.5  # Decrease step size if unsuccessful\n\n            if self.step_size < 1e-6:\n                x = np.random.uniform(lb, ub, size=self.dim)  # Restart if step size too small\n                self.step_size = 0.1\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a7e66a98-1758-494a-b08a-54b1828f2c91", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "Implements a covariance matrix adaptation evolution strategy (CMA-ES) inspired algorithm with simplified updates and a focus on exploration, using a single population member and adapting the step size based on success.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = initial_step_size\n        self.success_prob = 0.5 # Start with 50% chance of a successful step\n\n    def __call__(self, func):\n        self.x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x)\n        self.x_opt = self.x.copy()\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a new solution by sampling from a normal distribution\n            z = np.random.normal(0, 1, size=self.dim)\n            x_new = self.x + self.step_size * z\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < self.f_opt:\n                # Successful step: Update the solution and adapt the step size\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                self.x = x_new.copy()\n                self.step_size *= np.exp(0.2 * (1 - 1/self.success_prob)) # increase step size\n                self.success_prob = 0.9\n\n            else:\n                # Unsuccessful step: Decrease the step size\n                self.step_size *= np.exp(-0.25 * (1/self.success_prob - 1))  # decrease step size\n                self.success_prob = 0.1\n            \n            self.step_size = np.clip(self.step_size, 1e-6, (self.ub - self.lb)/2)\n\n        return self.f_opt, self.x_opt", "objective": -0.08881, "other_inf": null}
{"id": "f780c8d1-1e28-47ba-9767-5ab3d51a1336", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A gradient-free optimization method that utilizes Nelder-Mead simplex method with adaptive simplex size and centroid-based shrinking for global exploration and local exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimplex:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=1.0, reflection_coefficient=1.0, expansion_coefficient=2.0, contraction_coefficient=0.5, shrinkage_coefficient=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.reflection_coefficient = reflection_coefficient\n        self.expansion_coefficient = expansion_coefficient\n        self.contraction_coefficient = contraction_coefficient\n        self.shrinkage_coefficient = shrinkage_coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize simplex\n        self.simplex = np.random.uniform(self.lb, self.ub, size=(self.dim + 1, self.dim))\n        self.simplex[0] = np.random.uniform(self.lb, self.ub, size=self.dim)\n        for i in range(1, self.dim + 1):\n          self.simplex[i] = self.simplex[0] + np.random.uniform(-self.initial_simplex_size, self.initial_simplex_size, size=self.dim)\n\n        self.fitness = np.array([func(x) for x in self.simplex])\n        self.eval_count = self.dim + 1\n\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.simplex[best_idx]\n\n        while self.eval_count < self.budget:\n            # Order the simplex\n            order = np.argsort(self.fitness)\n            self.simplex = self.simplex[order]\n            self.fitness = self.fitness[order]\n\n            # Calculate centroid\n            centroid = np.mean(self.simplex[:-1], axis=0)\n\n            # Reflection\n            reflected_point = centroid + self.reflection_coefficient * (centroid - self.simplex[-1])\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            reflected_fitness = func(reflected_point)\n            self.eval_count += 1\n\n            if reflected_fitness < self.fitness[0]:\n                # Expansion\n                expanded_point = centroid + self.expansion_coefficient * (reflected_point - centroid)\n                expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                expanded_fitness = func(expanded_point)\n                self.eval_count += 1\n\n                if expanded_fitness < reflected_fitness:\n                    self.simplex[-1] = expanded_point\n                    self.fitness[-1] = expanded_fitness\n                else:\n                    self.simplex[-1] = reflected_point\n                    self.fitness[-1] = reflected_fitness\n            elif reflected_fitness < self.fitness[-2]:\n                self.simplex[-1] = reflected_point\n                self.fitness[-1] = reflected_fitness\n            else:\n                # Contraction\n                contracted_point = centroid + self.contraction_coefficient * (self.simplex[-1] - centroid)\n                contracted_point = np.clip(contracted_point, self.lb, self.ub)\n                contracted_fitness = func(contracted_point)\n                self.eval_count += 1\n\n                if contracted_fitness < self.fitness[-1]:\n                    self.simplex[-1] = contracted_point\n                    self.fitness[-1] = contracted_fitness\n                else:\n                    # Shrink\n                    for i in range(1, self.dim + 1):\n                        self.simplex[i] = self.simplex[0] + self.shrinkage_coefficient * (self.simplex[i] - self.simplex[0])\n                        self.simplex[i] = np.clip(self.simplex[i], self.lb, self.ub)\n                        self.fitness[i] = func(self.simplex[i])\n                        self.eval_count += 1\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.simplex[best_idx]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "7cb4287f-1235-45a8-b057-84a881e7f584", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589", "6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A gradient-free optimization algorithm that uses a Nelder-Mead simplex method combined with adaptive restarts and a shrinking mechanism to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, simplex_size=None, reflection=1.0, expansion=2.0, contraction=0.5, shrink=0.5, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = simplex_size if simplex_size is not None else dim + 1\n        self.reflection = reflection\n        self.expansion = expansion\n        self.contraction = contraction\n        self.shrink = shrink\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_simplex(self, func):\n        simplex = np.random.uniform(self.lb, self.ub, size=(self.simplex_size, self.dim))\n        fitness = np.array([func(x) for x in simplex])\n        self.budget -= self.simplex_size\n        return simplex, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        simplex, fitness = self.initialize_simplex(func)\n\n        while self.budget > 0:\n            # Order the simplex vertices by fitness\n            order = np.argsort(fitness)\n            simplex = simplex[order]\n            fitness = fitness[order]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = simplex[0].copy()\n\n            # Calculate the centroid of the best vertices\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected_point = centroid + self.reflection * (centroid - simplex[-1])\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            f_reflected = func(reflected_point)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n            \n            if fitness[0] <= f_reflected < fitness[-2]:\n                simplex[-1] = reflected_point\n                fitness[-1] = f_reflected\n            else:\n                # Expansion\n                if f_reflected < fitness[0]:\n                    expanded_point = centroid + self.expansion * (reflected_point - centroid)\n                    expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                    f_expanded = func(expanded_point)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_expanded < f_reflected:\n                        simplex[-1] = expanded_point\n                        fitness[-1] = f_expanded\n                    else:\n                        simplex[-1] = reflected_point\n                        fitness[-1] = f_reflected\n                else:\n                    # Contraction\n                    contracted_point = centroid + self.contraction * (simplex[-1] - centroid)\n                    contracted_point = np.clip(contracted_point, self.lb, self.ub)\n                    f_contracted = func(contracted_point)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_contracted < fitness[-1]:\n                        simplex[-1] = contracted_point\n                        fitness[-1] = f_contracted\n                    else:\n                        # Shrink\n                        for i in range(1, self.simplex_size):\n                            simplex[i] = simplex[0] + self.shrink * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n                            fitness[i] = func(simplex[i])\n                            self.budget -= 1\n\n                            if self.budget <= 0:\n                                break\n                        if self.budget <= 0:\n                            break\n            if np.random.rand() < self.restart_prob:\n                simplex, fitness = self.initialize_simplex(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.48344, "other_inf": null}
{"id": "19ab588c-1f15-466e-b472-14d5e95507f7", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "Evolves a population of solutions using a combination of differential evolution mutation and a gradient-based local search, dynamically adjusting the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEGradient:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n        self.eval_count = 0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def local_search(self, func, x, step_size=0.1):\n        \"\"\"Performs a simple gradient-based local search.\"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Calculate numerical gradient along each dimension\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n\n            #Clip to bounds\n            x_plus[i] = np.clip(x_plus[i], self.lb, self.ub)\n            x_minus[i] = np.clip(x_minus[i], self.lb, self.ub)\n                \n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.eval_count += 2\n            gradient = (f_plus - f_minus) / (2 * step_size)\n\n            # Update the solution based on the gradient\n            x_new[i] -= step_size * gradient\n            x_new[i] = np.clip(x_new[i], self.lb, self.ub)  # Clip to bounds\n        return x_new, func(x_new)\n\n    def __call__(self, func):\n        # Initialization\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Local Search with probability\n                if np.random.rand() < self.local_search_prob:\n                    trial, f_trial = self.local_search(func, trial)\n                else:\n                    f_trial = func(trial)\n                    self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "0573950c-8708-4d9e-95c8-a1e5611a90eb", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb"], "algorithm": "# Description: An iterative algorithm that samples new solutions using a Cauchy distribution, adaptively scaling the distribution based on the success rate of improvements.\n# Code:\n```", "code": "import numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, initial_scale=1.0, success_rate_window=100):\n        self.budget = budget\n        self.dim = dim\n        self.initial_scale = initial_scale\n        self.scale = initial_scale\n        self.success_rate_window = success_rate_window\n        self.successes = 0\n        self.attempts = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample new solution from Cauchy distribution\n            z = np.random.standard_cauchy(size=self.dim)\n            new_x = self.x_opt + self.scale * z\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            evals += 1\n            self.attempts += 1\n\n            # Update if improvement\n            if new_f < self.f_opt:\n                self.f_opt = new_f\n                self.x_opt = new_x\n                self.successes += 1\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n            \n            # Adaptive scaling of Cauchy distribution\n            if self.attempts > self.success_rate_window:\n                self.attempts = 0\n                success_rate = np.mean(self.success_history[-self.success_rate_window:])\n                if success_rate > 0.2:\n                    self.scale *= 1.1  # Increase scale if success rate is high\n                else:\n                    self.scale *= 0.9  # Decrease scale if success rate is low\n\n        return self.f_opt, self.x_opt", "objective": -0.53993, "other_inf": null}
{"id": "61eab1aa-cdda-499d-a450-6230c80d7545", "parents": ["d0e9a24c-b38d-4d14-8cb6-f7eb9c311cbb", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "This algorithm iteratively refines promising regions by focusing search efforts around the best solutions found so far, adjusting search volume based on performance, and using orthogonal arrays for efficient exploration within each region.", "code": "import numpy as np\nfrom pyDOE import lhs\n\nclass OrthogonalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, refinement_factor=0.5, oa_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.refinement_factor = refinement_factor\n        self.oa_size = oa_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while eval_count < self.budget:\n            # Refine search space around best solution\n            range_lb = np.maximum(lb, self.x_opt - self.refinement_factor * (ub - lb) / 2)\n            range_ub = np.minimum(ub, self.x_opt + self.refinement_factor * (ub - lb) / 2)\n\n            # Generate orthogonal array\n            oa = lhs(self.dim, samples=self.oa_size)\n            new_solutions = range_lb + oa * (range_ub - range_lb)\n\n            new_fitness = np.array([func(x) for x in new_solutions])\n            eval_count += self.oa_size\n\n            # Update best solution\n            best_idx_oa = np.argmin(new_fitness)\n            if new_fitness[best_idx_oa] < self.f_opt:\n                self.f_opt = new_fitness[best_idx_oa]\n                self.x_opt = new_solutions[best_idx_oa]\n\n            # Adapt refinement factor\n            if self.f_opt == np.min(fitness):\n                self.refinement_factor *= 0.9  # Reduce search volume if no improvement\n            else:\n                self.refinement_factor = min(0.5, self.refinement_factor * 1.1)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a886165f-6ffd-4b6e-8dfe-fec447786b6d", "parents": ["a2fb82fc-f29b-4950-be62-0473ecff94e7", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "# Description: A population-based algorithm that uses a combination of global random search and local gradient-based refinement, adaptively switching between exploration and exploitation phases based on the improvement rate.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveExplorationExploitation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_prob=0.5, lr=0.01, exploration_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_prob = exploration_prob\n        self.lr = lr\n        self.exploration_decay = exploration_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration: Random search around the current solution\n                    new_solution = population[i] + np.random.uniform(-self.lr, self.lr, size=self.dim) * (ub - lb)\n                    new_solution = np.clip(new_solution, lb, ub)\n                else:\n                    # Exploitation: Gradient-based refinement (simplified)\n                    gradient = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus = population[i].copy()\n                        x_minus = population[i].copy()\n                        delta = 1e-4\n                        x_plus[j] += delta\n                        x_minus[j] -= delta\n                        x_plus = np.clip(x_plus, lb, ub)\n                        x_minus = np.clip(x_minus, lb, ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        evals += 2\n                        gradient[j] = (f_plus - f_minus) / (2 * delta)\n\n                    new_solution = population[i] - self.lr * gradient\n                    new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n                \n                if new_fitness < fitness[i]:\n                    new_population[i] = new_solution\n                    fitness[i] = new_fitness\n\n            # Update population\n            population = new_population\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            # Adaptive exploration probability\n            self.exploration_prob *= self.exploration_decay\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "5c5772d2-e76b-4e80-b9d9-41804dade776", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A differential evolution algorithm with adaptive mutation and crossover rates based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Adaptive F and CR\n            std = np.std(population, axis=0)\n            adaptive_F = self.F * (1 + np.mean(std)) # Add some randomness with std\n            adaptive_CR = self.CR * (1 - np.mean(std))\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                mutant = population[i] + adaptive_F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n\n                # Evaluation\n                f = func(trial_vector)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.15704, "other_inf": null}
{"id": "bc621a3d-2ff8-4665-8465-d49f53731448", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "This algorithm uses a decaying step size and momentum to guide the search, focusing exploration early on and exploitation later.", "code": "import numpy as np\n\nclass MomentumSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        v = np.zeros(self.dim)  # Initialize velocity\n        \n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Calculate the gradient (approximation)\n            grad = np.zeros(self.dim)\n            delta = 1e-4\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_plus[i] += delta\n                f_plus = func(x_plus) if evals + 1 <= self.budget else np.inf\n                if f_plus == np.inf:\n                    break\n                evals += 1\n\n                x_minus = x.copy()\n                x_minus[i] -= delta\n                f_minus = func(x_minus) if evals + 1 <= self.budget else np.inf\n                if f_minus == np.inf:\n                    break\n                evals += 1\n                \n                grad[i] = (f_plus - f_minus) / (2 * delta)\n                \n\n            # Update velocity and position\n            v = self.momentum_factor * v - step_size * grad\n            x = x + v\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x) if evals + 1 <= self.budget else np.inf\n            if f == np.inf:\n                break\n            evals += 1\n\n            # Update best solution\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            # Decay step size\n            step_size *= 0.999\n        \n        return self.f_opt, self.x_opt", "objective": -0.31479, "other_inf": null}
{"id": "9ccd8964-1063-45ac-9087-0f3f33f1b190", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A population-based algorithm that combines elements of differential evolution with adaptive mutation and crossover rates based on the population's diversity and progress towards the optimum.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n\n        return self.f_opt, self.x_opt", "objective": -0.6468, "other_inf": null}
{"id": "39022cf0-d9e3-4dd2-8ecb-42ea6570ef20", "parents": ["0573950c-8708-4d9e-95c8-a1e5611a90eb"], "algorithm": "# Description: This algorithm combines Cauchy mutations with a Simulated Annealing-like acceptance criterion and adaptive scaling of the Cauchy distribution.\n# Code:\n```", "code": "import numpy as np\n\nclass CauchyAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_scale=1.0, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_scale = initial_scale\n        self.scale = initial_scale\n        self.initial_temp = initial_temp\n        self.temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample new solution from Cauchy distribution\n            z = np.random.standard_cauchy(size=self.dim)\n            new_x = self.x_opt + self.scale * z\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            evals += 1\n\n            # Simulated Annealing acceptance criterion\n            delta_f = new_f - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.f_opt = new_f\n                self.x_opt = new_x\n\n            #Cooling\n            self.temp *= self.cooling_rate\n\n            #Adaptive scaling\n            if evals % 1000 == 0: # Adjust every 1000 evaluations.\n                if new_f < self.f_opt:\n                   self.scale *= 1.05\n                else:\n                   self.scale *= 0.95\n                self.scale = np.clip(self.scale, 0.01, 10.0)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.33927, "other_inf": null}
{"id": "6d6dbc18-6de6-43b4-a1ca-01a661b18827", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success of previous generations, promoting exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.archive_factor = 2.0 # Size of the archive relative to pop_size\n        self.archive = []\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + self.f * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                    \n                    self.archive.append(population[i].copy())\n                    if len(self.archive) > self.archive_factor * self.pop_size:\n                        self.archive.pop(0)  # Maintain archive size\n\n                    self.success_cr.append(self.cr)\n                    self.success_f.append(self.f)\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Update CR and F\n            if self.success_cr and self.success_f:\n                self.cr = np.mean(self.success_cr)\n                self.f = np.mean(self.success_f)\n                self.success_cr = []\n                self.success_f = []\n            else:\n                # No successful updates, increase exploration\n                self.cr = min(1.0, self.cr + 0.1)\n                self.f = min(1.0, self.f + 0.1)\n\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.f = np.clip(self.f, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.68051, "other_inf": null}
{"id": "71c78de7-d788-40c8-ab75-13937f33fe99", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A population-based algorithm that combines particle swarm optimization principles with a mutation operator to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass PSOWithMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        self.f_opt = fitness[best_idx]\n        self.x_opt = global_best_position.copy()\n\n        while evals < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (self.w * velocities\n                          + self.c1 * r1 * (personal_best_positions - population)\n                          + self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n\n            # Apply boundary constraints\n            population = np.clip(population, lb, ub)\n\n            # Apply mutation\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < self.mutation_rate\n            population[mutation_mask] = np.random.uniform(lb, ub, size=np.sum(mutation_mask))\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n\n            # Update personal bests\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_idx = np.argmin(personal_best_fitness)\n            if personal_best_fitness[best_idx] < self.f_opt:\n                self.f_opt = personal_best_fitness[best_idx]\n                self.x_opt = personal_best_positions[best_idx].copy()\n                global_best_position = personal_best_positions[best_idx].copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7e290f57-9c0c-4a2e-982e-e9e8a5c5c6cd", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "A self-adaptive differential evolution algorithm that adjusts its parameters (crossover rate and scaling factor) during the optimization process based on the success of previous generations.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cr_memory = np.ones(self.pop_size) * self.cr_init\n        self.f_memory = np.ones(self.pop_size) * self.f_init\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                cr = self.cr_memory[i]\n                f = self.f_memory[i]\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant_vector = population[i] + f * (x2 - x3)\n                mutant_vector = np.clip(mutant_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        trial_vector[j] = mutant_vector[j]\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Success!\n                    self.success_cr.append(cr)\n                    self.success_f.append(f)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                # Update CR and F\n                if len(self.success_cr) > 0:\n                    cr_mean = np.mean(self.success_cr)\n                    f_mean = np.mean(self.success_f)\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * cr_mean # Exponential smoothing\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * f_mean # Exponential smoothing\n                else:\n                    self.cr_memory[i] = np.clip(np.random.normal(self.cr_init, 0.1), 0, 1)\n                    self.f_memory[i] = np.clip(np.random.normal(self.f_init, 0.1), 0, 2)\n\n                if len(self.success_cr) > self.pop_size:\n                    self.success_cr = self.success_cr[-self.pop_size:]\n                    self.success_f = self.success_f[-self.pop_size:]\n\n        return self.f_opt, self.x_opt", "objective": -0.53981, "other_inf": null}
{"id": "523a1d2d-61b3-481f-a46b-2081d56ee0b7", "parents": ["6cffcfc9-ce50-4268-b2b7-7290d6fd3589"], "algorithm": "An adaptive population-based algorithm that dynamically adjusts its exploration-exploitation balance based on the function's evaluation landscape, using a combination of differential evolution and a simplified PSO, coupled with a self-adaptive local search.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.6, pso_w=0.5, pso_c=1.0, local_search_init_prob=0.2, exploration_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c = pso_c\n        self.local_search_prob = local_search_init_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_threshold = exploration_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO (simplified - no individual best)\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            \n            # Adaptive parameter adjustment based on progress\n            if iteration % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std < self.exploration_threshold:\n                    self.local_search_prob *= 1.1  # Increase local search\n                    self.de_f *= 0.9 # Decrease differential weight\n                else:\n                    self.local_search_prob *= 0.9   # Decrease local search\n                    self.de_f *= 1.1 # Increase differential weight\n                self.local_search_prob = np.clip(self.local_search_prob, 0.05, 0.5)\n                self.de_f = np.clip(self.de_f, 0.4, 1.0)\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                if np.random.rand() < 0.5:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    \n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else: # Simplified Particle Swarm Optimization (no personal best)\n                    r = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c * r * (global_best_position - population[i]))\n                    trial_vector = population[i] + velocities[i]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (self.ub - self.lb)\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    trial_vector = trial_vector + step_size * random_direction\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n        return self.f_opt, self.x_opt", "objective": -0.63308, "other_inf": null}
{"id": "7c9cab84-6cf9-4eed-83ea-b5c9fd43113c", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "Simulated Annealing with adaptive temperature and step size, restarting if the temperature is too low.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, min_temp=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n        step_size = (ub - lb) / 10.0 \n\n        while self.budget > 0:\n            x_new = x + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            temp *= self.cooling_rate\n            step_size *= self.cooling_rate**(1/self.dim) #Adapt step size\n\n            if temp < self.min_temp:\n                # Restart if temperature is too low\n                x = np.random.uniform(lb, ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                temp = self.initial_temp\n                step_size = (ub-lb) / 10.0\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.40282, "other_inf": null}
{"id": "359f059b-4d8b-4982-8f2b-8241a0cc77cd", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "523a1d2d-61b3-481f-a46b-2081d56ee0b7"], "algorithm": "A gradient-based optimization algorithm that estimates the gradient using finite differences and adaptively adjusts the step size based on the success of previous steps, incorporating momentum for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum=0.9, finite_diff_delta=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.momentum = momentum\n        self.finite_diff_delta = finite_diff_delta\n        self.lb = -5.0\n        self.ub = 5.0\n        self.velocity = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize within bounds\n        self.f_opt = func(self.x_opt)\n        self.budget -= 1\n        \n        success_count = 0\n        iteration = 0\n\n        while self.budget > 0:\n            iteration += 1\n            \n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus_delta = self.x_opt.copy()\n                x_plus_delta[i] += self.finite_diff_delta\n                x_plus_delta = np.clip(x_plus_delta, self.lb, self.ub)\n                \n                f_plus_delta = func(x_plus_delta)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                x_minus_delta = self.x_opt.copy()\n                x_minus_delta[i] -= self.finite_diff_delta\n                x_minus_delta = np.clip(x_minus_delta, self.lb, self.ub)\n                \n                f_minus_delta = func(x_minus_delta)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                gradient[i] = (f_plus_delta - f_minus_delta) / (2 * self.finite_diff_delta)\n            \n            # Update velocity with momentum\n            self.velocity = self.momentum * self.velocity - self.step_size * gradient\n            \n            # Update position\n            x_new = self.x_opt + self.velocity\n            x_new = np.clip(x_new, self.lb, self.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                success_count += 1\n                # Increase step size if successful\n                if success_count > 5:\n                    self.step_size *= 1.1\n                    success_count = 0 # Reset the success count\n            else:\n                # Decrease step size if unsuccessful\n                self.step_size *= 0.5\n                success_count = 0 # Reset success count\n            \n            #Limit step size to avoid divergence\n            self.step_size = min(self.step_size, 1.0)\n            \n        return self.f_opt, self.x_opt", "objective": -0.1358, "other_inf": null}
{"id": "79f8cede-2e78-4a30-a1f4-115feb1810cc", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A hybrid algorithm that combines Particle Swarm Optimization (PSO) for global search with Nelder-Mead Simplex for local refinement.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.4, c2=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize PSO\n        particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/2, abs(ub-lb)/2, size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - particles) +\n                          self.c2 * r2 * (global_best_position - particles))\n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = particles[i].copy()\n\n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[global_best_index]\n                global_best_position = personal_best_positions[global_best_index].copy()\n                self.x_opt = global_best_position.copy()\n\n            if self.budget <= 0:\n                break\n\n        # Local search using Nelder-Mead around the global best found by PSO\n        nm_budget = min(500, self.budget) # limit local search budget\n        result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': nm_budget", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.4, c2=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize PSO\n        particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/2, abs(ub-lb)/2, size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - particles) +\n                          self.c2 * r2 * (global_best_position - particles))\n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = particles[i].copy()\n\n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[global_best_index]\n                global_best_position = personal_best_positions[global_best_index].copy()\n                self.x_opt = global_best_position.copy()\n\n            if self.budget <= 0:\n                break\n\n        # Local search using Nelder-Mead around the global best found by PSO\n        nm_budget = min(500, self.budget) # limit local search budget\n        result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': nm_budget})\n        \n        if result.fun < self.f_opt:\n            self.f_opt = result.fun\n            self.x_opt = result.x\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b7874ff2-adde-4041-8b2e-8977a6eb026c", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "A gradient-free optimization algorithm that iteratively refines a population of candidate solutions by perturbing them based on their fitness and spatial relationships, using a decaying perturbation strength to promote exploration early and exploitation later.", "code": "import numpy as np\n\nclass PerturbationOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, perturbation_strength=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.perturbation_strength = perturbation_strength\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Perturbation\n                \n                # Weight other solutions based on fitness. Better solutions have more influence.\n                weights = np.exp(-(fitness - fitness[i]) / (np.std(fitness) + 1e-8))  # Softmax-like weighting\n                weights[i] = 0  # Don't consider the current solution itself.\n                weights = weights / np.sum(weights)\n\n                weighted_center = np.sum(population * weights[:, None], axis=0)\n\n                # Perturb based on distance from weighted center and random component\n                perturbation = self.perturbation_strength * (weighted_center - population[i]) + \\\n                              self.perturbation_strength * np.random.uniform(-1, 1, self.dim)\n\n                trial = population[i] + perturbation\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate\n                f_trial = func(trial)\n                evals += 1\n\n                # Update if better\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Decay perturbation strength\n            self.perturbation_strength = self.perturbation_strength * (1 - evals / self.budget)\n\n        return self.f_opt, self.x_opt", "objective": -0.30603, "other_inf": null}
{"id": "9eef5554-22ae-4132-b6de-a340f1566aac", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "# Description: An iterative search that refines the search space by focusing on promising regions identified through a Gaussian process model.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random samples\n        X = np.random.uniform(lb, ub, size=(self.n_initial, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial\n\n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        # Gaussian process model\n        kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while evals < self.budget:\n            # Fit the GP model\n            gp.fit(X, y)\n\n            # Acquisition function (Upper Confidence Bound)\n            def acquisition(x):\n                mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n                return mu - self.exploration_weight * sigma\n\n            # Optimize acquisition function (using a simple random search)\n            n_candidates = 100\n            X_candidates = np.random.uniform(lb, ub, size=(n_candidates, self.dim))\n            acq_values = np.array([acquisition(x) for x in X_candidates])\n            best_candidate_idx = np.argmin(acq_values)\n            x_new = X_candidates[best_candidate_idx]\n\n            # Evaluate the new point\n            f_new = func(x_new)\n            evals += 1\n\n            # Update the data\n            X = np.vstack((X, x_new))\n            y = np.append(y, f_new)\n\n            # Update best solution\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "5ce1fa0f-698d-4e34-abb8-fbd7346896d8", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "9ccd8964-1063-45ac-9087-0f3f33f1b190"], "algorithm": "A self-organizing search algorithm that iteratively refines promising regions by concentrating search points around the best solutions found so far, adapting the search radius based on the distribution of function values.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, num_points=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_points = num_points\n        self.radius = initial_radius\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize search points randomly\n        points = np.random.uniform(self.lb, self.ub, size=(self.num_points, self.dim))\n        fitness = np.array([func(x) for x in points])\n        self.budget -= self.num_points\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = points[best_index].copy()\n\n        while self.budget > 0:\n            # Sort points by fitness\n            sorted_indices = np.argsort(fitness)\n            points = points[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Concentrate search around best points\n            new_points = []\n            for i in range(self.num_points):\n                # Sample from a normal distribution centered around top solutions\n                center_index = min(i, self.num_points // 4) # Focus on top quarter\n                center = points[center_index]\n                \n                new_point = np.random.normal(center, self.radius, size=self.dim)\n                new_point = np.clip(new_point, self.lb, self.ub)\n                new_points.append(new_point)\n\n            new_points = np.array(new_points)\n            new_fitness = np.array([func(x) for x in new_points])\n            self.budget -= self.num_points\n\n            # Update best solution\n            for i in range(self.num_points):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_points[i].copy()\n\n            # Combine old and new points\n            all_points = np.concatenate([points, new_points])\n            all_fitness = np.concatenate([fitness, new_fitness])\n            \n            # Select the best points for the next iteration\n            sorted_indices = np.argsort(all_fitness)[:self.num_points]\n            points = all_points[sorted_indices]\n            fitness = all_fitness[sorted_indices]\n\n            # Adjust search radius based on fitness distribution\n            std_dev = np.std(fitness)\n            self.radius = max(0.01, self.radius * (1 - std_dev / abs(self.f_opt + 1e-8)))  # Ensure division by zero is avoided\n            self.radius = min(self.radius, (self.ub - self.lb) / 2.0)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.2657, "other_inf": null}
{"id": "aa517607-314b-4e94-86f1-d3249aec3a8b", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190", "e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "This algorithm focuses on iteratively refining a single solution by stochastically perturbing it and accepting the perturbation if it leads to an improvement, with an adaptive step size based on the success rate of previous perturbations.", "code": "import numpy as np\n\nclass AdaptiveStepSizeSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.6):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a new solution by perturbing the current best\n            noise = np.random.normal(0, self.step_size, size=self.dim)\n            x_new = x + noise\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Accept the new solution if it's better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_count += 1\n\n            self.iteration_count += 1\n\n            # Adjust step size based on success rate\n            if self.iteration_count > 100:\n                success_rate = self.success_count / self.iteration_count\n                if success_rate > self.success_rate_threshold:\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n\n                self.step_size = np.clip(self.step_size, 1e-6, (ub-lb)/2) # Ensure step size does not become too small or too large\n                self.success_count = 0\n                self.iteration_count = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.25907, "other_inf": null}
{"id": "aab47c35-3c39-40bf-95af-76add256b5fb", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a", "9ccd8964-1063-45ac-9087-0f3f33f1b190"], "algorithm": "# Description: A single-solution based algorithm that iteratively refines a solution by combining gradient estimation with random exploration, adapting the step size based on success.\n# Code:\n```", "code": "import numpy as np\n\nclass GradientGuidedSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Estimate gradient (simplified - random direction)\n            direction = np.random.normal(0, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)\n\n            # Take a step\n            x_new = x + self.step_size * direction\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_rate = 0.9 * self.success_rate + 0.1\n            else:\n                self.success_rate = 0.9 * self.success_rate\n\n            # Adjust step size\n            if self.success_rate > 0.5:\n                self.step_size *= 1.1\n            else:\n                self.step_size *= 0.9\n\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.15753, "other_inf": null}
{"id": "ce4d753c-e468-4698-a823-1f4f6e39021a", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: An adaptive variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adjusts its parameters based on the landscape.\n# Code: \n```", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lb = lb\n        self.ub = ub\n        self.sigma = initial_sigma\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.mu = self.pop_size // 2\n        self.weights = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize()\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, self.lb, self.ub)\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[:, np.argmin(fitness)].copy()\n            \n            # Sort by fitness\n            indices = np.argsort(fitness)\n            x_sorted = x[:, indices]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(x_sorted[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n            # Update evolution paths\n            B = np.linalg.cholesky(self.C)\n            z_mean = np.sum(z[:, indices[:self.mu]] * self.weights[np.newaxis, :], axis=1)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.dot(B, z_mean))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.mean - mean_old) / self.sigma\n            \n            # Update covariance matrix\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.budget / self.pop_size))) / self.chiN < 1.4 + 2/(self.dim + 1))\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.c_mu * np.sum(self.weights[np.newaxis, :] * (z[:, indices[:self.mu]] @ z[:, indices[:self.mu]].T), axis=1)\n            \n            # Adapt step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T # enforce symmetry\n            self.C = np.linalg.solve(np.tril(self.C), np.triu(self.C)) # enforce positive definiteness (not always correct)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "21cafca6-a5af-4177-a3ae-49d8a3804603", "parents": ["523a1d2d-61b3-481f-a46b-2081d56ee0b7"], "algorithm": "An adaptive algorithm combining differential evolution with covariance matrix adaptation evolution strategy (CMA-ES) to balance global exploration and local exploitation, using a population-based approach with dynamic parameter adjustments based on the function's landscape.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.6, cma_sigma=0.1, exploration_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.cma_sigma = cma_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_threshold = exploration_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        covariance = np.eye(self.dim)\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive parameter adjustment based on progress\n            if iteration % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std < self.exploration_threshold:\n                    self.cma_sigma *= 0.9  # Reduce CMA-ES step size\n                    self.de_f *= 1.1  # Increase DE exploration\n                else:\n                    self.cma_sigma *= 1.1  # Increase CMA-ES step size\n                    self.de_f *= 0.9  # Reduce DE exploration\n                self.cma_sigma = np.clip(self.cma_sigma, 0.01, 1.0)\n                self.de_f = np.clip(self.de_f, 0.4, 1.0)\n\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n\n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                else:\n                    # CMA-ES Sample\n                    trial_vector = np.random.multivariate_normal(mean, self.cma_sigma * covariance)\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n                new_population.append(trial_vector)\n                new_fitness.append(f)\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial_vector.copy()\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n            \n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update CMA-ES mean\n            mean = np.mean(population, axis=0)\n\n        return self.f_opt, self.x_opt", "objective": -0.24286, "other_inf": null}
{"id": "33ec0f24-c977-4d07-b796-c65d7c3c4898", "parents": ["e83c0a95-568e-4688-a865-cbe648ffe41a"], "algorithm": "A population-based algorithm that uses a combination of differential evolution and a local search strategy, adaptively adjusting parameters based on the function landscape.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Mutation\n                v_trial = population[i] + self.F * (x_r1 - x_r2)\n                v_trial = np.clip(v_trial, lb, ub)\n                \n                # Crossover\n                u_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u_trial[j] = v_trial[j]\n\n                f_trial = func(u_trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = u_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = u_trial\n                \n                # Local Search\n                elif np.random.rand() < self.local_search_prob:\n                    # Perform a small local search around the current solution\n                    local_x = np.random.normal(population[i], scale=0.05 * (ub - lb), size=self.dim)\n                    local_x = np.clip(local_x, lb, ub)\n                    local_f = func(local_x)\n                    evals += 1\n                    if local_f < fitness[i]:\n                        population[i] = local_x\n                        fitness[i] = local_f\n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_x\n                            \n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.53848, "other_inf": null}
{"id": "7155db6b-00e2-49a9-badf-a26abfeaf788", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190"], "algorithm": "# Description: This algorithm employs a self-adaptive differential evolution strategy with a restart mechanism triggered by stagnation detection, aiming to escape local optima and enhance exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, stagnation_limit=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n            \n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n              population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n              fitness = np.array([func(x) for x in population])\n              evals += self.pop_size\n              \n              best_idx = np.argmin(fitness)\n              self.f_opt = fitness[best_idx]\n              self.x_opt = population[best_idx]\n              self.stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "objective": -0.68351, "other_inf": null}
{"id": "27a92e79-0c34-4b4d-8cec-02c12881e105", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a population-based approach with a Gaussian mutation operator and a selection mechanism based on fitness rank, aiming to balance exploration and exploitation.", "code": "import numpy as np\n\nclass RankBasedGaussianMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Rank-based selection\n            ranked_indices = np.argsort(fitness)\n            selected_indices = ranked_indices[:self.pop_size // 2]  # Select top half\n\n            for i in range(self.pop_size):\n                # Mutation\n                if i in selected_indices or np.random.rand() < self.mutation_rate:\n                    mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) * (ub - lb)\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    mutant = np.copy(population[i])\n\n                # Evaluation\n                f_mutant = func(mutant)\n                evals += 1\n\n                # Selection: replace if better\n                if f_mutant < fitness[i]:\n                    population[i] = mutant\n                    fitness[i] = f_mutant\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n        return self.f_opt, self.x_opt", "objective": -0.33163, "other_inf": null}
{"id": "c4ede682-e2b3-4d67-8cbf-1c67d053b94f", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190"], "algorithm": "An enhanced differential evolution strategy that incorporates a local search component using Nelder-Mead simplex method applied to the best individuals, aiming to refine the solution in promising regions.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_frequency=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.local_search_frequency = local_search_frequency\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Local Search using Nelder-Mead on best solution\n            if evals % self.local_search_frequency == 0:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds)\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    \n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "02939c0e-6d6a-4144-900c-486765e92e72", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm combines a simplified differential evolution strategy with a Cauchy mutation operator for enhanced exploration, particularly suitable for escaping local optima in challenging search spaces.", "code": "import numpy as np\n\nclass CauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, cauchy_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                mutant = population[i] + self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.33964, "other_inf": null}
{"id": "478aaff4-e8cb-49ca-a602-bbfb0289f1f4", "parents": ["523a1d2d-61b3-481f-a46b-2081d56ee0b7"], "algorithm": "# Description: An enhanced adaptive population-based algorithm that employs a dynamic weighting strategy between differential evolution and particle swarm optimization based on population diversity, combined with a covariance matrix adaptation evolution strategy (CMA-ES) inspired local search for intensified exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.8, de_f=0.7, pso_w=0.6, pso_c=1.2, ls_init_prob=0.1, diversity_threshold=0.05, cma_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c = pso_c\n        self.ls_prob = ls_init_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.diversity_threshold = diversity_threshold\n        self.cma_sigma = cma_sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        # Initialize CMA-ES-like covariance matrix (diagonal for simplicity)\n        covariance = np.eye(self.dim) * self.cma_sigma**2\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive parameter adjustment based on population diversity\n            diversity = np.std(population)\n            if diversity < self.diversity_threshold:\n                de_weight = 0.2  # Favor PSO (exploitation)\n                self.ls_prob = min(self.ls_prob * 1.2, 0.7)  # Increase local search\n            else:\n                de_weight = 0.8  # Favor DE (exploration)\n                self.ls_prob = max(self.ls_prob * 0.8, 0.05)  # Decrease local search\n\n            for i in range(self.pop_size):\n                # Adaptive DE/PSO selection\n                if np.random.rand() < de_weight:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n\n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else:\n                    # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c * r1 * (global_best_position - population[i]) +\n                                    self.pso_c * r2 * (population[np.random.randint(self.pop_size)] - population[i]))  # Adding social component\n                    trial_vector = population[i] + velocities[i]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # CMA-ES inspired local search\n                if np.random.rand() < self.ls_prob:\n                    z = np.random.normal(0, 1, self.dim)\n                    step = np.sqrt(np.diag(covariance)) * z # Scale each dimension by stdev\n                    trial_vector = population[i] + step\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    # Simplified covariance adaptation (you could use a more sophisticated update rule)\n                    covariance = covariance * 0.99 + np.outer(step, step) * 0.01\n\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n\n\n        return self.f_opt, self.x_opt", "objective": -0.58303, "other_inf": null}
{"id": "1b9b9079-3d0f-42c0-89db-9ba9af2429e6", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a covariance matrix adaptation evolution strategy (CMA-ES) inspired approach, which adapts the search distribution by learning from successful search steps to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, damps=None, c_cov=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / (self.pop_size + (self.dim + 1)**2)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        C = np.eye(self.dim)\n        P_c = np.zeros(self.dim)\n        P_sigma = np.zeros(self.dim)\n\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            population = np.array([mean + self.sigma * z for z in Z])\n            population = np.clip(population, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n\n            # Sort population and fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            population = population[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Update mean\n            mean_old = mean\n            mean = np.mean(population[:self.pop_size // 2], axis=0) # Use only the best individuals\n            \n            # Update evolution path\n            diff = (mean - mean_old) / self.sigma\n            P_sigma = (1 - self.cs) * P_sigma + np.sqrt(self.cs * (2 - self.cs)) * diff\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(P_sigma) - np.sqrt(self.dim)))\n\n            # Update covariance matrix\n            C = (1-self.c_cov) * C + self.c_cov * np.outer(P_sigma, P_sigma)\n\n            # Ensure positive definiteness\n            try:\n                L = np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim) # Reset covariance matrix\n                P_sigma = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e1060106-1f0b-4c08-b01d-e32651ebeaa5", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "A gradient-free optimization method that estimates gradients using simplex-based derivative-free search and adapts step sizes based on function value changes.", "code": "import numpy as np\n\nclass SimplexSearch:\n    def __init__(self, budget=10000, dim=10, initial_step=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step = initial_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize simplex\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n        self.x_opt = x0\n        self.f_opt = func(x0)\n        self.budget -= 1\n\n        simplex = [x0]\n        for i in range(self.dim):\n            x = np.copy(x0)\n            x[i] += self.initial_step\n            x = np.clip(x, lb, ub)\n            simplex.append(x)\n\n        while self.budget > 0:\n            fitness = np.array([func(x) if i>0 or self.budget < 9999 else self.f_opt for i, x in enumerate(simplex)])\n            self.budget -= self.dim\n            if self.budget <= 0:\n                break\n\n            best_idx = np.argmin(fitness)\n            worst_idx = np.argmax(fitness)\n            \n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = simplex[best_idx]\n            \n            # Centroid of all points except the worst\n            centroid = np.mean([simplex[i] for i in range(len(simplex)) if i != worst_idx], axis=0)\n\n            # Reflection\n            reflection = centroid + (centroid - simplex[worst_idx])\n            reflection = np.clip(reflection, lb, ub)\n\n            f_reflection = func(reflection)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n\n            if f_reflection < fitness[worst_idx]:\n                simplex[worst_idx] = reflection\n                fitness[worst_idx] = f_reflection\n                if f_reflection < self.f_opt:\n                    self.f_opt = f_reflection\n                    self.x_opt = reflection\n\n                # Expansion\n                expansion = centroid + 2 * (centroid - simplex[worst_idx])\n                expansion = np.clip(expansion, lb, ub)\n\n                f_expansion = func(expansion)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n                \n                if f_expansion < f_reflection:\n                    simplex[worst_idx] = expansion\n                    fitness[worst_idx] = f_expansion\n                    if f_expansion < self.f_opt:\n                        self.f_opt = f_expansion\n                        self.x_opt = expansion\n            else:\n                # Contraction\n                contraction = centroid + 0.5 * (simplex[worst_idx] - centroid)\n                contraction = np.clip(contraction, lb, ub)\n                \n                f_contraction = func(contraction)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n                if f_contraction < fitness[worst_idx]:\n                    simplex[worst_idx] = contraction\n                    fitness[worst_idx] = f_contraction\n                    if f_contraction < self.f_opt:\n                        self.f_opt = f_contraction\n                        self.x_opt = contraction\n                else:\n                    # Shrink\n                    for i in range(len(simplex)):\n                        if i != best_idx:\n                            simplex[i] = simplex[best_idx] + 0.5 * (simplex[i] - simplex[best_idx])\n                            simplex[i] = np.clip(simplex[i], lb, ub)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "ee14ac18-3f24-45f6-b5c3-53ee7d5026f2", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "523a1d2d-61b3-481f-a46b-2081d56ee0b7"], "algorithm": "'initial_simplex': initial_simplex, 'maxiter': self.nm_max_iter, 'maxfev': self.budget - evals, 'xatol': 1e-6, 'fatol': 1e-6", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, simplex_size=None, sobol_init_size=100, nm_max_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = dim + 1 if simplex_size is None else simplex_size\n        self.sobol_init_size = sobol_init_size\n        self.nm_max_iter = nm_max_iter\n        try:\n            from sobol_seq import i4_sobol_generate\n            self.sobol_generator = i4_sobol_generate\n        except ImportError:\n            print(\"sobol_seq package not found. Install it using: pip install sobol_seq\")\n            self.sobol_generator = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        evals = 0\n\n        if self.sobol_generator is None:\n            raise ImportError(\"Sobol sequence generator is not available. Please install 'sobol_seq' package.\")\n\n        # Sobol initialization\n        sobol_points = self.sobol_generator(self.dim, self.sobol_init_size)\n        initial_population = lb + (ub - lb) * sobol_points.T\n        initial_fitness = np.array([func(x) for x in initial_population])\n        evals += self.sobol_init_size\n\n        best_idx = np.argmin(initial_fitness)\n        self.f_opt = initial_fitness[best_idx]\n        self.x_opt = initial_population[best_idx]\n\n        while evals < self.budget:\n            # Initialize simplex with best Sobol point and some random variations\n            initial_simplex = np.zeros((self.simplex_size, self.dim))\n            initial_simplex[0] = self.x_opt\n            for i in range(1, self.simplex_size):\n                initial_simplex[i] = self.x_opt + np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=self.dim)\n                initial_simplex[i] = np.clip(initial_simplex[i], lb, ub)\n\n            # Nelder-Mead optimization\n            result = minimize(func, self.x_opt, method='Nelder-Mead',\n                               options={'initial_simplex': initial_simplex, 'maxiter': self.nm_max_iter, 'maxfev': self.budget - evals, 'xatol': 1e-6, 'fatol': 1e-6})\n            evals += result.nfev\n            \n            if result.fun < self.f_opt:\n                self.f_opt = result.fun\n                self.x_opt = result.x\n                \n            # Generate a new sobol point for the next iteration, if possible given the budget\n            if evals < self.budget:\n                new_sobol_point = self.sobol_generator(self.dim, 1).T[0]\n                new_x = lb + (ub - lb) * new_sobol_point\n                f_new = func(new_x)\n                evals += 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = new_x\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b5ec865c-39aa-4b16-a123-e704a07b21d0", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "This algorithm uses a particle swarm optimization approach with a constriction factor to control the swarm's convergence and exploration, coupled with a velocity clamping mechanism to prevent premature convergence.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, phi_p=1.49445, phi_g=1.49445, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega  # Inertia weight\n        self.phi_p = phi_p  # Cognitive coefficient\n        self.phi_g = phi_g  # Social coefficient\n        self.k = 2 / abs(2 - (phi_p + phi_g) - np.sqrt((phi_p + phi_g)**2 - 4 * (phi_p + phi_g))) # Constriction factor\n        self.v_max_ratio = v_max_ratio\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = population.copy()\n        pbest_fitness = np.array([func(x) for x in population])\n\n        # Find initial global best\n        best_idx = np.argmin(pbest_fitness)\n        self.f_opt = pbest_fitness[best_idx]\n        self.x_opt = pbest_positions[best_idx]\n        \n        evals = self.pop_size\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r_p = np.random.rand(self.dim)\n                r_g = np.random.rand(self.dim)\n                \n                cognitive_component = self.phi_p * r_p * (pbest_positions[i] - population[i])\n                social_component = self.phi_g * r_g * (self.x_opt - population[i])\n\n                velocities[i] = self.k * (self.omega * velocities[i] + cognitive_component + social_component)\n                \n                # Velocity clamping\n                v_max = abs(ub-lb) * self.v_max_ratio\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                fitness = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = fitness\n                    pbest_positions[i] = population[i].copy()\n                    \n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i]\n                \n                if evals >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt", "objective": -0.19713, "other_inf": null}
{"id": "69beea78-ccc3-4c73-b1b0-56f882be6178", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: This algorithm uses a population-based approach with a learning strategy that probabilistically combines the best-performing individual's direction with random exploration to find better solutions.\n# Code:\n```", "code": "import numpy as np\n\nclass ProbabilisticLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.1, exploration_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.exploration_prob = exploration_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration: Randomly sample a new solution\n                    trial = np.random.uniform(lb, ub)\n                else:\n                    # Exploitation: Learn from the best individual\n                    direction = self.x_opt - population[i]\n                    trial = population[i] + self.learning_rate * direction\n                    trial = np.clip(trial, lb, ub)\n                \n                f_trial = func(trial)\n                evals += 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "objective": -0.28804, "other_inf": null}
{"id": "10db5cc6-c053-4970-89b1-602d5510bc1b", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "523a1d2d-61b3-481f-a46b-2081d56ee0b7"], "algorithm": "This algorithm uses a Gaussian process to model the objective function and adaptively samples new points based on the predicted mean and variance, balancing exploration and exploitation through an Upper Confidence Bound (UCB) acquisition function, which is adjusted based on the landscape's characteristics.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\n\nclass GaussianProcessUCB:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_weight = exploration_weight\n        if kernel is None:\n            self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = []\n        self.y = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition(self, x, gp, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu[0] + self.exploration_weight * sigma[0]\n\n    def __call__(self, func):\n        # Initial random sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.budget -= self.n_initial\n\n        self.X = X_init.tolist()\n        self.y = y_init.tolist()\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            self.gp.fit(self.X, self.y)\n            \n            # Generate candidate points (random sampling)\n            X_candidate = np.random.uniform(self.lb, self.ub, size=(100, self.dim))\n            \n            # Select the best candidate based on acquisition function\n            acq_values = np.array([self.acquisition(x, self.gp) for x in X_candidate])\n            best_candidate_idx = np.argmin(acq_values)\n            x_new = X_candidate[best_candidate_idx]\n            \n            # Evaluate the new point\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Update lists\n            self.X.append(x_new.tolist())\n            self.y.append(f_new)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ef4cad56-81b4-4af6-b28a-8a5b03aa3947", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "# Description: This algorithm simulates a particle swarm, where particles adjust their positions based on their own best historical position and the swarm's best position, incorporating a constriction factor to control convergence.\n# Code:\n```", "code": "import numpy as np\n\nclass ParticleSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.kappa = 1 # Constriction factor denominator\n        self.phi = self.c1 + self.c2\n        if self.phi > 4:\n          self.kappa = 2 / abs(2 - self.phi - np.sqrt(self.phi**2 - 4 * self.phi))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))  #Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = np.copy(population)\n        personal_best_fitnesses = np.copy(fitness)\n        \n        # Find global best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.kappa * (self.w * velocities[i] +\n                                   self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                   self.c2 * r2 * (self.x_opt - population[i]))\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)  # Clip to bounds\n\n                # Evaluate fitness\n                f_trial = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f_trial < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = f_trial\n                    personal_best_positions[i] = np.copy(population[i])\n                    \n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = population[i]\n        return self.f_opt, self.x_opt", "objective": -0.44516, "other_inf": null}
{"id": "176c0496-0e76-406e-99c3-e5708952390e", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "# Description: This algorithm adaptively adjusts the search space by shrinking or expanding it based on the success rate of finding better solutions within the current search range.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSearchSpace:\n    def __init__(self, budget=10000, dim=10, initial_radius=1.0, shrink_factor=0.9, expand_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random solution\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.evals += 1\n        self.f_opt = f\n        self.x_opt = x\n        \n        success_count = 0\n\n        while self.evals < self.budget:\n            # Generate new candidate solution within the current radius\n            x_new = np.random.uniform(np.maximum(lb, self.x_opt - self.radius), np.minimum(ub, self.x_opt + self.radius), size=self.dim)\n\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                success_count += 1\n\n            # Adjust search space radius\n            if self.evals % 100 == 0:\n                success_rate = success_count / 100.0\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expand_factor\n                    self.radius = min(self.radius, (ub[0]-lb[0])/2)\n                else:\n                    self.radius *= self.shrink_factor\n                success_count = 0\n        \n        return self.f_opt, self.x_opt", "objective": -0.50554, "other_inf": null}
{"id": "8725a05f-69d9-401d-b538-a636cd33efd3", "parents": ["9ccd8964-1063-45ac-9087-0f3f33f1b190"], "algorithm": "# Description: A modified differential evolution algorithm with a self-adaptive population size and a restart mechanism based on stagnation detection.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter +=1\n            \n            self.best_fitness_history.append(self.f_opt)\n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n            \n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                 # Reduce population size if stagnating\n                if self.pop_size > 10: #set a minimum population size\n                    self.pop_size = max(10, int(self.pop_size * 0.75)) #reduce pop size\n                else: \n                    self.pop_size = int(min(50, self.pop_size * 1.1)) # grow pop size if small\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                self.stagnation_counter = 0\n        \n        return self.f_opt, self.x_opt", "objective": -0.50448, "other_inf": null}
{"id": "fc7769a5-4de0-49ba-b544-613dddadd800", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm utilizes a modified self-adaptive differential evolution strategy incorporating a shrinking population size based on the remaining budget and adaptive parameter control for enhanced exploitation and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Dynamically adjust population size based on remaining budget\n            remaining_evals = self.budget - evals\n            self.pop_size = max(10, int(self.initial_pop_size * (remaining_evals / self.budget)))\n\n            if self.pop_size < population.shape[0]:\n                 idx_to_keep = np.argsort(fitness)[:self.pop_size]\n                 population = population[idx_to_keep]\n                 fitness = fitness[idx_to_keep]\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) < 3:\n                    break # Handle edge case where population is too small\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.3 * np.random.rand()\n            self.CR = 0.4 + 0.5 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "objective": -0.66023, "other_inf": null}
{"id": "f63903f6-dffd-4551-86f2-42906e3dd38e", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm implements a modified self-adaptive differential evolution with a local search operator triggered probabilistically to refine promising solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    x_local = np.copy(population[i])\n                    step_size = 0.1 * (ub - lb)  # Define step size for local search\n\n                    for j in range(self.dim):\n                        # Explore in both directions for each dimension\n                        x_plus = np.copy(x_local)\n                        x_minus = np.copy(x_local)\n                        x_plus[j] = np.clip(x_local[j] + step_size, lb, ub)\n                        x_minus[j] = np.clip(x_local[j] - step_size, lb, ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        evals += 2\n\n                        if f_plus < fitness[i] and f_plus < f_minus:\n                            population[i] = x_plus\n                            fitness[i] = f_plus\n                            if f_plus < self.f_opt:\n                                self.f_opt = f_plus\n                                self.x_opt = x_plus\n                        elif f_minus < fitness[i] and f_minus < f_plus:\n                            population[i] = x_minus\n                            fitness[i] = f_minus\n                            if f_minus < self.f_opt:\n                                self.f_opt = f_minus\n                                self.x_opt = x_minus\n                        \n                        if evals >= self.budget:\n                          return self.f_opt, self.x_opt #break early if budget exceeded\n\n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "59b2a211-d070-4f76-a6af-163ca18d6c1e", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a modified self-adaptive differential evolution with a local search operator, adaptively adjusting mutation and crossover rates based on the success of previous iterations, and applying a local search to further refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        self.success_F = []\n        self.success_CR = []\n        self.archive_F = []\n        self.archive_CR = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_ls = np.copy(trial)\n                    for j in range(self.dim):\n                        trial_ls[j] += np.random.uniform(-self.local_search_radius, self.local_search_radius)\n                    trial_ls = np.clip(trial_ls, lb, ub)\n                else:\n                    trial_ls = trial\n\n                # Selection\n                f_trial = func(trial_ls)\n                evals += 1\n                \n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    \n                    population[i] = trial_ls\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_ls\n\n            #Adapt F and CR\n            if self.success_F:\n                self.archive_F.extend(self.success_F)\n                self.archive_CR.extend(self.success_CR)\n                \n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                \n                self.success_F = []\n                self.success_CR = []\n            else:\n                self.F = 0.5 + 0.4 * np.random.rand()\n                self.CR = 0.1 + 0.9 * np.random.rand()\n                \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n                \n\n        return self.f_opt, self.x_opt", "objective": -0.76443, "other_inf": null}
{"id": "74cefdb3-c241-4cc7-b1b0-a6db5a1d4378", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm employs a covariance matrix adaptation evolution strategy (CMA-ES) with a small population size and restarts, aiming to quickly adapt to the problem's structure and escape local optima.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=4, sigma0=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        evals = 0\n\n        for _ in range(self.restarts):\n            mean = np.random.uniform(lb, ub, size=self.dim)\n            C = np.eye(self.dim)\n            sigma = self.sigma0\n\n            while evals < self.budget:\n                # Sample population\n                z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n                population = mean + sigma * z\n                population = np.clip(population, lb, ub)\n\n                # Evaluate population\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n\n                # Sort population\n                idx = np.argsort(fitness)\n                fitness = fitness[idx]\n                population = population[idx]\n\n                # Update best solution\n                if fitness[0] < self.f_opt:\n                    self.f_opt = fitness[0]\n                    self.x_opt = population[0]\n\n                # Update CMA-ES parameters (simplified)\n                mean = population[0]  # elitist selection\n                C = np.cov(population.T)  # update covariance matrix\n                sigma *= np.exp(0.5 * (fitness[0] - fitness[-1]) / self.dim)  # adapt step size\n\n                if evals >= self.budget:\n                    break\n            \n        return self.f_opt, self.x_opt", "objective": -0.1029, "other_inf": null}
{"id": "dfc98437-2789-4ecb-879f-947c2d786cf3", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a modified differential evolution strategy with a smaller population size, increased exploration by dynamically adjusting the mutation factor (F), and a simplified crossover strategy to maintain diversity and efficiently explore the search space.", "code": "import numpy as np\n\nclass ModifiedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                #Dynamically adjust F\n                F_dynamic = self.F + 0.1 * np.random.randn()\n                F_dynamic = np.clip(F_dynamic, 0.1, 0.9)\n\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover - Simplified: Always perform crossover on one random dimension\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                trial[j_rand] = mutant[j_rand]\n\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "835c6ca4-f8ce-4cb3-b738-190cfe16e610", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a modified self-adaptive differential evolution strategy with a smaller population size, increased exploration through a higher mutation factor, and a reduced crossover rate to emphasize mutation, along with an adaptive population size adjustment based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=10, F=0.7, CR=0.3, stagnation_limit=300, pop_adjust_freq=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.pop_adjust_freq = pop_adjust_freq\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.5 * np.random.rand()\n            self.CR = 0.1 + 0.3 * np.random.rand()\n            \n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n              population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n              fitness = np.array([func(x) for x in population])\n              evals += self.pop_size\n              \n              best_idx = np.argmin(fitness)\n              self.f_opt = fitness[best_idx]\n              self.x_opt = population[best_idx]\n              self.stagnation_counter = 0 # Reset stagnation counter\n            \n            # Adaptive Population size\n            if evals % self.pop_adjust_freq == 0:\n                if self.f_opt == np.min(self.best_fitness_history):\n                    self.pop_size = max(5, int(self.pop_size / 2))\n                else:\n                    self.pop_size = min(50, int(self.pop_size * 1.2))\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 10:\n                self.best_fitness_history.pop(0)\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "89be4f8f-7f79-43b5-9acc-dc8eaa11dbc5", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm implements a covariance matrix adaptation evolution strategy (CMA-ES) with a budget-aware restart mechanism, adapting the step size and covariance matrix to efficiently explore the search space and restarting when stagnation is detected to improve exploration.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.restart_trigger = restart_trigger\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_step_size\n        C = np.eye(self.dim)\n        \n        evals = 0\n        restart = False\n\n        while evals < self.budget:\n            if restart:\n                mean = np.random.uniform(lb, ub, size=self.dim)\n                sigma = self.initial_step_size\n                C = np.eye(self.dim)\n                restart = False\n            \n            # Sample population\n            Z = np.random.randn(self.pop_size, self.dim)\n            X = mean + sigma * Z @ np.linalg.cholesky(C).T\n            X = np.clip(X, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X])\n            evals += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:self.mu], axis=0)\n\n            # Cumulation\n            ps = (mean - mean_old) / sigma\n            cs = np.linalg.norm(ps) / np.sqrt(1 - (1 - 0.33)**2) / np.sqrt(self.dim)\n            if cs > 0.7:\n                ps = np.zeros_like(ps)\n            \n            pc = (1 - 0.044) * ps + np.sqrt(0.044 * (2 - 0.044)) * (mean - mean_old) / sigma\n            \n            # Update covariance matrix\n            C = (1 - 0.044) * C + 0.044 / np.linalg.norm(pc)**2 * (np.outer(pc, pc) - C)\n            \n            # Update step size\n            sigma *= np.exp(0.2 * (np.linalg.norm(ps) / 1.414 - 1))\n            \n            # Check for stagnation and restart\n            if np.max(np.diag(C)) < self.restart_trigger:\n                restart = True\n            \n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "0c350a27-e3be-4c7f-89b3-28c424194dca", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "This algorithm utilizes a particle swarm optimization strategy with velocity clamping and dynamic inertia weight adjustment to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2, c2=2, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_ratio = v_max_ratio\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitness\n        pbest_positions = population.copy()\n        fitness = np.array([func(x) for x in population])\n        pbest_fitness = fitness.copy()\n        evals = self.pop_size\n        \n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n        \n        while evals < self.budget:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n            \n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (w * velocities[i]\n                                 + self.c1 * r1 * (pbest_positions[i] - population[i])\n                                 + self.c2 * r2 * (self.x_opt - population[i]))\n                \n                # Velocity clamping\n                v_max = abs(ub - lb) * self.v_max_ratio\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                # Update positions\n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = population[i].copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n            \n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.45635, "other_inf": null}
{"id": "a6dc1045-e1b9-4291-b25b-62d7099ba4e1", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to guide the search, iteratively selecting points with high expected improvement and updating the model.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogate:\n    def __init__(self, budget=10000, dim=10, lb=-5.0, ub=5.0, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.n_initial_samples = n_initial_samples\n        self.x_samples = []\n        self.y_samples = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        \n        if sigma == 0:\n           return 0\n        \n        improvement = (self.f_opt - mu) / sigma\n        return - (improvement * norm.cdf(improvement) + norm.pdf(improvement))\n\n    def suggest_next_point(self):\n        x_start = np.random.uniform(self.lb, self.ub, size=self.dim)\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(self.acquisition_function, x_start, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        # Initial sampling\n        for i in range(self.n_initial_samples):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            y = func(x)\n            self.x_samples.append(x)\n            self.y_samples.append(y)\n            self.budget -= 1\n\n            if y < self.f_opt:\n                self.f_opt = y\n                self.x_opt = x.copy()\n\n            if self.budget <= 0:\n                return self.f_opt, self.x_opt\n\n        self.x_samples = np.array(self.x_samples)\n        self.y_samples = np.array(self.y_samples)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit GP model\n            self.gp.fit(self.x_samples, self.y_samples)\n\n            # Suggest next point\n            x_next = self.suggest_next_point()\n\n            # Evaluate function\n            y_next = func(x_next)\n            self.budget -= 1\n\n            # Update samples\n            self.x_samples = np.vstack((self.x_samples, x_next))\n            self.y_samples = np.append(self.y_samples, y_next)\n\n            # Update best\n            if y_next < self.f_opt:\n                self.f_opt = y_next\n                self.x_opt = x_next.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "de359894-4641-4872-afd8-0ad2a07cc67b", "parents": ["fc7769a5-4de0-49ba-b544-613dddadd800", "7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm employs a Gaussian Process surrogate model to guide the search, balancing exploration and exploitation by sampling from the GP's posterior distribution, with an acquisition function that favors regions of high uncertainty and potential improvement.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogateOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel=None, acquisition_function='EI'):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.kernel = kernel if kernel is not None else C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.acquisition_function = acquisition_function\n\n    def expected_improvement(self, x, gp, f_best, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        sigma = np.maximum(sigma, 1e-9) \n        imp = f_best - mu - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def upper_confidence_bound(self, x, gp, kappa=1.96):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu + kappa * sigma\n    \n    def thompson_sampling(self, x, gp):\n        return gp.sample_y(x.reshape(1, -1), n_samples=1)[0][0]\n    \n    def acquisition(self, x, gp, f_best):\n        if self.acquisition_function == 'EI':\n            return self.expected_improvement(x, gp, f_best)\n        elif self.acquisition_function == 'UCB':\n            return self.upper_confidence_bound(x, gp)\n        elif self.acquisition_function == 'TS':\n            return self.thompson_sampling(x, gp)\n        else:\n            raise ValueError(\"Invalid acquisition function.\")\n\n    def optimize_acquisition(self, gp, f_best, lb, ub):\n        def neg_acquisition(x):\n            return -self.acquisition(x, gp, f_best)\n\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n        bounds = [(lb, ub)] * self.dim\n        result = minimize(neg_acquisition, x0, method='L-BFGS-B', bounds=bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial sampling\n        X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial_samples\n        \n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        # Gaussian process regression\n        gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n        while evals < self.budget:\n            gp.fit(X, y)\n            \n            # Find next point to evaluate by maximizing the acquisition function\n            x_next = self.optimize_acquisition(gp, self.f_opt, lb, ub)\n            \n            # Evaluate the objective function\n            f_next = func(x_next)\n            evals += 1\n\n            # Add the new data to the training set\n            X = np.vstack((X, x_next))\n            y = np.append(y, f_next)\n            \n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "3c0d667c-757d-4a3b-be69-9c17d2a3aa75", "parents": ["fc7769a5-4de0-49ba-b544-613dddadd800", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "This algorithm employs a Gaussian process surrogate model to guide the search, iteratively selecting points based on an acquisition function that balances exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogateOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, acq_func=\"EI\"):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.kernel = kernel if kernel is not None else ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.acq_func = acq_func\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def acquisition(self, x, gp, bounds):\n        x = x.reshape(-1, self.dim)\n        mu, sigma = gp.predict(x, return_std=True)\n        if self.acq_func == \"EI\":\n            imp = mu - self.f_opt\n            Z = imp / sigma\n            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n            return -ei\n        elif self.acq_func == \"UCB\":\n            kappa = 2.0\n            return -(mu + kappa * sigma)\n        else:\n            raise ValueError(\"Acquisition function not supported.\")\n\n    def propose_location(self, gp, bounds, n_restarts=25):\n        lb = bounds.lb\n        ub = bounds.ub\n        x_start = np.random.uniform(lb, ub, size=(n_restarts, self.dim))\n        min_val = np.inf\n        min_x = None\n        for x0 in x_start:\n            res = minimize(self.acquisition, x0, bounds=bounds, args=(gp, bounds), method=\"L-BFGS-B\")\n            if res.fun < min_val:\n                min_val = res.fun[0]\n                min_x = res.x\n        return min_x\n\n    def __call__(self, func):\n        X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial\n        \n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n        while evals < self.budget:\n            gp.fit(X, y)\n            x_next = self.propose_location(gp, func.bounds)\n            f_next = func(x_next)\n            evals += 1\n            \n            X = np.vstack((X, x_next))\n            y = np.append(y, f_next)\n            \n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9e1c029a-5001-4005-b2fb-73f64713eac7", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "```", "code": "import numpy as np\n\nclass SimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    # Description: A simulated annealing algorithm that probabilistically accepts worse solutions to escape local optima, with the acceptance probability decreasing as the temperature cools down.\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        current_x = np.random.uniform(lb, ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        temp = self.initial_temp\n\n        while self.budget > 0:\n            new_x = current_x + np.random.normal(0, temp/100, size=self.dim)\n            new_x = np.clip(new_x, lb, ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            \n            if new_f < current_f:\n                current_x = new_x\n                current_f = new_f\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n            else:\n                acceptance_probability = np.exp((current_f - new_f) / temp)\n                if np.random.rand() < acceptance_probability:\n                    current_x = new_x\n                    current_f = new_f\n\n            temp *= self.cooling_rate\n            if self.budget <=0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.12248, "other_inf": null}
{"id": "e671c2b8-ebca-4269-81a7-bc87ecfb34d5", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm uses a population-based approach, where each individual represents a solution, and evolves through selection, crossover, and mutation, inspired by genetic algorithms, while incorporating a gradient-based local search to refine promising solutions.", "code": "import numpy as np\n\nclass GradientEnhancedGeneticAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            new_population = []\n            for i in range(self.pop_size):\n                # Selection (Tournament Selection)\n                idx1 = np.random.randint(self.pop_size)\n                idx2 = np.random.randint(self.pop_size)\n                if fitness[idx1] < fitness[idx2]:\n                    parent1 = population[idx1]\n                else:\n                    parent1 = population[idx2]\n                \n                idx1 = np.random.randint(self.pop_size)\n                idx2 = np.random.randint(self.pop_size)\n                if fitness[idx1] < fitness[idx2]:\n                    parent2 = population[idx1]\n                else:\n                    parent2 = population[idx2]\n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        child[j] += np.random.uniform(-0.1, 0.1)  # Small perturbation\n                        child[j] = np.clip(child[j], lb, ub)\n\n                new_population.append(child)\n\n            new_population = np.array(new_population)\n\n            # Local Search (Gradient Descent) on best individual\n            best_idx = np.argmin(fitness)\n            x_ls = np.copy(population[best_idx])\n            \n            for _ in range(self.local_search_iterations):\n                # Estimate gradient (simplified finite difference)\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = np.copy(x_ls)\n                    x_minus = np.copy(x_ls)\n                    delta = 0.001  # Small step for gradient estimation\n                    x_plus[j] += delta\n                    x_minus[j] -= delta\n                    x_plus[j] = np.clip(x_plus[j], lb, ub)\n                    x_minus[j] = np.clip(x_minus[j], lb, ub)\n                    gradient[j] = (func(x_plus) - func(x_minus)) / (2 * delta)\n                    evals += 2 #account for function evaluations\n                    if evals >= self.budget:\n                        break\n\n                # Update position (gradient descent)\n                x_ls -= 0.01 * gradient\n                x_ls = np.clip(x_ls, lb, ub)\n                if evals >= self.budget:\n                    break\n                \n            f_ls = func(x_ls)\n            evals += 1\n\n            # Replace worst individual with locally optimized solution\n            worst_idx = np.argmax(fitness)\n            new_population[worst_idx] = x_ls\n            fitness_ls = f_ls #func(x_ls) #evals already updated\n\n            fitness_new = np.array([func(x) if i!=worst_idx else fitness_ls for i, x in enumerate(new_population)])\n            evals += (self.pop_size -1) if (evals < self.budget) else 0 \n            \n            population = new_population\n            fitness = fitness_new\n                \n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                \n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "76effbd0-b385-44b0-be96-0dc1d2a83b7b", "parents": ["fc7769a5-4de0-49ba-b544-613dddadd800", "fc7769a5-4de0-49ba-b544-613dddadd800"], "algorithm": "Simulated Annealing with adaptive temperature and step size control for efficient exploration and exploitation within the budget.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Generate a neighbor solution\n            x_new = x + np.random.normal(0, step_size, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            \n            f_new = func(x_new)\n            evals += 1\n            \n            # Acceptance probability\n            delta_e = f_new - f\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adaptive temperature and step size\n            temp *= self.cooling_rate\n            step_size *= 0.99  # Gradual step size reduction\n\n\n        return self.f_opt, self.x_opt", "objective": -0.31498, "other_inf": null}
{"id": "df200ac4-220e-4587-8ea1-a3870d522052", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "```", "code": "import numpy as np\n\nclass HarmonySearch:\n    def __init__(self, budget=10000, dim=10, HMS=20, HMCR=0.9, PAR=0.3, bw=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.HMS = HMS  # Harmony Memory Size\n        self.HMCR = HMCR  # Harmony Memory Consideration Rate\n        self.PAR = PAR  # Pitch Adjusting Rate\n        self.bw = bw  # Bandwidth\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize Harmony Memory\n        HM = np.random.uniform(lb, ub, size=(self.HMS, self.dim))\n        HM_fitness = np.array([func(x) for x in HM])\n        self.budget -= self.HMS\n\n        # Find global best\n        best_index = np.argmin(HM_fitness)\n        self.f_opt = HM_fitness[best_index]\n        self.x_opt = HM[best_index].copy()\n\n        while self.budget > 0:\n            # Improvise a new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.HMCR:\n                    # Memory consideration\n                    new_harmony[i] = HM[np.random.randint(self.HMS), i]\n                    # Pitch adjustment\n                    if np.random.rand() < self.PAR:\n                        new_harmony[i] += np.random.uniform(-self.bw, self.bw)\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(lb, ub)\n                \n                new_harmony[i] = np.clip(new_harmony[i], lb, ub)\n            \n            # Evaluate new harmony\n            new_fitness = func(new_harmony)\n            self.budget -= 1\n            \n            # Update Harmony Memory\n            if new_fitness < np.max(HM_fitness):\n                worst_index = np.argmax(HM_fitness)\n                HM[worst_index] = new_harmony\n                HM_fitness[worst_index] = new_fitness\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_harmony.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```\n\n# Description: This Harmony Search algorithm mimics the improvisation process of musicians, iteratively refining solutions by considering existing harmonies, adjusting pitches, and introducing randomness to discover better combinations within the search space.\n# Code: \n```python\nimport numpy as np\n\nclass HarmonySearch:\n    def __init__(self, budget=10000, dim=10, HMS=20, HMCR=0.9, PAR=0.3, bw=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.HMS = HMS  # Harmony Memory Size\n        self.HMCR = HMCR  # Harmony Memory Consideration Rate\n        self.PAR = PAR  # Pitch Adjusting Rate\n        self.bw = bw  # Bandwidth\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize Harmony Memory\n        HM = np.random.uniform(lb, ub, size=(self.HMS, self.dim))\n        HM_fitness = np.array([func(x) for x in HM])\n        self.budget -= self.HMS\n\n        # Find global best\n        best_index = np.argmin(HM_fitness)\n        self.f_opt = HM_fitness[best_index]\n        self.x_opt = HM[best_index].copy()\n\n        while self.budget > 0:\n            # Improvise a new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.HMCR:\n                    # Memory consideration\n                    new_harmony[i] = HM[np.random.randint(self.HMS), i]\n                    # Pitch adjustment\n                    if np.random.rand() < self.PAR:\n                        new_harmony[i] += np.random.uniform(-self.bw, self.bw)\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(lb, ub)\n                \n                new_harmony[i] = np.clip(new_harmony[i], lb, ub)\n            \n            # Evaluate new harmony\n            new_fitness = func(new_harmony)\n            self.budget -= 1\n            \n            # Update Harmony Memory\n            if new_fitness < np.max(HM_fitness):\n                worst_index = np.argmax(HM_fitness)\n                HM[worst_index] = new_harmony\n                HM_fitness[worst_index] = new_fitness\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_harmony.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "63645c5f-d60b-4daf-9bb5-4986ee5ad9dd", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "This algorithm uses a modified differential evolution with a shrinking population size and adaptive parameters to intensify the search in promising regions.", "code": "import numpy as np\n\nclass ShrinkingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, shrink_factor=0.9, min_pop_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.shrink_factor = shrink_factor\n        self.min_pop_size = min_pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget and self.pop_size > self.min_pop_size:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n\n            # Shrink population\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices[:int(self.pop_size * self.shrink_factor)]]\n            fitness = fitness[sorted_indices[:int(self.pop_size * self.shrink_factor)]]\n            self.pop_size = len(population)\n            if self.pop_size > 0:\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n            \n        # Final Search with small population if budget remains\n        while evals < self.budget:\n            if self.pop_size == 0:\n                population = np.random.uniform(lb, ub, size=(self.min_pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.min_pop_size\n                self.pop_size = self.min_pop_size\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            else:\n                # Mutation\n                i = 0\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) >= 3:\n                  a, b, c = np.random.choice(idxs, 3, replace=False)\n                  mutant = population[a] + self.F * (population[b] - population[c])\n                  mutant = np.clip(mutant, lb, ub)\n\n                  # Crossover\n                  trial = np.copy(population[i])\n                  j_rand = np.random.randint(self.dim)\n                  for j in range(self.dim):\n                      if np.random.rand() < self.CR or j == j_rand:\n                          trial[j] = mutant[j]\n\n                  # Selection\n                  f_trial = func(trial)\n                  evals += 1\n\n                  if f_trial < fitness[i]:\n                      population[i] = trial\n                      fitness[i] = f_trial\n\n                      # Update best solution\n                      if f_trial < self.f_opt:\n                          self.f_opt = f_trial\n                          self.x_opt = trial\n                else:\n                    x = np.random.uniform(lb, ub)\n                    f = func(x)\n                    evals += 1\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n        return self.f_opt, self.x_opt", "objective": -0.35811, "other_inf": null}
{"id": "ac44020a-4c65-49f1-bf63-52b089ce47d3", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm employs a self-adaptive Differential Evolution with a Cauchy mutation operator and a ranking-based selection mechanism to enhance exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRanking:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                cauchy_sample = self.F * np.random.standard_cauchy(size=self.dim)\n                mutant = population[i] + cauchy_sample * (population[ranked_indices[0]] - population[ranked_indices[-1]]) #Cauchy mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection (ranking-based)\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            #Adapt F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n                \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.35779, "other_inf": null}
{"id": "96365403-39a6-4fb8-9074-0035cfe19da6", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: An adaptive Differential Evolution strategy that uses a ranking-based selection of parents and adjusts the mutation factor based on the rank of the current individual.\n# Code:\n```", "code": "import numpy as np\n\nclass RankAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f = initial_f\n        self.cr = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Rank the population\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Select parents based on rank: Better ranked individuals have higher probability\n                probabilities = (ranked_indices.size - np.arange(ranked_indices.size)) / np.sum(np.arange(1, ranked_indices.size + 1))\n                parent_indices = np.random.choice(ranked_indices, 3, replace=False, p=probabilities)\n                x1, x2, x3 = population[parent_indices]\n\n                # Adjust mutation factor based on rank\n                rank = np.where(ranked_indices == i)[0][0]\n                mutation_factor = self.f * (1.0 - rank / self.pop_size) # Smaller f for better ranks\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + mutation_factor * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                    \n                if self.budget <= 0:\n                    break\n            \n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "objective": -0.38584, "other_inf": null}
{"id": "c22a1ed8-a7b2-47d7-92c5-ff50c4686c90", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: An adaptive Differential Evolution algorithm with a modified mutation strategy that incorporates information from the best solution found so far and adjusts the scaling factor dynamically based on success.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDEBest1:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.archive_factor = 2.0 # Size of the archive relative to pop_size\n        self.archive = []\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation - DE/best/1 strategy with adaptive F\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = population[idxs]\n\n                # Use best solution so far in mutation\n                trial_vector = self.x_opt + self.f * (x1 - x2)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_population[i][j] = trial_vector[j]\n                    else:\n                        new_population[i][j] = population[i][j]\n\n                new_population[i] = np.clip(new_population[i], self.lb, self.ub)\n\n                f = func(new_population[i])\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_population[i].copy()\n                    \n                    self.archive.append(population[i].copy())\n                    if len(self.archive) > self.archive_factor * self.pop_size:\n                        self.archive.pop(0)  # Maintain archive size\n\n                    self.success_cr.append(self.cr)\n                    self.success_f.append(self.f)\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Update CR and F\n            if self.success_cr and self.success_f:\n                cr_mean = np.mean(self.success_cr)\n                f_mean = np.mean(self.success_f)\n\n                self.cr = 0.9 * self.cr + 0.1 * cr_mean  # Exponential smoothing\n                self.f = 0.9 * self.f + 0.1 * f_mean\n                \n                self.success_cr = []\n                self.success_f = []\n\n            else:\n                # No successful updates, increase exploration\n                self.cr = min(1.0, self.cr + 0.1)\n                self.f = min(1.0, self.f + 0.1)\n\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.f = np.clip(self.f, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.62736, "other_inf": null}
{"id": "f6657dc1-f1d9-43ef-af51-5b19c40a8e5c", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm employs a covariance matrix adaptation evolution strategy (CMA-ES) with a budget-aware step size adaptation scheme to efficiently explore the search space.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cumcov = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cumsigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.dampsigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cumsigma\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_step_size\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        B = np.eye(self.dim)\n        D = np.ones(self.dim)\n        C = B @ np.diag(D**2) @ B.T\n        invsqrtC = B @ np.diag(D**-1) @ B.T\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.randn(self.dim, self.pop_size)\n            x = mean[:, None] + sigma * (B @ (D[:, None] * z))\n            x = np.clip(x, lb, ub)\n            fitness = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n            \n            arindex = np.argsort(fitness)\n            xsorted = x[:, arindex]\n            fitness_sorted = fitness[arindex]\n\n            xmean = np.sum(xsorted[:, :self.mu] * self.weights[None, :], axis=1)\n            \n            if fitness_sorted[0] < self.f_opt:\n                self.f_opt = fitness_sorted[0]\n                self.x_opt = xsorted[:, 0]\n            \n            y = invsqrtC @ (xmean - mean)\n            ps = (1 - self.cumsigma) * ps + np.sqrt(self.cumsigma * (2 - self.cumsigma) * self.mueff) * y\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cumsigma)**(2 * evals / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            pc = (1 - self.cumcov) * pc + hsig * np.sqrt(self.cumcov * (2 - self.cumcov) * self.mueff) * (xmean - mean)\n            mean = xmean\n\n            C = (1 - self.cumcov) * C + self.cumcov * (pc[:, None] @ pc[None, :] + (1 - hsig) * self.cumcov * (2 - self.cumcov) * C) + self.cumcov * np.sum(self.weights[None, :] * (xsorted[:, :self.mu] - mean[:, None]) @ (xsorted[:, :self.mu] - mean[:, None]).T, axis=1)\n            \n            try:\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(np.maximum(D, 1e-16))\n                invsqrtC = B @ np.diag(D**-1) @ B.T\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n                B = np.eye(self.dim)\n                D = np.ones(self.dim)\n                invsqrtC = np.eye(self.dim)\n            \n            sigma *= np.exp((self.cumsigma / self.dampsigma) * (np.linalg.norm(ps) / self.chiN - 1))\n            sigma = min(sigma, (ub - lb) / 2)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fa8c5f7e-cf19-4a66-97aa-13631edc64f5", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm implements a self-adaptive differential evolution strategy with a restart mechanism and a dynamically adjusted population size to escape local optima and explore the search space more effectively.", "code": "import numpy as np\n\nclass AdaptiveDEwithRestart:\n    def __init__(self, budget=10000, dim=10, pop_size_init=20, F=0.5, CR=0.7, restart_prob=0.05, pop_size_adapt_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.pop_size = pop_size_init\n        self.evals = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.evals += 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Restart Mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n\n            # Population Size Adaptation\n            if self.evals % self.pop_size_adapt_freq == 0:\n                if np.random.rand() < 0.5:\n                    self.pop_size = int(self.pop_size * 1.1)  # Increase population size\n                else:\n                    self.pop_size = int(self.pop_size * 0.9)  # Decrease population size\n                self.pop_size = max(10, min(self.pop_size, 50))\n                new_population = np.random.uniform(lb, ub, size=(self.pop_size - population.shape[0], self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.evals += new_population.shape[0]\n\n                population = np.vstack((population, new_population))\n                fitness = np.concatenate((fitness, new_fitness))\n\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "10db8315-78cf-42cf-8134-2c2a9efd187d", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm implements a self-adjusting covariance matrix adaptation evolution strategy (CMA-ES) that dynamically adapts the search distribution based on successful steps, focusing on exploration in promising areas.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.C = np.eye(dim)\n        self.mu = None\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.pop_size + 2) / (dim + self.pop_size + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.pop_size - 1)/(dim + 1)) - 1) + self.c_sigma\n        self.c_c = 4 / (dim + 4)\n        self.c_mu = 4\n        self.c_mu /= (dim + 10)\n        self.weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mueff)\n        self.c_mu_adapt = min(1 - self.c_1, self.c_mu * (self.mueff - 2 + 1/self.mueff) / ((dim + 2.0)**2 + self.mueff))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        self.mu = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.sigma0\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mu + sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n            # Clipping\n            x = np.clip(x, lb, ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mu_old = self.mu.copy()\n            self.mu = np.sum(x[:self.pop_size] * self.weights[:, np.newaxis], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * np.linalg.solve(np.linalg.cholesky(self.C), (self.mu - mu_old)) / sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (evals/self.pop_size))) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (self.mu - mu_old) / sigma\n\n            # Update covariance matrix\n            artmp = (x[:self.pop_size] - mu_old) / sigma\n            self.C = (1 - self.c_1 - self.c_mu_adapt) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.c_c * (2 - self.c_c) * self.C) + self.c_mu_adapt * np.sum(self.weights[:, np.newaxis, np.newaxis] * artmp[:, :, np.newaxis] * artmp[:, np.newaxis, :], axis=0)\n\n            # Update step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            \n        return self.f_opt, self.x_opt", "objective": -0.57563, "other_inf": null}
{"id": "baa8315f-572f-4819-b813-7b5d99e73448", "parents": ["fc7769a5-4de0-49ba-b544-613dddadd800"], "algorithm": "This algorithm implements a self-adaptive differential evolution with a Cauchy mutation operator and a rank-based selection mechanism, aiming to enhance exploration and convergence speed.", "code": "import numpy as np\n\nclass CauchyRankDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            \n            ranks = np.argsort(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) < 3:\n                    break\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                cauchy_mutation = population[a] + self.F * (population[b] - population[c]) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(cauchy_mutation, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection (Rank-based)\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive F and CR based on ranks\n            self.F = 0.5 + 0.3 * np.random.rand() * (1 - ranks[i]/self.pop_size) # F decreases for better ranked individuals\n            self.CR = 0.4 + 0.5 * np.random.rand() * (ranks[i]/self.pop_size)   # CR increases for better ranked individuals\n\n        return self.f_opt, self.x_opt", "objective": -0.46779, "other_inf": null}
{"id": "c5570449-4d6a-4429-96c7-aee70b7730ae", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "fc7769a5-4de0-49ba-b544-613dddadd800"], "algorithm": "This algorithm employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation through an acquisition function based on the predicted improvement.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogateOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel=None):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        if kernel is None:\n            self.kernel = C(1.0, constant_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=9)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial sampling\n        self.X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        evals = self.n_initial_samples\n\n        best_idx = np.argmin(self.y)\n        self.f_opt = self.y[best_idx]\n        self.x_opt = self.X[best_idx]\n        \n        while evals < self.budget:\n            self.gp.fit(self.X, self.y)\n\n            # Find the next point to evaluate by maximizing the acquisition function\n            x_next = None\n            best_acq = np.inf\n            \n            for _ in range(100): # Try 100 random points\n                x_candidate = np.random.uniform(lb, ub, size=self.dim)\n                acq_value = self.acquisition_function(x_candidate, self.gp)\n\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    x_next = x_candidate\n\n            f_next = func(x_next)\n            evals += 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c53130e1-1a75-42c2-aa06-a922a99bad01", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "A population-based algorithm using a combination of Gaussian mutation and Cauchy mutation to balance exploration and exploitation, adaptively adjusting mutation rates based on success.", "code": "import numpy as np\n\nclass AdaptiveMutationOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.mutation_rate = initial_mutation_rate\n        self.success_history = []  # Store successful mutation rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation: Gaussian or Cauchy\n                if np.random.rand() < 0.5:  # 50% chance of Gaussian mutation\n                    mutation = np.random.normal(0, self.mutation_rate, size=self.dim)\n                else:  # 50% chance of Cauchy mutation\n                    mutation = np.random.standard_cauchy(size=self.dim) * self.mutation_rate\n                    \n                trial_vector = population[i] + mutation\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        self.success_history.append(self.mutation_rate) # Store the mutation rate when successful\n\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adaptive mutation rate update\n            if self.success_history:\n                self.mutation_rate = np.mean(self.success_history)\n                self.success_history = [] # Reset history\n            else:\n                # If no improvements, increase the mutation rate to explore more\n                self.mutation_rate *= 1.1\n\n            self.mutation_rate = np.clip(self.mutation_rate, 0.001, 1.0) # Constrain the mutation rate\n        return self.f_opt, self.x_opt", "objective": -0.33263, "other_inf": null}
{"id": "0fbe14b3-3968-4ae2-97b1-e3328171ab9a", "parents": ["7155db6b-00e2-49a9-badf-a26abfeaf788", "7155db6b-00e2-49a9-badf-a26abfeaf788"], "algorithm": "# Description: This algorithm employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by predicting the objective function and its uncertainty.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial=10, xi=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.xi = xi\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n    def acquisition(self, X, gp, y_max, xi):\n        mu, sigma = gp.predict(X, return_std=True)\n        sigma = np.maximum(sigma, 1e-9)\n        imp = mu - y_max - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gp, y_max, bounds, xi, n_restarts=25):\n        def min_obj(X):\n            return -self.acquisition(X.reshape(-1, self.dim), gp, y_max, xi)\n\n        best_min = np.inf\n        best_x = None\n\n        for _ in range(n_restarts):\n            x0 = np.random.uniform(bounds.lb, bounds.ub, size=self.dim)\n            res = minimize(min_obj, x0, method='L-BFGS-B', bounds=bounds)\n            if res.fun < best_min:\n                best_min = res.fun\n                best_x = res.x\n\n        return best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        bounds = func.bounds\n\n        # Initial sampling\n        X_init = np.random.uniform(lb, ub, size=(self.n_initial, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        evals = self.n_initial\n\n        self.gp.fit(X_init, y_init)\n        y_max = y_init.min()\n        self.f_opt = y_max\n        self.x_opt = X_init[np.argmin(y_init)]\n\n        while evals < self.budget:\n            # Propose new location\n            x_new = self.propose_location(self.gp, y_max, bounds, self.xi)\n\n            # Evaluate function\n            f_new = func(x_new)\n            evals += 1\n\n            # Update GP\n            X_init = np.vstack((X_init, x_new))\n            y_init = np.append(y_init, f_new)\n            self.gp.fit(X_init, y_init)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                y_max = f_new # Update y_max\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7feb7138-6574-4ca9-9747-fee59a0998e8", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "A population-based algorithm that uses a velocity-based update rule inspired by Particle Swarm Optimization, combined with a restart strategy based on stagnation detection, and adaptive parameters to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/50, abs(ub-lb)/50, size=(self.pop_size, self.dim)) #Initialize small velocities\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        \n        global_best_idx = np.argmin(fitness)\n        self.f_opt = fitness[global_best_idx]\n        self.x_opt = population[global_best_idx]\n        global_best_position = np.copy(self.x_opt)\n\n        stagnation_counter = 0\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = np.copy(population[i])\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i]\n                        global_best_position = np.copy(self.x_opt)\n                        stagnation_counter = 0 #Reset stagnation counter\n            \n            stagnation_counter += self.pop_size\n            \n            # Stagnation Check and Restart\n            if stagnation_counter > self.stagnation_threshold:\n                # Restart a portion of the population\n                restart_indices = np.random.choice(self.pop_size, size=self.pop_size // 4, replace=False)\n                population[restart_indices] = np.random.uniform(lb, ub, size=(self.pop_size // 4, self.dim))\n                velocities[restart_indices] = np.random.uniform(-abs(ub-lb)/50, abs(ub-lb)/50, size=(self.pop_size // 4, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                evals += self.pop_size // 4\n                \n                #Update personal bests of the restarted population\n                for i in restart_indices:\n                    personal_best_positions[i] = np.copy(population[i])\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n                        global_best_position = np.copy(self.x_opt)\n                \n                stagnation_counter = 0\n\n            # Adaptive Inertia (Linear Decrease)\n            self.inertia = 0.7 - (0.7 - 0.2) * (evals / self.budget)\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "681b0934-e8e0-463a-9a32-32613a1ea6d5", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm employs a population-based approach with stochastic gradient estimation, iteratively updating each individual's position based on noisy gradient information obtained from evaluating nearby points, mimicking a particle swarm optimization influenced by gradient descent.", "code": "import numpy as np\n\nclass StochasticGradientSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, num_neighbors=5, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.num_neighbors = num_neighbors\n        self.momentum = momentum\n        self.velocities = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        if self.velocities is None:\n            self.velocities = np.zeros_like(population)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Estimate Gradient\n                grad_estimate = np.zeros(self.dim)\n                for _ in range(self.num_neighbors):\n                    delta = np.random.normal(0, self.step_size, self.dim)\n                    x_neighbor = np.clip(population[i] + delta, lb, ub)\n                    f_neighbor = func(x_neighbor)\n                    evals += 1\n\n                    grad_estimate += (f_neighbor - fitness[i]) * delta\n\n                    if f_neighbor < self.f_opt:\n                        self.f_opt = f_neighbor\n                        self.x_opt = x_neighbor\n\n                    if evals >= self.budget:\n                        return self.f_opt, self.x_opt\n\n                grad_estimate /= self.num_neighbors * self.step_size**2  #approximation of the gradient\n\n\n                # Update Velocity and Position\n                self.velocities[i] = self.momentum * self.velocities[i] - self.step_size * grad_estimate # Gradient Descent with Momentum\n                new_position = population[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                evals += 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n                if evals >= self.budget:\n                    return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt", "objective": -0.29436, "other_inf": null}
{"id": "c65e61ad-1859-4e67-a937-d2a4c67dcc8f", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "This algorithm combines the strengths of particle swarm optimization (PSO) and covariance matrix adaptation evolution strategy (CMA-ES) by using PSO to explore the search space and CMA-ES to exploit promising regions identified by PSO.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, pso_inertia=0.7, pso_cognitive=1.4, pso_social=1.4, cmaes_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.pso_inertia = pso_inertia\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n        self.cmaes_sigma = cmaes_sigma\n\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.cmaes_mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.cmaes_covariance = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initialize PSO\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.particles[i])\n            self.budget -= 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.particles[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            # PSO update\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.pso_inertia * self.velocities[i] +\n                                      self.pso_cognitive * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.pso_social * r2 * (self.global_best_position - self.particles[i]))\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n            # Evaluate PSO particles\n            for i in range(self.pop_size):\n                f = func(self.particles[i])\n                self.budget -= 1\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.particles[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n            # CMA-ES update (every few iterations)\n            if self.budget % (self.pop_size * 5) == 0:\n                # Sample new solutions from CMA-ES\n                new_solutions = np.random.multivariate_normal(self.cmaes_mean, self.cmaes_sigma * self.cmaes_covariance, size=self.pop_size)\n                new_solutions = np.clip(new_solutions, self.lb, self.ub)\n                new_fitness = np.zeros(self.pop_size)\n\n                for i in range(self.pop_size):\n                    new_fitness[i] = func(new_solutions[i])\n                    self.budget -= 1\n                    if new_fitness[i] < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness[i]\n                        self.global_best_position = new_solutions[i].copy()\n                        self.f_opt = self.global_best_fitness\n                        self.x_opt = self.global_best_position\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                # Update CMA-ES parameters\n                best_index = np.argmin(new_fitness)\n                self.cmaes_mean = new_solutions[best_index]\n                # Simple covariance update (can be replaced with more sophisticated methods)\n                self.cmaes_covariance = np.cov(new_solutions.T)\n                if np.linalg.det(self.cmaes_covariance) <= 0:\n                    self.cmaes_covariance = np.eye(self.dim)\n        return self.f_opt, self.x_opt", "objective": -0.52492, "other_inf": null}
{"id": "7b03ff2c-bdd6-441b-9ec3-11bf4e02ce0f", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "", "code": "import numpy as np\n\nclass ReinforcementLearningEA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, gamma=0.9, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.gamma = gamma\n        self.exploration_rate = exploration_rate\n        self.Q = {}  # Q-table: Q[(state, action)] = value\n\n    def _get_state(self, population):\n        # State: average pairwise distance + best fitness\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        avg_distance = np.mean(distances) if distances else 0.0\n        return (round(avg_distance, 2), round(self.f_opt, 5))\n\n    def _get_reward(self, old_fitness, new_fitness, population, old_population):\n        fitness_improvement = np.mean(old_fitness) - np.mean(new_fitness)\n        diversity_reward = self._calculate_diversity_reward(population, old_population)\n        return fitness_improvement + 0.1 * diversity_reward\n\n    def _calculate_diversity_reward(self, population, old_population):\n        diversity_improvement = self._calculate_population_diversity(population) - self._calculate_population_diversity(old_population)\n        return diversity_improvement\n        \n    def _calculate_population_diversity(self, population):\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        avg_distance = np.mean(distances) if distances else 0.0\n        return avg_distance\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            old_population = population.copy()\n            old_fitness = fitness.copy()\n            state = self._get_state(population)\n\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Epsilon-greedy action selection\n                if np.random.rand() < self.exploration_rate:\n                    action = np.random.choice(['mutation', 'crossover', 'random_restart'])\n                else:\n                    # Choose action with highest Q-value for the current state\n                    q_values = [self.Q.get((state, a), 0) for a in ['mutation', 'crossover', 'random_restart']]\n                    action = ['mutation', 'crossover', 'random_restart'][np.argmax(q_values)]\n\n                if action == 'mutation':\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + 0.5 * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n                    trial = mutant\n\n                elif action == 'crossover':\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    parent1, parent2 = population[idxs]\n                    alpha = np.random.rand(self.dim)\n                    trial = alpha * parent1 + (1 - alpha) * parent2\n                    trial = np.clip(trial, lb, ub)\n\n                elif action == 'random_restart':\n                    trial = np.random.uniform(lb, ub)\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                \n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            reward = self._get_reward(old_fitness, fitness, population, old_population)\n            new_state = self._get_state(population)\n\n            # Update Q-table for each individual\n            for i in range(self.pop_size):\n                if np.array_equal(population[i], new_population[i]):\n                    continue # Individual did not change, no reward to propagate\n                q_values = [self.Q.get((state, a), 0) for a in ['mutation', 'crossover', 'random_restart']]\n                action = ['mutation', 'crossover', 'random_restart'][np.argmax(q_values)]\n\n                old_value = self.Q.get((state, action), 0)\n                next_max = max([self.Q.get((new_state, a), 0) for a in ['mutation', 'crossover', 'random_restart']])\n\n                new_value = (1 - self.lr) * old_value + self.lr * (reward + self.gamma * next_max)\n                self.Q[(state, action)] = new_value\n\n        return self.f_opt, self.x_opt", "objective": -0.50746, "other_inf": null}
{"id": "b6a0c2d6-9642-4402-bd4e-6b71acc15e7e", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e", "59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "The algorithm uses a population-based approach with momentum-based velocity updates, inspired by particle swarm optimization, and incorporates a random restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass MomentumPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, momentum=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.momentum = momentum\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(population)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            global_best_idx = np.argmin(personal_best_fitness)\n            global_best_position = personal_best_positions[global_best_idx]\n\n            for i in range(self.pop_size):\n                # Update velocities with momentum\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n                velocities[i] = self.momentum * velocities[i] + self.w * velocities[i] + cognitive_component + social_component\n\n                # Update positions\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i]\n\n                # Random Restart\n                if np.random.rand() < self.restart_prob:\n                    population[i] = np.random.uniform(lb, ub, size=(self.dim))\n                    velocities[i] = np.zeros(self.dim)\n                    f = func(population[i])\n                    evals += 1\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i]\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "ad29f246-dc52-403f-9884-b72a6af46a96", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm employs a self-adaptive Differential Evolution with a restart mechanism and covariance matrix adaptation (CMA) for enhanced exploration and exploitation, periodically re-initializing the population based on stagnation detection, and adapting the search distribution using CMA to improve convergence speed.", "code": "import numpy as np\n\nclass AdaptiveDEwithCMAandRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_trigger=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_trigger = restart_trigger\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = None\n        self.covariance = None\n        self.success_history = []\n        self.stagnation_counter = 0\n        self.restart_threshold = budget // 100 # Number of iterations without improvement before restart\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.covariance = np.eye(self.dim) * ((ub - lb) / 2)**2  # Initialize with a diagonal covariance matrix\n\n        population = self.initialize_population(lb, ub)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                trial = np.clip(trial, lb, ub)\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.success_history.append(f_trial)\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # CMA-ES adaptation of search distribution\n            if self.success_history:\n                self.mean = np.mean(population, axis=0)\n                \n                # Sample a direction from the covariance matrix\n                z = np.random.normal(0, 1, self.dim)\n                direction = np.dot(np.linalg.cholesky(self.covariance), z)\n\n                # Update covariance matrix (simplified)\n                self.covariance = (1 - self.cma_learning_rate) * self.covariance + self.cma_learning_rate * np.outer(direction, direction)\n\n                self.success_history = []\n\n            # Stagnation detection and restart\n            if self.f_opt >= old_f_opt:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                population = self.initialize_population(lb, ub)\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.covariance = np.eye(self.dim) * ((ub - lb) / 2)**2\n                self.stagnation_counter = 0\n\n            # Adapt F and CR (simplified)\n            self.F = 0.5 + 0.3 * np.random.rand()\n            self.CR = 0.6 + 0.4 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "objective": -0.81402, "other_inf": null}
{"id": "c96a5eef-4ae0-42d9-87b2-5781237a479d", "parents": ["59b2a211-d070-4f76-a6af-163ca18d6c1e"], "algorithm": "This algorithm uses a self-adaptive covariance matrix adaptation evolution strategy (CMA-ES) to evolve a population of solutions, updating the covariance matrix based on the successful steps taken during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize variables\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n        chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # Parameters\n        c_sigma = (self.mu / self.dim) / 4\n        c_c = (4 + self.mu / self.dim) / (self.dim + 4)\n        c_mu = self.mu / (self.dim**2)\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim+1)) - 1) + c_sigma\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        c_mu_eff = min(1 - c_1, c_mu * (self.mu - 1 + 1/self.mu))\n        \n        evals = 0\n        while evals < self.budget:\n            # Generate and evaluate population\n            Z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            X = mean + sigma * Z\n            X = np.clip(X, lb, ub)\n            fitness = np.array([func(x) for x in X])\n            evals += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            X = X[idx]\n            fitness = fitness[idx]\n\n            # Update mean\n            weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n            weights = weights / np.sum(weights)\n            mean_old = np.copy(mean)\n            mean = np.sum(weights[:, None] * X[:self.mu], axis=0)\n\n            # Update evolution paths\n            z_mean = np.mean(Z[idx[:self.mu]], axis=0)\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * c_mu_eff) * np.linalg.inv(np.linalg.cholesky(C)) @ (mean - mean_old) / sigma\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c) * c_mu_eff) * (mean - mean_old) / sigma\n            \n            # Adapt covariance matrix\n            C = (1 - c_1 - c_mu_eff) * C + c_1 * (pc[:, None] @ pc[None, :])\n            C += c_mu * np.sum(weights[:, None, None] * (Z[idx[:self.mu], :, None] @ Z[idx[:self.mu], None, :]), axis=0)\n\n            # Adapt step size\n            sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps)/chiN - 1))\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[0]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f58cf110-95e6-4333-9095-ea67d7b8cc10", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "An enhanced differential evolution algorithm with a self-adaptive population size and a learning strategy that dynamically adjusts mutation and crossover rates based on the performance of individuals.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.learning_rate = learning_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.update_best()\n\n    def update_best(self):\n        global_best_index = np.argmin(self.fitness)\n        if self.fitness[global_best_index] < self.f_opt:\n            self.f_opt = self.fitness[global_best_index]\n            self.x_opt = self.population[global_best_index].copy()\n\n    def adjust_population_size(self):\n        if np.random.rand() < 0.1:  # Adjust population size probabilistically\n            if np.random.rand() < 0.5:\n                self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            else:\n                self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.adjust_population_size()\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + self.f * (x2[j] - x3[j])\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n\n                    # Parameter Adaptation\n                    if np.random.rand() < self.learning_rate:\n                        self.cr = np.random.uniform(0.1, 0.9)\n                        self.f = np.random.uniform(0.1, 0.9)\n\n                else:\n                    new_population[i] = self.population[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n            self.update_best()\n\n            # Global Adaptation of Parameters\n            self.cr = np.clip(self.cr + np.random.normal(0, 0.05), 0.1, 0.9)\n            self.f = np.clip(self.f + np.random.normal(0, 0.05), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "16874de1-39ed-4dbc-a973-5421c78e6198", "parents": ["6d6dbc18-6de6-43b4-a1ca-01a661b18827"], "algorithm": "# Description: This algorithm employs a population-based approach with a decaying exploration rate and adaptive mutation scaling based on population diversity to balance exploration and exploitation.\n# Code: \n```", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7, exploration_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.exploration_decay = exploration_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        exploration_rate = 1.0\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.pop_size):\n                # Mutation scaling based on diversity\n                mutation_scale = self.f * (1 + exploration_rate * diversity)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + mutation_scale * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n            \n            # Decay exploration rate\n            exploration_rate *= self.exploration_decay\n\n        return self.f_opt, self.x_opt", "objective": -0.45057, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "c0808515-c88c-42c6-9861-4830e0468958", "parents": [], "algorithm": "This algorithm uses a population-based approach with differential evolution, incorporating a dynamic adaptation of the scaling factor and crossover rate based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adapt F and CR dynamically (example - based on fitness variance)\n            fitness_std = np.std(fitness)\n            if fitness_std > 0.1:  # Example threshold\n                self.F = np.clip(self.F + np.random.normal(0, 0.05), 0.1, 1.0)\n                self.CR = np.clip(self.CR + np.random.normal(0, 0.05), 0.1, 1.0)\n\n            if self.budget <= 0:\n                break\n                \n        return self.f_opt, self.x_opt", "objective": -0.6147, "other_inf": null}
{"id": "df25b97f-f16f-4ba2-81c9-5d709a220621", "parents": [], "algorithm": "An adaptive differential evolution strategy with a population size adjusted based on function evaluation budget and a self-adaptive mutation factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)  # Adaptive population size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update mutation factor\n                    if np.random.rand() < 0.1:\n                        self.F = np.random.uniform(0.4, 0.9)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.7516, "other_inf": null}
{"id": "0de35187-e376-46bb-9f45-492295449f7c", "parents": [], "algorithm": "This algorithm employs a Gaussian mutation hill-climbing approach with adaptive step size control based on success rate and a restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, step_size_adaptation_factor=0.9, success_threshold=0.2, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.step_size_adaptation_factor = step_size_adaptation_factor\n        self.success_threshold = success_threshold\n        self.restart_probability = restart_probability\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        successes = 0\n        evaluations = 1\n\n        while evaluations < self.budget:\n            # Generate a mutated solution\n            x_new = x + self.step_size * np.random.normal(0, 1, size=self.dim)\n\n            # Clip the solution to stay within bounds\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluate the mutated solution\n            f_new = func(x_new)\n            evaluations += 1\n\n            if f_new < f:\n                # Accept the mutated solution\n                x = x_new\n                f = f_new\n                successes += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt step size\n            if evaluations % 100 == 0:\n                success_rate = successes / 100\n                if success_rate > self.success_threshold:\n                    self.step_size /= self.step_size_adaptation_factor # decrease step size\n                else:\n                    self.step_size *= self.step_size_adaptation_factor # increase step size\n                successes = 0\n\n            # Restart with a small probability\n            if np.random.rand() < self.restart_probability:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                evaluations +=1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt", "objective": -0.31905, "other_inf": null}
{"id": "03a31c42-9b26-44b0-830d-28bc22c208d5", "parents": [], "algorithm": "A population-based algorithm with adaptive step size and selection based on fitness and diversity.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def evaluate_population(self, func, population):\n        fitness = np.array([func(x) for x in population])\n        return fitness\n\n    def select_parents(self, population, fitness, num_parents=2):\n        # Fitness-based selection with diversity preservation\n        probabilities = np.exp(-fitness / np.std(fitness)) if np.std(fitness) > 0 else np.ones_like(fitness) / len(fitness)\n        probabilities /= np.sum(probabilities)\n\n        selected_indices = np.random.choice(len(population), size=num_parents, replace=False, p=probabilities)\n        return population[selected_indices]\n\n    def crossover(self, parents, crossover_rate=0.8):\n        if np.random.rand() < crossover_rate:\n            alpha = np.random.rand(self.dim)\n            child = alpha * parents[0] + (1 - alpha) * parents[1]\n        else:\n            child = parents[np.random.randint(0, 2)].copy()\n        return child\n\n    def mutate(self, child, mutation_rate=0.1):\n        for i in range(self.dim):\n            if np.random.rand() < mutation_rate:\n                child[i] += self.step_size * np.random.normal(0, 1)\n        child = np.clip(child, self.lb, self.ub)\n        return child\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        \n        population = self.initialize_population()\n        fitness = self.evaluate_population(func, population)\n        eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                \n\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.pop_size):\n                parents = self.select_parents(population, fitness)\n                child = self.crossover(parents)\n                child = self.mutate(child)\n                new_population.append(child)\n\n            new_population = np.array(new_population)\n            new_fitness = self.evaluate_population(func, new_population)\n            eval_count += self.pop_size\n            \n            combined_population = np.vstack((population, new_population))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n\n            #Elitism: Keep the best individual\n            best_idx = np.argmin(combined_fitness)\n            best_x = combined_population[best_idx]\n            best_f = combined_fitness[best_idx]\n            \n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x.copy()\n                \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n            \n            self.step_size *= 0.99  # Adaptive step size\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "65c31ba7-af28-47a1-aade-b25af00f7abe", "parents": [], "algorithm": "A population-based algorithm that combines particle swarm optimization (PSO) with differential evolution (DE) strategies for enhanced exploration and exploitation, adaptively adjusting the balance between the two based on performance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, pso_weight=0.7, de_cross_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross_rate = de_cross_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_step(self, func):\n        inertia_weight = self.pso_weight  # Inertia weight\n        cognitive_coeff = 2.0  # Cognitive coefficient\n        social_coeff = 2.0  # Social coefficient\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (inertia_weight * self.velocities +\n                           cognitive_coeff * r1 * (self.personal_best_positions - self.population) +\n                           social_coeff * r2 * (self.global_best_position - self.population))\n\n        self.population += self.velocities\n\n        # Clip to boundaries\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        \n        for i in range(self.pop_size):\n            if new_fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if new_fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = new_fitness[i]\n                self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func):\n        mutation_factor = 0.5\n        crossover_rate = self.de_cross_rate\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + mutation_factor * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, self.lb, self.ub)\n\n            u_trial = np.zeros(self.dim)\n            j_rand = np.random.randint(0, self.dim)\n\n            for j in range(self.dim):\n                if np.random.rand() <= crossover_rate or j == j_rand:\n                    u_trial[j] = v_trial[j]\n                else:\n                    u_trial[j] = self.population[i][j]\n            \n            f_trial = func(u_trial)\n            self.eval_count += 1\n            \n            if f_trial < self.fitness[i]:\n                self.population[i] = u_trial.copy()\n                self.fitness[i] = f_trial\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_trial.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_trial.copy()\n\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < 0.5:\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.41919, "other_inf": null}
{"id": "9034547c-6b9d-42da-90fc-9d03e414d972", "parents": [], "algorithm": "This algorithm uses a combination of local search and global exploration, where promising regions are intensified with shrinking bounds while random jumps ensure global coverage.", "code": "import numpy as np\n\nclass AdaptiveRandomSearch:\n    def __init__(self, budget=10000, dim=10, local_search_prob = 0.7):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        lb = np.full(self.dim, self.lb)\n        ub = np.full(self.dim, self.ub)\n        \n        for i in range(self.budget):\n            if np.random.rand() < self.local_search_prob or self.x_opt is None:\n                x = np.random.uniform(lb, ub)\n            else:\n                # Local search around the current best\n                width = (ub - lb) / 10  # Adjust step size\n                new_lb = np.maximum(self.lb, self.x_opt - width)\n                new_ub = np.minimum(self.ub, self.x_opt + width)\n                x = np.random.uniform(new_lb, new_ub)  # Sample around best\n            \n            f = func(x)\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                # Shrink bounds towards the current best\n                shrink_factor = 0.1 #How quickly the boundaries shrink\n                lb = np.maximum(self.lb, self.x_opt - shrink_factor*(self.x_opt - np.full(self.dim, self.lb))) \n                ub = np.minimum(self.ub, self.x_opt + shrink_factor*(np.full(self.dim, self.ub) - self.x_opt))\n                \n        return self.f_opt, self.x_opt", "objective": -0.26185, "other_inf": null}
{"id": "4bb4d002-d8ee-4b7b-a3e3-a732800e889b", "parents": [], "algorithm": "An adaptive Differential Evolution strategy that adjusts its parameters based on the success rate of generating improved solutions.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                # Ensure bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n                # Adaptive Parameter Control (Example: Adjust F based on success)\n                if self.eval_count % self.pop_size == 0:\n                   success_rate = np.sum(self.fitness < np.array([func(x) for x in self.pop])) / self.pop_size\n                   if success_rate > 0.2:\n                        self.F *= 0.9  # Reduce F if too many improvements\n                   elif success_rate < 0.05:\n                        self.F *= 1.1 # Increase F if too few improvements\n                   self.F = np.clip(self.F, 0.1, 1.0) #Ensure F within range\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "e67c3442-3f3b-4b26-ad89-268967017797", "parents": [], "algorithm": "This algorithm combines a Gaussian mutation hill-climbing approach with a restart mechanism to escape local optima and explore the search space more effectively.", "code": "import numpy as np\n\nclass AdaptiveHillClimber:\n    def __init__(self, budget=10000, dim=10, sigma=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        while self.budget > 0:\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                continue\n\n            x_new = x + np.random.normal(0, self.sigma, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                self.sigma *= 0.95  # Reduce step size if no improvement\n            \n            if self.budget <= 0:\n              break\n            \n        return self.f_opt, self.x_opt", "objective": -0.25379, "other_inf": null}
{"id": "d7825971-8ff7-46f8-abe1-ee1254cb5ef0", "parents": ["c0808515-c88c-42c6-9861-4830e0468958", "65c31ba7-af28-47a1-aade-b25af00f7abe"], "algorithm": "This algorithm employs a stochastic local search with adaptive step size control based on the success rate of previous steps, aiming to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveStochasticSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_rate_threshold=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        while self.budget > 0:\n            # Generate a random step\n            direction = np.random.normal(0, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            # Take a step in the random direction\n            x_new = x + self.step_size * direction\n            x_new = np.clip(x_new, self.lb, self.ub)  # Clip to boundaries\n\n            # Evaluate the new position\n            f_new = func(x_new)\n            self.budget -= 1\n            self.iteration_count += 1\n\n            # Check for improvement\n            if f_new < f:\n                self.success_count += 1\n                x = x_new\n                f = f_new\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt step size based on success rate\n            if self.iteration_count % 100 == 0:\n                success_rate = self.success_count / 100\n                if success_rate > self.success_rate_threshold:\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n                self.success_count = 0\n        \n        return self.f_opt, self.x_opt", "objective": -0.41138, "other_inf": null}
{"id": "188ed271-5743-4ca9-bcfb-4cf43c553a58", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "0de35187-e376-46bb-9f45-492295449f7c"], "algorithm": "A population-based algorithm with a spiral dynamic search strategy, where each individual moves along a spiral trajectory towards the current best solution, adapting the spiral parameters based on the search progress.", "code": "import numpy as np\n\nclass SpiralDynamicAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_param_a=0.1, spiral_param_r=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_param_a = spiral_param_a\n        self.spiral_param_r = spiral_param_r\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Spiral movement\n                r = self.spiral_param_r\n                theta = np.random.uniform(-np.pi, np.pi, size=self.dim)\n                \n                # Ensure that theta has the correct shape for element-wise operations\n                spiral_move = self.spiral_param_a * np.exp(r * theta) * np.cos(theta) * (self.x_opt - population[i])\n                \n                new_position = population[i] + spiral_move\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position.copy()\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n\n            # Update spiral parameters occasionally\n            if self.budget > 0 and self.budget % 500 == 0:\n                self.spiral_param_a *= 0.95  # Reduce spiral tightness\n                self.spiral_param_r *= 0.98  # Reduce spiral range\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.30955, "other_inf": null}
{"id": "9ac2c1dc-8a55-4122-8e13-2ea93ddeab7c", "parents": ["c0808515-c88c-42c6-9861-4830e0468958", "65c31ba7-af28-47a1-aade-b25af00f7abe"], "algorithm": "This algorithm utilizes a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by sampling from the posterior distribution with an acquisition function.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel='RBF'):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        if kernel == 'RBF':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        elif kernel == 'Matern':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * Matern(length_scale=1.0, length_scale_bounds=\"fixed\", nu=1.5)\n        else:\n            raise ValueError(\"Invalid kernel type. Choose 'RBF' or 'Matern'.\")\n\n    def acquisition_function(self, x, xi=0.01):\n        \"\"\"Expected Improvement acquisition function.\"\"\"\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        \n        # Avoid division by zero\n        sigma = np.maximum(sigma, 1e-9)\n        \n        imp = mu - self.y.min() - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return -ei  # We want to maximize EI, but minimize function\n\n    def optimize_acquisition_function(self):\n        \"\"\"Optimizes the acquisition function to find the next sampling point.\"\"\"\n        bounds = [(self.lb, self.ub)] * self.dim\n        \n        # Start from multiple random points\n        x0 = np.random.uniform(self.lb, self.ub, size=(10, self.dim))\n        \n        best_x = None\n        best_acq = np.inf\n        \n        for start_point in x0:\n            res = minimize(self.acquisition_function, start_point, method='L-BFGS-B', bounds=bounds)\n            if res.fun < best_acq:\n                best_acq = res.fun\n                best_x = res.x\n        \n        return best_x\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n        \n        best_idx = np.argmin(self.y)\n        if self.y[best_idx] < self.f_opt:\n            self.f_opt = self.y[best_idx]\n            self.x_opt = self.X[best_idx]\n\n        # Gaussian process regression\n        self.gpr = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=0, alpha=1e-6) # Increased n_restarts_optimizer\n\n        while self.budget > 0:\n            # Fit the GP model\n            self.gpr.fit(self.X, self.y)\n\n            # Find the next point to sample using the acquisition function\n            x_next = self.optimize_acquisition_function()\n\n            # Evaluate the function at the new point\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b2f64ecb-508f-4ec3-be1a-a63c0f4eec41", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A hybrid algorithm combining a simplified particle swarm optimization (PSO) for global search with a Nelder-Mead simplex method for local refinement.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, swarm_size=10, pso_iters=100, nm_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.pso_iters = pso_iters\n        self.nm_iters = nm_iters\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize PSO swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        self.budget -= self.swarm_size\n        \n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n\n        # PSO iterations\n        for i in range(self.pso_iters):\n            for j in range(self.swarm_size):\n                # Update velocity and position\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[j] = self.w * velocities[j] + \\\n                                 self.c1 * r1 * (personal_best_positions[j] - swarm[j]) + \\\n                                 self.c2 * r2 * (global_best_position - swarm[j])\n                swarm[j] = np.clip(swarm[j] + velocities[j], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate fitness\n                fitness = func(swarm[j])\n                self.budget -= 1\n                \n                # Update personal best\n                if fitness < personal_best_fitnesses[j]:\n                    personal_best_fitnesses[j] = fitness\n                    personal_best_positions[j] = swarm[j].copy()\n                    \n                    # Update global best\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = swarm[j].copy()\n                        \n                        if fitness < self.f_opt:\n                            self.f_opt = fitness\n                            self.x_opt = swarm[j].copy()\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n\n        # Nelder-Mead refinement around the best solution found by PSO\n        if self.budget > 0:\n            nm_result = minimize(func, global_best_position, method='Nelder-Mead',\n                                 options={'maxiter': self.nm_iters, 'maxfev': self.budget", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, swarm_size=10, pso_iters=100, nm_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.pso_iters = pso_iters\n        self.nm_iters = nm_iters\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize PSO swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        self.budget -= self.swarm_size\n        \n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n\n        # PSO iterations\n        for i in range(self.pso_iters):\n            for j in range(self.swarm_size):\n                # Update velocity and position\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[j] = self.w * velocities[j] + \\\n                                 self.c1 * r1 * (personal_best_positions[j] - swarm[j]) + \\\n                                 self.c2 * r2 * (global_best_position - swarm[j])\n                swarm[j] = np.clip(swarm[j] + velocities[j], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate fitness\n                fitness = func(swarm[j])\n                self.budget -= 1\n                \n                # Update personal best\n                if fitness < personal_best_fitnesses[j]:\n                    personal_best_fitnesses[j] = fitness\n                    personal_best_positions[j] = swarm[j].copy()\n                    \n                    # Update global best\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = swarm[j].copy()\n                        \n                        if fitness < self.f_opt:\n                            self.f_opt = fitness\n                            self.x_opt = swarm[j].copy()\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n\n        # Nelder-Mead refinement around the best solution found by PSO\n        if self.budget > 0:\n            nm_result = minimize(func, global_best_position, method='Nelder-Mead',\n                                 options={'maxiter': self.nm_iters, 'maxfev': self.budget})\n            \n            if nm_result.success:\n                if nm_result.fun < self.f_opt:\n                    self.f_opt = nm_result.fun\n                    self.x_opt = nm_result.x\n            \n            self.budget -= nm_result.nfev\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "57d293a1-8639-43a9-b66b-8a895c2daa3f", "parents": ["d7825971-8ff7-46f8-abe1-ee1254cb5ef0", "c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "This algorithm simulates the diffusion of particles in a potential field, where particles move towards better solutions with a velocity influenced by the fitness gradient and a random exploration component.", "code": "import numpy as np\n\nclass DiffusionSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.budget -= 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.population[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_velocity = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(self.population[i])\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = self.population[i].copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.53909, "other_inf": null}
{"id": "1125abd1-8b00-4a73-a823-0d7430096ddf", "parents": ["c0808515-c88c-42c6-9861-4830e0468958", "65c31ba7-af28-47a1-aade-b25af00f7abe"], "algorithm": "This algorithm combines a simplified covariance matrix adaptation evolution strategy (CMA-ES) with Nelder-Mead simplex search to balance global exploration and local refinement.}\n# Code:\n```python\nimport numpy as np\n\nclass CMA_ES_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=1.0, c_sigma=0.4, d_sigma=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.mean = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.path_sigma = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Sample population\n            population = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n            population = np.clip(population, self.lb, self.ub)\n\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n            if evals > self.budget:\n                fitness = fitness[:self.budget - (evals - self.pop_size)]\n                population = population[:self.budget - (evals - self.pop_size)]\n                evals = self.budget\n                \n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update CMA-ES parameters\n            sorted_indices = np.argsort(fitness)\n            selected_individuals = population[sorted_indices[:self.pop_size // 2]]\n            old_mean = self.mean.copy()\n            self.mean = np.mean(selected_individuals, axis=0)\n\n            self.path_sigma = (1 - self.c_sigma) * self.path_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.mean - old_mean) / self.sigma\n            self.sigma *= np.exp(self.d_sigma / 0.44 * (np.linalg.norm(self.path_sigma) - np.sqrt(self.dim)))\n            self.sigma = np.clip(self.sigma, 1e-6, 5)\n            \n            # Apply Nelder-Mead every few iterations\n            if evals % (self.pop_size * 5) == 0 and evals + self.dim + 1 < self.budget:\n                \n                def nm_func(x):\n                    val = func(x)\n                    return val\n                \n                import scipy.optimize\n                \n                try:\n                    res = scipy.optimize.minimize(nm_func, self.x_opt, method='Nelder-Mead', options={'maxfev': min(self.budget - evals, 200)", "code": "import numpy as np\n\nclass CMA_ES_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=1.0, c_sigma=0.4, d_sigma=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.mean = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.path_sigma = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Sample population\n            population = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n            population = np.clip(population, self.lb, self.ub)\n\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n            if evals > self.budget:\n                fitness = fitness[:self.budget - (evals - self.pop_size)]\n                population = population[:self.budget - (evals - self.pop_size)]\n                evals = self.budget\n                \n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update CMA-ES parameters\n            sorted_indices = np.argsort(fitness)\n            selected_individuals = population[sorted_indices[:self.pop_size // 2]]\n            old_mean = self.mean.copy()\n            self.mean = np.mean(selected_individuals, axis=0)\n\n            self.path_sigma = (1 - self.c_sigma) * self.path_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.mean - old_mean) / self.sigma\n            self.sigma *= np.exp(self.d_sigma / 0.44 * (np.linalg.norm(self.path_sigma) - np.sqrt(self.dim)))\n            self.sigma = np.clip(self.sigma, 1e-6, 5)\n            \n            # Apply Nelder-Mead every few iterations\n            if evals % (self.pop_size * 5) == 0 and evals + self.dim + 1 < self.budget:\n                \n                def nm_func(x):\n                    val = func(x)\n                    return val\n                \n                import scipy.optimize\n                \n                try:\n                    res = scipy.optimize.minimize(nm_func, self.x_opt, method='Nelder-Mead', options={'maxfev': min(self.budget - evals, 200)})\n                    \n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                    evals += res.nfev\n                    \n                except:\n                    pass\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "5fbaa5fc-025c-4143-8eac-4102120c43b1", "parents": ["d7825971-8ff7-46f8-abe1-ee1254cb5ef0", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "Simultaneous exploration and exploitation using multiple agents with information sharing based on a ring topology.", "code": "import numpy as np\n\nclass RingTopologyPSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n\n        # Initialize neighborhood best positions (ring topology)\n        neighborhood_best_positions = np.zeros((self.num_particles, self.dim))\n        neighborhood_best_values = np.full(self.num_particles, np.inf)\n        \n        for i in range(self.num_particles):\n            left = (i - 1) % self.num_particles\n            right = (i + 1) % self.num_particles\n            \n            if personal_best_values[left] < personal_best_values[i]:\n                if personal_best_values[left] < personal_best_values[right]:\n                    neighborhood_best_positions[i] = personal_best_positions[left]\n                    neighborhood_best_values[i] = personal_best_values[left]\n                else:\n                    neighborhood_best_positions[i] = personal_best_positions[right]\n                    neighborhood_best_values[i] = personal_best_values[right]\n\n            elif personal_best_values[right] < personal_best_values[i]:\n                neighborhood_best_positions[i] = personal_best_positions[right]\n                neighborhood_best_values[i] = personal_best_values[right]\n            else:\n                neighborhood_best_positions[i] = personal_best_positions[i]\n                neighborhood_best_values[i] = personal_best_values[i]\n                    \n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            for i in range(self.num_particles):\n                # Update velocity\n                inertia_term = self.inertia * velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (neighborhood_best_positions[i] - particles[i])\n                velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update neighborhood best\n                    left = (i - 1) % self.num_particles\n                    right = (i + 1) % self.num_particles\n                    \n                    for neighbor_index in [i, left, right]:\n                        local_f_opt = np.inf\n                        local_x_opt = None\n\n                        left_neighbor = (neighbor_index - 1) % self.num_particles\n                        right_neighbor = (neighbor_index + 1) % self.num_particles\n                        \n                        for neighbor_index2 in [neighbor_index, left_neighbor, right_neighbor]:\n                            if personal_best_values[neighbor_index2] < local_f_opt:\n                                local_f_opt = personal_best_values[neighbor_index2]\n                                local_x_opt = personal_best_positions[neighbor_index2]\n                        \n                        neighborhood_best_values[neighbor_index] = local_f_opt\n                        neighborhood_best_positions[neighbor_index] = local_x_opt\n\n\n                # Update global best\n                if fitness < self.f_opt:\n                    self.f_opt = fitness\n                    self.x_opt = particles[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.56282, "other_inf": null}
{"id": "3f3f7c1c-efe4-4973-b6ba-1f36ded325e1", "parents": ["65c31ba7-af28-47a1-aade-b25af00f7abe", "c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "An algorithm that uses a Gaussian process surrogate model to guide the search, iteratively sampling new points based on the model's predictions and uncertainty, balancing exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.eval_count += self.n_initial_samples\n\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n        self.gpr.fit(self.X, self.y)\n\n    def acquisition_function(self, x, xi=0.01):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        return mu - xi * sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Find the next point to evaluate by maximizing the acquisition function\n            from scipy.optimize import minimize\n            bounds = [(self.lb, self.ub)] * self.dim\n            \n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n            res = minimize(lambda x: -self.acquisition_function(x), x0,\n                           bounds=bounds, method='L-BFGS-B')  # Use L-BFGS-B to respect bounds\n            \n            x_next = res.x\n\n            # Evaluate the function at the new point\n            f_next = func(x_next)\n            self.eval_count += 1\n\n            # Update the Gaussian process model\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            self.gpr.fit(self.X, self.y)\n            \n            # Update the best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "0f93e1e2-d136-4c44-92f2-106a13ca0022", "parents": ["5fbaa5fc-025c-4143-8eac-4102120c43b1"], "algorithm": "Adaptive Particle Swarm Optimization with velocity clamping and dynamic parameter adjustment based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0, velocity_clamp=1.0, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_limit = stagnation_limit\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n        \n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n            self.previous_best_fitness = self.f_opt\n\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / (self.budget + self.num_particles))\n\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = inertia * velocities[i] + \\\n                                self.cognitive_coeff * r1 * (personal_best_positions[i] - particles[i]) + \\\n                                self.social_coeff * r2 * (self.x_opt - particles[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i]\n\n            # Stagnation detection and parameter adjustment\n            if abs(self.f_opt - self.previous_best_fitness) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_limit:\n                # Reset particles to explore new regions\n                particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n                velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.num_particles, self.dim))\n                personal_best_positions = particles.copy()\n                personal_best_values = np.array([func(x) for x in particles])\n                self.budget -= self.num_particles\n                \n                if np.min(personal_best_values) < self.f_opt:\n                    self.f_opt = np.min(personal_best_values)\n                    self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n                \n                # Increase exploration by increasing inertia\n                self.inertia_max = min(0.95, self.inertia_max + 0.05) # Ensure it does not become bigger than 0.95\n                self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.11731, "other_inf": null}
{"id": "4a7ffab3-a9f5-4524-8748-d5f74be79511", "parents": ["57d293a1-8639-43a9-b66b-8a895c2daa3f"], "algorithm": "This algorithm introduces a dynamic adaptation of the inertia weight in the particle swarm optimization based on the exploration-exploitation ratio, encouraging more exploration initially and more exploitation as the search progresses.", "code": "import numpy as np\n\nclass AdaptiveInertiaPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, final_inertia=0.4, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_inertia = initial_inertia\n        self.final_inertia = final_inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.budget -= 1\n            self.eval_count += 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.population[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            # Calculate dynamic inertia weight\n            inertia = self.initial_inertia - (self.initial_inertia - self.final_inertia) * (self.eval_count / self.budget)\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_velocity = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(self.population[i])\n                self.budget -= 1\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = self.population[i].copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.47939, "other_inf": null}
{"id": "40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and adaptive inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        \n        self.budget -= self.pop_size\n\n        if np.min(personal_best_fitness) < self.f_opt:\n            self.f_opt = np.min(personal_best_fitness)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_fitness)]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        global_best_fitness = np.min(personal_best_fitness)\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / self.budget) # Linear decrease of inertia\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # Velocity clamping\n                v_max = 0.2*(func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = particles[i]\n                        \n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.62454, "other_inf": null}
{"id": "47009ae4-3b92-4913-8722-eb1068d5ae98", "parents": ["5fbaa5fc-025c-4143-8eac-4102120c43b1"], "algorithm": "# Description: Adaptively adjusts inertia weight and acceleration coefficients of PSO based on population diversity and individual performance.\n# Code: \n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, initial_inertia=0.9, initial_cognitive_coeff=2.0, initial_social_coeff=2.0, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia = initial_inertia\n        self.cognitive_coeff = initial_cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n\n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(particles)\n\n            # Adapt inertia weight and coefficients based on diversity\n            if diversity < self.diversity_threshold:\n                self.inertia = min(self.inertia + 0.01, 0.9)\n                self.cognitive_coeff = max(self.cognitive_coeff - 0.01, 1.5)\n                self.social_coeff = max(self.social_coeff - 0.01, 1.5)\n            else:\n                self.inertia = max(self.inertia - 0.01, 0.4)\n                self.cognitive_coeff = min(self.cognitive_coeff + 0.01, 2.5)\n                self.social_coeff = min(self.social_coeff + 0.01, 2.5)\n\n            for i in range(self.num_particles):\n                # Update velocity\n                inertia_term = self.inertia * velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - particles[i]) # Using global best\n                velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.39452, "other_inf": null}
{"id": "a836adbe-2ef2-4b7b-8135-9793aefd502d", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "A differential evolution algorithm with adaptive crossover rate and mutation factor based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_min=0.1, F_max=0.9, CR_min=0.1, CR_max=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.CR_min = CR_min\n        self.CR_max = CR_max\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Adaptive F and CR based on population diversity\n                diversity = np.std(fitness)\n                F = self.F_min + (self.F_max - self.F_min) * diversity\n                CR = self.CR_min + (self.CR_max - self.CR_min) * diversity\n                F = np.clip(F, self.F_min, self.F_max)\n                CR = np.clip(CR, self.CR_min, self.CR_max)\n\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "objective": -0.57856, "other_inf": null}
{"id": "dc00a97c-885b-4e90-9466-bfed773f0f91", "parents": ["c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "This algorithm employs a particle swarm optimization strategy with velocity clamping and dynamic inertia weight adaptation to balance exploration and exploitation within the search space.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        self.f_opt = fitness[best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia * (1 - (self.budget / 10000 if self.budget <= 10000 else 0)) #self.inertia * (self.budget / initial_budget)\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n                \n                velocities[i] = inertia * velocities[i] + cognitive_component + social_component\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluate new position\n                f_new = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f_new < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_new\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position.copy()\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.48227, "other_inf": null}
{"id": "1fba0f0b-c233-4dbf-aacb-fbcfd7b15406", "parents": ["5fbaa5fc-025c-4143-8eac-4102120c43b1"], "algorithm": "Adaptive Differential Evolution with elitist mutation strategy and dynamic parameter adjustment based on function evaluation success.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        success_history = []\n\n        while self.budget > 0:\n            generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation - Elitist strategy\n                elite_index = np.argmin(fitness)\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                indices = np.random.choice(indices, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                \n                mutant = population[elite_index] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Evaluation\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = trial_vector\n                        success_history.append(1)\n                    else:\n                        success_history.append(0)\n\n                else:\n                    success_history.append(0)\n\n                if len(success_history) > 50:\n                    success_rate = np.mean(success_history[-50:])\n                    self.F = np.clip(self.F + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n                    self.CR = np.clip(self.CR + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.37248, "other_inf": null}
{"id": "26ab590f-bc5f-4e4c-be17-c0015942f55a", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) with a budget-aware adaptation of the population size and step size.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(4 + np.floor(3 * np.log(self.dim)))  # Dynamically adjust based on dim\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.random.uniform(-1, 1, self.dim)\n        self.sigma = initial_step_size  # Step-size\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n        self.c_sigma = (self.mu / self.pop_size)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim+1)) - 1) + self.c_sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            samples = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate\n            fitness = np.array([func(x) for x in samples.T])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget]\n                samples = samples[:, :self.pop_size + self.budget]\n                self.pop_size = self.pop_size + self.budget\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            samples = samples[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = samples[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.dot(samples[:, :self.mu], self.weights)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.m - m_old) / self.sigma)\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2*(self.budget//self.pop_size))) < self.chiN * (1.4 + 2/(self.dim + 1))\n            dhsig = (1-hsig) * self.c_c * (2-self.c_c)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + dhsig * self.C)\n            for i in range(self.mu):\n                self.C += self.c_mu * self.weights[i] * np.outer((samples[:, i] - m_old) / self.sigma, (samples[:, i] - m_old) / self.sigma)\n\n            # Update step-size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c71016d8-b021-4296-b876-d509187e5a69", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) with adaptive step size control and rank-one update of the covariance matrix.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim / 2\n        self.c_cov = c_cov\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            samples = self.m + self.sigma * z @ np.linalg.cholesky(self.C).T\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in samples])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[np.argmin(fitness)]\n\n            # Selection and Recombination\n            idx = np.argsort(fitness)\n            best_samples = samples[idx[:self.mu]]\n            self.m = np.sum(self.weights[:, None] * best_samples, axis=0)\n\n            # Update Evolution Path\n            z_mean = np.mean(z[idx[:self.mu]], axis=0)\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * z_mean\n            \n            # Update Covariance Matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n\n            # Update Step Size\n            fitness_diff = np.max(fitness) - np.min(fitness)\n            self.sigma *= np.exp(0.5 * self.cs / self.damps * (fitness_diff / np.std(fitness) - 1))\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.2878, "other_inf": null}
{"id": "daa295ad-3eaf-4c92-b2d0-e39d9628e6d9", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "# Description: A covariance matrix adaptation evolution strategy (CMA-ES) with a simplified update rule and a fixed, small population size for quick adaptation to function landscape.\n# Code: \n```", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=4, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma\n        self.mean = None\n        self.C = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Covariance matrix\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            population = self.mean + self.sigma * z\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            best_x = population[idx[0]]\n            best_f = fitness[idx[0]]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Update mean\n            self.mean = best_x\n\n            # Simplified rank-1 update for covariance matrix (adaptation)\n            diff = best_x - self.mean\n            self.C = (0.9 * self.C + 0.1 * np.outer(diff, diff))\n            \n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.24425, "other_inf": null}
{"id": "d8eb90ce-1d3e-42e1-bd72-4ea59bf06760", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "Simulated Annealing with adaptive temperature and step size based on the success rate of finding better solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.success_rate = 0.0\n        self.success_counter = 0\n        self.iteration_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n        \n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = current_x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate neighbor solution\n            new_f = func(new_x)\n            self.budget -= 1\n            \n            # Acceptance probability\n            if new_f < current_f:\n                # Accept better solution\n                current_x = new_x\n                current_f = new_f\n                self.success_counter += 1\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n            else:\n                # Accept worse solution with probability\n                acceptance_prob = np.exp((current_f - new_f) / self.temp)\n                if np.random.rand() < acceptance_prob:\n                    current_x = new_x\n                    current_f = new_f\n\n            # Update temperature\n            self.temp *= self.cooling_rate\n            \n            #Adaptive step size\n            self.iteration_counter += 1\n            if self.iteration_counter % 100 == 0:\n                self.success_rate = self.success_counter / 100.0\n                self.success_counter = 0\n                if self.success_rate > 0.6:\n                    self.step_size *= 1.1\n                elif self.success_rate < 0.4:\n                    self.step_size *= 0.9\n                self.step_size = np.clip(self.step_size, 0.01, (func.bounds.ub - func.bounds.lb)/2) #Clamp the step size\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.47824, "other_inf": null}
{"id": "f030e881-1975-4946-9cd5-cce2d9c46ac7", "parents": ["c0808515-c88c-42c6-9861-4830e0468958", "c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to estimate the objective function and an acquisition function (Expected Improvement) to balance exploration and exploitation.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x):\n        x = x.reshape(1, -1)\n        mu, sigma = self.gp.predict(x, return_std=True)\n        \n        if sigma == 0:\n            return 0\n        \n        improvement = self.f_opt - mu\n        Z = improvement / sigma\n        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return -ei  # We want to maximize EI, so minimize -EI\n\n    def __call__(self, func):\n        # Initial sampling\n        initial_X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        initial_y = np.array([func(x) for x in initial_X])\n        self.budget -= self.n_initial_samples\n\n        self.X = initial_X\n        self.y = initial_y\n\n        best_index = np.argmin(initial_y)\n        self.f_opt = initial_y[best_index]\n        self.x_opt = initial_X[best_index]\n\n        while self.budget > 0:\n            # Fit Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            bounds = [(self.lb, self.ub)] * self.dim\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initial guess\n            result = minimize(self.acquisition_function, x0, bounds=bounds, method='L-BFGS-B')\n            x_next = result.x\n\n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Add to data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "bcde793a-3430-4bfa-a02d-1ca805d12b7d", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "# Description: A population-based search that iteratively refines the search space based on the best-performing individuals, shrinking the search space adaptively.\n# Code:\n```", "code": "import numpy as np\n\nclass ShrinkingSearchSpace:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_x = population[best_index]\n        best_f = fitness[best_index]\n\n        self.f_opt = best_f\n        self.x_opt = best_x\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Calculate the new search space based on the best solutions\n            center = np.mean(population[:self.pop_size // 2], axis=0) # Use the best half to define center\n\n            width = (ub - lb) * self.shrink_factor\n            new_lb = np.maximum(center - width / 2, func.bounds.lb)\n            new_ub = np.minimum(center + width / 2, func.bounds.ub)\n\n            # Generate new population within the shrunk search space\n            new_population = np.random.uniform(new_lb, new_ub, size=(self.pop_size, self.dim))\n\n            # Evaluate fitness of the new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Combine old and new populations (elitism)\n            combined_population = np.concatenate((population[:self.pop_size // 2], new_population)) #Keep half of the previous population\n            combined_fitness = np.concatenate((fitness[:self.pop_size // 2], new_fitness))\n            \n            population = combined_population\n            fitness = combined_fitness\n            \n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n            best_f = fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.30193, "other_inf": null}
{"id": "dac14a0e-25ef-435f-b89d-2dbe5aef213b", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) with restart mechanism and budget-aware adaptation of parameters.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.restarts = restarts\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        if sigma0 is None:\n            self.sigma0 = 0.5\n        else:\n            self.sigma0 = sigma0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        for _ in range(self.restarts):\n            self.f_opt_restart = np.inf\n            self.x_opt_restart = None\n            \n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            chiN = np.mean(np.sqrt(np.sum(np.random.randn(self.pop_size, self.dim)**2, axis=1)))\n            mu = self.pop_size // 2\n            weights = np.log(mu+1/2) - np.log(np.arange(1, mu+1))\n            weights = weights / np.sum(weights)\n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n            \n            c_sigma = (mueff + 2) / (self.dim + mueff + 5)\n            c_c = (4 + mueff / self.dim) / (self.dim + 4 + 2 * mueff / self.dim)\n            c_1 = 2 / ((self.dim + 1.3)**2 + mueff)\n            c_mu = min(1 - c_1, 2 * (mueff - 2 + 1 / mueff) / ((self.dim + 2)**2 + mueff))\n            d_sigma = 1 + 2 * max(0, np.sqrt((mueff - 1) / (self.dim + 1)) - 1) + c_sigma\n            \n            B = None\n            D = None\n            \n            evals_used = 0\n            while self.budget > 0 and evals_used < self.budget // self.restarts:\n                # Sampling\n                if B is None or D is None:\n                    eigenvalues, eigenvectors = np.linalg.eigh(C)\n                    B = eigenvectors\n                    D = np.diag(np.sqrt(eigenvalues))\n\n                z = np.random.randn(self.pop_size, self.dim)\n                x = mean + sigma * B @ D @ z.T\n                x = np.clip(x.T, func.bounds.lb, func.bounds.ub)\n                \n                fitness = np.array([func(xi) for xi in x])\n                evals_used += self.pop_size\n                self.budget -= self.pop_size\n                \n                if np.min(fitness) < self.f_opt_restart:\n                    self.f_opt_restart = np.min(fitness)\n                    self.x_opt_restart = x[np.argmin(fitness)]\n                \n                # Selection and Recombination\n                idx = np.argsort(fitness)\n                x_mu = x[idx[:mu]]\n                z_mu = z[idx[:mu]]\n                \n                mean_old = mean.copy()\n                mean = np.sum(weights[:, None] * x_mu, axis=0)\n                zmean = np.sum(weights[:, None] * z_mu, axis=0)\n\n                # Update Evolution Path\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mueff) * (B @ zmean)\n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * evals_used / self.pop_size)) < (1.4 + 2 / (self.dim + 1)) * chiN\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c) * mueff) * (mean - mean_old) / sigma\n                \n                # Update Covariance Matrix\n                C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :]) + c_mu * np.sum(weights[:, None, None] * (z_mu[:, :, None] @ z_mu[:, None, :]), axis=0)\n                \n                # Update Step Size\n                sigma = sigma * np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps) / chiN - 1))\n\n                if self.budget <= 0:\n                    break\n            \n            if self.f_opt_restart < self.f_opt:\n                self.f_opt = self.f_opt_restart\n                self.x_opt = self.x_opt_restart\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "423d220a-f8d9-40a3-8c2c-f6763007a89f", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "Evolve a population of solutions using a combination of differential evolution mutation, crossover, and selection, coupled with a niching strategy to maintain diversity and explore multiple local optima.", "code": "import numpy as np\n\nclass NicheDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, num_niches=5, F=0.5, CR=0.7, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_niches = num_niches\n        self.F = F\n        self.CR = CR\n        self.niche_radius = niche_radius\n\n        self.niches = []  # List to store niche centers\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize niches randomly\n        for _ in range(self.num_niches):\n            self.niches.append(np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim))\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose a niche to focus on (either the closest or a random one)\n                distances = np.array([np.linalg.norm(population[i] - niche) for niche in self.niches])\n                closest_niche_index = np.argmin(distances)\n                \n                if np.random.rand() < 0.8: #Probability to exploit the nearest niche\n                    chosen_niche_index = closest_niche_index\n                else: #Otheriwse explore by picking random niche\n                    chosen_niche_index = np.random.randint(0, self.num_niches)\n\n                # Mutation (DE within the chosen niche)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update the chosen niche center if the new point is close enough\n                    if np.linalg.norm(trial - self.niches[chosen_niche_index]) < self.niche_radius:\n                        self.niches[chosen_niche_index] = trial.copy()\n\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "objective": -0.62441, "other_inf": null}
{"id": "452290ff-50c0-4ac3-bbed-0cbe236cb004", "parents": ["a836adbe-2ef2-4b7b-8135-9793aefd502d", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "# Description: A population-based algorithm that iteratively refines solutions by learning from successful individuals and exploring new regions based on distance-weighted averaging.\n# Code:\n```", "code": "import numpy as np\n\nclass DistanceWeightedExploration:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Learn from top individuals\n            num_elites = max(1, self.pop_size // 5)\n            elites = population[:num_elites]\n\n            for i in range(self.pop_size):\n                # Distance-weighted average for exploration\n                distances = np.linalg.norm(elites - population[i], axis=1)\n                weights = np.exp(-distances)\n                weights /= np.sum(weights)  # Normalize weights\n\n                new_x = np.sum(elites * weights[:, np.newaxis], axis=0)\n                # Add a random exploration component\n                exploration_factor = 0.1\n                new_x += exploration_factor * np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                f = func(new_x)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_x\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.36038, "other_inf": null}
{"id": "215fe9b8-df3b-4c7b-9da9-65c5e2e91723", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A particle swarm optimization with velocity clamping and constriction factor to balance exploration and exploitation, and adaptive inertia weight to adjust particle influence over time.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.velocity_clamp = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n                \n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = population[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i]\n                        global_best_position = population[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.31792, "other_inf": null}
{"id": "45aa696b-f808-4b1e-aaa0-26f2dd2b8190", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A hybrid algorithm combining differential evolution with a local search strategy using a dynamically adjusted step size to refine solutions found by DE.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5\n        self.CR = 0.9\n        self.local_search_prob = local_search_prob\n\n    def local_search(self, func, x, step_size):\n        x_new = x + np.random.normal(0, step_size, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.budget -= 1\n        return f_new, x_new\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    step_size = np.std(population[:, i]) if np.std(population[:, i]) > 0 else 0.1\n                    f_local, x_local = self.local_search(func, population[i], step_size)\n                    if f_local < fitness[i]:\n                        fitness[i] = f_local\n                        population[i] = x_local\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "54e099c3-4721-4b4d-acaa-eec6675b736b", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A self-organizing migrating algorithm (SOMA) with adaptive step size and migration length to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = 0.1  # Initial step size\n        self.path_length = 2.0  # Initial path length\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Leader selection (find the best individual)\n                leader_idx = np.argmin(fitness)\n                leader = population[leader_idx]\n                \n                # Migration\n                for j in range(self.pop_size):\n                    if i == j:\n                        continue\n                    \n                    # Generate new candidate based on SOMA migration\n                    direction_vector = leader - population[j]\n                    num_steps = int(self.path_length / self.step_size)\n                    \n                    for step in range(1, num_steps + 1):\n                        new_position = population[j] + self.step_size * step * direction_vector\n                        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                        f = func(new_position)\n                        self.budget -= 1\n                        \n                        if f < fitness[j]:\n                            fitness[j] = f\n                            population[j] = new_position\n                            \n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = new_position\n                        \n                        if self.budget <= 0:\n                            break\n                    if self.budget <= 0:\n                        break\n            # Adapt step size and path length (simple heuristic)\n            if np.random.rand() < 0.1:\n                self.step_size *= np.random.uniform(0.8, 1.2)\n                self.path_length *= np.random.uniform(0.8, 1.2)\n                self.step_size = np.clip(self.step_size, 0.01, 0.5)  # reasonable bounds\n                self.path_length = np.clip(self.path_length, 0.5, 3.0)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "59660b81-f8ba-4779-a938-9636d94abde5", "parents": ["c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "# Description: This algorithm uses a particle swarm optimization approach with velocity clamping and dynamic inertia weight adjustment based on swarm convergence.\n# Code:\n```", "code": "import numpy as np\n\nclass DynamicParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = (self.ub - self.lb) * 0.2  # Clamp velocity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find best initial global solution\n        best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[best_index].copy()\n        self.f_opt = personal_best_fitnesses[best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            # Update inertia weight dynamically\n            inertia = self.inertia * (0.5 + 0.5 * np.exp(-np.std(personal_best_fitnesses)))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                fitness = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i].copy()\n            \n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": -0.29623, "other_inf": null}
{"id": "c281ede7-b3ee-41fb-9dfd-17f4c45fcf6c", "parents": ["c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "This algorithm employs a variant of particle swarm optimization (PSO) with velocity clamping and dynamic inertia weight adaptation based on swarm diversity.", "code": "import numpy as np\n\nclass ClampedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                # Find global best\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best_position = personal_best_positions[global_best_index]\n\n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                \n                population[i] = new_position\n\n            # Adapt inertia dynamically (example - based on fitness variance)\n            fitness_std = np.std(personal_best_fitness)\n            if fitness_std > 0.1:  # Example threshold\n                self.inertia = np.clip(self.inertia + np.random.normal(0, 0.02), 0.4, 0.9)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.54959, "other_inf": null}
{"id": "08df66a4-9427-40ae-8a00-19c806c5ea62", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "A differential evolution algorithm with a modified update rule that incorporates information from the best solution found so far to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index]\n        best_fitness = fitness[best_index]\n\n        self.f_opt = best_fitness\n        self.x_opt = best_position\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose three distinct individuals\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                np.random.shuffle(indices)\n                a, b, c = indices[:3]\n\n                # Create a trial vector\n                trial_vector = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                         trial_vector[j] = population[i][j] + self.F * (best_position[j] - population[i][j]) + self.F * (population[a][j] - population[b][j])\n\n                # Clip the trial vector to the bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector\n\n                    # Update best solution found so far\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_position = trial_vector\n                        self.f_opt = best_fitness\n                        self.x_opt = best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.47636, "other_inf": null}
{"id": "5dfb557b-4b5c-4acc-afa1-20e94572d660", "parents": ["c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "This algorithm employs a population-based approach using a modified Particle Swarm Optimization (PSO) with velocity clamping and dynamic inertia weight adjustment based on swarm diversity.", "code": "import numpy as np\n\nclass ModifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max  # Maximum velocity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial solution (global best)\n        best_index = np.argmin(personal_best_fitness)\n        if personal_best_fitness[best_index] < self.f_opt:\n            self.f_opt = personal_best_fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Calculate global best position\n            global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.inertia * velocities[i]\n                                + self.c1 * r1 * (personal_best_positions[i] - population[i])\n                                + self.c2 * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                new_velocity = np.clip(new_velocity, -self.v_max, self.v_max)\n                velocities[i] = new_velocity\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Boundary handling\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                # Evaluate fitness\n                f_new = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f_new < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_new\n                    personal_best_positions[i] = new_position\n                    \n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position\n\n            # Dynamic inertia weight adjustment (based on swarm diversity)\n            diversity = np.std(personal_best_fitness)\n            if diversity < 0.1:  # If swarm is converging\n                self.inertia *= 0.95  # Reduce inertia to encourage exploration\n            else:\n                self.inertia = min(self.inertia * 1.05, 0.9) #Increase inertia to encourage exploration\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": -0.24459, "other_inf": null}
{"id": "88abd178-840f-4769-ace1-c41df9e29aa7", "parents": ["c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired approach, simplifying the update rules for faster adaptation and reduced computational cost, while retaining the core idea of learning a distribution over promising solutions.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=1.0, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma  # Overall standard deviation\n        self.mean = np.zeros(dim)  # Mean of the search distribution\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cs = cs\n        self.c_cov = c_cov\n        self.pc = np.zeros(dim)  # Evolution path for the mean\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Sample population\n            population = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n            population = np.clip(population, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget]\n                population = population[:self.pop_size + self.budget]\n            \n            # Find best solution in population\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update distribution parameters\n            \n            # Weighted recombination\n            weights = np.sort(np.random.rand(len(fitness)))[::-1]  #random weights for recombination (can be adapted)\n            weights = weights / np.sum(weights)\n            x_mean = np.sum(population * weights[:, None], axis=0)\n\n            # Update evolution path\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * (x_mean - self.mean) / self.sigma\n\n            # Update mean\n            self.mean = x_mean\n            \n            # Simple variance adaptation based on path length\n            self.sigma *= np.exp(self.c_cov/2 * (np.linalg.norm(self.pc)**2 - self.dim)/self.dim)\n            self.sigma = max(min(self.sigma,10), 0.001) # Clip sigma\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.16149, "other_inf": null}
{"id": "064663ca-c4e0-4260-88a3-abe8b581a841", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A covariance matrix adaptation evolution strategy with a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter +=1\n\n            if self.budget <= 0:\n                break\n                \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n            \n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n            \n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n            \n            # Update covariance matrix\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n            for i in range(self.mu):\n                C += self.ccov * self.weights[i] * (z[i, :, None] @ z[i, None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = self.sigma0\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.73813, "other_inf": null}
{"id": "daeea80f-27b5-4934-88d7-5b083f051a21", "parents": ["c0808515-c88c-42c6-9861-4830e0468958", "423d220a-f8d9-40a3-8c2c-f6763007a89f"], "algorithm": "# Description: This algorithm iteratively refines a single solution by applying Gaussian mutations and accepting the new solution if it improves the fitness or satisfies a simulated annealing-like acceptance probability.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, initial_std=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_std = initial_std\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        std = self.initial_std\n        temperature = 1.0\n\n        while self.budget > 0:\n            # Mutation\n            x_new = np.clip(x + np.random.normal(0, std, size=self.dim), self.lb, self.ub)\n\n            # Evaluate new solution\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Acceptance criterion (Simulated Annealing)\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                f = f_new\n            else:\n                delta = f_new - f\n                acceptance_probability = np.exp(-delta / temperature)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n            \n            # Reduce standard deviation and temperature\n            std *= self.cooling_rate\n            temperature *= self.cooling_rate\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.27541, "other_inf": null}
{"id": "9b6f4460-53b4-4bfc-a80c-41d949f073ba", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "c0808515-c88c-42c6-9861-4830e0468958"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n        \n        temp = self.initial_temp\n        acceptance_rate = 0.0\n        acceptance_count = 0\n\n        while self.budget > 0 and temp > self.temp_min:\n            # Generate neighbor solution\n            new_x = current_x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n            new_x = np.clip(new_x, self.lb, self.ub)  # Clip to bounds\n            \n            new_f = func(new_x)\n            self.budget -= 1\n            \n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                current_x = new_x\n                current_f = new_f\n                acceptance_count +=1\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n\n            #Adaptive Temperature Cooling\n            acceptance_rate = acceptance_count / (self.budget + acceptance_count) if (self.budget + acceptance_count) > 0 else 0.0\n            if acceptance_rate > 0.5:\n                temp *= 0.9 #cool more slowly\n            else:\n                temp *= self.cooling_rate #cool faster\n\n        return self.f_opt, self.x_opt", "objective": -0.17309, "other_inf": null}
{"id": "b30cac38-829e-48a7-9ac0-58c06e2197d0", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) inspired algorithm with simplified adaptation rules and restart mechanism for exploration.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.mean = None\n        self.C = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = 100  # Threshold for stagnation detection\n        self.stagnation_counter = 0\n    \n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        mu = self.pop_size // 4\n\n        while self.budget > 0:\n            # Sample population\n            population = self.sample_population()\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate fitness\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            population = population[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n                \n            # Update mean\n            delta_mean = np.sum(weights[:mu, None] * (population[:mu] - self.mean), axis=0)\n            self.mean += delta_mean\n\n            # Rank-one update of covariance matrix\n            self.C = (1 - 0.1) * self.C + 0.1 * delta_mean[:, None] @ delta_mean[None, :] / (self.sigma**2)\n\n            # Update step size\n            self.sigma *= np.exp(0.2 * (np.mean(fitness) - fitness[0]) / np.std(fitness))\n            self.sigma = np.clip(self.sigma, 1e-10, 1) # Avoid sigma explosion\n\n            # Check for stagnation and restart\n            if self.stagnation_counter > self.restart_trigger:\n                self.initialize(func)\n                self.stagnation_counter = 0\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.46998, "other_inf": null}
{"id": "255cc6b7-ac61-46ca-93c7-39415ee09d13", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "423d220a-f8d9-40a3-8c2c-f6763007a89f"], "algorithm": "# Description: Iteratively refine promising regions by sampling within shrinking hyperrectangles centered around elite solutions and adaptively adjusting hyperrectangle dimensions based on fitness improvements.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveHyperrectangleSearch:\n    def __init__(self, budget=10000, dim=10, num_elite=5, initial_side_length=1.0, shrink_factor=0.9, expand_factor=1.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_elite = num_elite\n        self.initial_side_length = initial_side_length\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.elite_solutions = []\n        self.elite_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize with random samples\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_elite, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.num_elite\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        self.elite_solutions = population.tolist()\n        self.elite_fitness = fitness.tolist()\n\n        side_lengths = np.full(self.dim, self.initial_side_length)\n\n        while self.budget > 0:\n            # Sort elite solutions by fitness\n            sorted_indices = np.argsort(self.elite_fitness)\n            self.elite_solutions = [self.elite_solutions[i] for i in sorted_indices]\n            self.elite_fitness = [self.elite_fitness[i] for i in sorted_indices]\n\n            # Sample within hyperrectangles around elite solutions\n            for i in range(self.num_elite):\n                center = self.elite_solutions[i]\n                lb = np.clip(center - side_lengths / 2, func.bounds.lb, func.bounds.ub)\n                ub = np.clip(center + side_lengths / 2, func.bounds.lb, func.bounds.ub)\n                \n                x = np.random.uniform(lb, ub)\n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                # Update elite solutions if better\n                if f < self.elite_fitness[-1]:\n                    self.elite_fitness[-1] = f\n                    self.elite_solutions[-1] = x.tolist()\n                    \n                    #Adjust the hyperrectangle side length if improvement is found\n                    side_lengths *= self.shrink_factor #Shrink the hyperrectangle\n\n                else:\n                    side_lengths *= self.expand_factor # Expand the hyperrectangle if no improvement is found\n                    \n                side_lengths = np.clip(side_lengths, 1e-6, func.bounds.ub - func.bounds.lb)  # Avoid zero side length\n                    \n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.3009, "other_inf": null}
{"id": "80e8e257-016f-4e72-9705-47dfd1fc76ee", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A population-based algorithm that combines the exploration of particle swarm optimization with the exploitation of differential evolution using a dynamic learning strategy.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F # Mutation factor\n        self.CR = CR # Crossover rate\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = np.array([func(x) for x in population])\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n\n        self.budget -= self.pop_size\n        \n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                              self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                              self.c2 * r2 * (global_best_position - population[i])\n\n                # Update position\n                population[i] = np.clip(population[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate fitness\n                fitness = func(trial)\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = trial\n\n                    # Update global best\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = trial\n                        \n                        if fitness < self.f_opt:\n                            self.f_opt = fitness\n                            self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.55848, "other_inf": null}
{"id": "3403bdc2-2d18-4bec-a2fd-0b8bd59e1686", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "423d220a-f8d9-40a3-8c2c-f6763007a89f"], "algorithm": "# Description: An adaptive population-based search that dynamically adjusts its search range and step size based on the observed fitness landscape and combines global and local search.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = initial_sigma\n        self.adaptation_rate = adaptation_rate\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n         self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.population])\n         self.budget -= self.pop_size\n         if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Generate offspring by sampling from a normal distribution around each parent\n            offspring = self.population + np.random.normal(0, self.sigma, size=(self.pop_size, self.dim))\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Select the best individuals from the parent and offspring populations\n            combined_population = np.concatenate((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n            \n            idx = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[idx]\n            self.fitness = combined_fitness[idx]\n\n            # Update the best solution found so far\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            # Adapt the step size based on the success rate\n            success_rate = np.sum(offspring_fitness < self.fitness) / self.pop_size\n            if success_rate > 0.2:\n                self.sigma *= (1 + self.adaptation_rate)\n            elif success_rate < 0.1:\n                self.sigma *= (1 - self.adaptation_rate)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.66683, "other_inf": null}
{"id": "f7566f25-804e-4a4b-a9dd-66d5144b06bc", "parents": ["423d220a-f8d9-40a3-8c2c-f6763007a89f", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "# Description: Iteratively refine promising regions by sampling new points around the best solutions found so far, adapting the sampling radius based on the success rate of finding better solutions.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSampling:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5, radius_decay=0.95, radius_increase=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n        self.radius_increase = radius_increase\n        self.success_threshold = success_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize\n        x_best = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f_best = func(x_best)\n        self.budget -= 1\n        self.f_opt = f_best\n        self.x_opt = x_best\n        radius = self.initial_radius\n        successes = 0\n        iterations = 0\n\n        while self.budget > 0:\n            # Sample around the best solution\n            x_new = np.clip(np.random.normal(x_best, radius, size=self.dim), func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            iterations += 1\n\n            # Update best solution\n            if f_new < f_best:\n                f_best = f_new\n                x_best = x_new\n                successes += 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                \n\n            # Adjust the sampling radius\n            if iterations > 10:\n                success_rate = successes / iterations\n                if success_rate > self.success_threshold:\n                    radius *= self.radius_increase  # Increase radius if successful\n                else:\n                    radius *= self.radius_decay  # Decrease radius if not successful\n                successes = 0\n                iterations = 0\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.53776, "other_inf": null}
{"id": "655a97e4-3f27-42c4-ac46-a6a2d22f4980", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A modified differential evolution algorithm with a linearly decreasing mutation factor and tournament selection to enhance exploration and exploitation balance over the optimization process.", "code": "import numpy as np\n\nclass ModifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F_initial = 0.7  # Initial mutation factor\n        self.F_final = 0.2    # Final mutation factor\n        self.CR = 0.9  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            F = self.F_initial + (self.F_final - self.F_initial) * generation / (self.budget + generation)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Tournament selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    # Tournament: Replace with a better random individual with certain probability.\n                    if np.random.rand() < 0.1:\n                        rand_idx = np.random.randint(0, self.pop_size)\n                        if fitness[rand_idx] < fitness[i]:\n                            fitness[i] = fitness[rand_idx]\n                            population[i] = population[rand_idx]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.74831, "other_inf": null}
{"id": "c9efc85a-e4fd-4447-afa5-23b90b3ec996", "parents": ["3403bdc2-2d18-4bec-a2fd-0b8bd59e1686"], "algorithm": "# Description: A differential evolution strategy with a dynamically adjusted mutation factor and crossover rate, promoting exploration and exploitation based on population diversity.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt F and CR based on population diversity\n            if self.budget <= 0:\n                break\n\n            diversity = np.std(self.fitness)\n            if diversity > 0.1:  # Example threshold, adjust as needed\n                self.F = np.clip(self.F + 0.01, 0.1, 0.9)\n                self.CR = np.clip(self.CR - 0.01, 0.1, 0.9)\n            else:\n                self.F = np.clip(self.F - 0.01, 0.1, 0.9)\n                self.CR = np.clip(self.CR + 0.01, 0.1, 0.9)\n                \n        return self.f_opt, self.x_opt", "objective": -0.58139, "other_inf": null}
{"id": "05ed7952-8be8-4a72-a9e4-2bb17b3db3b0", "parents": ["40894f3a-bde9-46a4-8c0a-6cdffdac93c4"], "algorithm": "An enhanced PSO with a dynamically adjusted constriction coefficient to control the balance between exploration and exploitation, along with a mutation operator to escape local optima.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=2.05, c2=2.05, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n\n        phi = self.c1 + self.c2\n        if phi > 4:\n            self.K = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n        else:\n            self.K = 1  # No constriction if phi is not greater than 4\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        if np.min(personal_best_fitness) < self.f_opt:\n            self.f_opt = np.min(personal_best_fitness)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_fitness)]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        global_best_fitness = np.min(personal_best_fitness)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.K * (velocities[i] +\n                                         self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                         self.c2 * r2 * (global_best_position - particles[i]))\n\n                # Velocity clamping\n                v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                \n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = particles[i]\n                        \n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.46235, "other_inf": null}
{"id": "3bbeb9a6-10c3-43d9-88f6-769912a4d824", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "This algorithm implements a simplified differential evolution strategy with adaptive parameter control based on success rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, F_adapt_rate=0.1, CR_adapt_rate=0.1, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.success_history_size = success_history_size\n        self.success_F_history = []\n        self.success_CR_history = []\n        self.success_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    self.success_count += 1\n                    \n                    self.success_F_history.append(self.F)\n                    self.success_CR_history.append(self.CR)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n                    \n            #Adapt parameters every generation after the initial burn-in of 10 generations\n            if len(self.success_F_history) >= self.success_history_size:\n                #Adapt F parameter\n                success_F_mean = np.mean(self.success_F_history[-self.success_history_size:])\n                self.F = self.F + self.F_adapt_rate * (success_F_mean - self.F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                \n                #Adapt CR parameter\n                success_CR_mean = np.mean(self.success_CR_history[-self.success_history_size:])\n                self.CR = self.CR + self.CR_adapt_rate * (success_CR_mean - self.CR)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.41031, "other_inf": null}
{"id": "1e01627e-af40-4b7c-b283-1143743b7028", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A self-organizing migrating algorithm (SOMA) with adaptive step size and migration length, focusing on gradual population convergence.", "code": "import numpy as np\n\nclass AdaptiveSOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = 0.1  # Initial step size\n        self.path_length = 2.0 # Initial path length\n        self.PRT = 0.1 # perturbation probability\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Find the leader (best individual)\n            leader_idx = np.argmin(fitness)\n            leader = population[leader_idx]\n\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if i == leader_idx:\n                    continue\n\n                # Migrate towards the leader\n                for j in range(1, int(self.path_length / self.step_size) + 1):\n                    new_position = population[i] + j * self.step_size * (leader - population[i])\n                    \n                    # Perturbation\n                    perturb_mask = np.random.rand(self.dim) < self.PRT\n                    new_position = np.where(perturb_mask, np.random.uniform(func.bounds.lb, func.bounds.ub, size = self.dim), new_position)\n                    \n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    f = func(new_position)\n                    self.budget -= 1\n                    if f < fitness[i]:\n                        fitness[i] = f\n                        new_population[i] = new_position\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = new_position\n                    if self.budget <= 0:\n                        break\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            #Adapt step size\n            self.step_size *= 0.99\n            self.path_length *= 0.99\n\n        return self.f_opt, self.x_opt", "objective": -0.3608, "other_inf": null}
{"id": "6a948212-8033-4159-b4a4-3ed48b9197cb", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A differential evolution algorithm with a modified mutation strategy that incorporates a self-adaptive parameter control for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.CR = CR\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Store best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Self-adaptive F and CR\n                F_i = np.random.normal(self.F, 0.1, 1)[0]\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = np.random.normal(self.CR, 0.1, 1)[0]\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n\n                # Select three random indices, different from each other and i\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                r1, r2, r3 = idxs\n\n                # Create mutant vector\n                mutant = population[r1] + F_i * (population[r2] - population[r3])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR_i\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.60237, "other_inf": null}
{"id": "bcac3f33-489e-47b0-b5c6-b86cc70c1acc", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A modified differential evolution algorithm with a smaller population size, a Cauchy-distributed mutation factor, and a rank-based selection to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass ModifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 20, dim * pop_multiplier)  # Smaller adaptive population size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            # Rank the population based on fitness\n            ranked_indices = np.argsort(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation (Cauchy distribution)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                #Cauchy distributed mutation factor\n                cauchy_F = self.F * np.random.standard_cauchy()\n                mutant = np.clip(a + cauchy_F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                #Rank-based selection: only update if better than the worst in top half\n                cutoff_rank = self.pop_size // 2\n                worst_in_top_half_idx = ranked_indices[cutoff_rank]\n                \n                if f < fitness[worst_in_top_half_idx]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.56417, "other_inf": null}
{"id": "1e4d0080-651a-45e9-9bbd-0a00e1dd2ae3", "parents": ["3403bdc2-2d18-4bec-a2fd-0b8bd59e1686"], "algorithm": "A differential evolution strategy with self-adaptive parameters and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n            \n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.budget -= 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.30794, "other_inf": null}
{"id": "8009aa65-2b03-4ed8-a342-bb7a85c6c488", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A simplified covariance matrix adaptation evolution strategy (CMA-ES) iteratively samples new solutions from a multivariate normal distribution, adapts the distribution's mean and covariance based on successful solutions, and focuses the search towards promising regions of the search space.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mean = None\n        self.sigma = 1.0\n        self.C = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) if self.mean is None else self.mean\n        self.C = np.eye(self.dim) if self.C is None else self.C\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            # Selection and update\n            idx = np.argsort(fitness)\n            x_sorted = x[idx[:self.mu]]\n            z_sorted = z[idx[:self.mu]]\n\n            self.mean = np.sum(self.weights[:, None] * x_sorted, axis=0)\n            \n            # Simplified covariance matrix adaptation\n            C_temp = np.sum(self.weights[:, None, None] * (z_sorted[:, :, None] @ z_sorted[:, None, :]), axis=0)\n            self.C = (1 - 0.1) * self.C + 0.1 * C_temp\n\n            # Update step size\n            self.sigma *= np.exp(0.2 * (np.mean(fitness[idx[:self.mu]]) - np.mean(fitness)) / np.std(fitness)) # Adjust step size adaptively\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.20531, "other_inf": null}
{"id": "941995f8-beb5-4fee-a3b5-8c39fc70dd6d", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "# Description: A Nelder-Mead simplex algorithm with adaptive parameters and a restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, alpha=1.0, beta=0.5, gamma=2.0, sigma=0.1, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha  # Reflection coefficient\n        self.beta = beta    # Contraction coefficient\n        self.gamma = gamma  # Expansion coefficient\n        self.sigma = sigma  # Shrink coefficient\n        self.restart_threshold = restart_threshold\n        self.restart_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_simplex(self, func):\n        simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n        fitness = np.array([func(x) for x in simplex])\n        self.budget -= self.dim + 1\n        return simplex, fitness\n\n    def __call__(self, func):\n        simplex, fitness = self.initialize_simplex(func)\n        \n        while self.budget > 0:\n            # Order the simplex\n            idx = np.argsort(fitness)\n            simplex = simplex[idx]\n            fitness = fitness[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = simplex[0]\n                self.restart_counter = 0\n            else:\n                self.restart_counter += 1\n            \n            if self.budget <= 0:\n                break\n\n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected = centroid + self.alpha * (centroid - simplex[-1])\n            reflected = np.clip(reflected, func.bounds.lb, func.bounds.ub)\n            f_reflected = func(reflected)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n            \n            if fitness[0] <= f_reflected < fitness[-2]:\n                simplex[-1] = reflected\n                fitness[-1] = f_reflected\n            else:\n                # Expansion\n                if f_reflected < fitness[0]:\n                    expanded = centroid + self.gamma * (reflected - centroid)\n                    expanded = np.clip(expanded, func.bounds.lb, func.bounds.ub)\n                    f_expanded = func(expanded)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_expanded < f_reflected:\n                        simplex[-1] = expanded\n                        fitness[-1] = f_expanded\n                    else:\n                        simplex[-1] = reflected\n                        fitness[-1] = f_reflected\n                else:\n                    # Contraction\n                    contracted = centroid + self.beta * (simplex[-1] - centroid)\n                    contracted = np.clip(contracted, func.bounds.lb, func.bounds.ub)\n                    f_contracted = func(contracted)\n                    self.budget -= 1\n                    \n                    if self.budget <= 0:\n                        break\n\n                    if f_contracted < fitness[-1]:\n                        simplex[-1] = contracted\n                        fitness[-1] = f_contracted\n                    else:\n                        # Shrink\n                        for i in range(1, self.dim + 1):\n                            simplex[i] = simplex[0] + self.sigma * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            fitness[i] = func(simplex[i])\n                            self.budget -= 1\n\n                            if self.budget <= 0:\n                                break\n                        if self.budget <= 0:\n                            break\n\n            if self.restart_counter > self.restart_threshold:\n                simplex, fitness = self.initialize_simplex(func)\n                self.restart_counter = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.51973, "other_inf": null}
{"id": "831867bc-c1c7-418f-b286-46bf094ae6cc", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "3403bdc2-2d18-4bec-a2fd-0b8bd59e1686"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to efficiently explore the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Strategy parameter setting: Selection\n        self.mu = self.pop_size // 2  # Number of parents/individuals for recombination\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Strategy parameter setting: Adaptation\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff)\n        self.ccov1 = min(1, self.ccov1 * (self.dim + 1.5) / (3 + (self.dim + 1.5) * self.ccovmu))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize dynamic (internal) strategy parameters and constants\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Mean value\n        P_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        P_C = np.zeros(self.dim)  # Evolution path for C\n        C = np.eye(self.dim)      # Covariance matrix\n        invC = np.linalg.inv(C)    # Inverse covariance matrix\n\n        while self.budget > 0:\n            # Generate and evaluate lambda offspring\n            Z = np.random.normal(0, 1, size=(self.pop_size, self.dim))  # iid Gaussian samples\n            Y = np.dot(Z, np.linalg.cholesky(C).T) # Samples from multivariate normal\n            X = mean + self.sigma * Y                 # Add mean\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x) for x in X])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = X[np.argmin(fitness)]\n\n            # Sort by fitness and compute weighted mean into mean\n            idx = np.argsort(fitness)\n            x_mu = X[idx[:self.mu]]\n            weights = self.weights\n            mean_new = np.sum(x_mu * weights[:, None], axis=0)\n\n            # Cumulation: Update evolution paths\n            y_mu = Y[idx[:self.mu]]\n            zmean = np.sum(y_mu * weights[:, None], axis=0)\n            P_sigma = (1 - self.cs) * P_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n            hsig = np.linalg.norm(P_sigma)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.budget)) / self.chiN < 1 + 2/(self.dim+1)\n\n            dC = np.outer(P_sigma, P_sigma)\n            P_C = (1-self.ccov1) * P_C + hsig * np.sqrt(self.ccov1 * (2-self.ccov1) * self.mueff) * zmean\n            C = (1 - self.ccov1 - self.ccovmu) * C + self.ccov1 * dC + self.ccovmu * np.dot(y_mu.T, np.diag(weights)).dot(y_mu)\n\n            # Adapt step size sigma\n            self.sigma = self.sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(P_sigma)/self.chiN - 1))\n\n            # Update mean\n            mean = mean_new\n\n            # Repair covariance matrix\n            C = np.triu(C) + np.triu(C, 1).T\n            C = (C + C.T) / 2\n            try:\n                np.linalg.cholesky(C)\n                invC = np.linalg.inv(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n                invC = np.eye(self.dim)\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "84b282cf-a039-4ccd-a26d-094cb4df0bdf", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "Simulated Annealing with adaptive temperature schedule and re-annealing to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, reannealing_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.reannealing_prob = reannealing_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        if current_f < self.f_opt:\n            self.f_opt = current_f\n            self.x_opt = current_x\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = current_x + np.random.normal(0, 0.1, size=self.dim)  # Adjust step size as needed\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                current_x = new_x\n                current_f = new_f\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n\n            # Temperature update\n            temperature *= self.cooling_rate\n\n            # Re-annealing\n            if np.random.rand() < self.reannealing_prob:\n                temperature = self.initial_temp\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.21853, "other_inf": null}
{"id": "d2afedb4-900e-426d-a56a-c406d3b6f236", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "A population-based algorithm that uses a combination of global random search and local search around the best solution found so far, with adaptive step size control.", "code": "import numpy as np\n\nclass GlobalLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.step_size = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.f_opt:\n            self.f_opt = fitness[best_idx]\n            self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Global search: Randomly select a solution and perturb it\n            idx = np.random.randint(0, self.pop_size)\n            x = population[idx] + self.step_size * np.random.normal(0, 1, self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = func(x)\n            self.budget -= 1\n\n            if f < fitness[idx]:\n                fitness[idx] = f\n                population[idx] = x\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.step_size *= 0.95 # reduce step size when finding better solution\n\n            # Local search around the best solution\n            for _ in range(self.local_steps):\n                x_local = self.x_opt + self.step_size * np.random.normal(0, 1, self.dim)\n                x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    self.step_size *= 0.95  # reduce step size when finding better solution\n\n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n            if self.step_size < 1e-5:\n                self.step_size = 0.1\n\n        return self.f_opt, self.x_opt", "objective": -0.29458, "other_inf": null}
{"id": "8ff5ba0f-0e2c-4ae0-80c7-5d59955d200f", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980", "3403bdc2-2d18-4bec-a2fd-0b8bd59e1686"], "algorithm": "A population-based algorithm that uses a combination of global random search and local gradient-based refinement, adaptively switching between the two based on performance.", "code": "import numpy as np\n\nclass HybridSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5, exploration_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.exploration_prob = exploration_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def local_refinement(self, func, x, steps):\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.budget -= 1\n        if f_current < self.f_opt:\n            self.f_opt = f_current\n            self.x_opt = x_current\n        \n        for _ in range(steps):\n            gradient = np.random.uniform(-0.1, 0.1, size=self.dim)\n            x_new = np.clip(x_current - 0.01 * gradient, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                x_current = x_new\n                f_current = f_new\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x_current\n            else:\n                break\n\n            if self.budget <= 0:\n                break\n        return x_current, f_current\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Global Search: Replace with a random point\n                    x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    f_new = func(x_new)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.population[i] = x_new\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = x_new\n                else:\n                    # Local Search: Gradient-based refinement\n                    self.population[i], self.fitness[i] = self.local_refinement(func, self.population[i], self.local_steps)\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.13384, "other_inf": null}
{"id": "a34845e7-388c-430e-ac3a-e058aeee096d", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm employing a stochastic ranking and selection mechanism to balance exploration and exploitation, prioritizing fitter individuals while allowing for occasional diversification through less fit ones.", "code": "import numpy as np\n\nclass StochasticRankingEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, rank_probability=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.rank_probability = rank_probability\n        self.F = 0.7\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Stochastic Ranking Selection\n                if (f < fitness[i] or np.random.rand() < self.rank_probability):\n                    new_fitness[i] = f\n                    new_population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            population = np.copy(new_population)\n            fitness = np.copy(new_fitness)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.29589, "other_inf": null}
{"id": "b1c9d71a-db16-4362-9200-c2b5c5964b00", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm employing a Gaussian process surrogate model to guide the search, iteratively refining the model with promising candidate solutions.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, acquisition_function='ucb', kappa=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.acquisition_function = acquisition_function\n        self.kappa = kappa\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def acquisition(self, X, gpr):\n        mu, sigma = gpr.predict(X, return_std=True)\n        if self.acquisition_function == 'ucb':\n            return mu - self.kappa * sigma  # Minimize -ucb for maximization\n        elif self.acquisition_function == 'ei':\n            from scipy.stats import norm\n            best = np.min(self.y)\n            z = (best - mu) / sigma\n            return mu + sigma * norm.pdf(z) / norm.cdf(z) # Minimize -EI\n        else:\n            return mu\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial sampling\n        X_initial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n        self.budget -= self.n_initial_samples\n        \n        self.X = X_initial\n        self.y = y_initial\n        \n        if np.min(self.y) < self.f_opt:\n            self.f_opt = np.min(self.y)\n            self.x_opt = self.X[np.argmin(self.y)]\n\n        # Gaussian process regression\n        kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n        self.gpr.fit(self.X, self.y)\n        \n        while self.budget > 0:\n            # Find next point to evaluate\n            from scipy.optimize import minimize\n            \n            def acquisition_wrapper(x):\n                return self.acquisition(x.reshape(1, -1), self.gpr)[0]\n\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n            bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n            res = minimize(acquisition_wrapper, x0, bounds=bounds, method='L-BFGS-B')\n            x_new = res.x\n            \n            # Evaluate the function\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            # Update data\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n            \n            # Update Gaussian process\n            self.gpr.fit(self.X, self.y)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "1e4f13dc-9ef7-410b-be76-a58434d80ead", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success rate of mutations and uses a population archive to maintain diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update optimal solution\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.zeros(self.pop_size)\n            success_count = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    self.success_history.append(True)\n                    success_count+=1\n                    # Archive successful mutants\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial)\n                    else:\n                        idx = np.random.randint(self.archive_size)\n                        self.archive[idx] = trial\n\n                else:\n                     self.success_history.append(False)\n                     new_population[i] = population[i] # Keep parent\n                     new_fitness[i] = fitness[i]\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adapt parameters\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                self.success_F = []\n                self.success_CR = []\n                # Adjust bounds to avoid infeasible parameters\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            #Diversity Maintenance\n            if len(self.archive) > 0:\n                for i in range(self.pop_size):\n                    if np.random.rand() < 0.1:  # Low probability to add archive element\n                        archived_individual = self.archive[np.random.randint(len(self.archive))]\n                        population[i] = archived_individual\n                        fitness[i] = func(archived_individual)\n                        self.budget -=1\n\n                        if fitness[i] < self.f_opt:\n                           self.f_opt = fitness[i]\n                           self.x_opt = archived_individual\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "60bad1c3-49cb-47ed-a026-694fedeede5a", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A particle swarm optimization algorithm with velocity clamping and adaptive inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(func.bounds.ub - func.bounds.lb), abs(func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / (self.budget + self.pop_size))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                social_velocity = self.social_coeff * r2 * (global_best_position - population[i])\n                velocities[i] = inertia * velocities[i] + cognitive_velocity + social_velocity\n                \n                # Velocity clamping (optional, but can improve stability)\n                max_velocity = 0.1 * abs(func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                f = func(new_position)\n                self.budget -= 1\n\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = new_position\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_position\n                        global_best_position = new_position.copy()  # Update global best position\n\n                population[i] = new_position\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.57145, "other_inf": null}
{"id": "9e08d41c-56d2-4221-85d1-516b6ca2388d", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "An improved adaptive differential evolution strategy incorporating a restart mechanism to escape local optima and a dynamically adjusted crossover rate based on the fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5\n        self.CR = 0.9\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n            self.stagnation_counter = 0\n        else:\n            self.stagnation_counter +=1\n        \n        while self.budget > 0:\n            best_fitness_before_gen = self.f_opt\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if np.random.rand() < 0.1:\n                        self.F = np.random.uniform(0.4, 0.9)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.stagnation_counter = 0\n                        self.CR = min(0.99, self.CR + 0.02)\n                else:\n                    self.CR = max(0.1, self.CR - 0.01)\n            \n                if self.budget <= 0:\n                    break\n\n            if self.f_opt >= best_fitness_before_gen:\n                self.stagnation_counter +=1\n            \n            if self.stagnation_counter > self.max_stagnation and self.budget > self.pop_size:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.46605, "other_inf": null}
{"id": "990cf5c6-1149-436b-b274-2f8d9e8bf685", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A modified differential evolution with a decaying mutation factor and tournament selection to enhance convergence while maintaining exploration.", "code": "import numpy as np\n\nclass DecayingDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.7  # Initial mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.decay_rate = decay_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection (Tournament)\n                f = func(trial)\n                self.budget -= 1\n\n                j = np.random.randint(0, self.pop_size)\n                if f < fitness[j]:\n                    if f < fitness[i]:\n                        fitness[i] = f\n                        population[i] = trial\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial\n\n\n            self.F *= self.decay_rate # Decay mutation factor\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.60099, "other_inf": null}
{"id": "9d3b9c50-367d-4743-bbcc-ca0ed7a240fa", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) with a simplified update rule for the covariance matrix to reduce computational complexity, focusing on adapting step size and principal axes of the search distribution based on successful search steps.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cs=0.3, damps=1.0, cc=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = 0.5  # Overall step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.cs = cs  # Step-size damping factor\n        self.damps = damps  # Damping for step-size\n        self.cc = cc  # Time constant for cumulation\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.mean = np.zeros(dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean[:, np.newaxis] + y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n            x = x.T\n\n            # Evaluate fitness\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update mean\n            xmean = np.mean(x[:self.pop_size // 2], axis=0)\n            ymean = xmean - self.mean\n            zmean = np.linalg.solve(np.linalg.cholesky(self.C), ymean * (1/self.sigma))\n            self.mean = xmean\n            \n\n            # Update evolution path\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * zmean\n\n            # Simplified rank-one update\n            self.C = (1 - self.cc) * self.C + self.cc * np.outer(self.pc, self.pc)\n\n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / np.sqrt(self.dim) - 1))\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b7f1afd6-a592-4a9f-a5fe-b491f6f71d6f", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "A self-adaptive differential evolution algorithm that adjusts mutation and crossover rates based on the success of previous generations to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.5  # Initial crossover rate\n        self.F_memory = np.full(self.pop_size, self.F)\n        self.CR_memory = np.full(self.pop_size, self.CR)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n        success_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adapt F and CR\n                self.F = self.F_memory[i]\n                self.CR = self.CR_memory[i]\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    success_count += 1\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR memories\n            if success_count > 0:\n                mean_F = np.mean(success_F)\n                mean_CR = np.mean(success_CR)\n\n                self.F_memory = np.clip(np.random.normal(mean_F, 0.1, self.pop_size), 0.1, 1.0)\n                self.CR_memory = np.clip(np.random.normal(mean_CR, 0.1, self.pop_size), 0.0, 1.0)\n\n                success_F = []\n                success_CR = []\n                success_count = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.59256, "other_inf": null}
{"id": "bc86caed-f169-4b46-8491-e998a026aa76", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "A self-adaptive differential evolution strategy with a population archive to maintain diversity and dynamically adjust mutation and crossover rates based on individual success.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.archive_size = archive_size\n        self.F_mean = 0.5\n        self.CR_mean = 0.5\n        self.archive = []\n        self.p_selection = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F_mean, 0.1)\n                CR = np.random.normal(self.CR_mean, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0 and np.random.rand() < self.p_selection:\n                    donor_vector = self.archive[np.random.randint(len(self.archive))]\n                    a = population[np.random.choice(idxs, 1, replace=False)][0]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(a + F * (donor_vector - a) + F * (b - c), func.bounds.lb, func.bounds.ub)\n                else:\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    # Update population and fitness\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update adaptation parameters\n                    self.F_mean = 0.9 * self.F_mean + 0.1 * F\n                    self.CR_mean = 0.9 * self.CR_mean + 0.1 * CR\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.6601, "other_inf": null}
{"id": "ebb7fa80-0fa8-4b92-933e-dd2e500080ff", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "An enhanced differential evolution strategy with a decaying mutation factor and a dynamically adjusted crossover rate based on the success history of previous generations, aiming to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.7  # Initial mutation factor\n        self.CR = 0.5  # Initial Crossover rate\n        self.CR_memory = []  # Memory for successful CR values\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Decay mutation factor\n            self.F = 0.7 * (0.99 ** generation) # Decaying F\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    self.CR_memory.append(self.CR) # Store successful CR value\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    break\n                    \n            # Adjust CR based on memory\n            if self.CR_memory:\n                self.CR = np.mean(self.CR_memory)\n                self.CR_memory = [] # Reset memory after update\n            else:\n                self.CR = 0.5 # Default value if no successful CRs recorded\n\n        return self.f_opt, self.x_opt", "objective": -0.682, "other_inf": null}
{"id": "306f7c49-a138-496b-a2ce-75e1a578f508", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A Gaussian process-based optimization algorithm that uses Bayesian optimization with a radial basis function kernel to model the objective function and an acquisition function (Expected Improvement) to guide the search, iteratively selecting new points to evaluate.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_points=10, kernel=None, exploration_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = n_initial_points\n        self.exploration_factor = exploration_factor # Controls exploration-exploitation trade-off\n\n        if kernel is None:\n           self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5, alpha=1e-6)\n\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def expected_improvement(self, x, gp, evaluated_loss, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        sigma = np.maximum(sigma, 1e-9) # avoid division by zero\n        imp = evaluated_loss - mu\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gp, evaluated_loss, bounds, n_restarts=25):\n        def min_obj(x):\n            return -self.expected_improvement(x, gp, evaluated_loss)\n\n        best_location = None\n        best_ei = -np.inf\n\n        for _ in range(n_restarts):\n            start_point = np.random.uniform(bounds.lb, bounds.ub, size=self.dim)\n            res = minimize(min_obj, start_point, bounds=bounds, method='L-BFGS-B') # Changed to L-BFGS-B\n            if -res.fun > best_ei:\n                best_ei = -res.fun\n                best_location = res.x\n\n        return best_location\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_points, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_points\n\n        if np.min(self.y) < self.f_opt:\n            self.f_opt = np.min(self.y)\n            self.x_opt = self.X[np.argmin(self.y)]\n\n        self.gp.fit(self.X, self.y)\n\n        # Bayesian optimization loop\n        while self.budget > 0:\n            # Find next point to evaluate\n            x_next = self.propose_location(self.gp, np.min(self.y), func.bounds)\n\n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "6829bc77-561f-4e6b-9081-0a293e4719d9", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A particle swarm optimization (PSO) algorithm with velocity clamping and constriction factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.729, c1=1.49445, c2=1.49445, vmax_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.vmax_ratio = vmax_ratio\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.vmax_ratio, abs(ub-lb)*self.vmax_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        # Initialize global best position and value\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_values[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        \n        # PSO iterations\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            velocities = self.inertia * velocities + \\\n                         self.c1 * r1 * (personal_best_positions - particles) + \\\n                         self.c2 * r2 * (global_best_position - particles)\n\n            # Velocity clamping\n            vmax = abs(ub - lb) * self.vmax_ratio\n            velocities = np.clip(velocities, -vmax, vmax)\n            \n            particles += velocities\n\n            # Boundary handling\n            particles = np.clip(particles, lb, ub)\n            \n            # Evaluate particles\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n            \n            # Update personal best positions and values\n            improved_indices = fitness < personal_best_values\n            personal_best_positions[improved_indices] = particles[improved_indices].copy()\n            personal_best_values[improved_indices] = fitness[improved_indices].copy()\n            \n            # Update global best position and value\n            if np.min(personal_best_values) < self.f_opt:\n                self.f_opt = np.min(personal_best_values)\n                global_best_index = np.argmin(personal_best_values)\n                self.x_opt = personal_best_positions[global_best_index].copy()\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": -0.29699, "other_inf": null}
{"id": "6f404d44-6b1a-40a7-9f6b-d9ff2c57144b", "parents": ["ebb7fa80-0fa8-4b92-933e-dd2e500080ff", "655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "Simulated Annealing with adaptive temperature schedule and perturbation range based on function evaluation history to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.perturbation_range = 1.0  # Initial perturbation range\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = np.clip(current_x + np.random.uniform(-self.perturbation_range, self.perturbation_range, size=self.dim), func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                current_x = new_x\n                current_f = new_f\n                self.success_history.append(True)\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n            else:\n                self.success_history.append(False)\n\n            # Adaptive temperature schedule\n            temperature *= self.cooling_rate\n\n            # Adaptive perturbation range\n            if len(self.success_history) > 50:\n                success_rate = np.mean(self.success_history[-50:])\n                if success_rate > 0.6:\n                    self.perturbation_range *= 1.1  # Increase perturbation range if too many successes\n                elif success_rate < 0.4:\n                    self.perturbation_range *= 0.9  # Decrease perturbation range if too few successes\n                self.perturbation_range = np.clip(self.perturbation_range, 0.01, 2.0)  # Limit the perturbation range\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.37573, "other_inf": null}
{"id": "0510d7d6-61be-4267-952f-10a4b12cedcf", "parents": ["ebb7fa80-0fa8-4b92-933e-dd2e500080ff", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A swarm-based algorithm where particles adjust their positions based on personal best, global best, and a velocity incorporating a constriction factor to control convergence and prevent premature stagnation.", "code": "import numpy as np\n\nclass ConstrictionParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w=0.729, c1=1.49445, c2=1.49445):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.kappa = 1  # Constriction factor denominator\n        self.phi = self.c1 + self.c2\n        self.chi = 2 * self.kappa / abs(2 - self.phi - np.sqrt(self.phi**2 - 4 * self.phi)) if self.phi > 4 else 1\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        personal_best_positions = particles.copy()\n        personal_best_fitnesses = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitnesses[global_best_index]\n        self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (global_best_position - particles[i])\n                \n                velocities[i] = self.chi * (self.w * velocities[i] + cognitive_component + social_component)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i].copy()\n                        global_best_position = particles[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.51756, "other_inf": null}
{"id": "c6beac7c-2a0e-4a54-bb6b-a5d175f73f2f", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "An algorithm that iteratively refines promising regions by sampling and updating a Gaussian Mixture Model based on function values.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimisation:\n    def __init__(self, budget=10000, dim=10, n_components=5, n_samples=50):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.n_samples = n_samples\n        self.gmm = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initial sampling\n        initial_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_samples, self.dim))\n        initial_fitness = np.array([func(x) for x in initial_samples])\n        self.budget -= self.n_samples\n        \n        if np.min(initial_fitness) < self.f_opt:\n            self.f_opt = np.min(initial_fitness)\n            self.x_opt = initial_samples[np.argmin(initial_fitness)]\n\n        # Initialize GMM\n        self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)\n        self.gmm.fit(initial_samples, sample_weight = np.exp(-initial_fitness))\n\n        while self.budget > 0:\n            # Sample from GMM\n            samples, _ = self.gmm.sample(self.n_samples)\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate samples\n            fitness = np.array([func(x) for x in samples])\n            self.budget -= self.n_samples\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n            \n            # Update GMM\n            all_samples = np.vstack((initial_samples, samples))\n            all_fitness = np.hstack((initial_fitness, fitness))\n            \n            self.gmm.fit(all_samples, sample_weight = np.exp(-all_fitness))\n            \n            initial_samples = all_samples\n            initial_fitness = all_fitness\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "4383a200-4cdc-43bd-a9b5-db226353f83e", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm where individuals are evolved using a combination of differential evolution mutation and a gradient-based descent method to exploit local optima.", "code": "import numpy as np\n\nclass HybridDEGradient:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.01, de_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.de_weight = de_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(population[i] + 0.5 * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Gradient Descent\n                x = population[i].copy()\n                grad = self.estimate_gradient(func, x)\n                descent = np.clip(x - self.lr * grad, func.bounds.lb, func.bounds.ub)\n\n                # Hybrid Move\n                trial = self.de_weight * mutant + (1 - self.de_weight) * descent\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def estimate_gradient(self, func, x, h=1e-5):\n        grad = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_minus_h = x.copy()\n            x_plus_h[i] += h\n            x_minus_h[i] -= h\n            grad[i] = (func(x_plus_h) - func(x_minus_h)) / (2 * h)\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d308f2c2-1f31-49af-bb98-0d835b2667be", "parents": ["ebb7fa80-0fa8-4b92-933e-dd2e500080ff", "ebb7fa80-0fa8-4b92-933e-dd2e500080ff"], "algorithm": "# Description: A population-based algorithm that iteratively refines solutions by sampling from a distribution centered around the best-performing individuals, adjusting the sampling variance based on success.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveSamplingOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = 1.0  # Initial sampling variance\n        self.success_rate = 0.0\n        self.success_history = []\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Find the best individual\n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                # Sample from a Gaussian distribution centered around the best individual\n                x = np.random.normal(best_x, self.sigma, size=self.dim)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    \n                new_population.append(x)\n                new_fitness.append(f)\n\n                if self.budget <= 0:\n                    break\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n\n            # Calculate success rate\n            successful_indices = new_fitness < fitness\n            success_count = np.sum(successful_indices)\n            self.success_rate = success_count / self.pop_size\n\n            # Update sampling variance adaptively\n            self.sigma *= np.exp(self.learning_rate * (self.success_rate - 0.2))  # Adjust sigma\n            self.sigma = max(0.01, min(self.sigma, 2.0)) # Clip sigma\n\n            # Replace old population with new population\n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "objective": -0.32269, "other_inf": null}
{"id": "e401affe-f1a5-4535-964a-27ebdc587b9e", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm that evolves individuals by combining the best individual, a random individual, and the difference between two other individuals, with adaptive parameters and a diversity maintenance strategy.", "code": "import numpy as np\n\nclass HybridEvolutionaryAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=None, alpha=0.8, beta=0.1, gamma=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.diversity_threshold = diversity_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            idx = np.argsort(fitness)\n            population = population[idx]\n            fitness = fitness[idx]\n\n            # Generate new population\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Select random individuals\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_rand1, x_rand2, x_rand3 = population[idxs]\n\n                # Create new individual\n                new_individual = self.alpha * population[0] + self.beta * x_rand1 + self.gamma * (x_rand2 - x_rand3)\n                new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n\n                new_population[i] = new_individual\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection: replace if better\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i]\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_population[i]\n\n            # Diversity check and update parameters\n            if self.budget > 0:\n                diversity = np.std(population)\n                if diversity < self.diversity_threshold:\n                    # Increase exploration\n                    self.beta += 0.05\n                    self.gamma += 0.05\n                    self.alpha -= 0.1\n\n                else:\n                    # Increase exploitation\n                    self.beta -= 0.025\n                    self.gamma -= 0.025\n                    self.alpha += 0.05\n\n                self.alpha = np.clip(self.alpha, 0.0, 1.0)\n                self.beta = np.clip(self.beta, 0.0, 1.0)\n                self.gamma = np.clip(self.gamma, 0.0, 1.0)\n                \n                if np.abs(np.sum([self.alpha, self.beta, self.gamma]) - 1.0) > 1e-5:\n                  self.gamma = 1.0 - self.alpha - self.beta\n                  self.gamma = np.clip(self.gamma, 0.0, 1.0)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.26218, "other_inf": null}
{"id": "2770eea0-e06a-49c5-b018-49ccb3620473", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "# Description: An adaptive differential evolution algorithm that dynamically adjusts its mutation factor and crossover rate based on the population's diversity and the optimization progress.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_adaptive_factor = 0.1\n        self.CR_adaptive_factor = 0.1\n        self.diversity_threshold = 0.01\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR based on diversity\n            if diversity < self.diversity_threshold:\n                self.F += self.F_adaptive_factor\n                self.CR += self.CR_adaptive_factor\n            else:\n                self.F -= self.F_adaptive_factor / 2\n                self.CR -= self.CR_adaptive_factor / 2\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n                \n        return self.f_opt, self.x_opt", "objective": -0.4318, "other_inf": null}
{"id": "bea2ab43-63d5-49d7-8d2d-596bea5076fc", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A particle swarm optimization (PSO) algorithm with velocity clamping and constriction factor to control exploration and exploitation, combined with a local search strategy to refine promising solutions.", "code": "import numpy as np\n\nclass ParticleSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, clamp_factor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.clamp_factor = clamp_factor\n        self.constriction_factor = 1.0  # No constriction by default initially\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        \n        # Personal best positions and fitness values\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        # Global best position and fitness\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - particles) +\n                          self.social_coeff * r2 * (global_best_position - particles))\n\n            # Velocity clamping\n            v_max = self.clamp_factor * (func.bounds.ub - func.bounds.lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            particles = particles + velocities\n            particles = np.clip(particles, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n            \n            # Update personal best positions\n            improved_mask = fitness < personal_best_fitness\n            personal_best_fitness[improved_mask] = fitness[improved_mask]\n            personal_best_positions[improved_mask] = particles[improved_mask]\n\n            # Update global best position\n            best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[best_index] < global_best_fitness:\n                global_best_fitness = personal_best_fitness[best_index]\n                global_best_position = personal_best_positions[best_index]\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n            if self.budget <= 0:\n                break\n                \n        return self.f_opt, self.x_opt", "objective": -0.51689, "other_inf": null}
{"id": "d779d170-545b-40f9-8f53-154eb96b37c2", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A simplified CMA-ES variant that reduces computational complexity by skipping covariance matrix adaptation and relying on step-size adaptation and restarts to explore the search space, incorporating a dynamic population size adjustment.", "code": "import numpy as np\n\nclass Simplified_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=3, sigma0=0.5, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor\n        self.pop_size = 4 + int(self.pop_size_factor * np.log(dim))  # Initial population size\n        self.sigma0 = sigma0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        \n        while self.budget > 0:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = mean + sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            if self.budget <= 0:\n                break\n\n            idx = np.argsort(fitness)\n            mean = x[idx[0]]\n\n            sigma *= np.exp(0.5 * (np.mean(fitness) - self.f_opt) / self.f_opt)\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = self.sigma0\n                self.stagnation_counter = 0\n                self.pop_size = 4 + int(self.pop_size_factor * np.log(self.dim)) #Adjust population size\n\n        return self.f_opt, self.x_opt", "objective": -0.25405, "other_inf": null}
{"id": "614d1bfa-e1e8-486a-bc13-46d6fdfaa441", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A modified CMA-ES that incorporates a dynamic population size adjustment based on the success rate of the algorithm, and uses a simplified covariance matrix update for faster convergence.", "code": "import numpy as np\n\nclass DynamicCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.success_threshold = success_threshold\n        self.success_rate = 0.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        archive_fitness = []\n\n        while self.budget - self.eval_count > 0:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            archive_fitness.append(np.min(fitness))\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n\n            # Update covariance matrix (simplified)\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Dynamic population size adjustment\n            if len(archive_fitness) > 10:\n                improvements = [archive_fitness[i] - archive_fitness[i-1] for i in range(1, len(archive_fitness))]\n                self.success_rate = sum([i < 0 for i in improvements[-10:]]) / 10\n                \n                if self.success_rate > self.success_threshold and self.pop_size < 2 * (4 + int(3 * np.log(self.dim))): #Upper limit to pop size\n                    self.pop_size = min(self.pop_size + 2, 2 * (4 + int(3 * np.log(self.dim))))\n                    self.mu = int(self.pop_size * 0.25)\n                    self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                    self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                    self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                elif self.success_rate < (1 - self.success_threshold) and self.pop_size > 4: #Lower limit to pop size\n                    self.pop_size = max(self.pop_size - 2, 4)\n                    self.mu = int(self.pop_size * 0.25)\n                    self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                    self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                    self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "74da60a3-ea55-49e7-9bf1-6542570bdf9b", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to effectively explore the search space, focusing on promising regions based on successful steps.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.cs = (self.mu + 2) / (dim + self.mu + 5)\n        self.ds = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.cmu = min(1 - self.c1, 2 * (self.mu - 2 + 1/self.mu) / ((dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Generate population\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget] # Truncate evaluations\n                x = x[:, :self.pop_size + self.budget]\n\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n\n            # Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n            self.m = xmean\n\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.budget / self.pop_size)) < self.chiN * (1.4 + 2 / (self.dim + 1))\n            dhsig = (1 - hsig) * self.cc * (2 - self.cc)\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + dhsig * self.C) + self.cmu * np.dot((x[:, :self.mu] - self.m[:, np.newaxis]) * self.weights, (x[:, :self.mu] - self.m[:, np.newaxis]).T) / self.sigma**2\n\n            self.sigma *= np.exp((self.cs / self.ds) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f6b2cf47-bcaa-4e96-8cf3-ea9dffd9d821", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix to improve search direction and step size, coupled with a budget-aware population size adjustment.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 20, 4 + int(3 * np.log(dim)))  # Budget-aware population size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(-1, 1, size=dim)  # Initialize mean\n        self.sigma = 0.5  # Initialize step size\n        self.C = np.eye(dim)  # Initialize covariance matrix\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sig = (self.mu / (dim + self.mu**2))**0.5\n        self.d_sig = 1 + 2*max(0, ((self.mu-1)/(dim+1) - 1)) + self.c_sig\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n\n    def __call__(self, func):\n        \n        while self.budget > 0:\n            # Generate and evaluate lambda offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if np.any(fitness < self.f_opt):\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n            \n            # Update mean\n            m_old = self.m\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Cumulation\n            self.ps = (1 - self.c_sig) * self.ps + (self.c_sig * (self.dim)**0.5) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ (self.m - m_old) / self.sigma)\n            hsig = np.linalg.norm(self.ps) / (1 - (1 - self.c_sig)**(self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * (self.c_c * (self.dim)**0.5) * ((self.m - m_old) / self.sigma)\n\n            # Adapt covariance matrix\n            artmp = (1/self.sigma) * (x[:self.mu] - m_old).T\n            self.C = (1 - self.c_1 - self.c_mu + self.c_1 * self.c_c * (2 - hsig**2)) * self.C + self.c_1 * self.pc[:, None] @ self.pc[None, :] + self.c_mu * artmp @ np.diag(self.weights) @ artmp.T\n\n            # Adapt step size\n            self.sigma = self.sigma * np.exp((self.c_sig / self.d_sig) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "objective": -0.49881, "other_inf": null}
{"id": "b8d35367-e3ef-4200-a888-aa8dd31735a0", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with rank-one update and active covariance update to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov_rank_one=None, c_cov_mu=0.0):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + self.mueff + 5))\n        if c_cov_rank_one is None:\n            self.c_cov_rank_one = 1 / ((self.mueff + 2) / (self.dim + self.mueff + 5))\n        else:\n            self.c_cov_rank_one = c_cov_rank_one\n\n        self.c_cov_mu = c_cov_mu\n\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n        self.mean = np.random.uniform(low=-2, high=2, size=self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = None\n        self.D = None\n        self.invsqrtC = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def update_decomposition(self):\n        self.C = (self.C + self.C.T) / 2  # Ensure symmetry\n        self.D, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))  # Ensure positive values\n        self.invsqrtC = self.B @ np.diag(1 / self.D) @ self.B.T  # Inverse square root of C\n\n    def __call__(self, func):\n        self.update_decomposition()\n        while self.budget > 0:\n            # Generate samples\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T\n\n            # Clip x to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            \n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            y = self.invsqrtC @ (xmean - self.mean)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * self.invsqrtC @ (xmean - self.mean)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.budget / (self.pop_size*2)))) / np.sqrt(self.dim+1) < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.cs) * self.pc + hsig * np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean)\n\n            # Update covariance matrix\n            rank_one = np.outer(self.pc, self.pc)\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + self.c_cov_rank_one * rank_one + self.c_cov_mu * np.sum(self.weights[:, None, None] * (x[:self.mu] - self.mean)[:, :, None] * (x[:self.mu] - self.mean)[:, None, :], axis=0)\n            \n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / 0.817 - 1))\n            self.mean = xmean\n            self.update_decomposition()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "bcdb1515-44b3-43b6-8edf-6deb7cae1ed9", "parents": ["ebb7fa80-0fa8-4b92-933e-dd2e500080ff"], "algorithm": "A self-adaptive differential evolution strategy that adjusts both mutation factor and crossover rate based on the success rate of previous generations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, F_init=0.5, CR_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = F_init  # Initial mutation factor\n        self.CR = CR_init  # Initial Crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.success_threshold = 0.1\n        self.restart_trigger = 50 #restart if no improvement in n generations\n        self.no_improvement_counter = 0\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    self.F_memory.append(self.F)\n                    self.CR_memory.append(self.CR)\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR\n            if self.F_memory:\n                self.F = np.clip(np.mean(self.F_memory), 0.1, 0.9)\n                self.CR = np.clip(np.mean(self.CR_memory), 0.1, 0.9)\n                self.F_memory = []\n                self.CR_memory = []\n            else:\n                self.F = 0.5\n                self.CR = 0.9\n                \n            #Restart mechanism\n            if self.f_opt >= old_f_opt:\n                self.no_improvement_counter += 1\n            else:\n                self.no_improvement_counter = 0\n                \n            if self.no_improvement_counter > self.restart_trigger:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n                self.no_improvement_counter = 0\n                self.F = 0.5\n                self.CR = 0.9\n\n        return self.f_opt, self.x_opt", "objective": -0.7344, "other_inf": null}
{"id": "1411780d-f10b-4649-a8a3-f366b1b62b78", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980", "bcdb1515-44b3-43b6-8edf-6deb7cae1ed9"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of worse solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.temp = initial_temp\n        self.cooling_factor = cooling_factor\n        self.x_current = None\n        self.f_current = np.inf\n        self.acceptance_rate = 0.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        self.x_current = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_current = func(self.x_current)\n        self.budget -= 1\n        self.f_opt = self.f_current\n        self.x_opt = self.x_current\n        \n        accepted = 0\n        total = 0\n\n        while self.budget > 0:\n            x_new = self.x_current + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_e = f_new - self.f_current\n\n            if delta_e < 0:\n                self.x_current = x_new\n                self.f_current = f_new\n                accepted += 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n            else:\n                try:\n                    acceptance_probability = np.exp(-delta_e / self.temp)\n                except OverflowError:\n                    acceptance_probability = 0.0\n                if np.random.rand() < acceptance_probability:\n                    self.x_current = x_new\n                    self.f_current = f_new\n                    accepted += 1\n            total +=1\n            \n            #Adaptive Temperature Adjustment\n            self.acceptance_rate = accepted / total if total > 0 else 0.0\n            self.acceptance_history.append(self.acceptance_rate)\n            \n            if len(self.acceptance_history) > 10:\n                avg_acceptance_rate = np.mean(self.acceptance_history[-10:])\n                if avg_acceptance_rate > 0.5:\n                    self.temp *= 1.05 #Slow down cooling\n                elif avg_acceptance_rate < 0.1:\n                    self.temp *= 0.9 #Speed up cooling\n            \n            self.temp *= self.cooling_factor\n            self.temp = max(self.temp, 1e-6)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.34173, "other_inf": null}
{"id": "e0ac2935-1d70-4bc7-855d-fc25ac49d9a4", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A differential evolution strategy that leverages a population-based search with mutation, crossover, and selection to iteratively improve candidate solutions.", "code": "import numpy as np\n\nclass DifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.8, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        # Find best solution in the final population\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n          self.f_opt = fitness[best_index]\n          self.x_opt = population[best_index]\n        return self.f_opt, self.x_opt", "objective": -0.4931, "other_inf": null}
{"id": "f5151ed9-98fb-4ec8-87c9-fe572a4bbd1e", "parents": ["655a97e4-3f27-42c4-ac46-a6a2d22f4980", "655a97e4-3f27-42c4-ac46-a6a2d22f4980"], "algorithm": "Simulated Annealing with adaptive temperature and step size based on the success rate of finding better solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        success_count = 0\n        total_count = 0\n\n        while self.budget > 0:\n            x_new = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            delta_e = f_new - f\n            if delta_e < 0:\n                x = x_new\n                f = f_new\n                success_count += 1\n            else:\n                if np.random.rand() < np.exp(-delta_e / temp):\n                    x = x_new\n                    f = f_new\n            \n            total_count += 1\n            \n            if total_count % 100 == 0:\n                success_rate = success_count / total_count\n                if success_rate > 0.4:\n                    self.step_size *= 1.1\n                elif success_rate < 0.1:\n                    self.step_size *= 0.9\n                success_count = 0\n                total_count = 0\n\n            temp *= self.cooling_rate\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.28824, "other_inf": null}
{"id": "9e70f415-4683-40d8-9eb3-f9b50cc5c6a9", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) adapted to a limited budget by initializing the population using Latin Hypercube Sampling (LHS) and iteratively updating the covariance matrix and step size, while employing a rank-one update strategy to reduce computational cost.", "code": "import numpy as np\n\nclass BudgetCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + np.floor(3 * np.log(dim)))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.sigma = 0.3\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = 4/(self.dim + 4)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n    def latin_hypercube_sampling(self, n_samples, bounds):\n        lower_bounds, upper_bounds = bounds.lb, bounds.ub\n        n_dim = len(lower_bounds)\n        samples = np.zeros((n_samples, n_dim))\n        for i in range(n_dim):\n            p = (np.random.permutation(n_samples) + np.random.rand(n_samples)) / n_samples\n            samples[:, i] = lower_bounds[i] + p * (upper_bounds[i] - lower_bounds[i])\n        return samples\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # Initialize population using LHS\n        population = self.latin_hypercube_sampling(self.pop_size, func.bounds)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n\n            idx = np.argsort(fitness)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            z_mean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_mean\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n\n            h_sigma = norm_ps/np.sqrt(1-(1-self.c_sigma)**(2*(self.budget/self.pop_size))) < (1.4 + 2/(self.dim + 1))*self.chiN\n\n            delta = (1 - h_sigma) * self.c_c * (2 - self.c_c)\n\n            self.C = (1 - self.c_1 - self.c_mu + self.c_1 * delta) * self.C + \\\n                       self.c_1 * np.outer(self.pc, self.pc)\n\n        return self.f_opt, self.x_opt", "objective": -0.20966, "other_inf": null}
{"id": "df08bcac-2d51-41c9-9775-164d5cc24de2", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm using a Gaussian mixture model to sample new candidate solutions, adaptively adjusting the mixture components based on the fitness landscape and exploration-exploitation trade-off.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Fit Gaussian Mixture Model\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', random_state=0, max_iter=10, n_init=1)\n            gmm.fit(population)\n\n            # Sample new candidate solutions\n            new_population = gmm.sample(self.pop_size)[0]\n            new_population = np.clip(new_population, self.bounds_lb, self.bounds_ub)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Elitism: Keep the best individual from the previous population\n            best_index = np.argmin(fitness)\n            worst_index = np.argmax(new_fitness)\n            if fitness[best_index] < new_fitness[worst_index]:\n                new_fitness[worst_index] = fitness[best_index]\n                new_population[worst_index] = population[best_index]\n\n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "00674814-5686-4a02-8fa7-be79c321cc14", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "Iteratively refine a population of solutions by stochastically blending them with the best solution found so far, introducing diversity through random perturbations.", "code": "import numpy as np\n\nclass StochasticBlend:\n    def __init__(self, budget=10000, dim=10, pop_size=20, blend_rate=0.1, perturb_std=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.blend_rate = blend_rate\n        self.perturb_std = perturb_std\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Blend with best and perturb\n            for i in range(self.pop_size):\n                if np.random.rand() < self.blend_rate:\n                    population[i] = (1 - self.blend_rate) * population[i] + self.blend_rate * self.x_opt + np.random.normal(0, self.perturb_std, size=self.dim)\n                else:\n                    population[i] = population[i] + np.random.normal(0, self.perturb_std, size=self.dim)\n\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluate\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Update best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.28831, "other_inf": null}
{"id": "30651de6-b599-4449-9744-ccf24123f7f5", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm that evolves a set of solutions by perturbing them with a combination of global and local search strategies, dynamically adjusting the perturbation strength based on the success rate of recent moves.", "code": "import numpy as np\n\nclass PerturbationBasedOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=None, local_ratio=0.5, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 20\n        self.local_ratio = local_ratio\n        self.success_threshold = success_threshold\n        self.perturbation_strength = 0.1\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Select a solution to perturb\n                x = population[i].copy()\n                f = fitness[i]\n\n                # Perturb the solution using a combination of global and local search\n                if np.random.rand() < self.local_ratio:\n                    # Local search: perturb each dimension with a small random value\n                    perturbation = np.random.normal(0, self.perturbation_strength, size=self.dim)\n                    x_new = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n                \n                else:\n                    # Global search: select another random solution and move towards it\n                    j = np.random.randint(self.pop_size)\n                    x_other = population[j]\n                    x_new = np.clip(x + self.perturbation_strength * (x_other - x), func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new solution\n                f_new = func(x_new)\n                self.budget -= 1\n                \n                # Accept the new solution if it's better\n                if f_new < f:\n                    fitness[i] = f_new\n                    population[i] = x_new\n                    \n                    # Update success history\n                    self.success_history.append(True)\n                    \n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                else:\n                    self.success_history.append(False)\n\n                # Adjust perturbation strength based on success rate\n                if len(self.success_history) > 50:\n                    success_rate = np.mean(self.success_history[-50:])\n                    if success_rate > self.success_threshold:\n                        self.perturbation_strength *= 1.1  # Increase perturbation strength\n                    else:\n                        self.perturbation_strength *= 0.9  # Decrease perturbation strength\n                    self.perturbation_strength = np.clip(self.perturbation_strength, 0.01, 1.0)  # Limit range\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.40804, "other_inf": null}
{"id": "f56ab5f3-7421-4be4-8ffe-645919c11e3c", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621", "df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "An iterative refinement algorithm that combines global exploration with local exploitation by generating candidate solutions through random walks and Gaussian perturbations, adaptively adjusting the step size based on success rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveRandomWalk:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.budget -= 1\n        \n        while self.budget > 0:\n            self.iteration += 1\n            # Random Walk\n            x_new_rw = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new_rw = np.clip(x_new_rw, func.bounds.lb, func.bounds.ub)\n            \n            # Gaussian Perturbation\n            x_new_gauss = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new_gauss = np.clip(x_new_gauss, func.bounds.lb, func.bounds.ub)\n            \n            f_rw = func(x_new_rw)\n            self.budget -= 1\n            \n            if f_rw < self.f_opt:\n                self.f_opt = f_rw\n                self.x_opt = x_new_rw\n                x = x_new_rw\n                self.success_count += 1\n                \n            elif self.budget > 0:\n                f_gauss = func(x_new_gauss)\n                self.budget -= 1\n            \n                if f_gauss < self.f_opt:\n                    self.f_opt = f_gauss\n                    self.x_opt = x_new_gauss\n                    x = x_new_gauss\n                    self.success_count += 1\n                else:\n                    pass\n            \n            # Adapt step size\n            success_rate = self.success_count / self.iteration if self.iteration > 0 else 0\n            if success_rate > self.success_rate_threshold:\n                self.step_size *= 1.1  # Increase step size\n            else:\n                self.step_size *= 0.9  # Decrease step size\n            \n            self.step_size = np.clip(self.step_size, 1e-6, (func.bounds.ub - func.bounds.lb)[0])  # Limit step size\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": -0.30547, "other_inf": null}
{"id": "a7af5121-ac82-4b6a-896d-b3c3aa5968d4", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A population-based algorithm that uses a velocity update rule inspired by Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameters to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.velocity = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocity\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) / 2\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find initial global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Velocity update with PSO and DE components\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # DE Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                \n                self.velocity[i] = self.w * self.velocity[i] + \\\n                                    self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                    self.c2 * r2 * (global_best_position - population[i]) + \\\n                                    0.1 * (mutant - population[i]) # Add a small DE component\n                \n                # Update position\n                trial = np.clip(population[i] + self.velocity[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = trial.copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        global_best_position = trial.copy() # update global best position as well\n                \n                # Update population\n                population[i] = trial.copy() # Always update the population\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive parameter adjustment\n            self.w = 0.7 - (0.7 - 0.4) * (self.budget / (self.budget + self.pop_size)) # linearlly decrease inertia weight\n            self.F = 0.5 + 0.3 * np.random.rand() # Adapt F to diversify mutation\n\n        return self.f_opt, self.x_opt", "objective": -0.50403, "other_inf": null}
{"id": "ea7b1d83-5e97-48b3-9235-b18b3d983c5f", "parents": ["df25b97f-f16f-4ba2-81c9-5d709a220621"], "algorithm": "A modified differential evolution strategy incorporating a Cauchy mutation operator for enhanced exploration and a shrinking population size over iterations to intensify local search.", "code": "import numpy as np\n\nclass CauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, initial_pop_fraction=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = int(min(budget // 10, dim * pop_multiplier * initial_pop_fraction))\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.shrink_factor = 0.99  # Population shrink rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                cauchy_noise = np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(a + self.F * (b - c) + 0.01 * cauchy_noise, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Shrink population (reduce exploration, focus on exploitation)\n            self.pop_size = max(int(self.pop_size * self.shrink_factor), 1)\n            if self.pop_size < self.initial_pop_size and self.budget > 0:\n\n                new_population_size = min(self.initial_pop_size, self.budget)\n\n                if new_population_size > self.pop_size:\n                    new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(new_population_size - self.pop_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.budget -= (new_population_size - self.pop_size)\n\n                    population = np.concatenate((population, new_population))\n                    fitness = np.concatenate((fitness, new_fitness))\n                    self.pop_size = new_population_size\n\n                    if np.min(fitness) < self.f_opt:\n                        self.f_opt = np.min(fitness)\n                        self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "objective": -0.55093, "other_inf": null}
{"id": "85e9cd32-43f6-47e0-ad50-4c07d2040cee", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "A modified CMA-ES with adaptive population size and a simplified restart strategy based on function value improvement.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, mu_factor=0.25, initial_pop_size=None, pop_size_adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.mu_factor = mu_factor\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(dim))\n        self.pop_size = self.initial_pop_size\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate\n        self.mu = int(self.pop_size * self.mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.last_improvement = 0\n        self.improvement_threshold = 0.01 #threshold to check if improvement is significant\n        \n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                improvement = (self.f_opt - np.min(fitness))/np.abs(self.f_opt)\n                if(np.abs(self.f_opt) < 1e-9):\n                  improvement = self.f_opt - np.min(fitness) # if near zero use absolute difference for improvement\n                if improvement > self.improvement_threshold: #significant improvement?\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = x[np.argmin(fitness)]\n                    self.last_improvement = generation #update generation of last improvement\n\n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n\n            # Update covariance matrix\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n            for i in range(self.mu):\n                C += self.ccov * self.weights[i] * (z[i, :, None] @ z[i, None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            #Adaptive population size\n            if generation - self.last_improvement > 50: #if no improvement for some time, reduce pop size\n                self.pop_size = max(4, int(self.pop_size * (1 - self.pop_size_adaptation_rate)))\n                self.mu = int(self.pop_size * self.mu_factor)\n                self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.last_improvement = generation\n            elif generation - self.last_improvement < 10 and self.pop_size < self.initial_pop_size * 2: #increase pop size if improvement is fast\n                self.pop_size = min(self.initial_pop_size * 2, int(self.pop_size * (1 + self.pop_size_adaptation_rate)))\n                self.mu = int(self.pop_size * self.mu_factor)\n                self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n\n            # Simplified Restart mechanism: Reset to best location with smaller sigma if stagnated\n            if generation - self.last_improvement > 100:\n                mean = self.x_opt + np.random.normal(0, 0.1, size=self.dim) #around best, small variation\n                mean = np.clip(mean, func.bounds.lb, func.bounds.ub)\n                sigma = self.sigma0 * 0.5 # smaller sigma after restart\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.last_improvement = generation\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "c2a34b70-c226-4b39-9096-62f0a5fd18f8", "parents": ["064663ca-c4e0-4260-88a3-abe8b581a841"], "algorithm": "An adaptive Differential Evolution strategy that adjusts its parameters based on the success rate of generating better solutions.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, adaptive_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.adaptive_factor = adaptive_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.pop[best_idx]\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            new_pop = np.zeros_like(self.pop)\n            new_fitness = np.zeros_like(self.fitness)\n            \n            num_improvements = 0\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                \n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                jrand = np.random.randint(self.dim)\n                u = np.copy(self.pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        u[j] = v[j]\n                \n                # Evaluation\n                f = func(u)\n                self.budget -= 1\n                \n                if f < self.fitness[i]:\n                    new_pop[i] = u\n                    new_fitness[i] = f\n                    num_improvements += 1\n                else:\n                    new_pop[i] = self.pop[i]\n                    new_fitness[i] = self.fitness[i]\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = u\n                \n                if self.budget <= 0:\n                    break\n            \n            if self.budget <= 0:\n                break\n\n            #Adapt F and CR\n            success_rate = num_improvements / self.pop_size\n            self.F = np.clip(self.F + self.adaptive_factor * (success_rate - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.adaptive_factor * (success_rate - 0.5), 0.1, 1.0)\n            \n            # Update population\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "objective": -0.56771, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "975580b7-0c25-4b26-a436-044e3f14a3c0", "parents": [], "algorithm": "This algorithm combines a Sobol sequence-based initialization with a Nelder-Mead simplex-based local search, adaptively restarting from new Sobol points based on stagnation detection.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, stagnation_tolerance=100):\n        self.budget = budget\n        self.dim = dim\n        self.stagnation_tolerance = stagnation_tolerance\n        try:\n            from sobol_seq import i4_sobol_generate\n            self.sobol_available = True\n            self.sobol_generator = i4_sobol_generate\n        except ImportError:\n            self.sobol_available = False\n            print(\"Warning: sobol_seq not found. Falling back to random initialization.\")\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            if self.sobol_available:\n                remaining_evals = self.budget - eval_count\n                n_points = min(100, remaining_evals)\n                sobol_points = self.sobol_generator(self.dim, n_points)\n                initial_points = func.bounds.lb + sobol_points * (func.bounds.ub - func.bounds.lb)\n            else:\n                initial_points = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(100, self.dim))\n                n_points = 100\n\n            for i in range(n_points):\n                if eval_count >= self.budget:\n                    break\n                x0 = initial_points[i, :]\n\n                res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'xatol': 1e-6, 'fatol': 1e-6", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, stagnation_tolerance=100):\n        self.budget = budget\n        self.dim = dim\n        self.stagnation_tolerance = stagnation_tolerance\n        try:\n            from sobol_seq import i4_sobol_generate\n            self.sobol_available = True\n            self.sobol_generator = i4_sobol_generate\n        except ImportError:\n            self.sobol_available = False\n            print(\"Warning: sobol_seq not found. Falling back to random initialization.\")\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            if self.sobol_available:\n                remaining_evals = self.budget - eval_count\n                n_points = min(100, remaining_evals)\n                sobol_points = self.sobol_generator(self.dim, n_points)\n                initial_points = func.bounds.lb + sobol_points * (func.bounds.ub - func.bounds.lb)\n            else:\n                initial_points = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(100, self.dim))\n                n_points = 100\n\n            for i in range(n_points):\n                if eval_count >= self.budget:\n                    break\n                x0 = initial_points[i, :]\n\n                res = minimize(func, x0, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'xatol': 1e-6, 'fatol': 1e-6})\n                \n                eval_count += res.nfev\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n                \n                if stagnation_counter > self.stagnation_tolerance:\n                    stagnation_counter = 0\n                    break  # Restart from a new Sobol point\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "637c5b14-298e-4d5a-9223-e04565f4936f", "parents": [], "algorithm": "Adaptive Differential Evolution with orthogonal crossover and archive to maintain diversity and exploration.", "code": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        archive = []\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size + len(archive), 4, replace=False)\n                if idxs[0] >= self.pop_size:\n                  a = archive[idxs[0] - self.pop_size]\n                else:\n                  a = population[idxs[0]]\n                if idxs[1] >= self.pop_size:\n                  b = archive[idxs[1] - self.pop_size]\n                else:\n                  b = population[idxs[1]]\n                if idxs[2] >= self.pop_size:\n                  c = archive[idxs[2] - self.pop_size]\n                else:\n                  c = population[idxs[2]]                  \n                \n                F = np.random.uniform(0.1, 0.9)\n                mutant = population[i] + F * (a - b) + F * (population[i] - c) \n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (Orthogonal Crossover)\n                CR = np.random.uniform(0, 1)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n\n                for j in range(self.dim):\n                  if np.random.rand() < CR or j == j_rand:\n                    trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update archive\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        archive[idx_to_replace] = population[i].copy()\n\n                # Update optimal solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.33162, "other_inf": null}
{"id": "90da0ec9-2bad-402c-805c-2a60f1bb07ca", "parents": [], "algorithm": "Adaptive Differential Evolution with local search refinement, adjusting parameters based on success and periodically applying a local search around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, f=0.5, cr=0.7, local_search_iterations=5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.local_search_iterations = local_search_iterations\n        self.local_search_radius = local_search_radius\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def mutate(self):\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.f * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, -5.0, 5.0)\n            \n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            yield i, trial\n\n    def local_search(self, func):\n        for _ in range(self.local_search_iterations):\n            x_new = self.x_opt + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_new = np.clip(x_new, -5.0, 5.0)\n            f_new = func(x_new)\n            self.eval_count += 1\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        generation = 0\n        while self.eval_count < self.budget:\n            generation += 1\n            \n            successful_f = []\n            successful_cr = []\n            \n            for i, trial in self.mutate():\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    successful_f.append(self.f)\n                    successful_cr.append(self.cr)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            if len(successful_f) > 0:\n                self.f = np.mean(successful_f) if len(successful_f) > 0 else 0.5\n                self.cr = np.mean(successful_cr) if len(successful_cr) > 0 else 0.7\n            else:\n                self.f = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.cr = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n                \n            if generation % 10 == 0:\n                self.local_search(func)\n        \n\n        return self.f_opt, self.x_opt", "objective": -0.63668, "other_inf": null}
{"id": "595bc584-928f-4401-a7f2-fe3b072b219f", "parents": [], "algorithm": "The algorithm employs a population-based approach with a central point and exploration/exploitation phases, adaptively adjusting step sizes and exploration range based on the success rate of function evaluations.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_rate = exploration_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = (self.ub - self.lb) / 10.0\n        self.success_rate = 0.0\n        self.success_memory = []\n        self.memory_size = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find best individual\n        best_index = np.argmin(fitness)\n        best_x = population[best_index]\n        best_f = fitness[best_index]\n        \n        self.f_opt = best_f\n        self.x_opt = best_x\n\n        while self.budget > 0:\n            # Generate new individuals around the best\n            new_population = np.zeros_like(population)\n            \n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random search within bounds\n                    new_population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                else:\n                    # Exploitation: Gaussian perturbation around the best\n                    new_population[i] = np.clip(best_x + np.random.normal(0, self.step_size, size=self.dim), self.lb, self.ub)\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Update success rate memory\n            successes = new_fitness < fitness\n            self.success_memory.append(np.mean(successes))\n            if len(self.success_memory) > self.memory_size:\n                self.success_memory.pop(0)\n            self.success_rate = np.mean(self.success_memory) if self.success_memory else 0.5\n\n            # Update population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n            # Update best individual\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                best_x = population[best_index]\n                best_f = fitness[best_index]\n            \n            # Adjust step size and exploration rate based on success rate\n            if self.success_rate > 0.3:\n                self.step_size *= 1.1\n                self.exploration_rate *= 0.95\n            elif self.success_rate < 0.2:\n                self.step_size *= 0.9\n                self.exploration_rate *= 1.05\n            \n            self.step_size = np.clip(self.step_size, (self.ub - self.lb) / 1000, (self.ub - self.lb) / 2)\n            self.exploration_rate = np.clip(self.exploration_rate, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.41587, "other_inf": null}
{"id": "807ae470-5705-4492-bf25-df697d615c81", "parents": [], "algorithm": "This algorithm uses a combination of a Latin hypercube sampling for initial points, followed by a local search (Nelder-Mead) around the best point found so far to refine the solution.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass LHCS_NM:\n    def __init__(self, budget=10000, dim=10, n_initial_points=50):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = min(n_initial_points, budget)  # Cap initial points\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def latin_hypercube_sampling(self, n_samples, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        samples = np.zeros((n_samples, self.dim))\n        for i in range(self.dim):\n            samples[:, i] = np.random.uniform(low=lb[i], high=ub[i], size=n_samples)\n\n            indices = np.random.permutation(n_samples)\n            samples[:, i] = samples[indices, i]\n        return samples\n    \n    def __call__(self, func):\n        # Latin Hypercube Sampling for initial points\n        initial_points = self.latin_hypercube_sampling(self.n_initial_points, func.bounds)\n\n        for i in range(self.n_initial_points):\n            if self.eval_count >= self.budget:\n                return self.f_opt, self.x_opt\n\n            x = initial_points[i]\n            f = func(x)\n            self.eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        # Local Search (Nelder-Mead) around the best point found so far\n        if self.eval_count < self.budget:\n\n            remaining_budget = self.budget - self.eval_count\n            options = {'maxfev': remaining_budget", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass LHCS_NM:\n    def __init__(self, budget=10000, dim=10, n_initial_points=50):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = min(n_initial_points, budget)  # Cap initial points\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def latin_hypercube_sampling(self, n_samples, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        samples = np.zeros((n_samples, self.dim))\n        for i in range(self.dim):\n            samples[:, i] = np.random.uniform(low=lb[i], high=ub[i], size=n_samples)\n\n            indices = np.random.permutation(n_samples)\n            samples[:, i] = samples[indices, i]\n        return samples\n    \n    def __call__(self, func):\n        # Latin Hypercube Sampling for initial points\n        initial_points = self.latin_hypercube_sampling(self.n_initial_points, func.bounds)\n\n        for i in range(self.n_initial_points):\n            if self.eval_count >= self.budget:\n                return self.f_opt, self.x_opt\n\n            x = initial_points[i]\n            f = func(x)\n            self.eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        # Local Search (Nelder-Mead) around the best point found so far\n        if self.eval_count < self.budget:\n\n            remaining_budget = self.budget - self.eval_count\n            options = {'maxfev': remaining_budget}\n\n            res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options=options)\n            \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n\n            self.eval_count = self.budget # Set eval count to budget since minimize already considers it\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e72efeb1-bda6-4b91-9e6d-1cc4b98f35b8", "parents": [], "algorithm": "This algorithm uses a population-based approach with differential evolution operators for exploration and exploitation, incorporating a local search based on Nelder-Mead simplex for fine-tuning the best solution found so far.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass DifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n                \n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search around best solution\n            if self.budget > self.dim*2:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', \n                               bounds=[(self.lb, self.ub)]*self.dim,\n                               options={'maxfev': min(self.budget, 500)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n                \n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search around best solution\n            if self.budget > self.dim*2:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', \n                               bounds=[(self.lb, self.ub)]*self.dim,\n                               options={'maxfev': min(self.budget, 500)})\n                \n                if res.fun < self.f_opt:\n                     self.f_opt = res.fun\n                     self.x_opt = res.x\n\n                self.budget -= res.nfev\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "feb238d4-2aa4-4598-97a1-fb2b108fe68a", "parents": [], "algorithm": "An adaptive differential evolution algorithm that adjusts its parameters based on the success rate of generating better solutions within the budget.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_history = []\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.pop[i]\n\n    def mutate(self):\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = a + self.F * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n            \n            #Crossover and trial vector\n            trial = np.copy(self.pop[i])\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    trial[j] = mutant[j]\n            \n            yield i, trial\n\n    def __call__(self, func):\n        self.initialize_population()\n        self.evaluate_population(func)\n        eval_count = self.pop_size  # Initial population evaluation\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            for i, trial in self.mutate():\n                f_trial = func(trial)\n                eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if eval_count >= self.budget:\n                    break\n            #Adaptive parameter control based on mutation success ratio\n            if self.pop_size > 0:\n                success_ratio = successful_mutations / self.pop_size if self.pop_size > 0 else 0.0\n\n                #Update F and CR based on success ratio\n                if success_ratio > 0.5: #Exploitation\n                    self.F *= 0.95\n                    self.CR *= 1.05\n                elif success_ratio < 0.1: #Exploration\n                    self.F *= 1.05\n                    self.CR *= 0.95\n\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "objective": -0.48765, "other_inf": null}
{"id": "ad3c9b96-00aa-41c7-8f95-9ae5fd198a55", "parents": [], "algorithm": "Adaptive Differential Evolution with a dynamically adjusted population size based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size if pop_size is not None else 10*dim\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.history_size = 10\n        self.fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop_size = self.pop_size_init  # Initialize population size\n\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.nevals = self.pop_size\n        \n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        while self.nevals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.nevals += 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            #Adaptive Population Size\n            self.fitness_history.append(self.f_opt)\n            if len(self.fitness_history) > self.history_size:\n              self.fitness_history.pop(0)\n              improvement = self.fitness_history[0] - self.fitness_history[-1]\n              if improvement > 0:\n                  self.pop_size = int(self.pop_size * 1.1)  # Increase population size if improving\n              else:\n                  self.pop_size = int(self.pop_size * 0.9)  # Decrease population size if stagnating\n\n              self.pop_size = max(self.dim + 1, min(self.pop_size, self.budget // 2))\n              \n              if self.pop_size != population.shape[0]: #Re-initialize population if needed\n                 new_pop_size = self.pop_size\n                 new_population = np.random.uniform(self.lb, self.ub, size=(new_pop_size, self.dim))\n                 new_fitness = np.array([func(x) for x in new_population])\n                 self.nevals += new_pop_size\n                 \n                 best_indices = np.argsort(fitness)[:min(self.pop_size, population.shape[0])]\n                 \n                 new_population[:len(best_indices)] = population[best_indices]\n                 new_fitness[:len(best_indices)] = fitness[best_indices]\n\n                 population = new_population\n                 fitness = new_fitness\n                 \n                 best_index = np.argmin(fitness)\n                 if fitness[best_index] < self.f_opt:\n                        self.f_opt = fitness[best_index]\n                        self.x_opt = population[best_index]\n                        \n            if self.nevals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "fc4bcf0c-c0e8-449f-9ed2-21188aa67d07", "parents": ["feb238d4-2aa4-4598-97a1-fb2b108fe68a", "595bc584-928f-4401-a7f2-fe3b072b219f"], "algorithm": "This algorithm uses a Gaussian process surrogate model to predict the objective function and adaptively samples new points based on the uncertainty and predicted improvement.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, xi=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.xi = xi  # Exploration-exploitation trade-off parameter\n        self.X_samples = []\n        self.Y_samples = []\n        self.gpr = None\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        mu = mu[0]\n        sigma = sigma[0]\n\n        if sigma == 0:\n          return 0\n\n        Z = (mu - self.best_f - self.xi) / sigma\n        return - (mu - self.best_f - self.xi) * norm.cdf(Z) - sigma * norm.pdf(Z)\n        \n    def optimize_acquisition_function(self):\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n        \n        res = minimize(self.acquisition_function, x0, method='L-BFGS-B', bounds=bounds)\n        return res.x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial sampling\n        X_initial = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        Y_initial = np.array([func(x) for x in X_initial])\n        self.X_samples = X_initial.tolist()\n        self.Y_samples = Y_initial.tolist()\n        self.best_f = np.min(Y_initial)\n        self.x_opt = X_initial[np.argmin(Y_initial)]\n        self.f_opt = self.best_f\n        eval_count = self.n_initial_samples\n        \n        # Gaussian process setup\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n        \n        # Optimization loop\n        while eval_count < self.budget:\n            # Fit GP model\n            self.gpr.fit(self.X_samples, self.Y_samples)\n            \n            # Find next sample point by maximizing acquisition function\n            x_new = self.optimize_acquisition_function()\n\n            # Evaluate function at new point\n            f_new = func(x_new)\n            eval_count += 1\n            \n            # Update samples\n            self.X_samples.append(x_new)\n            self.Y_samples.append(f_new)\n            \n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n            self.best_f = np.min(self.Y_samples)\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "71685a72-e4be-4e50-b501-1133159c7fe4", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "637c5b14-298e-4d5a-9223-e04565f4936f"], "algorithm": "Simulated Annealing with adaptive temperature and step size based on acceptance rate.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, temp_min=0.0001, alpha=0.99, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.temp_min = temp_min\n        self.alpha = alpha\n        self.step_size = step_size\n        self.temp = initial_temp\n        self.eval_count = 0\n        self.acceptance_rate = 0.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n\n        while self.eval_count < self.budget and self.temp > self.temp_min:\n            x_new = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_e = f_new - f\n\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                x = x_new\n                f = f_new\n                self.acceptance_rate += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n            self.temp *= self.alpha\n            \n            if self.eval_count % 100 == 0:\n                self.acceptance_rate /= 100\n                self.acceptance_history.append(self.acceptance_rate)\n                if self.acceptance_rate > 0.6:\n                    self.step_size *= 1.1\n                elif self.acceptance_rate < 0.4:\n                    self.step_size *= 0.9\n                self.step_size = np.clip(self.step_size, 0.01, 1.0)\n                self.acceptance_rate = 0.0\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.19703, "other_inf": null}
{"id": "e9c9ed42-cfd6-4e73-815a-6c42bf37ccdf", "parents": ["feb238d4-2aa4-4598-97a1-fb2b108fe68a", "595bc584-928f-4401-a7f2-fe3b072b219f"], "algorithm": "This algorithm uses a Nelder-Mead simplex method, iteratively refining a simplex of points to find the minimum of the function within the budget.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass NelderMeadOptimization:\n    def __init__(self, budget=10000, dim=10, initial_simplex=None):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_simplex = initial_simplex\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initial guess (center of the search space)\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        # Define the bounds for the optimization\n        bounds = [(self.lb, self.ub)] * self.dim\n\n        # Perform Nelder-Mead optimization\n        result = minimize(func, x0, method='Nelder-Mead', bounds=bounds,\n                            options={'maxfev': self.budget, 'xatol': 1e-4, 'fatol': 1e-4", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass NelderMeadOptimization:\n    def __init__(self, budget=10000, dim=10, initial_simplex=None):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_simplex = initial_simplex\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initial guess (center of the search space)\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n        # Define the bounds for the optimization\n        bounds = [(self.lb, self.ub)] * self.dim\n\n        # Perform Nelder-Mead optimization\n        result = minimize(func, x0, method='Nelder-Mead', bounds=bounds,\n                            options={'maxfev': self.budget, 'xatol': 1e-4, 'fatol': 1e-4})\n\n        self.f_opt = result.fun\n        self.x_opt = result.x\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "abb3fa75-ceed-4e2b-a4a1-7ec9a0311be5", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Simulated Annealing with adaptive temperature decay based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, temp_decay_factor=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_decay_factor = temp_decay_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n\n        while self.eval_count < self.budget:\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                acceptance_probability = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n            \n            # Adaptive temperature decay\n            if acceptance_probability > 0.5:\n                temp *= (1 - self.temp_decay_factor)\n            else:\n                temp *= self.cooling_rate\n            \n            if temp < 1e-5:\n                temp = 1e-5\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "768c8da4-3632-41d0-af7d-d0102b879c1f", "parents": ["637c5b14-298e-4d5a-9223-e04565f4936f", "feb238d4-2aa4-4598-97a1-fb2b108fe68a"], "algorithm": "A population-based algorithm that evolves solutions by stochastically perturbing the best solution found so far, and periodically re-initializing a portion of the population to maintain diversity.", "code": "import numpy as np\n\nclass StochasticPerturbation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, perturbation_factor=0.1, reinit_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.perturbation_factor = perturbation_factor\n        self.reinit_rate = reinit_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Perturb the best solution\n                perturbation = np.random.normal(0, self.perturbation_factor, size=self.dim)\n                trial = self.x_opt + perturbation\n                trial = np.clip(trial, self.lb, self.ub)\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial.copy()\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                # Periodically re-initialize a portion of the population\n                if np.random.rand() < self.reinit_rate:\n                    population[i] = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.3343, "other_inf": null}
{"id": "b7152a49-e52a-4833-afe1-0b0d9811e1b5", "parents": ["feb238d4-2aa4-4598-97a1-fb2b108fe68a", "595bc584-928f-4401-a7f2-fe3b072b219f"], "algorithm": "A population-based algorithm that evolves hyper-ellipsoids to enclose promising regions of the search space, adapting shape and orientation based on successful function evaluations.", "code": "import numpy as np\n\nclass EllipsoidalEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=15, initial_volume=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_volume = initial_volume\n        self.ellipsoids = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_ellipsoids(self):\n        # Initial ellipsoid: center, covariance matrix\n        center = np.random.uniform(self.lb, self.ub, size=self.dim)\n        initial_covariance = np.eye(self.dim) * (self.initial_volume**(1/self.dim))\n        self.ellipsoids = [(center, initial_covariance)]\n\n    def sample_ellipsoid(self, center, covariance, num_samples=1):\n        A = np.linalg.cholesky(covariance)\n        z = np.random.normal(size=(num_samples, self.dim))\n        samples = center + z @ A.T\n        samples = np.clip(samples, self.lb, self.ub)\n        return samples\n\n    def update_ellipsoid(self, ellipsoid, successful_points):\n        center, covariance = ellipsoid\n        if len(successful_points) > self.dim + 1:\n            new_center = np.mean(successful_points, axis=0)\n            centered_points = successful_points - new_center\n            new_covariance = np.cov(centered_points, rowvar=False)\n            # Regularize covariance matrix to avoid singularity\n            new_covariance += np.eye(self.dim) * 1e-6\n            return new_center, new_covariance\n        else:\n            return center, covariance  # No significant update\n\n    def __call__(self, func):\n        self.initialize_ellipsoids()\n        eval_count = 0\n\n        while eval_count < self.budget:\n            new_ellipsoids = []\n            for center, covariance in self.ellipsoids:\n                # Sample points from ellipsoid\n                samples = self.sample_ellipsoid(center, covariance, num_samples=self.pop_size)\n                fitness_values = np.array([func(x) for x in samples])\n                eval_count += self.pop_size\n                \n                #Update best solution\n                for i in range(self.pop_size):\n                    if fitness_values[i] < self.f_opt:\n                        self.f_opt = fitness_values[i]\n                        self.x_opt = samples[i]\n\n                # Identify successful points\n                threshold = np.mean(fitness_values)\n                successful_points = samples[fitness_values < threshold]\n\n                # Update ellipsoid parameters\n                new_center, new_covariance = self.update_ellipsoid((center, covariance), successful_points)\n                new_ellipsoids.append((new_center, new_covariance))\n\n            self.ellipsoids = new_ellipsoids\n\n            # Adaptive ellipsoid management: split or merge (simplified)\n            if len(self.ellipsoids) < 5 and eval_count < self.budget * 0.8 :  # Limit ellipsoid count\n                center = np.random.uniform(self.lb, self.ub, size=self.dim)\n                initial_covariance = np.eye(self.dim) * (self.initial_volume**(1/self.dim))\n                self.ellipsoids.append((center, initial_covariance))\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "f235a5c1-9cab-4f80-89b3-8011e247129f", "parents": ["637c5b14-298e-4d5a-9223-e04565f4936f", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Evolving a population using Gaussian mutation with adaptive step size, then selecting the best individuals and recentering the distribution around them.", "code": "import numpy as np\n\nclass AdaptiveGaussianOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.mean = None\n        self.std = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.std = np.ones(self.dim) * 0.5  # Initial standard deviation\n\n        population = np.random.normal(self.mean, self.std, size=(self.pop_size, self.dim))\n        population = np.clip(population, func.bounds.lb, func.bounds.ub)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Generate new population\n            new_population = np.random.normal(self.mean, self.std, size=(self.pop_size, self.dim))\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                new_fitness = new_fitness[:self.budget + self.pop_size]\n                new_population = new_population[:self.budget + self.pop_size]\n\n\n            # Selection: Combine old and new populations, select best\n            combined_population = np.concatenate((population, new_population))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n            \n            \n            sorted_indices = np.argsort(combined_fitness)\n            best_indices = sorted_indices[:self.pop_size]\n            \n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update mean and std\n            self.mean = np.mean(population, axis=0)\n            self.std = np.std(population, axis=0)\n            self.std = np.maximum(self.std, 1e-6) # Ensure standard deviation is not zero\n\n            # Adapt step size (std) based on success\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n        return self.f_opt, self.x_opt", "objective": -0.16619, "other_inf": null}
{"id": "c4638c60-289a-4ce6-8adf-6037567b880a", "parents": ["595bc584-928f-4401-a7f2-fe3b072b219f", "feb238d4-2aa4-4598-97a1-fb2b108fe68a"], "algorithm": "This algorithm uses a combination of global random search and local gradient estimation to find the optimum by alternating between exploration and exploitation phases.", "code": "import numpy as np\n\nclass GradientGuidedSearch:\n    def __init__(self, budget=10000, dim=10, exploration_prob=0.2, step_size=0.1, num_gradient_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_prob = exploration_prob\n        self.step_size = step_size\n        self.num_gradient_samples = num_gradient_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def estimate_gradient(self, func, x):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            delta = np.zeros(self.dim)\n            delta[i] = self.step_size\n            \n            x_plus = np.clip(x + delta, self.lb, self.ub)\n            x_minus = np.clip(x - delta, self.lb, self.ub)\n            \n            gradient[i] = (func(x_plus) - func(x_minus)) / (2 * self.step_size)\n            self.budget -= 2\n            if self.budget <= 0:\n              break\n        return gradient\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial guess\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        \n        self.f_opt = f\n        self.x_opt = x\n\n        while self.budget > 0:\n            if np.random.rand() < self.exploration_prob:\n                # Exploration: Random search\n                x_new = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f_new = func(x_new)\n                self.budget -= 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                    x = x_new\n                    f = f_new\n\n            else:\n                # Exploitation: Gradient-guided search\n                gradient = self.estimate_gradient(func, x)\n                if self.budget <= 0:\n                  break\n                \n                # Normalize gradient\n                norm = np.linalg.norm(gradient)\n                if norm > 0:\n                    gradient = gradient / norm\n                \n                x_new = np.clip(x - self.step_size * gradient, self.lb, self.ub)\n                f_new = func(x_new)\n                self.budget -= 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                    x = x_new\n                    f = f_new\n                else:\n                    # If the gradient step doesn't improve, try a smaller random step\n                    x_new = np.clip(x + np.random.normal(0, self.step_size/2, size=self.dim), self.lb, self.ub)\n                    f_new = func(x_new)\n                    self.budget -= 1\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                        x = x_new\n                        f = f_new\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "aaa2694a-bd5f-4ae9-a13c-56fa9d613ffa", "parents": ["595bc584-928f-4401-a7f2-fe3b072b219f"], "algorithm": "# Description: This algorithm uses a population-based approach with a central point, adaptive step sizes, and a Cauchy mutation operator for enhanced exploration, alongside a local search around the best solution.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=1.0, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = initial_step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_iterations = local_search_iterations\n\n    def cauchy_mutation(self, x):\n        return x + self.step_size * np.random.standard_cauchy(size=self.dim)\n\n    def local_search(self, func, x):\n        best_x = x.copy()\n        best_f = func(x)\n        self.budget -= 1\n\n        for _ in range(self.local_search_iterations):\n            if self.budget <= 0:\n                break\n            new_x = np.clip(x + np.random.normal(0, self.step_size/2, size=self.dim), self.lb, self.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x.copy()\n        \n        return best_f, best_x\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial individual\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index].copy()\n        self.f_opt = fitness[best_index]\n\n        while self.budget > 0:\n            # Generate new individuals using Cauchy mutation\n            new_population = np.array([np.clip(self.cauchy_mutation(self.x_opt), self.lb, self.ub) for _ in range(self.pop_size)])\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update best individual\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i].copy()\n            \n            # Local search around the best solution\n            local_f, local_x = self.local_search(func, self.x_opt.copy())\n            if local_f < self.f_opt:\n                 self.f_opt = local_f\n                 self.x_opt = local_x.copy()\n\n            # Adjust step size\n            self.step_size *= 0.95\n\n            self.step_size = np.clip(self.step_size, (self.ub - self.lb) / 1000, (self.ub - self.lb) / 2)\n\n        return self.f_opt, self.x_opt", "objective": -0.51715, "other_inf": null}
{"id": "6f4d8a2b-fefc-4ef9-8aff-2ba541c289f6", "parents": ["768c8da4-3632-41d0-af7d-d0102b879c1f"], "algorithm": "# Description: An evolutionary strategy algorithm that combines mutation and selection, with a self-adaptive step size for each individual.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, tau=None, tau_prime=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.tau = tau or (1 / np.sqrt(2 * dim))\n        self.tau_prime = tau_prime or (1 / np.sqrt(2 * np.sqrt(dim)))\n        self.initial_step_size = initial_step_size\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.full((self.pop_size, self.dim), self.initial_step_size)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutate step sizes\n                xi = np.random.normal(0, 1, size=self.dim)\n                global_mutation = self.tau_prime * np.random.normal(0, 1)\n                new_step_sizes = step_sizes[i] * np.exp(global_mutation + self.tau * xi)\n                new_step_sizes = np.clip(new_step_sizes, 1e-10, 1) # Avoid zero step sizes\n\n                # Mutate solution\n                mutation = np.random.normal(0, new_step_sizes, size=self.dim)\n                trial = population[i] + mutation\n                trial = np.clip(trial, self.lb, self.ub)\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial.copy()\n                    step_sizes[i] = new_step_sizes.copy()\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.34385, "other_inf": null}
{"id": "86ba0c1d-306d-42d4-9e34-79ee35af11e6", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Simulated Annealing with adaptive temperature and re-annealing strategy.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, min_temp=1e-5, reanneal_factor=1.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n        self.reanneal_factor = reanneal_factor\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.eval_count += 1\n\n        temp = self.initial_temp\n\n        while self.eval_count < self.budget and temp > self.min_temp:\n            x_new = x + np.random.uniform(-0.1, 0.1, size=self.dim) * temp  # Perturbation scaled by temperature\n            x_new = np.clip(x_new, -5.0, 5.0)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_e = f_new - self.f_opt\n\n            if delta_e < 0:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n            else:\n                acceptance_probability = np.exp(-delta_e / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n\n            temp *= self.cooling_rate\n            \n            # Re-annealing strategy: If no improvement after a certain number of iterations, re-anneal\n            if self.eval_count % (self.budget // 10) == 0:\n                if func(self.x_opt) > self.f_opt:  # Check if x_opt is still valid\n                    temp *= self.reanneal_factor # Increase the temperature\n        \n        return self.f_opt, self.x_opt", "objective": -0.16906, "other_inf": null}
{"id": "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d", "parents": ["595bc584-928f-4401-a7f2-fe3b072b219f"], "algorithm": "# Description: This algorithm employs a population-based approach with differential evolution and a self-adaptive mutation strategy.\n# Code: \n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Self-adaptive F\n                F_adaptive = np.random.normal(self.F, 0.1)\n                F_adaptive = np.clip(F_adaptive, 0.1, 1.0)\n\n                mutant = a + F_adaptive * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.63869, "other_inf": null}
{"id": "49d50de9-55b7-47bf-846b-5827454aa517", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "A population-based optimization algorithm with Gaussian mutation and Simulated Annealing acceptance criteria to balance exploration and exploitation.", "code": "import numpy as np\n\nclass GaussianDE_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.5, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.temperature = self.initial_temp\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def mutate(self, func):\n        for i in range(self.pop_size):\n            mutant = self.population[i] + self.mutation_rate * np.random.normal(0, 1, self.dim)\n            mutant = np.clip(mutant, -5.0, 5.0)\n\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutant, self.population[i])\n            f_trial = func(trial)\n            self.eval_count += 1\n\n            delta_e = f_trial - self.fitness[i]\n            if delta_e < 0:\n                self.fitness[i] = f_trial\n                self.population[i] = trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial\n            else:\n                acceptance_prob = np.exp(-delta_e / self.temperature)\n                if np.random.rand() < acceptance_prob:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.mutate(func)\n            self.temperature *= self.cooling_rate\n            if self.temperature < 0.0001:\n                self.temperature = 0.0001\n        return self.f_opt, self.x_opt", "objective": -0.23537, "other_inf": null}
{"id": "6d4d96c4-70a4-43f6-b46f-81bc5797d559", "parents": ["aaa2694a-bd5f-4ae9-a13c-56fa9d613ffa"], "algorithm": "This algorithm combines a differential evolution strategy for global exploration with a Nelder-Mead simplex method for local refinement, adaptively switching between them based on stagnation detection.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.5, de_crossover_rate=0.7, nm_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_iterations = nm_iterations\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n        self.using_de = True\n\n    def differential_evolution(self, func, population):\n        new_population = np.zeros_like(population)\n        fitness = np.zeros(self.pop_size)\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Mutation\n            indices = np.random.choice(self.pop_size, 4, replace=False)\n            x_r1, x_r2, x_r3, x_r4 = population[indices]\n            v_mutation = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n\n            # Crossover\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate or j == np.random.randint(0, self.dim):\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = population[i][j]\n            u_crossover = np.clip(u_crossover, self.lb, self.ub)\n\n            # Selection\n            f = func(u_crossover)\n            self.budget -= 1\n\n            fitness[i] = f\n            new_population[i] = u_crossover\n\n        return new_population, fitness\n\n    def nelder_mead(self, func, x0):\n        if self.budget <= 0:\n            return self.f_opt, self.x_opt\n        \n        result = minimize(func, x0, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxiter': self.nm_iterations, 'maxfev': self.budget", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.5, de_crossover_rate=0.7, nm_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_iterations = nm_iterations\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n        self.using_de = True\n\n    def differential_evolution(self, func, population):\n        new_population = np.zeros_like(population)\n        fitness = np.zeros(self.pop_size)\n\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            # Mutation\n            indices = np.random.choice(self.pop_size, 4, replace=False)\n            x_r1, x_r2, x_r3, x_r4 = population[indices]\n            v_mutation = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n\n            # Crossover\n            u_crossover = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate or j == np.random.randint(0, self.dim):\n                    u_crossover[j] = v_mutation[j]\n                else:\n                    u_crossover[j] = population[i][j]\n            u_crossover = np.clip(u_crossover, self.lb, self.ub)\n\n            # Selection\n            f = func(u_crossover)\n            self.budget -= 1\n\n            fitness[i] = f\n            new_population[i] = u_crossover\n\n        return new_population, fitness\n\n    def nelder_mead(self, func, x0):\n        if self.budget <= 0:\n            return self.f_opt, self.x_opt\n        \n        result = minimize(func, x0, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxiter': self.nm_iterations, 'maxfev': self.budget})\n        \n        if result.success:\n          self.budget -= result.nfev\n          return result.fun, result.x\n        else:\n          return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial individual\n        best_index = np.argmin(fitness)\n        self.x_opt = population[best_index].copy()\n        self.f_opt = fitness[best_index]\n\n        while self.budget > 0:\n            if self.using_de:\n                # Differential Evolution\n                new_population, new_fitness = self.differential_evolution(func, population)\n\n                # Update best individual\n                for i in range(self.pop_size):\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_population[i].copy()\n                \n                population = new_population.copy()\n                \n                # Stagnation check\n                if np.min(new_fitness) >= self.f_opt:\n                    self.stagnation_counter +=1\n                else:\n                    self.stagnation_counter = 0\n                    \n                if self.stagnation_counter > self.max_stagnation:\n                    self.using_de = False\n                    self.stagnation_counter = 0\n\n            else:\n                # Nelder-Mead\n                local_f, local_x = self.nelder_mead(func, self.x_opt.copy())\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x.copy()\n                \n                self.using_de = True # switch back to DE\n                self.stagnation_counter = 0 # reset stagnation\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a688f476-897d-4b2e-a4fb-3c5dfdee65c8", "parents": ["feb238d4-2aa4-4598-97a1-fb2b108fe68a"], "algorithm": "A modified CMA-ES algorithm that adapts the covariance matrix and step size based on successful and unsuccessful steps, while also incorporating a simple restart mechanism when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.8, c_cov=0.05, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.c_cov = c_cov\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.path_success = np.zeros(self.dim)\n        self.restart_trigger = restart_trigger\n        self.no_improvement_count = 0\n        self.best_f_history = []\n\n    def sample_population(self):\n        z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.pop_size)\n        x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        x = np.clip(x, self.lb, self.ub)\n        return x\n\n    def update_parameters(self, x, fitness):\n        idx = np.argsort(fitness)\n        x_best = x[idx[0]]\n        f_best = fitness[idx[0]]\n\n        if f_best < self.f_opt:\n            self.f_opt = f_best\n            self.x_opt = x_best\n            self.no_improvement_count = 0\n        else:\n            self.no_improvement_count += 1\n\n        y = (x_best - self.mean) / self.sigma\n        self.path_success = (1 - self.cs) * self.path_success + np.sqrt(self.cs * (2 - self.cs)) * y\n        self.mean = x_best\n\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.path_success, self.path_success)\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C += 1e-6 * np.eye(self.dim)\n\n        if self.no_improvement_count > self.restart_trigger:\n            self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            self.C = np.eye(self.dim)\n            self.sigma = 0.5\n            self.no_improvement_count = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.no_improvement_count = 0\n        self.best_f_history = []\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.path_success = np.zeros(self.dim)\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            self.update_parameters(x, fitness)\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.60746, "other_inf": null}
{"id": "5d75d017-4d6a-4178-bc4b-419829182b18", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "This algorithm uses a particle swarm optimization approach with velocity clamping and dynamic inertia weight adjustment for exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=30, w_max=0.9, w_min=0.4, c1=2, c2=2, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight maximum\n        self.w_min = w_min  # Inertia weight minimum\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max # Maximum velocity\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = np.copy(particles)\n        pbest_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        best_index = np.argmin(pbest_fitness)\n        self.f_opt = pbest_fitness[best_index]\n        self.x_opt = pbest_positions[best_index]\n        \n        # PSO iterations\n        while self.budget > 0:\n            # Dynamic inertia weight adjustment\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / self.budget)\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (pbest_positions[i] - particles[i]) + \\\n                                self.c2 * r2 * (self.x_opt - particles[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update particle position\n                particles[i] = particles[i] + velocities[i]\n                \n                # Boundary handling\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = fitness\n                    pbest_positions[i] = np.copy(particles[i])\n                    \n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "8335ac2b-a855-42f4-981d-c08050c0b989", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adaptively explore the search space, adjusting the search distribution based on the success of previous samples.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, dsigma=0.2, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mean = None\n        self.C = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.cs = cs\n        self.dsigma = dsigma\n        self.c_cov = c_cov\n        self.p_sigma = np.zeros(dim)\n        self.p_c = np.zeros(dim)\n        self.eigenspace = None\n        self.eval_count = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n        self.eigenspace = eigenvectors\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        samples = self.mean + self.sigma * self.eigenspace @ (np.sqrt(np.diag(self.C)) * z.T).T\n        samples = np.clip(samples, self.lb, self.ub)\n        return samples\n\n    def update_distribution(self, population, fitness):\n        best_indices = np.argsort(fitness)\n        selected_indices = best_indices[:self.pop_size // 2]\n        selected_samples = population[selected_indices]\n\n        old_mean = self.mean.copy()\n        self.mean = np.mean(selected_samples, axis=0)\n        \n        z = (self.mean - old_mean) / self.sigma\n        self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * z\n        self.sigma *= np.exp((self.dsigma / self.dim) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n        self.sigma = np.clip(self.sigma, 1e-10, 10)\n\n        rank_one = np.outer(z, z)\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * rank_one\n\n        try:\n            eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n            self.eigenspace = eigenvectors\n            self.C = eigenvectors @ np.diag(eigenvalues) @ eigenvectors.T\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n            eigenvalues, eigenvectors = np.linalg.eigh(self.C)\n            self.eigenspace = eigenvectors\n\n    def __call__(self, func):\n        self.initialize()\n\n        while self.eval_count < self.budget:\n            population = self.sample_population()\n            fitness = np.array([func(x) for x in population])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            self.update_distribution(population, fitness)\n        \n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "05096e39-01b1-40f0-90c8-51a4abaa4047", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by sampling points with high uncertainty and low predicted function values.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, alpha=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        if kernel is None:\n            self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.alpha = alpha\n        self.X = None\n        self.y = None\n        self.gp = None\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return -mu + 2 * sigma  # Upper confidence bound\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Gaussian process regression\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10, alpha=self.alpha)\n        self.gp.fit(self.X, self.y)\n\n        while self.budget > 0:\n            # Find next point to evaluate using acquisition function\n            x_next = None\n            best_acq = -np.inf\n            for _ in range(1000): # Sample multiple points and pick best\n                x_sample = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq = self.acquisition_function(x_sample, self.gp)\n                if acq > best_acq:\n                    best_acq = acq\n                    x_next = x_sample\n\n            # Evaluate function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            # Update Gaussian process\n            self.gp.fit(self.X, self.y)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "269179d7-ef0c-47bb-8ea6-1e271549e71e", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, temp_decay_factor=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_decay_factor = temp_decay_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n        \n        acceptance_rate = 0.0\n\n        while self.eval_count < self.budget:\n            x_new = x + np.random.normal(0, temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                acceptance_rate += 1\n            \n            if self.eval_count % 100 == 0:\n                if acceptance_rate / 100 > 0.5:\n                    temp *= (1 + self.temp_decay_factor)\n                else:\n                    temp *= (1 - self.temp_decay_factor)\n                acceptance_rate = 0.0\n            \n            temp *= self.cooling_rate\n            temp = max(temp, 1e-6)\n\n        return self.f_opt, self.x_opt", "objective": -0.29276, "other_inf": null}
{"id": "2e17ebf9-6723-421b-a12b-c026ba0e0e47", "parents": ["a688f476-897d-4b2e-a4fb-3c5dfdee65c8", "a688f476-897d-4b2e-a4fb-3c5dfdee65c8"], "algorithm": "This algorithm employs a differential evolution strategy with a population-based approach, crossover, and mutation to explore the search space, combined with a local search using Nelder-Mead simplex method on the best individual found so far.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        # DE iterations\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Local search on best\n            res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': max(1, self.budget - self.eval_count)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        # DE iterations\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Local search on best\n            res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': max(1, self.budget - self.eval_count)})\n            if res.success:\n                  self.x_opt = res.x\n                  self.f_opt = res.fun\n            self.eval_count = min(self.budget, self.eval_count + res.nfev) #Ensuring evaluation budget constraint\n            if self.eval_count >= self.budget:\n                  break\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fb466233-7231-42c3-8bf4-103966c23783", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rate.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, temp_min=0.0001, alpha=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.temp_min = temp_min\n        self.alpha = alpha\n        self.temp = initial_temp\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n\n        self.x_opt = x\n        self.f_opt = f\n\n        while self.eval_count < self.budget and self.temp > self.temp_min:\n            x_new = x + np.random.uniform(-0.1, 0.1, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    \n            self.temp *= self.alpha\n\n        return self.f_opt, self.x_opt", "objective": -0.21497, "other_inf": null}
{"id": "9cfb8793-40b9-45af-b745-e861ab9fe03c", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "# Description: This algorithm combines a simplified particle swarm optimization with a restart mechanism based on stagnation detection.\n# Code:\n```", "code": "import numpy as np\n\nclass ParticleSwarmRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.pbest_swarm = self.swarm.copy()\n        self.pbest_fitness = self.fitness.copy()\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.swarm[best_index]\n        self.budget -= self.pop_size\n    \n    def update_swarm(self, func):\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            \n            self.velocities[i] = (self.inertia * self.velocities[i] +\n                                self.cognitive_coeff * r1 * (self.pbest_swarm[i] - self.swarm[i]) +\n                                self.social_coeff * r2 * (self.x_opt - self.swarm[i]))\n            \n            self.swarm[i] = self.swarm[i] + self.velocities[i]\n            self.swarm[i] = np.clip(self.swarm[i], self.lb, self.ub)\n            \n            fitness = func(self.swarm[i])\n            self.budget -= 1\n            \n            if fitness < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = fitness\n                self.pbest_swarm[i] = self.swarm[i].copy()\n                \n                if fitness < self.f_opt:\n                    self.f_opt = fitness\n                    self.x_opt = self.swarm[i].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        \n        while self.budget > 0:\n            self.update_swarm(func)\n            \n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                if np.std(self.best_fitness_history[-self.stagnation_threshold:]) < 1e-6:\n                    self.stagnation_counter += 1\n                else:\n                    self.stagnation_counter = 0\n\n                if self.stagnation_counter > 5:\n                    self.initialize_swarm(func)  # Restart\n                    self.stagnation_counter = 0\n                    self.best_fitness_history = []\n\n        return self.f_opt, self.x_opt", "objective": -0.52841, "other_inf": null}
{"id": "6d16857b-c543-444f-9695-4744cf93e2b4", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "# Description: Employs a population-based approach where individuals move towards better solutions found by others, with a probabilistic element to encourage exploration and avoid premature convergence.\n# Code: \n```", "code": "import numpy as np\n\nclass SocialLearningOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.1, exploration_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.exploration_prob = exploration_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration: Randomly move the individual\n                    new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                else:\n                    # Social Learning: Move towards a better individual\n                    better_indices = np.where(fitness < fitness[i])[0]\n                    if len(better_indices) > 0:\n                        chosen_index = np.random.choice(better_indices)\n                        chosen_x = population[chosen_index]\n                        new_x = population[i] + self.learning_rate * (chosen_x - population[i])\n                        new_x = np.clip(new_x, self.lb, self.ub)\n                    else:\n                        new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n                # Evaluation\n                f_new = func(new_x)\n                self.budget -= 1\n\n                # Selection: Replace if better\n                if f_new < fitness[i]:\n                    population[i] = new_x\n                    fitness[i] = f_new\n\n                    # Update best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n        return self.f_opt, self.x_opt", "objective": -0.28186, "other_inf": null}
{"id": "17776295-362c-4fb8-96d6-cc2734bac84d", "parents": ["aaa2694a-bd5f-4ae9-a13c-56fa9d613ffa", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "'maxiter': self.nelder_mead_iterations, 'maxfev': self.nelder_mead_iterations", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass CMAES_Restart_NelderMead:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, restart_threshold=1e-12, nelder_mead_iterations=50):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initial_sigma = initial_sigma\n        self.restart_threshold = restart_threshold\n        self.nelder_mead_iterations = nelder_mead_iterations\n\n    def __call__(self, func):\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)  # Covariance matrix\n\n        while self.budget > 0:\n            # Sample a new point from the multivariate normal distribution\n            z = np.random.normal(0, 1, size=self.dim)\n            x = mean + sigma * np.dot(np.linalg.cholesky(C), z)\n            x = np.clip(x, self.lb, self.ub)\n\n            f = func(x)\n            self.budget -= 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n\n            # Update the mean and covariance matrix using a simplified CMA-ES update rule\n            mean = 0.9 * mean + 0.1 * x\n            C = 0.9 * C + 0.1 * np.outer(x - mean, x - mean)\n\n            # Restart strategy: If the function value hasn't improved significantly, restart with a new mean\n            if self.f_opt - f < self.restart_threshold or self.budget % 1000 == 0:\n                mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                sigma = self.initial_sigma\n                C = np.eye(self.dim)\n\n            # Local search with Nelder-Mead\n            if self.budget > self.nelder_mead_iterations:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', \n                               bounds=[(self.lb, self.ub)] * self.dim, \n                               options={'maxiter': self.nelder_mead_iterations, 'maxfev': self.nelder_mead_iterations})\n                \n                self.budget -= res.nfev\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a88e8111-3eb5-405d-8a8e-96c4ae889e3b", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "This algorithm uses a particle swarm optimization with velocity clamping and constriction factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ClampedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n        self.K = 2 / abs(2 - (self.c1 + self.c2) - np.sqrt((self.c1 + self.c2)**2 - 4*(self.c1 + self.c2))) if (self.c1 + self.c2) > 4 else 1\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = np.copy(particles)\n        fitness = np.array([func(x) for x in particles])\n        personal_best_fitness = np.copy(fitness)\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = particles[best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            global_best_position = np.tile(self.x_opt, (self.pop_size, 1))  # Repeat global best\n\n            velocities = self.K * (self.w * velocities +\n                               self.c1 * r1 * (personal_best_positions - particles) +\n                               self.c2 * r2 * (global_best_position - particles))\n\n            velocities = np.clip(velocities, -self.v_max, self.v_max)\n            particles = particles + velocities\n            particles = np.clip(particles, self.lb, self.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n\n            # Update personal bests\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = np.copy(particles[i])\n\n            # Update global best\n            best_index = np.argmin(new_fitness)\n            if new_fitness[best_index] < self.f_opt:\n                self.f_opt = new_fitness[best_index]\n                self.x_opt = np.copy(particles[best_index])\n\n        return self.f_opt, self.x_opt", "objective": -0.60076, "other_inf": null}
{"id": "06ac8cc3-e730-462f-abde-ed65d403a07a", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "# Description: This algorithm combines differential evolution with a restart mechanism triggered by stagnation detection and dynamically adjusts the crossover rate based on success.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Initial Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.previous_best = np.inf\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.previous_best = self.f_opt\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Self-adaptive F\n                F_adaptive = np.random.normal(self.F, 0.1)\n                F_adaptive = np.clip(F_adaptive, 0.1, 1.0)\n\n                mutant = a + F_adaptive * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.success_history.append(1)\n                    else:\n                        self.success_history.append(0)\n                else:\n                    self.success_history.append(0)\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            # Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size # Account for new evaluations\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                self.stagnation_counter = 0\n                self.CR = 0.9  # Reset CR\n                self.previous_best = self.f_opt\n\n            # Adjust Crossover Rate (CR) based on success\n            if len(self.success_history) > self.pop_size:\n                 success_rate = np.mean(self.success_history[-self.pop_size:])\n                 self.CR = np.clip(success_rate, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.3682, "other_inf": null}
{"id": "0c74a561-8ecd-45c7-86c8-305448e13008", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "This algorithm combines differential evolution with a covariance matrix adaptation strategy (CMA-ES) to adapt the mutation and crossover parameters based on the population's covariance structure, aiming for faster convergence and better exploration.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.sigma = sigma # Step size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.C = np.eye(dim)  # Covariance matrix\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Update covariance matrix (simplified CMA-ES update)\n            weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n            weights /= np.sum(weights)\n            \n            mean = np.sum(population * weights[:, None], axis=0)\n            \n            C_update = np.zeros_like(self.C)\n            for i in range(self.pop_size):\n                diff = population[i] - mean\n                C_update += weights[i] * np.outer(diff, diff)\n            \n            self.C = (1 - 0.1) * self.C + 0.1 * C_update  # Learning rate\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Sample mutation vector from multivariate normal distribution\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                mutant = a + self.F * (b - c) + self.sigma * z\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.74681, "other_inf": null}
{"id": "8c2c1861-da75-4736-b974-fd2e2be3e680", "parents": ["9cfb8793-40b9-45af-b745-e861ab9fe03c"], "algorithm": "This algorithm uses a differential evolution strategy with a population-based approach and adaptive parameter tuning to explore the search space efficiently.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n                    \n            # Adaptive F and Cr (optional, but can improve performance)\n            if np.random.rand() < 0.1:\n                self.F = np.random.uniform(0.1, 0.9)\n                self.Cr = np.random.uniform(0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "objective": -0.72314, "other_inf": null}
{"id": "b2844cb9-c812-4c54-a629-c5023d4e2300", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts, adapting the step size and covariance matrix of a multivariate normal distribution to efficiently explore the search space and handling stagnation by restarting with a perturbed distribution.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        self.eval_count = 0\n        self.x_mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigenspace_ready = False\n        self.B = None\n        self.D = None\n        self.mueff = None\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_count = 0\n\n    def initialize(self, func):\n        self.x_mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.sigma0\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eigenspace_ready = False\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        if self.eigenspace_ready:\n            y = self.B @ (self.D * z.T)\n            x = self.x_mean + self.sigma * y.T\n        else:\n            x = self.x_mean + self.sigma * z\n        x = np.clip(x, -5.0, 5.0)\n        return x\n\n    def update_distribution(self, x, fitness):\n        x_sorted = x[np.argsort(fitness)]\n        y = (x_sorted[:self.mu] - self.x_mean) / self.sigma\n        \n        self.x_mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n        \n        ps_tmp = np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.linalg.solve(self.B @ np.diag(self.D**2) @ self.B.T, (x_sorted[:self.mu] - self.x_mean).sum(axis=0))\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (x_sorted[:self.mu] - self.x_mean).sum(axis=0) / self.sigma\n        \n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count // self.pop_size))) < (1.4 + 2 / (self.dim + 1)) * np.sqrt(self.dim)\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y.sum(axis=0)\n\n        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + self.cmu * (y.T @ np.diag(self.weights) @ y)\n        \n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n    def prepare_eigenspace(self):\n        try:\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            self.eigenspace_ready = True\n        except np.linalg.LinAlgError:\n            self.C += 1e-6 * np.eye(self.dim)\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(np.maximum(self.D, 1e-16))\n            self.eigenspace_ready = True\n\n    def restart(self, func):\n        self.restart_count += 1\n        self.x_mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.sigma0\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eigenspace_ready = False\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n\n            self.update_distribution(x, fitness)\n            \n            if self.eval_count // self.pop_size % (self.budget // (self.pop_size * self.restarts)) == 0 and self.restart_count < self.restarts - 1:\n                self.restart(func)\n            \n            if not self.eigenspace_ready and self.eval_count > self.dim * 5:\n                self.prepare_eigenspace()\n            \n            if self.eval_count >= self.budget:\n                break\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fc7910e9-5a48-4b3b-b562-ba8586441a3a", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm employs a particle swarm optimization (PSO) strategy with velocity clamping and constriction factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, phi_p=2.05, phi_g=2.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega  # Inertia weight\n        self.phi_p = phi_p  # Personal learning coefficient\n        self.phi_g = phi_g  # Global learning coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.k = 2.0 / abs(2.0 - (self.phi_p + self.phi_g) - np.sqrt((self.phi_p + self.phi_g)**2 - 4 * (self.phi_p + self.phi_g))) if (self.phi_p + self.phi_g) > 4 else 1\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.swarm[best_index]\n        self.global_best_position = self.x_opt.copy()\n\n    def update_swarm(self, func):\n        for i in range(self.pop_size):\n            r_p = np.random.rand(self.dim)\n            r_g = np.random.rand(self.dim)\n\n            # Velocity update with clamping\n            self.velocities[i] = self.k * (self.omega * self.velocities[i] +\n                                       self.phi_p * r_p * (self.personal_best_positions[i] - self.swarm[i]) +\n                                       self.phi_g * r_g * (self.global_best_position - self.swarm[i]))\n\n            v_max = (self.ub - self.lb) * 0.1\n            self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max) #velocity clamping\n\n            # Position update\n            self.swarm[i] += self.velocities[i]\n            self.swarm[i] = np.clip(self.swarm[i], self.lb, self.ub)\n\n            # Evaluate fitness\n            f = func(self.swarm[i])\n            self.budget -= 1\n\n            # Update personal best\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.swarm[i].copy()\n\n            # Update global best\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = self.swarm[i].copy()\n                self.global_best_position = self.x_opt.copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.budget > 0:\n            self.update_swarm(func)\n        return self.f_opt, self.x_opt", "objective": -0.56378, "other_inf": null}
{"id": "89970829-8e60-4720-b9bc-d46209ac76d8", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_percentage=0.5, restart_threshold=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = int(self.pop_size * mu_percentage)\n        self.weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = (1 / self.mueff) * min(1, (2 / ((self.dim + 1.3)**2 + self.mueff)))\n        self.ccovmu = min(1 - self.ccov1, (2 * (self.mueff - 2 + 1/self.mueff)) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n        self.m = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_threshold = restart_threshold\n        self.last_f_opt = np.inf\n        self.no_improvement_count = 0\n\n    def update_decomposition(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.abs(self.D))\n        self.invsqrtC = np.dot(self.B, np.dot(np.diag(self.D**-1), self.B.T))\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        x = self.m + self.sigma * np.dot(z, self.B * self.D)\n        return x, z\n\n    def __call__(self, func):\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.last_f_opt = np.inf\n        self.no_improvement_count = 0\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n\n        while self.eval_count < self.budget:\n            x, z = self.sample_population()\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            y = x_sorted[:self.mu] - self.m\n            z_mu = z_sorted[:self.mu]\n\n            y_w = np.sum((y.T * self.weights).T, axis=0)\n            z_w = np.sum((z_mu.T * self.weights).T, axis=0)\n\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.dot(self.invsqrtC, z_w)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) / self.chiN) < (1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.damps * self.cs) * self.pc + hsig * np.sqrt(self.damps * (2 - self.damps) * self.mueff) * y_w\n\n            artmp = (1 / self.sigma) * y_mu\n            self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * (self.ccovmu > 0) * (2 / (self.sigma**2)) * np.sum((artmp.T * self.weights).T * artmp, axis=0)) * self.C + self.ccov1 * self.pc[:, None] @ self.pc[None, :] + self.ccovmu * np.sum((artmp.T * self.weights).T[:, :, None] * artmp[:, :, None].transpose(0, 2, 1), axis=0)\n\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.m = x_sorted[0] + self.pc\n\n            self.update_decomposition()\n\n            if self.f_opt < self.last_f_opt - self.restart_threshold:\n                self.no_improvement_count = 0\n                self.last_f_opt = self.f_opt\n            else:\n                self.no_improvement_count += self.pop_size\n\n            if self.no_improvement_count > self.budget / 5: #dynamic restart condition\n               self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n               self.sigma *= 2\n               self.ps = np.zeros(self.dim)\n               self.pc = np.zeros(self.dim)\n               self.C = np.eye(self.dim)\n               self.B = np.eye(self.dim)\n               self.D = np.ones(self.dim)\n               self.invsqrtC = np.eye(self.dim)\n               self.no_improvement_count = 0\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "87c335d6-7e7e-4823-8f03-51724c6dfaa6", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.eval_count += 1\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n\n        while self.eval_count < self.budget:\n            x_new = x + np.random.normal(0, temp/10, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            temp *= self.cooling_rate\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                self.eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                temp = self.initial_temp\n\n        return self.f_opt, self.x_opt", "objective": -0.18353, "other_inf": null}
{"id": "74a558e0-6ad4-475e-8aa1-d01f0e3b2b68", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm employs a particle swarm optimization strategy with velocity clamping and dynamic inertia weight adjustment for effective exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max = v_max\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = particles.copy()\n        personal_best_fitnesses = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        best_index = np.argmin(personal_best_fitnesses)\n        self.f_opt = personal_best_fitnesses[best_index]\n        self.x_opt = personal_best_positions[best_index].copy()\n        \n        global_best_position = self.x_opt.copy()\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia * (self.budget / (self.budget + self.pop_size)) #+ 0.4\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_velocity = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_velocity = self.c2 * r2 * (global_best_position - particles[i])\n                \n                velocities[i] = inertia * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)  # Velocity clamping\n                \n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = particles[i].copy()\n                    \n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i].copy()\n                        global_best_position = self.x_opt.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.64796, "other_inf": null}
{"id": "a847b7d1-e6a2-4029-8de5-8b5fd28ea564", "parents": ["90da0ec9-2bad-402c-805c-2a60f1bb07ca", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "A swarm-based approach where particles adjust their positions based on personal best and neighborhood best, with velocity clamping and adaptive inertia weight for exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n\n    def initialize_swarm(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.personal_best_fitness)\n        self.f_opt = self.personal_best_fitness[best_index]\n        self.x_opt = self.personal_best_positions[best_index]\n\n    def update_particle(self, func, i):\n        # Find neighborhood best\n        neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n        best_neighbor_index = neighborhood_indices[np.argmin(self.personal_best_fitness[neighborhood_indices])]\n        \n        # Adaptive inertia weight\n        inertia_adaptive = self.inertia * (0.5 + 0.5 * np.exp(-10 * (self.personal_best_fitness[i] - self.f_opt) / (np.max(self.personal_best_fitness) - self.f_opt + 1e-8)))\n\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = inertia_adaptive * self.velocities[i] + \\\n                            self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                            self.social_coeff * r2 * (self.personal_best_positions[best_neighbor_index] - self.particles[i])\n        \n        # Velocity clamping\n        v_max = (self.ub - self.lb) * 0.1  # Clamp to 10% of the search range\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n        # Update position\n        self.particles[i] = self.particles[i] + self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n        # Evaluate new position\n        f_new = func(self.particles[i])\n        self.budget -= 1\n\n        # Update personal best\n        if f_new < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = f_new\n            self.personal_best_positions[i] = np.copy(self.particles[i])\n\n            # Update global best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = np.copy(self.particles[i])\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                self.update_particle(func, i)\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.54101, "other_inf": null}
{"id": "aee49d97-9f2a-47f2-af42-2b281c594888", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "90da0ec9-2bad-402c-805c-2a60f1bb07ca"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rate, combined with a local search intensification around promising solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.local_search_radius = local_search_radius\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.temp = initial_temp\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.eval_count += 1\n\n        while self.eval_count < self.budget:\n            x_new = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_e = f_new - self.f_opt\n\n            if delta_e < 0:\n                x = x_new\n                self.f_opt = f_new\n                self.x_opt = x\n            else:\n                acceptance_prob = np.exp(-delta_e / self.temp)\n                if np.random.rand() < acceptance_prob:\n                    x = x_new\n\n            self.temp *= self.cooling_rate\n\n            # Adaptive temperature adjustment based on acceptance rate\n            if self.eval_count % 100 == 0:\n                # Estimate acceptance rate\n                num_accepted = 0\n                for _ in range(50):\n                    x_new = x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    x_new = np.clip(x_new, self.lb, self.ub)\n                    f_new = func(x_new)\n\n                    delta_e = f_new - self.f_opt\n                    if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                        num_accepted += 1\n                acceptance_rate = num_accepted / 50.0\n                if acceptance_rate > 0.7:\n                    self.temp *= 1.1  # Increase temperature if too many accepted\n                elif acceptance_rate < 0.3:\n                    self.temp *= 0.9 # Decrease temperature if too few accepted\n                    \n                self.temp = np.clip(self.temp, 1e-6, self.initial_temp) # keep temp within bounds\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "2a20ed00-c6a8-441d-bd77-99b2f3d0b141", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by predicting the objective function and its uncertainty.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, lb=-5.0, ub=5.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        if kernel is None:\n            self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n        self.X = None\n        self.y = None\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n    \n    def acquisition(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma\n    \n    def find_next_point(self, gp):\n        best_x = None\n        best_acq = np.inf\n        for i in range(1000):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition(x, gp)\n            if acq < best_acq:\n                best_acq = acq\n                best_x = x\n        return best_x\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            self.gp.fit(self.X, self.y)\n            \n            x_next = self.find_next_point(self.gp)\n\n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "6d1e9758-4848-4ceb-995e-67a68aaa659e", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation based on the predicted function values and uncertainties.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial = n_initial\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n    def acquisition(self, x):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Lower Confidence Bound\n\n    def __call__(self, func):\n        self.initialize(func)\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n        while self.budget > 0:\n            self.gpr.fit(self.X, self.y)\n            \n            # Find next point to evaluate using acquisition function\n            x_next = None\n            best_acq = np.inf\n            for _ in range(100):\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq = self.acquisition(x_candidate)\n                if acq < best_acq:\n                    best_acq = acq\n                    x_next = x_candidate\n            \n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "8cb5ee04-b40a-450f-afc4-9effd519552c", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm employs a swarm of particles that probabilistically explore the search space, guided by their individual best positions and the global best position discovered so far, while adapting their search behavior using a velocity clamping mechanism.", "code": "import numpy as np\n\nclass ProbabilisticSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(self.lb, self.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find initial global best\n        best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[best_index].copy()\n        self.f_opt = personal_best_fitnesses[best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - swarm[i])\n                social_component = self.social_coeff * r2 * (global_best_position - swarm[i])\n                velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (self.ub - self.lb), self.velocity_clamp * (self.ub - self.lb))\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluation\n                f = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = f\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_position.copy()\n                        global_best_position = new_position.copy()\n\n                swarm[i] = new_position\n\n        return self.f_opt, self.x_opt", "objective": -0.53664, "other_inf": null}
{"id": "30b09f24-c533-4240-89a6-bfbdbb3e44cc", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "# Description: This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation to efficiently find the optimum.\n# Code: \n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n        self.gp.fit(self.X, self.y)\n\n    def acquisition(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Lower confidence bound\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            # Find next point to evaluate using acquisition function\n            x_next = None\n            best_acq = np.inf\n            for _ in range(100): # Sample multiple candidate points\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq = self.acquisition(x_candidate)\n                if acq < best_acq:\n                    best_acq = acq\n                    x_next = x_candidate\n            \n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            self.gp.fit(self.X, self.y)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "6f66fbc2-e170-4b09-8d1e-a1f2f262bf09", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d", "8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "# Description: This algorithm employs a gradient-free approach, iteratively refining a single solution by randomly sampling and accepting better solutions within a shrinking neighborhood.\n# Code:\n```", "code": "import numpy as np\n\nclass SingleSolutionNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = initial_step_size\n\n    def __call__(self, func):\n        # Initialize solution\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        while self.budget > 0:\n            # Generate a neighbor\n            neighbor = x + np.random.normal(0, self.step_size, size=self.dim)\n            neighbor = np.clip(neighbor, self.lb, self.ub)\n\n            # Evaluate the neighbor\n            f_neighbor = func(neighbor)\n            self.budget -= 1\n\n            # Accept if better\n            if f_neighbor < self.f_opt:\n                self.f_opt = f_neighbor\n                self.x_opt = neighbor\n                x = neighbor  # Move to the new solution\n\n            # Reduce step size (simulated annealing-like)\n            self.step_size *= 0.999\n\n            if self.step_size < 1e-6:\n                self.step_size = 1e-6\n\n        return self.f_opt, self.x_opt", "objective": -0.49898, "other_inf": null}
{"id": "d2f959b4-37d7-488e-8518-80b7939e867a", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm combines the strengths of both Differential Evolution (DE) and Particle Swarm Optimization (PSO) by using DE for exploration and PSO for exploitation, adaptively adjusting the balance between them based on performance.", "code": "import numpy as np\n\nclass HybridDE_PSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, de_ratio=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor for DE\n        self.CR = CR  # Crossover rate for DE\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.de_ratio = de_ratio  # Ratio of DE updates vs. PSO updates\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        self.velocities = np.zeros((self.pop_size, self.dim))\n\n\n    def differential_evolution(self, i, func):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, self.lb, self.ub)\n\n        trial = np.copy(self.population[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n\n        f_trial = func(trial)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial\n            self.fitness[i] = f_trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n\n    def particle_swarm_optimization(self, i, func):\n        personal_best = self.population[i]\n        personal_best_fitness = self.fitness[i]\n\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        \n        self.velocities[i] = self.w * self.velocities[i] + \\\n                             self.c1 * r1 * (personal_best - self.population[i]) + \\\n                             self.c2 * r2 * (self.x_opt - self.population[i])\n        \n        new_position = self.population[i] + self.velocities[i]\n        new_position = np.clip(new_position, self.lb, self.ub)\n        \n        f_new = func(new_position)\n        self.budget -= 1\n        \n        if f_new < self.fitness[i]:\n            self.population[i] = new_position\n            self.fitness[i] = f_new\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_position\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_ratio:\n                    self.differential_evolution(i, func)\n                else:\n                    self.particle_swarm_optimization(i, func)\n                    \n        return self.f_opt, self.x_opt", "objective": -0.68189, "other_inf": null}
{"id": "0751a59d-44b5-4040-9023-0d243e78a489", "parents": ["74a558e0-6ad4-475e-8aa1-d01f0e3b2b68"], "algorithm": "# Description: This algorithm implements a differential evolution strategy with self-adaptive parameters and a repair mechanism to maintain feasibility.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                \n                # Repair\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        \n                        \n\n            # Self-adaptive F and CR (optional)\n            self.F = 0.5 #np.random.normal(0.5, 0.1)\n            self.CR = 0.9 #np.random.normal(0.9, 0.1)\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n                        \n        return self.f_opt, self.x_opt", "objective": -0.69603, "other_inf": null}
{"id": "7b60df47-231e-466a-8175-8e968316e4e2", "parents": ["f6a41fd5-4bb1-4542-bf0c-ede1c767cb7d"], "algorithm": "This algorithm combines Differential Evolution with a local search strategy based on the gradient estimation to refine the solutions.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n\n    def local_search(self, func, x, step_size=0.1):\n        \"\"\"Performs a simple gradient-based local search.\"\"\"\n        x_new = np.copy(x)\n        for i in range(self.dim):\n            # Estimate gradient\n            x_plus = np.copy(x)\n            x_minus = np.copy(x)\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n            x_plus[i] = np.clip(x_plus[i], self.lb, self.ub)\n            x_minus[i] = np.clip(x_minus[i], self.lb, self.ub)\n            \n            if self.budget >=2:\n              f_plus = func(x_plus)\n              f_minus = func(x_minus)\n              self.budget -= 2\n\n\n              # Update x if improvement\n              if f_plus < func(x_new):\n                  x_new = x_plus\n              elif f_minus < func(x_new):\n                  x_new = x_minus\n            else:\n              break\n        return x_new\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local Search\n            for i in range(self.pop_size):\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    population[i] = self.local_search(func, population[i])\n                    fitness[i] = func(population[i])\n                    self.budget -= 1\n\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "47ab143b-4534-49a7-92a3-831ea14802d8", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm combines differential evolution with a local search strategy using Nelder-Mead simplex to refine promising solutions within the population.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_freq = local_search_freq\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n\n            # Local Search (Nelder-Mead) on the best solution\n            if self.budget > 0 and np.random.rand() < 1.0 / self.local_search_freq:\n                \n                res = minimize(func, self.x_opt, method='Nelder-Mead',\n                               bounds=np.array([(self.lb, self.ub)] * self.dim),\n                               options={'maxfev': min(self.budget, self.local_search_freq)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9, local_search_freq=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_freq = local_search_freq\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n\n            # Local Search (Nelder-Mead) on the best solution\n            if self.budget > 0 and np.random.rand() < 1.0 / self.local_search_freq:\n                \n                res = minimize(func, self.x_opt, method='Nelder-Mead',\n                               bounds=np.array([(self.lb, self.ub)] * self.dim),\n                               options={'maxfev': min(self.budget, self.local_search_freq)})  # Limit FE\n                \n                if res.fun < self.f_opt:\n                  \n                  self.f_opt = res.fun\n                  self.x_opt = res.x.copy()\n                  \n                self.budget -= res.nfev # account function evaluations\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "541dd910-25ae-4601-a0ae-06f2e18696c4", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm employs a self-adaptive differential evolution strategy with a dynamically adjusted population size based on the progress of optimization, focusing on intensifying the search around promising regions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def adjust_population_size(self):\n        if self.budget > 0:\n            reduction_factor = 0.1\n            new_pop_size = max(10, int(self.pop_size * (1 - reduction_factor)))\n            \n            if new_pop_size < self.pop_size:\n                self.pop_size = new_pop_size\n                sorted_indices = np.argsort(self.fitness)\n                self.population = self.population[sorted_indices[:self.pop_size]]\n                self.fitness = self.fitness[sorted_indices[:self.pop_size]]\n                \n\n    def __call__(self, func):\n        self.initialize_population()\n\n        while self.budget > 0:\n            \n            self.adjust_population_size()\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "8c114a00-954d-412a-af72-33da5b7cc35a", "parents": ["0751a59d-44b5-4040-9023-0d243e78a489"], "algorithm": "# Description: This algorithm implements a Particle Swarm Optimization (PSO) strategy with velocity clamping and constriction factor to control exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.4, c2=1.4, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n        self.constriction_factor = 0.729  # Standard value for constriction factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = fitness.copy()\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (self.x_opt - population[i])\n                \n                velocities[i] = self.constriction_factor * (self.inertia * velocities[i] + cognitive_component + social_component)\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update positions\n                population[i] = population[i] + velocities[i]\n\n                # Boundary handling (clip)\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i].copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.44191, "other_inf": null}
{"id": "0182a2fa-1d0f-49fa-86f9-a932145446c3", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a self-adaptive Differential Evolution (SaDE) approach where mutation and crossover strategies are probabilistically selected and adapted based on their past success, promoting exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.num_strategies = 4\n        self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n        self.memory_size = 10\n        self.success_memory = [[] for _ in range(self.num_strategies)]\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                strategy_index = np.random.choice(self.num_strategies, p=self.probabilities)\n\n                if strategy_index == 0: # DE/rand/1\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + 0.5 * (b - c)\n                elif strategy_index == 1: # DE/best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = best + 0.5 * (b - c)\n                elif strategy_index == 2: # DE/rand/2\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c, d, e = population[np.random.choice(idxs, 5, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + 0.5 * (b - c) + 0.5 * (d - e)\n                else: # DE/current-to-best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = population[i] + 0.5 * (best - population[i]) + 0.5 * (b - c)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                CR = 0.9\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    self.success_memory[strategy_index].append(1)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_memory[strategy_index].append(0)\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if len(self.success_memory[strategy_index]) > self.memory_size:\n                    self.success_memory[strategy_index].pop(0)\n            \n            population = new_population\n            fitness = new_fitness\n\n            # Update probabilities\n            success_rates = [np.mean(s) if s else 0 for s in self.success_memory]\n            sum_success = np.sum(success_rates)\n            if sum_success > 0:\n                self.probabilities = success_rates / sum_success\n            else:\n                self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n\n        return self.f_opt, self.x_opt", "objective": -0.76696, "other_inf": null}
{"id": "d53ebba5-8c78-49f6-89e2-adb51d71aa97", "parents": ["d2f959b4-37d7-488e-8518-80b7939e867a"], "algorithm": "This algorithm implements a Self-Adaptive Differential Evolution (SaDE) strategy where mutation and crossover strategies are probabilistically selected and adjusted based on their recent success.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.mutation_strategies = [self.mutation_1, self.mutation_2]\n        self.crossover_rates = [0.5, 0.9]\n        self.success_counts = np.zeros(len(self.mutation_strategies))\n        self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def mutation_1(self, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, self.lb, self.ub)\n        return mutant\n\n    def mutation_2(self, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = self.population[np.random.choice(idxs, 2, replace=False)]\n        mutant = self.x_opt + self.F * (a - b)\n        mutant = np.clip(mutant, self.lb, self.ub)\n        return mutant\n\n    def crossover(self, individual, mutant, cr):\n        trial = np.copy(individual)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < cr or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def update_strategy_probs(self):\n        total_success = np.sum(self.success_counts)\n        if total_success > 0:\n            self.strategy_probs = self.success_counts / total_success\n        else:\n            self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.strategy_probs = 0.9 * self.strategy_probs + 0.1 / len(self.mutation_strategies)\n        self.strategy_probs /= np.sum(self.strategy_probs)\n        self.success_counts[:] = 0  # Reset success counts\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                strategy_index = np.random.choice(len(self.mutation_strategies), p=self.strategy_probs)\n                mutation_strategy = self.mutation_strategies[strategy_index]\n                mutant = mutation_strategy(i)\n                trial = self.crossover(self.population[i], mutant, self.CR)\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.success_counts[strategy_index] += 1\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            if generation % 10 == 0:\n                self.update_strategy_probs()\n\n        return self.f_opt, self.x_opt", "objective": -0.41979, "other_inf": null}
{"id": "f24b5654-2af5-4ef7-8cc1-0bb5b2743746", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm uses a Gaussian process to model the objective function and sequentially selects points to evaluate based on the Upper Confidence Bound acquisition function, balancing exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessUCB:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.Y = None\n        self.gp = None\n\n    def _acquisition(self, x, kappa=2.576):\n        \"\"\"Upper Confidence Bound acquisition function.\"\"\"\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return mu + kappa * sigma\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        Y_init = np.array([func(x) for x in X_init])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(Y_init)\n        self.f_opt = Y_init[best_index]\n        self.x_opt = X_init[best_index]\n        self.X = X_init\n        self.Y = Y_init\n\n        # Gaussian process model\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-5)\n\n        while self.budget > 0:\n            self.gp.fit(self.X, self.Y)\n\n            # Select next point to evaluate\n            x_next = None\n            best_acq = -np.inf\n            n_candidates = min(1000, self.budget)  # Reduce candidate size when budget is low\n            X_candidates = np.random.uniform(self.lb, self.ub, size=(n_candidates, self.dim))\n            for x in X_candidates:\n                acq = self._acquisition(x)\n                if acq > best_acq:\n                    best_acq = acq\n                    x_next = x\n\n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.Y = np.append(self.Y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "341b5994-e6da-48fb-89f3-3704f93c6387", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm employs a Gaussian process surrogate model to estimate the objective function, guiding the search towards promising regions while balancing exploration and exploitation using an acquisition function.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        if kernel is None:\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2*sigma  # Lower Confidence Bound\n\n    def __call__(self, func):\n        # Initial random sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            self.gp.fit(self.X, self.y)\n            \n            # Find next point to evaluate\n            x_next = None\n            best_acq = np.inf\n            n_candidates = 100\n            candidates = np.random.uniform(self.lb, self.ub, size=(n_candidates, self.dim))\n\n            for x in candidates:\n                acq = self.acquisition_function(x, self.gp)\n                if acq < best_acq:\n                    best_acq = acq\n                    x_next = x\n\n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update the best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f5f559ef-8708-4ddc-91db-dd8aa8a8c8eb", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0751a59d-44b5-4040-9023-0d243e78a489"], "algorithm": "This algorithm employs a Gaussian Process surrogate model to guide the search for the optimum, balancing exploration and exploitation by sampling from the posterior distribution of the GP, and updating the GP with each new function evaluation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.evaluated = 0\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2*sigma  # Optimizing for minimum value\n\n    def __call__(self, func):\n        # Initial sampling\n        initial_X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        initial_y = np.array([func(x) for x in initial_X])\n        self.budget -= self.n_initial_samples\n        self.evaluated += self.n_initial_samples\n\n        self.X = initial_X\n        self.y = initial_y\n\n        best_index = np.argmin(initial_y)\n        self.f_opt = initial_y[best_index]\n        self.x_opt = initial_X[best_index]\n\n        while self.budget > 0:\n            # Fit GP model\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            best_x = None\n            best_acq = np.inf\n            for _ in range(100):  # Sample candidate points\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq_value = self.acquisition_function(x_candidate, self.gp)\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    best_x = x_candidate\n            \n            # Evaluate function at new point\n            f_new = func(best_x)\n            self.budget -= 1\n            self.evaluated += 1\n\n            # Update data\n            self.X = np.vstack((self.X, best_x))\n            self.y = np.append(self.y, f_new)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = best_x\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "00eebbd5-09b7-46ba-8905-72532e72656f", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm employs a Krill Herd Optimization approach, simulating the herding behavior of krill to find optimal solutions, where krill movement is influenced by other krill, foraging activity, and random diffusion.", "code": "import numpy as np\n\nclass KrillHerd:\n    def __init__(self, budget=10000, dim=10, pop_size=50, Nmax=0.01, Vf=0.02, Dmax=0.005):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.Nmax = Nmax  # Maximum induced speed\n        self.Vf = Vf  # Foraging speed\n        self.Dmax = Dmax  # Maximum diffusion speed\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.krill = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.delta_t = 1\n\n    def calculate_fitness(self, func):\n        for i in range(self.pop_size):\n            if self.budget > 0:\n                self.fitness[i] = func(self.krill[i])\n                self.budget -= 1\n            else:\n                self.fitness[i] = np.inf\n        return self.fitness\n    \n    def calculate_induced_motion(self, krill_index):\n        Si = np.zeros(self.dim)\n        for j in range(self.pop_size):\n            if j != krill_index:\n                dist = np.linalg.norm(self.krill[krill_index] - self.krill[j])\n                alpha = np.exp(-dist / (2 * self.sigma))\n                Si += (self.fitness[j] - self.fitness[krill_index]) * alpha * (self.krill[j] - self.krill[krill_index])\n        return self.Nmax * Si\n\n    def calculate_foraging_motion(self, krill_index):\n        Fi = np.zeros(self.dim)\n        best_index = np.argmin(self.fitness)\n        dist = np.linalg.norm(self.krill[krill_index] - self.krill[best_index])\n        beta = np.exp(-dist / (2 * self.sigma))\n        Fi = self.Vf * beta * (self.krill[best_index] - self.krill[krill_index])\n        return Fi\n    \n    def calculate_diffusion_motion(self):\n        Di = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * self.Dmax\n        return Di\n\n    def __call__(self, func):\n        self.sigma = (self.ub - self.lb) / 2 \n        self.fitness = self.calculate_fitness(func)\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.krill[best_index]\n\n        while self.budget > 0:\n            new_krill = np.copy(self.krill)\n            for i in range(self.pop_size):\n                induced_motion = self.calculate_induced_motion(i)\n                foraging_motion = self.calculate_foraging_motion(i)\n                diffusion_motion = self.calculate_diffusion_motion()[i]\n\n                new_krill[i] = self.krill[i] + self.delta_t * (induced_motion + foraging_motion + diffusion_motion)\n                new_krill[i] = np.clip(new_krill[i], self.lb, self.ub)\n\n            self.krill = new_krill\n            self.fitness = self.calculate_fitness(func)\n            \n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.krill[best_index]\n            \n        return self.f_opt, self.x_opt", "objective": -0.17327, "other_inf": null}
{"id": "ebda476a-e644-4deb-b6bd-b0b9e02837ca", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on acceptance rates.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.99, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.acceptance_rate = 0.0\n        self.acceptance_window = 100\n        self.accepted_moves = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n\n        while self.budget > 0:\n            # Generate neighbor\n            x_new = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n            \n            # Acceptance criterion\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new\n                f = f_new\n                self.accepted_moves += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Temperature update\n            if self.budget % self.acceptance_window == 0:\n                self.acceptance_rate = self.accepted_moves / self.acceptance_window\n                self.accepted_moves = 0\n                \n                if self.acceptance_rate > 0.6:\n                    self.step_size *= 1.1 #Explore wider\n                elif self.acceptance_rate < 0.4:\n                    self.step_size *= 0.9 #Exploit narrower\n                \n                self.temp *= self.alpha #Cooling schedule\n\n        return self.f_opt, self.x_opt", "objective": -0.27771, "other_inf": null}
{"id": "5e368800-37e9-47ec-8c00-19debe8f42cd", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "0751a59d-44b5-4040-9023-0d243e78a489"], "algorithm": "# Description: This algorithm combines the strengths of particle swarm optimization and simulated annealing, using PSO to explore the search space and simulated annealing to refine the solutions and escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass PSO_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, temp_init=1.0, temp_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.temp = temp_init  # Initial temperature for SA\n        self.temp_decay = temp_decay # Temperature decay rate\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (self.x_opt - population[i]))\n\n                # Update positions\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                else:\n                    # Simulated Annealing\n                    delta_e = f - personal_best_fitness[i]\n                    if delta_e > 0:\n                        p = np.exp(-delta_e / self.temp)\n                        if np.random.rand() < p:\n                            personal_best_fitness[i] = f\n                            personal_best_positions[i] = population[i].copy()\n\n                            # Update global best\n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = population[i].copy()\n\n            # Decay temperature\n            self.temp *= self.temp_decay\n\n        return self.f_opt, self.x_opt", "objective": -0.45807, "other_inf": null}
{"id": "c6f93d98-c7d5-4112-a10e-cc50e9999f51", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "A population-based algorithm that uses a combination of global search and local refinement, where individuals adapt their search behavior based on the local gradient information and distance to the population mean.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.learning_rate = learning_rate\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            mean_position = np.mean(population, axis=0)\n\n            for i in range(self.pop_size):\n                # Local gradient estimation (simplified)\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                x_perturbed = np.clip(population[i] + perturbation, self.lb, self.ub)\n                f_perturbed = func(x_perturbed)\n                self.budget -= 1\n\n                if f_perturbed < fitness[i]:\n                  gradient_estimate = x_perturbed - population[i]\n                  step_size = self.learning_rate\n                else:\n                  gradient_estimate = population[i] - x_perturbed\n                  step_size = -self.learning_rate\n                \n                # Move towards population mean with some randomness\n                new_position = population[i] + step_size * gradient_estimate + 0.1 * np.random.normal(0, 1, self.dim) + 0.01*(mean_position - population[i])\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                f_new = func(new_position)\n                self.budget -= 1\n\n                if f_new < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position\n\n                if self.budget <= 0:\n                  break\n\n        return self.f_opt, self.x_opt", "objective": -0.25676, "other_inf": null}
{"id": "8dda5641-6032-4387-8cf3-9ca223317db9", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm adaptively adjusts the step size of each dimension based on the success rate of previous steps, promoting exploration in promising directions and exploitation around optima.", "code": "import numpy as np\n\nclass AdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = np.full(dim, initial_step_size)\n        self.success_rate = np.zeros(dim)\n        self.memory_size = 10\n        self.success_history = [[] for _ in range(dim)]\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.budget -= 1\n\n        while self.budget > 0:\n            dim_index = np.random.randint(self.dim)\n            original_x = np.copy(x)\n            step = self.step_size[dim_index] * np.random.normal()\n            x[dim_index] += step\n\n            x = np.clip(x, self.lb, self.ub)\n            f = func(x)\n            self.budget -= 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                self.success_history[dim_index].append(1)\n                self.step_size[dim_index] *= (1 + self.learning_rate)\n            else:\n                x = original_x\n                f = self.f_opt # keep the best\n                self.success_history[dim_index].append(0)\n                self.step_size[dim_index] *= (1 - self.learning_rate)\n\n            if len(self.success_history[dim_index]) > self.memory_size:\n                self.success_history[dim_index].pop(0)\n            \n            self.success_rate[dim_index] = np.mean(self.success_history[dim_index]) if self.success_history[dim_index] else 0\n\n            self.step_size = np.clip(self.step_size, 1e-6, self.ub - self.lb)\n\n        return self.f_opt, self.x_opt", "objective": -0.21152, "other_inf": null}
{"id": "50f4dacb-3413-4137-a030-ba91d031ab3e", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm uses a modified differential evolution strategy with a shrinking population size and intensified local search around the best solution found so far.", "code": "import numpy as np\n\nclass ShrinkingDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = shrink_factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def evolve(self, func):\n        new_population = []\n        new_fitness = []\n        \n        for i in range(self.pop_size):\n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = self.population[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    trial[j] = mutant[j]\n\n            # Selection\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                new_fitness.append(f)\n                new_population.append(trial)\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial.copy()\n            else:\n                new_fitness.append(self.fitness[i])\n                new_population.append(self.population[i])\n\n            if self.budget <= 0:\n                break\n                \n        self.population = np.array(new_population)\n        self.fitness = np.array(new_fitness)\n        \n        # Shrink population and intensify local search\n        if len(self.population) > 1 and np.random.rand() < 0.2:\n            num_to_keep = int(self.pop_size * self.shrink_factor)\n            indices = np.argsort(self.fitness)[:num_to_keep]\n            self.population = self.population[indices]\n            self.fitness = self.fitness[indices]\n            self.pop_size = len(self.population)\n            \n            # Local search around best solution\n            for i in range(min(5, self.budget)):\n                x = self.x_opt + np.random.normal(0, 0.1, size=self.dim)\n                x = np.clip(x, self.lb, self.ub)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n                if self.budget <= 0:\n                  break\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9f3df4b7-edcc-40b1-b17a-c0a3278a9887", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "# Description: This algorithm combines Particle Swarm Optimization (PSO) with a mutation operator inspired by Differential Evolution (DE) to balance exploration and exploitation, adapting the PSO's velocity updates based on the best-performing particles and random differences to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index]\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity with PSO components\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                # Apply mutation using DE inspired strategy\n                if np.random.rand() < self.mutation_rate:\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b = population[np.random.choice(idxs, 2, replace=False)]\n                    mutation_vector = a - b\n                    velocities[i] += 0.5 * mutation_vector  # Incorporate mutation into velocity\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub) # Clip to bounds\n\n\n                f_trial = func(new_position)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = f_trial\n                    \n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = new_position\n                        \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = new_position\n                        global_best_position = new_position\n\n        return self.f_opt, self.x_opt", "objective": -0.38865, "other_inf": null}
{"id": "e5473484-86eb-49bf-9cd7-86e622e85ff7", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm employs a population-based approach with a velocity update rule inspired by Particle Swarm Optimization (PSO), but incorporates a self-adaptive learning rate mechanism to dynamically adjust the influence of the personal best and global best positions during the search process, enhancing both exploration and convergence.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.learning_rate_personal = 0.7\n        self.learning_rate_global = 0.7\n\n    def initialize_population(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(self.personal_best_fitness)\n        self.global_best_position = self.personal_best_positions[best_index]\n        self.global_best_fitness = self.personal_best_fitness[best_index]\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n    def update_velocities(self):\n        inertia_weight = 0.5\n        cognitive_component = self.learning_rate_personal * np.random.rand(self.pop_size, self.dim) * (self.personal_best_positions - self.particles)\n        social_component = self.learning_rate_global * np.random.rand(self.pop_size, self.dim) * (self.global_best_position - self.particles)\n        self.velocities = inertia_weight * self.velocities + cognitive_component + social_component\n\n    def update_positions(self):\n        self.particles = self.particles + self.velocities\n        self.particles = np.clip(self.particles, self.lb, self.ub)\n\n    def update_personal_and_global_best(self, func):\n        fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness[i]\n                self.personal_best_positions[i] = self.particles[i]\n\n        best_index = np.argmin(self.personal_best_fitness)\n        if self.personal_best_fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.personal_best_fitness[best_index]\n            self.global_best_position = self.personal_best_positions[best_index]\n            self.f_opt = self.global_best_fitness\n            self.x_opt = self.global_best_position\n\n    def adjust_learning_rates(self):\n        if np.random.rand() < 0.1:\n            self.learning_rate_personal = np.random.uniform(0.1, 0.9)\n            self.learning_rate_global = np.random.uniform(0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > self.pop_size:\n            self.update_velocities()\n            self.update_positions()\n            self.update_personal_and_global_best(func)\n            self.adjust_learning_rates()\n\n        return self.f_opt, self.x_opt", "objective": -0.52416, "other_inf": null}
{"id": "5688494d-189c-47bc-bb26-bcf5fb533967", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "# Description: This algorithm employs a population-based approach with velocity and position updates inspired by Particle Swarm Optimization (PSO), but adapts the inertia weight and acceleration coefficients using a self-adaptive mechanism based on the success rate of particles, balancing exploration and exploitation dynamically.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity = None\n        self.personal_best_position = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 10\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.personal_best_position = np.copy(population)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        self.personal_best_fitness = np.copy(fitness)\n        best_index = np.argmin(fitness)\n        self.global_best_position = population[best_index]\n        self.global_best_fitness = fitness[best_index]\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            self.velocity = (self.inertia_weight * self.velocity +\n                             self.c1 * r1 * (self.personal_best_position - population) +\n                             self.c2 * r2 * (self.global_best_position - population))\n\n            population += self.velocity\n            population = np.clip(population, self.lb, self.ub)\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            improved = new_fitness < self.personal_best_fitness\n            self.success_history.extend(improved)\n            self.personal_best_position[improved] = population[improved]\n            self.personal_best_fitness[improved] = new_fitness[improved]\n\n            best_index = np.argmin(self.personal_best_fitness)\n            if self.personal_best_fitness[best_index] < self.global_best_fitness:\n                self.global_best_position = self.personal_best_position[best_index]\n                self.global_best_fitness = self.personal_best_fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n            \n            #Adaptive Inertia Weight and Acceleration Coefficients\n            if len(self.success_history) > self.history_length:\n                self.success_rate = np.mean(self.success_history[-self.history_length:])\n            else:\n                self.success_rate = np.mean(self.success_history) if self.success_history else 0\n\n            self.inertia_weight = 0.7 + 0.2 * (1-self.success_rate)  # Adjust inertia weight\n\n            self.c1 = 1.5 + 0.5 * self.success_rate       # Adjust c1\n            self.c2 = 1.5 + 0.5 * self.success_rate       # Adjust c2\n                \n\n        return self.f_opt, self.x_opt", "objective": -0.36054, "other_inf": null}
{"id": "33b70706-6146-40a9-9ea0-082d8a5ae0bf", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm implements a simplified Particle Swarm Optimization (PSO) with velocity clamping and inertia weight adaptation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SimplifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=2.0, social_coeff=2.0, velocity_clamp=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index]\n        global_best_position = np.copy(population[global_best_index])\n\n        iteration = 0\n        while self.budget > 0:\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * iteration / (self.budget // self.pop_size + iteration + 1)\n            \n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                velocities[i] = (inertia * velocities[i]\n                                 + self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                                 + self.social_coeff * r2 * (global_best_position - population[i]))\n                \n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                f_current = func(population[i])\n                self.budget -= 1\n\n                if f_current < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_current\n                    personal_best_positions[i] = np.copy(population[i])\n\n                    if f_current < self.f_opt:\n                        self.f_opt = f_current\n                        self.x_opt = np.copy(population[i])\n                        global_best_position = np.copy(population[i])\n\n            iteration += 1\n\n        return self.f_opt, self.x_opt", "objective": -0.5381, "other_inf": null}
{"id": "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a self-adaptive Differential Evolution (SaDE) strategy to dynamically adjust the mutation and crossover parameters based on the success rate of previous generations, promoting a balance between exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0,\n                 num_strategies=4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.num_strategies = num_strategies\n        self.mutation_factors = np.random.uniform(0.5, 1.0, size=num_strategies)\n        self.crossover_rates = np.random.uniform(0.5, 1.0, size=num_strategies)\n        self.success_rates_F = np.ones(num_strategies) / num_strategies\n        self.success_rates_CR = np.ones(num_strategies) / num_strategies\n        self.memory_F = np.zeros(num_strategies)\n        self.memory_CR = np.zeros(num_strategies)\n        self.memory_p = 0.1\n        self.archive_size = int(self.pop_size / 2)\n        self.archive = []\n    \n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.success_rates_F / np.sum(self.success_rates_F))\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.mutation_factors[strategy_index] * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rates[strategy_index] or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update success rates\n                    self.success_rates_F[strategy_index] = (1 - self.memory_p) * self.success_rates_F[strategy_index] + self.memory_p\n                    self.success_rates_CR[strategy_index] = (1 - self.memory_p) * self.success_rates_CR[strategy_index] + self.memory_p\n\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                     self.success_rates_F[strategy_index] = (1 - self.memory_p) * self.success_rates_F[strategy_index]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.76931, "other_inf": null}
{"id": "5a4be93b-1214-4114-9a77-272b6542252c", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm employs a self-adaptive differential evolution strategy with a shrinking population size to balance exploration and exploitation, adjusting the mutation factor and crossover rate based on the population's success.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0 and self.pop_size > 3:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Dynamic adjustment of F and CR\n            success_indices = fitness < np.mean(fitness)\n            if np.sum(success_indices) > 0:\n                self.F = np.mean(np.random.uniform(0.4, 0.9, size=np.sum(success_indices)))\n                self.CR = np.mean(np.random.uniform(0.7, 1.0, size=np.sum(success_indices)))\n            else:\n                self.F = 0.5  # Reset if no improvement\n                self.CR = 0.9\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Shrink the population\n            self.pop_size = int(self.pop_size * self.shrink_factor)\n            population = population[:self.pop_size]\n            fitness = fitness[:self.pop_size]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.35605, "other_inf": null}
{"id": "1374ef0c-39c0-418b-9b08-922a4a992740", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm uses a self-adaptive Differential Evolution (SaDE) approach with a larger population size, adjusted mutation rates, and a dynamic crossover strategy to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.num_strategies = 4\n        self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n        self.memory_size = 10\n        self.success_memory = [[] for _ in range(self.num_strategies)]\n        self.mutation_factor = 0.7\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                strategy_index = np.random.choice(self.num_strategies, p=self.probabilities)\n\n                if strategy_index == 0: # DE/rand/1\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + self.mutation_factor * (b - c)\n                elif strategy_index == 1: # DE/best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = best + self.mutation_factor * (b - c)\n                elif strategy_index == 2: # DE/rand/2\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    a, b, c, d, e = population[np.random.choice(idxs, 5, replace=False)]\n                    mutant = population[np.random.choice(idxs)] + self.mutation_factor * (b - c) + self.mutation_factor * (d - e)\n                else: # DE/current-to-best/1\n                    best = population[np.argmin(fitness)]\n                    idxs = [idx for idx in range(self.pop_size) if idx != i]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = population[i] + self.mutation_factor * (best - population[i]) + self.mutation_factor * (b - c)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                \n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    self.success_memory[strategy_index].append(1)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_memory[strategy_index].append(0)\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if len(self.success_memory[strategy_index]) > self.memory_size:\n                    self.success_memory[strategy_index].pop(0)\n            \n            population = new_population\n            fitness = new_fitness\n\n            # Update probabilities\n            success_rates = [np.mean(s) if s else 0 for s in self.success_memory]\n            sum_success = np.sum(success_rates)\n            if sum_success > 0:\n                self.probabilities = success_rates / sum_success\n            else:\n                self.probabilities = np.ones(self.num_strategies) / self.num_strategies\n            self.mutation_factor = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n            self.crossover_rate = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "objective": -0.54487, "other_inf": null}
{"id": "34d621cd-a5fe-4e0c-b37f-2c23cbf051b2", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a Gaussian process surrogate model to predict the fitness landscape and an acquisition function to balance exploration and exploitation by selecting points for evaluation, iteratively refining the surrogate model and converging towards the optimum.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.gp = None\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Lower Confidence Bound\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Gaussian process regression\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while self.budget > 0:\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            x_next = None\n            best_acq = np.inf\n            for _ in range(100):  # Sample multiple points and choose the best one\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq = self.acquisition_function(x_candidate, self.gp)\n                if acq < best_acq:\n                    best_acq = acq\n                    x_next = x_candidate\n\n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "67248528-5403-4e81-8207-c3d968d4b6d8", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by predicting function values and uncertainties, and iteratively updating the model with new evaluations.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10, alpha=1e-10)\n\n    def acquisition_function(self, x, gp, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        mu = mu[0]\n        sigma = sigma[0]\n\n        if sigma == 0:\n          return 0\n        \n        imp = self.f_opt - mu - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate\n            best_x = None\n            best_acq = -np.inf\n            for _ in range(100): # Sample multiple times and pick the best\n              x_rand = np.random.uniform(self.lb, self.ub, size=self.dim)\n              acq_value = self.acquisition_function(x_rand, self.gp)\n              if acq_value > best_acq:\n                  best_acq = acq_value\n                  best_x = x_rand\n\n            \n            x_next = best_x\n            \n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n            \n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            \n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ea109031-ac45-4408-a4c4-0a598be03591", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm uses a Gaussian process surrogate model to predict the fitness landscape and employs an acquisition function to balance exploration and exploitation when selecting new points to evaluate.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n        \n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=0)\n        self.gpr.fit(self.X, self.y)\n\n    def acquisition_function(self, x, xi=0.01):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        mu = mu[0]\n        sigma = sigma[0]\n        return (self.f_opt - mu - xi * sigma)\n\n    def optimize_acquisition(self):\n        best_x = None\n        best_acq = -np.inf\n        for _ in range(100):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition_function(x)\n            if acq > best_acq:\n                best_acq = acq\n                best_x = x\n        return best_x\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.budget > 0:\n            x_new = self.optimize_acquisition()\n            f_new = func(x_new)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n            self.gpr.fit(self.X, self.y)\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "74bbc46d-0033-43f2-aba7-0b025b58d35d", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a Gaussian process to model the objective function and sequentially selects points to evaluate by maximizing an acquisition function that balances exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n        \n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n    def acquisition_function(self, x, gpr, xi=0.01):\n        mu, sigma = gpr.predict(x.reshape(1, -1), return_std=True)\n        return mu + xi * sigma\n\n    def find_next_point(self, gpr):\n        best_x = None\n        best_acq = -np.inf\n        for i in range(1000):  # Sample many points and pick the best\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition_function(x, gpr)\n            if acq > best_acq:\n                best_acq = acq\n                best_x = x\n        return best_x\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n\n        while self.budget > 0:\n            self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n            self.gpr.fit(self.X, self.y)\n            \n            x_next = self.find_next_point(self.gpr)\n            f_next = func(x_next)\n            self.budget -= 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n                \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a19a94c5-8aaa-438d-9b02-5672c5b88d61", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm employs a population-based approach where individuals probabilistically move towards promising regions identified by kernel density estimation of the top-performing solutions.", "code": "import numpy as np\nfrom scipy.stats import gaussian_kde\n\nclass KernelDensityEstimationOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, top_fraction=0.25, bw_method=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.top_fraction = top_fraction\n        self.bw_method = bw_method\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Select top individuals\n            num_top = int(self.pop_size * self.top_fraction)\n            top_indices = np.argsort(fitness)[:num_top]\n            top_individuals = population[top_indices]\n\n            # Kernel density estimation\n            try:\n                kde = gaussian_kde(top_individuals.T, bw_method=self.bw_method)\n            except np.linalg.LinAlgError:\n                # Fallback to a wider bandwidth if covariance is singular\n                kde = gaussian_kde(top_individuals.T, bw_method=0.5) # or some other value\n\n            # Generate new samples\n            new_samples = kde.resample(self.pop_size)\n            new_samples = np.clip(new_samples.T, self.lb, self.ub)\n\n            # Evaluate new samples\n            new_fitness = np.array([func(x) for x in new_samples])\n            self.budget -= self.pop_size\n            \n            # Update population\n            population = new_samples\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "467dceab-616f-4d11-86ed-a29e1b400c8e", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "A population-based algorithm employing a Gaussian Mixture Model (GMM) to adaptively sample promising regions of the search space, iteratively refining the GMM based on the fitness of the sampled individuals.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GMMOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.n_components = n_components\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.gmm = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Fit GMM to top individuals\n            top_indices = np.argsort(fitness)[:self.pop_size // 2]\n            top_population = population[top_indices]\n            \n            if len(top_population) > self.n_components:\n              self.gmm = GaussianMixture(n_components=self.n_components, random_state=0, covariance_type='full', max_iter=10) #full, tied, diag, spherical\n              self.gmm.fit(top_population)\n\n              # Sample new individuals from GMM\n              new_population, _ = self.gmm.sample(self.pop_size)\n              new_population = np.clip(new_population, self.lb, self.ub)\n            else:\n                new_population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                \n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Combine old and new populations\n            population = np.concatenate((population, new_population))\n            fitness = np.concatenate((fitness, new_fitness))\n\n            # Select best individuals for next iteration\n            indices = np.argsort(fitness)[:self.pop_size]\n            population = population[indices]\n            fitness = fitness[indices]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "7f769a82-0e59-4e9b-871e-35dd2ab34e77", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680", "8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, alpha=0.99, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.temp = temp_init\n        self.alpha = alpha\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x.copy()\n\n        while self.budget > 0:\n            x_new = x + np.random.normal(0, self.temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n\n            self.temp *= self.alpha  #Cooling\n\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                  self.f_opt = f\n                  self.x_opt = x.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.21184, "other_inf": null}
{"id": "b4adc653-526a-400b-a40e-7939fea1b2fb", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm employs a population-based approach where individuals learn from the best solution found so far and a randomly selected individual, while also incorporating a velocity-based update mechanism to guide the search.", "code": "import numpy as np\n\nclass VelocityEnhancedLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.velocity = None\n\n    def __call__(self, func):\n        # Initialize population and velocity\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                # Learn from global best and a random individual\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                random_index = np.random.choice(idxs)\n\n                self.velocity[i] = (self.w * self.velocity[i] +\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                self.c2 * r2 * (self.x_opt - population[i]))\n                \n                # Update position\n                new_position = population[i] + self.velocity[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluation\n                f_new = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f_new < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_new\n                    personal_best_positions[i] = new_position\n\n                # Update global best\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = new_position\n                \n                population[i] = new_position\n                fitness[i] = f_new\n                \n        return self.f_opt, self.x_opt", "objective": -0.46705, "other_inf": null}
{"id": "4e293ce4-e08a-4a13-9be8-dac583c144df", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a restart mechanism to adapt the search distribution and escape local optima, focusing on efficient exploration through principal component analysis of the covariance matrix.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = initial_step_size\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu))**0.5\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = 1000\n        self.eval_count = 0\n        self.restart_count = 0\n\n    def __call__(self, func):\n        while self.budget > 0:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            C_sqrt = np.linalg.cholesky(self.C)\n            x = self.m + self.sigma * z @ C_sqrt.T\n            x = np.clip(x, self.lb, self.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            idx = np.argsort(fitness)\n            x_mu = x[idx[:self.mu]]\n            z_mu = z[idx[:self.mu]]\n            \n            y = x_mu - self.m\n            y_w = np.sum(self.weights[:, None] * y, axis=0)\n            z_w = np.sum(self.weights[:, None] * z_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_w\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * np.sqrt(np.sum(self.weights**2)) * C_sqrt @ z_w\n            \n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n            \n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n            self.C += self.c_mu * (z_mu.T @ np.diag(self.weights) @ z_mu)\n\n            self.m = x_mu.T @ self.weights\n            \n            if np.any(np.isnan(self.C)):\n                self.C = np.eye(self.dim)\n            \n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            if self.eval_count - self.restart_count * self.restart_trigger > self.restart_trigger:\n                self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = 0.2\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.restart_count += 1\n                \n\n        return self.f_opt, self.x_opt", "objective": -0.24917, "other_inf": null}
{"id": "7c36cc22-e70b-46db-ae54-ec7065c94370", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "'maxfev': self.budget", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, de_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.de_steps = de_steps\n        self.F = 0.7\n        self.CR = 0.9\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        for _ in range(self.de_steps):\n            if self.budget <= 0:\n                break\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        # Local Search\n        if self.budget > self.dim * 10:\n            result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev': self.budget})\n            if result.fun < self.f_opt:\n                self.f_opt = result.fun\n                self.x_opt = result.x\n            self.budget -= result.nfev\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "16b580f3-1758-4bad-9fbb-d4e42ab8a615", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm combines a simplified CMA-ES strategy for covariance adaptation with a population-based stochastic gradient descent (PBSGD) approach to update individuals, leveraging the covariance matrix to guide the search direction and a momentum term to accelerate convergence.", "code": "import numpy as np\n\nclass CMAES_PBSGD:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.01, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.momentum = momentum\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.C = np.eye(dim)  # Covariance matrix\n        self.velocity = np.zeros((pop_size, dim))\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Update covariance matrix (simplified CMA-ES update)\n            weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n            weights /= np.sum(weights)\n            \n            mean = np.sum(population * weights[:, None], axis=0)\n            \n            C_update = np.zeros_like(self.C)\n            for i in range(self.pop_size):\n                diff = population[i] - mean\n                C_update += weights[i] * np.outer(diff, diff)\n            \n            self.C = (1 - 0.1) * self.C + 0.1 * C_update  # Learning rate\n\n            # Population-based Stochastic Gradient Descent\n            for i in range(self.pop_size):\n                # Sample search direction from multivariate normal distribution\n                direction = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n\n                # Update velocity with momentum\n                self.velocity[i] = self.momentum * self.velocity[i] + self.learning_rate * direction\n\n                # Update individual position\n                trial = population[i] - self.velocity[i] # Gradient Descent\n                trial = np.clip(trial, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.22064, "other_inf": null}
{"id": "469512c7-f57d-4421-9fb5-04f0b8f1162f", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a self-adaptive differential evolution (SaDE) approach, where mutation and crossover strategies are dynamically adjusted based on their past success, combined with a local search operator to refine solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.strategy_probs = np.array([0.5, 0.5])  # Probabilities for DE strategies\n        self.num_strategies = 2\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        success_memory_fitness = np.zeros((self.pop_size,self.num_strategies))\n        success_memory_locations = np.zeros((self.pop_size,self.num_strategies,self.dim))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Strategy selection\n                strategy_index = np.random.choice(self.num_strategies, p=self.strategy_probs)\n\n                # Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                if strategy_index == 0: # DE/rand/1\n                    mutant = population[np.random.choice(idxs, 1, replace=False)][0] + self.F * (b - c)\n                else: # DE/current-to-best/1\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (b - c)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Local search with a probability\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, func) #changed from population[i] to trial because we are searching around trial\n                    trial = np.clip(trial, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                    success_memory_fitness[i,strategy_index] = f_trial\n                    success_memory_locations[i,strategy_index] = trial\n                    \n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Update strategy probabilities (simplified)\n            success_rate = np.mean(success_memory_fitness < fitness[:,None], axis=0) #this is not working\n            self.strategy_probs = (success_rate + 0.01) / np.sum(success_rate + 0.01) # avoid division by zero\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, x, func, radius=0.1, num_steps=5):\n        \"\"\"Performs a simple local search around the given solution.\"\"\"\n        best_x = x\n        best_f = func(x)\n        self.budget -= 1 #Important for not exceeding the budget\n        \n        for _ in range(num_steps):\n            # Generate a random neighbor within the radius\n            neighbor = x + np.random.uniform(-radius, radius, size=self.dim)\n            neighbor = np.clip(neighbor, self.lb, self.ub)\n            \n            f_neighbor = func(neighbor)\n            self.budget -= 1 #Important for not exceeding the budget\n            \n            if f_neighbor < best_f:\n                best_f = f_neighbor\n                best_x = neighbor\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d8af3141-295b-4b04-b213-8b450eed2e49", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) which adaptively updates the covariance matrix of a multivariate normal distribution to efficiently explore the search space, focusing on promising regions and adjusting the step size based on the success of previous steps.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0,\n                 sigma0=0.5, cs=0.3, dsigma=1.0, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.sigma = sigma0\n        self.mean = np.random.uniform(lb, ub, size=dim)\n        self.C = np.eye(dim)\n        self.ps = np.zeros(dim)\n        self.pc = np.zeros(dim)\n        self.cs = cs\n        self.dsigma = dsigma\n        self.c_cov = c_cov\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_s = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_cov = (1 / self.mueff) * ((self.mueff - 2 + 1/self.mueff) / (self.dim + 2)**2 + (2 - 1/self.mueff) / ((self.dim + 2) * np.sqrt(self.mueff + 2)))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Generate population\n            Z = np.random.randn(self.pop_size, self.dim)\n            X = self.mean + self.sigma * Z @ np.linalg.cholesky(self.C).T\n            X = np.clip(X, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[idx]\n\n            # Update best\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[0]\n\n            # Update mean\n            xmean = np.sum(X[:self.mu].T * self.weights, axis=1)\n            y = (xmean - self.mean) / self.sigma\n            self.mean = xmean\n\n            # Update evolution path\n            self.ps = (1 - self.c_s) * self.ps + np.sqrt(self.c_s * (2 - self.c_s) * self.mueff) * y\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_s)**2)**0.5 / np.sqrt(self.dim) < 1.4 + 2 / (self.dim + 1)\n\n            # Update covariance matrix\n            self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov) * self.mueff) * y\n            artmp = (X[:self.mu] - np.tile(self.mean, (self.mu, 1))).T / self.sigma\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (1 / self.mueff * (self.pc[:, None] @ self.pc[None, :]) + np.sum(self.weights[:, None, None] * artmp[:, :, None] @ artmp[:, None, :], axis=0))\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / (np.sqrt(self.dim) * (1 - (1 - self.cs)**(2 * (self.budget // self.pop_size)))**0.5) - 1))\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "debd6805-96c8-4822-ba34-3a8f13b3cfd6", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified update rule to efficiently adapt the search distribution.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, cs=0.3, c_cov=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(lb, ub, size=dim)\n        self.sigma = 0.3 * (ub - lb)\n        self.cs = cs\n        self.c_cov = c_cov\n        self.p_sigma = np.zeros(dim)\n        self.C = np.eye(dim)\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            population = self.mean + self.sigma * z\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Find best individual\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update mean\n            x_best = population[best_index]\n            self.mean = x_best\n\n            # Update evolution path for sigma\n            z_best = (x_best - self.mean) / self.sigma\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * z_best\n\n            # Update covariance matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.p_sigma, self.p_sigma)\n\n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / 0.8 ) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt", "objective": -0.25137, "other_inf": null}
{"id": "5b0e8598-417c-4206-a92b-1fe1c1f9b085", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "# Description: This algorithm implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified parameter adaptation scheme for efficient exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, cs=0.3, damps=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = 0.3 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps\n\n    def __call__(self, func):\n        while self.budget > 0:\n            Z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            X = self.m + self.sigma * Z\n            X = np.clip(X, self.lb, self.ub)\n            \n            fitness = np.array([func(x) for x in X])\n            self.budget -= self.pop_size\n            \n            idx = np.argsort(fitness)\n            best_indices = idx[:self.mu]\n            \n            x_best = X[best_indices]\n            f_best = fitness[best_indices]\n            \n            if np.min(f_best) < self.f_opt:\n                self.f_opt = np.min(f_best)\n                self.x_opt = x_best[np.argmin(f_best)]\n\n            m_old = self.m\n            self.m = np.sum(x_best * self.weights[:, np.newaxis], axis=0)\n\n            B = X[best_indices] - m_old\n            self.C = (1 - self.cs) * self.C + self.cs * np.cov(B.T, aweights=self.weights, bias=True)\n            \n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.m - m_old) / self.sigma - 1))\n            \n        return self.f_opt, self.x_opt", "objective": -0.30466, "other_inf": null}
{"id": "dc517787-0844-4e62-9974-c200b5dee1cc", "parents": ["8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm uses a particle swarm optimization strategy with velocity clamping and constriction factor to balance exploration and exploitation, guiding particles towards promising regions of the search space.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max  # Velocity clamping\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.constriction_factor = 0.729  # Constriction factor to improve convergence\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Update velocity\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.c1 * r1 * (self.pbest_positions[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.x_opt - self.population[i])\n            self.velocities[i] = self.constriction_factor * (self.w * self.velocities[i] + cognitive_component + social_component)\n            self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n\n            # Update position\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n            # Evaluate fitness\n            f = func(self.population[i])\n            self.budget -= 1\n\n            # Update personal best\n            if f < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = f\n                self.pbest_positions[i] = self.population[i].copy()\n\n            # Update global best\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = self.population[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "objective": -0.55826, "other_inf": null}
{"id": "694d8cef-0d9d-4bb3-93e4-7521906464e3", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "8c2c1861-da75-4736-b974-fd2e2be3e680"], "algorithm": "This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adapt the search distribution's covariance matrix, enabling efficient exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu / (self.dim + self.mu**2))**0.5\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim)/(self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1-self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.budget > 0:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            y = self.sigma * z\n            x = self.m + y\n            \n            # Clip to bounds\n            x = np.clip(x, self.lb, self.ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)].copy()\n            \n            idx = np.argsort(fitness)\n            x_mu = x[idx[:self.mu]]\n            y_mu = y[idx[:self.mu]]\n\n            self.m = np.sum(x_mu * self.weights[:, None], axis=0)\n            z_mu = np.sum(y_mu * self.weights[:, None], axis=0) / self.sigma\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_mu\n            norm_ps = np.linalg.norm(self.ps)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n            self.sigma = min(max(self.sigma, 1e-10), 10)  # Clamp sigma\n            \n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * y_mu[0] / self.sigma  # use only one y_mu to prevent rank deficient\n\n            delta = x_mu - self.m\n            self.C = (1 - self.c_1 - self.c_mu) * self.C \\\n                        + self.c_1 * np.outer(self.pc, self.pc) \\\n                        + self.c_mu * np.sum(self.weights[:, None, None] * delta[:, :, None] * delta[:, None, :], axis=0)\n            \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T # enforce symmetry\n            \n            try:\n                L = np.linalg.cholesky(self.C) # check if pos definite\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)  #regularize the matrix if not positive definite\n\n\n        return self.f_opt, self.x_opt", "objective": -0.26405, "other_inf": null}
{"id": "a51158b2-c3a9-4686-b434-4a6d3920039f", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm uses a simplified particle swarm optimization (PSO) with velocity clamping and constriction factor to balance exploration and exploitation in continuous search spaces.", "code": "import numpy as np\n\nclass SimplifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max # Velocity clamping\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.K = 0.729  # Constriction factor\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.budget -= self.pop_size\n\n        # Find initial global best\n        best_index = np.argmin(self.personal_best_fitness)\n        self.global_best_position = self.personal_best_positions[best_index]\n        self.global_best_fitness = self.personal_best_fitness[best_index]\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.K * (self.w * self.velocities[i] + cognitive_component + social_component)\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                        self.f_opt = self.global_best_fitness\n                        self.x_opt = self.global_best_position\n        return self.f_opt, self.x_opt", "objective": -0.58823, "other_inf": null}
{"id": "e6464bcd-aa89-4735-97e8-e52ea9821338", "parents": ["0182a2fa-1d0f-49fa-86f9-a932145446c3", "0182a2fa-1d0f-49fa-86f9-a932145446c3"], "algorithm": "This algorithm employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation by predicting function values and uncertainties, iteratively refining the model with new evaluations.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\n\nclass BayesianOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def acquisition_function(self, x, xi=0.01):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        mu = mu[0]\n        sigma = sigma[0]\n        \n        if sigma == 0:\n            return 0\n            \n        imp = (mu - self.f_opt - xi)\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Gaussian process regression\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n\n        while self.budget > 0:\n            self.gpr.fit(self.X, self.y)\n\n            # Find the next point to evaluate using acquisition function\n            from scipy.optimize import minimize\n            def objective(x):\n                return -self.acquisition_function(x)\n\n            bounds = [(self.lb, self.ub)] * self.dim\n            \n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            res = minimize(objective, x0, method='L-BFGS-B', bounds=bounds)\n            x_next = res.x\n\n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update the best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b261a9db-4c48-4605-83d5-f28ca26ed05c", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adaptively update the search distribution based on successful steps, promoting efficient exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, sigma=0.5, cs=0.3, damps=1.0, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_percentage=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.sigma = sigma\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.pop_size * mu_percentage)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = (ub + lb) / 2 * np.ones(self.dim)\n        self.P_sigma = np.zeros(self.dim)\n        self.P_c = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.damps = damps + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) * damps\n        self.c_cov_mean = c_cov_mean if c_cov_mean else self.mu / (self.dim + np.square(self.mu / self.dim))\n        self.c_cov_rank_one = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_cov_rank_mu = 2 * (self.mu - 1 + 1e-8) / ((self.dim + 2)**2 + self.mu)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Generate samples\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, self.lb, self.ub)\n            \n            # Evaluate samples\n            fitness = np.array([func(x[:, i]) for i in range(self.pop_size)])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            idxs = np.argsort(fitness)\n            x = x[:, idxs]\n            fitness = fitness[idxs]\n\n            # Update best\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.dot(x[:, :self.mu], self.weights)\n            \n            # Update evolution path for sigma\n            B = np.linalg.cholesky(self.C)\n            z_mean = np.dot(z[:, idxs[:self.mu]], self.weights)\n            self.P_sigma = (1 - self.cs) * self.P_sigma + np.sqrt(self.cs * (2 - self.cs)) * np.dot(B, z_mean)\n\n            # Update covariance matrix\n            h_sigma = np.linalg.norm(self.P_sigma) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget / self.pop_size))) < (1.4 + 2 / (self.dim + 1)) * self.dim**(0.5)\n            d_h_sigma = 1 if h_sigma else 0\n            \n            self.P_c = (1 - self.c_cov_mean) * self.P_c + d_h_sigma * np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean)) * (self.m - m_old) / self.sigma\n            self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + self.c_cov_rank_one * np.outer(self.P_c, self.P_c)\n            \n            for i in range(self.mu):\n              self.C += self.c_cov_rank_mu * self.weights[i] * np.outer((x[:,i]-m_old)/self.sigma, (x[:,i]-m_old)/self.sigma)\n\n            # Ensure positive definiteness\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = np.linalg.eigvalsh(self.C).min()*np.eye(self.dim)*0.00000000001 + self.C\n            \n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.P_sigma) / np.sqrt(self.dim) - 1))\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9d322310-8199-4a24-9a59-48d13fd3a2f8", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm employs a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to adaptively adjust the search distribution based on the success history of previous search steps, focusing on promising regions of the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, initial_sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mean = np.random.uniform(lb, ub, size=dim)\n        self.sigma = initial_sigma\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (100 * dim**2)))\n        self.c_sigma = (self.pop_size + 2) / (dim + self.pop_size + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.c_sigma * (2 - self.c_sigma)) * dim**2) - 1) + self.c_sigma\n        self.c_c = 4 / (dim + 4)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1 / self.mu) / ((dim + 2)**2 + self.mu))\n        self.B = None\n        self.D = None\n        self.update_BD()\n\n    def update_BD(self):\n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(np.diag(self.D))\n        self.B = np.real(self.B)\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            y = self.B @ self.D @ z.T\n            population = self.mean + self.sigma * y.T\n            population = np.clip(population, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size+self.budget]\n                population = population[:self.pop_size+self.budget]\n            \n            # Find best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Selection and Recombination\n            fitness_sorted_indices = np.argsort(fitness)\n            y_k = y[:, fitness_sorted_indices[:self.mu]]\n            x_diff = y_k @ self.weights\n\n            # Update Evolution Paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ x_diff)\n            if np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(self.budget / self.pop_size)) < self.chiN * (1.4 + 2 / (self.dim + 1)):\n                hsig = 1\n            else:\n                hsig = 0\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * x_diff\n            \n            # Update Covariance Matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for k in range(self.mu):\n                self.C += self.c_mu * self.weights[k] * (y_k[:, k:k+1] @ y_k[:, k:k+1].T)\n\n            # Update Step Size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean += self.sigma * self.B @ self.D @ np.sum(y_k * self.weights, axis=1)\n\n            # Keep C positive definite\n            try:\n                self.C = np.triu(self.C) + np.triu(self.C, 1).T\n                self.C = self.C / np.linalg.norm(self.C)\n            except:\n                self.C = np.eye(self.dim)\n            self.update_BD()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "1f7e2e8e-8de8-41ba-8e49-2d9066395907", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "Simulated annealing with adaptive temperature schedule based on fitness variance and a restart mechanism upon stagnation.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, alpha=0.99, min_temp=1e-5, step_size=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.alpha = alpha\n        self.min_temp = min_temp\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        self.f_opt = f\n        self.x_opt = x\n        temp = self.initial_temp\n\n        while self.budget > 0 and temp > self.min_temp:\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n            else:\n                self.stagnation_counter += 1\n\n            # Adaptive temperature schedule and step size\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart mechanism: Re-initialize x if stagnated\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                temp = self.initial_temp # Reinitialize temperature\n\n                self.stagnation_counter = 0\n\n            else:\n                temp *= self.alpha\n\n        return self.f_opt, self.x_opt", "objective": -0.25933, "other_inf": null}
{"id": "2511f144-91bc-48fc-8055-d858eeaac8e9", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "This algorithm evolves a population using a combination of global random search and local gradient estimation, dynamically adapting the step size based on the success of gradient-based moves.", "code": "import numpy as np\n\nclass GradientAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, grad_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.grad_samples = grad_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Gradient estimation\n                grad_est = np.zeros(self.dim)\n                for _ in range(self.grad_samples):\n                    perturbation = np.random.normal(0, self.step_size, size=self.dim)\n                    x_perturbed = np.clip(population[i] + perturbation, self.lb, self.ub)\n                    f_perturbed = func(x_perturbed)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    grad_est += (f_perturbed - fitness[i]) * perturbation\n                grad_est /= self.grad_samples * self.step_size**2\n\n                # Gradient-based move\n                x_new = np.clip(population[i] - self.step_size * grad_est, self.lb, self.ub)\n                f_new = func(x_new)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n                \n                # Adaptive step size\n                if f_new < fitness[i]:\n                    population[i] = x_new\n                    fitness[i] = f_new\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n\n                # Random exploration\n                if np.random.rand() < 0.1:\n                    x_rand = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    f_rand = func(x_rand)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                    if f_rand < fitness[i]:\n                        population[i] = x_rand\n                        fitness[i] = f_rand\n\n                # Update best\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i]\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.34229, "other_inf": null}
{"id": "c0f0460a-32c9-4f80-88fb-9b12216db7c1", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc", "8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that adjusts its step size and covariance matrix based on the success of previous search steps, while incorporating restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0,\n                 sigma0=0.5, mu_ratio=0.25, cs=0.3, damps=1.0, ccov1=0.0, ccovmu=0.0):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.sigma0 = sigma0\n        self.mu_ratio = mu_ratio\n\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = int(self.pop_size * self.mu_ratio)\n\n        self.weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damps + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.p_th = 0.1\n\n        self.C = np.eye(self.dim)\n        self.sigma = self.sigma0\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = None\n        self.D = None\n\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = min(1 - self.ccov1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.alpha = 1.5\n        self.iteration = 0\n        self.restart_iter = int(self.budget / (10*self.pop_size))\n\n    def __call__(self, func):\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        while self.budget > 0:\n            self.iteration += 1\n            if self.iteration % self.restart_iter == 0:\n                mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = self.sigma0\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.B = None\n                self.D = None\n\n            if self.B is None or self.D is None:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(self.D)\n\n            z = np.random.randn(self.dim, self.pop_size)\n            x = mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, self.lb, self.ub)\n\n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[:, np.argmin(fitness)]\n\n            idx = np.argsort(fitness)\n            x_mu = x[:, idx[:self.mu]]\n            z_mu = z[:, idx[:self.mu]]\n\n            mean_new = np.sum(self.weights[np.newaxis, :] * x_mu, axis=1)\n            zmean = np.sum(self.weights * z_mu, axis=1)\n\n            ps_temp = self.ps\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ zmean)\n            norm_ps = np.linalg.norm(self.ps)\n\n            if norm_ps / np.sqrt(1 - (1 - self.cs)**(2*self.budget/self.pop_size)) < self.alpha * self.chiN:\n                self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                    + self.ccovmu * (self.weights[None, :] * z_mu) @ z_mu.T\n            else:\n                self.ps = ps_temp\n            \n            self.pc = (1 - 1) * self.pc + np.sqrt(1 * (2 - 1) * self.mueff) * (mean_new - mean) / self.sigma\n            self.C = (1-self.ccov1-self.ccovmu) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                    + self.ccovmu * (self.weights[None, :] * z_mu) @ z_mu.T\n            mean = mean_new\n            self.sigma *= np.exp((self.cs/self.damps) * (norm_ps/self.chiN -1))\n                \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = self.C / np.linalg.norm(self.C)\n\n            min_eig = np.min(np.linalg.eigvalsh(self.C))\n            if min_eig < 1e-10:\n                self.C += (1e-10 - min_eig) * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": -0.6236, "other_inf": null}
{"id": "c7e2c8e3-4776-4ec2-adbd-b439fee5d23b", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "# Description: This algorithm utilizes a covariance matrix adaptation evolution strategy (CMA-ES) inspired approach with simplified adaptation rules and restarts to effectively explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, cs=0.3, mu_fact=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = 0.5 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.cs = cs\n        self.mu = max(1, int(self.pop_size * mu_fact))\n        self.restart_trigger = 100 * self.dim \n        self.restart_count = 0\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            population = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            population = np.clip(population, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            population = population[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Update mean\n            old_mean = self.mean.copy()\n            self.mean = np.mean(population[:self.mu], axis=0)\n\n            # Update covariance matrix\n            diff = (self.mean - old_mean) / self.sigma\n            self.C = (1 - self.cs) * self.C + self.cs * np.outer(diff, diff)\n\n            # Update step size\n            self.sigma *= np.exp(self.cs / 2 * (np.linalg.norm(diff)**2 - 1))\n\n            # Restart if covariance matrix collapses\n            if np.any(np.isnan(self.C)):\n                self.restart_count +=1\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = 0.5 * (self.ub - self.lb)\n                self.C = np.eye(self.dim)\n            \n            if self.restart_count > self.restart_trigger:\n                self.restart_count = 0\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = 0.5 * (self.ub - self.lb)\n                self.C = np.eye(self.dim)\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "745cf32b-9bbe-4dea-8be6-850c8d0ecce0", "parents": ["8cdf8f0f-8d4b-4ee7-a2e0-9e601501d2bc"], "algorithm": "# Description: This algorithm enhances Differential Evolution by incorporating a velocity update mechanism inspired by Particle Swarm Optimization (PSO) to guide the search direction, along with adaptive adjustment of inertia weight, acceleration coefficients, mutation, and crossover rates.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.velocity = np.zeros_like(self.population)\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_fitness = np.full(self.pop_size, np.inf)\n\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.inertia_decay = 0.995\n        self.mutation_decay = 0.995\n        self.crossover_decay = 0.995\n\n    def __call__(self, func):\n        # Initialize population and evaluate fitness\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.budget -= 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i]\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            # Find global best\n            global_best_index = np.argmin(self.personal_best_fitness)\n            global_best_position = self.personal_best_positions[global_best_index]\n\n            for i in range(self.pop_size):\n                # Update velocity\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coeff * np.random.rand() * (self.personal_best_positions[i] - self.population[i]) +\n                                    self.social_coeff * np.random.rand() * (global_best_position - self.population[i]))\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.mutation_factor * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Update position based on velocity and crossover\n                trial = np.clip(trial + self.velocity[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n\n            # Update parameters\n            self.inertia_weight *= self.inertia_decay\n            self.mutation_factor *= self.mutation_decay\n            self.crossover_rate *= self.crossover_decay\n\n        return self.f_opt, self.x_opt", "objective": -0.56457, "other_inf": null}
{"id": "d3ee5d0d-69f1-4270-a494-c42bb71c4768", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm utilizes a self-adaptive differential evolution strategy with a dynamically adjusted population size and a restart mechanism to escape local optima and enhance exploration.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, F_init=0.5, CR_init=0.7, restart_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_freq = restart_freq\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adapt population size\n            if generation % self.restart_freq == 0:\n                self.pop_size = int(self.pop_size * 0.9) + 50  # Reduce and add baseline\n                self.pop_size = min(self.pop_size, 200) # Cap population size\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Adaptive F and CR\n                F_i = np.random.normal(self.F, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = np.random.normal(self.CR, 0.1)\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n                \n                mutant = a + F_i * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR_i or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.64519, "other_inf": null}
{"id": "43ace63b-5519-48c5-9431-76d65cf1006d", "parents": ["0c74a561-8ecd-45c7-86c8-305448e13008"], "algorithm": "This algorithm utilizes a self-adaptive differential evolution strategy with a dynamically adjusted population size and incorporates a local search component based on the current best solution.", "code": "import numpy as np\n\nclass SelfAdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size_init=20, F_init=0.5, CR_init=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.F_init = F_init  # Initial Mutation factor\n        self.CR_init = CR_init  # Initial Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop_size = pop_size_init\n        self.F = F_init\n        self.CR = CR_init\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Self-adaptive parameters\n            self.F = np.random.normal(self.F_init, 0.1, self.pop_size)\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.random.normal(self.CR_init, 0.1, self.pop_size)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            \n            # Adjust population size (example, can be more sophisticated)\n            if generation % 100 == 0:\n                if np.std(fitness) < 1e-6:\n                    self.pop_size = max(10, int(self.pop_size * 0.8))  # Reduce if converging\n                else:\n                    self.pop_size = min(self.pop_size_init, int(self.pop_size * 1.2)) # Increase exploration\n\n                if self.pop_size != population.shape[0]:\n                    #resize population\n                    if self.pop_size < population.shape[0]:\n                      population = population[:self.pop_size]\n                      fitness = fitness[:self.pop_size]\n                    else:\n                      num_new = self.pop_size-population.shape[0]\n                      new_pop = np.random.uniform(self.lb, self.ub, size=(num_new, self.dim))\n                      population = np.vstack((population, new_pop))\n                      new_fitness = np.array([func(x) for x in new_pop])\n                      fitness = np.concatenate((fitness,new_fitness))\n                      self.budget -= num_new\n        \n\n            for i in range(population.shape[0]):\n                # Mutation\n                idxs = [idx for idx in range(population.shape[0]) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                mutant = a + self.F[i] * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR[i] or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local search around best solution\n            if np.random.rand() < self.local_search_prob and self.budget > 0:\n                x_local = self.x_opt + np.random.normal(0, 0.01, self.dim)\n                x_local = np.clip(x_local, self.lb, self.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt", "objective": -0.71222, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": null, "parents": [], "algorithm": null, "code": null, "objective": null, "other_inf": null}
{"id": "d21343ec-7567-464d-8e7c-b48aed862c53", "parents": [], "algorithm": "A population-based algorithm employing a combination of global and local search strategies, adaptively adjusting search parameters based on the success rate of exploration.", "code": "import numpy as np\n\nclass AdaptiveExploration:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_rate=0.5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_rate = exploration_rate\n        self.local_search_radius = local_search_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            # Exploration phase\n            if np.random.rand() < self.exploration_rate:\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n            \n            # Exploitation phase (local search around the best individual)\n            else:\n                new_population = np.clip(np.random.normal(self.x_opt, self.local_search_radius, size=(self.pop_size, self.dim)), func.bounds.lb, func.bounds.ub)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness.max():\n                    worst_index = np.argmax(fitness)\n                    fitness[worst_index] = new_fitness[i]\n                    population[worst_index] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt exploration rate based on success\n            improvement_ratio = np.sum(new_fitness < fitness) / self.pop_size\n            self.exploration_rate = np.clip(self.exploration_rate + 0.1 * (improvement_ratio - 0.5), 0.1, 0.9)\n        \n        return self.f_opt, self.x_opt", "objective": -0.37906, "other_inf": null}
{"id": "aeb21e49-113b-44b9-8099-59d61d6f0a88", "parents": [], "algorithm": "Adaptive Differential Evolution with dynamic parameter adaptation based on successful iterations and a restart strategy when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, stagnation_threshold=0.001, stagnation_iter=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iter = stagnation_iter\n        self.best_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.f_vals = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.f_vals)\n        self.x_opt = self.population[np.argmin(self.f_vals)]\n        self.eval_count = self.pop_size #Initial population evaluation\n        \n        self.best_history.append(self.f_opt)\n        \n        iter_since_last_improvement = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.f_vals[i]:\n                    self.population[i] = trial_vector\n                    self.f_vals[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        iter_since_last_improvement = 0\n                    \n                        # Adaptive CR and F: If improvement found, modify params\n                        self.CR = np.random.normal(0.7, 0.1) \n                        self.F = np.random.normal(0.5, 0.1)\n                        self.CR = np.clip(self.CR, 0.0, 1.0)\n                        self.F = np.clip(self.F, 0.1, 1.0)\n                else:\n                    iter_since_last_improvement += 1\n                    \n                    # If parameters are stuck and aren't improving, modify params more aggressively\n                    if iter_since_last_improvement > 200:\n                         self.CR = np.random.rand()\n                         self.F = np.random.uniform(0.1, 0.9)\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Stagnation check\n            if iter_since_last_improvement > self.stagnation_iter:\n                # Restart strategy\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.f_vals = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.f_vals)\n                \n                if self.f_vals[best_index] < self.f_opt:\n                    self.f_opt = self.f_vals[best_index]\n                    self.x_opt = self.population[best_index]\n                \n                iter_since_last_improvement = 0\n                # Reset the CR and F too.\n                self.CR = np.random.normal(0.7, 0.1) \n                self.F = np.random.normal(0.5, 0.1)\n                self.CR = np.clip(self.CR, 0.0, 1.0)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                    \n\n        return self.f_opt, self.x_opt", "objective": -0.56571, "other_inf": null}
{"id": "8ce253e4-58d5-48a7-84e7-1691c6a6534e", "parents": [], "algorithm": "This algorithm combines a Nelder-Mead simplex approach for local search with a differential evolution strategy for global exploration, using a shrinking strategy on the simplex size when improvements stall.", "code": "import numpy as np\n\nclass AdaptiveDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.7, nm_init_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.nm_init_size = nm_init_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n        self.simplex = None\n        self.simplex_size = self.nm_init_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                mask = np.random.rand(self.dim) < self.CR\n                trial[mask] = mutant[mask]\n\n                # Selection\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local Search with Nelder-Mead on the best individual\n            best_idx = np.argmin(self.fitness)\n            best_x = self.population[best_idx].copy()\n\n            if self.simplex is None:\n                 self.simplex = self.initialize_simplex(best_x, self.simplex_size)\n            \n            self.simplex, improved = self.nelder_mead(func, self.simplex)\n            \n            \n            if improved:\n                best_simplex_fitness = func(self.simplex[0])\n                if best_simplex_fitness < self.f_opt:\n                    self.f_opt = best_simplex_fitness\n                    self.x_opt = self.simplex[0]\n                self.simplex_size = self.nm_init_size # Reset simplex size after improvement\n            else:\n                # Shrink the simplex if no improvement\n                self.simplex_size *= 0.9\n                self.simplex = self.initialize_simplex(best_x, self.simplex_size)\n\n            for i in range(len(self.simplex)):\n              self.simplex[i] = np.clip(self.simplex[i], self.lb, self.ub)\n        return self.f_opt, self.x_opt\n\n    def initialize_simplex(self, x0, step_size):\n        simplex = [x0]\n        for i in range(self.dim):\n            x = x0.copy()\n            x[i] += step_size\n            simplex.append(x)\n        return np.array(simplex)\n    \n\n    def nelder_mead(self, func, simplex, alpha=1, beta=0.5, gamma=2):\n      \n        improved = False\n        for _ in range(min(self.dim+1, self.budget - self.eval_count)):\n\n            # 1. Order the simplex\n            fitness_values = np.array([func(x) for x in simplex])\n            self.eval_count += len(simplex) - len(fitness_values)\n            if self.eval_count > self.budget:\n              break\n\n            sorted_indices = np.argsort(fitness_values)\n            simplex = simplex[sorted_indices]\n            fitness_values = fitness_values[sorted_indices]\n\n            best = simplex[0]\n            worst = simplex[-1]\n\n            # 2. Calculate centroid (excluding the worst point)\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # 3. Reflection\n            reflected_point = centroid + alpha * (centroid - worst)\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            f_reflected = func(reflected_point)\n            self.eval_count += 1\n\n            if self.eval_count > self.budget:\n              break\n            \n            if fitness_values[0] <= f_reflected < fitness_values[-2]:\n                simplex[-1] = reflected_point\n                improved = True\n                continue\n\n            # 4. Expansion\n            if f_reflected < fitness_values[0]:\n                expanded_point = centroid + gamma * (reflected_point - centroid)\n                expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                f_expanded = func(expanded_point)\n                self.eval_count += 1\n                if self.eval_count > self.budget:\n                  break\n\n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded_point\n                    improved = True\n                    continue\n                else:\n                    simplex[-1] = reflected_point\n                    improved = True\n                    continue\n\n            # 5. Contraction\n            if f_reflected >= fitness_values[-2]:\n                contracted_point = centroid + beta * (worst - centroid)\n                contracted_point = np.clip(contracted_point, self.lb, self.ub)\n\n                f_contracted = func(contracted_point)\n                self.eval_count += 1\n\n                if self.eval_count > self.budget:\n                  break\n\n                if f_contracted < fitness_values[-1]:\n                    simplex[-1] = contracted_point\n                    improved = True\n                    continue\n                else:\n                   # 6. Shrink\n                    for i in range(1, len(simplex)):\n                        simplex[i] = best + beta * (simplex[i] - best)\n                        simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n                    \n                    new_fitness_values = np.array([func(x) for x in simplex[1:]])\n\n                    self.eval_count += len(simplex) - 1\n                    if self.eval_count > self.budget:\n                      break\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "243d013f-c3f7-47ab-b3ad-51547b5b8efd", "parents": [], "algorithm": "Adaptive Differential Evolution with dynamic parameter tuning and population size reduction for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Adaptive F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n            #Population Size Reduction\n            if eval_count > self.budget * 0.75 and self.pop_size > 10:\n               worst_index = np.argmax(self.fitness)\n               self.population = np.delete(self.population, worst_index, axis = 0)\n               self.fitness = np.delete(self.fitness, worst_index)\n               self.pop_size -= 1\n\n\n        return self.f_opt, self.x_opt", "objective": -0.70495, "other_inf": null}
{"id": "da06fcfc-82f9-400d-b696-27a994124edf", "parents": [], "algorithm": "A population-based algorithm with a dynamic adaptation of step size based on the success rate of previous steps, combined with a local search strategy.", "code": "import numpy as np\n\nclass AdaptiveStepSizeES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.5, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.success_threshold = success_threshold\n        self.archive_x = []\n        self.archive_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.archive_x.extend(population.tolist())\n        self.archive_f.extend(fitness.tolist())\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            # Generate offspring\n            noise = np.random.normal(0, self.step_size, size=(self.pop_size, self.dim))\n            offspring = population + noise\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.archive_x.extend(offspring.tolist())\n            self.archive_f.extend(offspring_fitness.tolist())\n            self.budget -= self.pop_size\n\n            # Selection (replace parents with better offspring)\n            successful_steps = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    population[i] = offspring[i]\n                    fitness[i] = offspring_fitness[i]\n                    successful_steps += 1\n\n            # Adapt step size\n            success_rate = successful_steps / self.pop_size\n            if success_rate > self.success_threshold:\n                self.step_size *= 1.1  # Increase step size\n            else:\n                self.step_size *= 0.9  # Decrease step size\n\n            # Local Search (every few iterations)\n            if self.budget > 0 and (self.budget % (self.pop_size*5)) == 0: \n                best_index = np.argmin(fitness)\n                x_local = population[best_index]\n                noise_local = np.random.normal(0, self.step_size/5, size=self.dim)\n                x_local_new = x_local + noise_local\n                x_local_new = np.clip(x_local_new, func.bounds.lb, func.bounds.ub)\n                f_local_new = func(x_local_new)\n                self.archive_x.append(x_local_new.tolist())\n                self.archive_f.append(f_local_new)\n                self.budget -= 1\n\n                if f_local_new < fitness[best_index]:\n                    population[best_index] = x_local_new\n                    fitness[best_index] = f_local_new\n                    \n            # Update best solution\n            best_fitness = np.min(fitness)\n            best_index = np.argmin(fitness)\n            if best_fitness < self.f_opt:\n                self.f_opt = best_fitness\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d", "parents": [], "algorithm": "Adaptive Differential Evolution with dynamic parameter adaptation based on past success and restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.restart_iter = budget // 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            self.F = np.mean(self.success_F)\n            self.CR = np.mean(self.success_CR)\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        iter_count = 0\n        while self.evals < self.budget:\n            iter_count += 1\n            if iter_count % self.restart_iter == 0:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.update_parameters()\n                continue\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n            \n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            self.update_parameters()\n        return self.f_opt, self.x_opt", "objective": -0.65441, "other_inf": null}
{"id": "fc59a19e-7ff7-40a8-9f06-2d3176dced22", "parents": [], "algorithm": "This algorithm combines a simplified particle swarm optimization (PSO) with a local search strategy using a dynamically adjusted step size to efficiently explore the search space and refine promising solutions.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, n_particles=20, inertia=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.n_particles = n_particles\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = np.random.uniform(self.lb, self.ub, size=(self.n_particles, self.dim))\n        self.v = np.random.uniform(-1, 1, size=(self.n_particles, self.dim))\n        self.pbest_x = self.x.copy()\n        self.pbest_f = np.full(self.n_particles, np.inf)\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n        self.step_size = 1.0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.n_particles):\n                f = func(self.x[i])\n                self.eval_count += 1\n                if f < self.pbest_f[i]:\n                    self.pbest_f[i] = f\n                    self.pbest_x[i] = self.x[i].copy()\n\n                if f < self.gbest_f:\n                    self.gbest_f = f\n                    self.gbest_x = self.x[i].copy()\n\n            self.f_opt = self.gbest_f\n            self.x_opt = self.gbest_x\n\n            for i in range(self.n_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.v[i] = self.inertia * self.v[i] + \\\n                            self.c1 * r1 * (self.pbest_x[i] - self.x[i]) + \\\n                            self.c2 * r2 * (self.gbest_x - self.x[i])\n\n                self.x[i] = self.x[i] + self.v[i]\n\n                self.x[i] = np.clip(self.x[i], self.lb, self.ub)\n\n            # Local search around the best particle\n            if self.eval_count < self.budget:\n                x_local = self.gbest_x + np.random.normal(0, self.step_size, self.dim)\n                x_local = np.clip(x_local, self.lb, self.ub)\n                f_local = func(x_local)\n                self.eval_count += 1\n                if f_local < self.gbest_f:\n                    self.gbest_f = f_local\n                    self.gbest_x = x_local.copy()\n                    self.step_size *= 1.1 # Increase step size if improving\n                else:\n                    self.step_size *= 0.9 # Reduce step size if not improving\n\n                self.f_opt = self.gbest_f\n                self.x_opt = self.gbest_x\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "ecdae9c3-61a6-433f-9061-cc071fc2b990", "parents": [], "algorithm": "This algorithm utilizes a population-based approach with differential evolution operators for exploration and exploitation, combined with a local search strategy for refinement.", "code": "import numpy as np\n\nclass DifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.7, CR=0.9, local_search_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_iters = local_search_iters\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                \n                    # Local Search (optional, apply only if improvement)\n                    for _ in range(self.local_search_iters):\n                        if self.budget <= 0:\n                            break\n                        \n                        # Create a small perturbation around the current best\n                        perturbation = np.random.normal(0, 0.01, size=self.dim)\n                        local_trial = np.clip(trial + perturbation, func.bounds.lb, func.bounds.ub)\n                        local_f = func(local_trial)\n                        self.budget -= 1\n                        \n                        if local_f < fitness[i]:\n                            fitness[i] = local_f\n                            population[i] = local_trial\n                            trial = local_trial # update trial for further local search\n\n            # Update overall best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "aa3579f0-57e4-4f8b-a287-144713e71f8c", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d", "aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "A population-based algorithm that utilizes a combination of global exploration and local exploitation using a gradient-based approach, dynamically adjusting search behavior based on population diversity and progress.", "code": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.01, exploration_prob=0.3, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.exploration_prob = exploration_prob\n        self.diversity_threshold = diversity_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def gradient_descent(self, func, x):\n        # Estimate gradient (simple finite difference)\n        h = 1e-5\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_plus_h[i] += h\n            f_plus_h = func(x_plus_h)\n            self.evals += 1\n\n            x_minus_h = x.copy()\n            x_minus_h[i] -= h\n            f_minus_h = func(x_minus_h)\n            self.evals += 1\n           \n            gradient[i] = (f_plus_h - f_minus_h) / (2 * h)\n           \n            if self.evals >= self.budget:\n                break\n        \n        # Gradient Descent step\n        x_new = x - self.lr * gradient\n        x_new = np.clip(x_new, self.lb, self.ub)\n\n        return x_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            diversity = self.calculate_diversity()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob or diversity < self.diversity_threshold:\n                    # Exploration: Random jump\n                    new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                else:\n                    # Exploitation: Gradient-based local search\n                    new_x = self.gradient_descent(func, self.population[i].copy())\n                \n                if self.evals >= self.budget:\n                    break\n\n                f_new = func(new_x)\n                self.evals += 1\n                if f_new < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_x.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "b9cb04d0-a1f4-4e9b-9dc6-0c1090f2b370", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "d21343ec-7567-464d-8e7c-b48aed862c53"], "algorithm": "Simulated Annealing with adaptive temperature schedule based on the acceptance rate of worse solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, temp_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.temp_decay = temp_decay\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        \n        current_x = self.x_opt.copy()\n        current_f = self.f_opt\n\n        temperature = self.initial_temp\n\n        while eval_count < self.budget:\n            # Generate a neighbor solution\n            new_x = current_x + np.random.normal(0, temperature, size=self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            \n            new_f = func(new_x)\n            eval_count += 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                current_x = new_x.copy()\n                current_f = new_f\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x.copy()\n\n            # Adaptive temperature schedule based on acceptance rate\n            if eval_count % 100 == 0:\n                acceptance_rate = np.mean(np.exp(-np.maximum(0, delta_f) / temperature) > np.random.rand(100))\n                if acceptance_rate > 0.5:\n                    temperature *= 1.05  # Increase temperature if accepting too often\n                else:\n                    temperature *= self.temp_decay # Decrease temperature\n                temperature = min(temperature, self.initial_temp)\n\n        return self.f_opt, self.x_opt", "objective": -0.32218, "other_inf": null}
{"id": "daa5eb9e-7f16-45dd-825b-65549617de85", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d", "aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "A Population-based algorithm that uses a Gaussian Mixture Model to sample new candidate solutions, adapting the model parameters based on the fitness of the population and employing a local search strategy.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimiser:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5, local_search_iterations=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.lb = -5.0\n        self.ub = 5.0\n        self.gmm = None\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_iterations = local_search_iterations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def fit_gmm(self):\n        self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n        self.gmm.fit(self.population)\n\n    def sample_new_solutions(self, n_samples):\n        new_solutions = self.gmm.sample(n_samples)[0]\n        return np.clip(new_solutions, self.lb, self.ub)\n    \n    def local_search(self, func, x):\n        best_x = x\n        best_f = func(x)\n        self.evals += 1\n        \n        for _ in range(self.local_search_iterations):\n            # Generate a random perturbation\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            new_x = np.clip(x + perturbation, self.lb, self.ub)\n            new_f = func(new_x)\n            self.evals += 1\n            \n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        \n        return best_x, best_f\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            self.fit_gmm()\n            new_solutions = self.sample_new_solutions(self.pop_size)\n            \n            for i in range(self.pop_size):\n                # Apply local search\n                x, f = self.local_search(func, new_solutions[i])\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                \n                if f < np.max(self.fitness):\n                    worst_index = np.argmax(self.fitness)\n                    self.population[worst_index] = x\n                    self.fitness[worst_index] = f\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2f820486-74bd-40d5-ade9-0bb165ef7763", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Simulated Annealing with adaptive temperature scheduling for balancing exploration and exploitation in continuous optimization.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        temperature = self.initial_temp\n\n        while eval_count < self.budget:\n            # Generate neighbor solution\n            x_new = self.x_opt + np.random.normal(0, temperature/self.initial_temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            eval_count += 1\n\n            # Acceptance probability\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                self.x_opt = x_new\n                self.f_opt = f_new\n\n            # Adaptive temperature adjustment\n            temperature *= self.cooling_rate\n            if eval_count > self.budget*0.75:\n                self.cooling_rate = 0.99 # Lower cooling rate after 75% of budget\n\n        return self.f_opt, self.x_opt", "objective": -0.11853, "other_inf": null}
{"id": "f659d27d-1ced-4ad7-9f9f-ab9debab9495", "parents": ["d21343ec-7567-464d-8e7c-b48aed862c53", "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "# Description: Employs a search strategy that combines aspects of pattern search with a self-adjusting step size and direction based on function evaluations, iteratively refining its search pattern.\n# Code:\n```", "code": "import numpy as np\n\nclass PatternAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, reduction_factor=0.5, expansion_factor=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.reduction_factor = reduction_factor\n        self.expansion_factor = expansion_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        self.budget -= 1\n        \n        while self.budget > 0:\n            improved = False\n            for i in range(self.dim):\n                # Explore positive direction\n                x_new_pos = self.x_opt.copy()\n                x_new_pos[i] += self.step_size\n                x_new_pos = np.clip(x_new_pos, func.bounds.lb, func.bounds.ub)\n                f_new_pos = func(x_new_pos)\n                self.budget -= 1\n\n                if f_new_pos < self.f_opt:\n                    self.f_opt = f_new_pos\n                    self.x_opt = x_new_pos\n                    improved = True\n                    continue  # Continue to the next dimension\n\n                # Explore negative direction\n                x_new_neg = self.x_opt.copy()\n                x_new_neg[i] -= self.step_size\n                x_new_neg = np.clip(x_new_neg, func.bounds.lb, func.bounds.ub)\n                f_new_neg = func(x_new_neg)\n                self.budget -= 1\n\n                if f_new_neg < self.f_opt:\n                    self.f_opt = f_new_neg\n                    self.x_opt = x_new_neg\n                    improved = True\n                \n            if not improved and self.budget > 0:\n                self.step_size *= self.reduction_factor  # Reduce step size if no improvement\n                if self.step_size < 1e-6:\n                    self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.f_opt = func(self.x_opt)\n                    self.budget -= 1\n                    self.step_size = 1.0\n            elif improved:\n                self.step_size *= self.expansion_factor\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "9be43ca2-34db-4df1-a130-e4970319e764", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d", "aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "Evolve a population of solutions using a simplified particle swarm optimization with adaptive inertia weight and velocity clamping, restarting when stagnation is detected.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, stagnation_iter=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_iter = stagnation_iter\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.evals = 0\n        self.stagnation_count = 0\n\n    def initialize_population(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.pop_size\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n        self.x_opt = self.global_best_position\n        self.f_opt = self.global_best_fitness\n\n    def update_velocity(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n        social_component = self.c2 * r2 * (self.global_best_position - self.particles[i])\n        self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n        \n        # Velocity clamping to prevent explosion\n        v_max = (self.ub - self.lb) * 0.1  # Example clamping value\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n    def update_position(self, i):\n        self.particles[i] = self.particles[i] + self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                self.update_velocity(i)\n                self.update_position(i)\n\n                f = func(self.particles[i])\n                self.evals += 1\n\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.particles[i].copy()\n                        self.x_opt = self.global_best_position\n                        self.f_opt = self.global_best_fitness\n                        self.stagnation_count = 0  # Reset stagnation count\n                else:\n                    self.stagnation_count +=1\n\n                if self.evals >= self.budget:\n                    break\n\n            if self.stagnation_count > self.stagnation_iter:\n                # Restart strategy - re-initialize particles except best one\n                best_index = np.argmin(self.fitness)\n                self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.particles[best_index] = self.global_best_position.copy()  # Keep the best\n                \n                self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.particles])\n                self.evals += self.pop_size - 1  # Minus 1 as we kept the best\n                self.personal_best_positions = self.particles.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                \n                if self.global_best_fitness < np.min(self.fitness):\n                    pass #global best stays as is\n                else:\n                    self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n                    self.global_best_fitness = np.min(self.fitness)\n                    self.x_opt = self.global_best_position\n                    self.f_opt = self.global_best_fitness\n                self.stagnation_count = 0  # Reset stagnation count\n                \n                # Adjust inertia weight after restart\n                self.w = np.clip(self.w * 0.9, 0.4, 0.9)\n            else:\n                # Linearly decrease the inertia weight\n                self.w = np.clip(self.w - (0.3 / (self.budget / self.pop_size)), 0.4, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "c12899fd-918c-4574-bccb-979d337950bc", "parents": ["d21343ec-7567-464d-8e7c-b48aed862c53", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "An iterative algorithm that combines random sampling with gradient estimation to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass GradientEstimationSearch:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, num_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.num_samples = num_samples\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        \n        self.f_opt = f\n        self.x_opt = x.copy()\n\n        while self.budget > 0:\n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                \n                x_plus[i] += self.step_size\n                x_minus[i] -= self.step_size\n\n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                self.budget -= 2\n\n                gradient[i] = (f_plus - f_minus) / (2 * self.step_size)\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n            # Move in the direction of the negative gradient\n            x_new = x - self.step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Accept the new solution if it's better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                x = x_new.copy()\n            else:\n                # Random perturbation if no improvement\n                x_rand = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f_rand = func(x_rand)\n                self.budget -= 1\n                if f_rand < self.f_opt:\n                   self.f_opt = f_rand\n                   self.x_opt = x_rand.copy()\n                   x = x_rand.copy()\n\n\n            # Adapt step size\n            if self.budget > 0:\n                self.step_size *= 0.99\n        \n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "b27b57b2-4d84-4c51-93fb-a0b4dae5c4dc", "parents": ["aeb21e49-113b-44b9-8099-59d61d6f0a88", "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "Simulated Annealing with adaptive temperature based on acceptance rate, incorporating a population of solutions and a perturbation mechanism inspired by Differential Evolution.", "code": "import numpy as np\n\nclass PopulationAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_temp=100, temp_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.temp_decay = temp_decay\n        self.lb = -5.0\n        self.ub = 5.0\n        self.temp = initial_temp\n        self.acceptance_rate = 0.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        accepted_count = 0\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Perturbation using DE-like mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + 0.5 * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                f_mutant = func(mutant)\n                self.eval_count += 1\n\n                delta_e = f_mutant - self.fitness[i]\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                    self.population[i] = mutant\n                    self.fitness[i] = f_mutant\n                    accepted_count += 1\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            self.acceptance_rate = accepted_count / self.pop_size\n            accepted_count = 0\n            #Adaptive temperature\n            if self.acceptance_rate > 0.5:\n                self.temp *= 1.05 #Slow down cooling if too many accepted\n            else:\n                self.temp *= self.temp_decay\n        return self.f_opt, self.x_opt", "objective": -0.25101, "other_inf": null}
{"id": "4fe6b935-30d9-4f71-bef0-fd1c089b6213", "parents": ["aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with budget-aware adaptation and restart mechanism for improved exploration and exploitation.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, restart_trigger=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for covariance matrix\n        self.ps = np.zeros(self.dim)  # Evolution path for step size\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n\n        self.cs = cs\n        self.damps = damps + 2 * max(0, np.sqrt((self.pop_size - 1)/(self.dim + 1)) - 1)\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.pop_size) if ccov1 is None else ccov1\n        self.ccovmu = min(1-self.ccov1, 2 * (self.pop_size-2 + 1/self.pop_size) / ((self.dim + 2)**2 + self.pop_size)) if ccovmu is None else ccovmu\n\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = restart_trigger # percentage of budget at which restart should occur if no improvements\n\n    def __call__(self, func):\n        weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        mu = int(self.pop_size / 2)\n        weights = weights[:mu]\n\n        B, D = np.linalg.eig(self.C)\n        B = np.real(B)\n        D = np.real(D)\n        D = np.sqrt(D)\n        B = np.real(B)\n        \n        iter_since_last_improvement = 0\n\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.dim, self.pop_size))\n            x = self.mean[:, np.newaxis] + self.sigma * (B * D) @ z\n            x = np.clip(x, self.lb, self.ub)\n            f_vals = np.array([func(xi) for xi in x.T])\n            self.eval_count += self.pop_size\n\n            # Selection and update\n            idx = np.argsort(f_vals)\n            x_k = x[:, idx]\n            f_vals_k = f_vals[idx]\n\n            if f_vals_k[0] < self.f_opt:\n                self.f_opt = f_vals_k[0]\n                self.x_opt = x_k[:, 0]\n                iter_since_last_improvement = 0\n            else:\n                iter_since_last_improvement += 1\n\n            mean_old = self.mean.copy()\n            self.mean = x_k[:, :mu] @ weights\n            \n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (B * D) @ ( (self.mean - mean_old) / self.sigma ) * np.sqrt(self.dim)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.eval_count / self.pop_size))) / self.chiN < 1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.ccov1) * self.pc + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1)) * ((self.mean - mean_old) / self.sigma)\n\n            # Update covariance matrix\n            y = x_k[:, :mu] - mean_old[:, np.newaxis]\n            self.C = (1 - self.ccov1 - self.ccovmu) * self.C + self.ccov1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.ccovmu * (y @ np.diag(weights) @ y.T) / self.sigma**2\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            if np.any(np.diag(self.C) <= 0) or np.isinf(self.sigma) or np.isnan(self.sigma) : # handles numerical issues\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_sigma\n\n            if self.eval_count > self.budget * self.restart_trigger and iter_since_last_improvement > self.pop_size * 5:  # Restart if no improvement\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = self.initial_sigma\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                B, D = np.linalg.eig(self.C)\n                B = np.real(B)\n                D = np.real(D)\n                D = np.sqrt(D)\n                B = np.real(B)\n                iter_since_last_improvement = 0\n                \n            if self.eval_count >= self.budget:\n                break\n\n            B, D = np.linalg.eig(self.C)\n            B = np.real(B)\n            D = np.real(D)\n            D = np.sqrt(D)\n            B = np.real(B)\n\n        return self.f_opt, self.x_opt", "objective": -0.14047, "other_inf": null}
{"id": "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "parents": ["d21343ec-7567-464d-8e7c-b48aed862c53"], "algorithm": "# Description: An algorithm employing a differential evolution strategy with adaptive scaling factors and crossover probabilities to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.75329, "other_inf": null}
{"id": "8db566ff-2b7c-40a0-965d-3b1ec63f51ee", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "'maxfev':max(1,int(0.01*self.budget))", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Self-adaptive mutation\n                if np.random.rand() < 0.1:\n                  F_i = np.random.uniform(0.5,1.0)\n                else:\n                  F_i = self.F\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F_i * (b - c), self.lb, self.ub)\n\n                # Dynamic Crossover\n                CR_i = self.CR * (1 + 0.1 * np.random.randn())\n\n                cross_points = np.random.rand(self.dim) < CR_i\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            #Local Search with Nelder-Mead every 20% of budget\n            if eval_count > self.budget * 0.2:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=[(self.lb, self.ub)] * self.dim, options={'maxfev':max(1,int(0.01*self.budget))})\n                if res.fun < self.f_opt:\n                  self.f_opt = res.fun\n                  self.x_opt = res.x\n                eval_count += res.nfev\n                if eval_count >= self.budget:\n                  break\n            \n            #Adaptive F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n                \n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2a43fbce-8646-4f29-a289-1563e7388de6", "parents": ["aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that dynamically adjusts its parameters based on success rates and restarts when stagnation is detected, using a population-based approach to explore the search space effectively.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, c_cov=0.2, mu_ratio=0.25, stagnation_threshold=1e-6, stagnation_iter=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu = int(self.pop_size * mu_ratio)\n        self.weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_iter = stagnation_iter\n\n    def __call__(self, func):\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        iter_since_last_improvement = 0\n\n        while self.eval_count < self.budget:\n            Z = np.random.randn(self.dim, self.pop_size)\n            try:\n                A = np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n                A = np.linalg.cholesky(self.C)\n\n            X = self.m[:, np.newaxis] + self.sigma * A @ Z\n            X = np.clip(X, self.lb, self.ub)\n            \n            f_vals = np.array([func(x) for x in X.T])\n            self.eval_count += self.pop_size\n\n            idx = np.argsort(f_vals)\n            x_mu = X[:, idx[:self.mu]]\n            f_mu = f_vals[idx[:self.mu]]\n            \n            m_old = self.m.copy()\n            self.m = x_mu @ self.weights\n            \n            z_mu = Z[:, idx[:self.mu]]\n            \n            C_update = np.sum([w * (z_mu[:, i][:, np.newaxis] @ z_mu[:, i][np.newaxis, :]) for i, w in enumerate(self.weights)], axis=0)\n            \n            self.C = (1 - self.c_cov) * self.C + self.c_cov * C_update\n\n            if np.min(f_vals) < self.f_opt:\n                self.f_opt = np.min(f_vals)\n                self.x_opt = X[:, np.argmin(f_vals)]\n                iter_since_last_improvement = 0\n            else:\n                iter_since_last_improvement += 1\n            \n            if iter_since_last_improvement > self.stagnation_iter:\n                self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma *= 0.8\n                iter_since_last_improvement = 0\n            \n            if self.eval_count >= self.budget:\n                break\n            \n\n        return self.f_opt, self.x_opt", "objective": -0.38933, "other_inf": null}
{"id": "eeb594f3-dfca-4c2f-aed0-f135c27cdd9f", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with adaptive population size and step size control for efficient exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = np.sqrt(dim) * (1 - (1 / (4 * dim)) + (1 / (21 * dim**2)))\n\n        if damps is None:\n            self.damps = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (dim + 1)) - 1) + cs\n        else:\n            self.damps = damps\n\n        self.cs = cs\n        self.c_cov = 2 / ((dim + np.sqrt(2))**2) if c_cov is None else c_cov\n        self.c_cov_mu = min(1, self.c_cov * (self.pop_size / 4))\n\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu = self.pop_size // 2\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.pop_size)\n            x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n\n            if np.any(f < self.f_opt):\n                best_index = np.argmin(f)\n                if f[best_index] < self.f_opt:\n                    self.f_opt = f[best_index]\n                    self.x_opt = x[best_index]\n\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.sqrt(self.weights[0]) * (self.mean - mean_old) / self.sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (eval_count / self.pop_size))) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.c_cov) * self.pc + hsig * np.sqrt(self.c_cov * (2 - self.c_cov)) * (self.mean - mean_old) / self.sigma\n\n            # Update covariance matrix\n            artmp = (1 / self.sigma) * (x_sorted[:self.mu] - mean_old)\n            self.C = (1 - self.c_cov) * self.C + self.c_cov_mu * np.dot(artmp.T, np.diag(self.weights[:self.mu])).dot(artmp) + self.c_cov * (1 - hsig) * self.pc[:, None].dot(self.pc[None, :])\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 1e10)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "12032839-7b82-4136-b9ce-efa9f78167db", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step-size adaptation to balance exploration and exploitation.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.m = None  # Mean\n        self.C = None  # Covariance matrix\n        self.sigma = None  # Step size\n        self.p_sigma = None # Evolution path for sigma\n        self.p_c = None # Evolution path for covariance\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_mu = None\n        self.weights = None\n        self.mu = self.pop_size // 2\n        self.c_1 = None\n        self.c_mu_eff = None\n        self.mu_eff = None\n        self.B = None\n        self.D = None\n        self.eigen_updated = False\n        self.initialize()\n\n    def initialize(self):\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_sigma\n        self.p_sigma = np.zeros(self.dim)\n        self.p_c = np.zeros(self.dim)\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu_eff - 2 + 1 / self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        self.c_mu_eff = 1\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        y = np.dot(z, self.B * np.sqrt(self.D))\n        x = self.m + self.sigma * y\n        return np.clip(x, self.lb, self.ub)\n\n    def update_parameters(self, x, fitness_values):\n        x_k = x[np.argsort(fitness_values)]\n        y_k = (x_k - self.m) / self.sigma\n        \n        self.m = np.sum(x_k[:self.mu] * self.weights[:self.mu, None], axis=0)\n        \n        self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mu_eff) * np.sum(y_k[:self.mu] * self.weights[:self.mu, None], axis=0)\n        \n        sigma_norm = np.linalg.norm(self.p_sigma) / np.sqrt(self.dim)\n        \n        self.sigma *= np.exp(self.c_sigma / self.d_sigma * (sigma_norm - 1))\n        self.sigma = np.clip(self.sigma, 1e-10, 5) \n\n        self.p_c = (1 - self.c_c) * self.p_c + np.sqrt(self.c_c * (2 - self.c_c) * self.mu_eff) * np.sum(y_k[:self.mu] * self.weights[:self.mu, None], axis=0)\n        \n        delta = y_k[:self.mu].T @ (self.weights[:self.mu] * y_k[:self.mu])\n        self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.p_c[:, None] @ self.p_c[None, :]) + self.c_mu * delta\n        \n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        \n        self.eigen_updated = False\n\n    def check_eigen_update(self):\n        if self.evals % (self.budget / 20) == 0 or not self.eigen_updated:\n            self.eigen_decomposition()\n            self.eigen_updated = True\n\n    def eigen_decomposition(self):\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-10))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        \n        while self.evals < self.budget:\n            self.check_eigen_update()\n            if not self.eigen_updated:\n                self.eigen_decomposition()\n                self.eigen_updated = True\n            \n            x = self.sample_population()\n            fitness_values = np.array([func(xi) for xi in x])\n            self.evals += self.pop_size\n\n            best_index = np.argmin(fitness_values)\n            if fitness_values[best_index] < self.f_opt:\n                self.f_opt = fitness_values[best_index]\n                self.x_opt = x[best_index]\n\n            self.update_parameters(x, fitness_values)\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c0245967-87d4-405e-bacf-be1561825ea2", "parents": ["aeb21e49-113b-44b9-8099-59d61d6f0a88"], "algorithm": "Simulated Annealing with adaptive temperature decay based on the acceptance rate of new solutions.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, alpha=0.99, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.alpha = alpha\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        self.x_current = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_current = func(self.x_current)\n        self.f_opt = self.f_current\n        self.x_opt = self.x_current\n        self.temp = self.initial_temp\n        self.eval_count = 1\n\n        while self.eval_count < self.budget and self.temp > self.temp_min:\n            x_new = self.x_current + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            delta_f = f_new - self.f_current\n\n            if delta_f < 0:\n                self.x_current = x_new\n                self.f_current = f_new\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                acceptance = 1.0\n            else:\n                try:\n                    acceptance_prob = np.exp(-delta_f / self.temp)\n                except OverflowError:\n                    acceptance_prob = 0.0\n                if np.random.rand() < acceptance_prob:\n                    self.x_current = x_new\n                    self.f_current = f_new\n                    acceptance = acceptance_prob\n                else:\n                    acceptance = 0.0\n\n            self.acceptance_history.append(acceptance)\n\n            #Adaptive Temperature Decay\n            if len(self.acceptance_history) > 100:\n                acceptance_rate = np.mean(self.acceptance_history[-100:])\n                if acceptance_rate > 0.96:\n                    self.alpha = 0.9\n                elif acceptance_rate < 0.04:\n                    self.alpha = 0.999\n                else:\n                    self.alpha = 0.99\n\n            self.temp *= self.alpha\n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": -0.24866, "other_inf": null}
{"id": "17fe7a31-bf6b-44af-beda-4e382a638025", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': self.popsize, 'maxfevals': self.budget, 'verbose':-9", "code": "import numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.x0 = np.zeros(dim)\n        self.sigma = 0.5\n        self.popsize = 4 + int(3 * np.log(dim))\n        self.es = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = 100 * dim  # Evaluations before restart check\n\n\n    def __call__(self, func):\n        self.es = cma.optimization_tools.CMAParameters(self.x0, self.sigma, {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': self.popsize, 'maxfevals': self.budget, 'verbose':-9}).instantiate()\n        \n        fevals_since_last_restart = 0\n        \n        while self.es.evaluations < self.budget:\n            solutions = []\n            for i in range(self.es.population_size):\n                x = self.es.ask()\n                f = func(x)\n                solutions.append((x,f))\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                fevals_since_last_restart += 1\n            \n            self.es.tell([(x,f) for x,f in solutions])\n            self.es.adapt()\n            \n            # Restart strategy based on stagnation\n            if fevals_since_last_restart > self.restart_trigger:\n                if self.es.best.f is not None and self.es.best.f >= self.f_opt:\n                    self.es.restart(seed=np.random.randint(0, 2**32))\n                    fevals_since_last_restart = 0\n                \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b2678f62-2953-4c5e-8eb8-1065ae6ab0f1", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "An algorithm employing a covariance matrix adaptation evolution strategy (CMA-ES) approach, updating a multivariate normal distribution to sample new candidate solutions and adapting the covariance matrix to capture dependencies between variables for efficient exploration of the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, damps=1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.3)**2 + self.mueff))\n        self.dampss = 1 + 2*max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            y = np.dot(z, np.linalg.cholesky(self.C).T)\n            x = self.mean + self.sigma * y\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            if eval_count > self.budget:\n                fitness = fitness[:self.pop_size - (eval_count-self.budget)]\n                x = x[:self.pop_size - (eval_count-self.budget)]\n                self.pop_size = self.pop_size - (eval_count-self.budget)\n                eval_count = self.budget\n                \n            \n            # Update best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = x[best_idx].copy()\n                \n            # Selection and Recombination\n            idx = np.argsort(fitness)\n            x_mu = x[idx[:self.mu]]\n            y_mu = y[idx[:self.mu]]\n\n            self.mean = np.sum(self.weights[:, None] * x_mu, axis=0)\n\n            # Update Evolution Path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (self.mean - self.mean) / self.sigma\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * np.sum(self.weights[:, None] * y_mu, axis=0)\n            \n            # Update Covariance Matrix\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (self.cc * (2 - self.cc)) * self.C)\n            self.C += self.cmu * np.sum(self.weights[:, None, None] * y_mu[:, :, None] * y_mu[:, None, :], axis=0)\n            \n            # Update Step Size\n            self.sigma *= np.exp((self.cs / self.dampss) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9832cdc3-72ee-48a5-a4fe-87496996d33f", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Simulated annealing with adaptive temperature and step size, focusing on intensification and diversification phases based on the success rate of moves.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x.copy()\n        temp = self.initial_temp\n        eval_count = 1\n        success_count = 0\n        iteration = 0\n\n        while eval_count < self.budget:\n            iteration += 1\n            x_new = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0:\n                x = x_new.copy()\n                f = f_new\n                success_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x.copy()\n            else:\n                acceptance_probability = np.exp(-delta_f / temp)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new.copy()\n                    f = f_new\n            \n            # Adaptive temperature and step size\n            if iteration % 100 == 0:\n                success_rate = success_count / 100\n                if success_rate > 0.6:\n                    self.step_size *= 1.1  # Intensification: Increase step size\n                elif success_rate < 0.4:\n                    self.step_size *= 0.9  # Diversification: Decrease step size\n                temp *= self.cooling_rate  #Cooling\n                success_count = 0\n            \n            self.step_size = np.clip(self.step_size, 0.001, 2.0) # bound the step size\n\n        return self.f_opt, self.x_opt", "objective": -0.28917, "other_inf": null}
{"id": "872cbdcc-f5d1-4257-b6d5-d62f9b498383", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified update rule and restart mechanism to adapt to the problem landscape.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, restart_threshold=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.cs = cs\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.restart_threshold = restart_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        eval_count = 0\n        restart_count = 0\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            x = self.m + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            x = np.clip(x, self.lb, self.ub)\n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            x = x[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Simplified covariance matrix adaptation\n            d = self.m - m_old\n            self.C = (1 - self.cs) * self.C + self.cs * (d[:, None] @ d[None, :]) / (self.sigma**2)\n\n            # Update step size\n            self.sigma *= np.exp(self.cs / 2 * (np.sum(self.weights * np.sum(z[:self.mu]**2, axis=1)) - self.dim) / self.dim)\n            \n            # Check for stagnation and restart if needed\n            if np.linalg.norm(d) < self.restart_threshold * self.sigma:\n                restart_count += 1\n                self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = 0.5\n                \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "a037eaca-7b99-4295-86cf-a6838194a538", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d", "a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "A gradient-free optimization algorithm that adaptively samples points around the current best solution, adjusting the sampling radius based on the success rate of finding better solutions.", "code": "import numpy as np\n\nclass AdaptiveSampling:\n    def __init__(self, budget=10000, dim=10, initial_radius=1.0, shrink_factor=0.9, expand_factor=1.1, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = np.inf\n        self.evals = 0\n        self.successes = 0\n\n    def sample(self):\n        x = self.x_opt + np.random.normal(0, self.radius, size=self.dim)\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.f_opt = func(self.x_opt)\n        self.evals += 1\n\n        while self.evals < self.budget:\n            x = self.sample()\n            f = func(x)\n            self.evals += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                self.successes += 1\n\n            if self.evals % 100 == 0:\n                success_rate = self.successes / 100\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expand_factor\n                else:\n                    self.radius *= self.shrink_factor\n                self.successes = 0\n                self.radius = np.clip(self.radius, 1e-6, 5.0)\n\n        return self.f_opt, self.x_opt", "objective": -0.54698, "other_inf": null}
{"id": "a58bc7e9-8714-4342-b20f-8fe27d28e6a9", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Evolving a population of solutions using a combination of gradient-based search and random perturbations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass GradientEnhancedEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, perturbation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.perturbation_rate = perturbation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gradient-based search (approximate gradient)\n                x = self.population[i]\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = x.copy()\n                    x_minus = x.copy()\n                    delta = self.step_size\n                    x_plus[j] += delta\n                    x_minus[j] -= delta\n\n                    x_plus = np.clip(x_plus, self.lb, self.ub)\n                    x_minus = np.clip(x_minus, self.lb, self.ub)\n\n                    f_plus = func(x_plus)\n                    f_minus = func(x_minus)\n                    eval_count += 2 #Corrected evaluation counter\n\n                    gradient[j] = (f_plus - f_minus) / (2 * delta)\n                    if eval_count >= self.budget:\n                        return self.f_opt, self.x_opt\n\n                # Update solution based on gradient\n                new_x = x - self.step_size * gradient\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Random perturbation for exploration\n                if np.random.rand() < self.perturbation_rate:\n                    new_x += np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n                    new_x = np.clip(new_x, self.lb, self.ub)\n\n                f = func(new_x)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = new_x\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n            self.step_size *= 0.99 # Optional Step Size Reduction\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "d33204fb-e2f3-45d6-abfa-1cdc3db6b243", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant that adapts the step size and covariance matrix based on successful steps, while incorporating a population-based approach for exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, damp=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size or (4 + int(3 * np.log(dim)))\n        self.sigma = sigma\n        self.mean = None\n        self.C = None\n        self.ps = None\n        self.pc = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damp = damp or 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2.3)**2 + self.mueff))\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            x = x[indices]\n            fitness = fitness[indices]\n            \n            #Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Update mean\n            xmean = np.sum(x[:self.mu] * self.weights[:, None], axis=0)\n            y = xmean - self.mean\n\n            # Update evolution paths\n            self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * y @ np.linalg.inv(np.linalg.cholesky(self.C)).T / self.sigma\n            self.pc = (1-self.cc)*self.pc + np.sqrt(self.cc*(2-self.cc)*self.mueff) * y / self.sigma\n\n            # Update covariance matrix\n            C_temp = self.c1 * (self.pc[:, None] @ self.pc[None, :])\n            C_temp += self.cmu * (x[:self.mu] - self.mean).T @ np.diag(self.weights) @ (x[:self.mu] - self.mean) / self.sigma**2\n\n            self.C = (1-self.c1-self.cmu) * self.C + C_temp\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damp)*(np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # Update mean\n            self.mean = xmean\n\n        return self.f_opt, self.x_opt", "objective": -0.61953, "other_inf": null}
{"id": "7506b1a6-9ed6-4437-ba14-d2cf4a46b1c0", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An algorithm that combines a Gaussian process surrogate model with Bayesian optimization and a local search to efficiently explore and exploit the search space.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.optimize import minimize\n\nclass BayesianOptimizationLocalSearch:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n        self.X = None\n        self.y = None\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return -mu + 2 * sigma\n\n    def local_search(self, func, x_start, max_iter=5):\n        x_current = x_start.copy()\n        f_current = func(x_current)\n        for _ in range(max_iter):\n            x_neighbor = x_current + np.random.normal(0, 0.1, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_current:\n                x_current = x_neighbor\n                f_current = f_neighbor\n            else:\n                break \n        return f_current, x_current\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        eval_count = self.n_initial_samples\n\n        # Bayesian optimization loop\n        while eval_count < self.budget:\n            self.gp.fit(self.X, self.y)\n            \n            # Find next point to evaluate by maximizing acquisition function\n            x_next = None\n            best_acq = np.inf\n            for _ in range(10): #optimize multiple times and choose the best\n                x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                res = minimize(self.acquisition_function, x0, args=(self.gp,), bounds=[(self.lb, self.ub)] * self.dim)\n                if res.fun < best_acq:\n                    x_next = res.x\n                    best_acq = res.fun\n\n\n            # Local Search from x_next\n            f_local, x_local = self.local_search(func, x_next)\n            eval_count +=1\n\n            if f_local < self.f_opt:\n                self.f_opt = f_local\n                self.x_opt = x_local\n            \n            # Update data\n            self.X = np.vstack((self.X, x_local))\n            self.y = np.append(self.y, f_local)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c06cb309-8212-4a69-bcc5-19ba50392d43", "parents": ["aeb21e49-113b-44b9-8099-59d61d6f0a88", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: Population-based search algorithm employing Gaussian mutation and selection inspired by evolution strategies, with adaptive step size control for each individual.\n# Code:\n```", "code": "import numpy as np\n\nclass GaussianAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.step_sizes = np.full((self.pop_size, self.dim), self.initial_step_size)\n        self.f_vals = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.f_vals)\n        self.x_opt = self.population[np.argmin(self.f_vals)]\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation with adaptive step size\n                mutation = np.random.normal(0, self.step_sizes[i], size=self.dim)\n                trial_vector = self.population[i] + mutation\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.f_vals[i]:\n                    self.population[i] = trial_vector\n                    self.f_vals[i] = f_trial\n\n                    # Adapt step size (success)\n                    self.step_sizes[i] *= np.exp(0.1)\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                else:\n                    # Adapt step size (failure)\n                    self.step_sizes[i] *= np.exp(-0.1)\n\n                # Ensure step sizes remain within reasonable bounds\n                self.step_sizes[i] = np.clip(self.step_sizes[i], 1e-6, 1.0)\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "objective": -0.27963, "other_inf": null}
{"id": "c36db2fd-a9b6-4184-b1ca-13959c17d885", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An algorithm employing a self-adaptive Differential Evolution with a dynamic population size reduction strategy to focus search effort on promising regions.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.reduction_factor = reduction_factor\n        self.min_pop_size = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0 and self.pop_size >= self.min_pop_size:\n            new_population = np.zeros((self.pop_size, self.dim))\n            new_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n                new_fitness[i] = func(trial)\n                self.budget -= 1\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = trial.copy()\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = trial.copy()\n\n            # Adapt parameters\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n\n            # Population reduction\n            if self.budget > 0 and self.pop_size > self.min_pop_size:\n                num_to_reduce = max(1, int(self.pop_size * (1 - self.reduction_factor)))\n                if self.pop_size - num_to_reduce >= self.min_pop_size:\n\n                    sorted_indices = np.argsort(fitness)[::-1]  # sort from worst to best\n                    population = population[sorted_indices[:-num_to_reduce]]\n                    fitness = fitness[sorted_indices[:-num_to_reduce]]\n                    self.pop_size -= num_to_reduce\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "14b1fe56-3093-4a53-9c2c-e31902aaad85", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An enhanced differential evolution algorithm that incorporates a restart mechanism based on stagnation detection and dynamically adjusts the population size based on performance.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, stagnation_threshold=500, pop_resize_freq=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.pop_resize_freq = pop_resize_freq\n        self.last_improvement = 0\n        self.initial_pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        generation = 0\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n            else:\n                self.stagnation_counter += 1\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n            \n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart the population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n\n            # Dynamic population size adjustment\n            if generation > 0 and generation % self.pop_resize_freq == 0:\n                improvement_ratio = (generation - self.last_improvement) / self.pop_resize_freq\n                if improvement_ratio < 0.2:  # Example threshold\n                    self.pop_size = max(10, int(self.pop_size * 0.8))  # Reduce population size\n                    # Reinitialize population (smaller)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size  # Account for new evals\n                    best_index = np.argmin(fitness)\n                    if fitness[best_index] < self.f_opt:\n                        self.f_opt = fitness[best_index]\n                        self.x_opt = population[best_index].copy()\n\n                elif improvement_ratio > 0.5:  # Example threshold\n                    self.pop_size = min(self.initial_pop_size, int(self.pop_size * 1.2)) # Increase population size\n                    # Reinitialize population (larger)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size # Account for new evals\n                    best_index = np.argmin(fitness)\n                    if fitness[best_index] < self.f_opt:\n                        self.f_opt = fitness[best_index]\n                        self.x_opt = population[best_index].copy()\n            generation += 1\n        return self.f_opt, self.x_opt", "objective": -0.73532, "other_inf": null}
{"id": "1206a378-cebf-4563-9b29-3c8e0d1f47b9", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: A self-adaptive differential evolution algorithm that adjusts its mutation strategy based on the success rate of previous generations.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, mutation_strategies=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        if mutation_strategies is None:\n            self.mutation_strategies = [\n                lambda pop, a, b, c, F: pop[a] + F * (pop[b] - pop[c]),\n                lambda pop, a, b, c, F, best: best + F * (pop[a] - pop[b]) + F * (pop[c] - pop[best]),\n                lambda pop, a, b, c, F: pop[a] + F * (pop[b] - pop[c]),\n            ]\n        else:\n            self.mutation_strategies = mutation_strategies\n        self.num_strategies = len(self.mutation_strategies)\n        self.strategy_successes = np.zeros(self.num_strategies)\n        self.strategy_counts = np.zeros(self.num_strategies)\n        self.epsilon = 1e-6\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        best_position = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            strategy_indices = np.random.randint(0, self.num_strategies, size=self.pop_size)\n            for i in range(self.pop_size):\n                # Mutation strategy selection\n                strategy_index = strategy_indices[i]\n                self.strategy_counts[strategy_index] += 1\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                try:\n                    mutant = self.mutation_strategies[strategy_index](population, a, b, c, self.F, best_position)\n                except TypeError:\n                     mutant = self.mutation_strategies[strategy_index](population, a, b, c, self.F)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n                    self.strategy_successes[strategy_indices[i]] += 1\n\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                best_position = population[best_index]\n\n\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n            #Adapt strategy probabilities, not needed.\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "164c65f5-cf92-46e0-a3b1-f882b0afe89a", "parents": ["d33204fb-e2f3-45d6-abfa-1cdc3db6b243"], "algorithm": "A CMA-ES variant with adaptive population size based on the success rate of the current population and using a rank-based update for the covariance matrix.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, sigma=0.3, cs=0.8, damp=None, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size or (4 + int(3 * np.log(dim)))\n        self.pop_size = self.initial_pop_size\n        self.sigma = sigma\n        self.mean = None\n        self.C = None\n        self.ps = None\n        self.pc = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damp = damp or 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2.3)**2 + self.mueff))\n        self.lb = -5.0\n        self.ub = 5.0\n        self.adaptation_rate = adaptation_rate\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            x = x[indices]\n            fitness = fitness[indices]\n\n            #Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Update mean\n            xmean = np.sum(x[:self.mu] * self.weights[:, None], axis=0)\n            y = xmean - self.mean\n\n            # Update evolution paths\n            self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * y @ np.linalg.inv(np.linalg.cholesky(self.C)).T / self.sigma\n            self.pc = (1-self.cc)*self.pc + np.sqrt(self.cc*(2-self.cc)*self.mueff) * y / self.sigma\n\n            # Update covariance matrix\n            delta = x - self.mean\n            rank_one = self.c1 * np.outer(self.pc, self.pc)\n            rank_mu = self.cmu * np.sum(w * np.outer(d, d) for w, d in zip(self.weights, delta[:self.mu]))\n            self.C = (1 - self.c1 - self.cmu) * self.C + rank_one + rank_mu / self.sigma**2\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damp)*(np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # Update mean\n            self.mean = xmean\n\n            # Adapt population size\n            success_rate = np.mean(fitness < np.median(fitness))\n            if success_rate > 0.7:\n                self.pop_size = min(self.initial_pop_size * 2, self.pop_size + int(self.adaptation_rate * self.initial_pop_size))\n                self.mu = self.pop_size // 2\n                self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            elif success_rate < 0.3:\n                self.pop_size = max(self.initial_pop_size // 2, self.pop_size - int(self.adaptation_rate * self.initial_pop_size))\n                self.mu = self.pop_size // 2\n                self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, self.mu+1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f01fd7bf-921f-40f4-80e2-5affa8c5a055", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a restart mechanism based on stagnation detection, aiming to adapt the search distribution more effectively and escape local optima.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu_factor=4):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.lb = -5.0\n        self.ub = 5.0\n        \n        if pop_size is None:\n          self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        \n        self.mu = self.pop_size // mu_factor # number of parents/elite individuals\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else self.cs\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else min(1, self.mu / (self.dim + 6))\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else min(1 - self.c_cov_rank_one, self.mueff / (self.dim + 13))\n        self.damps = self.damps + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) * self.damps * (1 - self.cs)\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.B = None # eigenvectors of C\n        self.D = None # diagonal of eigenvalues of C\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_threshold = budget // 10\n        self.stagnation_counter = 0\n        self.min_delta = 1e-12\n\n    def sample_population(self):\n        if self.B is None or self.D is None:\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(self.D)\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        y = self.B @ (self.D[:, None] * z.T)\n        x = self.mean + self.sigma * y.T\n        return np.clip(x, self.lb, self.ub)\n\n    def update_distribution(self, population, fitness):\n        idx = np.argsort(fitness)\n        elite_idx = idx[:self.mu]\n        elite_pop = population[elite_idx]\n\n        y_mean = np.sum(self.weights[:, None] * (elite_pop - self.mean), axis=0)\n        self.mean = self.mean + self.cs * y_mean\n\n        C_rank_one = self.c_cov_rank_one * y_mean[:, None] @ y_mean[None, :]\n        \n        z = (elite_pop - self.mean) / self.sigma\n        C_rank_mu = self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * z[:, :, None] @ z[:, None, :], axis=0)\n\n        self.C = (1 - self.c_cov_rank_one - self.c_cov_rank_mu) * self.C + C_rank_one + C_rank_mu\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(y_mean) / np.linalg.norm(np.random.normal(0, 1, self.dim)) - 1))\n\n        delta = np.max(np.abs(elite_pop[0] - self.mean))\n        if delta < self.min_delta:\n              self.stagnation_counter += 1\n        else:\n              self.stagnation_counter = 0\n        \n        if self.stagnation_counter > self.restart_threshold:\n            self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            self.C = np.eye(self.dim)\n            self.sigma = 0.5\n            self.stagnation_counter = 0\n            self.B = None\n            self.D = None\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            population = self.sample_population()\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.pop_size\n            \n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            self.update_distribution(population, fitness)\n\n        return self.f_opt, self.x_opt", "objective": -0.10603, "other_inf": null}
{"id": "c7ea91cc-e9aa-4a01-ae31-8af75d5fd021", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: A particle swarm optimization algorithm with velocity clamping and dynamic inertia weight adaptation based on swarm stagnation.\n# Code:\n```", "code": "import numpy as np\n\nclass ClampedDynamicPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, \n                 cognitive_coeff=2.0, social_coeff=2.0, velocity_clamp=0.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.global_best_position = None\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm_position = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        swarm_velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.swarm_size, self.dim))\n        personal_best_position = swarm_position.copy()\n        personal_best_fitness = np.array([func(x) for x in swarm_position])\n        self.budget -= self.swarm_size\n\n        # Initialize global best\n        best_index = np.argmin(personal_best_fitness)\n        self.f_opt = personal_best_fitness[best_index]\n        self.x_opt = personal_best_position[best_index].copy()\n        self.global_best_position = self.x_opt.copy()\n        \n        generation = 0\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            inertia_weight = self.inertia_max - (self.inertia_max - self.inertia_min) * generation / (self.budget // self.swarm_size + generation)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_position[i] - swarm_position[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - swarm_position[i])\n                swarm_velocity[i] = inertia_weight * swarm_velocity[i] + cognitive_component + social_component\n                \n                # Velocity clamping\n                swarm_velocity[i] = np.clip(swarm_velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                swarm_position[i] = swarm_position[i] + swarm_velocity[i]\n                swarm_position[i] = np.clip(swarm_position[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(swarm_position[i])\n                self.budget -= 1\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_position[i] = swarm_position[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = swarm_position[i].copy()\n                        self.global_best_position = self.x_opt.copy()\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1 # Increment stagnation counter\n\n                if self.budget <= 0:\n                  break;\n            \n            if self.stagnation_counter > self.stagnation_threshold:\n                # Re-initialize a fraction of the swarm\n                num_reinitialize = self.swarm_size // 4\n                indices_to_reinitialize = np.random.choice(self.swarm_size, num_reinitialize, replace=False)\n                \n                swarm_position[indices_to_reinitialize] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinitialize, self.dim))\n                swarm_velocity[indices_to_reinitialize] = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(num_reinitialize, self.dim))\n                \n                for i in indices_to_reinitialize:\n                    personal_best_position[i] = swarm_position[i].copy()\n                    personal_best_fitness[i] = func(swarm_position[i])\n                    self.budget -=1\n                    if personal_best_fitness[i] < self.f_opt:\n                        self.f_opt = personal_best_fitness[i]\n                        self.x_opt = swarm_position[i].copy()\n                        self.global_best_position = self.x_opt.copy()\n                self.stagnation_counter = 0\n            generation += 1\n\n        return self.f_opt, self.x_opt", "objective": -0.54779, "other_inf": null}
{"id": "6c7b31c2-6119-4fa1-8f91-6f7f2468af49", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step size adaptation.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5 * (self.ub - self.lb) # Initial step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.ps = np.zeros(dim)  # Evolution path for sigma\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.budget/self.dim)**(-0.25) # Adaptive step size dampening\n        self.c_c = 4 / (dim + 4)\n        self.c_1 = 2 / ((dim + np.sqrt(2))**2)\n        self.c_mu = 2 * (min(1 - self.c_1, (self.budget / self.dim)**(-0.25)))/ ((dim + 2)**2)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        x = np.clip(x, self.lb, self.ub)\n        return x, z\n\n    def update_parameters(self, x, z, fitness):\n        idx = np.argsort(fitness)\n        x_sorted = x[idx]\n        z_sorted = z[idx]\n\n        y = x_sorted[:self.mu] - self.mean\n        self.mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n        \n        zmean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n        self.ps = (1 - self.c_sigma) * self.ps + (self.c_sigma * (2 - self.c_sigma))**0.5 * zmean\n        self.sigma *= np.exp((self.c_sigma / self.chiN) * (np.linalg.norm(self.ps) - self.chiN))\n        self.sigma = np.clip(self.sigma, 1e-10, 1000)  #Prevent sigma from becoming too small/large\n\n        self.pc = (1 - self.c_c) * self.pc + (self.c_c * (2 - self.c_c))**0.5 * np.linalg.solve(self.C**0.5, y[0])\n\n        C_temp = self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n        for i in range(self.mu):\n            C_temp += self.c_mu * self.weights[i] * (y[i, :, None] @ y[i, None, :]) / self.sigma**2\n        self.C = (1 - self.c_1 - self.c_mu) * self.C + C_temp\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T  #Enforce symmetry\n\n        try: #handle ill-conditioned matrix\n            if np.linalg.det(self.C) <= 0:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n            self.C = self.C * (np.linalg.norm(self.ps)**2 < self.dim) + self.C * (np.linalg.norm(self.ps)**2 >= self.dim) #Dampen C for explosion\n        except: #Restart if matrix is invalid\n            self.C = np.eye(self.dim)\n\n    def __call__(self, func):\n        while self.evals < self.budget:\n            x, z = self.sample_population()\n            fitness = np.array([func(xi) for xi in x])\n            self.evals += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            self.update_parameters(x, z, fitness)\n        return self.f_opt, self.x_opt", "objective": -0.20089, "other_inf": null}
{"id": "851876e6-2776-4345-966a-ecfb1e540613", "parents": ["a6cbfb4a-5af3-42e5-a269-1d6fe0d9dc2d"], "algorithm": "A self-adaptive Differential Evolution algorithm with a smaller population size, aggressive parameter adaptation, and periodic local search using Nelder-Mead simplex method.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.adaptation_rate = 0.1\n        self.local_search_interval = budget // 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            self.F = (1 - self.adaptation_rate) * self.F + self.adaptation_rate * mean_F\n            self.CR = (1 - self.adaptation_rate) * self.CR + self.adaptation_rate * mean_CR\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.population[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(self.budget - self.evals, 50)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.archive = []\n        self.archive_size = 10\n        self.adaptation_rate = 0.1\n        self.local_search_interval = budget // 20\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            self.F = (1 - self.adaptation_rate) * self.F + self.adaptation_rate * mean_F\n            self.CR = (1 - self.adaptation_rate) * self.CR + self.adaptation_rate * mean_CR\n        else:\n            self.F = 0.5\n            self.CR = 0.9\n        \n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.CR = np.clip(self.CR, 0.1, 0.9)\n        self.success_F = []\n        self.success_CR = []\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.population[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='Nelder-Mead', bounds=bounds, options={'maxfev': min(self.budget - self.evals, 50)})\n\n            if res.fun < self.fitness[i]:\n                self.population[i] = res.x\n                self.fitness[i] = res.fun\n                self.evals += res.nfev\n\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        iter_count = 0\n        while self.evals < self.budget:\n            iter_count += 1\n\n            if iter_count % self.local_search_interval == 0:\n                self.local_search(func)\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  new_population.append(self.population[i])\n                  new_fitness.append(self.fitness[i])\n                  continue\n\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n            \n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            self.update_parameters()\n        return self.f_opt, self.x_opt", "objective": -0.76561, "other_inf": null}
{"id": "55a7998d-b62f-41b9-80b0-093a77b86dd0", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "This algorithm uses a Gaussian process to model the fitness landscape and iteratively samples new points based on the GP's predicted mean and variance, balancing exploration and exploitation.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, xi=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.xi = xi # Exploration-exploitation trade-off parameter\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.evals = 0\n\n    def expected_improvement(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        if sigma == 0:\n            return 0\n        imp = (mu - self.f_opt - self.xi)\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gp, func, n_restarts=25):\n        best_ei = -np.inf\n        best_x = None\n        bounds = np.array([[self.lb, self.ub]] * self.dim)\n\n        for restart in range(n_restarts):\n            x0 = np.random.uniform(bounds[:, 0], bounds[:, 1], size=self.dim)\n\n            res = minimize(lambda x: -self.expected_improvement(x, gp), x0=x0,\n                           bounds=bounds, method='L-BFGS-B')\n\n            if -res.fun > best_ei:\n                best_ei = -res.fun\n                best_x = res.x\n\n        return best_x\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.evals = self.n_initial\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index].copy()\n\n        # Gaussian process\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        # Optimization loop\n        while self.evals < self.budget:\n            gp.fit(self.X, self.y)\n            x_next = self.propose_location(gp, func)\n            f_next = func(x_next)\n            self.evals += 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d7849035-a616-48fb-9df2-37b251e93c1f", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "Simulated Annealing with adaptive temperature and step size, incorporating a local search operator for refinement.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        temp = self.initial_temp\n\n        while eval_count < self.budget:\n            # Generate neighbor\n            x_new = self.x_opt + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            # Acceptance probability\n            delta_f = f_new - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                self.x_opt = x_new\n                self.f_opt = f_new\n\n            # Local Search (occasional refinement)\n            if eval_count % 100 == 0:\n                x_local = self.local_search(func, self.x_opt, budget=min(100, self.budget - eval_count))\n                f_local = func(x_local)\n                eval_count += 1\n                if f_local < self.f_opt:\n                    self.x_opt = x_local\n                    self.f_opt = f_local\n                    \n\n            # Cooling\n            temp *= self.cooling_rate\n            self.step_size *= 0.99 #Reduce step size\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x_start, budget):\n        x_best = x_start.copy()\n        f_best = func(x_start)\n        eval_count = 0\n        while eval_count < budget:\n             x_new = x_best + np.random.normal(0, 0.1, size=self.dim)\n             x_new = np.clip(x_new, self.lb, self.ub)\n             f_new = func(x_new)\n             eval_count+=1\n             if f_new < f_best:\n                  f_best = f_new\n                  x_best = x_new\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "647cd445-225d-452c-b151-92fce161f115", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "A swarm-based algorithm that dynamically adjusts its exploration-exploitation balance by varying the neighborhood size and inertia weight based on the swarm's performance.", "code": "import numpy as np\n\nclass DynamicSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, w_max=0.9, w_min=0.4, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.positions = None\n        self.velocities = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.neighborhood_size = int(swarm_size * 0.2) # Initial neighborhood size\n\n    def initialize_swarm(self, func):\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.positions])\n        self.evals = self.swarm_size\n        self.pbest_positions = self.positions.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.positions[np.argmin(self.fitness)]\n\n    def update_velocity(self, i, gbest_position):\n        w = self.w_max - (self.w_max - self.w_min) * (self.evals / self.budget)  # Dynamic inertia weight\n\n        # Neighborhood best\n        neighbors = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighbor_fitness = self.pbest_fitness[neighbors]\n        nbest_index = neighbors[np.argmin(neighbor_fitness)]\n        nbest_position = self.pbest_positions[nbest_index]\n      \n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = w * self.velocities[i] + \\\n                            self.c1 * r1 * (self.pbest_positions[i] - self.positions[i]) + \\\n                            self.c2 * r2 * (nbest_position - self.positions[i])\n                            #self.c2 * r2 * (gbest_position - self.positions[i])\n        \n        #Velocity clipping\n        v_max = (self.ub - self.lb) * 0.1\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n    def update_position(self, i):\n        self.positions[i] = np.clip(self.positions[i] + self.velocities[i], self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.evals < self.budget:\n            # Find global best\n            gbest_index = np.argmin(self.pbest_fitness)\n            gbest_position = self.pbest_positions[gbest_index]\n\n            for i in range(self.swarm_size):\n                if self.evals >= self.budget:\n                    break\n\n                self.update_velocity(i, gbest_position)\n                self.update_position(i)\n\n                f = func(self.positions[i])\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = f\n                        self.pbest_positions[i] = self.positions[i].copy()\n\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = self.positions[i].copy()\n\n            # Adjust neighborhood size based on swarm diversity\n            if self.evals % (self.budget//10) == 0:\n                diversity = np.mean(np.std(self.positions, axis=0))\n                if diversity < 0.1 * (self.ub - self.lb):\n                    self.neighborhood_size = min(self.neighborhood_size + 1, self.swarm_size)  # Increase exploration\n                else:\n                    self.neighborhood_size = max(int(self.swarm_size * 0.1), self.neighborhood_size - 1) # Decrease exploration\n        return self.f_opt, self.x_opt", "objective": -0.44637, "other_inf": null}
{"id": "95578a44-2014-4d4f-a67c-81a73346ef79", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A population-based algorithm utilizing a Gaussian Mixture Model (GMM) to learn the distribution of promising solutions and sample new candidate solutions from this learned distribution, adaptively focusing the search in high-probability regions.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptim:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        while self.budget > 0:\n            # Select top individuals\n            num_elites = int(self.pop_size * 0.2)  # 20% elites\n            elite_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elite_indices]\n            \n            # Learn GMM from elites\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', random_state=0, max_iter=100, n_init=1, tol=1e-3)\n            gmm.fit(elites)\n            \n            # Sample new individuals from GMM\n            new_population = gmm.sample(self.pop_size)[0]\n            new_population = np.clip(new_population, self.lb, self.ub)\n            \n            # Evaluate new individuals\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Combine old and new populations\n            combined_population = np.vstack((population, new_population))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n            \n            # Select the best individuals for the next generation\n            indices = np.argsort(combined_fitness)[:self.pop_size]\n            population = combined_population[indices]\n            fitness = combined_fitness[indices]\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "0039a6a4-83f3-4093-8b10-58ac7e5e2d90", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "# Description: A population-based algorithm that uses a Gaussian process surrogate model to guide the search, balancing exploration and exploitation through uncertainty sampling and adaptive hyperparameter tuning.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\nfrom scipy.stats import norm\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10)) + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5, 1e-1))\n\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n        self.X = []\n        self.y = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        if sigma==0:\n          return 0\n        return mu - self.exploration_weight * sigma\n\n\n    def __call__(self, func):\n        # Initial random sampling\n        X_initial = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n\n        self.X = X_initial.tolist()\n        self.y = y_initial.tolist()\n\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n\n        evals = self.n_initial\n\n        while evals < self.budget:\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            best_x = None\n            best_acq = np.inf\n\n            for _ in range(1000):  # Sample potential next points\n                x_candidate = np.random.uniform(self.lb, self.ub, size=self.dim)\n                acq_value = self.acquisition_function(x_candidate)\n\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    best_x = x_candidate\n\n\n            f_new = func(best_x)\n            evals += 1\n\n            self.X.append(best_x)\n            self.y.append(f_new)\n\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = best_x\n\n            # Adapt exploration weight (decay over time)\n            self.exploration_weight = max(0.1, self.exploration_weight * 0.99)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "f7ed5b7d-4fe5-42e3-9da3-64b2108a22a3", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "A population-based algorithm that iteratively refines solutions by perturbing individuals towards the best solution found so far, using a dynamically adjusted step size inspired by the success rate of perturbations.", "code": "import numpy as np\n\nclass PerturbationBasedOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.success_rate_threshold = success_rate_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        successes = 0\n        iterations = 0\n\n        while self.budget > 0:\n            iterations += 1\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Perturb towards the best solution\n                perturbation = self.step_size * (self.x_opt - population[i])\n                trial = population[i] + perturbation\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial.copy()\n                    successes += 1\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n            \n            success_rate = successes / iterations if iterations > 0 else 0\n            \n            # Adjust step size based on success rate\n            if success_rate > self.success_rate_threshold:\n                self.step_size *= 1.05  # Increase step size\n            else:\n                self.step_size *= 0.95   # Decrease step size\n            \n            self.step_size = np.clip(self.step_size, 0.001, 1.0) # Prevent step size from going too low or high\n            \n            if iterations > 1000:\n                break\n\n\n        return self.f_opt, self.x_opt", "objective": -0.25904, "other_inf": null}
{"id": "9dfcb31d-1999-4e6e-b1d4-127cdc3335e7", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and simulated annealing, where particles probabilistically explore the search space, cooling down over time to converge on a solution.\n# Code:\n```", "code": "import numpy as np\n\nclass PSO_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=30, w=0.7, c1=1.5, c2=1.5, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and values\n        personal_best_positions = population.copy()\n        personal_best_values = np.array([func(x) for x in population])\n        \n        # Find global best\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n\n        self.f_opt = global_best_value\n        self.x_opt = global_best_position\n        \n        eval_count = self.pop_size\n        temperature = self.initial_temp\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                              self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                              self.c2 * r2 * (global_best_position - population[i])\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                new_value = func(new_position)\n                eval_count += 1\n\n                # Simulated Annealing acceptance criterion\n                delta_e = new_value - personal_best_values[i]\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temperature):\n                    population[i] = new_position.copy()\n                    if new_value < personal_best_values[i]:\n                        personal_best_values[i] = new_value\n                        personal_best_positions[i] = new_position.copy()\n                        \n                        if new_value < global_best_value:\n                            global_best_value = new_value\n                            global_best_position = new_position.copy()\n\n                            self.f_opt = global_best_value\n                            self.x_opt = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n            \n            #Cooling\n            temperature *= self.cooling_rate\n\n        return self.f_opt, self.x_opt", "objective": -0.54293, "other_inf": null}
{"id": "c36e8a14-5976-42ae-839e-558a9c1da9b5", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: A swarm-based approach where particles adjust their positions based on their individual best, the swarm's best, and a dynamically adjusted inertia weight, incorporating a local search component for refinement.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize particles and velocities\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))  # Initialize velocities\n\n        # Evaluate initial fitness\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.pbest_fitness = self.fitness.copy()\n        self.pbest_positions = self.particles.copy()\n\n        # Find global best\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.particles[np.argmin(self.fitness)]\n        self.gbest_position = self.x_opt.copy()\n\n        eval_count = self.swarm_size\n\n        while eval_count < self.budget:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia - (self.inertia - 0.4) * (eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.pbest_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.gbest_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Randomly select a dimension for local search\n                    dim_index = np.random.randint(0, self.dim)\n                    # Small random perturbation\n                    perturbation = np.random.uniform(-0.1, 0.1)\n                    self.particles[i, dim_index] = np.clip(self.particles[i, dim_index] + perturbation, self.lb, self.ub)\n\n                # Evaluate fitness\n                f = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal best\n                if f < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = f\n                    self.pbest_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.particles[i].copy()\n                        self.gbest_position = self.x_opt.copy()\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "a2fa1d50-1b82-403a-b046-10bd0b574d91", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A variant of Differential Evolution with a dynamically adjusted population size and a restart mechanism based on stagnation detection, incorporating a covariance matrix adaptation strategy for mutation.", "code": "import numpy as np\n\nclass DynDE_CMA:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=20, restart_trigger=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = initial_pop_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.max_stagnation = budget // 100\n\n        self.C = np.eye(dim)\n        self.mu = 0\n        self.step_size = 1.0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.mu = self.population[np.argmin(self.fitness)]\n\n    def mutate(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mu + self.step_size * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.pop_size, self.dim) < 0.9\n        repair = np.random.randint(0, self.dim, self.pop_size)\n        for i in range(self.pop_size):\n            cross_points[i, repair[i]] = True\n        return np.where(cross_points, mutant, target)\n\n    def update_parameters(self):\n        best_idx = np.argmin(self.fitness)\n        delta = self.population[best_idx] - self.mu\n        self.mu = self.population[best_idx]\n\n        self.C = (1 - 0.1) * self.C + 0.1 * np.outer(delta / self.step_size, delta / self.step_size)\n        self.step_size *= np.exp(0.1 * (np.linalg.norm(delta) / self.dim - 1))\n        self.step_size = np.clip(self.step_size, 0.1, 5.0)\n        \n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx]\n            self.stagnation_counter = 0\n        else:\n            self.stagnation_counter += 1\n\n        if self.stagnation_counter > self.max_stagnation:\n            self.reset()\n\n    def reset(self):\n        self.C = np.eye(self.dim)\n        self.step_size = 1.0\n        self.stagnation_counter = 0\n        self.pop_size = int(self.pop_size * (1 - self.restart_trigger))\n        self.pop_size = max(10, self.pop_size)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.evals < self.budget:\n            mutant = self.mutate()\n            mutant = np.clip(mutant, self.lb, self.ub)\n            trial = self.crossover(mutant, self.population)\n\n            new_fitness = np.array([func(x) for x in trial])\n            self.evals += self.pop_size\n\n            improved = new_fitness < self.fitness\n            self.population[improved] = trial[improved]\n            self.fitness[improved] = new_fitness[improved]\n\n            self.update_parameters()\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2b6354b4-1815-4f8d-bbd1-e844fcf04c5d", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: A hybrid algorithm that combines particle swarm optimization (PSO) with a local search (LS) strategy, adaptively switching between exploration (PSO) and exploitation (LS) based on stagnation detection.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, ls_frequency=500, stagnation_threshold=500, ls_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.ls_frequency = ls_frequency\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.ls_radius = ls_radius\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def local_search(self, func, x_current):\n        x_new = x_current.copy()\n        for i in range(self.dim):\n            delta = np.random.uniform(-self.ls_radius, self.ls_radius)\n            x_new[i] = np.clip(x_current[i] + delta, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.budget -= 1\n        return f_new, x_new\n    \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population (particles) and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitness values\n        pbest_positions = population.copy()\n        pbest_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize global best position and fitness value\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_position = pbest_positions[gbest_index].copy()\n        self.f_opt = pbest_fitness[gbest_index]\n        self.x_opt = gbest_position.copy()\n        \n        generation = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (pbest_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (gbest_position - population[i])\n                \n                # Update positions\n                population[i] = np.clip(population[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate fitness\n                fitness = func(population[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = fitness\n                    pbest_positions[i] = population[i].copy()\n                    \n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i].copy()\n                        gbest_position = population[i].copy()\n                        self.stagnation_counter = 0\n                    else:\n                        self.stagnation_counter += 1\n\n            # Local Search application\n            if generation > 0 and generation % self.ls_frequency == 0:\n                 for i in range(self.pop_size):\n                    if self.budget > 0:\n                        new_f, new_x = self.local_search(func, population[i])\n                        if new_f < pbest_fitness[i]:\n                            pbest_fitness[i] = new_f\n                            pbest_positions[i] = new_x.copy()\n\n                            if new_f < self.f_opt:\n                                self.f_opt = new_f\n                                self.x_opt = new_x.copy()\n                                gbest_position = new_x.copy()\n                                self.stagnation_counter = 0\n                        else:\n                            self.stagnation_counter +=1\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart PSO if stagnated\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n                pbest_positions = population.copy()\n                pbest_fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_position = pbest_positions[gbest_index].copy()\n                self.f_opt = pbest_fitness[gbest_index]\n                self.x_opt = gbest_position.copy()\n                self.stagnation_counter = 0 #Reset Stagnation Counter\n\n            generation += 1\n        return self.f_opt, self.x_opt", "objective": -0.45318, "other_inf": null}
{"id": "02a68f78-8994-450e-a920-9601438ef294", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "# Description: An adaptive Differential Evolution strategy with self-adaptive parameters, orthogonal learning, and population reduction to enhance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDEOL:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def orthogonal_learning(self, func, x, eval_count, num_samples=5):\n        best_f = func(x)\n        eval_count += 1\n        best_x = x.copy()\n        for _ in range(num_samples):\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new.copy()\n        return best_f, best_x, eval_count\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection and Orthogonal Learning\n                f, trial, eval_count = self.orthogonal_learning(func, trial, eval_count)\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Adaptive F and CR\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n            #Population Size Reduction\n            if eval_count > self.budget * 0.75 and self.pop_size > 10:\n               worst_index = np.argmax(self.fitness)\n               self.population = np.delete(self.population, worst_index, axis = 0)\n               self.fitness = np.delete(self.fitness, worst_index)\n               self.pop_size -= 1\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "6d90a60a-a3c7-4e43-93ba-9069c1d7538b", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An enhanced differential evolution algorithm that incorporates a self-adaptive population size and a restart mechanism to escape local optima.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7, reduction_factor=0.5, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n        self.reduction_factor = reduction_factor\n        self.restart_trigger = restart_trigger\n        self.no_improvement_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                self.no_improvement_count = 0\n            else:\n                self.no_improvement_count += 1\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            # Adapt population size\n            if self.no_improvement_count > self.restart_trigger and self.pop_size > 10:\n                self.pop_size = int(self.pop_size * self.reduction_factor)\n                self.pop_size = max(10, self.pop_size)  # Ensure a minimum population size\n                population = population[np.argsort(fitness)[:self.pop_size]]\n                fitness = fitness[np.argsort(fitness)[:self.pop_size]]\n                self.no_improvement_count = 0\n\n            # Restart mechanism\n            if self.no_improvement_count > 2 * self.restart_trigger:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                self.no_improvement_count = 0\n            # Adapt parameters (simple adaptation - can be improved)\n            self.F = np.clip(self.F + np.random.normal(0, 0.01), 0.1, 0.9)\n            self.CR = np.clip(self.CR + np.random.normal(0, 0.01), 0.1, 0.9)\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.54628, "other_inf": null}
{"id": "ea92b9c6-3e55-450c-bf20-7e401506043a", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with increased exploration and a restart mechanism to escape local optima.}\n# Code:\n```python\nimport numpy as np\nimport cma\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, sigma=0.5, popsize=None, inc_popsize=2, restart_trigger=1e-9):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.popsize = popsize if popsize else 4 + int(3 * np.log(dim))\n        self.inc_popsize = inc_popsize\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.evals = 0\n\n    def __call__(self, func):\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n        es = cma.PureCMAES(x0, self.sigma, {\n            'bounds': [self.lb, self.ub],\n            'popsize': self.popsize,\n            'max_evaluations': self.budget,\n            'verbose': -9,\n        })\n\n        while self.evals < self.budget and not es.stop():\n            solutions = []\n            for i in range(es.popsize):\n                if self.evals >= self.budget:\n                    break\n                x = es.ask()\n                f = func(x)\n                self.evals += 1\n                solutions.append((x, f))\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            es.tell([s[0] for s in solutions], [s[1] for s in solutions])\n            es.disp()\n\n            if es.result.fbest - self.f_opt > self.restart_trigger:\n                x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.popsize *= self.inc_popsize\n                self.popsize = min(self.popsize, self.budget//2)\n\n                es = cma.PureCMAES(x0, self.sigma, {\n                    'bounds': [self.lb, self.ub],\n                    'popsize': self.popsize,\n                    'max_evaluations': self.budget - self.evals,\n                    'verbose': -9,\n                ", "code": "import numpy as np\nimport cma\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, sigma=0.5, popsize=None, inc_popsize=2, restart_trigger=1e-9):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.popsize = popsize if popsize else 4 + int(3 * np.log(dim))\n        self.inc_popsize = inc_popsize\n        self.restart_trigger = restart_trigger\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x_opt = None\n        self.f_opt = np.inf\n        self.evals = 0\n\n    def __call__(self, func):\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n        es = cma.PureCMAES(x0, self.sigma, {\n            'bounds': [self.lb, self.ub],\n            'popsize': self.popsize,\n            'max_evaluations': self.budget,\n            'verbose': -9,\n        })\n\n        while self.evals < self.budget and not es.stop():\n            solutions = []\n            for i in range(es.popsize):\n                if self.evals >= self.budget:\n                    break\n                x = es.ask()\n                f = func(x)\n                self.evals += 1\n                solutions.append((x, f))\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            es.tell([s[0] for s in solutions], [s[1] for s in solutions])\n            es.disp()\n\n            if es.result.fbest - self.f_opt > self.restart_trigger:\n                x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.popsize *= self.inc_popsize\n                self.popsize = min(self.popsize, self.budget//2)\n\n                es = cma.PureCMAES(x0, self.sigma, {\n                    'bounds': [self.lb, self.ub],\n                    'popsize': self.popsize,\n                    'max_evaluations': self.budget - self.evals,\n                    'verbose': -9,\n                })\n\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "b11ea9aa-4f5d-46cf-9888-a011db93ef0a", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: This algorithm uses a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware population size and a simplified update rule focusing on faster convergence in the early stages of the optimization.\n# Code:\n```", "code": "import numpy as np\n\nclass BudgetCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, cs=0.3, damps=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(np.floor(self.dim / 2 + 1)) # Number of parents/selected points\n        if initial_pop_size is None:\n             self.lambda_ = int(4 + np.floor(3 * np.log(self.dim))) # Pop size\n        else:\n            self.lambda_ = initial_pop_size\n        self.C = np.eye(self.dim) # Covariance matrix\n        self.m = np.zeros(self.dim) # Mean\n        self.sigma = 0.5  # Step size\n        self.cs = cs # Learning rate for the step size\n        self.damps = damps # Dampening for the step size\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.B = None # Eigenvectors of C\n        self.D = None # Eigenvalues of C\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.gen = 0\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Generate lambda offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.lambda_)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate offspring\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.lambda_\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Select parents\n            x_m = x[:self.mu]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.mean(x_m, axis=0)\n\n            # Update evolution path and step size\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * (self.m - m_old) / self.sigma\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc)**2 / self.dim - 1))\n\n            self.gen += 1\n        return self.f_opt, self.x_opt", "objective": -0.26981, "other_inf": null}
{"id": "f2419468-bd42-4774-91b9-3724741bb85b", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step-size adaptation and restarts to improve exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        \n        for restart in range(self.restarts):\n            mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n            sigma = self.initial_step_size\n            C = np.eye(self.dim)\n            \n            mu = self.pop_size // 2\n\n            c_m = 1 / mu\n            c_sigma = (mu + 2) / (self.dim + mu + 5)\n            d_sigma = 1 + 2 * max(0, np.sqrt((mu - 1) / (self.dim + 1)) - 1) + c_sigma\n            c_c = (4 + mu / self.dim) / (self.dim + 4 + 2 * mu / self.dim)\n            c_1 = 2 / ((self.dim + 1.3)**2 + mu)\n            c_mu = min(1 - c_1, 2 * (mu - 2 + 1 / mu) / ((self.dim + 2)**2 + 2 * mu))\n            \n            P_sigma = np.zeros(self.dim)\n            P_c = np.zeros(self.dim)\n            B = None\n            D = None\n            eigen_updated = 0\n\n            while evals < self.budget:\n                z = np.random.multivariate_normal(np.zeros(self.dim), np.eye(self.dim), size=self.pop_size)\n                x = mean + sigma * z @ np.linalg.cholesky(C).T\n\n                # Clipping\n                x = np.clip(x, self.lb, self.ub)\n                \n                f = np.array([func(xi) for xi in x])\n                evals += self.pop_size\n\n                if np.min(f) < self.f_opt:\n                    self.f_opt = np.min(f)\n                    self.x_opt = x[np.argmin(f)].copy()\n\n                idx = np.argsort(f)\n                x_mu = x[idx[:mu]]\n\n                mean_old = mean.copy()\n                mean = np.mean(x_mu, axis=0)\n\n                z_mu = (x_mu - mean_old) / sigma\n                \n                P_sigma = (1 - c_sigma) * P_sigma + np.sqrt(c_sigma * (2 - c_sigma)) * (B @ D @ np.mean(z_mu, axis=0))\n                \n                hsig = np.linalg.norm(P_sigma) / np.sqrt(1 - (1 - c_sigma)**(evals/self.pop_size)) / 1.4 > 2 + 4/(self.dim+1)\n                P_c = (1-c_c) * P_c + hsig * np.sqrt(c_c * (2 - c_c)) * (mean - mean_old) / sigma\n\n                C = (1 - c_1 - c_mu + c_1 * (c_c * (2 - c_c)) * np.sum(P_c**2) ) * C \\\n                  + c_1 * np.outer(P_c, P_c) \\\n                  + c_mu * np.mean(np.array([np.outer(z_mu[i], z_mu[i]) for i in range(mu)]), axis=0)\n\n                sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(P_sigma) / np.sqrt(self.dim) - 1))\n                sigma = min(sigma, abs(self.ub - self.lb))\n                \n                if evals - eigen_updated > self.pop_size / c_1 / self.dim / 10:\n                    eigen_updated = evals\n                    C = np.triu(C) + np.triu(C, 1).T\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(np.maximum(D, 1e-16))\n        \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "9ca199b9-f2a4-4c30-beb7-5984e980f995", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restart mechanism and budget-aware population size adaptation for enhanced exploration and exploitation in continuous optimization problems.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.3, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))  # Default CMA-ES pop size\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.c_sigma = (self.mu / (self.dim + (np.sqrt(2) * self.mu / (self.dim + 1))**2)) if self.dim > 1 else 1\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (self.mu / (self.dim + 2)) if self.dim > 1 else 1\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2.3)**2 + self.mu))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_iter = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            D, B = np.linalg.eig(self.C)\n            D = np.diag(np.sqrt(D))\n            x = self.m + self.sigma * z @ B @ D\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update CMA-ES parameters\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            zmean = np.sum(z[idx[:self.mu]].T * self.weights, axis=1)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * zmean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (xmean - self.m) / self.sigma\n\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.eval_count / self.pop_size))) / self.chiN < 1.4 + 2/(self.dim + 1))\n\n            self.m = xmean\n\n            dC = (self.c_1 * (self.pc[:, None] @ self.pc[None, :])) + (self.c_mu * (x[:self.mu] - self.m).T @ np.diag(self.weights) @ (x[:self.mu] - self.m)) / self.sigma**2\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + dC\n\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = min(self.sigma, (self.ub-self.lb)/3)\n            \n            if np.min(np.diag(self.C)) < 1e-16:\n                self.C += 1e-16 * np.eye(self.dim)\n\n            if np.isinf(self.f_opt) or np.isnan(self.f_opt):\n                self.restart_iter += 1\n                self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = self.initial_sigma\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n            # Budget-aware population size adaptation (optional)\n            remaining_evals = self.budget - self.eval_count\n            if remaining_evals < self.pop_size and self.pop_size > 2:\n                self.pop_size = max(2, remaining_evals // 2)  # Reduce pop size towards the end\n                self.mu = self.pop_size // 2\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n\n        return self.f_opt, self.x_opt", "objective": -0.11376, "other_inf": null}
{"id": "365b9af1-b354-4275-b8c2-381ef622fbaf", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A population-based algorithm that uses a Gaussian mixture model to sample new solutions and adaptively adjusts the model parameters based on the fitness of the samples.}\n# Code: \n```python\nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.gmm = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def update_gmm(self):\n        if self.evals > self.pop_size: # Ensure sufficient data points to train GMM.\n            # Select top individuals to fit the GMM\n            top_indices = np.argsort(self.fitness)[:self.pop_size // 2]\n            top_individuals = self.population[top_indices]\n\n            self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n            try:\n                self.gmm.fit(top_individuals)\n            except ValueError as e:\n                print(f\"GMM fit failed: {e}. Resetting GMM.\")\n                self.gmm = None # Reset gmm if fit fails\n            except Exception as e:\n                print(f\"An unexpected error occurred during GMM fitting: {e}\")\n                self.gmm = None\n\n    def sample_new_population(self, func):\n        new_population = []\n        new_fitness = []\n\n        if self.gmm is None: # Handle the case where GMM fitting failed or hasn't been trained yet.\n            for _ in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.evals += 1\n                new_population.append(x)\n                new_fitness.append(f)\n        else:\n            num_samples_needed = self.pop_size\n            while num_samples_needed > 0 and self.evals < self.budget:\n                try:\n                    samples = self.gmm.sample(num_samples_needed)[0]\n                except Exception as e:\n                    print(f\"Sampling from GMM failed: {e", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.gmm = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def update_gmm(self):\n        if self.evals > self.pop_size: # Ensure sufficient data points to train GMM.\n            # Select top individuals to fit the GMM\n            top_indices = np.argsort(self.fitness)[:self.pop_size // 2]\n            top_individuals = self.population[top_indices]\n\n            self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n            try:\n                self.gmm.fit(top_individuals)\n            except ValueError as e:\n                print(f\"GMM fit failed: {e}. Resetting GMM.\")\n                self.gmm = None # Reset gmm if fit fails\n            except Exception as e:\n                print(f\"An unexpected error occurred during GMM fitting: {e}\")\n                self.gmm = None\n\n    def sample_new_population(self, func):\n        new_population = []\n        new_fitness = []\n\n        if self.gmm is None: # Handle the case where GMM fitting failed or hasn't been trained yet.\n            for _ in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.evals += 1\n                new_population.append(x)\n                new_fitness.append(f)\n        else:\n            num_samples_needed = self.pop_size\n            while num_samples_needed > 0 and self.evals < self.budget:\n                try:\n                    samples = self.gmm.sample(num_samples_needed)[0]\n                except Exception as e:\n                    print(f\"Sampling from GMM failed: {e}. Resetting GMM.\")\n                    self.gmm = None  # Reset GMM if sampling fails\n                    return self.sample_new_population(func) # Recursive call to re-sample randomly\n\n                for x in samples:\n                    if self.evals >= self.budget:\n                        break\n                    x = np.clip(x, self.lb, self.ub)  # Clip to bounds\n                    f = func(x)\n                    self.evals += 1\n                    new_population.append(x)\n                    new_fitness.append(f)\n                    num_samples_needed -= 1 # Reduce needed sample count\n        return np.array(new_population), np.array(new_fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.evals < self.budget:\n            self.update_gmm()\n            new_population, new_fitness = self.sample_new_population(func)\n\n            # Combine old and new populations (Elitism)\n            combined_population = np.concatenate((self.population, new_population)) if len(new_population) > 0 else self.population\n            combined_fitness = np.concatenate((self.fitness, new_fitness)) if len(new_fitness) > 0 else self.fitness\n\n            # Select the best individuals for the next generation\n            top_indices = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[top_indices]\n            self.fitness = combined_fitness[top_indices]\n\n            # Update the best solution found so far\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ca873441-5faf-40c0-afae-bfe9422450ac", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) that adapts the covariance matrix of a multivariate normal distribution to efficiently sample the search space.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mu=None, c_cov_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None  # Mean vector\n        self.C = None  # Covariance matrix\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.chiN = None\n        self.cs = cs # Cumulation factor for sigma\n        if damps is None:\n            self.damps = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        else:\n            self.damps = damps\n        \n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else 2 / (self.dim**2 + 6)\n        self.c_cov_one = c_cov_one if c_cov_one is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.B = None # Eigenvectors of C\n        self.D = None # Eigenvalues of C (sqrt)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize mean and covariance matrix\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        \n        self.D, self.B = np.linalg.eig(self.C)\n        self.D = np.sqrt(self.D)\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.randn(self.dim, self.pop_size)\n            y = self.B @ np.diag(self.D) @ z\n            x = self.m + self.sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            x = x[:, indices]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(x[:, :self.mu] * self.weights[None, :], axis=1)\n\n            # Update evolution paths\n            y_mean = np.mean(y[:, :self.mu], axis=1)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (self.B @ y_mean)\n            \n            c_sig = (np.linalg.norm(self.ps)/self.chiN) < (1.4 + 2/(self.dim+1))\n            \n            self.pc = (1-self.c_cov_one) * self.pc + c_sig * np.sqrt(self.c_cov_one * (2-self.c_cov_one)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            artmp = (x[:, :self.mu] - m_old[:, None]) / self.sigma\n            self.C = (1 - self.c_cov_one - self.c_cov_mu) * self.C \\\n                     + self.c_cov_one * np.outer(self.pc, self.pc) \\\n                     + self.c_cov_mu * artmp @ np.diag(self.weights) @ artmp.T\n            \n            # Adapt step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            \n            self.D, self.B = np.linalg.eig(self.C)\n            self.D = np.sqrt(self.D)\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0].copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "6e5f6893-9d92-4511-b28b-0030e4453815", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "A cooperative swarm optimization algorithm that uses multiple swarms with different search strategies and information sharing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass CooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, num_swarms=5, swarm_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.swarms = []\n        self.fitness = []\n        self.velocities = []\n        self.pbest_positions = []\n        self.pbest_fitness = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.inertia = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.exploration_rate = 0.3\n        self.exploitation_rate = 0.7\n\n        for _ in range(num_swarms):\n            self.swarms.append(np.random.uniform(self.lb, self.ub, size=(swarm_size, dim)))\n            self.fitness.append(np.zeros(swarm_size))\n            self.velocities.append(np.random.uniform(-1, 1, size=(swarm_size, dim)))\n            self.pbest_positions.append(self.swarms[-1].copy())\n            self.pbest_fitness.append(np.full(swarm_size, np.inf))\n\n    def evaluate_swarm(self, func, swarm_index):\n        for i in range(self.swarm_size):\n            if self.evals >= self.budget:\n                return\n            self.fitness[swarm_index][i] = func(self.swarms[swarm_index][i])\n            self.evals += 1\n\n            if self.fitness[swarm_index][i] < self.pbest_fitness[swarm_index][i]:\n                self.pbest_fitness[swarm_index][i] = self.fitness[swarm_index][i]\n                self.pbest_positions[swarm_index][i] = self.swarms[swarm_index][i].copy()\n\n            if self.fitness[swarm_index][i] < self.f_opt:\n                self.f_opt = self.fitness[swarm_index][i]\n                self.x_opt = self.swarms[swarm_index][i].copy()\n\n    def update_velocity(self, swarm_index, gbest):\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n        cognitive_component = self.cognitive_coeff * r1 * (self.pbest_positions[swarm_index] - self.swarms[swarm_index])\n        social_component = self.social_coeff * r2 * (gbest - self.swarms[swarm_index])\n        self.velocities[swarm_index] = self.inertia * self.velocities[swarm_index] + cognitive_component + social_component\n\n    def update_position(self, swarm_index):\n        self.swarms[swarm_index] = np.clip(self.swarms[swarm_index] + self.velocities[swarm_index], self.lb, self.ub)\n\n    def migrate_information(self):\n        best_swarm_index = np.argmin([np.min(fitness) for fitness in self.fitness])\n        worst_swarm_index = np.argmax([np.max(fitness) for fitness in self.fitness])\n\n        best_particle_index = np.argmin(self.fitness[best_swarm_index])\n        worst_particle_index = np.argmax(self.fitness[worst_swarm_index])\n\n        self.swarms[worst_swarm_index][worst_particle_index] = self.pbest_positions[best_swarm_index][best_particle_index].copy()\n        self.fitness[worst_swarm_index][worst_particle_index] = self.pbest_fitness[best_swarm_index][best_particle_index]\n\n    def __call__(self, func):\n        for i in range(self.num_swarms):\n            self.evaluate_swarm(func, i)\n\n        while self.evals < self.budget:\n            gbest_swarm_index = np.argmin([np.min(fitness) for fitness in self.fitness])\n            gbest = self.pbest_positions[gbest_swarm_index][np.argmin(self.pbest_fitness[gbest_swarm_index])]\n\n            for i in range(self.num_swarms):\n                self.update_velocity(i, gbest)\n                self.update_position(i)\n                self.evaluate_swarm(func, i)\n\n            if np.random.rand() < 0.1:\n                self.migrate_information()\n\n        return self.f_opt, self.x_opt", "objective": -0.5615, "other_inf": null}
{"id": "db43c08c-b13b-44f1-860a-19d490502a6a", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "A particle swarm optimization algorithm with velocity clamping, dynamic inertia weight adaptation, and a local search enhancement using a quasi-Newton method.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO:\n    def __init__(self, budget=10000, dim=10, pop_size=30, w=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max\n        self.lb = -5.0\n        self.ub = 5.0\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.gbest_position = None\n        self.gbest_fitness = np.inf\n        self.evals = 0\n        self.inertia_reduction_rate = 0.995\n        self.local_search_interval = budget // 15\n        self.local_search_fev = 25\n\n    def initialize_particles(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.pop_size\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_position = self.pbest_positions[np.argmin(self.pbest_fitness)].copy()\n        self.gbest_fitness = np.min(self.pbest_fitness)\n\n        self.f_opt = self.gbest_fitness\n        self.x_opt = self.gbest_position\n\n    def update_velocities(self):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.pbest_positions - self.particles)\n        social_component = self.c2 * r2 * (self.gbest_position - self.particles)\n\n        self.velocities = self.w * self.velocities + cognitive_component + social_component\n        self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n\n    def update_positions(self):\n        self.particles = self.particles + self.velocities\n        self.particles = np.clip(self.particles, self.lb, self.ub)\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.particles[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(self.budget - self.evals, self.local_search_fev)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PSO:\n    def __init__(self, budget=10000, dim=10, pop_size=30, w=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max = v_max\n        self.lb = -5.0\n        self.ub = 5.0\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.gbest_position = None\n        self.gbest_fitness = np.inf\n        self.evals = 0\n        self.inertia_reduction_rate = 0.995\n        self.local_search_interval = budget // 15\n        self.local_search_fev = 25\n\n    def initialize_particles(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.pop_size\n\n        self.pbest_positions = self.particles.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_position = self.pbest_positions[np.argmin(self.pbest_fitness)].copy()\n        self.gbest_fitness = np.min(self.pbest_fitness)\n\n        self.f_opt = self.gbest_fitness\n        self.x_opt = self.gbest_position\n\n    def update_velocities(self):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.pbest_positions - self.particles)\n        social_component = self.c2 * r2 * (self.gbest_position - self.particles)\n\n        self.velocities = self.w * self.velocities + cognitive_component + social_component\n        self.velocities = np.clip(self.velocities, -self.v_max, self.v_max)\n\n    def update_positions(self):\n        self.particles = self.particles + self.velocities\n        self.particles = np.clip(self.particles, self.lb, self.ub)\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x0 = self.particles[i].copy()\n            bounds = [(self.lb, self.ub)] * self.dim\n            res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(self.budget - self.evals, self.local_search_fev)})\n\n            if res.fun < self.fitness[i]:\n                self.particles[i] = res.x\n                self.fitness[i] = res.fun\n                self.evals += res.nfev\n                self.pbest_positions[i] = res.x\n                self.pbest_fitness[i] = res.fun\n\n                if res.fun < self.gbest_fitness:\n                    self.gbest_fitness = res.fun\n                    self.gbest_position = res.x\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n\n\n    def __call__(self, func):\n        self.initialize_particles(func)\n        iter_count = 0\n\n        while self.evals < self.budget:\n            iter_count += 1\n\n            if iter_count % self.local_search_interval == 0:\n                self.local_search(func)\n\n            self.update_velocities()\n            self.update_positions()\n\n            new_fitness = np.array([func(x) for x in self.particles])\n            self.evals += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.pbest_fitness[i]:\n                    self.pbest_fitness[i] = new_fitness[i]\n                    self.pbest_positions[i] = self.particles[i].copy()\n\n                    if new_fitness[i] < self.gbest_fitness:\n                        self.gbest_fitness = new_fitness[i]\n                        self.gbest_position = self.particles[i].copy()\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = self.particles[i].copy()\n            \n            self.fitness = new_fitness.copy()\n            self.w *= self.inertia_reduction_rate\n            self.w = max(0.4, self.w)\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "27c9cc23-9171-4be7-94f3-05263a47e10d", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "This algorithm uses a population-based approach with Gaussian mutation and selection, coupled with a restart mechanism when stagnation is detected to escape local optima.", "code": "import numpy as np\n\nclass GaussianMutationES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sigma=0.5, restart_trigger=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_trigger = restart_trigger\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index].copy()\n        \n        no_improvement_count = 0\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                mutation = np.random.normal(0, self.sigma, size=self.dim)\n                new_individual = self.population[i] + mutation\n                new_individual = np.clip(new_individual, self.lb, self.ub)\n                new_population[i] = new_individual\n            \n            new_fitness = np.array([func(x) for x in new_population])\n            self.eval_count += self.pop_size\n            \n            for i in range(self.pop_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = new_population[i].copy()\n            \n            current_best_index = np.argmin(self.fitness)\n            if self.fitness[current_best_index] < self.f_opt:\n                self.f_opt = self.fitness[current_best_index]\n                self.x_opt = self.population[current_best_index].copy()\n                no_improvement_count = 0\n            else:\n                no_improvement_count += self.pop_size\n            \n            if no_improvement_count > self.restart_trigger:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.fitness)\n                \n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.population[best_index].copy()\n                no_improvement_count = 0\n        \n        return self.f_opt, self.x_opt", "objective": -0.16677, "other_inf": null}
{"id": "7a0484b2-2be6-47e0-a2af-404e21aa3ff7", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "'maxiter': self.simplex_iters, 'maxfev': self.simplex_iters", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SimplexEnhancedEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, simplex_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.simplex_iters = simplex_iters\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            # Select individuals for simplex-based search (e.g., top 50% + some random)\n            num_elite = self.pop_size // 2\n            elite_indices = np.argsort(fitness)[:num_elite]\n            random_indices = np.random.choice(self.pop_size, self.pop_size - num_elite, replace=False)\n            selected_indices = np.concatenate([elite_indices, random_indices])\n\n            for i in selected_indices:\n                if self.budget <= 0:\n                  break\n\n                # Nelder-Mead Simplex\n                initial_simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n                initial_simplex[0] = population[i]\n                \n                def simplex_objective(x):\n                  val = func(x)\n                  return val\n\n                res = minimize(simplex_objective, population[i], method='Nelder-Mead',\n                                bounds=[(func.bounds.lb, func.bounds.ub)] * self.dim,\n                                options={'maxiter': self.simplex_iters, 'maxfev': self.simplex_iters})\n\n                self.budget -= res.nfev\n\n                if res.fun < fitness[i]:\n                    fitness[i] = res.fun\n                    population[i] = res.x.copy()\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x.copy()\n            \n            # Global Exploration: Introduce some diversity (e.g., replace worst individuals)\n            num_replace = self.pop_size // 4\n            worst_indices = np.argsort(fitness)[-num_replace:]\n            for i in worst_indices:\n                population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                fitness[i] = func(population[i])\n                self.budget -= 1\n\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i].copy()\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "49bb79c6-3be5-4daa-b7b6-25c0c3028648", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "An evolutionary algorithm that uses a population of solutions, adaptive mutation based on fitness landscape exploration, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, sigma=0.1, decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma\n        self.decay_rate = decay_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_trigger = 100\n        self.stagnation_counter = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, individual):\n        noise = np.random.normal(0, self.sigma, size=self.dim)\n        return np.clip(individual + noise, self.lb, self.ub)\n\n    def evaluate(self, func, individual):\n        f = func(individual)\n        self.evals += 1\n        return f\n\n    def restart_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.sigma = 0.1\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.evals < self.budget:\n            \n            parents_fitness = self.fitness.copy()\n            children = np.array([self.mutate(x) for x in self.population])\n            children_fitness = np.array([self.evaluate(func, x) for x in children])\n            \n            for i in range(self.pop_size):\n              if children_fitness[i] < parents_fitness[i]:\n                self.population[i] = children[i]\n                self.fitness[i] = children_fitness[i]\n            \n                if children_fitness[i] < self.f_opt:\n                    self.f_opt = children_fitness[i]\n                    self.x_opt = children[i]\n                    self.stagnation_counter = 0\n\n            self.sigma *= self.decay_rate\n            self.stagnation_counter += 1\n\n            if self.stagnation_counter > self.restart_trigger or self.sigma < 1e-5:\n              if self.evals + self.pop_size < self.budget:\n                self.restart_population(func)\n              else:\n                break\n              \n        return self.f_opt, self.x_opt", "objective": -0.24811, "other_inf": null}
{"id": "d26cf16b-34e2-4235-8c14-9e4bbad4a0ce", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "Adaptively samples promising regions by clustering successful points and focusing search around cluster centroids, while maintaining diversity through a repulsion mechanism.", "code": "import numpy as np\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nfrom scipy.spatial.distance import cdist\n\nclass AdaptiveClusteringSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, num_clusters=5, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_clusters = num_clusters\n        self.repulsion_factor = repulsion_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.successful_points = []\n        self.bandwidth = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.successful_points.extend(self.population[self.fitness < np.median(self.fitness)])\n\n    def generate_samples(self, func):\n        new_samples = []\n        if not self.successful_points:\n            new_samples = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        else:\n            bandwidth = estimate_bandwidth(self.successful_points, quantile=0.2)\n            if bandwidth == 0:\n                bandwidth = 0.1\n            ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n            ms.fit(self.successful_points)\n            cluster_centers = ms.cluster_centers_\n            \n            if len(cluster_centers) == 0:\n                 new_samples = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n            else:\n                num_per_cluster = self.pop_size // len(cluster_centers)\n                for center in cluster_centers:\n                    for _ in range(num_per_cluster):\n                        sample = np.random.normal(center, 0.5, size=self.dim)\n                        sample = np.clip(sample, self.lb, self.ub)\n                        new_samples.append(sample)\n\n                while len(new_samples) < self.pop_size:\n                    sample = np.random.uniform(self.lb, self.ub, size=self.dim)\n                    new_samples.append(sample)\n\n        # Repulsion mechanism\n        if self.successful_points:\n            for i in range(len(new_samples)):\n                distances = cdist([new_samples[i]], self.successful_points)[0]\n                closest_idx = np.argmin(distances)\n                repulsion_vector = new_samples[i] - self.successful_points[closest_idx]\n                new_samples[i] = np.clip(new_samples[i] + self.repulsion_factor * repulsion_vector, self.lb, self.ub)\n        return np.array(new_samples)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            new_population = self.generate_samples(func)\n            new_fitness = np.array([func(x) for x in new_population])\n            self.evals += self.pop_size\n            \n            for i in range(self.pop_size):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i]\n\n            self.population = new_population\n            self.fitness = new_fitness\n            self.successful_points.extend(self.population[self.fitness < np.median(self.fitness)])\n            if len(self.successful_points) > 100:\n                self.successful_points = self.successful_points[-100:]\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "d1a2d882-8f18-4426-93b2-e32d03f73ec1", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: A particle swarm optimization algorithm with velocity clamping, constriction factor, and adaptive inertia weight based on swarm diversity and stagnation detection.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia_max=0.9, inertia_min=0.4, c1=2.0, c2=2.0, velocity_clamp=0.5, stagnation_threshold=500, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            # Calculate diversity\n            diversity = np.std(swarm)\n\n            # Adaptive inertia weight\n            if diversity < self.diversity_threshold:\n                inertia = self.inertia_min  # Reduce inertia for exploitation\n                self.stagnation_counter +=1\n            else:\n                inertia = self.inertia_max  # Increase inertia for exploration\n                self.stagnation_counter = 0\n                \n            #Velocity clamping and constriction factor\n\n            constriction_factor = 0.729  # Standard constriction factor\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = constriction_factor * (inertia * velocities[i] +\n                                        self.c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                        self.c2 * r2 * (global_best_position - swarm[i]))\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                swarm[i] = new_position\n                \n            # Evaluate fitness\n            new_fitness = np.array([func(x) for x in swarm])\n            self.budget -= self.swarm_size\n\n            # Update personal best\n            for i in range(self.swarm_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = swarm[i].copy()\n\n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[global_best_index]\n                self.x_opt = personal_best_positions[global_best_index].copy()\n                self.stagnation_counter = 0\n\n            #Stagnation Detection and swarm restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n                velocities = np.random.uniform(-self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb), size=(self.swarm_size, self.dim))\n                fitness = np.array([func(x) for x in swarm])\n                self.budget -= self.swarm_size\n\n                personal_best_positions = swarm.copy()\n                personal_best_fitness = fitness.copy()\n\n                global_best_index = np.argmin(fitness)\n                global_best_position = swarm[global_best_index].copy()\n                self.f_opt = fitness[global_best_index]\n                self.x_opt = global_best_position.copy()\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "83f79e4d-30ca-4e56-a5cf-3587f0766164", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A modified Differential Evolution algorithm with dynamic population sizing, adaptive mutation strategies, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10, F=0.5, CR=0.9, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_prob = restart_prob\n        self.archive = []\n        self.archive_size = 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        if np.random.rand() < 0.5: # Strategy 1: classic DE\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n            return np.clip(a + self.F * (b - c), self.lb, self.ub)\n        else: # Strategy 2: current-to-best\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b = pop[np.random.choice(idxs, 2, replace=False)]\n            return np.clip(pop[i] + self.F * (self.x_opt - pop[i]) + self.F * (a - b), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n    \n    def adjust_population_size(self):\n        if len(self.archive) > self.archive_size:\n            self.pop_size = max(self.min_pop_size, self.pop_size // 2)\n            self.population = self.population[np.argsort(self.fitness)[:self.pop_size]]\n            self.fitness = self.fitness[np.argsort(self.fitness)[:self.pop_size]]\n    \n    def restart(self, func):\n        if np.random.rand() < self.restart_prob:\n            self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n            self.fitness = np.array([func(x) for x in self.population])\n            self.evals += self.pop_size\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.evals < self.budget:\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(trial)\n                        else:\n                            self.archive[np.random.randint(0, self.archive_size)] = trial\n\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n            \n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            self.adjust_population_size()\n            self.restart(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.33226, "other_inf": null}
{"id": "7f7ee65e-b37e-46a9-ae41-9b3c87fd15fa", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A modified CMA-ES algorithm with a budget-aware covariance matrix adaptation strategy and a local search component using BFGS.}\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = initial_sigma\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.pop_size + 2) / (dim + 5) / 3\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.c_sigma * (2 - self.c_sigma) * self.chiN**2 - 1)))\n        self.c_c = 4 / (dim + 4)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.c_mu = min(1 - self.c_c, 2 * (self.mu - 1 + 1/(self.mu + 1)) / ( (dim + 2)**2 + self.mu))\n        self.c_1 = 0.1\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_interval = budget // 15\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def update_distribution(self, population, fitness_values):\n        idx = np.argsort(fitness_values)\n        elite_population = population[idx[:self.mu]]\n        y = elite_population - self.mean\n        self.pc = (1 - self.c_c) * self.pc + (self.c_c * (2 - self.c_c))**0.5 * np.sum(self.weights[:, None] * y, axis=0) / self.sigma\n        self.ps = (1 - self.c_sigma) * self.ps + (self.c_sigma * (2 - self.c_sigma))**0.5 * self.pc / (np.linalg.det(self.C)**(1 / (2 * self.dim)))\n        \n        hsig = np.linalg.norm(self.ps) / (1 - (1-self.c_sigma)**(self.evals/self.pop_size)) / self.chiN < 1.4 + 2/(self.dim + 1)\n\n        self.sigma *= np.exp(min(0.5, self.c_sigma / self.d_sigma * (np.linalg.norm(self.ps)/self.chiN - 1)))\n\n        delta = y / self.sigma\n        \n        self.C = (1 - self.c_1 - self.c_mu + self.c_1 * self.c_c * (2 - self.c_c) * (not hsig)) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n        self.C += self.c_mu * np.sum(self.weights[:, None, None] * delta[:, :, None] * delta[:, None, :], axis=0)\n\n        self.mean = np.sum(self.weights[:, None] * elite_population, axis=0)\n\n    def local_search(self, func):\n        bounds = [(self.lb, self.ub)] * self.dim\n        res = minimize(func, self.x_opt, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(self.budget - self.evals, 50)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = initial_sigma\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.pop_size + 2) / (dim + 5) / 3\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.c_sigma * (2 - self.c_sigma) * self.chiN**2 - 1)))\n        self.c_c = 4 / (dim + 4)\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.c_mu = min(1 - self.c_c, 2 * (self.mu - 1 + 1/(self.mu + 1)) / ( (dim + 2)**2 + self.mu))\n        self.c_1 = 0.1\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_interval = budget // 15\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def update_distribution(self, population, fitness_values):\n        idx = np.argsort(fitness_values)\n        elite_population = population[idx[:self.mu]]\n        y = elite_population - self.mean\n        self.pc = (1 - self.c_c) * self.pc + (self.c_c * (2 - self.c_c))**0.5 * np.sum(self.weights[:, None] * y, axis=0) / self.sigma\n        self.ps = (1 - self.c_sigma) * self.ps + (self.c_sigma * (2 - self.c_sigma))**0.5 * self.pc / (np.linalg.det(self.C)**(1 / (2 * self.dim)))\n        \n        hsig = np.linalg.norm(self.ps) / (1 - (1-self.c_sigma)**(self.evals/self.pop_size)) / self.chiN < 1.4 + 2/(self.dim + 1)\n\n        self.sigma *= np.exp(min(0.5, self.c_sigma / self.d_sigma * (np.linalg.norm(self.ps)/self.chiN - 1)))\n\n        delta = y / self.sigma\n        \n        self.C = (1 - self.c_1 - self.c_mu + self.c_1 * self.c_c * (2 - self.c_c) * (not hsig)) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n        self.C += self.c_mu * np.sum(self.weights[:, None, None] * delta[:, :, None] * delta[:, None, :], axis=0)\n\n        self.mean = np.sum(self.weights[:, None] * elite_population, axis=0)\n\n    def local_search(self, func):\n        bounds = [(self.lb, self.ub)] * self.dim\n        res = minimize(func, self.x_opt, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(self.budget - self.evals, 50)})\n\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x\n        self.evals += res.nfev\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.x_opt = self.mean.copy()\n        self.f_opt = func(self.mean)\n        self.evals +=1\n\n        iter_count = 0\n        while self.evals < self.budget:\n            iter_count += 1\n            population = self.sample_population()\n            population = np.clip(population, self.lb, self.ub)\n            fitness_values = np.array([func(x) for x in population])\n            self.evals += self.pop_size\n\n            if np.min(fitness_values) < self.f_opt:\n                self.f_opt = np.min(fitness_values)\n                self.x_opt = population[np.argmin(fitness_values)].copy()\n            \n            self.update_distribution(population, fitness_values)\n            \n            if iter_count % self.local_search_interval == 0 and self.evals < self.budget:\n                self.local_search(func)\n\n            if self.evals >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "1b38b57b-efbf-4da0-bde9-0473fd3683ea", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A hybrid algorithm combining Differential Evolution with a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for enhanced exploration and exploitation.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cmaes_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.cmaes_interval = cmaes_interval\n        self.cmaes_sigma = 0.5 #initial sigma for CMA-ES\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def cmaes_step(self, func):\n        x0 = self.x_opt.copy()\n        bounds = [(self.lb, self.ub)] * self.dim\n\n        def cmaes_objective(x):\n            return func(x)\n\n        options = {'maxfev': min(self.cmaes_interval, self.budget - self.evals), 'sigma': self.cmaes_sigma", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, cmaes_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.cmaes_interval = cmaes_interval\n        self.cmaes_sigma = 0.5 #initial sigma for CMA-ES\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def cmaes_step(self, func):\n        x0 = self.x_opt.copy()\n        bounds = [(self.lb, self.ub)] * self.dim\n\n        def cmaes_objective(x):\n            return func(x)\n\n        options = {'maxfev': min(self.cmaes_interval, self.budget - self.evals), 'sigma': self.cmaes_sigma}\n        res = minimize(cmaes_objective, x0, method='trust-constr', bounds=bounds, options=options) # or method='SLSQP' or 'TNC'\n\n        if res.fun < self.f_opt:\n            self.f_opt = res.fun\n            self.x_opt = res.x\n            \n        self.evals += res.nfev\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        generation = 0\n        while self.evals < self.budget:\n            generation += 1\n            if generation % (self.cmaes_interval // self.pop_size) == 0:\n                self.cmaes_step(func)\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n                    continue\n\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "1de4c506-628d-4f81-b1bd-a4a81a1ded94", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a smaller population size, a lower learning rate, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=10, sigma=0.5, cs=0.1, damps=0.1, ccov1=0.02, ccovmu=0.01, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.ccov1 = ccov1\n        self.ccovmu = ccovmu\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mu = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize(self):\n        self.mu = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.evals = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample_population(self):\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n        x = self.mu + self.sigma * z\n        x = np.clip(x, self.lb, self.ub)\n        return x, z\n\n    def update_parameters(self, x, z, fitness):\n        idx = np.argsort(fitness)\n        x_sorted = x[idx]\n        z_sorted = z[idx]\n\n        weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n\n        mu_old = self.mu.copy()\n        self.mu = np.sum(x_sorted[:self.pop_size] * weights[:, np.newaxis], axis=0)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * np.sum(weights**2)) * (self.mu - mu_old) / self.sigma\n        self.pc = (1 - self.damps) * self.pc + np.sqrt(self.damps * (2 - self.damps)) * (self.mu - mu_old)\n\n        artw = z_sorted[:self.pop_size] * weights[:, np.newaxis]\n        self.C = (1 - self.ccov1 - self.ccovmu) * self.C + self.ccov1 * (np.outer(self.pc, self.pc) + 0.01*np.eye(self.dim)) + self.ccovmu * np.sum(artw[:, :, np.newaxis] @ artw[:, np.newaxis, :], axis=0)\n\n        self.sigma *= np.exp((np.linalg.norm(self.ps) - np.sqrt(self.dim)) / self.cs / self.damps)\n\n    def __call__(self, func):\n        self.initialize()\n        \n        restart_count = 0\n        while restart_count < self.restarts:\n            while self.evals < self.budget // self.restarts:\n                x, z = self.sample_population()\n                fitness = np.array([func(xi) for xi in x])\n                self.evals += self.pop_size\n\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = x[np.argmin(fitness)]\n\n                self.update_parameters(x, z, fitness)\n\n                if np.any(np.isnan(self.C)):\n                    self.initialize()\n                    break\n            \n            if self.evals >= self.budget // self.restarts:\n                break\n            \n            restart_count += 1\n            self.initialize()\n        \n        return self.f_opt, self.x_opt", "objective": -0.19289, "other_inf": null}
{"id": "781f9727-1fb6-4a66-a065-726cfd3b9331", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An algorithm employing a particle swarm optimization strategy with velocity clamping and inertia weight adaptation to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max_ratio = v_max_ratio\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max_ratio * (func.bounds.ub - func.bounds.lb), self.v_max_ratio * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        pbest_positions = population.copy()\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        pbest_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        gbest_position = population[best_index].copy()\n\n        v_max = self.v_max_ratio * (func.bounds.ub - func.bounds.lb)\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest_positions - population) + self.c2 * r2 * (gbest_position - population)\n            velocities = np.clip(velocities, -v_max, v_max)  # Clamp velocities\n\n            population = population + velocities\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions\n            for i in range(self.pop_size):\n                if new_fitness[i] < pbest_fitness[i]:\n                    pbest_fitness[i] = new_fitness[i]\n                    pbest_positions[i] = population[i].copy()\n\n            # Update global best position\n            best_index = np.argmin(pbest_fitness)\n            if pbest_fitness[best_index] < self.f_opt:\n                self.f_opt = pbest_fitness[best_index]\n                self.x_opt = pbest_positions[best_index].copy()\n                gbest_position = pbest_positions[best_index].copy()\n\n            # Adapt inertia weight\n            self.w = np.clip(self.w * 0.99, 0.4, 0.9)\n\n        return self.f_opt, self.x_opt", "objective": -0.4978, "other_inf": null}
{"id": "08d999e7-dbb5-4cbc-bcf1-062ea7d2aa7b", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: A particle swarm optimization algorithm with velocity clamping and adaptive inertia weight to balance exploration and exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.5, c2=1.5, w_start=0.9, w_end=0.4, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.w_start = w_start # initial inertia weight\n        self.w_end = w_end # final inertia weight\n        self.v_max_ratio = v_max_ratio\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max_ratio * (func.bounds.ub - func.bounds.lb), self.v_max_ratio * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        global_best_position = population[best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            # Adaptive inertia weight\n            w = self.w_start - (self.w_start - self.w_end) * iteration / (self.budget / self.pop_size + iteration)\n\n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n\n                # Velocity clamping\n                v_max = self.v_max_ratio * (func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                # Update positions\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Update personal best positions\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position\n            best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[best_index]\n                self.x_opt = personal_best_positions[best_index].copy()\n                global_best_position = personal_best_positions[best_index].copy()\n            \n            iteration += 1\n\n        return self.f_opt, self.x_opt", "objective": -0.5147, "other_inf": null}
{"id": "4383c477-6a3b-4a4c-addc-ebd042a1544e", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is used with a step-size adaptation strategy to efficiently explore the search space.}\n# Code:\n```python\nimport numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.es = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.es = cma.purecma.CMAEvolutionStrategy(x0, self.sigma0,\n                                             {'bounds': [self.lb, self.ub],\n                                              'verbose': -9,\n                                              'maxfevals': self.budget", "code": "import numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n        self.es = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.es = cma.purecma.CMAEvolutionStrategy(x0, self.sigma0,\n                                             {'bounds': [self.lb, self.ub],\n                                              'verbose': -9,\n                                              'maxfevals': self.budget})\n\n        while self.es.result[0] is None and self.es.countevals < self.budget:\n            solutions = self.es.ask()\n            fitness_list = []\n            for s in solutions:\n                fitness_list.append(func(s))\n            self.es.tell(solutions, fitness_list)\n            if min(fitness_list) < self.f_opt:\n                self.f_opt = min(fitness_list)\n                self.x_opt = solutions[np.argmin(fitness_list)]\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2952a406-393e-4316-bc9a-d9e9220cb8f8", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: This algorithm utilizes a Nelder-Mead simplex method with adaptive step size control and a restart strategy based on the simplex volume.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, reflection=1.0, expansion=2.0, contraction=0.5, shrinkage=0.5, volume_threshold=1e-8):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.reflection = reflection\n        self.expansion = expansion\n        self.contraction = contraction\n        self.shrinkage = shrinkage\n        self.volume_threshold = volume_threshold\n        self.simplex = None\n        self.values = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_simplex(self, func):\n        # Initialize simplex vertices around a random point\n        initial_point = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.simplex = np.zeros((self.dim + 1, self.dim))\n        self.simplex[0] = initial_point\n        for i in range(1, self.dim + 1):\n            self.simplex[i] = initial_point.copy()\n            self.simplex[i][i-1] += self.initial_simplex_size * (func.bounds.ub - func.bounds.lb)\n            self.simplex[i] = np.clip(self.simplex[i], func.bounds.lb, func.bounds.ub) # Keep in bounds\n        self.values = np.array([func(x) for x in self.simplex])\n        self.budget -= self.dim + 1\n        \n        best_index = np.argmin(self.values)\n        self.f_opt = self.values[best_index]\n        self.x_opt = self.simplex[best_index].copy()\n\n    def calculate_simplex_volume(self):\n        # Calculate the volume of the simplex\n        if self.dim == 1:\n           return np.abs(self.simplex[1] - self.simplex[0])\n        matrix = self.simplex[1:] - self.simplex[0]\n        return np.abs(np.linalg.det(matrix))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_simplex(func)\n        \n        while self.budget > 0:\n            # Order vertices by value\n            order = np.argsort(self.values)\n            self.simplex = self.simplex[order]\n            self.values = self.values[order]\n            \n            best = self.simplex[0]\n            worst = self.simplex[-1]\n            second_worst = self.simplex[-2]\n            centroid = np.mean(self.simplex[:-1], axis=0)\n            \n            # Reflection\n            reflected = centroid + self.reflection * (centroid - worst)\n            reflected = np.clip(reflected, func.bounds.lb, func.bounds.ub)\n            f_reflected = func(reflected)\n            self.budget -= 1\n            if self.budget <= 0:\n                break\n            \n            if self.values[0] <= f_reflected < self.values[-2]:\n                self.simplex[-1] = reflected\n                self.values[-1] = f_reflected\n            elif f_reflected < self.values[0]:\n                # Expansion\n                expanded = centroid + self.expansion * (reflected - centroid)\n                expanded = np.clip(expanded, func.bounds.lb, func.bounds.ub)\n                f_expanded = func(expanded)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_expanded < f_reflected:\n                    self.simplex[-1] = expanded\n                    self.values[-1] = f_expanded\n                else:\n                    self.simplex[-1] = reflected\n                    self.values[-1] = f_reflected\n            else:\n                # Contraction\n                contracted = centroid + self.contraction * (worst - centroid)\n                contracted = np.clip(contracted, func.bounds.lb, func.bounds.ub)\n                f_contracted = func(contracted)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_contracted < self.values[-1]:\n                    self.simplex[-1] = contracted\n                    self.values[-1] = f_contracted\n                else:\n                    # Shrink\n                    for i in range(1, self.dim + 1):\n                        self.simplex[i] = best + self.shrinkage * (self.simplex[i] - best)\n                        self.simplex[i] = np.clip(self.simplex[i], func.bounds.lb, func.bounds.ub)\n                        self.values[i] = func(self.simplex[i])\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n                    if self.budget <= 0:\n                        break\n\n            # Update best solution\n            best_index = np.argmin(self.values)\n            if self.values[best_index] < self.f_opt:\n                self.f_opt = self.values[best_index]\n                self.x_opt = self.simplex[best_index].copy()\n            \n            # Check for stagnation and restart based on simplex volume\n            volume = self.calculate_simplex_volume()\n            if volume < self.volume_threshold:\n                self.initialize_simplex(func) #restart\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fbf5512c-8ccc-45ea-bd66-77f193bd9f9b", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85", "14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: A covariance matrix adaptation evolution strategy (CMA-ES) with adaptive step size control and a rank-one update for exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov1=0.1, c_covmu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size or (4 + int(3 * np.log(dim)))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.c_cov1 = c_cov1\n        self.c_covmu = c_covmu\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.p_sigma = np.zeros(dim)\n        self.p_c = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        while self.budget > 0:\n            # Sample population\n            A = np.linalg.cholesky(self.C)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.m + self.sigma * A @ z.T\n            x = x.T\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            fitness = fitness[idx]\n            \n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n\n            # Update distribution parameters\n            xmean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            \n            y = x[:self.mu] - self.m\n            \n            # Update evolution path\n            self.p_sigma = (1 - self.cs) * self.p_sigma + (self.cs * (2 - self.cs))**0.5 * A @ z[idx[:self.mu]].T @ self.weights\n            \n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / self.chiN - 1))\n\n            # Update covariance matrix\n            self.p_c = (1 - self.c_cov1) * self.p_c + (self.c_cov1 * (2 - self.c_cov1))**0.5 * (xmean - self.m) / self.sigma\n            self.C = (1 - self.c_cov1 - self.c_covmu) * self.C + self.c_cov1 * np.outer(self.p_c, self.p_c)\n            \n            for k in range(self.mu):\n                 artmp = (y[k] / self.sigma).reshape(-1, 1)\n                 self.C += self.c_covmu * self.weights[k] * (artmp @ artmp.T)\n            \n            # Ensure covariance matrix is positive definite\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            \n            # Update mean\n            self.m = xmean.copy()\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "663e079b-6ed9-4714-94c4-08de71e05d3c", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, temp_init=100.0, alpha=0.99, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.alpha = alpha\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for _ in range(self.restarts):\n            x = np.random.uniform(lb, ub, size=self.dim)\n            f = func(x)\n            eval_count = 1\n\n            temp = self.temp_init\n\n            while eval_count < self.budget:\n                x_new = x + np.random.normal(0, temp**0.5, size=self.dim)\n                x_new = np.clip(x_new, lb, ub)\n                f_new = func(x_new)\n                eval_count += 1\n\n                delta_e = f_new - f\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                    x = x_new\n                    f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                temp *= self.alpha\n                if temp < 1e-5:\n                    temp = self.temp_init\n                    x = np.random.uniform(lb, ub, size=self.dim)\n                    f = func(x)\n                    eval_count += 1\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "493dc19c-6612-4869-8906-7a36fc57dd8f", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "Simulated Annealing with adaptive temperature and step size control based on the acceptance rate and recent search performance.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, alpha=0.95, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.alpha = alpha\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        eval_count = 1\n        \n        acceptance_count = 0\n        \n        while eval_count < self.budget:\n            x_new = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n            if delta_f < 0:\n                x = x_new\n                f = f_new\n                acceptance_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                probability = np.exp(-delta_f / temp)\n                if np.random.rand() < probability:\n                    x = x_new\n                    f = f_new\n                    acceptance_count += 1\n\n            # Adaptive temperature and step size\n            temp *= self.alpha\n            \n            if eval_count % 100 == 0:\n                acceptance_rate = acceptance_count / 100.0\n                if acceptance_rate > 0.6:\n                    self.step_size *= 1.1\n                elif acceptance_rate < 0.4:\n                    self.step_size *= 0.9\n                acceptance_count = 0\n\n        return self.f_opt, self.x_opt", "objective": -0.28146, "other_inf": null}
{"id": "81c2891c-0206-49c4-96dd-b331f50023fe", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "# Description: An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that adjusts the step size and covariance matrix based on the success history of previous steps, and incorporates a restart mechanism.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, mu_factor=0.25, cs=0.3, damps=1.0, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.mu = int(self.pop_size * mu_factor)\n        self.mu_weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.mu_weights /= np.sum(self.mu_weights)\n        self.m = np.zeros(dim)\n        self.P_sigma = np.zeros(dim)\n        self.P_c = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.c_sigma = (damps * (self.mu_weights[0] + self.dim / 3)) / (np.linalg.norm(self.P_sigma) ** 2 + damps) if np.linalg.norm(self.P_sigma) > 0 else cs #cs\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_weights[0] + self.dim / 3 - 1) / (self.dim + 1)) - 1) + cs\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.ccov1 = 2 / ((dim + 1.3)**2 + self.mu) if ccov1 is None else ccov1\n        self.ccovmu = min(1-self.ccov1, 2 * (self.mu - 1 + 1/self.mu_weights[0]) / ((dim+2)**2 + 2*self.mu)) if ccovmu is None else ccovmu\n        self.B = None\n        self.D = None\n        self.restart_trigger = False\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def sample_population(self, func):\n        z = np.random.randn(self.pop_size, self.dim)\n        y = self.B @ (self.D * z.T)\n        x = self.m + self.sigma * y.T\n        x = np.clip(x, self.lb, self.ub)\n        fitness = np.array([func(xi) for xi in x])\n        self.budget -= self.pop_size\n        return x, fitness\n\n    def update_distribution(self, x, fitness):\n        idx = np.argsort(fitness)\n        x_mu = x[idx[:self.mu]]\n        y_mu = (x_mu - self.m) @ self.B @ np.diag(1/self.D) / self.sigma\n        self.m = np.sum(self.mu_weights[:,None] * x_mu, axis=0)\n\n        # Cumulation\n        self.P_sigma = (1-self.c_sigma) * self.P_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.B @ y_mu.mean(axis=0))\n        hsig = (np.linalg.norm(self.P_sigma)/np.sqrt(1-(1-self.c_sigma)**(2*self.budget/self.pop_size))/self.chiN < 1.4 + 2/(self.dim+1))\n        self.P_c = (1-self.ccov1) * self.P_c + hsig * np.sqrt(self.ccov1 * (2 - self.ccov1)) * (x_mu.mean(axis=0) - self.m) / self.sigma\n\n        # Adaptation covariance matrix\n        C_temp = self.ccov1 * (self.P_c[:,None] @ self.P_c[None,:])\n        C_temp += self.ccovmu * (x_mu - self.m).T @ np.diag(self.mu_weights) @ (x_mu - self.m) / self.sigma**2\n        self.C = (1-self.ccov1-self.ccovmu) * self.C + C_temp\n\n        self.sigma *= np.exp((self.c_sigma/self.damps) * (np.linalg.norm(self.P_sigma)/self.chiN - 1))\n\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))\n\n    def check_restart(self, f_best_list, tolerance=1e-12, patience=1000):\n            if len(f_best_list) > patience:\n                recent_values = f_best_list[-patience:]\n                if np.std(recent_values) < tolerance:\n                    return True\n            return False\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim) # Initialize mean vector\n        self.B, self.D = np.linalg.eig(self.C)\n        self.D = np.sqrt(np.maximum(self.D, 1e-16)) # Ensure positivity\n        \n        f_best_list = []\n        generation = 0\n        \n        while self.budget > 0:\n            x, fitness = self.sample_population(func)\n            \n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = x[best_idx].copy()\n                \n            f_best_list.append(self.f_opt)\n\n            self.update_distribution(x, fitness)\n\n            if self.check_restart(f_best_list):\n                self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.sigma = 0.5\n                self.P_sigma = np.zeros(self.dim)\n                self.P_c = np.zeros(self.dim)\n                self.C = np.eye(self.dim)\n                self.B, self.D = np.linalg.eig(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16))\n                f_best_list = []\n                \n\n            generation+=1\n            \n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "898a3882-d0bc-4d36-a215-59ed9dc1594c", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A population-based algorithm that iteratively refines candidate solutions by probabilistically shifting the population towards promising regions and exploring new areas based on population variance.", "code": "import numpy as np\n\nclass AdaptiveScatterSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, subset_size=10, diversification_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.subset_size = subset_size\n        self.diversification_rate = diversification_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def refine_subset(self, func):\n        indices = np.argsort(self.fitness)[:self.subset_size]\n        subset = self.population[indices]\n        centroid = np.mean(subset, axis=0)\n\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            \n            # Move towards centroid with probability, diversify otherwise\n            if np.random.rand() > self.diversification_rate:\n                direction = centroid - self.population[i]\n                step_size = np.random.rand()  # Adaptive step size\n                new_x = self.population[i] + step_size * direction\n            else:\n                new_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            self.evals += 1\n\n            if new_f < self.fitness[i]:\n                self.population[i] = new_x\n                self.fitness[i] = new_f\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            self.refine_subset(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.29236, "other_inf": null}
{"id": "3e84a821-9999-4e7a-8eed-c10eabbeab5e", "parents": ["243d013f-c3f7-47ab-b3ad-51547b5b8efd", "243d013f-c3f7-47ab-b3ad-51547b5b8efd"], "algorithm": "Simulated Annealing with adaptive temperature schedule and random restarts to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n        temperature = self.initial_temp\n\n        while eval_count < self.budget:\n            x_new = self.x_opt + np.random.normal(0, temperature/self.initial_temp, size=self.dim)\n            x_new = np.clip(x_new, self.lb, self.ub)\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_e = f_new - self.f_opt\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temperature):\n                self.x_opt = x_new\n                self.f_opt = f_new\n\n            temperature *= self.cooling_rate\n\n            if np.random.rand() < self.restart_prob:\n                self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.f_opt = func(self.x_opt)\n                eval_count += 1\n                temperature = self.initial_temp\n        return self.f_opt, self.x_opt", "objective": -0.2839, "other_inf": null}
{"id": "39d25583-e69c-46d2-ad2f-90f8c11ebc6a", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A covariance matrix adaptation evolution strategy (CMA-ES) with a budget-aware adaptation of the population size, dynamically adjusting it based on the remaining budget and recent performance, and restarting when stagnation is detected.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=None, restart_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.mu = 0.5 # Proportion of top individuals to use for recombination\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.pop_size = self.initial_pop_size\n        self.mean = np.zeros(self.dim)\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu * 2) / (self.dim + 2)**2  # Learning rate for sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4) # Learning rate for C\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma # Damping for sigma\n        self.mu_eff = np.sum(self.mu)**2 / np.sum(self.mu**2)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.cmu = min(1 - self.c1, 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        self.weights = np.log(self.mu+1/2) - np.log(np.arange(1, int(self.mu+1)))\n        self.weights = self.weights / np.sum(self.weights)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_threshold = restart_threshold\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        generation = 0\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            population = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            population = np.clip(population, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Sort population\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            population = population[indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0].copy()\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n            else:\n                self.stagnation_counter += 1\n\n            # Recombination\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * population[:int(self.mu)], axis=0)\n\n            # Update evolution paths\n            B = np.linalg.cholesky(self.C)\n            z_mean = (self.mean - mean_old) / self.sigma @ np.linalg.inv(B).T\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_mean\n            \n            if np.sum(self.ps**2) / self.dim < 2 + 4/(self.dim + 1):\n                self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.mean - mean_old) / self.sigma\n                hsig = 1\n            else:\n                self.pc = (1 - self.c_c) * self.pc\n                hsig = 0\n\n            # Update covariance matrix\n            dC = np.sum(self.weights[:, None] * (population[:int(self.mu)] - mean_old) * (population[:int(self.mu)] - mean_old), axis=0)\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] * self.pc)\n            self.C += self.cmu * (population[:int(self.mu)] - mean_old).T @ np.diag(self.weights) @ (population[:int(self.mu)] - mean_old)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Dynamic Population Size Adjustment\n            remaining_budget_ratio = self.budget / 10000 # Assuming initial budget is 10000\n            improvement_ratio = (generation - self.last_improvement) / (generation + 1e-9)\n\n            if remaining_budget_ratio < 0.5 and improvement_ratio < 0.2:\n                self.pop_size = max(4, int(self.pop_size * 0.8))\n            elif remaining_budget_ratio > 0.75 and improvement_ratio > 0.5:\n                self.pop_size = min(self.initial_pop_size, int(self.pop_size * 1.2))\n            \n            self.pop_size = int(min(self.pop_size, self.budget))\n            \n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.restart_threshold:\n                self.mean = np.zeros(self.dim)\n                self.sigma = 0.5\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                self.last_improvement = generation\n            \n            generation += 1\n        return self.f_opt, self.x_opt", "objective": -0.14521, "other_inf": null}
{"id": "137d9a07-0ec0-4f54-8667-75ec1b71d11d", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: An enhanced differential evolution algorithm incorporating a restart mechanism and dynamic parameter adaptation based on population diversity to escape local optima and maintain exploration.\n# Code:\n```", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.restart_trigger = restart_trigger  # Percentage of budget used before considering a restart\n        self.initial_F = F\n        self.initial_CR = CR\n        self.restart_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        initial_budget = self.budget + self.pop_size # to compute restart threshold\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Adapt parameters based on population diversity\n            diversity = np.std(population)\n            self.F = np.clip(self.initial_F + np.random.normal(0, 0.01 * diversity), 0.1, 0.9)\n            self.CR = np.clip(self.initial_CR + np.random.normal(0, 0.01 * diversity), 0.1, 0.9)\n\n            # Restart mechanism\n            if (initial_budget - self.budget) / initial_budget > self.restart_trigger:\n                if diversity < 0.01:  # If population has converged\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                    self.F = self.initial_F  # Reset parameters\n                    self.CR = self.initial_CR\n                    self.restart_count += 1\n        return self.f_opt, self.x_opt", "objective": -0.74433, "other_inf": null}
{"id": "7e523626-4b8d-4a91-a8cf-129c05303a9d", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is used to adapt the search distribution and iteratively find the optimum.}\n# Code: \n```python\nimport numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        es = cma.PureCMAES(mean=np.zeros(self.dim), sigma=self.sigma,\n                           bounds=[self.lb, self.ub],\n                           inopts={'maxfevals': self.budget, 'verbose': -9", "code": "import numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        es = cma.PureCMAES(mean=np.zeros(self.dim), sigma=self.sigma,\n                           bounds=[self.lb, self.ub],\n                           inopts={'maxfevals': self.budget, 'verbose': -9})  # Disable verbose output\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while es.result.fbest == None or es.result.fbest > self.f_opt and es.countevals() < self.budget :\n             solutions = []\n             for candidate in es.ask():\n                value = func(candidate)\n                solutions.append(value)\n                if value < self.f_opt:\n                    self.f_opt = value\n                    self.x_opt = candidate\n             es.tell(es.ask(), solutions)  # pass the objective function values to update the distribution\n\n        if es.result.fbest < self.f_opt:\n             self.f_opt = es.result.fbest\n             self.x_opt = es.result.xbest\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "2839a343-78bf-4e41-b59d-436bb5251024", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: An adaptive Differential Evolution algorithm using a CMA-ES-inspired step size adaptation and a simplified restart strategy based on fitness variance.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.7, c_sigma=0.1, restart_threshold=1e-8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.c_sigma = c_sigma\n        self.sigma = 0.1  # Initial step size\n        self.restart_threshold = restart_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        generation = 0\n\n        while self.budget > 0:\n            new_population = np.zeros((self.pop_size, self.dim))\n            \n            # Mutation and Crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Selection\n            improved = new_fitness < fitness\n            fitness[improved] = new_fitness[improved]\n            population[improved] = new_population[improved].copy()\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n\n            # Step size adaptation (CMA-ES inspired)\n            success_ratio = np.sum(improved) / self.pop_size\n            self.sigma *= np.exp(self.c_sigma * (success_ratio - 0.2))  # Simple rule\n\n            # Restart based on fitness variance\n            if np.var(fitness) < self.restart_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n                self.sigma = 0.1 #reset step size\n                \n            generation += 1\n        return self.f_opt, self.x_opt", "objective": -0.53102, "other_inf": null}
{"id": "f45e4133-0311-489a-b572-a857723814d5", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: A self-adaptive differential evolution algorithm with a covariance matrix adaptation strategy to guide the search direction and step size.\n# Code:\n```", "code": "import numpy as np\n\nclass SelfAdaptiveCMAESDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.7, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))  # reasonable default\n        else:\n            self.pop_size = pop_size\n        if mu is None:\n            self.mu = self.pop_size // 2\n        else:\n            self.mu = mu\n\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # evolution path for C\n        self.ps = np.zeros(self.dim) # evolution path for sigma\n        self.sigma = 0.3 # overall standard deviation\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.CR # damping for sigma\n        self.cc = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.cs = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.cmu = min(1 - self.c1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            # Generate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            population = self.x_opt + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Selection and update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n            \n            # Sort population and fitness\n            indices = np.argsort(fitness)\n            population = population[indices]\n            fitness = fitness[indices]\n\n            # Weighted recombination\n            weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n            weights /= np.sum(weights)\n\n            y = population[:self.mu] - self.x_opt\n            z = np.dot(y.T, weights)\n\n            # Update evolution paths\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * z / self.sigma\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * z\n\n            # Update covariance matrix\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * np.outer(self.pc, self.pc)\n            self.C += self.cmu * np.dot((weights * y).T, y) / self.sigma**2\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "3bba9930-948f-48e3-a50b-81e7d30501a4", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A hybrid algorithm combining a simplified Differential Evolution (DE) with a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for global exploration and exploitation, respectively, switching between them based on performance.}\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport cma\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.7, cma_sigma=0.5, switch_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.cma_sigma = cma_sigma\n        self.switch_interval = switch_interval\n        self.de_phase = True\n        self.cma_es = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def de_step(self, func):\n        new_population = []\n        new_fitness = []\n\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                new_population.append(self.population[i])\n                new_fitness.append(self.fitness[i])\n                continue\n\n            mutant = self.mutate(self.population, i)\n            trial = self.crossover(mutant, self.population[i])\n            f = func(trial)\n            self.evals += 1\n\n            if f < self.fitness[i]:\n                new_population.append(trial)\n                new_fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n            else:\n                new_population.append(self.population[i])\n                new_fitness.append(self.fitness[i])\n        \n        self.population = np.array(new_population)\n        self.fitness = np.array(new_fitness)\n\n    def cma_es_step(self, func):\n        if self.cma_es is None:\n            self.cma_es = cma.optimization_tools.ES(self.x_opt, self.cma_sigma,\n                                                     {'bounds': [self.lb, self.ub], 'verbose': -9", "code": "import numpy as np\nfrom scipy.optimize import minimize\nimport cma\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.7, cma_sigma=0.5, switch_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.cma_sigma = cma_sigma\n        self.switch_interval = switch_interval\n        self.de_phase = True\n        self.cma_es = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def de_step(self, func):\n        new_population = []\n        new_fitness = []\n\n        for i in range(self.pop_size):\n            if self.evals >= self.budget:\n                new_population.append(self.population[i])\n                new_fitness.append(self.fitness[i])\n                continue\n\n            mutant = self.mutate(self.population, i)\n            trial = self.crossover(mutant, self.population[i])\n            f = func(trial)\n            self.evals += 1\n\n            if f < self.fitness[i]:\n                new_population.append(trial)\n                new_fitness.append(f)\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n            else:\n                new_population.append(self.population[i])\n                new_fitness.append(self.fitness[i])\n        \n        self.population = np.array(new_population)\n        self.fitness = np.array(new_fitness)\n\n    def cma_es_step(self, func):\n        if self.cma_es is None:\n            self.cma_es = cma.optimization_tools.ES(self.x_opt, self.cma_sigma,\n                                                     {'bounds': [self.lb, self.ub], 'verbose': -9})\n\n        solutions = []\n        for _ in range(self.pop_size):\n            if self.evals >= self.budget:\n                break\n            x = self.cma_es.ask()\n            f = func(x)\n            self.evals += 1\n            solutions.append((x,f))\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n        \n        if solutions:\n           self.cma_es.tell(solutions)\n           self.cma_es.logger.add()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        iteration = 0\n        while self.evals < self.budget:\n            iteration += 1\n            if self.de_phase:\n                self.de_step(func)\n            else:\n                self.cma_es_step(func)\n\n            if iteration % self.switch_interval == 0:\n                self.de_phase = not self.de_phase\n                if not self.de_phase:\n                  self.cma_es = None # Reset CMA-ES for a fresh start\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "6999e26e-f964-49ec-b259-ab033449cdec", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with increased exploration and a restart mechanism for stagnation, adapting the step size and covariance matrix to efficiently explore the search space.}\n# Code: \n```python\nimport numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, popsize=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        \n        for r in range(self.restarts):\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            es = cma.PureCMAES(x0, self.sigma0, \n                               {'bounds': [self.lb, self.ub], \n                                'popsize': self.popsize,\n                                'maxfevals': (self.budget // self.restarts) if r < self.restarts -1 else (self.budget - evals),\n                                'verbose': -9", "code": "import numpy as np\nimport cma\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, popsize=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        \n        for r in range(self.restarts):\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            es = cma.PureCMAES(x0, self.sigma0, \n                               {'bounds': [self.lb, self.ub], \n                                'popsize': self.popsize,\n                                'maxfevals': (self.budget // self.restarts) if r < self.restarts -1 else (self.budget - evals),\n                                'verbose': -9})\n\n            while es.result is None and evals < self.budget:\n                solutions = []\n                for i in range(es.population_size):\n                    x = es.ask()\n                    f = func(x)\n                    solutions.append((x, f))\n                    evals += 1\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n                es.tell(solutions)\n                \n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "e6da08c5-a0b7-414a-942e-28f60295676e", "parents": ["851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A modified Differential Evolution with dynamic population size, adaptive mutation and crossover, and a restart mechanism to enhance exploration.", "code": "import numpy as np\n\nclass DynamicDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.7, CR=0.8, reduction_factor=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.initial_pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.reduction_factor = reduction_factor\n        self.restart_prob = restart_prob\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n\n                mutant = self.mutate(self.population, i)\n                trial = self.crossover(mutant, self.population[i])\n                f = func(trial)\n                self.evals += 1\n\n                if f < self.fitness[i]:\n                    new_population.append(trial)\n                    new_fitness.append(f)\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    self.F = np.clip(self.F * np.random.normal(1, 0.1), 0.1, 0.9)\n                    self.CR = np.clip(self.CR * np.random.normal(1, 0.1), 0.1, 0.9)\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n\n            if np.random.rand() < self.restart_prob:\n                self.pop_size = self.initial_pop_size\n                self.initialize_population(func)\n            elif self.evals < self.budget // 2 and len(new_population) < self.pop_size // 4:\n                self.pop_size = int(self.pop_size * self.reduction_factor)\n                if self.pop_size < 5:\n                  self.pop_size = 5\n\n        return self.f_opt, self.x_opt", "objective": -0.36713, "other_inf": null}
{"id": "1d81f591-771c-4b3e-a318-de2e5755c30f", "parents": ["14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "'maxfev': min(self.budget // 2, 500)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.4, c2=1.4, stagnation_threshold=500, nm_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.nm_freq = nm_freq\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        personal_best_positions = particles.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = particles[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n        generation = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - particles[i]) + \\\n                                self.c2 * r2 * (global_best_position - particles[i])\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                new_fitness = func(particles[i])\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n                \n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = particles[i].copy()\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = particles[i].copy()\n                    global_best_position = particles[i].copy()\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n            if self.budget <= 0:\n                break\n            # Nelder-Mead local search\n            if generation > 0 and generation % self.nm_freq == 0:\n                # Apply Nelder-Mead around the global best\n                nm_result = minimize(func, self.x_opt, method='Nelder-Mead',\n                                    bounds=np.stack((func.bounds.lb * np.ones(self.dim), func.bounds.ub * np.ones(self.dim)), axis=-1),\n                                    options={'maxfev': min(self.budget // 2, 500)})\n                \n                if nm_result.fun < self.f_opt:\n                    self.f_opt = nm_result.fun\n                    self.x_opt = nm_result.x.copy()\n                    global_best_position = nm_result.x.copy()\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                self.budget -= nm_result.nfev\n\n            # Stagnation check and adjust parameters\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Perturb particles to escape local optima\n                for i in range(self.pop_size):\n                    particles[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in particles])\n                self.budget -= self.pop_size\n                \n                personal_best_positions = particles.copy()\n                personal_best_fitness = fitness.copy()\n\n                global_best_index = np.argmin(fitness)\n                global_best_position = particles[global_best_index].copy()\n                if fitness[global_best_index] < self.f_opt:\n                    self.f_opt = fitness[global_best_index]\n                    self.x_opt = global_best_position.copy()\n\n                self.stagnation_counter = 0  # Reset counter\n            generation += 1\n        return self.f_opt, self.x_opt", "objective": -0.50992, "other_inf": null}
{"id": "b412995b-f468-4b8e-af6d-bfc37afc4990", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "14b1fe56-3093-4a53-9c2c-e31902aaad85"], "algorithm": "# Description: An algorithm employing a Gaussian process surrogate model to guide the search, balancing exploration and exploitation through an acquisition function that favors regions with high potential for improvement.\n# Code:\n```", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.Y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x, gp, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - xi * sigma\n\n    def __call__(self, func):\n\n        # Initial sampling\n        X_initial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        Y_initial = np.array([func(x) for x in X_initial])\n        self.budget -= self.n_initial_samples\n\n        best_index = np.argmin(Y_initial)\n        self.f_opt = Y_initial[best_index]\n        self.x_opt = X_initial[best_index].copy()\n        self.X = X_initial\n        self.Y = Y_initial\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit Gaussian process\n            self.gp.fit(self.X, self.Y)\n\n            # Find next point to evaluate by maximizing the acquisition function\n            x_next = self.find_next_point(func)\n\n            # Evaluate the function at the new point\n            y_next = func(x_next)\n            self.budget -= 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.Y = np.append(self.Y, y_next)\n\n            # Update best solution\n            if y_next < self.f_opt:\n                self.f_opt = y_next\n                self.x_opt = x_next.copy()\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self, func, n_sample=1000):\n        \"\"\"\n        Find the next point to sample by maximizing the acquisition function.\n        \"\"\"\n        X_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(n_sample, self.dim))\n        acq_values = np.array([self.acquisition_function(x, self.gp) for x in X_sample])\n        \n        # Return best found point\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "ede00b5a-2100-41ef-a8da-42f94ab2d089", "parents": ["137d9a07-0ec0-4f54-8667-75ec1b71d11d", "137d9a07-0ec0-4f54-8667-75ec1b71d11d"], "algorithm": "# Description: A hybrid algorithm combining particle swarm optimization with a local search strategy, adaptively adjusting inertia and exploration to balance global exploration and local exploitation.\n# Code:\n```", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.local_search_prob = local_search_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n        \n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n                \n                # Local search with a probability\n                if np.random.rand() < self.local_search_prob:\n                    # Perform a small random perturbation\n                    perturbation = np.random.normal(0, 0.05, size=self.dim)\n                    local_point = population[i] + perturbation\n                    local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                    \n                    local_fitness = func(local_point)\n                    self.budget -= 1\n                    if local_fitness < fitness[i] and self.budget > 0:\n                        fitness[i] = local_fitness\n                        population[i] = local_point.copy()\n                        \n            # Evaluate updated population\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n            # Update personal best positions\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n            \n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[global_best_index]\n                global_best_position = personal_best_positions[global_best_index].copy()\n                self.x_opt = global_best_position.copy()\n\n            # Adaptive inertia weight adjustment\n            self.w = 0.9 - (0.5 / self.budget)\n\n        return self.f_opt, self.x_opt", "objective": -0.0, "other_inf": null}
{"id": "0d1af72f-78a5-442b-b403-b57cdf43c79e", "parents": ["60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5", "60ae84ff-3bb2-4f1d-8dfd-24a50de13cd5"], "algorithm": "# Description: A covariance matrix adaptation evolution strategy (CMA-ES) that adapts the mutation distribution by learning a covariance matrix to efficiently explore the search space.\n# Code:\n```", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.mu / (self.dim + (np.sqrt(self.mu) / self.sigma)))**2\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim)/(self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            B = np.linalg.cholesky(self.C) # Cholesky decomposition\n            x = self.m + self.sigma * z @ B.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            x = x[idx]\n            fitness = fitness[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0].copy()\n            \n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path for covariance matrix\n            z_mean = np.mean(z[idx[:self.mu]], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (B @ z_mean)\n            \n            # Adapt step size\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n\n            # Update evolution path for mean\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.pc, self.pc)\n            for i in range(self.mu):\n                self.C += self.c_mu * self.weights[i] * np.outer((x[i] - m_old) / self.sigma, (x[i] - m_old) / self.sigma)\n            \n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Keep covariance matrix positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "objective": -0.3238, "other_inf": null}
{"id": "1ac2f4b0-8bd3-451a-9fde-9ab6107bbf0b", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A population-based algorithm that uses a combination of Gaussian mutation, opposition-based learning, and a restart strategy to explore and exploit the search space effectively.", "code": "import numpy as np\n\nclass GOBLRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_rate=0.3, restart_threshold=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.exploration_rate = exploration_rate\n        self.restart_threshold = restart_threshold\n        self.restart_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def gaussian_mutation(self, individual):\n        mutation = np.random.normal(0, self.exploration_rate * (self.ub - self.lb), size=self.dim)\n        mutated_individual = np.clip(individual + mutation, self.lb, self.ub)\n        return mutated_individual\n\n    def opposition_based_learning(self, individual):\n        opposition = self.lb + self.ub - individual\n        return opposition\n\n    def restart_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals += self.pop_size\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n        self.restart_count += 1\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  new_population.append(self.population[i])\n                  new_fitness.append(self.fitness[i])\n                  continue\n                mutated_individual = self.gaussian_mutation(self.population[i])\n                opposition_individual = self.opposition_based_learning(self.population[i])\n\n                f_mutated = func(mutated_individual)\n                self.evals += 1\n                if self.evals >= self.budget:\n                  new_population.append(self.population[i])\n                  new_fitness.append(self.fitness[i])\n                  continue\n                f_opposition = func(opposition_individual)\n                self.evals += 1\n                \n                if f_mutated < self.fitness[i] and f_mutated <= f_opposition:\n                    new_population.append(mutated_individual)\n                    new_fitness.append(f_mutated)\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_individual\n                elif f_opposition < self.fitness[i]:\n                    new_population.append(opposition_individual)\n                    new_fitness.append(f_opposition)\n                    if f_opposition < self.f_opt:\n                        self.f_opt = f_opposition\n                        self.x_opt = opposition_individual\n                else:\n                    new_population.append(self.population[i])\n                    new_fitness.append(self.fitness[i])\n\n            self.population = np.array(new_population)\n            self.fitness = np.array(new_fitness)\n            \n            if np.random.rand() < self.restart_threshold:\n                if self.evals < self.budget:\n                    self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "objective": -0.28636, "other_inf": null}
{"id": "68a15d4f-5516-4729-881d-523a44938b67", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "A Gaussian Process based optimization algorithm that adaptively samples new points based on the predicted mean and variance of the Gaussian Process model, balancing exploration and exploitation using an acquisition function.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\nfrom scipy.stats import norm\n\nclass GP_Optimizer:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel='RBF'):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n        self.X = None\n        self.y = None\n        self.gp = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n        if kernel == 'RBF':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))\n        elif kernel == 'Matern':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n        else:\n            raise ValueError(\"Invalid kernel type. Choose 'RBF' or 'Matern'.\")\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.evals = self.n_initial\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n        self.gp.fit(self.X, self.y)\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        if sigma == 0:\n            return 0\n        z = (self.f_opt - mu) / sigma\n        return (self.f_opt - mu) * norm.cdf(z) + sigma * norm.pdf(z)\n\n    def find_next_point(self, func, num_restarts=20):\n        best_x = None\n        best_acq = -np.inf\n        for _ in range(num_restarts):\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n            res = minimize(lambda x: -self.acquisition_function(x), x0, bounds=[(self.lb, self.ub)] * self.dim, method='L-BFGS-B')\n            if -res.fun > best_acq:\n                best_acq = -res.fun\n                best_x = res.x\n        return best_x\n\n    def __call__(self, func):\n        self.initialize(func)\n        while self.evals < self.budget:\n            x_next = self.find_next_point(func)\n            f_next = func(x_next)\n            self.evals += 1\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            self.gp.fit(self.X, self.y)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "fff489dd-358f-47ed-8e46-945a37be81d8", "parents": ["137d9a07-0ec0-4f54-8667-75ec1b71d11d", "137d9a07-0ec0-4f54-8667-75ec1b71d11d"], "algorithm": "# Description: A population-based search algorithm that uses a Voronoi decomposition to identify promising regions for intensified sampling and exploration, dynamically adjusting Voronoi cell sizes based on fitness landscape characteristics.\n# Code: \n```", "code": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\nclass VoronoiOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_weight=0.1, voronoi_update_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_weight = exploration_weight\n        self.voronoi_update_frequency = voronoi_update_frequency\n        self.points = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.vor = None\n        self.cell_volumes = None\n\n    def __call__(self, func):\n\n        # Initialize population\n        self.points = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.points])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.points[best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            \n            # Voronoi decomposition and cell volume calculation\n            try:\n                self.vor = Voronoi(self.points)\n                self.cell_volumes = self._calculate_cell_volumes()\n            except Exception as e:\n                # Handle potential issues with Voronoi calculation (e.g., all points collinear)\n                # If voronoi calculation fails, default to random sampling\n                new_point = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(new_point)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_point.copy()\n                continue\n            \n            # Sample new points based on Voronoi cell volumes and fitness\n            probabilities = self.cell_volumes * np.exp(-self.exploration_weight * self.fitness)\n            probabilities /= np.sum(probabilities)\n\n            new_points = np.zeros((self.pop_size, self.dim))\n            new_fitness = np.zeros(self.pop_size)\n            \n            for i in range(self.pop_size):\n                chosen_cell_index = np.random.choice(range(self.pop_size), p=probabilities)\n                \n                # Sample within the chosen Voronoi cell. If cell is unbounded, fallback to global sampling.\n                if np.isinf(self.cell_volumes[chosen_cell_index]):\n                    new_point = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                else:\n                    center = self.points[chosen_cell_index]\n                    # Sample near the center of the Voronoi cell\n                    new_point = np.random.normal(center, scale=np.sqrt(self.cell_volumes[chosen_cell_index]) / self.dim, size=self.dim)\n                    new_point = np.clip(new_point, func.bounds.lb, func.bounds.ub)\n\n                new_points[i] = new_point\n                new_fitness[i] = func(new_point)\n                self.budget -= 1\n\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_point.copy()\n\n\n            # Update population: Replace worst performing points with new points\n            worst_indices = np.argsort(self.fitness)[-self.pop_size // 2:]  # Replace half the population\n            self.points[worst_indices] = new_points[:self.pop_size // 2]\n            self.fitness[worst_indices] = new_fitness[:self.pop_size // 2]\n\n\n            # Periodically update exploration weight to balance exploration and exploitation\n            if iteration % self.voronoi_update_frequency == 0:\n                self.exploration_weight = np.clip(self.exploration_weight * (1 - 0.05), 0.01, 0.5) # Gradually decrease exploration\n\n        return self.f_opt, self.x_opt\n\n    def _calculate_cell_volumes(self):\n        \"\"\"Calculates the volume of each Voronoi cell. Uses a simple approximation.\"\"\"\n        volumes = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            if self.vor.regions[self.vor.point_region[i]]:\n                vertices = self.vor.vertices[self.vor.regions[self.vor.point_region[i]]]\n                # Approximate volume by the average distance to the vertices\n                if vertices.shape[0] > 0:\n                    distances = np.linalg.norm(vertices - self.points[i], axis=1)\n                    volumes[i] = np.mean(distances)\n                else:\n                    volumes[i] = np.inf #Unbounded region\n            else:\n                volumes[i] = np.inf  # Unbounded region.\n\n        return self.f_opt, self.x_opt", "objective": -0.29039, "other_inf": null}
{"id": "1cd093c4-9321-4525-bf6e-0e3207942043", "parents": ["137d9a07-0ec0-4f54-8667-75ec1b71d11d", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "'maxfun': min(self.budget - self.evals, 50)", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.evals = 0\n        self.local_search_prob = local_search_prob\n\n    def initialize_particles(self, func):\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.array([func(x) for x in self.particles])\n        self.evals += self.pop_size\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n\n    def update_particle(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        # Update velocity\n        self.velocities[i] = (self.w * self.velocities[i]\n                              + self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i])\n                              + self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n        # Clip velocities (optional, but can help with exploration)\n        # self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n\n        # Update position\n        self.particles[i] = self.particles[i] + self.velocities[i]\n        self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n        # Evaluate fitness\n        fitness = func(self.particles[i])\n        self.evals += 1\n\n        # Update personal best\n        if fitness < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = fitness\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            # Update global best\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.particles[i].copy()\n\n    def local_search(self, func, x0):\n        bounds = [(self.lb, self.ub)] * self.dim\n        res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(self.budget - self.evals, 50)})\n        self.evals += res.nfev\n        return res.fun, res.x\n\n    def __call__(self, func):\n        self.initialize_particles(func)\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n                if np.random.rand() < self.local_search_prob:\n                    f, x = self.local_search(func, self.particles[i].copy())\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = x.copy()\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = x.copy()\n                        self.particles[i] = x.copy()\n                else:\n                    self.update_particle(i, func)\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n        return self.f_opt, self.x_opt", "objective": Infinity, "other_inf": null}
{"id": "c74c7277-a48c-4fed-87d0-9c652d5b2806", "parents": ["851876e6-2776-4345-966a-ecfb1e540613", "851876e6-2776-4345-966a-ecfb1e540613"], "algorithm": "An adaptive sampling strategy, where the sampling distribution is iteratively updated based on the function values of the samples, concentrating on promising regions while maintaining diversity through a global search component.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass AdaptiveSampling:\n    def __init__(self, budget=10000, dim=10, initial_samples=100, adaptation_rate=0.1, exploration_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_samples = initial_samples\n        self.adaptation_rate = adaptation_rate\n        self.exploration_prob = exploration_prob\n        self.means = np.zeros(dim)\n        self.stddevs = np.ones(dim) * 2.5  # Initialize with a relatively large standard deviation\n\n    def initialize_sampling(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.initial_samples, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.initial_samples\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.means = np.mean(self.population, axis=0)\n        self.stddevs = np.std(self.population, axis=0)\n\n    def sample(self):\n        if np.random.rand() < self.exploration_prob:\n            return np.random.uniform(self.lb, self.ub, size=self.dim)\n        else:\n            sample = np.random.normal(self.means, self.stddevs, size=self.dim)\n            return np.clip(sample, self.lb, self.ub)\n\n    def update_distribution(self, x, f):\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n            # Update means and stddevs based on the new best point\n            new_means = (1 - self.adaptation_rate) * self.means + self.adaptation_rate * x\n            new_stddevs = (1 - self.adaptation_rate) * self.stddevs + self.adaptation_rate * np.abs(x - self.means)\n\n            self.means = new_means\n            self.stddevs = np.maximum(new_stddevs, 0.1)  # Ensure stddevs don't go to zero\n\n\n    def __call__(self, func):\n        self.initialize_sampling(func)\n\n        while self.evals < self.budget:\n            x = self.sample()\n            f = func(x)\n            self.evals += 1\n            self.update_distribution(x, f)\n\n        return self.f_opt, self.x_opt", "objective": -0.30439, "other_inf": null}
