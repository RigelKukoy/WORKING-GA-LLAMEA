{"id": "05ce4824-e555-4bf6-801f-7759d32074c6", "fitness": 0.4829797893808756, "name": "HybridOptimizer", "description": "A population-based algorithm that combines elements of particle swarm optimization and differential evolution with a self-adaptive strategy for parameter control.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.archive_size = int(pop_size * 0.2)  # Archive size is 20% of population size\n        self.archive = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness values\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness value\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Apply mutation using Differential Evolution\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    # ensure velocity remains within a reasonable range\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Boundary handling\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n            \n                population[i] = new_position\n\n                # Update archive (using global_best_position as a candidate for diversity)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())  # Append a copy\n                else:\n                    # Replace a random element in the archive\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = global_best_position.copy()\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.budget / (self.budget + self.pop_size))\n\n            # Early stopping criterion (example: if no improvement for a certain number of iterations)\n            if self.budget <= 0:\n                break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridOptimizer scored 0.483 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization and differential evolution with a self-adaptive strategy for parameter control.\n# Code:\n```python\nimport numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.archive_size = int(pop_size * 0.2)  # Archive size is 20% of population size\n        self.archive = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness values\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness value\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Apply mutation using Differential Evolution\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    # ensure velocity remains within a reasonable range\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                # Update position\n                new_position = population[i] + velocities[i]\n\n                # Boundary handling\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n            \n                population[i] = new_position\n\n                # Update archive (using global_best_position as a candidate for diversity)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())  # Append a copy\n                else:\n                    # Replace a random element in the archive\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = global_best_position.copy()\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.budget / (self.budget + self.pop_size))\n\n            # Early stopping criterion (example: if no improvement for a certain number of iterations)\n            if self.budget <= 0:\n                break\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.16777974090932857, 0.44607926983535795, 0.4792324532527785, 0.8875364557502098, 0.30156208133443574, 0.5544967172182416, 0.3380081002206753, 0.4795225534316976, 0.5115502987129945, 0.2325986813119102, 0.8323278307097236, 0.9987807182179996, 0.24467852338724738, 0.25777676036203845, 0.807115804860483, 0.5705360228827479, 0.3923904040153764, 0.3785462523408146, 0.2533199783486162, 0.5257571405148359], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "210371e5-e605-48aa-8dd9-4ee62c7bab21", "fitness": 0.6100042599514683, "name": "AdaptiveShrinkingDE", "description": "An adaptive Differential Evolution algorithm with a population size that shrinks over time and a mutation strategy that adapts based on success rate.", "code": "import numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor  # Reduce population size each generation\n        self.archive_size = int(self.population_size * 0.2) # 20% of the population size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9) # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1) # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy() # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5) # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveShrinkingDE scored 0.610 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm with a population size that shrinks over time and a mutation strategy that adapts based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor  # Reduce population size each generation\n        self.archive_size = int(self.population_size * 0.2) # 20% of the population size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9) # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1) # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy() # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5) # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19537060451022992, 0.32124220534024606, 0.7708366388282866, 0.8729148100167607, 0.6756560559747387, 0.8479688017497767, 0.33156695561040084, 0.5932884395031892, 0.7456381796619378, 0.41653188293828647, 0.857279129739736, 0.999088359809699, 0.5520210146303279, 0.3064772329931028, 0.9261805865056285, 0.8208416539832494, 0.40944659960215835, 0.8763310517340474, 0.18619602278522074, 0.4952089731123418], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "ce5826c6-edf2-4e09-b25b-710ff46edd3f", "fitness": 0.0, "name": "AdaptiveVelocityOptimizer", "description": "Population-based algorithm with velocity updates, adaptive exploration rate, and local search.", "code": "import numpy as np\n\nclass AdaptiveVelocityOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_radius = local_search_radius  # Radius for local search around the best particle\n        self.exploration_rate = 0.5  # Initial exploration rate, adaptively reduced\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) / 10, abs(ub - lb) / 10, size=(self.pop_size, self.dim))  # Initialize velocities with a fraction of the search range\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_index = np.argmin(fitness)\n        self.global_best_position = self.population[self.global_best_index].copy()\n        self.global_best_fitness = fitness[self.global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions - self.population)\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population)\n            self.velocities = self.inertia * self.velocities + cognitive_component + social_component\n\n            # Apply velocity clipping\n            v_max = abs(ub - lb) / 2  # Clip velocities to half the search range\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            new_population = self.population + self.velocities\n\n            # Apply boundary handling (clip or bounce back)\n            new_population = np.clip(new_population, lb, ub)\n            \n            # Apply exploration with a probability\n            exploration_mask = np.random.rand(self.pop_size, self.dim) < self.exploration_rate\n            new_population[exploration_mask] = np.random.uniform(lb, ub, size=new_population[exploration_mask].shape)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal and global bests\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness[i]\n                    self.personal_best_positions[i] = new_population[i].copy()\n\n            new_global_best_index = np.argmin(new_fitness)\n            if new_fitness[new_global_best_index] < self.global_best_fitness:\n                self.global_best_fitness = new_fitness[new_global_best_index]\n                self.global_best_position = new_population[new_global_best_index].copy()\n                \n            # Local search around the best particle\n            if self.budget > 0 and self.local_search_radius > 0:\n                local_point = self.global_best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                local_point = np.clip(local_point, lb, ub)  # Ensure local point is within bounds\n                local_fitness = func(local_point)\n                self.budget -= 1\n                if local_fitness < self.global_best_fitness:\n                    self.global_best_fitness = local_fitness\n                    self.global_best_position = local_point.copy()\n\n            # Update population\n            self.population = new_population\n\n            # Adaptive Exploration Rate Update\n            self.exploration_rate *= 0.99  # Gradually reduce exploration\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (15,) and arg 1 with shape (2,).", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with velocity updates, adaptive exploration rate, and local search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveVelocityOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.local_search_radius = local_search_radius  # Radius for local search around the best particle\n        self.exploration_rate = 0.5  # Initial exploration rate, adaptively reduced\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) / 10, abs(ub - lb) / 10, size=(self.pop_size, self.dim))  # Initialize velocities with a fraction of the search range\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = fitness.copy()\n        self.global_best_index = np.argmin(fitness)\n        self.global_best_position = self.population[self.global_best_index].copy()\n        self.global_best_fitness = fitness[self.global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions - self.population)\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population)\n            self.velocities = self.inertia * self.velocities + cognitive_component + social_component\n\n            # Apply velocity clipping\n            v_max = abs(ub - lb) / 2  # Clip velocities to half the search range\n            self.velocities = np.clip(self.velocities, -v_max, v_max)\n\n            new_population = self.population + self.velocities\n\n            # Apply boundary handling (clip or bounce back)\n            new_population = np.clip(new_population, lb, ub)\n            \n            # Apply exploration with a probability\n            exploration_mask = np.random.rand(self.pop_size, self.dim) < self.exploration_rate\n            new_population[exploration_mask] = np.random.uniform(lb, ub, size=new_population[exploration_mask].shape)\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal and global bests\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness[i]\n                    self.personal_best_positions[i] = new_population[i].copy()\n\n            new_global_best_index = np.argmin(new_fitness)\n            if new_fitness[new_global_best_index] < self.global_best_fitness:\n                self.global_best_fitness = new_fitness[new_global_best_index]\n                self.global_best_position = new_population[new_global_best_index].copy()\n                \n            # Local search around the best particle\n            if self.budget > 0 and self.local_search_radius > 0:\n                local_point = self.global_best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                local_point = np.clip(local_point, lb, ub)  # Ensure local point is within bounds\n                local_fitness = func(local_point)\n                self.budget -= 1\n                if local_fitness < self.global_best_fitness:\n                    self.global_best_fitness = local_fitness\n                    self.global_best_position = local_point.copy()\n\n            # Update population\n            self.population = new_population\n\n            # Adaptive Exploration Rate Update\n            self.exploration_rate *= 0.99  # Gradually reduce exploration\n\n        return self.global_best_fitness, self.global_best_position\n```"}, "task_prompt": ""}
{"id": "49b1900b-cafd-423f-9781-edbb87f23b13", "fitness": 0.0, "name": "BudgetAwareCMAES", "description": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant with a simplified adaptation rule and budget-aware step size control.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.1, c_mu=0.1, c_cov=0.01, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.sigma = sigma0  # Overall step size\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        self.cs = cs  # Learning rate for sigma\n        self.c_mu = c_mu # Learning rate for mean\n        self.c_cov = c_cov  # Learning rate for covariance matrix\n        self.eigeneval = 0\n        self.max_eigeneval = 100\n        self.D = None\n        self.B = None\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            if self.eigeneval > (1 / (self.c_cov * self.dim * self.dim)):\n                self.C = np.eye(self.dim)\n                self.B = None\n                self.D = None\n                self.eigeneval = 0\n            if self.D is None or self.B is None:\n                try:\n                    self.D, self.B = np.linalg.eigh(self.C)\n                    self.D = np.sqrt(self.D)\n                    self.eigeneval = 0\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-6 * np.eye(self.dim)\n                    continue # Restart if it fails\n            y = self.B @ (self.D[:, None] * z)\n            x = self.m[:, None] + self.sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights * x[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y_mean = self.m - m_old\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (self.B @ y_mean / self.sigma)\n            self.pc = (1 - self.c_mu) * self.pc + np.sqrt(self.c_mu * (2 - self.c_mu)) * y_mean / self.sigma\n\n\n            #Update covariance matrix (simplified)\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:,None] @ self.pc[None,:])\n            \n            #Budget aware step size control\n            remaining_budget_ratio = (self.budget - evals) / self.budget\n            self.sigma *= np.exp(0.1 * (remaining_budget_ratio - 0.5)) # adapt sigma to budget\n\n            self.eigeneval += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant with a simplified adaptation rule and budget-aware step size control.\n# Code: \n```python\nimport numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.1, c_mu=0.1, c_cov=0.01, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.sigma = sigma0  # Overall step size\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        self.cs = cs  # Learning rate for sigma\n        self.c_mu = c_mu # Learning rate for mean\n        self.c_cov = c_cov  # Learning rate for covariance matrix\n        self.eigeneval = 0\n        self.max_eigeneval = 100\n        self.D = None\n        self.B = None\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean\n        self.C = np.eye(self.dim) # Initialize covariance matrix\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        evals = 0\n        while evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            if self.eigeneval > (1 / (self.c_cov * self.dim * self.dim)):\n                self.C = np.eye(self.dim)\n                self.B = None\n                self.D = None\n                self.eigeneval = 0\n            if self.D is None or self.B is None:\n                try:\n                    self.D, self.B = np.linalg.eigh(self.C)\n                    self.D = np.sqrt(self.D)\n                    self.eigeneval = 0\n                except np.linalg.LinAlgError:\n                    self.C = self.C + 1e-6 * np.eye(self.dim)\n                    continue # Restart if it fails\n            y = self.B @ (self.D[:, None] * z)\n            x = self.m[:, None] + self.sigma * y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights * x[:, :self.mu], axis=1)\n\n            # Update evolution paths\n            y_mean = self.m - m_old\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (self.B @ y_mean / self.sigma)\n            self.pc = (1 - self.c_mu) * self.pc + np.sqrt(self.c_mu * (2 - self.c_mu)) * y_mean / self.sigma\n\n\n            #Update covariance matrix (simplified)\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:,None] @ self.pc[None,:])\n            \n            #Budget aware step size control\n            remaining_budget_ratio = (self.budget - evals) / self.budget\n            self.sigma *= np.exp(0.1 * (remaining_budget_ratio - 0.5)) # adapt sigma to budget\n\n            self.eigeneval += 1\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "618bb0de-e1d0-44d9-bab8-59ed81ef84f1", "fitness": 0.0, "name": "AdaptiveODE", "description": "Adaptive Differential Evolution with orthogonal learning, population diversity maintenance, and dynamic parameter adjustment.", "code": "import numpy as np\n\nclass AdaptiveODE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor  # Reduce population size each generation\n        self.archive_size = int(self.population_size * 0.2) # 20% of the population size\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.diversity_history = []\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the diversity of the population based on the average pairwise distance.\"\"\"\n        distances = np.sum((population[:, None, :] - population[None, :, :]) ** 2, axis=2)\n        diversity = np.mean(distances)\n        return diversity\n\n    def orthogonal_design(self, population, num_samples=5):\n        \"\"\"Generates orthogonal samples around the best solution.\"\"\"\n        best_idx = np.argmin([func(x) for x in population])\n        best_solution = population[best_idx]\n        \n        orthogonal_samples = []\n        for _ in range(num_samples):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n            step_size = np.random.uniform(-0.1, 0.1)  # Smaller step size\n            sample = best_solution + step_size * direction\n            sample = np.clip(sample, func.bounds.lb, func.bounds.ub)\n            orthogonal_samples.append(sample)\n        return np.array(orthogonal_samples)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9) # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1) # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    orthogonal_samples = self.orthogonal_design(population, num_samples=3)\n                    orthogonal_fitnesses = [func(sample) for sample in orthogonal_samples]\n                    self.eval_count += len(orthogonal_fitnesses)\n\n                    best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                    if orthogonal_fitnesses[best_orthogonal_index] < f_trial:\n                         trial = orthogonal_samples[best_orthogonal_index]\n                         f_trial = orthogonal_fitnesses[best_orthogonal_index]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy() # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5) # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n            # Diversity Maintenance\n            current_diversity = self.calculate_diversity(population)\n            self.diversity_history.append(current_diversity)\n\n            if len(self.diversity_history) > 10 and current_diversity < np.mean(self.diversity_history[-10:]):\n                # Introduce new random individuals if diversity is low.\n                num_new = int(0.1 * self.population_size)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.eval_count += num_new\n\n                population = np.concatenate((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n                # Select best individuals to maintain population size\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal learning, population diversity maintenance, and dynamic parameter adjustment.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveODE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor  # Reduce population size each generation\n        self.archive_size = int(self.population_size * 0.2) # 20% of the population size\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.diversity_history = []\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the diversity of the population based on the average pairwise distance.\"\"\"\n        distances = np.sum((population[:, None, :] - population[None, :, :]) ** 2, axis=2)\n        diversity = np.mean(distances)\n        return diversity\n\n    def orthogonal_design(self, population, num_samples=5):\n        \"\"\"Generates orthogonal samples around the best solution.\"\"\"\n        best_idx = np.argmin([func(x) for x in population])\n        best_solution = population[best_idx]\n        \n        orthogonal_samples = []\n        for _ in range(num_samples):\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n            step_size = np.random.uniform(-0.1, 0.1)  # Smaller step size\n            sample = best_solution + step_size * direction\n            sample = np.clip(sample, func.bounds.lb, func.bounds.ub)\n            orthogonal_samples.append(sample)\n        return np.array(orthogonal_samples)\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9) # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1) # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    orthogonal_samples = self.orthogonal_design(population, num_samples=3)\n                    orthogonal_fitnesses = [func(sample) for sample in orthogonal_samples]\n                    self.eval_count += len(orthogonal_fitnesses)\n\n                    best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                    if orthogonal_fitnesses[best_orthogonal_index] < f_trial:\n                         trial = orthogonal_samples[best_orthogonal_index]\n                         f_trial = orthogonal_fitnesses[best_orthogonal_index]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy() # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5) # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n            # Diversity Maintenance\n            current_diversity = self.calculate_diversity(population)\n            self.diversity_history.append(current_diversity)\n\n            if len(self.diversity_history) > 10 and current_diversity < np.mean(self.diversity_history[-10:]):\n                # Introduce new random individuals if diversity is low.\n                num_new = int(0.1 * self.population_size)\n                new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_new, self.dim))\n                new_fitness = np.array([func(x) for x in new_individuals])\n                self.eval_count += num_new\n\n                population = np.concatenate((population, new_individuals))\n                fitness = np.concatenate((fitness, new_fitness))\n\n                # Select best individuals to maintain population size\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.18585139437648232, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "368ea3e7-15ba-40d8-bd08-cd86c5f8f858", "fitness": 0.649672376425906, "name": "AdaptiveHybridOptimizer", "description": "Combines adaptive differential evolution with a modified particle swarm optimization using an archive to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_size = int(self.population_size * archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = None\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n                \n                # DE mutation\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = self.inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                        if f_trial < global_best_fitness:\n                            global_best_fitness = f_trial\n                            global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (self.eval_count / self.budget)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.650 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines adaptive differential evolution with a modified particle swarm optimization using an archive to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_size = int(self.population_size * archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = None\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n                \n                # DE mutation\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                \n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = self.inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                        if f_trial < global_best_fitness:\n                            global_best_fitness = f_trial\n                            global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (self.eval_count / self.budget)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17126876983928063, 0.5952834078507562, 0.8094165357566321, 0.8889913286181131, 0.8158156399507149, 0.8579003810334294, 0.33111413812278434, 0.756984774750775, 0.745527470232152, 0.2288005494410681, 0.8728016330371225, 0.9921806570981525, 0.37653610619109956, 0.6733006245698652, 0.9130848919325316, 0.8432267915584253, 0.49549543520097805, 0.8777482770241278, 0.24806691032542882, 0.4999032059846841], "operator": "crossover", "theta_sampled": 0.09184946512969898, "reward": 0.03966811647443769, "generation": 1}, "task_prompt": ""}
{"id": "fb52bff1-2514-42da-aafe-93c47c2b66d3", "fitness": 0.0, "name": "SelfAdaptiveDE", "description": "Implements a self-adaptive differential evolution with an archive, shrinking population, and a local search component triggered when stagnation is detected.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_size = int(self.population_size * 0.2)\n        self.stagnation_threshold = stagnation_threshold\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.stagnation_counter = 0\n\n    def local_search(self, func, x0, bounds, max_evals=100):\n        \"\"\"Performs a local search around a given point.\"\"\"\n        res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': max_evals})\n        return res.fun, res.x\n\n    def __call__(self, func):\n        bounds = [(func.bounds.lb[0], func.bounds.ub[0])] * self.dim\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.success_history.append(0)\n                    self.stagnation_counter += 1\n\n\n            # Stagnation check and local search trigger\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Perform local search on the best solution\n                f_local, x_local = self.local_search(func, self.x_opt, bounds, max_evals=min(100, self.budget - self.eval_count))  # Limit evals\n                self.eval_count += min(100, self.budget - self.eval_count)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                self.stagnation_counter = 0 # Reset counter after local search\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Implements a self-adaptive differential evolution with an archive, shrinking population, and a local search component triggered when stagnation is detected.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_size = int(self.population_size * 0.2)\n        self.stagnation_threshold = stagnation_threshold\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.stagnation_counter = 0\n\n    def local_search(self, func, x0, bounds, max_evals=100):\n        \"\"\"Performs a local search around a given point.\"\"\"\n        res = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': max_evals})\n        return res.fun, res.x\n\n    def __call__(self, func):\n        bounds = [(func.bounds.lb[0], func.bounds.ub[0])] * self.dim\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.success_history.append(0)\n                    self.stagnation_counter += 1\n\n\n            # Stagnation check and local search trigger\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Perform local search on the best solution\n                f_local, x_local = self.local_search(func, self.x_opt, bounds, max_evals=min(100, self.budget - self.eval_count))  # Limit evals\n                self.eval_count += min(100, self.budget - self.eval_count)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                self.stagnation_counter = 0 # Reset counter after local search\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.3223196731950419, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "e3dd3a67-b6cd-4836-bcb8-14d788937744", "fitness": 0.23582753734476744, "name": "GaussianCrossoverAdaptation", "description": "Population-based algorithm with a combination of Gaussian mutation, crossover, and adaptive parameter control based on population diversity.", "code": "import numpy as np\n\nclass GaussianCrossoverAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.7, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Crossover rate\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                mutated_individual = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        mutated_individual[j] += np.random.normal(0, 0.1 * (self.ub - self.lb))\n                        mutated_individual[j] = np.clip(mutated_individual[j], self.lb, self.ub)\n\n                # Crossover\n                crossover_individual = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        crossover_individual[j] = mutated_individual[j]\n\n                # Evaluate the new individual\n                f = func(crossover_individual)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                  new_population[i] = crossover_individual\n                  new_fitness[i] = f\n                else:\n                  new_population[i] = population[i]\n                  new_fitness[i] = fitness[i]\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = crossover_individual.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            # Adaptive Parameter Control based on Population Diversity\n            diversity = np.std(new_population)\n            self.cr = min(0.9, self.cr + 0.1 * (diversity - 0.5)) # Adjust crossover rate based on diversity\n            self.mutation_rate = max(0.01, self.mutation_rate - 0.05 * (diversity - 0.5)) # Adjust mutation rate based on diversity\n            \n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GaussianCrossoverAdaptation scored 0.236 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with a combination of Gaussian mutation, crossover, and adaptive parameter control based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianCrossoverAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.7, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Crossover rate\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                mutated_individual = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        mutated_individual[j] += np.random.normal(0, 0.1 * (self.ub - self.lb))\n                        mutated_individual[j] = np.clip(mutated_individual[j], self.lb, self.ub)\n\n                # Crossover\n                crossover_individual = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr:\n                        crossover_individual[j] = mutated_individual[j]\n\n                # Evaluate the new individual\n                f = func(crossover_individual)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                  new_population[i] = crossover_individual\n                  new_fitness[i] = f\n                else:\n                  new_population[i] = population[i]\n                  new_fitness[i] = fitness[i]\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = crossover_individual.copy()\n\n                if self.budget <= 0:\n                    break\n                    \n            # Adaptive Parameter Control based on Population Diversity\n            diversity = np.std(new_population)\n            self.cr = min(0.9, self.cr + 0.1 * (diversity - 0.5)) # Adjust crossover rate based on diversity\n            self.mutation_rate = max(0.01, self.mutation_rate - 0.05 * (diversity - 0.5)) # Adjust mutation rate based on diversity\n            \n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.06957737461165547, 0.12859117513613605, 0.23061644172216356, 0.16820203926974786, 0.13636645184509377, 0.17514484271966357, 0.20435093858670095, 0.17458746321042762, 0.1789329906015792, 0.13433585665847636, 0.1933196878889023, 0.9999117242720956, 0.22594461522733678, 0.16708536221172232, 0.3478496187160862, 0.23838734335596046, 0.19532482229736237, 0.19013396794505144, 0.12806643619589608, 0.4298215944232917], "operator": "random_new", "theta_sampled": 0.1183745170277585, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "b4e27c77-cfb3-461c-8b07-48cd72a019e6", "fitness": 0.667865711608749, "name": "AdaptiveHybridOptimizer", "description": "A hybrid algorithm combining adaptive differential evolution with particle swarm optimization and an archive for diversity, dynamically adjusting parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.668 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid algorithm combining adaptive differential evolution with particle swarm optimization and an archive for diversity, dynamically adjusting parameters for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21886837862798048, 0.6859675810997989, 0.8048134195880221, 0.8969798072273066, 0.5960394843611945, 0.8416890007745464, 0.37477795572844197, 0.4604978859797353, 0.7363027577069339, 0.7825462409090369, 0.8792256095788177, 0.996833614325196, 0.376776132491325, 0.5531140066424296, 0.9359577973136297, 0.8497276583869361, 0.6829151116416617, 0.8795629103596627, 0.309985126843796, 0.49473375258852814], "operator": "crossover", "theta_sampled": 0.22414109098526624, "reward": 0.05786145165728063, "generation": 1}, "task_prompt": ""}
{"id": "80f64a6b-faa6-49de-8d7b-0547a1d41d0f", "fitness": 0.5250741013331571, "name": "AdaptiveHybridOptimizer", "description": "Combines Adaptive Shrinking DE with PSO-inspired velocity updates and archive for diversity and parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_percentage=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_percentage = archive_percentage\n        self.archive_size = int(self.population_size * self.archive_percentage)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)  # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)  # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n\n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices:  # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n\n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # PSO-inspired velocity update and mutation\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n                \n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                trial = population[i] + velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()  # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                    \n                    if f_trial < global_best_fitness:\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.success_history.append(0)\n                    \n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)  # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx].copy()\n                fitness = fitness[idx].copy()\n                personal_best_positions = personal_best_positions[idx].copy()\n                personal_best_fitness = personal_best_fitness[idx].copy()\n                velocities = velocities[idx].copy()\n\n            self.archive_size = int(self.population_size * self.archive_percentage)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.eval_count / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.525 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines Adaptive Shrinking DE with PSO-inspired velocity updates and archive for diversity and parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_percentage=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_percentage = archive_percentage\n        self.archive_size = int(self.population_size * self.archive_percentage)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)].copy()\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)  # Reduce mutation if doing well\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)  # Increase mutation if struggling\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1  with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n\n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices:  # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n\n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # PSO-inspired velocity update and mutation\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n                \n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                trial = population[i] + velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()  # Replace a random element\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                    \n                    if f_trial < global_best_fitness:\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                else:\n                    self.success_history.append(0)\n                    \n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)  # Ensure minimum pop size\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx].copy()\n                fitness = fitness[idx].copy()\n                personal_best_positions = personal_best_positions[idx].copy()\n                personal_best_fitness = personal_best_fitness[idx].copy()\n                velocities = velocities[idx].copy()\n\n            self.archive_size = int(self.population_size * self.archive_percentage)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.eval_count / self.budget)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16050013071592728, 0.7264800998547452, 0.8512193033411057, 0.1950219494634221, 0.30810946886873225, 0.936425580736404, 0.3238755693318651, 0.45499924517312207, 0.8365025270302984, 0.19298574850166683, 0.9514451584992957, 0.9971200146831031, 0.28348094634368914, 0.2693905669593629, 0.672172028614231, 0.8287648650427901, 0.5201370854901634, 0.2903933169829288, 0.21796184053940226, 0.48449658049088806], "operator": "crossover", "theta_sampled": 0.05459389342912658, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "5b61f59f-f34f-4a31-a350-3ed0ee33e52d", "fitness": 0.0, "name": "EnhancedHybridOptimizer", "description": "A hybrid optimization algorithm combining Particle Swarm Optimization (PSO) with a self-adaptive Differential Evolution (DE) mutation and an archive to enhance exploration and exploitation. It incorporates CMA-ES inspired steps, restarts based on population diversity, and parameter adaptation.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1, archive_size_factor=0.2, restart_trigger=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.archive_size = int(pop_size * archive_size_factor)  # Archive size is a fraction of population size\n        self.archive = []\n        self.restart_trigger = restart_trigger # Threshold to trigger a restart\n        self.cma_learning_rate = cma_learning_rate  # Learning rate for CMA-ES inspired steps\n        self.mean = np.zeros(dim) # Mean for CMA-ES\n        self.covariance = np.eye(dim) # Covariance matrix for CMA-ES\n        self.min_diversity = 0.1  # Minimum diversity threshold\n        self.no_improvement_count = 0\n        self.max_no_improvement = budget // 100  # Reduce computational cost\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness values\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness value\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        self.best_fitness = global_best_fitness\n        self.best_position = global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Apply mutation using Differential Evolution\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    # ensure velocity remains within a reasonable range\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # CMA-ES inspired step (exploration)\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n                cma_step = self.cma_learning_rate * z\n\n                # Update position\n                new_position = population[i] + velocities[i] + cma_step\n\n                # Boundary handling\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        \n                        if new_fitness < self.best_fitness:\n                            self.best_fitness = new_fitness\n                            self.best_position = new_position.copy()\n                            self.no_improvement_count = 0 # Reset counter\n                        else:\n                            self.no_improvement_count +=1\n            \n                population[i] = new_position\n\n                # Update archive (using global_best_position as a candidate for diversity)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())  # Append a copy\n                else:\n                    # Replace a random element in the archive\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = global_best_position.copy()\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.budget / (self.budget + self.pop_size))\n            self.mutation_rate = min(0.5, self.mutation_rate + 0.01) # Gradually increase mutation rate to explore.\n\n            # Update CMA-ES mean and covariance (simplified)\n            self.mean = np.mean(population, axis=0)\n            self.covariance = np.cov(population.T) + 1e-8 * np.eye(self.dim)  # Add a small constant for numerical stability\n            \n            # Population diversity check and potential restart\n            diversity = np.std(population)\n            if diversity < self.min_diversity or np.random.rand() < self.restart_trigger:\n                # Restart: re-initialize a fraction of the population around the best solution\n                num_to_restart = int(self.pop_size * 0.3)\n                indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                population[indices_to_restart] = np.random.normal(self.best_position, 0.1 * (func.bounds.ub - func.bounds.lb), size=(num_to_restart, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= num_to_restart\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n                self.inertia_weight = 0.7 # Reset inertia weight after restart\n                self.mutation_rate = 0.1 # Reset Mutation rate after restart\n\n            if self.no_improvement_count > self.max_no_improvement:\n                break # Early stopping due to lack of improvement.\n\n            if self.budget <= 0:\n                break\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedHybridOptimizer scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid optimization algorithm combining Particle Swarm Optimization (PSO) with a self-adaptive Differential Evolution (DE) mutation and an archive to enhance exploration and exploitation. It incorporates CMA-ES inspired steps, restarts based on population diversity, and parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, mutation_rate=0.1, archive_size_factor=0.2, restart_trigger=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.mutation_rate = mutation_rate\n        self.archive_size = int(pop_size * archive_size_factor)  # Archive size is a fraction of population size\n        self.archive = []\n        self.restart_trigger = restart_trigger # Threshold to trigger a restart\n        self.cma_learning_rate = cma_learning_rate  # Learning rate for CMA-ES inspired steps\n        self.mean = np.zeros(dim) # Mean for CMA-ES\n        self.covariance = np.eye(dim) # Covariance matrix for CMA-ES\n        self.min_diversity = 0.1  # Minimum diversity threshold\n        self.no_improvement_count = 0\n        self.max_no_improvement = budget // 100  # Reduce computational cost\n        self.best_fitness = np.inf\n        self.best_position = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness values\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness value\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        self.best_fitness = global_best_fitness\n        self.best_position = global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Apply mutation using Differential Evolution\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    # ensure velocity remains within a reasonable range\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # CMA-ES inspired step (exploration)\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n                cma_step = self.cma_learning_rate * z\n\n                # Update position\n                new_position = population[i] + velocities[i] + cma_step\n\n                # Boundary handling\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_position.copy()\n                        \n                        if new_fitness < self.best_fitness:\n                            self.best_fitness = new_fitness\n                            self.best_position = new_position.copy()\n                            self.no_improvement_count = 0 # Reset counter\n                        else:\n                            self.no_improvement_count +=1\n            \n                population[i] = new_position\n\n                # Update archive (using global_best_position as a candidate for diversity)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())  # Append a copy\n                else:\n                    # Replace a random element in the archive\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = global_best_position.copy()\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.budget / (self.budget + self.pop_size))\n            self.mutation_rate = min(0.5, self.mutation_rate + 0.01) # Gradually increase mutation rate to explore.\n\n            # Update CMA-ES mean and covariance (simplified)\n            self.mean = np.mean(population, axis=0)\n            self.covariance = np.cov(population.T) + 1e-8 * np.eye(self.dim)  # Add a small constant for numerical stability\n            \n            # Population diversity check and potential restart\n            diversity = np.std(population)\n            if diversity < self.min_diversity or np.random.rand() < self.restart_trigger:\n                # Restart: re-initialize a fraction of the population around the best solution\n                num_to_restart = int(self.pop_size * 0.3)\n                indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                population[indices_to_restart] = np.random.normal(self.best_position, 0.1 * (func.bounds.ub - func.bounds.lb), size=(num_to_restart, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.budget -= num_to_restart\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n                self.inertia_weight = 0.7 # Reset inertia weight after restart\n                self.mutation_rate = 0.1 # Reset Mutation rate after restart\n\n            if self.no_improvement_count > self.max_no_improvement:\n                break # Early stopping due to lack of improvement.\n\n            if self.budget <= 0:\n                break\n\n        return self.best_fitness, self.best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.06446787250683782, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "87cf2ac4-89c9-4e24-8183-826ba0b88f9d", "fitness": 0.5276866315563448, "name": "AdaptiveHybridOptimizer", "description": "Combines adaptive differential evolution with a PSO-inspired velocity update and archive, shrinking population, and self-adaptive parameters.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_size = int(self.population_size * 0.2)\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n                \n                # DE mutation with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        \n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # PSO inspired velocity update\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n                \n                # Apply mutation from HybridOptimizer using Differential Evolution\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Update position with velocity\n                trial = population[i] + velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n                    if f_trial < global_best_fitness:\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n                    if np.random.rand() < 0.05 and len(self.archive) < self.archive_size: #small chance to add even if not better\n                        self.archive.append(population[i].copy())\n\n                # Update archive with global best\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())\n                else:\n                    self.archive[np.random.randint(len(self.archive))] = global_best_position.copy()\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.eval_count / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines adaptive differential evolution with a PSO-inspired velocity update and archive, shrinking population, and self-adaptive parameters.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_size = int(self.population_size * 0.2)\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.archive = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n                \n                # DE mutation with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        \n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # PSO inspired velocity update\n                inertia = self.inertia_weight * velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                velocities[i] = inertia + cognitive + social\n                \n                # Apply mutation from HybridOptimizer using Differential Evolution\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    velocities[i] += 0.8 * (population[idxs[0]] - population[idxs[1]]) + 0.2 * (population[idxs[2]] - population[i])\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Update position with velocity\n                trial = population[i] + velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n                    if f_trial < global_best_fitness:\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n                    if np.random.rand() < 0.05 and len(self.archive) < self.archive_size: #small chance to add even if not better\n                        self.archive.append(population[i].copy())\n\n                # Update archive with global best\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(global_best_position.copy())\n                else:\n                    self.archive[np.random.randint(len(self.archive))] = global_best_position.copy()\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Self-adaptive parameter control (example: linearly decreasing inertia weight)\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (1 - self.eval_count / self.budget)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13217786835627465, 0.18593684941348398, 0.645890673550718, 0.9391829635807525, 0.2576440074186146, 0.8429717931659388, 0.32259466976280393, 0.4890534568312379, 0.7291219730022578, 0.20716077884799544, 0.9466870116546156, 0.999775887679942, 0.34690131081083886, 0.31043741119083257, 0.7673926179299383, 0.9288314741383892, 0.401574966703946, 0.381277314739051, 0.2114862558563353, 0.5076333464929288], "operator": "crossover", "theta_sampled": 0.029830430516630344, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "32077e51-5a0f-4869-9433-7cbe07128f4c", "fitness": 0.33069643269901466, "name": "GaussianCauchyOptimizer", "description": "An algorithm that combines a Gaussian mutation with a Cauchy distribution sampling strategy for exploration and exploitation, adaptively adjusting its parameters.", "code": "import numpy as np\n\nclass GaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr_gaussian=0.1, lr_cauchy=0.1, exploration_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr_gaussian = lr_gaussian\n        self.lr_cauchy = lr_cauchy\n        self.exploration_factor = exploration_factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration using Cauchy distribution\n                if np.random.rand() < self.exploration_factor:\n                    step_size = self.lr_cauchy * np.random.standard_cauchy(size=self.dim)\n                    x_new = population[i] + step_size\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                # Exploitation using Gaussian mutation\n                else:\n                    step_size = self.lr_gaussian * np.random.normal(size=self.dim)\n                    x_new = population[i] + step_size\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update individual if better\n                if f_new < fitness[i]:\n                    fitness[i] = f_new\n                    population[i] = x_new\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n            \n            # Adaptive learning rate adjustment (example: linear decay)\n            self.lr_gaussian *= 0.999\n            self.lr_cauchy *= 0.999\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GaussianCauchyOptimizer scored 0.331 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An algorithm that combines a Gaussian mutation with a Cauchy distribution sampling strategy for exploration and exploitation, adaptively adjusting its parameters.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr_gaussian=0.1, lr_cauchy=0.1, exploration_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr_gaussian = lr_gaussian\n        self.lr_cauchy = lr_cauchy\n        self.exploration_factor = exploration_factor\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Exploration using Cauchy distribution\n                if np.random.rand() < self.exploration_factor:\n                    step_size = self.lr_cauchy * np.random.standard_cauchy(size=self.dim)\n                    x_new = population[i] + step_size\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                # Exploitation using Gaussian mutation\n                else:\n                    step_size = self.lr_gaussian * np.random.normal(size=self.dim)\n                    x_new = population[i] + step_size\n                    x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update individual if better\n                if f_new < fitness[i]:\n                    fitness[i] = f_new\n                    population[i] = x_new\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n            \n            # Adaptive learning rate adjustment (example: linear decay)\n            self.lr_gaussian *= 0.999\n            self.lr_cauchy *= 0.999\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11080812956893349, 0.19406620380165984, 0.3734008409328239, 0.3151225663341518, 0.24148136503710893, 0.28254431102994493, 0.26027574554999533, 0.28893363219871937, 0.20938701808834437, 0.17627151464228097, 0.31859162362822147, 0.9881320192238349, 0.2850304980552246, 0.23722604795720248, 0.666805007296571, 0.32150657422040363, 0.27724320543637027, 0.4099194657838775, 0.18477460166509907, 0.47240828352952535], "operator": "random_new", "theta_sampled": 0.10689260341154097, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "c641b944-3f6a-4f29-8e3b-130ab01d7f02", "fitness": 0.6054502803451357, "name": "SelfAdaptiveEnsembleDE", "description": "Self-Adaptive Differential Evolution with Ensemble of Mutation Strategies and an external archive, dynamically adjusting parameters based on success rate and exploration pressure.", "code": "import numpy as np\n\nclass SelfAdaptiveEnsembleDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.mutation_factors = [initial_mutation_factor] * self.population_size\n        self.crossover_rates = [crossover_rate] * self.population_size\n        self.strategy_weights = np.ones(3) / 3  # Equal weights for 3 mutation strategies\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive parameter control\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        self.mutation_factors[i] = max(0.1, self.mutation_factors[i] * 0.95)\n                        self.crossover_rates[i] = min(0.9, self.crossover_rates[i] * 1.05)\n                    else:\n                        self.mutation_factors[i] = min(0.9, self.mutation_factors[i] * 1.05)\n                        self.crossover_rates[i] = max(0.1, self.crossover_rates[i] * 0.95)\n\n                mutation_factor = self.mutation_factors[i]\n                crossover_rate = self.crossover_rates[i]\n\n                # Ensemble of mutation strategies\n                strategy = np.random.choice(3, p=self.strategy_weights)\n                if strategy == 0:\n                    # DE/rand/1\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                elif strategy == 1:\n                    # DE/current-to-best/1\n                    best_vector = self.x_opt\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = population[i] + mutation_factor * (best_vector - population[i]) + mutation_factor * (vectors[0] - vectors[1])\n                else:\n                    # DE/best/1\n                    best_vector = self.x_opt\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = best_vector + mutation_factor * (vectors[0] - vectors[1])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Dynamic Strategy Weight Adjustment (simplified)\n            num_successes = sum(self.success_history[-self.population_size:]) if len(self.success_history) >= self.population_size else sum(self.success_history)\n            if num_successes > self.population_size * 0.4: # Exploration pressure. If doing too well, increase exploration\n                self.strategy_weights = np.clip(self.strategy_weights + np.random.normal(0, 0.05, 3), 0.05, 0.95)\n                self.strategy_weights /= np.sum(self.strategy_weights)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.mutation_factors = [self.mutation_factors[i] for i in idx]\n                self.crossover_rates = [self.crossover_rates[i] for i in idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveEnsembleDE scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Self-Adaptive Differential Evolution with Ensemble of Mutation Strategies and an external archive, dynamically adjusting parameters based on success rate and exploration pressure.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveEnsembleDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.mutation_factors = [initial_mutation_factor] * self.population_size\n        self.crossover_rates = [crossover_rate] * self.population_size\n        self.strategy_weights = np.ones(3) / 3  # Equal weights for 3 mutation strategies\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive parameter control\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        self.mutation_factors[i] = max(0.1, self.mutation_factors[i] * 0.95)\n                        self.crossover_rates[i] = min(0.9, self.crossover_rates[i] * 1.05)\n                    else:\n                        self.mutation_factors[i] = min(0.9, self.mutation_factors[i] * 1.05)\n                        self.crossover_rates[i] = max(0.1, self.crossover_rates[i] * 0.95)\n\n                mutation_factor = self.mutation_factors[i]\n                crossover_rate = self.crossover_rates[i]\n\n                # Ensemble of mutation strategies\n                strategy = np.random.choice(3, p=self.strategy_weights)\n                if strategy == 0:\n                    # DE/rand/1\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                elif strategy == 1:\n                    # DE/current-to-best/1\n                    best_vector = self.x_opt\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = population[i] + mutation_factor * (best_vector - population[i]) + mutation_factor * (vectors[0] - vectors[1])\n                else:\n                    # DE/best/1\n                    best_vector = self.x_opt\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant = best_vector + mutation_factor * (vectors[0] - vectors[1])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Dynamic Strategy Weight Adjustment (simplified)\n            num_successes = sum(self.success_history[-self.population_size:]) if len(self.success_history) >= self.population_size else sum(self.success_history)\n            if num_successes > self.population_size * 0.4: # Exploration pressure. If doing too well, increase exploration\n                self.strategy_weights = np.clip(self.strategy_weights + np.random.normal(0, 0.05, 3), 0.05, 0.95)\n                self.strategy_weights /= np.sum(self.strategy_weights)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.mutation_factors = [self.mutation_factors[i] for i in idx]\n                self.crossover_rates = [self.crossover_rates[i] for i in idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1981854375694726, 0.29391298014961453, 0.7104206363402714, 0.9118673819969005, 0.8838168642873607, 0.6174986358803143, 0.35683861239107484, 0.588311785131392, 0.7786609152782973, 0.2001641519456694, 0.8890972752713375, 0.9946778005965008, 0.23651754991065232, 0.5420020741468425, 0.8810011679367403, 0.8886582171002687, 0.4630038575464549, 0.9115531513011421, 0.23363318728936255, 0.529183924833046], "operator": "mutation", "theta_sampled": 0.2823569545523832, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "762eed78-2cd0-44d3-819e-5496273072aa", "fitness": 0.0, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with orthogonal learning, shrinking population, archive and success-history based parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    # Select two random dimensions for orthogonal learning\n                    dims = np.random.choice(self.dim, size=2, replace=False)\n                    \n                    # Create an orthogonal array (simple 2-level full factorial design)\n                    oa = np.array([[1, 1], [-1, 1], [1, -1], [-1, -1]])\n\n                    # Map the levels to the bounds for the selected dimensions\n                    levels_dim1 = np.linspace(func.bounds.lb[dims[0]], func.bounds.ub[dims[0]], 2)\n                    levels_dim2 = np.linspace(func.bounds.lb[dims[1]], func.bounds.ub[dims[1]], 2)\n\n                    # Evaluate the design points\n                    fitness_oa = []\n                    points_oa = []\n                    for k in range(oa.shape[0]):\n                        point = trial.copy()\n                        point[dims[0]] = levels_dim1[(oa[k, 0] + 1) // 2]\n                        point[dims[1]] = levels_dim2[(oa[k, 1] + 1) // 2]\n                        \n                        f_oa = func(point)\n                        self.eval_count += 1\n                        fitness_oa.append(f_oa)\n                        points_oa.append(point)\n\n                    # Select the best point from the orthogonal array\n                    best_oa_index = np.argmin(fitness_oa)\n                    if fitness_oa[best_oa_index] < func(trial):\n                        trial = points_oa[best_oa_index]\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal learning, shrinking population, archive and success-history based parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    # Select two random dimensions for orthogonal learning\n                    dims = np.random.choice(self.dim, size=2, replace=False)\n                    \n                    # Create an orthogonal array (simple 2-level full factorial design)\n                    oa = np.array([[1, 1], [-1, 1], [1, -1], [-1, -1]])\n\n                    # Map the levels to the bounds for the selected dimensions\n                    levels_dim1 = np.linspace(func.bounds.lb[dims[0]], func.bounds.ub[dims[0]], 2)\n                    levels_dim2 = np.linspace(func.bounds.lb[dims[1]], func.bounds.ub[dims[1]], 2)\n\n                    # Evaluate the design points\n                    fitness_oa = []\n                    points_oa = []\n                    for k in range(oa.shape[0]):\n                        point = trial.copy()\n                        point[dims[0]] = levels_dim1[(oa[k, 0] + 1) // 2]\n                        point[dims[1]] = levels_dim2[(oa[k, 1] + 1) // 2]\n                        \n                        f_oa = func(point)\n                        self.eval_count += 1\n                        fitness_oa.append(f_oa)\n                        points_oa.append(point)\n\n                    # Select the best point from the orthogonal array\n                    best_oa_index = np.argmin(fitness_oa)\n                    if fitness_oa[best_oa_index] < func(trial):\n                        trial = points_oa[best_oa_index]\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.23961635805116624, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "08ea39c5-c071-430a-86b6-47be29657cc3", "fitness": 0.4371047723116555, "name": "AdaptiveGaussianCauchyOptimizer", "description": "A population-based algorithm that leverages a combination of Gaussian mutation and a Cauchy-based random walk for exploration, dynamically adapting the step sizes based on success rates.", "code": "import numpy as np\n\nclass AdaptiveGaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, gaussian_mutation_rate=0.8, cauchy_mutation_rate=0.2, initial_gaussian_step_size=0.1, initial_cauchy_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.gaussian_mutation_rate = gaussian_mutation_rate\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.gaussian_step_size = initial_gaussian_step_size\n        self.cauchy_step_size = initial_cauchy_step_size\n        self.success_history_gaussian = []\n        self.success_history_cauchy = []\n        self.success_window = 10 # Size of the sliding window to track success rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    # Gaussian mutation\n                    mutation = np.random.normal(0, self.gaussian_step_size, self.dim)\n                    new_x = population[i] + mutation\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    if new_f < fitness[i]:\n                        new_population[i] = new_x\n                        new_fitness[i] = new_f\n                        self.success_history_gaussian.append(1)\n                    else:\n                        self.success_history_gaussian.append(0)\n                elif np.random.rand() < self.cauchy_mutation_rate:\n                    # Cauchy mutation (random walk)\n                    mutation = self.cauchy_step_size * np.random.standard_cauchy(size=self.dim)\n                    new_x = population[i] + mutation\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if new_f < fitness[i]:\n                        new_population[i] = new_x\n                        new_fitness[i] = new_f\n                        self.success_history_cauchy.append(1)\n                    else:\n                        self.success_history_cauchy.append(0)\n                else:\n                    # Simple replacement\n                    new_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    if new_f < fitness[i]:\n                         new_population[i] = new_x\n                         new_fitness[i] = new_f\n                    \n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Adjust step sizes based on success rate\n            if len(self.success_history_gaussian) > self.success_window:\n                success_rate_gaussian = np.mean(self.success_history_gaussian[-self.success_window:])\n                if success_rate_gaussian > 0.2:\n                    self.gaussian_step_size *= 1.1\n                else:\n                    self.gaussian_step_size *= 0.9\n                self.gaussian_step_size = np.clip(self.gaussian_step_size, 0.001, 1.0) #Clamp values\n            \n            if len(self.success_history_cauchy) > self.success_window:\n                success_rate_cauchy = np.mean(self.success_history_cauchy[-self.success_window:])\n                if success_rate_cauchy > 0.2:\n                    self.cauchy_step_size *= 1.1\n                else:\n                    self.cauchy_step_size *= 0.9\n                self.cauchy_step_size = np.clip(self.cauchy_step_size, 0.001, 1.0) #Clamp values\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianCauchyOptimizer scored 0.437 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that leverages a combination of Gaussian mutation and a Cauchy-based random walk for exploration, dynamically adapting the step sizes based on success rates.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, gaussian_mutation_rate=0.8, cauchy_mutation_rate=0.2, initial_gaussian_step_size=0.1, initial_cauchy_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.gaussian_mutation_rate = gaussian_mutation_rate\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n        self.gaussian_step_size = initial_gaussian_step_size\n        self.cauchy_step_size = initial_cauchy_step_size\n        self.success_history_gaussian = []\n        self.success_history_cauchy = []\n        self.success_window = 10 # Size of the sliding window to track success rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    # Gaussian mutation\n                    mutation = np.random.normal(0, self.gaussian_step_size, self.dim)\n                    new_x = population[i] + mutation\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    if new_f < fitness[i]:\n                        new_population[i] = new_x\n                        new_fitness[i] = new_f\n                        self.success_history_gaussian.append(1)\n                    else:\n                        self.success_history_gaussian.append(0)\n                elif np.random.rand() < self.cauchy_mutation_rate:\n                    # Cauchy mutation (random walk)\n                    mutation = self.cauchy_step_size * np.random.standard_cauchy(size=self.dim)\n                    new_x = population[i] + mutation\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if new_f < fitness[i]:\n                        new_population[i] = new_x\n                        new_fitness[i] = new_f\n                        self.success_history_cauchy.append(1)\n                    else:\n                        self.success_history_cauchy.append(0)\n                else:\n                    # Simple replacement\n                    new_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    if new_f < fitness[i]:\n                         new_population[i] = new_x\n                         new_fitness[i] = new_f\n                    \n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # Adjust step sizes based on success rate\n            if len(self.success_history_gaussian) > self.success_window:\n                success_rate_gaussian = np.mean(self.success_history_gaussian[-self.success_window:])\n                if success_rate_gaussian > 0.2:\n                    self.gaussian_step_size *= 1.1\n                else:\n                    self.gaussian_step_size *= 0.9\n                self.gaussian_step_size = np.clip(self.gaussian_step_size, 0.001, 1.0) #Clamp values\n            \n            if len(self.success_history_cauchy) > self.success_window:\n                success_rate_cauchy = np.mean(self.success_history_cauchy[-self.success_window:])\n                if success_rate_cauchy > 0.2:\n                    self.cauchy_step_size *= 1.1\n                else:\n                    self.cauchy_step_size *= 0.9\n                self.cauchy_step_size = np.clip(self.cauchy_step_size, 0.001, 1.0) #Clamp values\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15535479068713554, 0.2042763782379312, 0.49533023208648463, 0.8125294637900742, 0.32033243457982385, 0.23844823950743244, 0.3055999751612226, 0.4524756342629972, 0.3120742916735796, 0.1664808761270271, 0.8452644035647842, 0.9942120039498827, 0.29909071990099967, 0.37007538039059795, 0.78862989939895, 0.3322827123232881, 0.2968396450228252, 0.682014320627233, 0.19860988838328364, 0.4721741565575557], "operator": "random_new", "theta_sampled": 0.47739297512107753, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "f14c6f59-0df6-4de0-896c-2a55da7dc9b5", "fitness": 0.0, "name": "AdaptiveDEOrthogonal", "description": "Adaptive Differential Evolution with orthogonal learning, population diversity maintenance, and dynamic parameter control.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.diversity_threshold = 0.01 # Threshold for diversity check\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.05)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    trial = self.orthogonal_learning(func, trial)\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n            \n            # Diversity Maintenance\n            if self.check_diversity(population):\n                # Introduce random individuals to increase diversity\n                num_random = int(0.1 * self.population_size)\n                random_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_random, self.dim))\n                random_fitness = np.array([func(x) for x in random_individuals])\n                self.eval_count += num_random\n\n                # Replace worst individuals with random ones\n                worst_indices = np.argsort(fitness)[-num_random:]\n                population[worst_indices] = random_individuals\n                fitness[worst_indices] = random_fitness\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n    \n    def orthogonal_learning(self, func, x):\n        # Generate orthogonal array (simplified for demonstration)\n        levels = 3  # Number of levels for each factor\n        factors = self.dim  # Number of factors (dimensions)\n        \n        # Create a simple orthogonal array (L9 array)\n        if factors <= 4:\n            orthogonal_array = np.array([\n                [0, 0, 0],\n                [0, 1, 1],\n                [0, 2, 2],\n                [1, 0, 1],\n                [1, 1, 2],\n                [1, 2, 0],\n                [2, 0, 2],\n                [2, 1, 0],\n                [2, 2, 1]\n            ])\n        elif factors <= 9: \n            orthogonal_array = np.array([\n                [0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 1, 1, 1, 1, 1],\n                [0, 0, 0, 2, 2, 2, 2, 2],\n                [0, 1, 1, 0, 0, 1, 1, 2],\n                [0, 1, 1, 1, 1, 2, 2, 0],\n                [0, 1, 1, 2, 2, 0, 0, 1],\n                [0, 2, 2, 0, 1, 0, 2, 1],\n                [0, 2, 2, 1, 2, 1, 0, 0],\n                [0, 2, 2, 2, 0, 2, 1, 0],\n                [1, 0, 1, 0, 2, 2, 1, 0],\n                [1, 0, 1, 1, 0, 0, 0, 2],\n                [1, 0, 1, 2, 1, 1, 2, 1],\n                [1, 1, 2, 0, 1, 1, 0, 2],\n                [1, 1, 2, 1, 2, 2, 1, 1],\n                [1, 1, 2, 2, 0, 0, 2, 0],\n                [1, 2, 0, 0, 0, 2, 2, 1],\n                [1, 2, 0, 1, 1, 0, 1, 0],\n                [1, 2, 0, 2, 2, 1, 0, 2],\n                [2, 0, 2, 0, 1, 2, 0, 1],\n                [2, 0, 2, 1, 2, 1, 2, 0],\n                [2, 0, 2, 2, 0, 0, 1, 2],\n                [2, 1, 0, 0, 2, 0, 2, 0],\n                [2, 1, 0, 1, 0, 1, 0, 1],\n                [2, 1, 0, 2, 1, 2, 1, 2],\n                [2, 2, 1, 0, 0, 1, 1, 0],\n                [2, 2, 1, 1, 1, 2, 2, 1],\n                [2, 2, 1, 2, 2, 0, 0, 2]\n            ])\n        else:\n            orthogonal_array = np.random.randint(0, levels, size=(levels**2, factors))\n\n        # Adjust the number of trials according to budget.\n        num_trials = min(orthogonal_array.shape[0], self.budget - self.eval_count)\n        orthogonal_array = orthogonal_array[:num_trials]\n\n        # Generate test points based on orthogonal array\n        test_points = np.zeros((num_trials, self.dim))\n        for j in range(self.dim):\n            delta = (func.bounds.ub[j] - func.bounds.lb[j]) / (levels - 1)\n            test_points[:, j] = func.bounds.lb[j] + orthogonal_array[:, j] * delta\n\n        # Evaluate test points\n        fitness_values = np.array([func(point) for point in test_points])\n        self.eval_count += num_trials\n\n        # Select the best point\n        best_index = np.argmin(fitness_values)\n        if fitness_values[best_index] < func(x):\n            return test_points[best_index]\n        else:\n            return x\n    \n    def check_diversity(self, population):\n        # Calculate the mean of the population\n        mean_individual = np.mean(population, axis=0)\n        \n        # Calculate the average distance of each individual from the mean\n        distances = np.linalg.norm(population - mean_individual, axis=1)\n        average_distance = np.mean(distances)\n        \n        # If the average distance is below the threshold, the population is considered diverse\n        return average_distance < self.diversity_threshold", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEOrthogonal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal learning, population diversity maintenance, and dynamic parameter control.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonal:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99, orthogonal_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.orthogonal_learning_rate = orthogonal_learning_rate\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.diversity_threshold = 0.01 # Threshold for diversity check\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            # Mutation and Crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation strategy based on success history\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.05)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=3, replace=False)\n                \n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Orthogonal Learning\n                if np.random.rand() < self.orthogonal_learning_rate:\n                    trial = self.orthogonal_learning(func, trial)\n                \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n            \n            # Diversity Maintenance\n            if self.check_diversity(population):\n                # Introduce random individuals to increase diversity\n                num_random = int(0.1 * self.population_size)\n                random_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_random, self.dim))\n                random_fitness = np.array([func(x) for x in random_individuals])\n                self.eval_count += num_random\n\n                # Replace worst individuals with random ones\n                worst_indices = np.argsort(fitness)[-num_random:]\n                population[worst_indices] = random_individuals\n                fitness[worst_indices] = random_fitness\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n            \n            self.archive_size = int(self.population_size * 0.2)\n            if len(archive) > self.archive_size:\n                archive = archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n    \n    def orthogonal_learning(self, func, x):\n        # Generate orthogonal array (simplified for demonstration)\n        levels = 3  # Number of levels for each factor\n        factors = self.dim  # Number of factors (dimensions)\n        \n        # Create a simple orthogonal array (L9 array)\n        if factors <= 4:\n            orthogonal_array = np.array([\n                [0, 0, 0],\n                [0, 1, 1],\n                [0, 2, 2],\n                [1, 0, 1],\n                [1, 1, 2],\n                [1, 2, 0],\n                [2, 0, 2],\n                [2, 1, 0],\n                [2, 2, 1]\n            ])\n        elif factors <= 9: \n            orthogonal_array = np.array([\n                [0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 1, 1, 1, 1, 1],\n                [0, 0, 0, 2, 2, 2, 2, 2],\n                [0, 1, 1, 0, 0, 1, 1, 2],\n                [0, 1, 1, 1, 1, 2, 2, 0],\n                [0, 1, 1, 2, 2, 0, 0, 1],\n                [0, 2, 2, 0, 1, 0, 2, 1],\n                [0, 2, 2, 1, 2, 1, 0, 0],\n                [0, 2, 2, 2, 0, 2, 1, 0],\n                [1, 0, 1, 0, 2, 2, 1, 0],\n                [1, 0, 1, 1, 0, 0, 0, 2],\n                [1, 0, 1, 2, 1, 1, 2, 1],\n                [1, 1, 2, 0, 1, 1, 0, 2],\n                [1, 1, 2, 1, 2, 2, 1, 1],\n                [1, 1, 2, 2, 0, 0, 2, 0],\n                [1, 2, 0, 0, 0, 2, 2, 1],\n                [1, 2, 0, 1, 1, 0, 1, 0],\n                [1, 2, 0, 2, 2, 1, 0, 2],\n                [2, 0, 2, 0, 1, 2, 0, 1],\n                [2, 0, 2, 1, 2, 1, 2, 0],\n                [2, 0, 2, 2, 0, 0, 1, 2],\n                [2, 1, 0, 0, 2, 0, 2, 0],\n                [2, 1, 0, 1, 0, 1, 0, 1],\n                [2, 1, 0, 2, 1, 2, 1, 2],\n                [2, 2, 1, 0, 0, 1, 1, 0],\n                [2, 2, 1, 1, 1, 2, 2, 1],\n                [2, 2, 1, 2, 2, 0, 0, 2]\n            ])\n        else:\n            orthogonal_array = np.random.randint(0, levels, size=(levels**2, factors))\n\n        # Adjust the number of trials according to budget.\n        num_trials = min(orthogonal_array.shape[0], self.budget - self.eval_count)\n        orthogonal_array = orthogonal_array[:num_trials]\n\n        # Generate test points based on orthogonal array\n        test_points = np.zeros((num_trials, self.dim))\n        for j in range(self.dim):\n            delta = (func.bounds.ub[j] - func.bounds.lb[j]) / (levels - 1)\n            test_points[:, j] = func.bounds.lb[j] + orthogonal_array[:, j] * delta\n\n        # Evaluate test points\n        fitness_values = np.array([func(point) for point in test_points])\n        self.eval_count += num_trials\n\n        # Select the best point\n        best_index = np.argmin(fitness_values)\n        if fitness_values[best_index] < func(x):\n            return test_points[best_index]\n        else:\n            return x\n    \n    def check_diversity(self, population):\n        # Calculate the mean of the population\n        mean_individual = np.mean(population, axis=0)\n        \n        # Calculate the average distance of each individual from the mean\n        distances = np.linalg.norm(population - mean_individual, axis=1)\n        average_distance = np.mean(distances)\n        \n        # If the average distance is below the threshold, the population is considered diverse\n        return average_distance < self.diversity_threshold\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.3662361976532417, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "7bde07c7-ae7f-46ef-a648-c0fe52bd2c44", "fitness": 0.38849527252162924, "name": "NeighborhoodAdaptiveDE", "description": "Adaptive Differential Evolution with dynamically adjusted mutation and crossover rates, combined with a neighborhood-based update to enhance exploration.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, initial_mutation_factor=0.5, crossover_rate=0.7, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.mutation_factor = initial_mutation_factor\n        self.crossover_rate = crossover_rate\n        self.neighborhood_size = neighborhood_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_mutation = []\n        self.success_history_crossover = []\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive Mutation Factor\n                if len(self.success_history_mutation) > 10:\n                    success_rate_mutation = np.mean(self.success_history_mutation[-10:])\n                    if success_rate_mutation > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.05)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # Adaptive Crossover Rate\n                if len(self.success_history_crossover) > 10:\n                    success_rate_crossover = np.mean(self.success_history_crossover[-10:])\n                    if success_rate_crossover > 0.5:\n                        crossover_rate = max(0.1, self.crossover_rate * 0.95)\n                    else:\n                        crossover_rate = min(0.9, self.crossover_rate * 1.05)\n                else:\n                    crossover_rate = self.crossover_rate\n\n\n                # Neighborhood selection\n                neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n                \n                # Ensure that i is not in the neighbors_indices\n                if i in neighbors_indices:\n                    neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n                    while i in neighbors_indices: # Ensure i is not in the neighbors_indices\n                        neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n\n\n                neighbors = population[neighbors_indices]\n\n                # Mutation\n                # Selecting 3 random vectors from the neighborhood\n                indices = np.random.choice(self.neighborhood_size, size=3, replace=False)\n                vectors = neighbors[indices]\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history_mutation.append(1)\n                    self.success_history_crossover.append(1)\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history_mutation.append(0)\n                    self.success_history_crossover.append(0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm NeighborhoodAdaptiveDE scored 0.388 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with dynamically adjusted mutation and crossover rates, combined with a neighborhood-based update to enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass NeighborhoodAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, initial_mutation_factor=0.5, crossover_rate=0.7, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.mutation_factor = initial_mutation_factor\n        self.crossover_rate = crossover_rate\n        self.neighborhood_size = neighborhood_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_mutation = []\n        self.success_history_crossover = []\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive Mutation Factor\n                if len(self.success_history_mutation) > 10:\n                    success_rate_mutation = np.mean(self.success_history_mutation[-10:])\n                    if success_rate_mutation > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.05)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # Adaptive Crossover Rate\n                if len(self.success_history_crossover) > 10:\n                    success_rate_crossover = np.mean(self.success_history_crossover[-10:])\n                    if success_rate_crossover > 0.5:\n                        crossover_rate = max(0.1, self.crossover_rate * 0.95)\n                    else:\n                        crossover_rate = min(0.9, self.crossover_rate * 1.05)\n                else:\n                    crossover_rate = self.crossover_rate\n\n\n                # Neighborhood selection\n                neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n                \n                # Ensure that i is not in the neighbors_indices\n                if i in neighbors_indices:\n                    neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n                    while i in neighbors_indices: # Ensure i is not in the neighbors_indices\n                        neighbors_indices = np.random.choice(self.population_size, size=self.neighborhood_size, replace=False)\n\n\n                neighbors = population[neighbors_indices]\n\n                # Mutation\n                # Selecting 3 random vectors from the neighborhood\n                indices = np.random.choice(self.neighborhood_size, size=3, replace=False)\n                vectors = neighbors[indices]\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history_mutation.append(1)\n                    self.success_history_crossover.append(1)\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history_mutation.append(0)\n                    self.success_history_crossover.append(0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14110966021107796, 0.25895688240370096, 0.37138975608653013, 0.3833321669380977, 0.2983795098409169, 0.39874685084922634, 0.28553267955903117, 0.3425058805938427, 0.3210933248367004, 0.19320977637257197, 0.5235870378018128, 0.9821911756222399, 0.3284559539673705, 0.30198567121783726, 0.7493043415635772, 0.4147608769825044, 0.31543382461428504, 0.4942075826035637, 0.18282477518427165, 0.4828977231834273], "operator": "mutation", "theta_sampled": 0.36045422113404735, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "b1ec9c22-1b23-49a2-892e-4d4927b38897", "fitness": 0.6405606740892555, "name": "SelfOrganizingPSO", "description": "Implements a Self-Organizing Particle Swarm Optimization (SOPSO) with dynamic inertia and constriction factor adaptation based on swarm diversity.", "code": "import numpy as np\n\nclass SelfOrganizingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, cognitive_coeff=2.0, social_coeff=2.0, initial_inertia=0.9, constriction_factor=0.729):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_inertia = initial_inertia\n        self.constriction_factor = constriction_factor\n\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) * 0.1, abs(ub - lb) * 0.1, size=(self.swarm_size, self.dim)) # Initialize velocities reasonably\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.positions[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                self.personal_best_positions[i] = self.positions[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.positions[i].copy()\n\n\n    def calculate_diversity(self):\n         # Calculate the average distance of each particle to the swarm's center.\n        center = np.mean(self.positions, axis=0)\n        distances = np.linalg.norm(self.positions - center, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n\n    def update_inertia_and_constriction(self):\n        # Dynamic adjustment based on swarm diversity.  If diversity is high (swarm is spread out), reduce inertia to promote exploration.\n        # If diversity is low (swarm is clustered), increase inertia to allow for broader search and increase constriction.\n        diversity = self.calculate_diversity()\n        max_diversity = np.linalg.norm(np.full(self.dim, 5.0) - np.full(self.dim, -5.0)) # Estimate of maximum possible diversity\n\n        normalized_diversity = diversity / max_diversity\n\n        # Linear adjustment, can be tuned.\n        self.inertia = self.initial_inertia * (1.0 - 0.5 * normalized_diversity)  # Reduce inertia if swarm is diverse\n        self.constriction_factor = 0.729 + 0.2 * normalized_diversity # increase constriction if swarm is clustered\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            self.update_inertia_and_constriction() # Adapt inertia based on swarm state.\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n                \n                # Clamp velocities to avoid excessive movement\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = abs(ub - lb) * 0.2\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n                # Update position\n                self.positions[i] = self.positions[i] + self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n                # Evaluate fitness\n                fitness = func(self.positions[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i].copy()\n\n                # Update global best\n                if fitness < self.global_best_fitness:\n                    self.global_best_fitness = fitness\n                    self.global_best_position = self.positions[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfOrganizingPSO scored 0.641 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Implements a Self-Organizing Particle Swarm Optimization (SOPSO) with dynamic inertia and constriction factor adaptation based on swarm diversity.\n# Code: \n```python\nimport numpy as np\n\nclass SelfOrganizingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, cognitive_coeff=2.0, social_coeff=2.0, initial_inertia=0.9, constriction_factor=0.729):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_inertia = initial_inertia\n        self.constriction_factor = constriction_factor\n\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) * 0.1, abs(ub - lb) * 0.1, size=(self.swarm_size, self.dim)) # Initialize velocities reasonably\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.positions[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                self.personal_best_positions[i] = self.positions[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.positions[i].copy()\n\n\n    def calculate_diversity(self):\n         # Calculate the average distance of each particle to the swarm's center.\n        center = np.mean(self.positions, axis=0)\n        distances = np.linalg.norm(self.positions - center, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n\n    def update_inertia_and_constriction(self):\n        # Dynamic adjustment based on swarm diversity.  If diversity is high (swarm is spread out), reduce inertia to promote exploration.\n        # If diversity is low (swarm is clustered), increase inertia to allow for broader search and increase constriction.\n        diversity = self.calculate_diversity()\n        max_diversity = np.linalg.norm(np.full(self.dim, 5.0) - np.full(self.dim, -5.0)) # Estimate of maximum possible diversity\n\n        normalized_diversity = diversity / max_diversity\n\n        # Linear adjustment, can be tuned.\n        self.inertia = self.initial_inertia * (1.0 - 0.5 * normalized_diversity)  # Reduce inertia if swarm is diverse\n        self.constriction_factor = 0.729 + 0.2 * normalized_diversity # increase constriction if swarm is clustered\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            self.update_inertia_and_constriction() # Adapt inertia based on swarm state.\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n                \n                # Clamp velocities to avoid excessive movement\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = abs(ub - lb) * 0.2\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n                # Update position\n                self.positions[i] = self.positions[i] + self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n                # Evaluate fitness\n                fitness = func(self.positions[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i].copy()\n\n                # Update global best\n                if fitness < self.global_best_fitness:\n                    self.global_best_fitness = fitness\n                    self.global_best_position = self.positions[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2044779868082618, 0.2910164858125288, 0.7881783549376141, 0.9222425485666951, 0.8104841985325937, 0.8606953205047548, 0.3573798991708168, 0.7462335861918827, 0.8197947103689639, 0.19625608910402903, 0.8976926674892595, 0.9949505062579976, 0.26078757037008315, 0.7290774938942132, 0.7394797422435837, 0.8462139626697001, 0.6676929269158848, 0.8849989233416448, 0.285561337941564, 0.5079991706630399], "operator": "random_new", "theta_sampled": 0.17064177412616913, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "a9ac1c33-f0b7-41d2-966d-240c13570a7d", "fitness": 0.0, "name": "AntColonyOptimization", "description": "A population-based algorithm inspired by the foraging behavior of ants, where ants probabilistically explore the search space and deposit \"pheromone\" to guide other ants towards promising regions, coupled with a pheromone evaporation mechanism and adaptive step size control.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=20, evaporation_rate=0.1, alpha=1.0, beta=2.0, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Influence of pheromone\n        self.beta = beta    # Influence of heuristic (fitness)\n        self.pheromone = np.ones(dim)  # Initialize pheromone levels\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        eval_count = 0\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_ants, self.dim))  # Initialize ant positions\n\n        while eval_count < self.budget:\n            fitness = np.zeros(self.n_ants)\n            for i in range(self.n_ants):\n                fitness[i] = func(ants[i])\n                eval_count += 1\n\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = ants[i].copy()\n\n                self.archive_x.append(ants[i])\n                self.archive_f.append(fitness[i])\n                if eval_count >= self.budget:\n                    break\n\n            # Pheromone update\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.f_opt / (fitness[i] + 1e-8)) * np.abs(ants[i] - self.x_opt) # Deposit pheromone based on ant's quality\n\n            self.pheromone = (1 - self.evaporation_rate) * self.pheromone + delta_pheromone\n\n            # Ant movement based on pheromone and fitness\n            for i in range(self.n_ants):\n                probabilities = (self.pheromone**self.alpha) * ((1 / (fitness + 1e-8))**self.beta) # Probability based on pheromone and fitness\n                probabilities = probabilities / np.sum(probabilities)\n                \n                # Choose a random direction based on probabilities\n                direction = np.random.normal(0, 1, self.dim)\n                \n                # Perturb ant position\n                ants[i] += self.step_size * direction * probabilities[i]\n\n                # Clip to bounds\n                ants[i] = np.clip(ants[i], func.bounds.lb, func.bounds.ub)\n\n            # Adaptive step size\n            if eval_count % 1000 == 0:  # Adjust step size periodically\n                improvements = np.sum(fitness < np.mean(self.archive_f[-self.n_ants:]))\n                if improvements > self.n_ants / 2:\n                    self.step_size *= 1.1  # Increase step size if doing well\n                else:\n                    self.step_size *= 0.9  # Decrease step size if not improving\n                self.step_size = min(self.step_size, self.initial_step_size*2)\n                self.step_size = max(self.step_size, self.initial_step_size*0.1)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,) (20,) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm inspired by the foraging behavior of ants, where ants probabilistically explore the search space and deposit \"pheromone\" to guide other ants towards promising regions, coupled with a pheromone evaporation mechanism and adaptive step size control.\n# Code: \n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, n_ants=20, evaporation_rate=0.1, alpha=1.0, beta=2.0, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.n_ants = n_ants\n        self.evaporation_rate = evaporation_rate\n        self.alpha = alpha  # Influence of pheromone\n        self.beta = beta    # Influence of heuristic (fitness)\n        self.pheromone = np.ones(dim)  # Initialize pheromone levels\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        eval_count = 0\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_ants, self.dim))  # Initialize ant positions\n\n        while eval_count < self.budget:\n            fitness = np.zeros(self.n_ants)\n            for i in range(self.n_ants):\n                fitness[i] = func(ants[i])\n                eval_count += 1\n\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = ants[i].copy()\n\n                self.archive_x.append(ants[i])\n                self.archive_f.append(fitness[i])\n                if eval_count >= self.budget:\n                    break\n\n            # Pheromone update\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.n_ants):\n                delta_pheromone += (self.f_opt / (fitness[i] + 1e-8)) * np.abs(ants[i] - self.x_opt) # Deposit pheromone based on ant's quality\n\n            self.pheromone = (1 - self.evaporation_rate) * self.pheromone + delta_pheromone\n\n            # Ant movement based on pheromone and fitness\n            for i in range(self.n_ants):\n                probabilities = (self.pheromone**self.alpha) * ((1 / (fitness + 1e-8))**self.beta) # Probability based on pheromone and fitness\n                probabilities = probabilities / np.sum(probabilities)\n                \n                # Choose a random direction based on probabilities\n                direction = np.random.normal(0, 1, self.dim)\n                \n                # Perturb ant position\n                ants[i] += self.step_size * direction * probabilities[i]\n\n                # Clip to bounds\n                ants[i] = np.clip(ants[i], func.bounds.lb, func.bounds.ub)\n\n            # Adaptive step size\n            if eval_count % 1000 == 0:  # Adjust step size periodically\n                improvements = np.sum(fitness < np.mean(self.archive_f[-self.n_ants:]))\n                if improvements > self.n_ants / 2:\n                    self.step_size *= 1.1  # Increase step size if doing well\n                else:\n                    self.step_size *= 0.9  # Decrease step size if not improving\n                self.step_size = min(self.step_size, self.initial_step_size*2)\n                self.step_size = max(self.step_size, self.initial_step_size*0.1)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.20661471609602364, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "cc0f0732-68de-4df1-a05d-4b0abc13350c", "fitness": 0.6718217556132814, "name": "AdaptiveHybridOptimizerV2", "description": "An adaptive hybrid optimizer combining shrinking population DE/PSO with success-rate based parameter control and archive-based mutation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV2 scored 0.672 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimizer combining shrinking population DE/PSO with success-rate based parameter control and archive-based mutation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21448300928133024, 0.6356344564841252, 0.788096865282188, 0.8877486861034197, 0.802354332367838, 0.8644652399488619, 0.34687816677018457, 0.7145171769970412, 0.8199261949504878, 0.6613465808836396, 0.8890343042100571, 0.9990875363653585, 0.25577551453637015, 0.488143355167616, 0.930149023552633, 0.8597627931601421, 0.6669841715834005, 0.8730839148874379, 0.21713941972401662, 0.5218243700094802], "operator": "crossover", "theta_sampled": 0.04225950061425894, "reward": 0.003956044004532422, "generation": 3}, "task_prompt": ""}
{"id": "6379ef27-c0bf-4027-b87e-e2e2846086b4", "fitness": 0.0, "name": "SelfAdaptiveDE", "description": "Implements a self-adaptive Differential Evolution strategy with a dynamically adjusted population size, mutation, and crossover rates based on success history and stagnation detection.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_cr = []\n        self.success_history_f = []\n        self.memory_cr = np.random.uniform(0, 1, size=10)  # Memory for CR\n        self.memory_f = np.random.uniform(0.1, 0.9, size=10) # Memory for F\n        self.p_best_rate = 0.1\n\n        self.cr = 0.5\n        self.f = 0.7\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Self-adaptive CR and F\n                memory_index = np.random.randint(10)\n                self.cr = self.memory_cr[memory_index]\n                self.f = self.memory_f[memory_index]\n                \n                # Ensure F is within bounds [0, 2] but usually less than 1\n                self.f = np.clip(self.f, 0.1, 1.0)\n\n\n                # p-best selection\n                p_size = max(int(self.population_size * self.p_best_rate), 2) #Ensure at least 2\n                p_best_indices = np.argsort(fitness)[:p_size]\n                \n                #Select one of the p-best individuals\n                p_best_index = np.random.choice(p_best_indices)\n                \n                # Mutation\n                indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n\n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n                \n                mutant = population[i] + self.f * (population[p_best_index] - population[i]) + self.f * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update memory\n                    self.success_history_cr.append(self.cr)\n                    self.success_history_f.append(self.f)\n                    \n                    if len(self.success_history_cr) > 5:\n                        weights = np.exp(np.linspace(0, -5, len(self.success_history_cr)))\n                        weights /= weights.sum()\n\n                        successful_crs = np.array(self.success_history_cr[-5:])\n                        successful_fs = np.array(self.success_history_f[-5:])\n                        \n                        weighted_avg_cr = np.sum(weights * successful_crs)\n                        weighted_avg_f = np.sum(weights * successful_fs)\n\n                        self.memory_cr[memory_index] = weighted_avg_cr\n                        self.memory_f[memory_index] = weighted_avg_f\n\n                    # Archive update\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (6,) (5,) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Implements a self-adaptive Differential Evolution strategy with a dynamically adjusted population size, mutation, and crossover rates based on success history and stagnation detection.\n\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.archive_size = int(self.population_size * 0.2)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_cr = []\n        self.success_history_f = []\n        self.memory_cr = np.random.uniform(0, 1, size=10)  # Memory for CR\n        self.memory_f = np.random.uniform(0.1, 0.9, size=10) # Memory for F\n        self.p_best_rate = 0.1\n\n        self.cr = 0.5\n        self.f = 0.7\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        archive = []\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Self-adaptive CR and F\n                memory_index = np.random.randint(10)\n                self.cr = self.memory_cr[memory_index]\n                self.f = self.memory_f[memory_index]\n                \n                # Ensure F is within bounds [0, 2] but usually less than 1\n                self.f = np.clip(self.f, 0.1, 1.0)\n\n\n                # p-best selection\n                p_size = max(int(self.population_size * self.p_best_rate), 2) #Ensure at least 2\n                p_best_indices = np.argsort(fitness)[:p_size]\n                \n                #Select one of the p-best individuals\n                p_best_index = np.random.choice(p_best_indices)\n                \n                # Mutation\n                indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                \n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(archive), size=2, replace=False)\n\n                # Select from population and archive\n                all_individuals = np.concatenate((population, np.array(archive) if archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n                \n                mutant = population[i] + self.f * (population[p_best_index] - population[i]) + self.f * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update memory\n                    self.success_history_cr.append(self.cr)\n                    self.success_history_f.append(self.f)\n                    \n                    if len(self.success_history_cr) > 5:\n                        weights = np.exp(np.linspace(0, -5, len(self.success_history_cr)))\n                        weights /= weights.sum()\n\n                        successful_crs = np.array(self.success_history_cr[-5:])\n                        successful_fs = np.array(self.success_history_f[-5:])\n                        \n                        weighted_avg_cr = np.sum(weights * successful_crs)\n                        weighted_avg_f = np.sum(weights * successful_fs)\n\n                        self.memory_cr[memory_index] = weighted_avg_cr\n                        self.memory_f[memory_index] = weighted_avg_f\n\n                    # Archive update\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                    else:\n                        archive[np.random.randint(len(archive))] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.09882653054344531, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "378dcabb-b33f-47b9-a45d-6a11cc8ed8e6", "fitness": 0.3750397386343524, "name": "AdaptiveEvolutionarySearch", "description": "Population-based optimization with adaptive mutation and crossover rates based on population diversity and fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveEvolutionarySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive mutation and crossover rates\n            diversity = np.std(population)  # Population diversity\n            fitness_improvement = np.mean(fitness) - np.min(fitness)\n            \n            # Dynamically adjust mutation rate\n            self.mutation_rate = 0.05 + 0.45 * np.exp(-diversity / (np.abs(func.bounds.ub[0]-func.bounds.lb[0]))) # Adjust between 0.05 and 0.5\n            # Dynamically adjust crossover rate\n            self.crossover_rate = 0.3 + 0.6 * np.exp(-fitness_improvement / np.abs(np.mean(fitness))) # Adjust between 0.3 and 0.9\n            \n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Selection and Crossover\n            for i in range(self.pop_size):\n                # Tournament Selection (size 2)\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                winner_index = indices[0] if fitness[indices[0]] < fitness[indices[1]] else indices[1]\n                parent1 = population[winner_index]\n\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                winner_index = indices[0] if fitness[indices[0]] < fitness[indices[1]] else indices[1]\n                parent2 = population[winner_index]\n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(1, self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1 # No crossover\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        child[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])  # Mutate each dimension independently\n\n                # Evaluate new solution\n                f_child = func(child)\n                self.budget -= 1\n\n                if f_child < new_fitness[i]:\n                    new_population[i] = child\n                    new_fitness[i] = f_child\n\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n\n                if self.budget <= 0:\n                   break\n\n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveEvolutionarySearch scored 0.375 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based optimization with adaptive mutation and crossover rates based on population diversity and fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveEvolutionarySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive mutation and crossover rates\n            diversity = np.std(population)  # Population diversity\n            fitness_improvement = np.mean(fitness) - np.min(fitness)\n            \n            # Dynamically adjust mutation rate\n            self.mutation_rate = 0.05 + 0.45 * np.exp(-diversity / (np.abs(func.bounds.ub[0]-func.bounds.lb[0]))) # Adjust between 0.05 and 0.5\n            # Dynamically adjust crossover rate\n            self.crossover_rate = 0.3 + 0.6 * np.exp(-fitness_improvement / np.abs(np.mean(fitness))) # Adjust between 0.3 and 0.9\n            \n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Selection and Crossover\n            for i in range(self.pop_size):\n                # Tournament Selection (size 2)\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                winner_index = indices[0] if fitness[indices[0]] < fitness[indices[1]] else indices[1]\n                parent1 = population[winner_index]\n\n                indices = np.random.choice(self.pop_size, 2, replace=False)\n                winner_index = indices[0] if fitness[indices[0]] < fitness[indices[1]] else indices[1]\n                parent2 = population[winner_index]\n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(1, self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1 # No crossover\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        child[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])  # Mutate each dimension independently\n\n                # Evaluate new solution\n                f_child = func(child)\n                self.budget -= 1\n\n                if f_child < new_fitness[i]:\n                    new_population[i] = child\n                    new_fitness[i] = f_child\n\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n\n                if self.budget <= 0:\n                   break\n\n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17902833216217384, 0.26118690077071016, 0.3421392049130362, 0.35282245934117595, 0.27479889095540844, 0.36426519328120033, 0.29665223844002053, 0.30907939663015016, 0.29239459998577055, 0.282067440970053, 0.36454279961679714, 0.9877139458698674, 0.3024763253456998, 0.3051552225033157, 0.7337882373144595, 0.42327483087720097, 0.3053685227230619, 0.42978302557906944, 0.2053360886709854, 0.48892111673689365], "operator": "random_new", "theta_sampled": 0.30837294497889545, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "6bcf5f17-d049-4664-b093-160468d67a1f", "fitness": 0.3569853341499206, "name": "CulturalAlgorithm", "description": "A population-based algorithm inspired by cultural algorithms, maintaining belief spaces (normative, situational, and historical) to guide search.", "code": "import numpy as np\n\nclass CulturalAlgorithm:\n    def __init__(self, budget=10000, dim=10, population_size=50, belief_space_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.belief_space_size = belief_space_size  # Number of best individuals to retain in belief space\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize belief space\n        belief_space_population = population[np.argsort(fitness)[:self.belief_space_size]]\n        belief_space_fitness = fitness[np.argsort(fitness)[:self.belief_space_size]]\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Generate offspring based on belief space\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                # Sample two individuals from belief space\n                idx1, idx2 = np.random.choice(self.belief_space_size, 2, replace=False)\n                parent1 = belief_space_population[idx1]\n                parent2 = belief_space_population[idx2]\n\n                # Create offspring using crossover and mutation based on belief space influence\n                alpha = np.random.rand(self.dim)  # Blend two parents\n                offspring[i] = alpha * parent1 + (1 - alpha) * parent2\n\n                # Mutation based on belief space.  Smaller fitness --> smaller mutation\n                mutation_rate = np.exp(-belief_space_fitness[idx1]) # Adjust mutation based on belief fitness\n                mutation_vector = np.random.normal(0, mutation_rate, self.dim)\n                offspring[i] += mutation_vector\n                offspring[i] = np.clip(offspring[i], lb, ub)  # Keep in bounds\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update population\n            combined_population = np.concatenate((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n\n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.population_size]]\n            fitness = combined_fitness[sorted_indices[:self.population_size]]\n\n            # Update belief space\n            belief_space_population = population[np.argsort(fitness)[:self.belief_space_size]]\n            belief_space_fitness = fitness[np.argsort(fitness)[:self.belief_space_size]]\n\n            # Update best solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CulturalAlgorithm scored 0.357 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm inspired by cultural algorithms, maintaining belief spaces (normative, situational, and historical) to guide search.\n\n# Code:\n```python\nimport numpy as np\n\nclass CulturalAlgorithm:\n    def __init__(self, budget=10000, dim=10, population_size=50, belief_space_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.belief_space_size = belief_space_size  # Number of best individuals to retain in belief space\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        # Initialize belief space\n        belief_space_population = population[np.argsort(fitness)[:self.belief_space_size]]\n        belief_space_fitness = fitness[np.argsort(fitness)[:self.belief_space_size]]\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Generate offspring based on belief space\n            offspring = np.zeros_like(population)\n            for i in range(self.population_size):\n                # Sample two individuals from belief space\n                idx1, idx2 = np.random.choice(self.belief_space_size, 2, replace=False)\n                parent1 = belief_space_population[idx1]\n                parent2 = belief_space_population[idx2]\n\n                # Create offspring using crossover and mutation based on belief space influence\n                alpha = np.random.rand(self.dim)  # Blend two parents\n                offspring[i] = alpha * parent1 + (1 - alpha) * parent2\n\n                # Mutation based on belief space.  Smaller fitness --> smaller mutation\n                mutation_rate = np.exp(-belief_space_fitness[idx1]) # Adjust mutation based on belief fitness\n                mutation_vector = np.random.normal(0, mutation_rate, self.dim)\n                offspring[i] += mutation_vector\n                offspring[i] = np.clip(offspring[i], lb, ub)  # Keep in bounds\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update population\n            combined_population = np.concatenate((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n\n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.population_size]]\n            fitness = combined_fitness[sorted_indices[:self.population_size]]\n\n            # Update belief space\n            belief_space_population = population[np.argsort(fitness)[:self.belief_space_size]]\n            belief_space_fitness = fitness[np.argsort(fitness)[:self.belief_space_size]]\n\n            # Update best solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.13696496860599416, 0.31299472707045406, 0.34182729970195247, 0.37454528345041416, 0.27375321457757906, 0.32800993737827555, 0.28010007519704083, 0.29353613239592846, 0.2711667011011625, 0.20224147213658095, 0.3550798577648474, 0.9942076476201129, 0.24167219457083533, 0.28900385804996087, 0.7113334692601307, 0.34482707830087045, 0.30989958043816224, 0.4061771984722664, 0.18664155249678938, 0.48572443440905344], "operator": "random_new", "theta_sampled": 0.31972029423626, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "bb0b9d37-7541-4413-9d39-42089d8acfe9", "fitness": 0.0, "name": "AdaptiveHybridOptimizerV2", "description": "An adaptive hybrid optimization algorithm combining DE, PSO, and a shrinking population with an archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_variant=\"rand/1/bin\", local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_variant = de_variant\n        self.local_search_probability = local_search_probability\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n\n    def __local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around a given solution.\"\"\"\n        x_new = x + np.random.uniform(-radius, radius, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        return f_new, x_new\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE mutation\n                if self.de_variant == \"rand/1/bin\":\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:  #DE/current-to-best/1\n                    mutant = population[i] + mutation_factor * (self.x_opt - population[i]) + mutation_factor * (np.random.choice(population.flatten(), size=self.dim) - np.random.choice(population.flatten(), size=self.dim))\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub) #Clip after crossover\n\n\n                # PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    f_local, trial_local = self.__local_search(func, trial)\n                    if f_local < func(trial):\n                        trial = trial_local\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimization algorithm combining DE, PSO, and a shrinking population with an archive for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_variant=\"rand/1/bin\", local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_variant = de_variant\n        self.local_search_probability = local_search_probability\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n\n    def __local_search(self, func, x, radius=0.1):\n        \"\"\"Performs a local search around a given solution.\"\"\"\n        x_new = x + np.random.uniform(-radius, radius, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.eval_count += 1\n        return f_new, x_new\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE mutation\n                if self.de_variant == \"rand/1/bin\":\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                else:  #DE/current-to-best/1\n                    mutant = population[i] + mutation_factor * (self.x_opt - population[i]) + mutation_factor * (np.random.choice(population.flatten(), size=self.dim) - np.random.choice(population.flatten(), size=self.dim))\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub) #Clip after crossover\n\n\n                # PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n                # Local search\n                if np.random.rand() < self.local_search_probability:\n                    f_local, trial_local = self.__local_search(func, trial)\n                    if f_local < func(trial):\n                        trial = trial_local\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.01190367611240298, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "3cfdc58c-cc46-4894-a148-9c3b2cc25b6f", "fitness": 0.6383748971457368, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An adaptive hybrid optimizer combining shrinking population, DE mutation with archive, PSO velocity updates influenced by DE, and dynamic parameter adjustments for exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_pso_influence=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_pso_influence = de_pso_influence # Controls how much DE influences PSO velocity\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n\n                # DE influence on PSO velocity\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                self.velocities[i] += self.de_pso_influence * (population[idxs[0]] - population[idxs[1]])\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1) #Clip velocity\n\n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer scored 0.638 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimizer combining shrinking population, DE mutation with archive, PSO velocity updates influenced by DE, and dynamic parameter adjustments for exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_pso_influence=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_pso_influence = de_pso_influence # Controls how much DE influences PSO velocity\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n\n                # DE influence on PSO velocity\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                self.velocities[i] += self.de_pso_influence * (population[idxs[0]] - population[idxs[1]])\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1) #Clip velocity\n\n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        global_best_fitness = f_trial\n                        global_best_position = trial.copy()\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21065413174253944, 0.31793815957033444, 0.7883796494865567, 0.8857069458362671, 0.8055802318884194, 0.8540368278941289, 0.39628555706204505, 0.6989826736016045, 0.8115233945105419, 0.3552972213945401, 0.8650173784479798, 0.9964380136036798, 0.3332916054656828, 0.43038969871824617, 0.9309567963495733, 0.8397656495750263, 0.6793672567497624, 0.8632397520416488, 0.19863990874379722, 0.5060070902323655], "operator": "crossover", "theta_sampled": 0.009069284252780564, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "dc5cda31-2ab7-47a5-8ad5-2e64ce7b24ac", "fitness": 0.5284055354180232, "name": "AdaptiveHybridOptimizerV2", "description": "Dynamically adjusts the balance between Differential Evolution (DE) and Particle Swarm Optimization (PSO) based on their recent success, while also incorporating an archive for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_proportion=0.5):  # de_proportion controls the probability of using DE update\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_de = []\n        self.success_history_pso = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.de_proportion = de_proportion  # Probability of applying DE update\n        self.pso_proportion = 1 - de_proportion # Probability of applying PSO update\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history_de) > 10:\n                    success_rate_de = np.mean(self.success_history_de[-10:])\n                    if success_rate_de > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n                \n                #PSO Mutation\n                \n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                self.velocities[i] = inertia + cognitive + social\n                mutant_pso = population[i] + self.velocities[i]\n                mutant_pso = np.clip(mutant_pso, func.bounds.lb, func.bounds.ub)\n                \n                \n                #Adaptive selection of DE or PSO\n                if np.random.rand() < self.de_proportion:\n                    trial = trial\n                else:\n                     trial = mutant_pso\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    if np.random.rand() < self.de_proportion:\n                         self.success_history_de.append(1)\n                    else:\n                         self.success_history_pso.append(1)\n                    \n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n                    \n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                     if np.random.rand() < self.de_proportion:\n                         self.success_history_de.append(0)\n                     else:\n                         self.success_history_pso.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n                \n            # Adapt DE/PSO proportions based on success\n            if len(self.success_history_de) > 10 and len(self.success_history_pso) > 10:\n                success_rate_de = np.mean(self.success_history_de[-10:])\n                success_rate_pso = np.mean(self.success_history_pso[-10:])\n                \n                if success_rate_de + success_rate_pso > 0:  # avoid division by zero\n                    self.de_proportion = success_rate_de / (success_rate_de + success_rate_pso)\n                    self.pso_proportion = success_rate_pso / (success_rate_de + success_rate_pso)\n                else:\n                    # If both have very low success, keep the existing proportion\n                    pass\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV2 scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Dynamically adjusts the balance between Differential Evolution (DE) and Particle Swarm Optimization (PSO) based on their recent success, while also incorporating an archive for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_proportion=0.5):  # de_proportion controls the probability of using DE update\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_de = []\n        self.success_history_pso = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.de_proportion = de_proportion  # Probability of applying DE update\n        self.pso_proportion = 1 - de_proportion # Probability of applying PSO update\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history_de) > 10:\n                    success_rate_de = np.mean(self.success_history_de[-10:])\n                    if success_rate_de > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n                \n                #PSO Mutation\n                \n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                self.velocities[i] = inertia + cognitive + social\n                mutant_pso = population[i] + self.velocities[i]\n                mutant_pso = np.clip(mutant_pso, func.bounds.lb, func.bounds.ub)\n                \n                \n                #Adaptive selection of DE or PSO\n                if np.random.rand() < self.de_proportion:\n                    trial = trial\n                else:\n                     trial = mutant_pso\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    if np.random.rand() < self.de_proportion:\n                         self.success_history_de.append(1)\n                    else:\n                         self.success_history_pso.append(1)\n                    \n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n                    \n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                     if np.random.rand() < self.de_proportion:\n                         self.success_history_de.append(0)\n                     else:\n                         self.success_history_pso.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n                \n            # Adapt DE/PSO proportions based on success\n            if len(self.success_history_de) > 10 and len(self.success_history_pso) > 10:\n                success_rate_de = np.mean(self.success_history_de[-10:])\n                success_rate_pso = np.mean(self.success_history_pso[-10:])\n                \n                if success_rate_de + success_rate_pso > 0:  # avoid division by zero\n                    self.de_proportion = success_rate_de / (success_rate_de + success_rate_pso)\n                    self.pso_proportion = success_rate_pso / (success_rate_de + success_rate_pso)\n                else:\n                    # If both have very low success, keep the existing proportion\n                    pass\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12796751159143738, 0.15822841437392976, 0.5124916472348, 0.8963338149518952, 0.3203042658396392, 0.8580925691721855, 0.3225798077774833, 0.3108179513057703, 0.7415239562505778, 0.22990035656716679, 0.8906990708093112, 0.9949760284498536, 0.36732487061544616, 0.29204861531177795, 0.5813190553541137, 0.8376380182595606, 0.48134671080771874, 0.8919062946589225, 0.2665135504883005, 0.4860981985405737], "operator": "crossover", "theta_sampled": 0.016246435295152194, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "6ec63b08-8d12-41a7-bfbf-d7d8797ebd61", "fitness": 0.25148226723128003, "name": "AdaptiveSwarmOptimizer", "description": "A swarm-based optimization algorithm with adaptive neighborhood radius and velocity clamping, promoting both exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        radius = self.initial_radius\n        radius_decay = 0.995 #Decay radius over time.\n        min_radius = 0.01\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                # Adaptive neighborhood: Consider particles within a certain radius\n                distances = np.linalg.norm(swarm - swarm[i], axis=1)\n                neighborhood_indices = np.where(distances <= radius)[0]\n\n                # Find best particle within the neighborhood\n                if len(neighborhood_indices) > 0:\n                  neighborhood_fitness = fitness[neighborhood_indices]\n                  best_neighbor_index = neighborhood_indices[np.argmin(neighborhood_fitness)]\n                  best_neighbor_position = swarm[best_neighbor_index]\n                else:\n                  best_neighbor_position = global_best_position # Fallback to global best if neighborhood is empty\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i]\n                                  + self.cognitive_coeff * r1 * (personal_best_positions[i] - swarm[i])\n                                  + self.social_coeff * r2 * (best_neighbor_position - swarm[i]))\n\n                # Velocity clamping to prevent divergence\n                v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n\n                # Boundary handling (clip to bounds)\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n                    \n                # Update particle\n                swarm[i] = new_position\n                fitness[i] = new_fitness\n            \n            radius = max(radius * radius_decay, min_radius)\n            \n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSwarmOptimizer scored 0.251 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A swarm-based optimization algorithm with adaptive neighborhood radius and velocity clamping, promoting both exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, size=(self.swarm_size, self.dim))\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        radius = self.initial_radius\n        radius_decay = 0.995 #Decay radius over time.\n        min_radius = 0.01\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                # Adaptive neighborhood: Consider particles within a certain radius\n                distances = np.linalg.norm(swarm - swarm[i], axis=1)\n                neighborhood_indices = np.where(distances <= radius)[0]\n\n                # Find best particle within the neighborhood\n                if len(neighborhood_indices) > 0:\n                  neighborhood_fitness = fitness[neighborhood_indices]\n                  best_neighbor_index = neighborhood_indices[np.argmin(neighborhood_fitness)]\n                  best_neighbor_position = swarm[best_neighbor_index]\n                else:\n                  best_neighbor_position = global_best_position # Fallback to global best if neighborhood is empty\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i]\n                                  + self.cognitive_coeff * r1 * (personal_best_positions[i] - swarm[i])\n                                  + self.social_coeff * r2 * (best_neighbor_position - swarm[i]))\n\n                # Velocity clamping to prevent divergence\n                v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                new_position = swarm[i] + velocities[i]\n\n                # Boundary handling (clip to bounds)\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n                    \n                # Update particle\n                swarm[i] = new_position\n                fitness[i] = new_fitness\n            \n            radius = max(radius * radius_decay, min_radius)\n            \n        return global_best_fitness, global_best_position\n```", "aucs": [0.0934814948024072, 0.16538245030980236, 0.24427244836409767, 0.16376153688355755, 0.1484507385590148, 0.15924520136073406, 0.19366525974512416, 0.17003886888932718, 0.1568994110145937, 0.1388478420727588, 0.15341718024897277, 0.9986980528589162, 0.24906462755959669, 0.1808959148221585, 0.5460349105814073, 0.28991475171877523, 0.19331395833903364, 0.22226162244976, 0.11157634722433518, 0.45042272682122764], "operator": "random_new", "theta_sampled": 0.021400841066388322, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "401075c6-d3d5-46e7-9e76-c58ad67e0f9e", "fitness": 0.42080583510683606, "name": "AdaptiveHybridOptimizerV3", "description": "Adaptive hybrid optimizer with self-adaptive parameter control, orthogonal learning, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 success_rate_threshold=0.3, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_size = int(self.population_size * archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = None\n        self.success_rate_threshold = success_rate_threshold  # Threshold for adaptive parameter adjustment\n        self.restart_trigger = restart_trigger # Trigger to re-initialize population\n\n    def orthogonal_learning(self, population, fitness, num_samples=5):\n        \"\"\"Performs orthogonal learning to generate diverse candidate solutions.\"\"\"\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index]\n        candidates = []\n\n        for _ in range(num_samples):\n            # Generate a random orthogonal matrix\n            orthogonal_matrix = np.random.randn(self.dim, self.dim)\n            q, _ = np.linalg.qr(orthogonal_matrix)\n\n            # Create a new candidate solution by perturbing the best individual along orthogonal directions\n            candidate = best_individual + np.random.normal(0, self.mutation_factor, self.dim).dot(q)\n            candidate = np.clip(candidate, -5, 5)\n            candidates.append(candidate)\n        return candidates\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        restart_count = 0 # count restarts to potentially reduce restart_trigger\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > self.success_rate_threshold:\n                        self.mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        self.mutation_factor = min(0.9, self.mutation_factor * 1.05)\n\n                # DE mutation\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = self.inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n\n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n\n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update personal best and global best\n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                        if f_trial < global_best_fitness:\n                            global_best_fitness = f_trial\n                            global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Orthogonal learning\n            candidates = self.orthogonal_learning(population, fitness)\n            for candidate in candidates:\n                if self.eval_count >= self.budget:\n                    break\n                f_candidate = func(candidate)\n                self.eval_count += 1\n                if f_candidate < global_best_fitness:\n                    global_best_fitness = f_candidate\n                    global_best_position = candidate\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (self.eval_count / self.budget)\n\n            # Restart mechanism\n            if len(self.success_history) > 50 and np.mean(self.success_history[-50:]) < self.restart_trigger:\n                restart_count += 1\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.population_size\n\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n                self.success_history = []\n\n                self.restart_trigger = max(0.01, self.restart_trigger * 0.9) # lower trigger if getting stuck\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV3 scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive hybrid optimizer with self-adaptive parameter control, orthogonal learning, and a restart mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight=0.7, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 success_rate_threshold=0.3, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight = inertia_weight\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_size = int(self.population_size * archive_proportion)\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = None\n        self.success_rate_threshold = success_rate_threshold  # Threshold for adaptive parameter adjustment\n        self.restart_trigger = restart_trigger # Trigger to re-initialize population\n\n    def orthogonal_learning(self, population, fitness, num_samples=5):\n        \"\"\"Performs orthogonal learning to generate diverse candidate solutions.\"\"\"\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index]\n        candidates = []\n\n        for _ in range(num_samples):\n            # Generate a random orthogonal matrix\n            orthogonal_matrix = np.random.randn(self.dim, self.dim)\n            q, _ = np.linalg.qr(orthogonal_matrix)\n\n            # Create a new candidate solution by perturbing the best individual along orthogonal directions\n            candidate = best_individual + np.random.normal(0, self.mutation_factor, self.dim).dot(q)\n            candidate = np.clip(candidate, -5, 5)\n            candidates.append(candidate)\n        return candidates\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        restart_count = 0 # count restarts to potentially reduce restart_trigger\n\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Adaptive mutation factor\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > self.success_rate_threshold:\n                        self.mutation_factor = max(0.1, self.mutation_factor * 0.95)\n                    else:\n                        self.mutation_factor = min(0.9, self.mutation_factor * 1.05)\n\n                # DE mutation\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                # Ensure that i is not in the indices\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices: # Ensure i is not in the indices\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                # Select from population and archive\n                vectors = []\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = self.inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n\n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n\n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update personal best and global best\n                    if f_trial < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_trial\n                        personal_best_positions[i] = trial.copy()\n                        if f_trial < global_best_fitness:\n                            global_best_fitness = f_trial\n                            global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Orthogonal learning\n            candidates = self.orthogonal_learning(population, fitness)\n            for candidate in candidates:\n                if self.eval_count >= self.budget:\n                    break\n                f_candidate = func(candidate)\n                self.eval_count += 1\n                if f_candidate < global_best_fitness:\n                    global_best_fitness = f_candidate\n                    global_best_position = candidate\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * 0.2)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.7 - (0.7 - 0.4) * (self.eval_count / self.budget)\n\n            # Restart mechanism\n            if len(self.success_history) > 50 and np.mean(self.success_history[-50:]) < self.restart_trigger:\n                restart_count += 1\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.population_size\n\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                global_best_position = population[global_best_index].copy()\n                global_best_fitness = fitness[global_best_index]\n                self.success_history = []\n\n                self.restart_trigger = max(0.01, self.restart_trigger * 0.9) # lower trigger if getting stuck\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17316872693448637, 0.22778511827925985, 0.41799954868696154, 0.43950036403257386, 0.4411824851279984, 0.5705428566360178, 0.30344017590044614, 0.3759897292794423, 0.4364731274747865, 0.19157111424874051, 0.47591407375216976, 0.9957250356035353, 0.30990490765611045, 0.29971176176967407, 0.7204569567323081, 0.5103714518492655, 0.2983029308181473, 0.5511920808427122, 0.19502691281553275, 0.4818573436965512], "operator": "mutation", "theta_sampled": 0.08387744740148192, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "5ddf7676-e00b-4a93-b0f5-225a42859bbe", "fitness": 0.0, "name": "AdaptiveNelderMead", "description": "Implements a gradient-free optimization using Nelder-Mead simplex method with adaptive restarts to escape local optima.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_trigger=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_simplex_size (float):  Size of the initial simplex as a fraction of the search space.\n            restart_trigger (int): Number of iterations without improvement before restarting the simplex.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_trigger = restart_trigger\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        no_improvement_counter = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n\n        def objective(x):\n            nonlocal eval_count\n            if eval_count >= self.budget:\n                return np.inf \n            eval_count += 1\n            return func(x)\n        \n\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n\n        while eval_count < self.budget:\n            \n            initial_simplex = np.zeros((self.dim + 1, self.dim))\n            initial_simplex[0] = x0\n            for i in range(self.dim):\n                initial_simplex[i+1] = x0.copy()\n                initial_simplex[i+1, i] += self.initial_simplex_size * (ub[i] - lb[i])\n\n            # Ensure initial simplex is within bounds\n            initial_simplex = np.clip(initial_simplex, lb, ub)\n\n            res = minimize(objective, x0, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex}) # Ensure that Nelder-Mead respects the budget constraint\n                \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n                no_improvement_counter = 0\n            else:\n                no_improvement_counter += 1\n\n            if no_improvement_counter > self.restart_trigger or res.success is False:  # Restart if no improvement or Nelder-Mead failed\n                x0 = np.random.uniform(lb, ub, size=self.dim)\n                no_improvement_counter = 0\n\n            else:\n                x0 = res.x\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Implements a gradient-free optimization using Nelder-Mead simplex method with adaptive restarts to escape local optima.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_trigger=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            initial_simplex_size (float):  Size of the initial simplex as a fraction of the search space.\n            restart_trigger (int): Number of iterations without improvement before restarting the simplex.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_trigger = restart_trigger\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        no_improvement_counter = 0\n        bounds = func.bounds\n        lb = bounds.lb\n        ub = bounds.ub\n\n\n        def objective(x):\n            nonlocal eval_count\n            if eval_count >= self.budget:\n                return np.inf \n            eval_count += 1\n            return func(x)\n        \n\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n\n        while eval_count < self.budget:\n            \n            initial_simplex = np.zeros((self.dim + 1, self.dim))\n            initial_simplex[0] = x0\n            for i in range(self.dim):\n                initial_simplex[i+1] = x0.copy()\n                initial_simplex[i+1, i] += self.initial_simplex_size * (ub[i] - lb[i])\n\n            # Ensure initial simplex is within bounds\n            initial_simplex = np.clip(initial_simplex, lb, ub)\n\n            res = minimize(objective, x0, method='Nelder-Mead', options={'maxfev': self.budget - eval_count, 'initial_simplex': initial_simplex}) # Ensure that Nelder-Mead respects the budget constraint\n                \n            if res.fun < self.f_opt:\n                self.f_opt = res.fun\n                self.x_opt = res.x\n                no_improvement_counter = 0\n            else:\n                no_improvement_counter += 1\n\n            if no_improvement_counter > self.restart_trigger or res.success is False:  # Restart if no improvement or Nelder-Mead failed\n                x0 = np.random.uniform(lb, ub, size=self.dim)\n                no_improvement_counter = 0\n\n            else:\n                x0 = res.x\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.1633607778647355, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "0e05fde5-5e18-4e4b-98f5-c11ed3981a4c", "fitness": 0.0, "name": "AdaptiveHybridOptimizerV3", "description": "A self-adaptive hybrid algorithm blending Differential Evolution (DE), Particle Swarm Optimization (PSO) with an archive and dynamically adjusted parameters for exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_variant=\"rand/1/bin\"): # Added DE variant\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_variant = de_variant # Store DE variant\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n        archive_fitness = [] # Fitness values of individuals in archive\n\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE mutation strategy selection\n                if self.de_variant == \"rand/1/bin\":\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover between DE mutant and current individual\n                    trial = np.copy(population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.crossover_rate or j == j_rand:\n                            trial[j] = mutant_de[j]\n                elif self.de_variant == \"current-to-pbest/1\": #A different DE variant\n                    pbest_proportion = 0.1  # Top 10%\n                    pbest_size = max(1, int(self.population_size * pbest_proportion))\n                    pbest_indices = np.argsort(fitness)[:pbest_size]\n                    pbest_vector = population[np.random.choice(pbest_indices)]\n                    indices = np.random.choice(self.population_size, size=2, replace=False)\n\n                    mutant_de = population[i] + mutation_factor * (pbest_vector - population[i]) + mutation_factor * (population[indices[0]] - population[indices[1]])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n                    trial = mutant_de # No crossover\n                else:  # \"rand/1/bin\" fallback\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover between DE mutant and current individual\n                    trial = np.copy(population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.crossover_rate or j == j_rand:\n                            trial[j] = mutant_de[j]\n\n\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = trial + self.velocities[i] #Using trial instead of population[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    # Archive update: Replace worst in archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                        archive_fitness.append(fitness[i]) #Keep track of fitness values\n                    else:\n                        worst_index = np.argmax(archive_fitness) #Find the index of the worst individual\n                        if fitness[i] < archive_fitness[worst_index]:\n                            self.archive[worst_index] = population[i].copy()\n                            archive_fitness[worst_index] = fitness[i]\n\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                # Prune archive to archive_size, removing worst entries\n                archive_fitness = np.array(archive_fitness)\n                idx = np.argpartition(archive_fitness, len(self.archive) - self.archive_size)[len(self.archive) - self.archive_size:]\n                self.archive = [self.archive[i] for i in range(len(self.archive)) if i not in idx] #Keep better solutions\n                archive_fitness = archive_fitness[~np.isin(np.arange(len(archive_fitness)), idx)] #Filter fitness values\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: 'numpy.ndarray' object has no attribute 'append'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A self-adaptive hybrid algorithm blending Differential Evolution (DE), Particle Swarm Optimization (PSO) with an archive and dynamically adjusted parameters for exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 de_variant=\"rand/1/bin\"): # Added DE variant\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.de_variant = de_variant # Store DE variant\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n        archive_fitness = [] # Fitness values of individuals in archive\n\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n                # DE mutation strategy selection\n                if self.de_variant == \"rand/1/bin\":\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover between DE mutant and current individual\n                    trial = np.copy(population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.crossover_rate or j == j_rand:\n                            trial[j] = mutant_de[j]\n                elif self.de_variant == \"current-to-pbest/1\": #A different DE variant\n                    pbest_proportion = 0.1  # Top 10%\n                    pbest_size = max(1, int(self.population_size * pbest_proportion))\n                    pbest_indices = np.argsort(fitness)[:pbest_size]\n                    pbest_vector = population[np.random.choice(pbest_indices)]\n                    indices = np.random.choice(self.population_size, size=2, replace=False)\n\n                    mutant_de = population[i] + mutation_factor * (pbest_vector - population[i]) + mutation_factor * (population[indices[0]] - population[indices[1]])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n                    trial = mutant_de # No crossover\n                else:  # \"rand/1/bin\" fallback\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    if i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n\n                    mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                    mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                    # Crossover between DE mutant and current individual\n                    trial = np.copy(population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.crossover_rate or j == j_rand:\n                            trial[j] = mutant_de[j]\n\n\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = trial + self.velocities[i] #Using trial instead of population[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    # Archive update: Replace worst in archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                        archive_fitness.append(fitness[i]) #Keep track of fitness values\n                    else:\n                        worst_index = np.argmax(archive_fitness) #Find the index of the worst individual\n                        if fitness[i] < archive_fitness[worst_index]:\n                            self.archive[worst_index] = population[i].copy()\n                            archive_fitness[worst_index] = fitness[i]\n\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                # Prune archive to archive_size, removing worst entries\n                archive_fitness = np.array(archive_fitness)\n                idx = np.argpartition(archive_fitness, len(self.archive) - self.archive_size)[len(self.archive) - self.archive_size:]\n                self.archive = [self.archive[i] for i in range(len(self.archive)) if i not in idx] #Keep better solutions\n                archive_fitness = archive_fitness[~np.isin(np.arange(len(archive_fitness)), idx)] #Filter fitness values\n\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": -0.006599778132671666, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "12ac5458-0af3-4477-801e-bd23930de0e9", "fitness": 0.4729145671018765, "name": "GreedyDifferentialEvolution", "description": "A population-based algorithm that uses a combination of differential evolution mutation and a greedy selection process, dynamically adjusting mutation parameters based on population fitness.", "code": "import numpy as np\n\nclass GreedyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n    def mutate(self, population):\n        mutated_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n            mutated_population[i] = x_r1 + self.F * (x_r2 - x_r3)\n\n        return mutated_population\n\n    def crossover(self, population, mutated_population):\n        crossed_population = np.copy(population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR:\n                    crossed_population[i, j] = mutated_population[i, j]\n        return crossed_population\n\n    def greedy_selection(self, func, population, crossed_population):\n        new_population = np.copy(population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f_trial = func(crossed_population[i])\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f_trial\n            else:\n                pass # Keep the old one\n\n        return new_population, new_fitness\n\n\n    def update_mutation_factor(self, fitness):\n        # Dynamically adjust mutation factor based on fitness variance\n        fitness_std = np.std(fitness)\n        self.F = np.clip(self.F + 0.1 * (fitness_std - 0.1), 0.1, 0.9)\n        self.CR = np.clip(self.CR + 0.1 * (fitness_std - 0.1), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            mutated_population = self.mutate(self.population)\n\n            # Clip the mutated vectors\n            mutated_population = np.clip(mutated_population, func.bounds.lb, func.bounds.ub)\n            \n            crossed_population = self.crossover(self.population, mutated_population)\n\n            self.population, self.fitness = self.greedy_selection(func, self.population, crossed_population)\n            \n            self.update_mutation_factor(self.fitness)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GreedyDifferentialEvolution scored 0.473 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of differential evolution mutation and a greedy selection process, dynamically adjusting mutation parameters based on population fitness.\n# Code: \n```python\nimport numpy as np\n\nclass GreedyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n    def mutate(self, population):\n        mutated_population = np.copy(population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = population[idxs]\n            mutated_population[i] = x_r1 + self.F * (x_r2 - x_r3)\n\n        return mutated_population\n\n    def crossover(self, population, mutated_population):\n        crossed_population = np.copy(population)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.CR:\n                    crossed_population[i, j] = mutated_population[i, j]\n        return crossed_population\n\n    def greedy_selection(self, func, population, crossed_population):\n        new_population = np.copy(population)\n        new_fitness = np.copy(self.fitness)\n\n        for i in range(self.pop_size):\n            f_trial = func(crossed_population[i])\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = crossed_population[i]\n                new_fitness[i] = f_trial\n            else:\n                pass # Keep the old one\n\n        return new_population, new_fitness\n\n\n    def update_mutation_factor(self, fitness):\n        # Dynamically adjust mutation factor based on fitness variance\n        fitness_std = np.std(fitness)\n        self.F = np.clip(self.F + 0.1 * (fitness_std - 0.1), 0.1, 0.9)\n        self.CR = np.clip(self.CR + 0.1 * (fitness_std - 0.1), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            mutated_population = self.mutate(self.population)\n\n            # Clip the mutated vectors\n            mutated_population = np.clip(mutated_population, func.bounds.lb, func.bounds.ub)\n            \n            crossed_population = self.crossover(self.population, mutated_population)\n\n            self.population, self.fitness = self.greedy_selection(func, self.population, crossed_population)\n            \n            self.update_mutation_factor(self.fitness)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1608404661919145, 0.2774840445022311, 0.4367593282034894, 0.6991327551502797, 0.43694476795534287, 0.5570732797407831, 0.33322797777344426, 0.3942365967773612, 0.40969023999326404, 0.30425066710579896, 0.6490451582632553, 0.9997410300120507, 0.3362072029269285, 0.4337798909346702, 0.7367902917429261, 0.5768587159241896, 0.3410175684437058, 0.6713113243746137, 0.20618305753832378, 0.49771697848295693], "operator": "random_new", "theta_sampled": 0.10318067929969957, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "420e2781-4d8b-4de2-bac1-8ed2560e04eb", "fitness": 0.7017708185998309, "name": "EnhancedAdaptiveHybridOptimizer", "description": "An adaptive hybrid optimization algorithm combining DE, PSO with velocity clamping, and a self-organizing archive with population shrinking for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizer scored 0.702 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimization algorithm combining DE, PSO with velocity clamping, and a self-organizing archive with population shrinking for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.26374480676322754, 0.7004760288144267, 0.7819316144578221, 0.8911174025011488, 0.8292122141330297, 0.856629629325705, 0.6087520142846292, 0.6833331015398569, 0.8215452890827571, 0.7315943497120341, 0.8670709383693285, 0.9936333481551246, 0.4369676790688005, 0.6070987170723889, 0.9303893071831372, 0.829821435348342, 0.6042981622598966, 0.8807171771941076, 0.21188022496045344, 0.5052029317704037], "operator": "crossover", "theta_sampled": 0.007400865264094642, "reward": 0.029949062986549535, "generation": 4}, "task_prompt": ""}
{"id": "e36fa323-c84a-4ae6-84ec-286fad1424b3", "fitness": 0.14575738162980548, "name": "AdaptiveHybridOptimizerV3", "description": "An adaptive hybrid optimizer that dynamically adjusts its parameters and population size based on the problem's characteristics, leveraging both Differential Evolution (DE) and Particle Swarm Optimization (PSO) with a self-adaptive local search.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 local_search_rate=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        self.mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        self.mutation_factor = min(0.9, self.mutation_factor * 1.1)\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n                    \n                # Local search around the best solution\n                if np.random.rand() < self.local_search_rate:\n                    trial_local = self.global_best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    trial_local = np.clip(trial_local, func.bounds.lb, func.bounds.ub)\n                    f_trial_local = func(trial_local)\n                    self.eval_count += 1\n\n                    if f_trial_local < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_local\n                        self.global_best_position = trial_local.copy()\n                        self.f_opt = f_trial_local\n                        self.x_opt = trial_local\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV3 scored 0.146 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimizer that dynamically adjusts its parameters and population size based on the problem's characteristics, leveraging both Differential Evolution (DE) and Particle Swarm Optimization (PSO) with a self-adaptive local search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 local_search_rate=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.local_search_rate = local_search_rate\n        self.local_search_radius = local_search_radius\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        self.mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        self.mutation_factor = min(0.9, self.mutation_factor * 1.1)\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n                    \n                # Local search around the best solution\n                if np.random.rand() < self.local_search_rate:\n                    trial_local = self.global_best_position + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    trial_local = np.clip(trial_local, func.bounds.lb, func.bounds.ub)\n                    f_trial_local = func(trial_local)\n                    self.eval_count += 1\n\n                    if f_trial_local < self.global_best_fitness:\n                        self.global_best_fitness = f_trial_local\n                        self.global_best_position = trial_local.copy()\n                        self.f_opt = f_trial_local\n                        self.x_opt = trial_local\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1455422062697036, 0.29172993861971286, 0], "operator": "mutation", "theta_sampled": 0.09850213819275916, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "74c863eb-39d1-4720-8a66-beeb1b6d4a27", "fitness": 0.0, "name": "AdaptiveLocalSearch", "description": "Population-based algorithm with adaptive mutation and crossover, focusing on local search intensification.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_radius = local_search_radius\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Selection (tournament selection)\n            selected_indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True)\n            parents = population[selected_indices]\n            parent_fitness = fitness[selected_indices]\n\n            # Crossover (uniform crossover)\n            offspring = parents.copy()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.crossover_rate:\n                    j = np.random.randint(self.pop_size)\n                    mask = np.random.rand(self.dim) < 0.5\n                    offspring[i, mask] = parents[j, mask]\n\n            # Mutation (adaptive mutation)\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_direction = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    offspring[i] = np.clip(offspring[i] + mutation_direction, func.bounds.lb, func.bounds.ub)\n\n            # Local Search (around best individual)\n            best_individual = population[best_index].copy()\n            local_search_points = np.random.uniform(\n                low=np.maximum(func.bounds.lb, best_individual - self.local_search_radius),\n                high=np.minimum(func.bounds.ub, best_individual + self.local_search_radius),\n                size=(min(self.budget, self.pop_size), self.dim)\n            )\n            local_search_fitness = np.array([func(x) for x in local_search_points])\n            self.budget -= len(local_search_points)\n\n            best_local_index = np.argmin(local_search_fitness)\n            if local_search_fitness[best_local_index] < fitness[best_index]:\n                offspring[best_index] = local_search_points[best_local_index]\n\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Update population\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adjust mutation rate\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-6:  # Stagnation\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.2)\n                    self.local_search_radius = min(1.0, self.local_search_radius * 1.1)  # Increase search radius\n                else:\n                    self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                    self.local_search_radius = max(0.01, self.local_search_radius * 0.9)  # Reduce search radius\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive mutation and crossover, focusing on local search intensification.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_radius = local_search_radius\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Selection (tournament selection)\n            selected_indices = np.random.choice(self.pop_size, size=self.pop_size, replace=True)\n            parents = population[selected_indices]\n            parent_fitness = fitness[selected_indices]\n\n            # Crossover (uniform crossover)\n            offspring = parents.copy()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.crossover_rate:\n                    j = np.random.randint(self.pop_size)\n                    mask = np.random.rand(self.dim) < 0.5\n                    offspring[i, mask] = parents[j, mask]\n\n            # Mutation (adaptive mutation)\n            for i in range(self.pop_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_direction = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                    offspring[i] = np.clip(offspring[i] + mutation_direction, func.bounds.lb, func.bounds.ub)\n\n            # Local Search (around best individual)\n            best_individual = population[best_index].copy()\n            local_search_points = np.random.uniform(\n                low=np.maximum(func.bounds.lb, best_individual - self.local_search_radius),\n                high=np.minimum(func.bounds.ub, best_individual + self.local_search_radius),\n                size=(min(self.budget, self.pop_size), self.dim)\n            )\n            local_search_fitness = np.array([func(x) for x in local_search_points])\n            self.budget -= len(local_search_points)\n\n            best_local_index = np.argmin(local_search_fitness)\n            if local_search_fitness[best_local_index] < fitness[best_index]:\n                offspring[best_index] = local_search_points[best_local_index]\n\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Update population\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Adjust mutation rate\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-6:  # Stagnation\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.2)\n                    self.local_search_radius = min(1.0, self.local_search_radius * 1.1)  # Increase search radius\n                else:\n                    self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                    self.local_search_radius = max(0.01, self.local_search_radius * 0.9)  # Reduce search radius\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.21737280810901582, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "c962a7bd-c841-44b5-afcb-2b24eb975ffe", "fitness": 0.5604934241315144, "name": "AdaptiveDifferentialEvolution", "description": "Population-based algorithm with adaptive mutation and crossover, focusing on exploration in early stages and exploitation in later stages using a modified differential evolution strategy.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR # Crossover probability\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size # Account for initial evaluations\n\n    def mutate(self, pop, F, best_idx):\n        mutated_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.9: # Adaptive mutation probability\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutated_pop[i] = pop[i] + F * (pop[best_idx] - pop[i]) + F * (pop[a] - pop[b]) # Mutation based on best\n\n                #Alternative Mutuation\n                #if np.random.rand() < 0.5:\n                #    mutated_pop[i] = pop[i] + F * (pop[best_idx] - pop[i])\n\n            mutated_pop[i] = np.clip(mutated_pop[i], self.lb, self.ub)\n        return mutated_pop\n\n\n    def crossover(self, pop, mutated_pop, CR):\n        crossed_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n        return crossed_pop\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            \n            best_idx = np.argmin(self.fitness)\n            mutated_pop = self.mutate(self.population, self.F, best_idx)\n            crossed_pop = self.crossover(self.population, mutated_pop, self.CR)\n            \n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = crossed_pop[i]\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = crossed_pop[i]\n\n\n            #Adaptive F and CR (Reduce Exploration)\n            self.F = max(0.1, self.F * 0.99)\n            self.CR = max(0.2, self.CR * 0.99)\n\n            #Early restart Mechanism\n            if self.eval_count < self.budget * 0.2:\n              if np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive mutation and crossover, focusing on exploration in early stages and exploitation in later stages using a modified differential evolution strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR # Crossover probability\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size # Account for initial evaluations\n\n    def mutate(self, pop, F, best_idx):\n        mutated_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            if np.random.rand() < 0.9: # Adaptive mutation probability\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutated_pop[i] = pop[i] + F * (pop[best_idx] - pop[i]) + F * (pop[a] - pop[b]) # Mutation based on best\n\n                #Alternative Mutuation\n                #if np.random.rand() < 0.5:\n                #    mutated_pop[i] = pop[i] + F * (pop[best_idx] - pop[i])\n\n            mutated_pop[i] = np.clip(mutated_pop[i], self.lb, self.ub)\n        return mutated_pop\n\n\n    def crossover(self, pop, mutated_pop, CR):\n        crossed_pop = np.copy(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR:\n                    crossed_pop[i, j] = mutated_pop[i, j]\n        return crossed_pop\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            \n            best_idx = np.argmin(self.fitness)\n            mutated_pop = self.mutate(self.population, self.F, best_idx)\n            crossed_pop = self.crossover(self.population, mutated_pop, self.CR)\n            \n            new_fitness = np.array([func(x) for x in crossed_pop])\n            self.eval_count += self.pop_size\n\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.fitness[i]:\n                    self.fitness[i] = new_fitness[i]\n                    self.population[i] = crossed_pop[i]\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = crossed_pop[i]\n\n\n            #Adaptive F and CR (Reduce Exploration)\n            self.F = max(0.1, self.F * 0.99)\n            self.CR = max(0.2, self.CR * 0.99)\n\n            #Early restart Mechanism\n            if self.eval_count < self.budget * 0.2:\n              if np.std(self.fitness) < 1e-6:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size\n                \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21239365202764415, 0.34681657586369286, 0.5517624268939689, 0.8617055654318608, 0.5963176702321893, 0.7257046201668338, 0.36263109067071886, 0.5079668067480474, 0.6509429260702381, 0.2781572501639671, 0.8740879130410324, 0.9981635762561106, 0.29546303078127834, 0.5219653770617431, 0.7504876992213987, 0.6551953504982657, 0.4807429543346501, 0.841318791336427, 0.20760228067060205, 0.49044292515961796], "operator": "random_new", "theta_sampled": 0.14932323056676577, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "8362479b-34b2-4764-82d2-84ad729a1446", "fitness": 0.6816483372046273, "name": "EnhancedAdaptiveHybridOptimizerV3", "description": "A hybrid optimizer that combines adaptive differential evolution, particle swarm optimization with velocity clamping, and a dynamic archive, with periodic re-initialization to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion # Proportion of population to re-initialize\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization\n            if self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizerV3 scored 0.682 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid optimizer that combines adaptive differential evolution, particle swarm optimization with velocity clamping, and a dynamic archive, with periodic re-initialization to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion # Proportion of population to re-initialize\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization\n            if self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.24083332649143563, 0.3651661587104811, 0.8059309089094223, 0.8807046836016797, 0.7236553636719862, 0.8639284325850507, 0.33701986778042914, 0.719714921782681, 0.8433266965555091, 0.7248072022960446, 0.8972942118049764, 0.9999149331854944, 0.5080676999422247, 0.7004644202448871, 0.9216793345048672, 0.8502285619338384, 0.5877560085045079, 0.8813190018163316, 0.2869965172702853, 0.494158492500414], "operator": "crossover", "theta_sampled": 0.006624616891930491, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "f9992b76-0232-4ed0-abae-31a3e5798265", "fitness": 0.0, "name": "EnhancedAdaptiveHybridOptimizerV3", "description": "A hybrid optimization algorithm combining DE, PSO, and a local search inspired by CMA-ES with adaptive parameter control and population shrinkage.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 local_search_probability=0.05, local_search_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.local_search_probability = local_search_probability\n        self.local_search_step_size = local_search_step_size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Local search around the trial solution\n                if np.random.rand() < self.local_search_probability:\n                    step = np.random.normal(0, self.local_search_step_size, self.dim)\n                    local_trial = trial + step\n                    local_trial = np.clip(local_trial, func.bounds.lb, func.bounds.ub)\n                    f_local_trial = func(local_trial)\n                    self.eval_count += 1\n                    if f_local_trial < func(trial):\n                        trial = local_trial\n                        f_trial = f_local_trial\n                    else:\n                         f_trial = func(trial)  # Ensure f_trial is evaluated if local search fails\n                         self.eval_count += 1 # Ensure eval_count is updated when local search fails\n\n\n                else:\n                    # Evaluation\n                    f_trial = func(trial)\n                    self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizerV3 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid optimization algorithm combining DE, PSO, and a local search inspired by CMA-ES with adaptive parameter control and population shrinkage.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 local_search_probability=0.05, local_search_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.local_search_probability = local_search_probability\n        self.local_search_step_size = local_search_step_size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Local search around the trial solution\n                if np.random.rand() < self.local_search_probability:\n                    step = np.random.normal(0, self.local_search_step_size, self.dim)\n                    local_trial = trial + step\n                    local_trial = np.clip(local_trial, func.bounds.lb, func.bounds.ub)\n                    f_local_trial = func(local_trial)\n                    self.eval_count += 1\n                    if f_local_trial < func(trial):\n                        trial = local_trial\n                        f_trial = f_local_trial\n                    else:\n                         f_trial = func(trial)  # Ensure f_trial is evaluated if local search fails\n                         self.eval_count += 1 # Ensure eval_count is updated when local search fails\n\n\n                else:\n                    # Evaluation\n                    f_trial = func(trial)\n                    self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.013943820116169358, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "9c231056-1b2c-42fd-8735-a851ba5bbfe3", "fitness": 0.0, "name": "DynamicInertiaPSO", "description": "A population-based algorithm that uses a simplified particle swarm optimization (PSO) variant with dynamic inertia weight and a local search operator for intensification.", "code": "import numpy as np\n\nclass DynamicInertiaPSO:\n    def __init__(self, budget=10000, dim=10, population_size=20, w_max=0.9, w_min=0.4, c=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c = c  # Local search probability\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0 # Keep track of function evaluations\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.population_size, self.dim)) # Reasonable velocity initialization\n\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.population_size # Increase the evaluation count\n\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_inertia_weight(self):\n        # Linearly decreasing inertia weight\n        return self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n    def local_search(self, x, func):\n        # Small random perturbation for local search\n        x_new = x + np.random.normal(0, 0.1, size=self.dim) # Standard deviation of 0.1\n\n        # Clip to ensure the solution remains within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        x_new = np.clip(x_new, lb, ub)\n\n        f_new = func(x_new)\n        self.eval_count += 1\n        return x_new, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            w = self.update_inertia_weight()\n\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                velocity = w * self.velocities[i] + 2.0 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                           2.0 * (1-r1) * (self.global_best_position - self.particles[i])\n                self.velocities[i] = velocity\n                \n                # Update position\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], lb, ub)\n                \n\n                # Evaluate new position\n                f = func(self.particles[i])\n                self.eval_count += 1\n                \n                #Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                    \n                    # Update global best if necessary\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.particles[i].copy()\n\n                # Local Search\n                if np.random.rand() < self.c and self.eval_count < self.budget: # Check if we still have budget to evaluate function.\n                    x_new, f_new = self.local_search(self.particles[i].copy(), func)\n                    if f_new < f:\n                        self.particles[i] = x_new.copy()\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.particles[i].copy()\n                        \n                        if f_new < self.global_best_fitness:\n                            self.global_best_fitness = f_new\n                            self.global_best_position = self.particles[i].copy()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicInertiaPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that uses a simplified particle swarm optimization (PSO) variant with dynamic inertia weight and a local search operator for intensification.\n# Code: \n```python\nimport numpy as np\n\nclass DynamicInertiaPSO:\n    def __init__(self, budget=10000, dim=10, population_size=20, w_max=0.9, w_min=0.4, c=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c = c  # Local search probability\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0 # Keep track of function evaluations\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.population_size, self.dim)) # Reasonable velocity initialization\n\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.population_size # Increase the evaluation count\n\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_inertia_weight(self):\n        # Linearly decreasing inertia weight\n        return self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n    def local_search(self, x, func):\n        # Small random perturbation for local search\n        x_new = x + np.random.normal(0, 0.1, size=self.dim) # Standard deviation of 0.1\n\n        # Clip to ensure the solution remains within bounds\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        x_new = np.clip(x_new, lb, ub)\n\n        f_new = func(x_new)\n        self.eval_count += 1\n        return x_new, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            w = self.update_inertia_weight()\n\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                velocity = w * self.velocities[i] + 2.0 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                           2.0 * (1-r1) * (self.global_best_position - self.particles[i])\n                self.velocities[i] = velocity\n                \n                # Update position\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], lb, ub)\n                \n\n                # Evaluate new position\n                f = func(self.particles[i])\n                self.eval_count += 1\n                \n                #Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                    \n                    # Update global best if necessary\n                    if f < self.global_best_fitness:\n                        self.global_best_fitness = f\n                        self.global_best_position = self.particles[i].copy()\n\n                # Local Search\n                if np.random.rand() < self.c and self.eval_count < self.budget: # Check if we still have budget to evaluate function.\n                    x_new, f_new = self.local_search(self.particles[i].copy(), func)\n                    if f_new < f:\n                        self.particles[i] = x_new.copy()\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.particles[i].copy()\n                        \n                        if f_new < self.global_best_fitness:\n                            self.global_best_fitness = f_new\n                            self.global_best_position = self.particles[i].copy()\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.0830665974304312, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "24dd7664-0675-4042-a6e7-279f8f14ee53", "fitness": 0.0, "name": "EnhancedAdaptiveHybridOptimizerV2", "description": "Integrates a local search (Nelder-Mead) component with adaptive restarts based on stagnation detection to enhance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 stagnation_threshold=1000, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_probability = restart_probability\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n        self.last_improvement = self.eval_count\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement = self.eval_count\n                else:\n                    self.success_history.append(0)\n\n            # Stagnation check and local search/restart\n            if self.eval_count - self.last_improvement > self.stagnation_threshold:\n                # Apply Nelder-Mead to the global best\n                res = minimize(func, self.global_best_position, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': self.stagnation_threshold // 5})\n                \n                if res.fun < self.global_best_fitness:\n                    self.global_best_fitness = res.fun\n                    self.global_best_position = res.x\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.last_improvement = self.eval_count\n                self.eval_count += res.nfev\n                \n                # Restart with some probability\n                if np.random.rand() < self.restart_probability:\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.eval_count += self.population_size\n                    \n                    self.personal_best_positions = population.copy()\n                    self.personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    \n                    if fitness[global_best_index] < self.global_best_fitness:\n                        self.global_best_position = population[global_best_index].copy()\n                        self.global_best_fitness = fitness[global_best_index]\n                        self.f_opt = fitness[global_best_index]\n                        self.x_opt = population[global_best_index]\n                        self.last_improvement = self.eval_count\n                    \n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates a local search (Nelder-Mead) component with adaptive restarts based on stagnation detection to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridOptimizerV2:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 stagnation_threshold=1000, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_probability = restart_probability\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n        self.last_improvement = self.eval_count\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement = self.eval_count\n                else:\n                    self.success_history.append(0)\n\n            # Stagnation check and local search/restart\n            if self.eval_count - self.last_improvement > self.stagnation_threshold:\n                # Apply Nelder-Mead to the global best\n                res = minimize(func, self.global_best_position, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': self.stagnation_threshold // 5})\n                \n                if res.fun < self.global_best_fitness:\n                    self.global_best_fitness = res.fun\n                    self.global_best_position = res.x\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    self.last_improvement = self.eval_count\n                self.eval_count += res.nfev\n                \n                # Restart with some probability\n                if np.random.rand() < self.restart_probability:\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.eval_count += self.population_size\n                    \n                    self.personal_best_positions = population.copy()\n                    self.personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    \n                    if fitness[global_best_index] < self.global_best_fitness:\n                        self.global_best_position = population[global_best_index].copy()\n                        self.global_best_fitness = fitness[global_best_index]\n                        self.f_opt = fitness[global_best_index]\n                        self.x_opt = population[global_best_index]\n                        self.last_improvement = self.eval_count\n                    \n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.056619824727491753, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "c57d7de2-babc-4fa4-be3c-3c0e71404d22", "fitness": 0.0, "name": "AdaptiveHybridOptimizerV3", "description": "Integrates a restart mechanism based on stagnation detection and an enhanced mutation strategy with a self-adaptive archive to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 stagnation_threshold=1000, stagnation_reset_proportion=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reset_proportion = stagnation_reset_proportion\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement_eval = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n        self.last_improvement_eval = self.eval_count\n\n\n        while self.eval_count < self.budget:\n            # Stagnation Check and Restart\n            if self.eval_count - self.last_improvement_eval > self.stagnation_threshold:\n                # Reset a portion of the population around the best solution\n                num_reset = int(self.population_size * self.stagnation_reset_proportion)\n                indices_to_reset = np.random.choice(self.population_size, num_reset, replace=False)\n                population[indices_to_reset] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reset, self.dim))\n                fitness[indices_to_reset] = np.array([func(x) for x in population[indices_to_reset]])\n                self.eval_count += num_reset\n                \n                #Update personal bests for reset individuals\n                self.personal_best_positions[indices_to_reset] = population[indices_to_reset].copy()\n                self.personal_best_fitness[indices_to_reset] = fitness[indices_to_reset].copy()\n                \n                # Potentially update global best\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.global_best_fitness:\n                    self.global_best_fitness = fitness[best_index]\n                    self.global_best_position = population[best_index].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n                    self.last_improvement_eval = self.eval_count\n\n                else:\n                    self.last_improvement_eval = self.eval_count  # Reset stagnation timer even if global best isn't updated\n                \n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                #Enhanced mutation strategy\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1]) + np.random.normal(0, 0.01, self.dim)  # Add small Gaussian noise\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    # Self-adaptive archive update strategy\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace the worst element in the archive\n                        archive_fitness = [func(x) for x in self.archive]\n                        worst_index = np.argmax(archive_fitness)\n                        self.archive[worst_index] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement_eval = self.eval_count\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV3 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates a restart mechanism based on stagnation detection and an enhanced mutation strategy with a self-adaptive archive to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 stagnation_threshold=1000, stagnation_reset_proportion=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reset_proportion = stagnation_reset_proportion\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement_eval = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n        self.last_improvement_eval = self.eval_count\n\n\n        while self.eval_count < self.budget:\n            # Stagnation Check and Restart\n            if self.eval_count - self.last_improvement_eval > self.stagnation_threshold:\n                # Reset a portion of the population around the best solution\n                num_reset = int(self.population_size * self.stagnation_reset_proportion)\n                indices_to_reset = np.random.choice(self.population_size, num_reset, replace=False)\n                population[indices_to_reset] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reset, self.dim))\n                fitness[indices_to_reset] = np.array([func(x) for x in population[indices_to_reset]])\n                self.eval_count += num_reset\n                \n                #Update personal bests for reset individuals\n                self.personal_best_positions[indices_to_reset] = population[indices_to_reset].copy()\n                self.personal_best_fitness[indices_to_reset] = fitness[indices_to_reset].copy()\n                \n                # Potentially update global best\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.global_best_fitness:\n                    self.global_best_fitness = fitness[best_index]\n                    self.global_best_position = population[best_index].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n                    self.last_improvement_eval = self.eval_count\n\n                else:\n                    self.last_improvement_eval = self.eval_count  # Reset stagnation timer even if global best isn't updated\n                \n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                #Enhanced mutation strategy\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1]) + np.random.normal(0, 0.01, self.dim)  # Add small Gaussian noise\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    # Self-adaptive archive update strategy\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        # Replace the worst element in the archive\n                        archive_fitness = [func(x) for x in self.archive]\n                        worst_index = np.argmax(archive_fitness)\n                        self.archive[worst_index] = population[i].copy()\n\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement_eval = self.eval_count\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.13988080663132982, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2b9b6942-8727-482e-8945-0a4cef1e1156", "fitness": 0.31210447209427783, "name": "HybridSwarmDE", "description": "A population-based algorithm that combines particle swarm optimization with differential evolution mutation, selecting the better of the two update strategies for each particle.", "code": "import numpy as np\n\nclass HybridSwarmDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate for DE\n        self.f = f  # Mutation factor for DE\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def pso_update(self, particle_index):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[particle_index] - self.population[particle_index])\n        social_component = self.c2 * r2 * (self.global_best_position - self.population[particle_index])\n\n        self.velocities[particle_index] = self.w * self.velocities[particle_index] + cognitive_component + social_component\n        new_position = self.population[particle_index] + self.velocities[particle_index]\n        return new_position\n\n    def de_update(self, particle_index):\n        # Differential Evolution Mutation and Crossover\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while particle_index in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x1, x2, x3 = self.population[idxs[0]], self.population[idxs[1]], self.population[idxs[2]]\n        v = x1 + self.f * (x2 - x3)\n        \n        # Crossover\n        j_rand = np.random.randint(self.dim)\n        new_position = self.population[particle_index].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                new_position[j] = v[j]\n        return new_position\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Choose between PSO and DE update\n                if np.random.rand() < 0.5:  # 50% probability for PSO\n                    new_position = self.pso_update(i)\n                else:\n                    new_position = self.de_update(i)\n                    \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.population[i] = new_position # Update position for next iteration\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridSwarmDE scored 0.312 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that combines particle swarm optimization with differential evolution mutation, selecting the better of the two update strategies for each particle.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSwarmDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate for DE\n        self.f = f  # Mutation factor for DE\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def pso_update(self, particle_index):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions[particle_index] - self.population[particle_index])\n        social_component = self.c2 * r2 * (self.global_best_position - self.population[particle_index])\n\n        self.velocities[particle_index] = self.w * self.velocities[particle_index] + cognitive_component + social_component\n        new_position = self.population[particle_index] + self.velocities[particle_index]\n        return new_position\n\n    def de_update(self, particle_index):\n        # Differential Evolution Mutation and Crossover\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while particle_index in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x1, x2, x3 = self.population[idxs[0]], self.population[idxs[1]], self.population[idxs[2]]\n        v = x1 + self.f * (x2 - x3)\n        \n        # Crossover\n        j_rand = np.random.randint(self.dim)\n        new_position = self.population[particle_index].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                new_position[j] = v[j]\n        return new_position\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Choose between PSO and DE update\n                if np.random.rand() < 0.5:  # 50% probability for PSO\n                    new_position = self.pso_update(i)\n                else:\n                    new_position = self.de_update(i)\n                    \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                    if new_fitness < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness\n                        self.global_best_position = new_position.copy()\n\n                self.population[i] = new_position # Update position for next iteration\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.12909463586654624, 0.20245464875929298, 0.2912805002770169, 0.2828057607758324, 0.23354227105186287, 0.27105250475773, 0.2554482136910303, 0.20128802856878425, 0.24236901090992535, 0.1931314381711149, 0.26092159356021616, 0.9987617446673643, 0.26766003134295346, 0.24053112564337842, 0.6398945880062101, 0.29396795678386656, 0.2503558307079512, 0.35372747942324756, 0.16482436130823697, 0.46897771761299556], "operator": "random_new", "theta_sampled": 0.44176279618855024, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "60effc17-62fd-4e1f-9d63-add315ac851c", "fitness": 0.20636321629309928, "name": "InformationDiffusionOptimizer", "description": "A population-based algorithm inspired by the diffusion of information in a network, where solutions exchange information based on their fitness.", "code": "import numpy as np\n\nclass InformationDiffusionOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=20, diffusion_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.diffusion_rate = diffusion_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Diffusion process: Each solution exchanges information with a better solution\n            for i in range(self.population_size):\n                # Select a better solution to learn from (weighted probability)\n                weights = np.arange(self.population_size, 0, -1)  # Give higher weight to better solutions\n                weights = weights / np.sum(weights)\n                \n                # Ensure that better solutions don't learn from worse ones\n                if i > 0:  \n                    weights[i:] = 0\n                    weights = weights / np.sum(weights) # renormalize\n                \n                \n                learner_index = np.random.choice(range(self.population_size), p=weights)\n\n                # Diffusion: Update solution based on the difference between the two solutions\n                diffusion_vector = (population[learner_index] - population[i]) * self.diffusion_rate\n                new_solution = population[i] + diffusion_vector\n\n                # Clip to bounds\n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                self.budget -= 1\n\n                # Update if better\n                if new_fitness < fitness[i]:\n                    population[i] = new_solution\n                    fitness[i] = new_fitness\n\n                    # Update overall best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_solution\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n              self.f_opt = fitness[best_index]\n              self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm InformationDiffusionOptimizer scored 0.206 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm inspired by the diffusion of information in a network, where solutions exchange information based on their fitness.\n# Code: \n```python\nimport numpy as np\n\nclass InformationDiffusionOptimizer:\n    def __init__(self, budget=10000, dim=10, population_size=20, diffusion_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.diffusion_rate = diffusion_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Diffusion process: Each solution exchanges information with a better solution\n            for i in range(self.population_size):\n                # Select a better solution to learn from (weighted probability)\n                weights = np.arange(self.population_size, 0, -1)  # Give higher weight to better solutions\n                weights = weights / np.sum(weights)\n                \n                # Ensure that better solutions don't learn from worse ones\n                if i > 0:  \n                    weights[i:] = 0\n                    weights = weights / np.sum(weights) # renormalize\n                \n                \n                learner_index = np.random.choice(range(self.population_size), p=weights)\n\n                # Diffusion: Update solution based on the difference between the two solutions\n                diffusion_vector = (population[learner_index] - population[i]) * self.diffusion_rate\n                new_solution = population[i] + diffusion_vector\n\n                # Clip to bounds\n                new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                self.budget -= 1\n\n                # Update if better\n                if new_fitness < fitness[i]:\n                    population[i] = new_solution\n                    fitness[i] = new_fitness\n\n                    # Update overall best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_solution\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n              self.f_opt = fitness[best_index]\n              self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.09975034294015694, 0.16992538338531626, 0.2918541636770374, 0.16415788234074902, 0.17071696096318756, 0.16300316280533556, 0.21517472082053246, 0.1088125300452022, 0.19267410898738346, 0.1589778149915566, 0.2528553001595497, 0.2294205049817355, 0.22409364931770637, 0.2061165746725866, 0.1391239944528495, 0.26965842830370934, 0.23296571892160933, 0.214257554481747, 0.16187955568886192, 0.4618459739251727], "operator": "random_new", "theta_sampled": 0.45847753156417625, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "8418e398-3377-4b01-aa57-d27a7df13cfa", "fitness": 0.0, "name": "SOM_DE_PSO", "description": "Integrates a self-organizing map (SOM) to adaptively adjust the population distribution, combined with DE and PSO elements for exploration and exploitation.", "code": "import numpy as np\nfrom minisom import MiniSom  # Requires pip install MiniSom\n\nclass SOM_DE_PSO:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 som_grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.som_grid_size = som_grid_size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize SOM\n        som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        som.train(population, 100) # Train SOM with initial population\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Retrain SOM periodically to adapt to population changes\n            if self.eval_count % (self.budget // 10) == 0:\n                 som.train(population, 50)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n\n                # SOM-guided PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n\n                    # Perturb based on SOM neighborhood\n                    winner = som.winner(population[i])\n                    neighborhood = som.neighborhood(winner, sigma=1)\n                    for x in range(self.som_grid_size):\n                        for y in range(self.som_grid_size):\n                            if neighborhood[x, y] > 0:\n                                som_vector = som.get_weights()[x, y]\n                                trial += 0.1 * neighborhood[x, y] * (som_vector - population[i])\n\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: No module named 'minisom'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates a self-organizing map (SOM) to adaptively adjust the population distribution, combined with DE and PSO elements for exploration and exploitation.\n# Code:\n```python\nimport numpy as np\nfrom minisom import MiniSom  # Requires pip install MiniSom\n\nclass SOM_DE_PSO:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 som_grid_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.som_grid_size = som_grid_size\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize SOM\n        som = MiniSom(self.som_grid_size, self.som_grid_size, self.dim, sigma=0.3, learning_rate=0.5)\n        som.train(population, 100) # Train SOM with initial population\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Retrain SOM periodically to adapt to population changes\n            if self.eval_count % (self.budget // 10) == 0:\n                 som.train(population, 50)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (DE part)\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n\n                # SOM-guided PSO Mutation\n                if np.random.rand() < self.pso_mutation_rate:\n                    inertia = inertia_weight * self.velocities[i]\n                    cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                    social = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - population[i])  # Using global best\n                    self.velocities[i] = inertia + cognitive + social\n                    trial = population[i] + self.velocities[i]\n\n                    # Perturb based on SOM neighborhood\n                    winner = som.winner(population[i])\n                    neighborhood = som.neighborhood(winner, sigma=1)\n                    for x in range(self.som_grid_size):\n                        for y in range(self.som_grid_size):\n                            if neighborhood[x, y] > 0:\n                                som_vector = som.get_weights()[x, y]\n                                trial += 0.1 * neighborhood[x, y] * (som_vector - population[i])\n\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)  # clip bounds\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    personal_best_fitness[i] = f_trial\n                    personal_best_positions[i] = trial.copy()\n\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                personal_best_positions = personal_best_positions[idx]\n                personal_best_fitness = personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.32456584328748905, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "d9696bf3-d850-4808-b0bb-3037f6af1057", "fitness": 0.0, "name": "EnhancedAdaptiveHybridOptimizerV4", "description": "Integrates adaptive mutation, velocity clamping, periodic re-initialization, and dynamic population shrinking within a hybrid Differential Evolution (DE) and Particle Swarm Optimization (PSO) framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion  # Proportion of population to re-initialize\n        self.local_search_prob = local_search_prob # Probability of applying local search\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    direction = direction / np.linalg.norm(direction)\n                    trial_local = trial + step_size * direction\n                    trial_local = np.clip(trial_local, func.bounds.lb, func.bounds.ub)\n\n                    f_trial_local = func(trial_local)\n                    self.eval_count += 1\n                    if f_trial_local < func(trial):\n                         trial = trial_local\n                         \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization\n            if self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizerV4 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates adaptive mutation, velocity clamping, periodic re-initialization, and dynamic population shrinking within a hybrid Differential Evolution (DE) and Particle Swarm Optimization (PSO) framework.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion  # Proportion of population to re-initialize\n        self.local_search_prob = local_search_prob # Probability of applying local search\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    direction = direction / np.linalg.norm(direction)\n                    trial_local = trial + step_size * direction\n                    trial_local = np.clip(trial_local, func.bounds.lb, func.bounds.ub)\n\n                    f_trial_local = func(trial_local)\n                    self.eval_count += 1\n                    if f_trial_local < func(trial):\n                         trial = trial_local\n                         \n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization\n            if self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.01680799094589816, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "de28c00f-3d85-4b2a-a3dd-ef7ccb43fd69", "fitness": 0.6237483261748376, "name": "SelfAdaptiveHybridOptimizer", "description": "Combines a self-adaptive Differential Evolution (SaDE) inspired mutation with Particle Swarm Optimization (PSO) and an external archive, dynamically adjusting parameters and population size.", "code": "import numpy as np\n\nclass SelfAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, archive_proportion=0.2,\n                 mutation_strategy_probs=None):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        # SaDE-inspired mutation strategy probabilities\n        if mutation_strategy_probs is None:\n            self.mutation_strategy_probs = np.array([0.3, 0.3, 0.4])  # Probabilities for DE/rand/1, DE/current-to-rand/1, and DE/best/1\n        else:\n            self.mutation_strategy_probs = np.array(mutation_strategy_probs)\n        self.mutation_strategy_probs /= np.sum(self.mutation_strategy_probs)  # Normalize\n        self.strategy_successes = np.zeros_like(self.mutation_strategy_probs)\n        self.strategy_counts = np.zeros_like(self.mutation_strategy_probs)\n        self.learning_rate = 0.1  # Learning rate for updating strategy probabilities\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Select mutation strategy based on probabilities\n                strategy_index = np.random.choice(len(self.mutation_strategy_probs), p=self.mutation_strategy_probs)\n                self.strategy_counts[strategy_index] += 1\n\n                # Mutation strategy implementation\n                if strategy_index == 0:  # DE/rand/1 with archive\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                elif strategy_index == 1:  # DE/current-to-rand/1\n                    idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    while i in idx:\n                        idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[idx]\n                    mutant_de = population[i] + self.mutation_factor * (np.random.rand(self.dim) * (vectors[0] - population[i]) + (vectors[1] - vectors[0]))\n\n                else:  # DE/best/1\n                    idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    while i in idx:\n                        idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[idx]\n                    mutant_de = population[i] + self.mutation_factor * (self.global_best_position - population[i]) + self.mutation_factor * (vectors[0] - vectors[1])\n\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    self.strategy_successes[strategy_index] += 1\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Update mutation strategy probabilities (SaDE adaptation)\n            success_rates = self.strategy_successes / (self.strategy_counts + 1e-6) #avoid division by zero\n            for k in range(len(self.mutation_strategy_probs)):\n                self.mutation_strategy_probs[k] += self.learning_rate * (success_rates[k] - np.mean(success_rates))\n            self.mutation_strategy_probs = np.maximum(0, self.mutation_strategy_probs) # Ensure non-negative probabilities\n            self.mutation_strategy_probs /= np.sum(self.mutation_strategy_probs) # Normalize\n\n            self.strategy_successes[:] = 0\n            self.strategy_counts[:] = 0\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveHybridOptimizer scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines a self-adaptive Differential Evolution (SaDE) inspired mutation with Particle Swarm Optimization (PSO) and an external archive, dynamically adjusting parameters and population size.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, archive_proportion=0.2,\n                 mutation_strategy_probs=None):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        # SaDE-inspired mutation strategy probabilities\n        if mutation_strategy_probs is None:\n            self.mutation_strategy_probs = np.array([0.3, 0.3, 0.4])  # Probabilities for DE/rand/1, DE/current-to-rand/1, and DE/best/1\n        else:\n            self.mutation_strategy_probs = np.array(mutation_strategy_probs)\n        self.mutation_strategy_probs /= np.sum(self.mutation_strategy_probs)  # Normalize\n        self.strategy_successes = np.zeros_like(self.mutation_strategy_probs)\n        self.strategy_counts = np.zeros_like(self.mutation_strategy_probs)\n        self.learning_rate = 0.1  # Learning rate for updating strategy probabilities\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Select mutation strategy based on probabilities\n                strategy_index = np.random.choice(len(self.mutation_strategy_probs), p=self.mutation_strategy_probs)\n                self.strategy_counts[strategy_index] += 1\n\n                # Mutation strategy implementation\n                if strategy_index == 0:  # DE/rand/1 with archive\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[indices]\n                    mutant_de = population[i] + self.mutation_factor * (vectors[0] - vectors[1])\n                elif strategy_index == 1:  # DE/current-to-rand/1\n                    idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    while i in idx:\n                        idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[idx]\n                    mutant_de = population[i] + self.mutation_factor * (np.random.rand(self.dim) * (vectors[0] - population[i]) + (vectors[1] - vectors[0]))\n\n                else:  # DE/best/1\n                    idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    while i in idx:\n                        idx = np.random.choice(self.population_size + len(self.archive), size=2, replace=False)\n                    all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                    vectors = all_individuals[idx]\n                    mutant_de = population[i] + self.mutation_factor * (self.global_best_position - population[i]) + self.mutation_factor * (vectors[0] - vectors[1])\n\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    self.strategy_successes[strategy_index] += 1\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n            # Update mutation strategy probabilities (SaDE adaptation)\n            success_rates = self.strategy_successes / (self.strategy_counts + 1e-6) #avoid division by zero\n            for k in range(len(self.mutation_strategy_probs)):\n                self.mutation_strategy_probs[k] += self.learning_rate * (success_rates[k] - np.mean(success_rates))\n            self.mutation_strategy_probs = np.maximum(0, self.mutation_strategy_probs) # Ensure non-negative probabilities\n            self.mutation_strategy_probs /= np.sum(self.mutation_strategy_probs) # Normalize\n\n            self.strategy_successes[:] = 0\n            self.strategy_counts[:] = 0\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.205708924331804, 0.3525897746630151, 0.4849662895248291, 0.9188839579263801, 0.6329638263774767, 0.8445292564754313, 0.4717553530019857, 0.6004184694737649, 0.6934593022626888, 0.5647505652443042, 0.9209488195383677, 0.997750265511252, 0.32578660161705775, 0.6629570865160064, 0.7324617435187992, 0.9086226771221574, 0.40333481206246347, 0.9141537011311885, 0.339983396946146, 0.4989417002516304], "operator": "mutation", "theta_sampled": 0.04608048496526436, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "9dafa0c4-f34a-4493-878c-c83fe74afeb2", "fitness": 0.7005841152689356, "name": "AdaptiveHybridOptimizerV3", "description": "Integrates a self-adaptive differential evolution (SaDE) mutation strategy directly into the PSO velocity update, dynamically adjusting mutation based on recent success, and introduces a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold # evaluations without improvement before restart\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement_eval = 0  # Evaluation count of the last improvement\n        self.mutation_type_probs = np.array([0.5, 0.5]) # Probability for each mutation type\n        self.mutation_types = ['current-to-rand', 'rand/1']\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_eval = self.eval_count # Reset last improvement\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Stagnation check and restart\n            if self.eval_count - self.last_improvement_eval > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.population_size\n\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                self.global_best_position = population[global_best_index].copy()\n                self.global_best_fitness = fitness[global_best_index]\n                if self.global_best_fitness < self.f_opt:\n                      self.f_opt = self.global_best_fitness\n                      self.x_opt = self.global_best_position\n\n                self.last_improvement_eval = self.eval_count\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Choose mutation type based on probabilities\n                mutation_type = np.random.choice(self.mutation_types, p=self.mutation_type_probs)\n\n                # Apply selected mutation strategy\n                if mutation_type == 'current-to-rand':\n                    indices = np.random.choice(self.population_size, size=2, replace=False)\n                    mutant = population[i] + self.mutation_factor * (population[indices[0]] - population[indices[1]])\n                elif mutation_type == 'rand/1':\n                     indices = np.random.choice(self.population_size, size=3, replace=False)\n                     mutant = population[indices[0]] + self.mutation_factor * (population[indices[1]] - population[indices[2]])\n                else:\n                    raise ValueError(\"Invalid mutation type\")\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using SaDE-inspired approach (Direct integration of DE mutation)\n                self.velocities[i] += 0.5 * (mutant - population[i])\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    #Mutation Adaptation\n                    if mutation_type == 'current-to-rand':\n                        self.mutation_type_probs[0] *= 1.1\n                        self.mutation_type_probs[1] *= 0.9\n                    else:\n                        self.mutation_type_probs[0] *= 0.9\n                        self.mutation_type_probs[1] *= 1.1\n                    self.mutation_type_probs /= np.sum(self.mutation_type_probs)\n\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement_eval = self.eval_count # Update last improvement\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV3 scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates a self-adaptive differential evolution (SaDE) mutation strategy directly into the PSO velocity update, dynamically adjusting mutation based on recent success, and introduces a restart mechanism based on stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV3:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold # evaluations without improvement before restart\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.last_improvement_eval = 0  # Evaluation count of the last improvement\n        self.mutation_type_probs = np.array([0.5, 0.5]) # Probability for each mutation type\n        self.mutation_types = ['current-to-rand', 'rand/1']\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.last_improvement_eval = self.eval_count # Reset last improvement\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Stagnation check and restart\n            if self.eval_count - self.last_improvement_eval > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.population_size\n\n                self.personal_best_positions = population.copy()\n                self.personal_best_fitness = fitness.copy()\n                global_best_index = np.argmin(fitness)\n                self.global_best_position = population[global_best_index].copy()\n                self.global_best_fitness = fitness[global_best_index]\n                if self.global_best_fitness < self.f_opt:\n                      self.f_opt = self.global_best_fitness\n                      self.x_opt = self.global_best_position\n\n                self.last_improvement_eval = self.eval_count\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Choose mutation type based on probabilities\n                mutation_type = np.random.choice(self.mutation_types, p=self.mutation_type_probs)\n\n                # Apply selected mutation strategy\n                if mutation_type == 'current-to-rand':\n                    indices = np.random.choice(self.population_size, size=2, replace=False)\n                    mutant = population[i] + self.mutation_factor * (population[indices[0]] - population[indices[1]])\n                elif mutation_type == 'rand/1':\n                     indices = np.random.choice(self.population_size, size=3, replace=False)\n                     mutant = population[indices[0]] + self.mutation_factor * (population[indices[1]] - population[indices[2]])\n                else:\n                    raise ValueError(\"Invalid mutation type\")\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using SaDE-inspired approach (Direct integration of DE mutation)\n                self.velocities[i] += 0.5 * (mutant - population[i])\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    #Mutation Adaptation\n                    if mutation_type == 'current-to-rand':\n                        self.mutation_type_probs[0] *= 1.1\n                        self.mutation_type_probs[1] *= 0.9\n                    else:\n                        self.mutation_type_probs[0] *= 0.9\n                        self.mutation_type_probs[1] *= 1.1\n                    self.mutation_type_probs /= np.sum(self.mutation_type_probs)\n\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                            self.last_improvement_eval = self.eval_count # Update last improvement\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.24175314375866952, 0.38299393678495897, 0.8404419881730201, 0.9042340888152285, 0.8656969267814525, 0.8823192152986238, 0.8120610681222182, 0.7322054541804636, 0.714122259340187, 0.8635866293439765, 0.8960766198389493, 0.9995747000580965, 0.38227668996083175, 0.5062603040924607, 0.9413967000070355, 0.8831330001634672, 0.5291795149715588, 0.8948921194127043, 0.2204482527106486, 0.5190296935641583], "operator": "mutation", "theta_sampled": 0.12090751349660944, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "4f4fbf2d-5b92-47d8-97cb-e1e47b94bdc0", "fitness": 0.0, "name": "AdaptiveHybridOptimizerV4", "description": "An adaptive hybrid optimizer that balances exploration and exploitation using dynamic parameter adaptation, orthogonal learning, and a simplified PSO update, with restarts triggered by stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, archive_proportion=0.2,\n                 stagnation_threshold=50, stagnation_reinit_proportion=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reinit_proportion = stagnation_reinit_proportion\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Check for stagnation\n            if np.abs(self.f_opt - np.min(fitness)) < 1e-6:  #Stagnation tolerance\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.stagnation_counter = 0\n                num_reinit = int(self.population_size * self.stagnation_reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n            \n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n                \n                #Simplified PSO update (no explicit velocity)\n                phi1 = self.cognitive_coeff * np.random.rand(self.dim)\n                phi2 = self.social_coeff * np.random.rand(self.dim)\n                trial = population[i] + inertia_weight * (self.global_best_position - population[i]) + phi1 * (self.personal_best_positions[i] - population[i]) + phi2 * (mutant_de - population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Orthogonal Learning\n                basis = np.random.randn(self.dim, self.dim)\n                Q, R = np.linalg.qr(basis) #Find orthogonal basis\n                rand_direction = Q[:, np.random.randint(0,self.dim)]\n                step_size = np.random.uniform(-mutation_factor, mutation_factor)\n                orthogonal_trial = trial + step_size * rand_direction\n                orthogonal_trial = np.clip(orthogonal_trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n                f_orthogonal_trial = func(orthogonal_trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i] and f_orthogonal_trial < fitness[i]:\n                    if f_trial < f_orthogonal_trial:\n                        best_trial = trial\n                        best_fitness = f_trial\n                    else:\n                        best_trial = orthogonal_trial\n                        best_fitness = f_orthogonal_trial\n                    \n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = best_fitness\n                    population[i] = best_trial\n                    \n                    # Update personal best and global best\n                    if best_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = best_fitness\n                        self.personal_best_positions[i] = best_trial.copy()\n                        if best_fitness < self.global_best_fitness:\n                            self.global_best_fitness = best_fitness\n                            self.global_best_position = best_trial.copy()\n                            self.f_opt = best_fitness\n                            self.x_opt = best_trial\n                elif f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                elif f_orthogonal_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_orthogonal_trial\n                    population[i] = orthogonal_trial\n                    \n                    # Update personal best and global best\n                    if f_orthogonal_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_orthogonal_trial\n                        self.personal_best_positions[i] = orthogonal_trial.copy()\n                        if f_orthogonal_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_orthogonal_trial\n                            self.global_best_position = orthogonal_trial.copy()\n                            self.f_opt = f_orthogonal_trial\n                            self.x_opt = orthogonal_trial\n                else:\n                    self.success_history.append(0)\n\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * 0.99), 5) #Slightly slower shrinking\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV4 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimizer that balances exploration and exploitation using dynamic parameter adaptation, orthogonal learning, and a simplified PSO update, with restarts triggered by stagnation detection.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, archive_proportion=0.2,\n                 stagnation_threshold=50, stagnation_reinit_proportion=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_reinit_proportion = stagnation_reinit_proportion\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Check for stagnation\n            if np.abs(self.f_opt - np.min(fitness)) < 1e-6:  #Stagnation tolerance\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.stagnation_counter = 0\n                num_reinit = int(self.population_size * self.stagnation_reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                \n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n            \n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n                \n                #Simplified PSO update (no explicit velocity)\n                phi1 = self.cognitive_coeff * np.random.rand(self.dim)\n                phi2 = self.social_coeff * np.random.rand(self.dim)\n                trial = population[i] + inertia_weight * (self.global_best_position - population[i]) + phi1 * (self.personal_best_positions[i] - population[i]) + phi2 * (mutant_de - population[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Orthogonal Learning\n                basis = np.random.randn(self.dim, self.dim)\n                Q, R = np.linalg.qr(basis) #Find orthogonal basis\n                rand_direction = Q[:, np.random.randint(0,self.dim)]\n                step_size = np.random.uniform(-mutation_factor, mutation_factor)\n                orthogonal_trial = trial + step_size * rand_direction\n                orthogonal_trial = np.clip(orthogonal_trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n                f_orthogonal_trial = func(orthogonal_trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i] and f_orthogonal_trial < fitness[i]:\n                    if f_trial < f_orthogonal_trial:\n                        best_trial = trial\n                        best_fitness = f_trial\n                    else:\n                        best_trial = orthogonal_trial\n                        best_fitness = f_orthogonal_trial\n                    \n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = best_fitness\n                    population[i] = best_trial\n                    \n                    # Update personal best and global best\n                    if best_fitness < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = best_fitness\n                        self.personal_best_positions[i] = best_trial.copy()\n                        if best_fitness < self.global_best_fitness:\n                            self.global_best_fitness = best_fitness\n                            self.global_best_position = best_trial.copy()\n                            self.f_opt = best_fitness\n                            self.x_opt = best_trial\n                elif f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                elif f_orthogonal_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_orthogonal_trial\n                    population[i] = orthogonal_trial\n                    \n                    # Update personal best and global best\n                    if f_orthogonal_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_orthogonal_trial\n                        self.personal_best_positions[i] = orthogonal_trial.copy()\n                        if f_orthogonal_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_orthogonal_trial\n                            self.global_best_position = orthogonal_trial.copy()\n                            self.f_opt = f_orthogonal_trial\n                            self.x_opt = orthogonal_trial\n                else:\n                    self.success_history.append(0)\n\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * 0.99), 5) #Slightly slower shrinking\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.22381121452356348, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "8496ea8b-ab2a-460a-9ec8-99309a616c5f", "fitness": 0.6514484517391963, "name": "AdaptiveHybridOptimizerV4", "description": "An adaptive hybrid optimizer combining DE, PSO, and periodic re-initialization with dynamic parameter adjustments based on success history and population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion # Proportion of population to re-initialize\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization, triggered by stagnation or low diversity\n            if (self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq) or diversity < self.diversity_threshold:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                    self.velocities[idx] = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, self.dim) # Reinitialize velocities\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridOptimizerV4 scored 0.651 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive hybrid optimizer combining DE, PSO, and periodic re-initialization with dynamic parameter adjustments based on success history and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizerV4:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2, velocity_clamp=1.0,\n                 reinit_freq=0.2, reinit_proportion=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.velocity_clamp = velocity_clamp\n        self.reinit_freq = reinit_freq  # Frequency of re-initialization (as a fraction of budget)\n        self.reinit_proportion = reinit_proportion # Proportion of population to re-initialize\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update\n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - population[i])\n                self.velocities[i] = inertia + cognitive + social\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Periodic Re-initialization, triggered by stagnation or low diversity\n            if (self.eval_count / self.budget > self.reinit_freq and np.random.rand() < self.reinit_freq) or diversity < self.diversity_threshold:\n                num_reinit = int(self.population_size * self.reinit_proportion)\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                population[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n                fitness[reinit_indices] = np.array([func(x) for x in population[reinit_indices]])\n                self.eval_count += num_reinit\n                \n                for idx in reinit_indices:\n                    self.personal_best_positions[idx] = population[idx].copy()\n                    self.personal_best_fitness[idx] = fitness[idx].copy()\n                    self.velocities[idx] = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, self.dim) # Reinitialize velocities\n\n                best_index = np.argmin(fitness)\n                self.global_best_position = population[best_index].copy()\n                self.global_best_fitness = fitness[best_index]\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n                \n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19185186838608237, 0.3608969637725592, 0.7383065417967936, 0.8935527191396146, 0.6991260682770953, 0.8586588185753866, 0.4628169787204056, 0.7612590502382852, 0.8076605623118801, 0.387375113891544, 0.893797667064747, 0.9997327345182065, 0.3884325438033811, 0.5994666939485047, 0.9365419893597289, 0.8450451459875543, 0.5964942236477441, 0.879969255665848, 0.22534545674318074, 0.5026386389353836], "operator": "crossover", "theta_sampled": 0.0052320171381975275, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "ae09b39b-292c-4323-a0d3-287f41696c51", "fitness": 0.6619426394179704, "name": "NeighborhoodAdaptiveHybridOptimizer", "description": "Integrates a self-adaptive differential evolution with a neighborhood-based PSO and a Cauchy mutation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass NeighborhoodAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 neighborhood_size=5, cauchy_mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.neighborhood_size = neighborhood_size\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update with neighborhood best\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                neighborhood_best_index = neighborhood_indices[np.argmin(fitness[neighborhood_indices])]\n                \n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (population[neighborhood_best_index] - population[i])  # Neighborhood best\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n                \n                # Cauchy mutation\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    trial += np.random.standard_cauchy(size=self.dim) * 0.1  # Adjust scale as needed\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm NeighborhoodAdaptiveHybridOptimizer scored 0.662 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Integrates a self-adaptive differential evolution with a neighborhood-based PSO and a Cauchy mutation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass NeighborhoodAdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, initial_population_size=50, crossover_rate=0.7, initial_mutation_factor=0.5, shrinking_factor=0.99,\n                 inertia_weight_start=0.7, inertia_weight_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, pso_mutation_rate=0.1, archive_proportion=0.2,\n                 neighborhood_size=5, cauchy_mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = initial_population_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = initial_mutation_factor\n        self.shrinking_factor = shrinking_factor\n        self.inertia_weight_start = inertia_weight_start\n        self.inertia_weight_end = inertia_weight_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.pso_mutation_rate = pso_mutation_rate\n        self.archive_proportion = archive_proportion\n        self.archive_size = int(self.population_size * self.archive_proportion)\n        self.archive = []\n        self.neighborhood_size = neighborhood_size\n        self.cauchy_mutation_rate = cauchy_mutation_rate\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history = []\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        self.personal_best_positions = population.copy()\n        self.personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        self.global_best_position = population[global_best_index].copy()\n        self.global_best_fitness = fitness[global_best_index]\n\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (PSO part)\n            inertia_weight = self.inertia_weight_start - (self.inertia_weight_start - self.inertia_weight_end) * (self.eval_count / self.budget)\n\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break  # Budget check inside the loop\n\n\n                # Adaptive mutation strategy based on success history (DE part)\n                if len(self.success_history) > 10:\n                    success_rate = np.mean(self.success_history[-10:])\n                    if success_rate > 0.5:\n                        mutation_factor = max(0.1, self.mutation_factor * 0.9)\n                    else:\n                        mutation_factor = min(0.9, self.mutation_factor * 1.1)\n                else:\n                    mutation_factor = self.mutation_factor\n\n\n                # DE/rand/1 with archive\n                indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                if i in indices:\n                    indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size + len(self.archive), size=3, replace=False)\n\n                all_individuals = np.concatenate((population, np.array(self.archive) if self.archive else np.empty((0, self.dim))), axis=0)\n                vectors = all_individuals[indices]\n\n                mutant_de = population[i] + mutation_factor * (vectors[0] - vectors[1])\n                mutant_de = np.clip(mutant_de, func.bounds.lb, func.bounds.ub)\n\n                # PSO velocity update with neighborhood best\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                neighborhood_best_index = neighborhood_indices[np.argmin(fitness[neighborhood_indices])]\n                \n                inertia = inertia_weight * self.velocities[i]\n                cognitive = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - population[i])\n                social = self.social_coeff * np.random.rand(self.dim) * (population[neighborhood_best_index] - population[i])  # Neighborhood best\n                self.velocities[i] = inertia + cognitive + social\n                \n                # PSO mutation using DE-inspired approach\n                if np.random.rand() < self.pso_mutation_rate:\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    self.velocities[i] += 0.5 * (population[idxs[0]] - population[idxs[1]])\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    \n                # Update position with PSO velocity\n                trial = population[i] + self.velocities[i]\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between DE mutant and PSO position\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial[j] = mutant_de[j]\n                \n                # Cauchy mutation\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    trial += np.random.standard_cauchy(size=self.dim) * 0.1  # Adjust scale as needed\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluation\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    self.success_history.append(1)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(len(self.archive))] = population[i].copy()\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Update personal best and global best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial.copy()\n                            self.f_opt = f_trial\n                            self.x_opt = trial\n                else:\n                    self.success_history.append(0)\n\n\n            # Shrink population size\n            self.population_size = max(int(self.population_size * self.shrinking_factor), 5)\n            if population.shape[0] > self.population_size:\n                idx = np.argpartition(fitness, self.population_size)[:self.population_size]\n                population = population[idx]\n                fitness = fitness[idx]\n                self.personal_best_positions = self.personal_best_positions[idx]\n                self.personal_best_fitness = self.personal_best_fitness[idx]\n                self.velocities = self.velocities[idx]\n\n            self.archive_size = int(self.population_size * self.archive_proportion)\n            if len(self.archive) > self.archive_size:\n                self.archive = self.archive[:self.archive_size]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1751647705453202, 0.3542008514218353, 0.7616190052965682, 0.8672941902651268, 0.8047093104486573, 0.8552897844984257, 0.34821311703288815, 0.7486983839409831, 0.8407502418129863, 0.731589963458811, 0.8400571298037262, 0.996570177619152, 0.4076713154159528, 0.47181672238626515, 0.9289697546630873, 0.8558182559491385, 0.5886046659883509, 0.8778464798164201, 0.18614607953617546, 0.5978225884595376], "operator": "mutation", "theta_sampled": 0.2090906146522027, "reward": 0.0, "generation": 6}, "task_prompt": ""}
