{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "9d74f643-a6a0-4948-ac70-72ab41bb1049", "fitness": 0.6819631406962364, "name": "MirroredDESearch", "description": "A Differential Evolution variant that uses a mirrored sampling strategy for diversity and a decaying local search radius to refine promising solutions.", "code": "import numpy as np\n\nclass MirroredDESearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, local_search_prob=0.1, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5\n        self.CR = 0.7\n        self.local_search_prob = local_search_prob\n        self.initial_radius = initial_radius\n        self.radius = initial_radius  # Decaying radius for local search\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adjust radius over time\n            self.radius = self.initial_radius * (1 - generation / (self.budget/self.pop_size + 1)) \n            \n            for i in range(self.pop_size):\n                # Mutation with mirrored sampling\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n\n                # Mirrored Boundary Handling: reflect out-of-bounds values\n                mutant = np.where(mutant < lb, 2*lb - mutant, mutant)\n                mutant = np.where(mutant > ub, 2*ub - mutant, mutant)\n                \n\n                # Crossover\n                trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    # Self-adapt F and CR (simplified)\n                    self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                    self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n                # Update best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                    # Trigger local search with probability\n                    if np.random.rand() < self.local_search_prob:\n                        self.x_opt, self.f_opt = self.local_search(func, self.x_opt, self.f_opt, radius=self.radius)\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x_opt, f_opt, radius, num_steps=5):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        for _ in range(num_steps):\n            # Generate a random direction\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)\n\n            # Generate a random step size\n            step_size = np.random.uniform(-radius, radius)\n\n            # Create a new candidate solution\n            x_new = x_opt + step_size * direction\n            x_new = np.clip(x_new, lb, ub)\n\n            # Evaluate the new solution\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Update the best solution if necessary\n            if f_new < f_opt:\n                f_opt = f_new\n                x_opt = x_new\n\n            if self.budget <= 0:\n                break\n\n        return x_opt, f_opt", "configspace": "", "generation": 5, "feedback": "The algorithm MirroredDESearch scored 0.682 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["077d7b9d-ba51-4b31-9952-a874a7fb2c41"], "operator": null, "metadata": {"aucs": [0.2214413715697846, 0.5003077908070128, 0.6669471957216389, 0.8877951930303265, 0.7360661551003999, 0.7952430484402486, 0.6683146152615435, 0.6712679513454833, 0.7671842335502432, 0.6256622290963122, 0.8433638431959991, 0.9946097821786294, 0.33669269186359396, 0.6844770182458504, 0.88237075937037, 0.8118552516184493, 0.5729091197305342, 0.8584883300724686, 0.49535753339141797, 0.6189087003344205]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-0-1", "seed": 0}
{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "b3161e05-1a44-4951-b60f-e9e7c857cd0a", "fitness": 0.750703070477917, "name": "BudgetDE", "description": "Budget-aware Differential Evolution with dynamic parameter adaptation and a simplified local search.", "code": "import numpy as np\n\nclass BudgetDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, F_base=0.5, Cr_base=0.7, local_search_prob=0.05, local_search_step=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base\n        self.Cr_base = Cr_base\n        self.local_search_prob = local_search_prob\n        self.local_search_step = local_search_step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            F = self.F_base # Dynamic F can be implemented later\n            Cr = self.Cr_base # Dynamic CR can be implemented later\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                    # Budget-aware local search\n                    if np.random.rand() < self.local_search_prob and self.budget > 0:\n                        x_local = self._local_search(func, trial, lb, ub)\n                        f_local = func(x_local)\n                        self.budget -= 1\n\n                        if f_local < fitness[i]:\n                            fitness[i] = f_local\n                            population[i] = x_local\n                            if f_local < self.f_opt:\n                                self.f_opt = f_local\n                                self.x_opt = x_local\n\n        return self.f_opt, self.x_opt\n\n    def _local_search(self, func, x, lb, ub,):\n        \"\"\"Simplified local search.\"\"\"\n        x_new = x.copy()\n        j = np.random.randint(self.dim) # Choose one dimension randomly\n        delta = np.random.uniform(-self.local_search_step, self.local_search_step) * (ub[j] - lb[j])\n        x_new[j] = np.clip(x[j] + delta, lb[j], ub[j])\n        return x_new", "configspace": "", "generation": 3, "feedback": "The algorithm BudgetDE scored 0.751 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["07dbc44f-09c7-494b-8a98-bd46a538629b"], "operator": null, "metadata": {"aucs": [0.3216637283799568, 0.673523383450318, 0.759531001106504, 0.9201118787044109, 0.8203146009533706, 0.8462376896810022, 0.7290774908235843, 0.7406924716710501, 0.8286913381687119, 0.8011420837122263, 0.8720384878868428, 0.9994171702659863, 0.4386665390409069, 0.7765799820729747, 0.9250472440109055, 0.8544182625527509, 0.6767850873489671, 0.8814791381493106, 0.4803142109693642, 0.668329620609192]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-1-1", "seed": 1}
{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "3aaba1c2-1756-4429-9658-b88142091311", "fitness": 0.6047044336007465, "name": "SimplifiedHybridOptimizer", "description": "A computationally lean hybrid algorithm using PSO-inspired velocity updates with a simplified CMA-ES step size adaptation driven by global best fitness improvements.", "code": "import numpy as np\n\nclass SimplifiedHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w=0.7, c1=1.5, c2=1.5, learning_rate=0.1, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.learning_rate = learning_rate\n        self.sigma = initial_sigma # Overall standard deviation\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, size=(self.pop_size, self.dim))  # Smaller initial velocities\n        \n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = population.copy()\n        pbest_fitness = fitness.copy()\n        \n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        gbest_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index].copy()\n        self.x_opt = gbest_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.budget > 0:\n            # Simplified CMA-ES-like step size adaptation\n            if len(self.best_fitness_history) > 5:\n                if self.best_fitness_history[-1] < min(self.best_fitness_history[:-1]):\n                    self.sigma *= np.exp(-self.learning_rate) # Reduce sigma if improvement\n                else:\n                    self.sigma *= np.exp(self.learning_rate)  # Increase sigma if no recent improvement\n            self.sigma = np.clip(self.sigma, 1e-6, 1.0)\n\n            for i in range(self.pop_size):\n                # Update velocity (PSO component) with adaptive noise\n                adaptive_noise = self.sigma * np.random.normal(0, 1, self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (pbest_positions[i] - population[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (gbest_position - population[i]) +\n                                 adaptive_noise)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n                \n                # Update personal and global bests\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = population[i].copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                        gbest_position = population[i].copy()\n                        self.best_fitness_history.append(self.f_opt)\n\n                if self.budget <= 0:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SimplifiedHybridOptimizer scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5c2560f5-8ef3-4a87-9d49-ef6609f1b75c"], "operator": null, "metadata": {"aucs": [0.2520935722894876, 0.18833352501653444, 0.7448724101967212, 0.4304224099360734, 0.8200476444722615, 0.7957757414403563, 0.33806490301723746, 0.6727104429343292, 0.8038638983665922, 0.18724593865147243, 0.6915016544751741, 0.9995814962531935, 0.29414329410852524, 0.7603706548834632, 0.9085637877916674, 0.8108794934515482, 0.7066751256044398, 0.8605786326661424, 0.32757447286029806, 0.5007895735994141]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-2-1", "seed": 2}
{"method_name": "LLaMEA-Prompt1-Mod", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt1-Mod", "budget": 50, "kwargs": {"mutation_prompts": ["Refine or redesign the selected algorithm to improve it."], "n_parents": 1, "n_offspring": 1, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "5ef0c596-eaa2-4178-b977-976597bdb1bd", "fitness": 0.7274746072677745, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with a novel self-adaptive mutation strategy, dynamically adjusted crossover probability, and a combined archive-based exploration strategy to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_factor=0.2, memory_size=10):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The size of the population.\n            archive_factor (float): Percentage of population size to use for the archive.\n            memory_size (int): Size of the memory for F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = int(self.pop_size * archive_factor)\n        self.archive = []\n        self.memory_size = memory_size\n        self.memory_F = np.ones(self.memory_size) * 0.5\n        self.memory_CR = np.ones(self.memory_size) * 0.7\n        self.success_F = []\n        self.success_CR = []\n        self.eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n\n        # Initialize population\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.update_best(self.fitness, self.population)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                F = self.select_F()\n                CR = self.select_CR()\n\n                # Mutation and Crossover\n                trial_vector = self.mutation_crossover(i, F, CR)\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                # Selection\n                self.selection(i, f_trial, trial_vector, F, CR)\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def mutation_crossover(self, i, F, CR):\n          # Mutation using current-to-pbest/1 with archive and adaptive strategy\n        p_best_count = max(int(0.1 * self.pop_size), 1)  # Select top 10% as pbest\n        p_best_indices = np.argsort(self.fitness)[:p_best_count]\n        p_best_idx = np.random.choice(p_best_indices)\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = self.population[idxs]\n        mutant = self.population[i] + F * (self.population[p_best_idx] - self.population[i]) + F * (x_r1 - x_r2)\n\n        # Archive interaction\n        if self.archive:\n            x_r3 = self.archive[np.random.randint(len(self.archive))]\n            mutant += F * (x_r3 - self.population[i])\n\n        # Crossover - Binomial Crossover\n        trial_vector = np.copy(self.population[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() <= CR or j == j_rand:\n                trial_vector[j] = mutant[j]\n        return trial_vector\n\n    def selection(self, i, f_trial, trial_vector, F, CR):\n        if f_trial < self.fitness[i]:\n            self.success_F.append(F)\n            self.success_CR.append(CR)\n\n            # Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                self.archive[np.random.randint(self.archive_size)] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial_vector\n            self.update_best(self.fitness, self.population)\n\n            # Update memory with success\n            self.update_memory()\n\n    def update_best(self, fitness, population):\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index].copy()\n\n    def select_F(self):\n        return np.random.choice(self.memory_F)\n\n    def select_CR(self):\n        return np.random.choice(self.memory_CR)\n\n    def update_memory(self):\n        if self.success_F:\n            mean_F = np.mean(self.success_F)\n            mean_CR = np.mean(self.success_CR)\n\n            self.memory_F = np.roll(self.memory_F, 1)\n            self.memory_CR = np.roll(self.memory_CR, 1)\n            self.memory_F[0] = mean_F\n            self.memory_CR[0] = mean_CR\n\n            self.success_F = []\n            self.success_CR = []\n        else:\n            # If no success, perturb the memory values\n            self.memory_F += 0.01 * np.random.randn(self.memory_size)\n            self.memory_CR += 0.01 * np.random.randn(self.memory_size)\n            self.memory_F = np.clip(self.memory_F, 0.1, 1.0)\n            self.memory_CR = np.clip(self.memory_CR, 0.1, 1.0)", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.727 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["e58be23a-fcfc-44fc-986a-289249829746"], "operator": null, "metadata": {"aucs": [0.3660243414414456, 0.7743145098527315, 0.4972489104489989, 0.8962248979304324, 0.8289473338394652, 0.8681056077921119, 0.7726969077479858, 0.7862896274647502, 0.8255661420814768, 0.7569930797531305, 0.8917892799748947, 0.9868698880796127, 0.46923733669073386, 0.8122258941941324, 0.8122795105102352, 0.851889445126745, 0.7417401055412338, 0.8855676269082445, 0.2104760752246383, 0.5150056247524905]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt1-Mod-MA_BBOB-0-1", "seed": 0}
{"method_name": "LLaMEA-Prompt1-Mod", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt1-Mod", "budget": 50, "kwargs": {"mutation_prompts": ["Refine or redesign the selected algorithm to improve it."], "n_parents": 1, "n_offspring": 1, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "4ce194e8-cc0d-4adf-9216-b5c28580484f", "fitness": 0.6360397432269586, "name": "SuccessHistoryAdaptiveDERestarts", "description": "A Differential Evolution strategy with success-history adaptation of F and CR, combined with a weighted recombination based on fitness improvement and periodic restarts with re-initialization around the best solution found so far.", "code": "import numpy as np\n\nclass SuccessHistoryAdaptiveDERestarts:\n    def __init__(self, budget=10000, dim=10, pop_size=None, memory_size=10, reduce_every=5000, restart_every=7500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.memory_size = memory_size\n        self.reduce_every = reduce_every\n        self.restart_every = restart_every\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize memory for F and CR\n        self.memory_F = np.full(self.memory_size, 0.5)\n        self.memory_CR = np.full(self.memory_size, 0.7)\n        self.memory_idx = 0\n\n        # Success history\n        self.S_F = []\n        self.S_CR = []\n        self.S_delta_f = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n        # Update best solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.eval_count < self.budget:\n            generation += 1\n            \n            F = np.random.choice(self.memory_F)\n            CR = np.random.choice(self.memory_CR)\n\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            successful_F = []\n            successful_CR = []\n            successful_delta_f = []\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                mutant = x_r1 + F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > CR and j != j_rand:\n                        mutant[j] = population[i, j]\n\n                # Weighted recombination\n                if len(self.S_delta_f) > 0:\n                    weights = np.array(self.S_delta_f) / np.sum(self.S_delta_f)\n                    idx = np.random.choice(len(self.S_delta_f), p=weights)\n\n                # Evaluation\n                f_mutant = func(mutant)\n                self.eval_count += 1\n\n                # Selection\n                if f_mutant < fitness[i]:\n                    delta_f = abs(f_mutant - fitness[i])\n                    new_population[i] = mutant\n                    new_fitness[i] = f_mutant\n\n                    successful_F.append(F)\n                    successful_CR.append(CR)\n                    successful_delta_f.append(delta_f)\n\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n            population = new_population\n            fitness = new_fitness\n\n            # Update memory\n            if successful_F:\n                self.memory_F[self.memory_idx] = np.mean(successful_F) if successful_F else 0.5\n                self.memory_CR[self.memory_idx] = np.mean(successful_CR) if successful_CR else 0.7\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                self.S_F.extend(successful_F)\n                self.S_CR.extend(successful_CR)\n                self.S_delta_f.extend(successful_delta_f)\n\n                # Keep only the last 100 successful values\n                self.S_F = self.S_F[-100:]\n                self.S_CR = self.S_CR[-100:]\n                self.S_delta_f = self.S_delta_f[-100:]\n            \n\n            # Population size reduction\n            if self.eval_count > 0 and self.eval_count % self.reduce_every == 0 and self.pop_size > 4:\n                # Reduce population size by 20%\n                new_pop_size = int(self.pop_size * 0.8)\n\n                # Keep the best individuals\n                sorted_indices = np.argsort(fitness)[:new_pop_size]\n                population = population[sorted_indices]\n                fitness = fitness[sorted_indices]\n                self.pop_size = new_pop_size\n            \n            # Restart mechanism\n            if self.eval_count > 0 and self.eval_count % self.restart_every == 0:\n                # Re-initialize population around the best solution\n                population = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.pop_size, self.dim))\n                population = np.clip(population, func.bounds.lb, func.bounds.ub)\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n\n                # Update best solution\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SuccessHistoryAdaptiveDERestarts scored 0.636 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2230a758-7a8c-48e4-abd9-d922d53a280c"], "operator": null, "metadata": {"aucs": [0.2254364161857878, 0.5046606512120635, 0.6100053920718362, 0.809317795698378, 0.6932079507822833, 0.7359030721554382, 0.5838596262296396, 0.5955321255528834, 0.6663104500640864, 0.6432749414012583, 0.785831244192873, 0.9996574049695838, 0.3992243990612597, 0.6522604497442556, 0.8600146219805342, 0.7208195133413298, 0.5325075886925957, 0.7932338905709295, 0.40168007842429254, 0.5080572522078627]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt1-Mod-MA_BBOB-1-1", "seed": 1}
{"method_name": "LLaMEA-Prompt1-Mod", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt1-Mod", "budget": 50, "kwargs": {"mutation_prompts": ["Refine or redesign the selected algorithm to improve it."], "n_parents": 1, "n_offspring": 1, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "5defeb4c-b380-4295-a314-429ddc70a304", "fitness": 0.6585609029707725, "name": "NovelSelfAdaptiveDE", "description": "Self-Adaptive Differential Evolution with a novel mutation strategy incorporating information from both top-ranked and randomly selected individuals, along with an aging mechanism to promote exploration.", "code": "import numpy as np\n\nclass NovelSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, rank_ratio=0.2, age_limit=50):\n        \"\"\"\n        Self-Adaptive Differential Evolution with a novel mutation strategy and aging.\n\n        Args:\n            budget (int): Maximum number of function evaluations.\n            dim (int): Dimensionality of the problem.\n            pop_size (int): Population size.\n            F (float): Initial scaling factor.\n            CR (float): Initial crossover rate.\n            rank_ratio (float): Ratio of top individuals to consider for ranking.\n            age_limit (int): Maximum age of an individual before forced mutation.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.rank_ratio = rank_ratio\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.age = None  # Age of each individual\n        self.age_limit = age_limit\n\n        self.F_history = []\n        self.CR_history = []\n        self.success_history = []\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population randomly within the bounds.\"\"\"\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.evals += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n        self.age = np.zeros(self.pop_size, dtype=int)\n\n    def mutate(self, pop, F):\n        \"\"\"Performs the mutation operation using ranking and aging.\"\"\"\n        mutated_pop = np.zeros_like(pop)\n        num_ranked = int(self.rank_ratio * self.pop_size)\n\n        for i in range(self.pop_size):\n            # Ranking-based selection\n            ranked_indices = np.argsort(self.fitness)\n            top_indices = ranked_indices[:num_ranked]\n\n            # Ensure i is not selected for r1 or r2 or r3\n            available_indices = [idx for idx in range(self.pop_size) if idx != i]\n\n            # Choose base vector from top ranked individuals with replacement\n            r1_idx = np.random.choice(top_indices) #top individual\n            r2_idx = np.random.choice(available_indices)\n            available_indices.remove(r2_idx) #ensure r3 is different\n            r3_idx = np.random.choice(available_indices)\n\n            x_r1, x_r2, x_r3 = pop[r1_idx], pop[r2_idx], pop[r3_idx]\n\n            # Aging Mechanism: If an individual is old, force mutation towards a random direction\n            if self.age[i] > self.age_limit:\n                random_direction = np.random.uniform(-1, 1, size=self.dim)\n                mutated_pop[i] = x_r1 + F * (x_r2 - x_r3) + 0.1 * random_direction  # Add random perturbation\n            else:\n                mutated_pop[i] = x_r1 + F * (x_r2 - x_r3)\n\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop, CR):\n        \"\"\"Performs the crossover operation.\"\"\"\n        crossed_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < CR or j == np.random.randint(self.dim):\n                    crossed_pop[i, j] = mutated_pop[i, j]\n                else:\n                    crossed_pop[i, j] = pop[i, j]\n        return crossed_pop\n\n    def selection(self, func, crossed_pop):\n        \"\"\"Performs the selection operation.\"\"\"\n        new_fitness = np.array([func(x) for x in crossed_pop])\n        self.evals += self.pop_size\n\n        for i in range(self.pop_size):\n            if new_fitness[i] < self.fitness[i]:\n                self.pop[i] = crossed_pop[i]\n                self.fitness[i] = new_fitness[i]\n                self.age[i] = 0  # Reset age if improved\n            else:\n                self.age[i] += 1  # Increment age if not improved\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n\n    def adapt_parameters(self):\n        \"\"\"Adapts F and CR based on sigmoid of success rate.\"\"\"\n        if self.success_history:\n            success_rate = np.mean(self.success_history[-10:])  # Consider last 10 generations\n            # Sigmoid function to map success rate to F/CR adjustments\n            sigmoid_output = 1 / (1 + np.exp(-10 * (success_rate - 0.2))) # Shifted sigmoid\n\n            # Use sigmoid output to adjust F and CR more smoothly and robustly\n            self.F = 0.1 + 0.9 * sigmoid_output  # F ranges from 0.1 to 1.0\n            self.CR = 0.1 + 0.9 * sigmoid_output  # CR ranges from 0.1 to 1.0\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n            self.F_history.append(self.F)\n            self.CR_history.append(self.CR)\n\n    def __call__(self, func):\n        \"\"\"Optimizes the given function.\"\"\"\n        self.initialize_population(func)\n\n        while self.evals < self.budget:\n            F = self.F\n            CR = self.CR\n\n            mutated_pop = self.mutate(self.pop, F)\n\n            # Boundary Handling: Clip values to remain within bounds\n            mutated_pop = np.clip(mutated_pop, func.bounds.lb, func.bounds.ub)\n\n            crossed_pop = self.crossover(self.pop, mutated_pop, CR)\n\n            # Boundary Handling: Clip values to remain within bounds\n            crossed_pop = np.clip(crossed_pop, func.bounds.lb, func.bounds.ub)\n\n            old_fitness = self.fitness.copy()  # keep old fitness for success rate calculation\n            self.selection(func, crossed_pop)\n\n            # Track Success Rate\n            improved_count = np.sum(self.fitness < old_fitness)\n            success_rate = improved_count / self.pop_size\n            self.success_history.append(success_rate)\n\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm NovelSelfAdaptiveDE scored 0.659 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5cd98e1c-e54d-4f27-8cdc-619e99923e9f"], "operator": null, "metadata": {"aucs": [0.2553671910435318, 0.5848515852968648, 0.6783819776236826, 0.8356628526338267, 0.6891315700238864, 0.7288566874928084, 0.6110462915326347, 0.6091710329410993, 0.6797744336700381, 0.6778284740771117, 0.8376201868612299, 0.9966067638797419, 0.27015723553725435, 0.6752478844090211, 0.8762159613440003, 0.7482742333749505, 0.5696090210530754, 0.8063981249052119, 0.5165969514252851, 0.524419600290196]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt1-Mod-MA_BBOB-2-1", "seed": 2}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 0.34864485548731117, "mean": 0.0011628803077196137, "var": 5.6538401825897195e-05, "std": 0.007519202206743558, "theta": -0.019304073230870026, "pulls": 5}, "crossover": {"count": 5.755414291988797, "mean": 0.006979892779657055, "var": 0.00011457807426438426, "std": 0.01070411482862475, "theta": 0.0011400562063206346, "pulls": 24}, "random_new": {"count": 3.748132023109549, "mean": 0.0005897173804588215, "var": 2.108298077164884e-05, "std": 0.004591620712956248, "theta": 0.0037110924235143655, "pulls": 11}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "1e65798b-a63c-4a21-ae97-2750c4eec13b", "fitness": 0.7328695526538804, "name": "HybridAdaptiveEvolution", "description": "A hybrid optimization algorithm combining CMA-ES mutation with differential evolution and adaptive variance search, dynamically adjusting strategy probabilities and parameters based on population diversity and fitness variance.", "code": "import numpy as np\n\nclass HybridAdaptiveEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, initial_variance=1.0, de_crossover_rate=0.7, de_scaling_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.variance = initial_variance\n        self.population = None\n        self.fitness = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.3  # Probability of applying CMA-ES mutation\n        self.variance_rate = 0.3 # Probability of applying variance search\n        self.de_rate = 0.4 #Probability of differential evolution\n        self.de_crossover_rate = de_crossover_rate\n        self.de_scaling_factor = de_scaling_factor\n        self.covariance_matrix = np.eye(dim) * initial_step_size**2  # Initialize covariance matrix for CMA-ES\n        self.learning_rate_covariance = 0.15 # How quickly covariance adapts\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates a measure of population diversity.\"\"\"\n        return np.std(self.population)\n\n    def update_step_size(self, diversity):\n        \"\"\"Adaptively adjust step size based on population diversity.\"\"\"\n        self.step_size = 0.5 * (diversity / (self.ub - self.lb))\n        self.step_size = np.clip(self.step_size, 0.01, 1.0)  # Ensure reasonable step size\n\n    def gaussian_mutation(self):\n        \"\"\"Apply CMA-ES mutation to generate new offspring.\"\"\"\n        mutation = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix, size=self.pop_size)\n        new_population = self.population + mutation\n        new_population = np.clip(new_population, self.lb, self.ub)\n        return new_population\n\n    def variance_search(self):\n         \"\"\"Apply variance search to the population\"\"\"\n         offspring = self.population + np.random.normal(0, self.variance, size=(self.pop_size, self.dim))\n         offspring = np.clip(offspring, self.lb, self.ub)\n         return offspring\n\n    def differential_evolution(self):\n        \"\"\"Apply differential evolution to generate new offspring.\"\"\"\n        new_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            v_i = x_r1 + self.de_scaling_factor * (x_r2 - x_r3)\n            v_i = np.clip(v_i, self.lb, self.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                    new_population[i, j] = v_i[j]\n                else:\n                    new_population[i, j] = self.population[i, j]\n        return new_population\n\n    def update_covariance_matrix(self, selected_individuals):\n        \"\"\"Update the covariance matrix based on the selected individuals (CMA-ES).\"\"\"\n        diff = selected_individuals - np.mean(self.population, axis=0)\n        self.covariance_matrix = (1 - self.learning_rate_covariance) * self.covariance_matrix + \\\n                                    self.learning_rate_covariance * np.cov(diff.T)\n        \n        # Ensure positive definiteness\n        min_eig = np.min(np.real(np.linalg.eigvals(self.covariance_matrix)))\n        if min_eig < 0:\n            self.covariance_matrix += np.eye(self.dim) * (abs(min_eig) + 1e-6)\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Evaluate initial population\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.update_step_size(diversity)\n            fitness_variance = np.var(self.fitness)\n\n\n            # Adaptive strategy selection\n            rand_val = np.random.rand()\n            if rand_val < self.mutation_rate:\n                new_population = self.gaussian_mutation()\n            elif rand_val < self.mutation_rate + self.variance_rate:\n                new_population = self.variance_search()\n            else:\n                new_population = self.differential_evolution()\n\n            new_fitness = np.full(self.pop_size, np.inf)\n\n            # Evaluate the new population\n            for i in range(self.pop_size):\n                new_fitness[i] = func(new_population[i])\n                eval_count += 1\n\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Selection: Replace the worst individuals with the best from the new population\n            for i in range(self.pop_size):\n                if new_fitness[i] < np.max(self.fitness):\n                    worst_index = np.argmax(self.fitness)\n                    self.fitness[worst_index] = new_fitness[i]\n                    self.population[worst_index] = new_population[i]\n            \n            # Adaptive variance adjustment\n            if fitness_variance > 0.1:\n                self.variance *= 1.1  # Increase variance (exploration)\n            else:\n                self.variance *= 0.9  # Decrease variance (exploitation)\n\n            self.variance = np.clip(self.variance, 0.01, 2.0)  # Keep variance within reasonable bounds\n\n            #Adapt de parameters:\n            if fitness_variance > 0.1:\n                self.de_scaling_factor *= 0.9\n            else:\n                self.de_scaling_factor *= 1.1\n\n            self.de_scaling_factor = np.clip(self.de_scaling_factor, 0.1, 1.0)\n\n            # Adaptive Covariance Matrix Update (CMA-ES)\n            best_indices = np.argsort(self.fitness)[:self.pop_size // 4]  # Consider the best 25%\n            best_individuals = self.population[best_indices]\n            self.update_covariance_matrix(best_individuals)\n\n            # Adapt strategy probabilities based on fitness variance:\n            if fitness_variance > 0.1: # Exploration\n                self.mutation_rate = min(self.mutation_rate + 0.05, 0.8)\n                self.variance_rate = min(self.variance_rate + 0.05, 0.8)\n                self.de_rate = max(self.de_rate - 0.1, 0.0)\n            else: #Exploitation\n                self.mutation_rate = max(self.mutation_rate - 0.05, 0.0)\n                self.variance_rate = max(self.variance_rate - 0.05, 0.0)\n                self.de_rate = min(self.de_rate + 0.1, 0.8)\n\n            # Normalize probabilities to sum to 1\n            total_rate = self.mutation_rate + self.variance_rate + self.de_rate\n            self.mutation_rate /= total_rate\n            self.variance_rate /= total_rate\n            self.de_rate /= total_rate\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveEvolution scored 0.733 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid optimization algorithm combining CMA-ES mutation with differential evolution and adaptive variance search, dynamically adjusting strategy probabilities and parameters based on population diversity and fitness variance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, initial_variance=1.0, de_crossover_rate=0.7, de_scaling_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.variance = initial_variance\n        self.population = None\n        self.fitness = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.3  # Probability of applying CMA-ES mutation\n        self.variance_rate = 0.3 # Probability of applying variance search\n        self.de_rate = 0.4 #Probability of differential evolution\n        self.de_crossover_rate = de_crossover_rate\n        self.de_scaling_factor = de_scaling_factor\n        self.covariance_matrix = np.eye(dim) * initial_step_size**2  # Initialize covariance matrix for CMA-ES\n        self.learning_rate_covariance = 0.15 # How quickly covariance adapts\n\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates a measure of population diversity.\"\"\"\n        return np.std(self.population)\n\n    def update_step_size(self, diversity):\n        \"\"\"Adaptively adjust step size based on population diversity.\"\"\"\n        self.step_size = 0.5 * (diversity / (self.ub - self.lb))\n        self.step_size = np.clip(self.step_size, 0.01, 1.0)  # Ensure reasonable step size\n\n    def gaussian_mutation(self):\n        \"\"\"Apply CMA-ES mutation to generate new offspring.\"\"\"\n        mutation = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix, size=self.pop_size)\n        new_population = self.population + mutation\n        new_population = np.clip(new_population, self.lb, self.ub)\n        return new_population\n\n    def variance_search(self):\n         \"\"\"Apply variance search to the population\"\"\"\n         offspring = self.population + np.random.normal(0, self.variance, size=(self.pop_size, self.dim))\n         offspring = np.clip(offspring, self.lb, self.ub)\n         return offspring\n\n    def differential_evolution(self):\n        \"\"\"Apply differential evolution to generate new offspring.\"\"\"\n        new_population = np.copy(self.population)\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            v_i = x_r1 + self.de_scaling_factor * (x_r2 - x_r3)\n            v_i = np.clip(v_i, self.lb, self.ub)\n\n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                    new_population[i, j] = v_i[j]\n                else:\n                    new_population[i, j] = self.population[i, j]\n        return new_population\n\n    def update_covariance_matrix(self, selected_individuals):\n        \"\"\"Update the covariance matrix based on the selected individuals (CMA-ES).\"\"\"\n        diff = selected_individuals - np.mean(self.population, axis=0)\n        self.covariance_matrix = (1 - self.learning_rate_covariance) * self.covariance_matrix + \\\n                                    self.learning_rate_covariance * np.cov(diff.T)\n        \n        # Ensure positive definiteness\n        min_eig = np.min(np.real(np.linalg.eigvals(self.covariance_matrix)))\n        if min_eig < 0:\n            self.covariance_matrix += np.eye(self.dim) * (abs(min_eig) + 1e-6)\n\n\n    def __call__(self, func):\n        self.initialize_population()\n        eval_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Evaluate initial population\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            self.update_step_size(diversity)\n            fitness_variance = np.var(self.fitness)\n\n\n            # Adaptive strategy selection\n            rand_val = np.random.rand()\n            if rand_val < self.mutation_rate:\n                new_population = self.gaussian_mutation()\n            elif rand_val < self.mutation_rate + self.variance_rate:\n                new_population = self.variance_search()\n            else:\n                new_population = self.differential_evolution()\n\n            new_fitness = np.full(self.pop_size, np.inf)\n\n            # Evaluate the new population\n            for i in range(self.pop_size):\n                new_fitness[i] = func(new_population[i])\n                eval_count += 1\n\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_population[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Selection: Replace the worst individuals with the best from the new population\n            for i in range(self.pop_size):\n                if new_fitness[i] < np.max(self.fitness):\n                    worst_index = np.argmax(self.fitness)\n                    self.fitness[worst_index] = new_fitness[i]\n                    self.population[worst_index] = new_population[i]\n            \n            # Adaptive variance adjustment\n            if fitness_variance > 0.1:\n                self.variance *= 1.1  # Increase variance (exploration)\n            else:\n                self.variance *= 0.9  # Decrease variance (exploitation)\n\n            self.variance = np.clip(self.variance, 0.01, 2.0)  # Keep variance within reasonable bounds\n\n            #Adapt de parameters:\n            if fitness_variance > 0.1:\n                self.de_scaling_factor *= 0.9\n            else:\n                self.de_scaling_factor *= 1.1\n\n            self.de_scaling_factor = np.clip(self.de_scaling_factor, 0.1, 1.0)\n\n            # Adaptive Covariance Matrix Update (CMA-ES)\n            best_indices = np.argsort(self.fitness)[:self.pop_size // 4]  # Consider the best 25%\n            best_individuals = self.population[best_indices]\n            self.update_covariance_matrix(best_individuals)\n\n            # Adapt strategy probabilities based on fitness variance:\n            if fitness_variance > 0.1: # Exploration\n                self.mutation_rate = min(self.mutation_rate + 0.05, 0.8)\n                self.variance_rate = min(self.variance_rate + 0.05, 0.8)\n                self.de_rate = max(self.de_rate - 0.1, 0.0)\n            else: #Exploitation\n                self.mutation_rate = max(self.mutation_rate - 0.05, 0.0)\n                self.variance_rate = max(self.variance_rate - 0.05, 0.0)\n                self.de_rate = min(self.de_rate + 0.1, 0.8)\n\n            # Normalize probabilities to sum to 1\n            total_rate = self.mutation_rate + self.variance_rate + self.de_rate\n            self.mutation_rate /= total_rate\n            self.variance_rate /= total_rate\n            self.de_rate /= total_rate\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0.3232339872854192, 0.7515957535502396, 0.7795631991049239, 0.916345068634814, 0.8594729689323082, 0.8657930424651852, 0.760885702372934, 0.733712703953171, 0.6946246481005101, 0.8173695604513561, 0.9057906486767622, 0.9994991021978854, 0.36867792211045725, 0.7970395214053223, 0.9431280318573201, 0.8243340785494313, 0.668399049781059, 0.8872077010730356, 0.22500268111368793, 0.5357156814617867], "operator": "crossover", "theta_sampled": 0.017065125553961866, "reward": 0.039801040209612504, "generation": 3}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-0-1", "seed": 0}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 1.81822950668283, "mean": 0.0024327656296635673, "var": 7.999494797541338e-05, "std": 0.00894398948878035, "theta": -0.008583813215388623, "pulls": 10}, "crossover": {"count": 2.911619927213324, "mean": 0.0092291807316474, "var": 0.00023997707414339872, "std": 0.015491193438318389, "theta": 0.03375712226510899, "pulls": 14}, "random_new": {"count": 5.122341736689502, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.26803439995735795, "pulls": 16}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "6d964760-7bef-4034-9c70-852c98548a3b", "fitness": 0.6192765119698016, "name": "EnhancedHybridDE", "description": "A hybrid DE with adaptive covariance matrix adaptation, archive injection, and a multi-faceted stagnation handling mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, initial_step_size=0.5, stagnation_threshold=50, restart_trigger=100, min_step_size=1e-6, exploration_probability=0.1, archive_size=20, cma_learning_rate=0.1, step_size_reduction=0.8, f_reduction=0.9, cr_increase=1.1, archive_injection_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.initial_step_size = initial_step_size\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_trigger = restart_trigger\n        self.min_step_size = min_step_size\n        self.exploration_probability = exploration_probability\n        self.archive_size = archive_size\n        self.archive = []\n        self.mean = None\n        self.C = None\n        self.step_size = self.initial_step_size\n        self.restart_count = 0\n        self.cma_learning_rate = cma_learning_rate\n        self.step_size_reduction = step_size_reduction\n        self.f_reduction = f_reduction\n        self.cr_increase = cr_increase\n        self.archive_injection_rate = archive_injection_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        self.mean = self.x_opt.copy()\n        self.C = np.eye(self.dim)\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Global Exploration or DE\n                if np.random.rand() < self.exploration_probability:\n                    # Global Exploration using uniform sampling\n                    trial_vector = np.random.uniform(lb, ub, size=self.dim)\n                else:\n                    # DE Mutation with adaptive F and CR\n                    indices = list(range(self.pop_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = population[a] + self.F * (population[b] - population[c])\n                    mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                    # Crossover\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR:\n                            trial_vector[j] = mutant_vector[j]\n\n                # Covariance Matrix Adaptation around Trial Vector\n                z = np.random.normal(0, 1, size=self.dim)\n                neighbor = trial_vector + self.step_size * np.dot(np.linalg.cholesky(self.C), z)\n                neighbor = np.clip(neighbor, lb, ub)\n\n                f_neighbor = func(neighbor)\n                self.budget -= 1\n\n                if f_neighbor < fitness[i]:\n                    fitness[i] = f_neighbor\n                    population[i] = neighbor\n                    if f_neighbor < self.f_opt:\n                        self.f_opt = f_neighbor\n                        self.x_opt = neighbor\n                        self.mean = neighbor.copy()\n                        stagnation_counter = 0\n                        # Rank-one update of covariance matrix\n                        z = np.linalg.solve(np.linalg.cholesky(self.C), (neighbor - self.mean) / self.step_size)\n                        self.C = (1 - self.cma_learning_rate) * self.C + self.cma_learning_rate * np.outer(z, z)\n                    else:\n                        stagnation_counter += 1\n                else:\n                    stagnation_counter += 1\n\n\n                # Archive update\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(population[i].copy())\n                else:\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = population[i].copy()\n\n            # Stagnation Handling\n            if stagnation_counter > self.stagnation_threshold:\n                # Step Size and Parameter Adaptation\n                self.step_size *= self.step_size_reduction\n                self.F = max(0.1, self.F * self.f_reduction)\n                self.CR = min(0.9, self.CR * self.cr_increase)\n\n                # Archive injection\n                if len(self.archive) > 0 and np.random.rand() < self.archive_injection_rate:\n                    num_inject = min(len(self.archive), self.pop_size // 2)\n                    replace_indices = np.random.choice(range(self.pop_size), num_inject, replace=False)\n                    for k in range(num_inject):\n                        archive_idx = k % len(self.archive)\n                        population[replace_indices[k]] = self.archive[archive_idx].copy()\n                        fitness[replace_indices[k]] = func(population[replace_indices[k]])\n                        self.budget -= 1\n                        if fitness[replace_indices[k]] < self.f_opt:\n                            self.f_opt = fitness[replace_indices[k]]\n                            self.x_opt = population[replace_indices[k]]\n                            self.mean = self.x_opt.copy()\n                            stagnation_counter = 0\n                else:\n                   # Reset the covariance matrix if archive is empty or injection is skipped.\n                    self.C = np.eye(self.dim)\n                stagnation_counter = 0 #reset counter after stagnation handling\n\n\n            # Restart Condition\n            if self.step_size < self.min_step_size or stagnation_counter > self.restart_trigger:\n                self.restart_count += 1\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.step_size = self.initial_step_size\n                stagnation_counter = 0\n\n                 # Re-initialize population\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedHybridDE scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid DE with adaptive covariance matrix adaptation, archive injection, and a multi-faceted stagnation handling mechanism for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, initial_step_size=0.5, stagnation_threshold=50, restart_trigger=100, min_step_size=1e-6, exploration_probability=0.1, archive_size=20, cma_learning_rate=0.1, step_size_reduction=0.8, f_reduction=0.9, cr_increase=1.1, archive_injection_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.initial_step_size = initial_step_size\n        self.stagnation_threshold = stagnation_threshold\n        self.restart_trigger = restart_trigger\n        self.min_step_size = min_step_size\n        self.exploration_probability = exploration_probability\n        self.archive_size = archive_size\n        self.archive = []\n        self.mean = None\n        self.C = None\n        self.step_size = self.initial_step_size\n        self.restart_count = 0\n        self.cma_learning_rate = cma_learning_rate\n        self.step_size_reduction = step_size_reduction\n        self.f_reduction = f_reduction\n        self.cr_increase = cr_increase\n        self.archive_injection_rate = archive_injection_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        self.mean = self.x_opt.copy()\n        self.C = np.eye(self.dim)\n        stagnation_counter = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Global Exploration or DE\n                if np.random.rand() < self.exploration_probability:\n                    # Global Exploration using uniform sampling\n                    trial_vector = np.random.uniform(lb, ub, size=self.dim)\n                else:\n                    # DE Mutation with adaptive F and CR\n                    indices = list(range(self.pop_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = population[a] + self.F * (population[b] - population[c])\n                    mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                    # Crossover\n                    trial_vector = np.copy(population[i])\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR:\n                            trial_vector[j] = mutant_vector[j]\n\n                # Covariance Matrix Adaptation around Trial Vector\n                z = np.random.normal(0, 1, size=self.dim)\n                neighbor = trial_vector + self.step_size * np.dot(np.linalg.cholesky(self.C), z)\n                neighbor = np.clip(neighbor, lb, ub)\n\n                f_neighbor = func(neighbor)\n                self.budget -= 1\n\n                if f_neighbor < fitness[i]:\n                    fitness[i] = f_neighbor\n                    population[i] = neighbor\n                    if f_neighbor < self.f_opt:\n                        self.f_opt = f_neighbor\n                        self.x_opt = neighbor\n                        self.mean = neighbor.copy()\n                        stagnation_counter = 0\n                        # Rank-one update of covariance matrix\n                        z = np.linalg.solve(np.linalg.cholesky(self.C), (neighbor - self.mean) / self.step_size)\n                        self.C = (1 - self.cma_learning_rate) * self.C + self.cma_learning_rate * np.outer(z, z)\n                    else:\n                        stagnation_counter += 1\n                else:\n                    stagnation_counter += 1\n\n\n                # Archive update\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(population[i].copy())\n                else:\n                    replace_index = np.random.randint(0, self.archive_size)\n                    self.archive[replace_index] = population[i].copy()\n\n            # Stagnation Handling\n            if stagnation_counter > self.stagnation_threshold:\n                # Step Size and Parameter Adaptation\n                self.step_size *= self.step_size_reduction\n                self.F = max(0.1, self.F * self.f_reduction)\n                self.CR = min(0.9, self.CR * self.cr_increase)\n\n                # Archive injection\n                if len(self.archive) > 0 and np.random.rand() < self.archive_injection_rate:\n                    num_inject = min(len(self.archive), self.pop_size // 2)\n                    replace_indices = np.random.choice(range(self.pop_size), num_inject, replace=False)\n                    for k in range(num_inject):\n                        archive_idx = k % len(self.archive)\n                        population[replace_indices[k]] = self.archive[archive_idx].copy()\n                        fitness[replace_indices[k]] = func(population[replace_indices[k]])\n                        self.budget -= 1\n                        if fitness[replace_indices[k]] < self.f_opt:\n                            self.f_opt = fitness[replace_indices[k]]\n                            self.x_opt = population[replace_indices[k]]\n                            self.mean = self.x_opt.copy()\n                            stagnation_counter = 0\n                else:\n                   # Reset the covariance matrix if archive is empty or injection is skipped.\n                    self.C = np.eye(self.dim)\n                stagnation_counter = 0 #reset counter after stagnation handling\n\n\n            # Restart Condition\n            if self.step_size < self.min_step_size or stagnation_counter > self.restart_trigger:\n                self.restart_count += 1\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.step_size = self.initial_step_size\n                stagnation_counter = 0\n\n                 # Re-initialize population\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2003285620734192, 0.23342268936410981, 0.7644594572659085, 0.9225726904780223, 0.8052677015267109, 0.825536473480594, 0.31686663361354994, 0.6795654144373264, 0.8072430048811906, 0.23274637839727985, 0.9069832056746757, 0.9964576491766862, 0.28195831046895636, 0.8221152890253947, 0.805898229674159, 0.8288389151799034, 0.7114858454875215, 0.8746272584500662, 0.3691565307405571, 0], "operator": "crossover", "theta_sampled": 0.019386616962868117, "reward": 0.03132708493025005, "generation": 4}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-0", "seed": 0}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 2.1493314118425757, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.1611384814004503, "pulls": 14}, "crossover": {"count": 4.3386410804005076, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.14569398860369187, "pulls": 16}, "random_new": {"count": 3.364218678342573, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.12075381537778887, "pulls": 10}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "1407c164-b957-4c8c-a5c3-e5b7f6ec0098", "fitness": 0.7839064908092543, "name": "AdaptiveDifferentialEvolution", "description": "A population-based algorithm that uses a modified differential evolution approach with a dynamically adjusted scaling factor based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Dynamically adjust F based on population diversity\n                diversity = np.std(fitness)\n                if diversity > 0.1:\n                    F = self.F + np.random.normal(0, 0.1)\n                else:\n                    F = self.F - np.random.normal(0, 0.1)\n                F = np.clip(F, 0.1, 0.9)\n\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.784 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm that uses a modified differential evolution approach with a dynamically adjusted scaling factor based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n\n                # Dynamically adjust F based on population diversity\n                diversity = np.std(fitness)\n                if diversity > 0.1:\n                    F = self.F + np.random.normal(0, 0.1)\n                else:\n                    F = self.F - np.random.normal(0, 0.1)\n                F = np.clip(F, 0.1, 0.9)\n\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.4214002071001608, 0.7869092304726016, 0.814312570368763, 0.9286104511912582, 0.8828466882202547, 0.8899725385339968, 0.8303662709623341, 0.8398776382310573, 0.8813880864734598, 0.8545365649565337, 0.8963927453540358, 0.9962110101103477, 0.35825796179738867, 0.8473361737969582, 0.9178526157801622, 0.9117377617400583, 0.795170677983253, 0.937075765946666, 0.37004103397705035, 0.5178338231887447], "generation": 0, "operator": "init"}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-1", "seed": 1}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 2.559088116141368, "mean": 0.0011648576203236256, "var": 3.846736366652008e-06, "std": 0.00196130985992831, "theta": -0.003885655884088255, "pulls": 10}, "crossover": {"count": 3.848376773604891, "mean": 0.005181578010535715, "var": 2.2173190393560583e-05, "std": 0.004708841725261169, "theta": 0.014253558238897334, "pulls": 12}, "random_new": {"count": 3.444726280839397, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.14689714102210327, "pulls": 18}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "86134f29-881f-4a07-b98b-72e179f8de41", "fitness": 0.625480855259003, "name": "HybridAdaptiveAntDE", "description": "A hybrid ant colony optimization algorithm combining adaptive step size, differential evolution mutation, elitism, and hypersphere sampling with radius adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveAntDE:\n    def __init__(self, budget=10000, dim=10, colony_size=20, initial_step_size=1.0, decay_rate=0.95, intensify_rate=1.05, elitism_factor=0.1, hypersphere_prob=0.2, de_mutation_factor=0.5, radius_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.step_size = initial_step_size\n        self.decay_rate = decay_rate\n        self.intensify_rate = intensify_rate\n        self.elitism_factor = elitism_factor\n        self.hypersphere_prob = hypersphere_prob\n        self.de_mutation_factor = de_mutation_factor\n        self.radius_decay = radius_decay\n        self.radius = 2.5\n\n    def __call__(self, func):\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.array([func(ant) for ant in ants])\n        self.budget -= self.colony_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = ants[np.argmin(fitness)]\n        \n        success_rate = 0.5  # Initialize success rate\n        \n        while self.budget > 0:\n            # Sort ants by fitness\n            sorted_indices = np.argsort(fitness)\n            ants = ants[sorted_indices]\n            fitness = fitness[sorted_indices]\n            \n            # Elitism: Keep the best ants\n            num_elites = int(self.colony_size * self.elitism_factor)\n            elites = ants[:num_elites].copy()\n            elite_fitness = fitness[:num_elites].copy()\n\n            # Determine the best ant (leader)\n            leader = ants[0]\n\n            # Move ants based on the leader and adaptive step size\n            new_ants = np.zeros_like(ants)\n            num_successful = 0\n            for i in range(self.colony_size):\n                if np.random.rand() < self.hypersphere_prob:\n                    # Hypersphere sampling\n                    direction = np.random.normal(0, 1, size=self.dim)\n                    direction /= np.linalg.norm(direction)\n                    new_ants[i] = ants[i] + self.radius * direction\n                    new_ants[i] = np.clip(new_ants[i], func.bounds.lb, func.bounds.ub)\n                else:\n                    # Ant colony movement with leader influence and DE mutation\n                    idxs = np.random.choice(self.colony_size, 3, replace=False)\n                    a, b, c = ants[idxs]\n                    diff = a - b\n                    mutation = self.de_mutation_factor * diff\n\n                    direction = leader - ants[i] + mutation + np.random.normal(0, self.step_size, size=self.dim)\n                    new_ants[i] = ants[i] + direction\n                    new_ants[i] = np.clip(new_ants[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new ant positions\n            new_fitness = np.array([func(ant) for ant in new_ants])\n            self.budget -= self.colony_size\n\n            # Update the colony (selection)\n            for i in range(self.colony_size):\n                if new_fitness[i] < fitness[i]:\n                    ants[i] = new_ants[i]\n                    fitness[i] = new_fitness[i]\n                    num_successful += 1\n\n            # Replace the worst ants with elites\n            ants[-num_elites:] = elites\n            fitness[-num_elites:] = elite_fitness\n\n            # Update best solution\n            current_best_fitness = np.min(fitness)\n            current_best_ant = ants[np.argmin(fitness)]\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_ant\n                self.step_size *= self.intensify_rate\n            else:\n                self.step_size *= self.decay_rate\n            \n            # Radius decay\n            self.radius *= self.radius_decay\n            self.radius = np.clip(self.radius, 1e-6, 2.5)\n\n            # Ensure step size remains within reasonable bounds\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n            \n            if self.colony_size > 0:\n                success_rate = num_successful / self.colony_size\n            \n            if success_rate > 0.4:\n                self.step_size *= self.intensify_rate  # Intensify search\n            else:\n                self.step_size *= self.decay_rate  # Reduce step-size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveAntDE scored 0.625 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid ant colony optimization algorithm combining adaptive step size, differential evolution mutation, elitism, and hypersphere sampling with radius adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveAntDE:\n    def __init__(self, budget=10000, dim=10, colony_size=20, initial_step_size=1.0, decay_rate=0.95, intensify_rate=1.05, elitism_factor=0.1, hypersphere_prob=0.2, de_mutation_factor=0.5, radius_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.step_size = initial_step_size\n        self.decay_rate = decay_rate\n        self.intensify_rate = intensify_rate\n        self.elitism_factor = elitism_factor\n        self.hypersphere_prob = hypersphere_prob\n        self.de_mutation_factor = de_mutation_factor\n        self.radius_decay = radius_decay\n        self.radius = 2.5\n\n    def __call__(self, func):\n        # Initialize ant positions randomly\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.array([func(ant) for ant in ants])\n        self.budget -= self.colony_size\n        \n        self.f_opt = np.min(fitness)\n        self.x_opt = ants[np.argmin(fitness)]\n        \n        success_rate = 0.5  # Initialize success rate\n        \n        while self.budget > 0:\n            # Sort ants by fitness\n            sorted_indices = np.argsort(fitness)\n            ants = ants[sorted_indices]\n            fitness = fitness[sorted_indices]\n            \n            # Elitism: Keep the best ants\n            num_elites = int(self.colony_size * self.elitism_factor)\n            elites = ants[:num_elites].copy()\n            elite_fitness = fitness[:num_elites].copy()\n\n            # Determine the best ant (leader)\n            leader = ants[0]\n\n            # Move ants based on the leader and adaptive step size\n            new_ants = np.zeros_like(ants)\n            num_successful = 0\n            for i in range(self.colony_size):\n                if np.random.rand() < self.hypersphere_prob:\n                    # Hypersphere sampling\n                    direction = np.random.normal(0, 1, size=self.dim)\n                    direction /= np.linalg.norm(direction)\n                    new_ants[i] = ants[i] + self.radius * direction\n                    new_ants[i] = np.clip(new_ants[i], func.bounds.lb, func.bounds.ub)\n                else:\n                    # Ant colony movement with leader influence and DE mutation\n                    idxs = np.random.choice(self.colony_size, 3, replace=False)\n                    a, b, c = ants[idxs]\n                    diff = a - b\n                    mutation = self.de_mutation_factor * diff\n\n                    direction = leader - ants[i] + mutation + np.random.normal(0, self.step_size, size=self.dim)\n                    new_ants[i] = ants[i] + direction\n                    new_ants[i] = np.clip(new_ants[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the new ant positions\n            new_fitness = np.array([func(ant) for ant in new_ants])\n            self.budget -= self.colony_size\n\n            # Update the colony (selection)\n            for i in range(self.colony_size):\n                if new_fitness[i] < fitness[i]:\n                    ants[i] = new_ants[i]\n                    fitness[i] = new_fitness[i]\n                    num_successful += 1\n\n            # Replace the worst ants with elites\n            ants[-num_elites:] = elites\n            fitness[-num_elites:] = elite_fitness\n\n            # Update best solution\n            current_best_fitness = np.min(fitness)\n            current_best_ant = ants[np.argmin(fitness)]\n\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = current_best_ant\n                self.step_size *= self.intensify_rate\n            else:\n                self.step_size *= self.decay_rate\n            \n            # Radius decay\n            self.radius *= self.radius_decay\n            self.radius = np.clip(self.radius, 1e-6, 2.5)\n\n            # Ensure step size remains within reasonable bounds\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n            \n            if self.colony_size > 0:\n                success_rate = num_successful / self.colony_size\n            \n            if success_rate > 0.4:\n                self.step_size *= self.intensify_rate  # Intensify search\n            else:\n                self.step_size *= self.decay_rate  # Reduce step-size\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18811163479311965, 0.2224765451170786, 0.8561884939845228, 0.9441074947400584, 0.8622685336130238, 0.8834742701537273, 0.32044028531591573, 0.7803528496072947, 0.8690458128711297, 0.1994264630453766, 0.9303055154336427, 0.9995166537455903, 0.26138613564519586, 0.30546224952286005, 0.9555038313467301, 0.7779081020159966, 0.5014758965307289, 0.9123100269068198, 0.23020676274544505, 0.5096495480458059], "operator": "crossover", "theta_sampled": -0.00017968239540035115, "reward": 0.024543003025534915, "generation": 5}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-2", "seed": 2}
