{"id": "cce83040-c009-4ae5-bbf5-d790194c1284", "fitness": 0.0, "name": "CMAES", "description": "Population-based algorithm with covariance matrix adaptation and restart mechanism.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.mean = None  # Initialize in __call__\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_trigger = False\n\n\n    def sample_population(self, func):\n         # Ensure population is within bounds\n        population = self.mean + self.sigma0 * (self.B @ (self.D * np.random.randn(self.dim, self.popsize)))\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        for j in range(self.popsize):\n            population[:, j] = np.clip(population[:, j], lb, ub)\n        return population\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize mean within bounds\n\n        while self.evals < self.budget:\n            # 1. Sample population\n            population = self.sample_population(func)\n\n            # 2. Evaluate population\n            fitness = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                if self.evals < self.budget:\n                    fitness[i] = func(population[:, i])\n                    self.evals += 1\n                else:\n                    fitness[i] = np.inf # or some large value\n            \n            # 3. Sort population\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            population = population[:, indices]\n\n            # 4. Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[:, 0]\n\n            # 5. Update CMA-ES parameters\n            y = population[:, :self.mu] - self.mean[:, None]\n            z = np.linalg.solve(self.B @ np.diag(self.D), y)\n\n            self.mean = self.mean + self.cs * self.sigma0 * (self.B @ (self.D * (self.weights @ z.T)))\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ (self.D * (self.weights @ z.T)))\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals / self.popsize)) < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (self.weights @ y.T)\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n\n            self.sigma0 *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n\n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16)) # Avoid negative or zero values\n            except np.linalg.LinAlgError:\n                # Restart mechanism if covariance matrix becomes ill-conditioned\n                self.restart_trigger = True\n            \n            if self.restart_trigger:\n                 # Resetting CMA-ES parameters to restart exploration\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma0 = 0.2 # Resetting sigma0 is crucial\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.restart_trigger = False\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,) (2,6) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with covariance matrix adaptation and restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.mean = None  # Initialize in __call__\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n        self.restart_trigger = False\n\n\n    def sample_population(self, func):\n         # Ensure population is within bounds\n        population = self.mean + self.sigma0 * (self.B @ (self.D * np.random.randn(self.dim, self.popsize)))\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        for j in range(self.popsize):\n            population[:, j] = np.clip(population[:, j], lb, ub)\n        return population\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize mean within bounds\n\n        while self.evals < self.budget:\n            # 1. Sample population\n            population = self.sample_population(func)\n\n            # 2. Evaluate population\n            fitness = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                if self.evals < self.budget:\n                    fitness[i] = func(population[:, i])\n                    self.evals += 1\n                else:\n                    fitness[i] = np.inf # or some large value\n            \n            # 3. Sort population\n            indices = np.argsort(fitness)\n            fitness = fitness[indices]\n            population = population[:, indices]\n\n            # 4. Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[:, 0]\n\n            # 5. Update CMA-ES parameters\n            y = population[:, :self.mu] - self.mean[:, None]\n            z = np.linalg.solve(self.B @ np.diag(self.D), y)\n\n            self.mean = self.mean + self.cs * self.sigma0 * (self.B @ (self.D * (self.weights @ z.T)))\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ (self.D * (self.weights @ z.T)))\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.evals / self.popsize)) < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (self.weights @ y.T)\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, None] @ self.pc[None, :]) + self.cmu * (y @ np.diag(self.weights) @ y.T)\n\n            self.sigma0 *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / np.sqrt(self.dim) - 1))\n\n\n            try:\n                self.D, self.B = np.linalg.eigh(self.C)\n                self.D = np.sqrt(np.maximum(self.D, 1e-16)) # Avoid negative or zero values\n            except np.linalg.LinAlgError:\n                # Restart mechanism if covariance matrix becomes ill-conditioned\n                self.restart_trigger = True\n            \n            if self.restart_trigger:\n                 # Resetting CMA-ES parameters to restart exploration\n                self.B = np.eye(self.dim)\n                self.D = np.ones(self.dim)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma0 = 0.2 # Resetting sigma0 is crucial\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.restart_trigger = False\n\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "a514c62f-698d-4f68-a14f-5bfb1e8ab563", "fitness": 0.0, "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget-aware adaptation of population size.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n        \n        for restart in range(self.restarts):\n            # Adapt population size based on remaining budget\n            N = int(4 + 3 * np.log(self.dim))  # Base population size\n            remaining_budget = self.budget - evals_used\n            \n            if remaining_budget <= 0:\n                break\n            \n            # Dynamically adjust N.  Ensure N > 0. Can't be more than budget.\n            N = max(1, min(N, remaining_budget))\n\n            mu = N // 2  # Number of parents/selected solutions\n            \n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n\n            # Evolution path and step size control\n            ps = np.zeros(self.dim)\n            pc = np.zeros(self.dim)\n            chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))  # Expectation of ||N(0,I)||\n\n            # Learning rates\n            c_sigma = (mu + 2) / (self.dim + mu + 5)\n            c_c = (4 + mu / self.dim) / (self.dim + 4 + 2 * mu / self.dim)\n            c_cov = (1 / (2 + np.sqrt(self.dim))) * (mu / (self.dim + 2)) #original\n            c_cov_mu = (2 / ((self.dim + np.sqrt(2))**2)) * mu\n\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = weights / np.sum(weights)  # Normalize weights\n\n            # Precompute constants\n            B, D = np.linalg.eig(C) # Eigen decomposition, expensive so do before the loop\n            B = np.real(B)\n            D = np.real(D)\n\n            D = np.sqrt(D)\n\n            generation = 0\n            while evals_used < self.budget and generation < 500:  # added generation limit\n                generation += 1\n                # Generate offspring\n                z = np.random.normal(0, 1, size=(self.dim, N))\n                x = mean[:, np.newaxis] + sigma * (B @ (D * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Clip the values\n\n                # Evaluate offspring\n                f = np.array([func(x[:, i]) for i in range(N)])\n                evals_used += N\n\n                # Sort offspring\n                indices = np.argsort(f)\n                x_sorted = x[:, indices]\n                f_sorted = f[indices]\n\n                # Update optimal solution\n                if f_sorted[0] < self.f_opt:\n                    self.f_opt = f_sorted[0]\n                    self.x_opt = x_sorted[:, 0].copy() # make a copy to avoid changes later\n\n                # Update mean\n                mean_new = np.sum(weights * x_sorted[:, :mu], axis=1)\n                \n                # Update evolution paths\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mu) * (B @ z[:, indices[:mu]].mean(axis=1))\n                \n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * (evals_used // N))) < (1.4 + 2 / (self.dim + 1)) * chiN # simplified conditional\n\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c) * mu) * (mean_new - mean) / sigma\n                \n                # Update covariance matrix\n                C = (1 - c_cov - c_cov_mu) * C + c_cov * (np.outer(pc, pc) + (1 - hsig) * c_c * (2 - c_c) * C)\n                C += c_cov_mu * (x_sorted[:, :mu] - mean[:, np.newaxis]) @ np.diag(weights) @ (x_sorted[:, :mu] - mean[:, np.newaxis]).T / sigma**2\n                \n                # Update step size\n                sigma = sigma * np.exp((c_sigma / 0.25) * (np.linalg.norm(ps) / chiN - 1))\n                \n                # Ensure C is positive definite by adding a small value\n                C = np.triu(C) + np.triu(C, k=1).T\n                C += 1e-8 * np.eye(self.dim)\n\n                # Eigen decomposition, expensive\n                B, D = np.linalg.eig(C)\n                B = np.real(B)\n                D = np.real(D)\n                D = np.sqrt(D)\n\n                # Update mean\n                mean = mean_new\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,2) (2,6) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and budget-aware adaptation of population size.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.restarts = restarts\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n        \n        for restart in range(self.restarts):\n            # Adapt population size based on remaining budget\n            N = int(4 + 3 * np.log(self.dim))  # Base population size\n            remaining_budget = self.budget - evals_used\n            \n            if remaining_budget <= 0:\n                break\n            \n            # Dynamically adjust N.  Ensure N > 0. Can't be more than budget.\n            N = max(1, min(N, remaining_budget))\n\n            mu = N // 2  # Number of parents/selected solutions\n            \n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n\n            # Evolution path and step size control\n            ps = np.zeros(self.dim)\n            pc = np.zeros(self.dim)\n            chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))  # Expectation of ||N(0,I)||\n\n            # Learning rates\n            c_sigma = (mu + 2) / (self.dim + mu + 5)\n            c_c = (4 + mu / self.dim) / (self.dim + 4 + 2 * mu / self.dim)\n            c_cov = (1 / (2 + np.sqrt(self.dim))) * (mu / (self.dim + 2)) #original\n            c_cov_mu = (2 / ((self.dim + np.sqrt(2))**2)) * mu\n\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = weights / np.sum(weights)  # Normalize weights\n\n            # Precompute constants\n            B, D = np.linalg.eig(C) # Eigen decomposition, expensive so do before the loop\n            B = np.real(B)\n            D = np.real(D)\n\n            D = np.sqrt(D)\n\n            generation = 0\n            while evals_used < self.budget and generation < 500:  # added generation limit\n                generation += 1\n                # Generate offspring\n                z = np.random.normal(0, 1, size=(self.dim, N))\n                x = mean[:, np.newaxis] + sigma * (B @ (D * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Clip the values\n\n                # Evaluate offspring\n                f = np.array([func(x[:, i]) for i in range(N)])\n                evals_used += N\n\n                # Sort offspring\n                indices = np.argsort(f)\n                x_sorted = x[:, indices]\n                f_sorted = f[indices]\n\n                # Update optimal solution\n                if f_sorted[0] < self.f_opt:\n                    self.f_opt = f_sorted[0]\n                    self.x_opt = x_sorted[:, 0].copy() # make a copy to avoid changes later\n\n                # Update mean\n                mean_new = np.sum(weights * x_sorted[:, :mu], axis=1)\n                \n                # Update evolution paths\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mu) * (B @ z[:, indices[:mu]].mean(axis=1))\n                \n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * (evals_used // N))) < (1.4 + 2 / (self.dim + 1)) * chiN # simplified conditional\n\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c) * mu) * (mean_new - mean) / sigma\n                \n                # Update covariance matrix\n                C = (1 - c_cov - c_cov_mu) * C + c_cov * (np.outer(pc, pc) + (1 - hsig) * c_c * (2 - c_c) * C)\n                C += c_cov_mu * (x_sorted[:, :mu] - mean[:, np.newaxis]) @ np.diag(weights) @ (x_sorted[:, :mu] - mean[:, np.newaxis]).T / sigma**2\n                \n                # Update step size\n                sigma = sigma * np.exp((c_sigma / 0.25) * (np.linalg.norm(ps) / chiN - 1))\n                \n                # Ensure C is positive definite by adding a small value\n                C = np.triu(C) + np.triu(C, k=1).T\n                C += 1e-8 * np.eye(self.dim)\n\n                # Eigen decomposition, expensive\n                B, D = np.linalg.eig(C)\n                B = np.real(B)\n                D = np.real(D)\n                D = np.sqrt(D)\n\n                # Update mean\n                mean = mean_new\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "159736a4-baa0-42cc-9a04-3f30afb5d611", "fitness": 0.6720383443271793, "name": "AdaptiveDifferentialEvolution", "description": "A population-based algorithm with a combination of global exploration using a Cauchy mutation and local exploitation using a Gaussian mutation, with adaptive step size control.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop,func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.672 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm with a combination of global exploration using a Cauchy mutation and local exploitation using a Gaussian mutation, with adaptive step size control.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop,func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2541948117943166, 0.6320180076735289, 0.6303848459305343, 0.8550387764975487, 0.7163514836202454, 0.76498606369955, 0.6240340537914189, 0.6165391130315317, 0.7039075472131462, 0.6370380429609971, 0.828514241141262, 0.997926453574308, 0.6310326015444662, 0.686630131470547, 0.8870087146296671, 0.7515543887232872, 0.5790424644651164, 0.817805305658182, 0.3020812663754048, 0.5246785727485292], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "9217ed5d-78a2-47f2-9d52-268e2fdec772", "fitness": 0.6313826370842432, "name": "ParticleSwarmOptimizer", "description": "A particle swarm optimization (PSO) algorithm with velocity clamping and constriction factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729  # Standard value for constriction factor PSO\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        eval_count = self.swarm_size #Account for initial swarm evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if eval_count >= self.budget:\n                break\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm ParticleSwarmOptimizer scored 0.631 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A particle swarm optimization (PSO) algorithm with velocity clamping and constriction factor to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729  # Standard value for constriction factor PSO\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        eval_count = self.swarm_size #Account for initial swarm evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if eval_count >= self.budget:\n                break\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.3078415911504977, 0.3509879137388522, 0.8941693462320857, 0.9482782167818904, 0.8958925061990128, 0.9087729599518626, 0.2656038484608363, 0.6126903983771397, 0.8943749556199908, 0.20149000940109274, 0.9409823285975303, 0.9985106153404466, 0.2742130151977872, 0.34243832349166536, 0.9528151191768512, 0.8908533262728836, 0.30280549515348043, 0.921180726502335, 0.21636249360197857, 0.5073895524366454], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "d34fe92d-4db5-4ea0-8b6e-b89f1a34f68c", "fitness": 0.7482370340537732, "name": "EnsembleAdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with ensemble of mutation strategies and self-adaptive parameters.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                mutation_idx = mutation_indices[i]\n                mutator = self.mutation_strategies[mutation_idx]\n                mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnsembleAdaptiveDifferentialEvolution scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with ensemble of mutation strategies and self-adaptive parameters.\n# Code: \n```python\nimport numpy as np\n\nclass EnsembleAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                mutation_idx = mutation_indices[i]\n                mutator = self.mutation_strategies[mutation_idx]\n                mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3596699016295106, 0.7436843452504429, 0.7623265839315538, 0.9006463171904885, 0.7944545916423189, 0.8306955823216504, 0.6715565204341083, 0.7103706254219846, 0.7896346045972149, 0.6942019283262888, 0.8970216024109627, 0.9934686467698397, 0.6865279147510452, 0.7890873060819168, 0.9466552424252062, 0.817775936447973, 0.6710503517246975, 0.8734966247017628, 0.5202315451523263, 0.5121845098641719], "operator": "mutation", "theta_sampled": 0.06880030279543589, "reward": 0.07619868972659383, "generation": 1}, "task_prompt": ""}
{"id": "0b69eef2-a4b3-4a61-961d-34b8d69a5888", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionAgingRestart", "description": "Adaptive Differential Evolution with Aging and Restart, periodically restarting the population and introducing age-based selection to prevent stagnation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionAgingRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, age_limit=50, restart_interval=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.age = None  # Age of each individual\n        self.age_limit = age_limit\n        self.restart_interval = restart_interval # restart interval\n        self.step_size = 0.1\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.age = np.zeros(self.pop_size, dtype=int)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, func, i):\n        if np.random.rand() < 0.1:\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = pop[i] + mutation\n        else:\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            self.age[i] = 0  # Reset age upon improvement\n\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True\n        else:\n            self.age[i] += 1  # Increment age if no improvement\n            return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def restart_population(self, func):\n         # Replace the worst individuals with new random individuals\n        num_to_replace = self.pop_size // 4\n        worst_indices = np.argsort(self.fitness)[-num_to_replace:] # indices of the worst individuals\n\n        for i in worst_indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            self.age[i] = 0\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def handle_aging(self, func):\n        # Replace old individuals to encourage exploration\n        for i in range(self.pop_size):\n            if self.age[i] > self.age_limit:\n                self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                self.fitness[i] = func(self.population[i])\n                self.age[i] = 0\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            self.handle_aging(func) #apply aging\n\n            if eval_count % self.restart_interval == 0:\n                self.restart_population(func) # restart periodically\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolutionAgingRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Aging and Restart, periodically restarting the population and introducing age-based selection to prevent stagnation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionAgingRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, age_limit=50, restart_interval=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.age = None  # Age of each individual\n        self.age_limit = age_limit\n        self.restart_interval = restart_interval # restart interval\n        self.step_size = 0.1\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.age = np.zeros(self.pop_size, dtype=int)\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, func, i):\n        if np.random.rand() < 0.1:\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = pop[i] + mutation\n        else:\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            self.age[i] = 0  # Reset age upon improvement\n\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True\n        else:\n            self.age[i] += 1  # Increment age if no improvement\n            return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def restart_population(self, func):\n         # Replace the worst individuals with new random individuals\n        num_to_replace = self.pop_size // 4\n        worst_indices = np.argsort(self.fitness)[-num_to_replace:] # indices of the worst individuals\n\n        for i in worst_indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            self.age[i] = 0\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n    def handle_aging(self, func):\n        # Replace old individuals to encourage exploration\n        for i in range(self.pop_size):\n            if self.age[i] > self.age_limit:\n                self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                self.fitness[i] = func(self.population[i])\n                self.age[i] = 0\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            self.handle_aging(func) #apply aging\n\n            if eval_count % self.restart_interval == 0:\n                self.restart_population(func) # restart periodically\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.16984224834446496, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "7ae53d92-ff62-40ea-b77b-7ff604222964", "fitness": 0.6336048578902316, "name": "HybridDEPSO", "description": "A hybrid algorithm combining Adaptive Differential Evolution's mutation and crossover with Particle Swarm Optimization's velocity update and constriction factor for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729  # Standard value for constriction factor PSO\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n\n    def mutate(self, func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = self.population[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, i, mutant):\n        trial = self.population[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def update_velocity(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n\n        self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n        # Velocity clamping\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        max_velocity = self.velocity_clamp_factor * (ub - lb)\n        self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n        # Update position\n        self.population[i] = self.population[i] + self.velocities[i]\n        self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size #Account for initial swarm evaluation\n        \n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # DE Mutation and Crossover\n                mutant = self.mutate(func, i)\n                trial = self.crossover(i, mutant)\n                \n                # Evaluate trial vector\n                f_trial = func(trial)\n                eval_count += 1\n\n                # PSO Velocity update\n                self.update_velocity(i, func)\n                f_pso = func(self.population[i])\n                eval_count += 1\n\n\n                # Selection: Compare trial to original and personal best\n                if f_trial < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()  # Store a copy\n                    self.population[i] = trial.copy()\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n\n                elif f_pso < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_pso\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_pso\n                        self.global_best_position = self.population[i].copy()\n\n\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO scored 0.634 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid algorithm combining Adaptive Differential Evolution's mutation and crossover with Particle Swarm Optimization's velocity update and constriction factor for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729  # Standard value for constriction factor PSO\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n\n    def mutate(self, func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = self.population[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, i, mutant):\n        trial = self.population[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def update_velocity(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n\n        self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n        # Velocity clamping\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        max_velocity = self.velocity_clamp_factor * (ub - lb)\n        self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n        # Update position\n        self.population[i] = self.population[i] + self.velocities[i]\n        self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size #Account for initial swarm evaluation\n        \n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                # DE Mutation and Crossover\n                mutant = self.mutate(func, i)\n                trial = self.crossover(i, mutant)\n                \n                # Evaluate trial vector\n                f_trial = func(trial)\n                eval_count += 1\n\n                # PSO Velocity update\n                self.update_velocity(i, func)\n                f_pso = func(self.population[i])\n                eval_count += 1\n\n\n                # Selection: Compare trial to original and personal best\n                if f_trial < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()  # Store a copy\n                    self.population[i] = trial.copy()\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n\n                elif f_pso < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_pso\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_pso\n                        self.global_best_position = self.population[i].copy()\n\n\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.33732014236888286, 0.23126015784906284, 0.768595841664187, 0.9161950450517031, 0.79982740894057, 0.838297385719849, 0.35856829823396397, 0.7297465837401895, 0.7893776529411585, 0.779783376339382, 0.8557032024608116, 0.9984887231719398, 0.26896296469501035, 0.3337650400382164, 0.7433200093430421, 0.8301674944064705, 0.4364778239863646, 0.8677893549003487, 0.27173859132189504, 0.5167120606315823], "operator": "crossover", "theta_sampled": 0.12067458348374771, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "81be8f47-9833-4f48-b01b-19b32ca7536a", "fitness": 0.5284870073629502, "name": "HybridDEPSO", "description": "A hybrid algorithm combining Adaptive Differential Evolution's mutation and crossover with Particle Swarm Optimization's social learning, adapting step sizes and inertia for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = []\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.eval_count = 0 # Track function evaluations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = self.fitness.copy()\n\n\n    def mutate(self, pop,func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n\n            if f_trial < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = f_trial\n                self.personal_best_positions[i] = trial.copy()\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def update_velocity(self, i, current_inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.x_opt - self.population[i]) #Global best from DE\n\n        velocity = current_inertia * (self.population[i] - self.personal_best_positions[i]) + cognitive_component + social_component\n        return velocity\n    \n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            #Linear decreasing inertia\n            current_inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (self.eval_count / self.budget)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                if self.eval_count >= self.budget:\n                    break\n\n                # PSO update using DE's global best\n                velocity = self.update_velocity(i, current_inertia)\n                self.population[i] = self.population[i] + velocity #Update position\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n\n                f_current = func(self.population[i])\n                self.eval_count += 1\n\n                if f_current < self.fitness[i]:\n                    self.fitness[i] = f_current\n\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = self.population[i].copy()\n                \n                if f_current < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_current\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid algorithm combining Adaptive Differential Evolution's mutation and crossover with Particle Swarm Optimization's social learning, adapting step sizes and inertia for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = []\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.eval_count = 0 # Track function evaluations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = self.fitness.copy()\n\n\n    def mutate(self, pop,func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        self.eval_count += 1\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n\n            if f_trial < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = f_trial\n                self.personal_best_positions[i] = trial.copy()\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def update_velocity(self, i, current_inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.x_opt - self.population[i]) #Global best from DE\n\n        velocity = current_inertia * (self.population[i] - self.personal_best_positions[i]) + cognitive_component + social_component\n        return velocity\n    \n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            #Linear decreasing inertia\n            current_inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (self.eval_count / self.budget)\n\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                if self.eval_count >= self.budget:\n                    break\n\n                # PSO update using DE's global best\n                velocity = self.update_velocity(i, current_inertia)\n                self.population[i] = self.population[i] + velocity #Update position\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n\n                f_current = func(self.population[i])\n                self.eval_count += 1\n\n                if f_current < self.fitness[i]:\n                    self.fitness[i] = f_current\n\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = self.population[i].copy()\n                \n                if f_current < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_current\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2187602475095053, 0.18651827371962315, 0.7958287084260334, 0.9597816912003835, 0.28451995992167334, 0.9473278922830578, 0.3271688293637981, 0.6226030269284207, 0.27020287292878065, 0.192042362642462, 0.5421447537995585, 0.9987648935175737, 0.22429862450730442, 0.5669708315721358, 0.8008479140683066, 0.6693876594183996, 0.28495510141042446, 0.9529649194722736, 0.22511352832675935, 0.49953805624253067], "operator": "crossover", "theta_sampled": 0.2811468657406571, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "bf992792-e100-4566-b6ad-32231ff67b79", "fitness": 0.0, "name": "AdaptiveSimplexRestart", "description": "An algorithm that combines Nelder-Mead simplex-based search with random restarts and adaptive scaling based on function evaluation history.", "code": "import numpy as np\n\nclass AdaptiveSimplexRestart:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_probability = restart_probability\n        self.f_history = []\n        self.simplex_size_scale = 1.0\n        self.simplex_size_min = 1e-6\n        self.simplex_size_max = 1.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        def evaluate(x):\n            nonlocal eval_count\n            if eval_count < self.budget:\n                eval_count += 1\n                f = func(x)\n                self.f_history.append(f)\n                return f\n            else:\n                return np.inf  # Budget exhausted\n\n        def initialize_simplex(x0):\n            simplex = [x0]\n            for i in range(self.dim):\n                x = np.copy(x0)\n                x[i] += self.initial_simplex_size * self.simplex_size_scale\n                simplex.append(x)\n            return np.array(simplex)\n\n        def nelder_mead(simplex, alpha=1.0, beta=0.5, gamma=2.0):\n            nonlocal self.f_opt, self.x_opt\n\n            while eval_count < self.budget:\n                # 1. Order\n                fitnesses = np.array([evaluate(x) for x in simplex])\n                if eval_count >= self.budget:\n                    break #Early exit, budget exceeded\n\n                order = np.argsort(fitnesses)\n                simplex = simplex[order]\n                fitnesses = fitnesses[order]\n                best_x = simplex[0]\n                best_f = fitnesses[0]\n                worst_x = simplex[-1]\n                worst_f = fitnesses[-1]\n                second_worst_x = simplex[-2]\n\n                if best_f < self.f_opt:\n                    self.f_opt = best_f\n                    self.x_opt = best_x\n\n                # 2. Reflect\n                centroid = np.mean(simplex[:-1], axis=0)\n                x_reflected = centroid + alpha * (centroid - worst_x)\n                f_reflected = evaluate(x_reflected)\n                if eval_count >= self.budget:\n                    break #Early exit, budget exceeded\n\n                if fitnesses[0] <= f_reflected < fitnesses[-2]:\n                    simplex[-1] = x_reflected\n\n                # 3. Expand\n                elif f_reflected < fitnesses[0]:\n                    x_expanded = centroid + gamma * (x_reflected - centroid)\n                    f_expanded = evaluate(x_expanded)\n                    if eval_count >= self.budget:\n                        break #Early exit, budget exceeded\n                    if f_expanded < f_reflected:\n                        simplex[-1] = x_expanded\n                    else:\n                        simplex[-1] = x_reflected\n\n                # 4. Contract\n                else:\n                    x_contracted = centroid + beta * (worst_x - centroid)\n                    f_contracted = evaluate(x_contracted)\n                    if eval_count >= self.budget:\n                        break #Early exit, budget exceeded\n                    if f_contracted < worst_f:\n                        simplex[-1] = x_contracted\n                    else:\n                        # 5. Shrink\n                        for i in range(1, len(simplex)):\n                            simplex[i] = best_x + beta * (simplex[i] - best_x)\n\n                #Adaptive Simplex Size scaling based on recent function value history\n                if len(self.f_history) > 100:\n                   recent_improvement = np.mean(self.f_history[-50:]) - np.mean(self.f_history[-100:-50])\n\n                   if recent_improvement < 0: # Recent improvement\n                        self.simplex_size_scale = min(self.simplex_size_scale * 1.1, self.simplex_size_max)\n                   else:\n                       self.simplex_size_scale = max(self.simplex_size_scale * 0.9, self.simplex_size_min)\n\n                if np.random.rand() < self.restart_probability:\n                    break  # Restart\n\n            return simplex[0], fitnesses[0]\n\n        # Main loop with restarts\n        while eval_count < self.budget:\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            simplex = initialize_simplex(x0)\n            best_x, best_f = nelder_mead(simplex)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: invalid syntax (<string>, line 39)", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An algorithm that combines Nelder-Mead simplex-based search with random restarts and adaptive scaling based on function evaluation history.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSimplexRestart:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.restart_probability = restart_probability\n        self.f_history = []\n        self.simplex_size_scale = 1.0\n        self.simplex_size_min = 1e-6\n        self.simplex_size_max = 1.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        def evaluate(x):\n            nonlocal eval_count\n            if eval_count < self.budget:\n                eval_count += 1\n                f = func(x)\n                self.f_history.append(f)\n                return f\n            else:\n                return np.inf  # Budget exhausted\n\n        def initialize_simplex(x0):\n            simplex = [x0]\n            for i in range(self.dim):\n                x = np.copy(x0)\n                x[i] += self.initial_simplex_size * self.simplex_size_scale\n                simplex.append(x)\n            return np.array(simplex)\n\n        def nelder_mead(simplex, alpha=1.0, beta=0.5, gamma=2.0):\n            nonlocal self.f_opt, self.x_opt\n\n            while eval_count < self.budget:\n                # 1. Order\n                fitnesses = np.array([evaluate(x) for x in simplex])\n                if eval_count >= self.budget:\n                    break #Early exit, budget exceeded\n\n                order = np.argsort(fitnesses)\n                simplex = simplex[order]\n                fitnesses = fitnesses[order]\n                best_x = simplex[0]\n                best_f = fitnesses[0]\n                worst_x = simplex[-1]\n                worst_f = fitnesses[-1]\n                second_worst_x = simplex[-2]\n\n                if best_f < self.f_opt:\n                    self.f_opt = best_f\n                    self.x_opt = best_x\n\n                # 2. Reflect\n                centroid = np.mean(simplex[:-1], axis=0)\n                x_reflected = centroid + alpha * (centroid - worst_x)\n                f_reflected = evaluate(x_reflected)\n                if eval_count >= self.budget:\n                    break #Early exit, budget exceeded\n\n                if fitnesses[0] <= f_reflected < fitnesses[-2]:\n                    simplex[-1] = x_reflected\n\n                # 3. Expand\n                elif f_reflected < fitnesses[0]:\n                    x_expanded = centroid + gamma * (x_reflected - centroid)\n                    f_expanded = evaluate(x_expanded)\n                    if eval_count >= self.budget:\n                        break #Early exit, budget exceeded\n                    if f_expanded < f_reflected:\n                        simplex[-1] = x_expanded\n                    else:\n                        simplex[-1] = x_reflected\n\n                # 4. Contract\n                else:\n                    x_contracted = centroid + beta * (worst_x - centroid)\n                    f_contracted = evaluate(x_contracted)\n                    if eval_count >= self.budget:\n                        break #Early exit, budget exceeded\n                    if f_contracted < worst_f:\n                        simplex[-1] = x_contracted\n                    else:\n                        # 5. Shrink\n                        for i in range(1, len(simplex)):\n                            simplex[i] = best_x + beta * (simplex[i] - best_x)\n\n                #Adaptive Simplex Size scaling based on recent function value history\n                if len(self.f_history) > 100:\n                   recent_improvement = np.mean(self.f_history[-50:]) - np.mean(self.f_history[-100:-50])\n\n                   if recent_improvement < 0: # Recent improvement\n                        self.simplex_size_scale = min(self.simplex_size_scale * 1.1, self.simplex_size_max)\n                   else:\n                       self.simplex_size_scale = max(self.simplex_size_scale * 0.9, self.simplex_size_min)\n\n                if np.random.rand() < self.restart_probability:\n                    break  # Restart\n\n            return simplex[0], fitnesses[0]\n\n        # Main loop with restarts\n        while eval_count < self.budget:\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            simplex = initialize_simplex(x0)\n            best_x, best_f = nelder_mead(simplex)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.14076579449007368, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "2924a2a7-05eb-4fc7-829c-9ee831759877", "fitness": 0.0, "name": "EnhancedParticleSwarmOptimizer", "description": "A PSO variant with velocity mutation, dynamic inertia, and adaptive velocity clamping to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor_start=0.3, velocity_clamp_factor_end=0.05, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor_start = velocity_clamp_factor_start\n        self.velocity_clamp_factor_end = velocity_clamp_factor_end\n        self.mutation_rate = mutation_rate\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor_start * (ub - lb), self.velocity_clamp_factor_start * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Dynamic inertia and velocity clamping factor\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (self.eval_count / self.budget)\n            velocity_clamp_factor = self.velocity_clamp_factor_start - (self.velocity_clamp_factor_start - self.velocity_clamp_factor_end) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Velocity mutation\n                mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n                self.velocities[i][mutation_mask] = np.random.uniform(-velocity_clamp_factor * (func.bounds.ub - func.bounds.lb), velocity_clamp_factor * (func.bounds.ub - func.bounds.lb), size=np.sum(mutation_mask))\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A PSO variant with velocity mutation, dynamic inertia, and adaptive velocity clamping to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor_start=0.3, velocity_clamp_factor_end=0.05, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor_start = velocity_clamp_factor_start\n        self.velocity_clamp_factor_end = velocity_clamp_factor_end\n        self.mutation_rate = mutation_rate\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor_start * (ub - lb), self.velocity_clamp_factor_start * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Dynamic inertia and velocity clamping factor\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (self.eval_count / self.budget)\n            velocity_clamp_factor = self.velocity_clamp_factor_start - (self.velocity_clamp_factor_start - self.velocity_clamp_factor_end) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Velocity mutation\n                mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n                self.velocities[i][mutation_mask] = np.random.uniform(-velocity_clamp_factor * (func.bounds.ub - func.bounds.lb), velocity_clamp_factor * (func.bounds.ub - func.bounds.lb), size=np.sum(mutation_mask))\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.10323536347507353, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "8e4ba1f3-739f-4814-bb44-159b1aa1dad5", "fitness": 0.0, "name": "AdaptivePSO", "description": "A PSO variant with velocity mutation and adaptive inertia weight to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.mutation_rate = mutation_rate\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight (linearly decreasing)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n                # Mutation (applied to velocity)\n                mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n                self.velocities[i][mutation_mask] = np.random.uniform(-max_velocity, max_velocity, size=np.sum(mutation_mask))\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A PSO variant with velocity mutation and adaptive inertia weight to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.mutation_rate = mutation_rate\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.swarm_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.full(self.swarm_size, np.inf)\n\n        for i in range(self.swarm_size):\n            fitness = func(self.particles[i])\n            self.eval_count += 1\n            if fitness < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = fitness\n                \n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive Inertia Weight (linearly decreasing)\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.eval_count / self.budget)\n\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n\n                # Velocity clamping\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n\n                # Mutation (applied to velocity)\n                mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n                self.velocities[i][mutation_mask] = np.random.uniform(-max_velocity, max_velocity, size=np.sum(mutation_mask))\n\n                # Update position\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)  # Keep particles within bounds\n\n                # Evaluate fitness\n                fitness = func(self.particles[i])\n                self.eval_count += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = self.particles[i].copy()\n            \n            if self.eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "mutation", "theta_sampled": 0.026472438972777984, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "0999c448-78aa-479d-8ad0-89ccc66ecf04", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionWithRejuvenation", "description": "An adaptive differential evolution algorithm that utilizes a combination of Cauchy and Gaussian mutations, adaptive step size control based on success history, and periodic population rejuvenation to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionWithRejuvenation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, rejuvenation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.rejuvenation_rate = rejuvenation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n\n    def initialize_population(self, func):\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        self.population = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, self.bounds_lb, self.bounds_ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def rejuvenate_population(self):\n        \"\"\"Replaces a fraction of the population with new random individuals.\"\"\"\n        num_rejuvenated = int(self.rejuvenation_rate * self.pop_size)\n        indices_to_rejuvenate = np.random.choice(self.pop_size, num_rejuvenated, replace=False)\n        \n        new_individuals = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(num_rejuvenated, self.dim))\n\n        for i, idx in enumerate(indices_to_rejuvenate):\n            self.population[idx] = new_individuals[i]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n            \n            # Rejuvenate population periodically\n            if eval_count % (self.budget // 10) == 0:  # Rejuvenate every 10% of the budget\n                self.rejuvenate_population()\n                self.fitness = np.array([func(x) for x in self.population]) #recalculate fitness of population after rejuvenation\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolutionWithRejuvenation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that utilizes a combination of Cauchy and Gaussian mutations, adaptive step size control based on success history, and periodic population rejuvenation to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionWithRejuvenation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, rejuvenation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.rejuvenation_rate = rejuvenation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n\n    def initialize_population(self, func):\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        self.population = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate(self, pop, func, i):\n        # Cauchy mutation for global exploration (occasionally)\n        if np.random.rand() < 0.1:\n            gamma = 0.1*self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5)) # Cauchy distribution.\n            mutant = pop[i] + mutation\n        else:\n            # Gaussian mutation for local search\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n\n        #clip values\n        mutant = np.clip(mutant, self.bounds_lb, self.bounds_ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def rejuvenate_population(self):\n        \"\"\"Replaces a fraction of the population with new random individuals.\"\"\"\n        num_rejuvenated = int(self.rejuvenation_rate * self.pop_size)\n        indices_to_rejuvenate = np.random.choice(self.pop_size, num_rejuvenated, replace=False)\n        \n        new_individuals = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(num_rejuvenated, self.dim))\n\n        for i, idx in enumerate(indices_to_rejuvenate):\n            self.population[idx] = new_individuals[i]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_step_size()\n            \n            # Rejuvenate population periodically\n            if eval_count % (self.budget // 10) == 0:  # Rejuvenate every 10% of the budget\n                self.rejuvenate_population()\n                self.fitness = np.array([func(x) for x in self.population]) #recalculate fitness of population after rejuvenation\n                best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.03915572386397601, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "9e7a50f2-f65e-4a76-9c89-a0b9882eb6e2", "fitness": 0.0, "name": "AdaptiveDEOrthogonalLearning", "description": "Implements an adaptive differential evolution with orthogonal learning to improve exploration and exploitation, coupled with restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDEOrthogonalLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, orthogonal_dim = 3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.orthogonal_dim = orthogonal_dim\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = []\n        self.restart_trigger = 100 # after 100 iterations without improvement, restart\n        self.no_improvement_counter = 0\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n    def mutate(self, pop,func, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n                self.no_improvement_counter = 0 #reset counter\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def orthogonal_learning(self, func):\n        # Select orthogonal dimensions\n        dims = np.random.choice(self.dim, self.orthogonal_dim, replace=False)\n        \n        # Generate orthogonal array (OA).  Using a simple 2-level OA here.\n        oa = np.array([[-1, -1, -1],\n                       [-1, 1, 1],\n                       [1, -1, 1],\n                       [1, 1, -1]])\n        \n        # Map -1 and 1 to the lower and upper bounds of the selected dimensions\n        levels = np.array([func.bounds.lb, func.bounds.ub])\n        \n        # Iterate through each row of the OA to create new candidate solutions\n        for i in range(oa.shape[0]):\n            candidate = self.x_opt.copy()  # Start with the best solution found so far\n            \n            for j, d in enumerate(dims):\n                candidate[d] = levels[(oa[i, j] + 1) // 2]  # Map -1/1 to lower/upper bounds\n            \n            # Evaluate the candidate solution\n            f_candidate = func(candidate)\n            \n            # Update the best solution if the candidate is better\n            if f_candidate < self.f_opt:\n                self.f_opt = f_candidate\n                self.x_opt = candidate\n                self.no_improvement_counter = 0 #reset counter\n            \n    def restart(self, func):\n        # Re-initialize the population and reset adaptive parameters\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.step_size = 0.1\n        self.success_history = []\n        self.no_improvement_counter = 0\n        print(\"Restarting...\")\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            \n            if self.f_opt == self.best_fitness_history[-1]:\n                self.no_improvement_counter += 1\n            else:\n                self.best_fitness_history.append(self.f_opt)\n                self.no_improvement_counter = 0\n\n            if self.no_improvement_counter >= self.restart_trigger:\n                 self.restart(func)\n            \n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.orthogonal_learning(func)\n            self.adapt_step_size()\n            eval_count += self.orthogonal_dim * 4 #approximate cost of orthogonal learning.\n            if eval_count >= self.budget:\n                    break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: Cannot take a larger sample than population when 'replace=False'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Implements an adaptive differential evolution with orthogonal learning to improve exploration and exploitation, coupled with restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEOrthogonalLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, orthogonal_dim = 3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.orthogonal_dim = orthogonal_dim\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = []\n        self.restart_trigger = 100 # after 100 iterations without improvement, restart\n        self.no_improvement_counter = 0\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n    def mutate(self, pop,func, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)  # Adaptive step size\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n                self.no_improvement_counter = 0 #reset counter\n            return True  # Indicate success\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9  # Reduce step size if no recent successes\n        self.step_size = np.clip(self.step_size, 1e-6, 1)  # Ensure step size remains within reasonable bounds\n\n    def orthogonal_learning(self, func):\n        # Select orthogonal dimensions\n        dims = np.random.choice(self.dim, self.orthogonal_dim, replace=False)\n        \n        # Generate orthogonal array (OA).  Using a simple 2-level OA here.\n        oa = np.array([[-1, -1, -1],\n                       [-1, 1, 1],\n                       [1, -1, 1],\n                       [1, 1, -1]])\n        \n        # Map -1 and 1 to the lower and upper bounds of the selected dimensions\n        levels = np.array([func.bounds.lb, func.bounds.ub])\n        \n        # Iterate through each row of the OA to create new candidate solutions\n        for i in range(oa.shape[0]):\n            candidate = self.x_opt.copy()  # Start with the best solution found so far\n            \n            for j, d in enumerate(dims):\n                candidate[d] = levels[(oa[i, j] + 1) // 2]  # Map -1/1 to lower/upper bounds\n            \n            # Evaluate the candidate solution\n            f_candidate = func(candidate)\n            \n            # Update the best solution if the candidate is better\n            if f_candidate < self.f_opt:\n                self.f_opt = f_candidate\n                self.x_opt = candidate\n                self.no_improvement_counter = 0 #reset counter\n            \n    def restart(self, func):\n        # Re-initialize the population and reset adaptive parameters\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.step_size = 0.1\n        self.success_history = []\n        self.no_improvement_counter = 0\n        print(\"Restarting...\")\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            \n            if self.f_opt == self.best_fitness_history[-1]:\n                self.no_improvement_counter += 1\n            else:\n                self.best_fitness_history.append(self.f_opt)\n                self.no_improvement_counter = 0\n\n            if self.no_improvement_counter >= self.restart_trigger:\n                 self.restart(func)\n            \n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations +=1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.orthogonal_learning(func)\n            self.adapt_step_size()\n            eval_count += self.orthogonal_dim * 4 #approximate cost of orthogonal learning.\n            if eval_count >= self.budget:\n                    break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.019544515753683094, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "fb8808e5-2186-4c8e-9d4e-e0e712ae8143", "fitness": 0.0, "name": "AdaptiveHybridSearch", "description": "A novel algorithm that combines a population-based approach with a local search strategy, adaptively adjusting search parameters based on the landscape characteristics encountered during optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def local_search(self, x, func):\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.budget -= 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a random perturbation\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            x_new = x_current + perturbation\n            x_new = np.clip(x_new, self.lb, self.ub)  # Keep within bounds\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n        \n        return f_current, x_current\n\n    def adapt_search_parameters(self):\n        # Example adaptation: Adjust local search iterations based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        self.local_search_iterations = max(1, int(5 * (1 - np.exp(-fitness_variance)))) #Keep it at least 1.\n        #Other adaptation rules could be added\n        \n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Select parents (e.g., tournament selection)\n            indices = np.random.choice(self.pop_size, size=2, replace=False)\n            if self.fitness[indices[0]] < self.fitness[indices[1]]:\n                parent = self.population[indices[0]]\n            else:\n                parent = self.population[indices[1]]\n\n            # Apply crossover and mutation (simplified example)\n            child = parent + np.random.normal(0, 0.1, size=self.dim)\n            child = np.clip(child, self.lb, self.ub)\n            \n\n            # Local search around the child\n            f_child, child = self.local_search(child, func)\n\n            # Update population (replace worst individual)\n            worst_index = np.argmax(self.fitness)\n            if f_child < self.fitness[worst_index]:\n                self.population[worst_index] = child\n                self.fitness[worst_index] = f_child\n\n                # Update global best\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n            \n            self.adapt_search_parameters() #Adapt the parameters\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A novel algorithm that combines a population-based approach with a local search strategy, adaptively adjusting search parameters based on the landscape characteristics encountered during optimization.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def local_search(self, x, func):\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.budget -= 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a random perturbation\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            x_new = x_current + perturbation\n            x_new = np.clip(x_new, self.lb, self.ub)  # Keep within bounds\n\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                f_current = f_new\n                x_current = x_new\n        \n        return f_current, x_current\n\n    def adapt_search_parameters(self):\n        # Example adaptation: Adjust local search iterations based on fitness variance\n        fitness_variance = np.var(self.fitness)\n        self.local_search_iterations = max(1, int(5 * (1 - np.exp(-fitness_variance)))) #Keep it at least 1.\n        #Other adaptation rules could be added\n        \n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Select parents (e.g., tournament selection)\n            indices = np.random.choice(self.pop_size, size=2, replace=False)\n            if self.fitness[indices[0]] < self.fitness[indices[1]]:\n                parent = self.population[indices[0]]\n            else:\n                parent = self.population[indices[1]]\n\n            # Apply crossover and mutation (simplified example)\n            child = parent + np.random.normal(0, 0.1, size=self.dim)\n            child = np.clip(child, self.lb, self.ub)\n            \n\n            # Local search around the child\n            f_child, child = self.local_search(child, func)\n\n            # Update population (replace worst individual)\n            worst_index = np.argmax(self.fitness)\n            if f_child < self.fitness[worst_index]:\n                self.population[worst_index] = child\n                self.fitness[worst_index] = f_child\n\n                # Update global best\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n            \n            self.adapt_search_parameters() #Adapt the parameters\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.11246419732554298, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "fb5dc304-f581-44a8-917f-d76dff81756b", "fitness": 0.0, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "An Adaptive Differential Evolution with velocity-based momentum, enhanced mutation strategies (including Levy flight and orthogonal learning), and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.restart_trigger = restart_trigger # Probability of population restart\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n        self.velocity = None #Velocity term for momentum\n        self.inertia = 0.7  # Inertia weight for velocity\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.velocity = np.zeros_like(self.population)\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n    \n    def orthogonal_learning(self, pop, i):\n        # Select two random individuals\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        \n        # Generate a random orthogonal matrix\n        Q, _ = np.linalg.qr(np.random.randn(self.dim, self.dim))\n        \n        # Create an orthogonal vector\n        orthogonal_vector = np.dot(Q, (pop[a] - pop[b]))\n        \n        # Apply orthogonal learning\n        mutant = pop[i] + orthogonal_vector * self.step_size\n        return mutant\n\n    def mutate(self, pop, func, i):\n        rand_val = np.random.rand()\n\n        if rand_val < 0.05: #Levy Flight\n            step = self.levy_flight()\n            mutant = pop[i] + self.step_size * step\n        elif rand_val < 0.15: #Orthogonal Learning\n            mutant = self.orthogonal_learning(pop, i)\n        elif rand_val < 0.3:  # Cauchy mutation\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = pop[i] + mutation\n        else: # Gaussian mutation with momentum\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n            \n            #Momentum\n            self.velocity[i] = self.inertia * self.velocity[i] + (mutant - pop[i])\n            mutant = pop[i] + self.velocity[i]\n\n        # Clip\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def restart_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocity = np.zeros_like(self.population) #reset velocity\n        \n        #Update optimal solution if restart improves it\n        current_f_opt = np.min(self.fitness)\n        if current_f_opt < self.f_opt:\n            self.f_opt = current_f_opt\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            \n            #Restart population with a given probability\n            if np.random.rand() < self.restart_trigger:\n                self.restart_population(func)\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An Adaptive Differential Evolution with velocity-based momentum, enhanced mutation strategies (including Levy flight and orthogonal learning), and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.restart_trigger = restart_trigger # Probability of population restart\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = 0.1  # Initial step size for adaptive mutation\n        self.success_history = [] #store successful step sizes\n        self.velocity = None #Velocity term for momentum\n        self.inertia = 0.7  # Inertia weight for velocity\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.velocity = np.zeros_like(self.population)\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n    \n    def orthogonal_learning(self, pop, i):\n        # Select two random individuals\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        \n        # Generate a random orthogonal matrix\n        Q, _ = np.linalg.qr(np.random.randn(self.dim, self.dim))\n        \n        # Create an orthogonal vector\n        orthogonal_vector = np.dot(Q, (pop[a] - pop[b]))\n        \n        # Apply orthogonal learning\n        mutant = pop[i] + orthogonal_vector * self.step_size\n        return mutant\n\n    def mutate(self, pop, func, i):\n        rand_val = np.random.rand()\n\n        if rand_val < 0.05: #Levy Flight\n            step = self.levy_flight()\n            mutant = pop[i] + self.step_size * step\n        elif rand_val < 0.15: #Orthogonal Learning\n            mutant = self.orthogonal_learning(pop, i)\n        elif rand_val < 0.3:  # Cauchy mutation\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = pop[i] + mutation\n        else: # Gaussian mutation with momentum\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n            \n            #Momentum\n            self.velocity[i] = self.inertia * self.velocity[i] + (mutant - pop[i])\n            mutant = pop[i] + self.velocity[i]\n\n        # Clip\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            \n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True\n        return False\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def restart_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocity = np.zeros_like(self.population) #reset velocity\n        \n        #Update optimal solution if restart improves it\n        current_f_opt = np.min(self.fitness)\n        if current_f_opt < self.f_opt:\n            self.f_opt = current_f_opt\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            successful_mutations = 0\n            \n            #Restart population with a given probability\n            if np.random.rand() < self.restart_trigger:\n                self.restart_population(func)\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.population, func, i)\n                trial = self.crossover(self.population, i, mutant)\n\n                is_successful = self.selection(func, trial, i)\n                if is_successful:\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.011056091514694824, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "b7ecc27f-1391-4cc3-8299-a2a9c56d0747", "fitness": 0.0, "name": "SimplexCMAES", "description": "An optimization algorithm that combines aspects of Nelder-Mead simplex with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass SimplexCMAES:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, sigma=0.1, mu_fraction=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = initial_simplex_size\n        self.sigma = sigma  # Step-size for CMA-ES\n        self.mu = int(mu_fraction * (self.dim + 1))  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eval_count = 0\n\n    def initialize_simplex(self, x0, func):\n        simplex = [x0]\n        fvals = [func(x0)]\n        self.eval_count += 1\n\n        for i in range(self.dim):\n            x = x0.copy()\n            x[i] += self.simplex_size\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = func(x)\n            self.eval_count += 1\n            simplex.append(x)\n            fvals.append(f)\n            if self.eval_count >= self.budget:\n                return simplex, fvals\n\n        return simplex, fvals\n\n    def nelder_mead_step(self, simplex, fvals, func):\n        # Order the simplex vertices by function value\n        indices = np.argsort(fvals)\n        simplex = [simplex[i] for i in indices]\n        fvals = [fvals[i] for i in indices]\n\n        # Centroid of the best vertices\n        x0 = np.mean(simplex[:-1], axis=0)\n\n        # Reflection\n        xr = x0 + 1.0 * (x0 - simplex[-1])\n        xr = np.clip(xr, func.bounds.lb, func.bounds.ub)\n        fr = func(xr)\n        self.eval_count += 1\n\n        if fr < fvals[0]:\n            # Expansion\n            xe = x0 + 2.0 * (x0 - simplex[-1])\n            xe = np.clip(xe, func.bounds.lb, func.bounds.ub)\n            fe = func(xe)\n            self.eval_count += 1\n\n            if fe < fr:\n                simplex[-1] = xe\n                fvals[-1] = fe\n            else:\n                simplex[-1] = xr\n                fvals[-1] = fr\n        elif fr < fvals[-2]:\n            simplex[-1] = xr\n            fvals[-1] = fr\n        else:\n            # Contraction\n            xc = x0 + 0.5 * (simplex[-1] - x0)\n            xc = np.clip(xc, func.bounds.lb, func.bounds.ub)\n            fc = func(xc)\n            self.eval_count += 1\n\n            if fc < fvals[-1]:\n                simplex[-1] = xc\n                fvals[-1] = fc\n            else:\n                # Shrink\n                for i in range(1, len(simplex)):\n                    simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                    simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                    fvals[i] = func(simplex[i])\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n        return simplex, fvals\n    \n    def cmaes_step(self, func):\n        \n        z = np.random.normal(0, 1, size=(self.dim, self.mu))\n        y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        x = self.x_mean[:, None] + y\n        \n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        \n        fvals = np.array([func(xi) for xi in x.T])\n        self.eval_count += self.mu\n        \n        arindex = np.argsort(fvals)\n        x_k = x[:, arindex]\n        fvals_k = fvals[arindex]\n        \n        x_mean_old = self.x_mean.copy()\n        self.x_mean = np.dot(x_k[:,:self.mu], self.weights)\n        \n        y_mean = self.x_mean - x_mean_old\n        \n        self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), y_mean) / self.sigma\n        hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.eval_count/self.mu))/1.4 + 2)/(self.dim + 1) < 0.5 + 1e-10\n        self.pc = (1-self.cc)*self.pc + hsig * np.sqrt(self.cc*(2-self.cc)*self.mueff) * y_mean / self.sigma\n        \n        artmp = (1/self.sigma) * (x_k[:,:self.mu] - x_mean_old[:,None])\n        self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig)*self.c1*self.C) + self.cmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n        \n        self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n        \n        self.f_opt = fvals_k[0]\n        self.x_opt = x_k[:,0]\n\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.x_mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize simplex\n        simplex, fvals = self.initialize_simplex(self.x_mean, func)\n        if self.eval_count >= self.budget:\n            best_index = np.argmin(fvals)\n            return fvals[best_index], simplex[best_index]\n        \n        # Alternate between Nelder-Mead and CMA-ES\n        while self.eval_count < self.budget:\n            simplex, fvals = self.nelder_mead_step(simplex, fvals, func)\n            if self.eval_count >= self.budget:\n                best_index = np.argmin(fvals)\n                return fvals[best_index], simplex[best_index]\n\n            f_cmaes, x_cmaes = self.cmaes_step(func)\n            \n            if f_cmaes < min(fvals):\n                best_index = np.argmin(fvals)\n                self.x_opt = simplex[best_index]\n                self.f_opt = fvals[best_index]\n            \n            else:\n                best_index = np.argmin(fvals)\n                self.x_opt = simplex[best_index]\n                self.f_opt = fvals[best_index]\n\n        best_index = np.argmin(fvals)\n        self.x_opt = simplex[best_index]\n        self.f_opt = fvals[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,0) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An optimization algorithm that combines aspects of Nelder-Mead simplex with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for efficient exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass SimplexCMAES:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, sigma=0.1, mu_fraction=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = initial_simplex_size\n        self.sigma = sigma  # Step-size for CMA-ES\n        self.mu = int(mu_fraction * (self.dim + 1))  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eval_count = 0\n\n    def initialize_simplex(self, x0, func):\n        simplex = [x0]\n        fvals = [func(x0)]\n        self.eval_count += 1\n\n        for i in range(self.dim):\n            x = x0.copy()\n            x[i] += self.simplex_size\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = func(x)\n            self.eval_count += 1\n            simplex.append(x)\n            fvals.append(f)\n            if self.eval_count >= self.budget:\n                return simplex, fvals\n\n        return simplex, fvals\n\n    def nelder_mead_step(self, simplex, fvals, func):\n        # Order the simplex vertices by function value\n        indices = np.argsort(fvals)\n        simplex = [simplex[i] for i in indices]\n        fvals = [fvals[i] for i in indices]\n\n        # Centroid of the best vertices\n        x0 = np.mean(simplex[:-1], axis=0)\n\n        # Reflection\n        xr = x0 + 1.0 * (x0 - simplex[-1])\n        xr = np.clip(xr, func.bounds.lb, func.bounds.ub)\n        fr = func(xr)\n        self.eval_count += 1\n\n        if fr < fvals[0]:\n            # Expansion\n            xe = x0 + 2.0 * (x0 - simplex[-1])\n            xe = np.clip(xe, func.bounds.lb, func.bounds.ub)\n            fe = func(xe)\n            self.eval_count += 1\n\n            if fe < fr:\n                simplex[-1] = xe\n                fvals[-1] = fe\n            else:\n                simplex[-1] = xr\n                fvals[-1] = fr\n        elif fr < fvals[-2]:\n            simplex[-1] = xr\n            fvals[-1] = fr\n        else:\n            # Contraction\n            xc = x0 + 0.5 * (simplex[-1] - x0)\n            xc = np.clip(xc, func.bounds.lb, func.bounds.ub)\n            fc = func(xc)\n            self.eval_count += 1\n\n            if fc < fvals[-1]:\n                simplex[-1] = xc\n                fvals[-1] = fc\n            else:\n                # Shrink\n                for i in range(1, len(simplex)):\n                    simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                    simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                    fvals[i] = func(simplex[i])\n                    self.eval_count += 1\n                    if self.eval_count >= self.budget:\n                        break\n\n        return simplex, fvals\n    \n    def cmaes_step(self, func):\n        \n        z = np.random.normal(0, 1, size=(self.dim, self.mu))\n        y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        x = self.x_mean[:, None] + y\n        \n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n        \n        fvals = np.array([func(xi) for xi in x.T])\n        self.eval_count += self.mu\n        \n        arindex = np.argsort(fvals)\n        x_k = x[:, arindex]\n        fvals_k = fvals[arindex]\n        \n        x_mean_old = self.x_mean.copy()\n        self.x_mean = np.dot(x_k[:,:self.mu], self.weights)\n        \n        y_mean = self.x_mean - x_mean_old\n        \n        self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), y_mean) / self.sigma\n        hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.eval_count/self.mu))/1.4 + 2)/(self.dim + 1) < 0.5 + 1e-10\n        self.pc = (1-self.cc)*self.pc + hsig * np.sqrt(self.cc*(2-self.cc)*self.mueff) * y_mean / self.sigma\n        \n        artmp = (1/self.sigma) * (x_k[:,:self.mu] - x_mean_old[:,None])\n        self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig)*self.c1*self.C) + self.cmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n        \n        self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n        \n        self.f_opt = fvals_k[0]\n        self.x_opt = x_k[:,0]\n\n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.x_mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize simplex\n        simplex, fvals = self.initialize_simplex(self.x_mean, func)\n        if self.eval_count >= self.budget:\n            best_index = np.argmin(fvals)\n            return fvals[best_index], simplex[best_index]\n        \n        # Alternate between Nelder-Mead and CMA-ES\n        while self.eval_count < self.budget:\n            simplex, fvals = self.nelder_mead_step(simplex, fvals, func)\n            if self.eval_count >= self.budget:\n                best_index = np.argmin(fvals)\n                return fvals[best_index], simplex[best_index]\n\n            f_cmaes, x_cmaes = self.cmaes_step(func)\n            \n            if f_cmaes < min(fvals):\n                best_index = np.argmin(fvals)\n                self.x_opt = simplex[best_index]\n                self.f_opt = fvals[best_index]\n            \n            else:\n                best_index = np.argmin(fvals)\n                self.x_opt = simplex[best_index]\n                self.f_opt = fvals[best_index]\n\n        best_index = np.argmin(fvals)\n        self.x_opt = simplex[best_index]\n        self.f_opt = fvals[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.1908533421380996, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "ee58e7dc-81e4-470c-9b9b-2145172b441f", "fitness": 0.0, "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid DEPSO algorithm incorporating a restart mechanism, orthogonal learning, and dynamic parameter adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.step_size = 0.1\n        self.success_history = []\n        self.restart_trigger = restart_trigger  # Number of iterations without improvement to trigger restart\n        self.no_improvement_count = 0\n        self.iteration = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n    def mutate(self, func, i):\n        if np.random.rand() < 0.1:  #Cauchy mutation for exploration\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = self.population[i] + mutation\n        else:\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, i, mutant):\n        trial = self.population[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def update_velocity(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n        self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        max_velocity = self.velocity_clamp_factor * (ub - lb)\n        self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n        self.population[i] = self.population[i] + self.velocities[i]\n        self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx1], self.population[idx2]\n\n        # Create an orthogonal array (example using two levels)\n        orthogonal_array = np.array([[1, 1], [1, 2], [2, 1], [2, 2]])\n        new_positions = []\n\n        for row in orthogonal_array:\n            new_pos = np.copy(self.population[np.random.randint(self.pop_size)]) # Start with a random position\n            for j in range(self.dim):\n                if row[0] == 1:\n                    new_pos[j] = x1[j]\n                else:\n                    new_pos[j] = x2[j]\n\n                if row[1] == 1:\n                    new_pos[j] = (new_pos[j] + self.global_best_position[j])/2 #Move towards global best\n                else:\n                    new_pos[j] = (new_pos[j] + self.personal_best_positions[np.random.randint(self.pop_size)][j])/2  #Move towards random best\n\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            new_positions.append(new_pos)\n\n        # Evaluate new positions and update\n        for new_pos in new_positions:\n            f_new = func(new_pos)\n            if f_new < self.global_best_fitness:\n                self.global_best_fitness = f_new\n                self.global_best_position = new_pos.copy()\n\n    def dynamic_parameter_adaptation(self):\n        # Adjust F and cr based on the success history\n        if len(self.success_history) > 5:\n            self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0.1, 1.0)\n            self.cr = np.clip(self.cr + 0.1 * np.random.normal(0, 1), 0.1, 1.0)\n\n        #Adapt inertia weight\n        self.inertia = 0.9 - (self.iteration / self.budget) * 0.7\n\n    def restart_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.iteration += 1\n            successful_mutations = 0\n            old_global_best = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(func, i)\n                trial = self.crossover(i, mutant)\n                f_trial = func(trial)\n                eval_count += 1\n\n                self.update_velocity(i, func)\n                f_pso = func(self.population[i])\n                eval_count += 1\n\n                if f_trial < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()\n                    self.population[i] = trial.copy()\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n\n                elif f_pso < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_pso\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_pso\n                        self.global_best_position = self.population[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            self.orthogonal_learning(func)\n            self.dynamic_parameter_adaptation()\n\n            if self.global_best_fitness == old_global_best:\n                self.no_improvement_count += 1\n            else:\n                self.no_improvement_count = 0\n\n            if self.no_improvement_count > self.restart_trigger:\n                self.restart_population(func)\n                self.no_improvement_count = 0\n                eval_count += self.pop_size  # Account for re-evaluation after restart\n                \n            if eval_count >= self.budget:\n              break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedHybridDEPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An enhanced hybrid DEPSO algorithm incorporating a restart mechanism, orthogonal learning, and dynamic parameter adaptation for improved exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, velocity_clamp_factor=0.2, restart_trigger=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.constriction_factor = 0.729\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.step_size = 0.1\n        self.success_history = []\n        self.restart_trigger = restart_trigger  # Number of iterations without improvement to trigger restart\n        self.no_improvement_count = 0\n        self.iteration = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n    def mutate(self, func, i):\n        if np.random.rand() < 0.1:  #Cauchy mutation for exploration\n            gamma = 0.1 * self.step_size\n            mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n            mutant = self.population[i] + mutation\n        else:\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n    def crossover(self, i, mutant):\n        trial = self.population[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        return trial\n\n    def update_velocity(self, i, func):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n        social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n        self.velocities[i] = self.constriction_factor * (self.inertia * self.velocities[i] + cognitive_component + social_component)\n\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        max_velocity = self.velocity_clamp_factor * (ub - lb)\n        self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n        self.population[i] = self.population[i] + self.velocities[i]\n        self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n    def adapt_step_size(self):\n        if len(self.success_history) > 0:\n            self.step_size = np.mean(self.success_history)\n            self.success_history = []\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx1], self.population[idx2]\n\n        # Create an orthogonal array (example using two levels)\n        orthogonal_array = np.array([[1, 1], [1, 2], [2, 1], [2, 2]])\n        new_positions = []\n\n        for row in orthogonal_array:\n            new_pos = np.copy(self.population[np.random.randint(self.pop_size)]) # Start with a random position\n            for j in range(self.dim):\n                if row[0] == 1:\n                    new_pos[j] = x1[j]\n                else:\n                    new_pos[j] = x2[j]\n\n                if row[1] == 1:\n                    new_pos[j] = (new_pos[j] + self.global_best_position[j])/2 #Move towards global best\n                else:\n                    new_pos[j] = (new_pos[j] + self.personal_best_positions[np.random.randint(self.pop_size)][j])/2  #Move towards random best\n\n            new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub)\n            new_positions.append(new_pos)\n\n        # Evaluate new positions and update\n        for new_pos in new_positions:\n            f_new = func(new_pos)\n            if f_new < self.global_best_fitness:\n                self.global_best_fitness = f_new\n                self.global_best_position = new_pos.copy()\n\n    def dynamic_parameter_adaptation(self):\n        # Adjust F and cr based on the success history\n        if len(self.success_history) > 5:\n            self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0.1, 1.0)\n            self.cr = np.clip(self.cr + 0.1 * np.random.normal(0, 1), 0.1, 1.0)\n\n        #Adapt inertia weight\n        self.inertia = 0.9 - (self.iteration / self.budget) * 0.7\n\n    def restart_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-self.velocity_clamp_factor * (ub - lb), self.velocity_clamp_factor * (ub - lb), size=(self.pop_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitnesses = np.full(self.pop_size, np.inf)\n        for i in range(self.pop_size):\n            fitness = func(self.population[i])\n            self.personal_best_fitnesses[i] = fitness\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best_position = self.population[i].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.iteration += 1\n            successful_mutations = 0\n            old_global_best = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                mutant = self.mutate(func, i)\n                trial = self.crossover(i, mutant)\n                f_trial = func(trial)\n                eval_count += 1\n\n                self.update_velocity(i, func)\n                f_pso = func(self.population[i])\n                eval_count += 1\n\n                if f_trial < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_trial\n                    self.personal_best_positions[i] = trial.copy()\n                    self.population[i] = trial.copy()\n                    successful_mutations += 1\n                    self.success_history.append(np.linalg.norm(self.population[i] - trial))\n\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n\n                elif f_pso < self.personal_best_fitnesses[i]:\n                    self.personal_best_fitnesses[i] = f_pso\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_pso < self.global_best_fitness:\n                        self.global_best_fitness = f_pso\n                        self.global_best_position = self.population[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            self.orthogonal_learning(func)\n            self.dynamic_parameter_adaptation()\n\n            if self.global_best_fitness == old_global_best:\n                self.no_improvement_count += 1\n            else:\n                self.no_improvement_count = 0\n\n            if self.no_improvement_count > self.restart_trigger:\n                self.restart_population(func)\n                self.no_improvement_count = 0\n                eval_count += self.pop_size  # Account for re-evaluation after restart\n                \n            if eval_count >= self.budget:\n              break\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.006876643227917901, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "260df348-1ae8-4e71-97ee-6b49606be858", "fitness": 0.0, "name": "HybridAdaptiveDE", "description": "A hybrid differential evolution algorithm that combines ensemble mutation strategies with adaptive step size control and parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_mutation_prob = 0.1  # Probability of applying Cauchy mutation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def cauchy_mutation(self, pop, i, func):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_mutation_prob:\n                    mutant = self.cauchy_mutation(self.population, i, func)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: cannot access local variable 'mutation_idx' where it is not associated with a value", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid differential evolution algorithm that combines ensemble mutation strategies with adaptive step size control and parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_mutation_prob = 0.1  # Probability of applying Cauchy mutation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def cauchy_mutation(self, pop, i, func):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_mutation_prob:\n                    mutant = self.cauchy_mutation(self.population, i, func)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.15637446558280918, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "33ba2b0b-dd9e-4661-a897-9da7db2c03c8", "fitness": 0.7252334511371401, "name": "HybridAdaptiveDE", "description": "A hybrid Differential Evolution algorithm that combines adaptive mutation with ensemble-based parameter adaptation and Cauchy jumps for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n    \n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))  # Cauchy distribution.\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n\n                # Add Cauchy mutation with a small probability\n                if np.random.rand() < 0.05:\n                   mutant = self.mutate_cauchy(self.population, i)\n                   mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                   trial = self.crossover(self.population, i, mutant, func)\n                   is_successful, step_size, cr_val = self.selection(func, trial, i)\n\n                   if is_successful:\n                       # No need to append to success_history as it's a rare event\n                       self.cr_history.append(cr_val)\n\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    trial = self.crossover(self.population, i, mutant, func)\n\n                    is_successful, step_size, cr_val = self.selection(func, trial, i)\n                    if is_successful:\n                        self.success_history[mutation_idx].append(step_size)\n                        self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid Differential Evolution algorithm that combines adaptive mutation with ensemble-based parameter adaptation and Cauchy jumps for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n    \n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))  # Cauchy distribution.\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n\n                # Add Cauchy mutation with a small probability\n                if np.random.rand() < 0.05:\n                   mutant = self.mutate_cauchy(self.population, i)\n                   mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                   trial = self.crossover(self.population, i, mutant, func)\n                   is_successful, step_size, cr_val = self.selection(func, trial, i)\n\n                   if is_successful:\n                       # No need to append to success_history as it's a rare event\n                       self.cr_history.append(cr_val)\n\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                    trial = self.crossover(self.population, i, mutant, func)\n\n                    is_successful, step_size, cr_val = self.selection(func, trial, i)\n                    if is_successful:\n                        self.success_history[mutation_idx].append(step_size)\n                        self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.34426648654071057, 0.710648435315596, 0.7262784748862868, 0.8952043821282004, 0.7794352291125325, 0.8129325521831586, 0.661806989231788, 0.688454643866034, 0.779537775746593, 0.6706450465015541, 0.8754106817038084, 0.9976235262712606, 0.669456520269549, 0.7448355480492368, 0.9418857883531606, 0.8167711875833531, 0.6944129802524242, 0.8728462736330947, 0.30601085095404934, 0.5162056501604146], "operator": "crossover", "theta_sampled": 0.3260840386007802, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "7608dd90-9dba-428e-bd09-e201c1b91b6f", "fitness": 0.7267064645417451, "name": "HybridAdaptiveDE", "description": "Combines ensemble mutation strategies with adaptive step size and crossover rate inspired by successful parameter adaptations.", "code": "import numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDE scored 0.727 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines ensemble mutation strategies with adaptive step size and crossover rate inspired by successful parameter adaptations.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.41140838857993456, 0.6875399134132165, 0.7321558637277144, 0.8904765136700092, 0.7697695885591636, 0.8153063200070156, 0.6720707014223268, 0.6806250519174457, 0.788084980695622, 0.6960535406709949, 0.8910222113402915, 0.9947512661763517, 0.6785868483435278, 0.7436208513539162, 0.93372370726189, 0.8105002161129351, 0.6957745445484587, 0.8790480935611902, 0.2523811794430253, 0.5112295100298747], "operator": "crossover", "theta_sampled": 0.24870226617685925, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "e35b4b22-9cf1-4c1e-8ec6-9f5198f5e9ba", "fitness": 0.1825970286255477, "name": "AdaptivePopulationSearch", "description": "Population-based algorithm using a combination of differential evolution and Gaussian mutation with adaptive parameter control and a restart mechanism for better exploration.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, de_rate=0.7, gauss_rate=0.2, restart_freq=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.gauss_rate = gauss_rate\n        self.restart_freq = restart_freq\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation strategy: Combination of DE and Gaussian\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    mutant = population[i] + self.F * (x_r2 - x_r3)\n\n                elif np.random.rand() < self.gauss_rate:\n                    # Gaussian Mutation\n                     mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) # Gaussian mutation with small std\n                else:\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub) # Random mutation\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive parameter control (example: adaptive F)\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adjust F dynamically\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_freq:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePopulationSearch scored 0.183 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of differential evolution and Gaussian mutation with adaptive parameter control and a restart mechanism for better exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, de_rate=0.7, gauss_rate=0.2, restart_freq=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_rate = de_rate\n        self.gauss_rate = gauss_rate\n        self.restart_freq = restart_freq\n        self.F = 0.5  # Differential evolution scaling factor\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation strategy: Combination of DE and Gaussian\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    mutant = population[i] + self.F * (x_r2 - x_r3)\n\n                elif np.random.rand() < self.gauss_rate:\n                    # Gaussian Mutation\n                     mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) # Gaussian mutation with small std\n                else:\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub) # Random mutation\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive parameter control (example: adaptive F)\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adjust F dynamically\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_freq:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11642273560184535, 0.18998480360107683, 0.2847251197770234, 0.22632332654741516, 0.2188964436748675, 0.24182677117660556, 0], "operator": "random_new", "theta_sampled": 0.07429226428782902, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "fbb5aa80-a819-4182-8dc2-efdceae5b31d", "fitness": 0.5602204048517244, "name": "AdaptiveClampingPSO", "description": "A particle swarm optimization algorithm with adaptive inertia weight and velocity clamping to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveClampingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max_ratio = v_max_ratio # velocity clamping factor\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(self.positions[i]) for i in range(self.swarm_size)])\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n        self.eval_count = self.swarm_size  # Account for initial evaluation\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.positions[best_index].copy()\n\n    def update_personal_best(self):\n        for i in range(self.swarm_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.positions[i].copy()\n\n    def update_velocities(self, w, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        v_max = abs(ub-lb)*self.v_max_ratio\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n\n            # Velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n    def update_positions(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = self.positions + self.velocities\n        \n        # Boundary handling: clip to boundaries\n        self.positions = np.clip(self.positions, lb, ub)\n\n        for i in range(self.swarm_size):\n             self.fitness[i] = func(self.positions[i])\n             self.eval_count += 1\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n            self.update_velocities(w, func)\n            self.update_positions(func)\n            self.update_personal_best()\n            self.update_global_best()\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveClampingPSO scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A particle swarm optimization algorithm with adaptive inertia weight and velocity clamping to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveClampingPSO:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.v_max_ratio = v_max_ratio # velocity clamping factor\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = np.random.uniform(lb, ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.swarm_size, self.dim))\n        self.fitness = np.array([func(self.positions[i]) for i in range(self.swarm_size)])\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitness)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitness)\n        self.eval_count = self.swarm_size  # Account for initial evaluation\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.positions[best_index].copy()\n\n    def update_personal_best(self):\n        for i in range(self.swarm_size):\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.positions[i].copy()\n\n    def update_velocities(self, w, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        v_max = abs(ub-lb)*self.v_max_ratio\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n\n            # Velocity clamping\n            self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n    def update_positions(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.positions = self.positions + self.velocities\n        \n        # Boundary handling: clip to boundaries\n        self.positions = np.clip(self.positions, lb, ub)\n\n        for i in range(self.swarm_size):\n             self.fitness[i] = func(self.positions[i])\n             self.eval_count += 1\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n\n            self.update_velocities(w, func)\n            self.update_positions(func)\n            self.update_personal_best()\n            self.update_global_best()\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.22673629264376582, 0.3217946433308554, 0.6603119949044576, 0.8086755663080321, 0.2941884799329386, 0.7160936316737453, 0.3161527847815915, 0.5587619285958808, 0.6889354407669099, 0.5863020080139709, 0.8427502938433088, 0.9963675332713252, 0.25031751996243845, 0.2948862921393527, 0.734192665145807, 0.7092531343059254, 0.39233448549463945, 0.7806176936904918, 0.5225542217326242, 0.5031814864964274], "operator": "random_new", "theta_sampled": 0.08491580215826929, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "0017f7fa-b81c-40f9-8240-b3b70957850a", "fitness": 0.0, "name": "EnhancedAdaptiveDE", "description": "An adaptive differential evolution with ensemble mutation strategies, Cauchy mutation, and step size adaptation, balancing exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.levy_prob = 0.05 #Probability of applying levy flight mutation\n        self.F_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n    \n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (abs(v) ** (1 / beta))\n        return step\n\n    def mutate_levy(self, pop, i):\n        step_size = 0.01 * self.step_size\n        levy_steps = self.levy_flight()\n        mutant = pop[i] + step_size * levy_steps\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt crossover rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt mutation factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n        #Adapt step size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                elif np.random.rand() < self.levy_prob:\n                    mutant = self.mutate_levy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > self.levy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive differential evolution with ensemble mutation strategies, Cauchy mutation, and step size adaptation, balancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.levy_prob = 0.05 #Probability of applying levy flight mutation\n        self.F_history = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n    \n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (abs(v) ** (1 / beta))\n        return step\n\n    def mutate_levy(self, pop, i):\n        step_size = 0.01 * self.step_size\n        levy_steps = self.levy_flight()\n        mutant = pop[i] + step_size * levy_steps\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt crossover rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt mutation factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n        #Adapt step size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                elif np.random.rand() < self.levy_prob:\n                    mutant = self.mutate_levy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > self.levy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.1941443576110352, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "971b5c46-5964-41d8-94c3-7af170106c2a", "fitness": 0.714413037041608, "name": "AdaptiveHybridDE", "description": "Combines ensemble-based adaptive DE with Cauchy mutation and a success-rate-based step size adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = [] # Archive for storing potentially useful solutions\n        self.archive_size = pop_size # Size of the archive\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    # Use archive information to guide mutation\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridDE scored 0.714 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines ensemble-based adaptive DE with Cauchy mutation and a success-rate-based step size adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = [] # Archive for storing potentially useful solutions\n        self.archive_size = pop_size # Size of the archive\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    # Use archive information to guide mutation\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3197220946046361, 0.7451879808129849, 0.7321013460157617, 0.9045567577698169, 0.7594113944404924, 0.805957042480022, 0.5982237053734123, 0.6752292550123096, 0.7625362668238289, 0.6456905250875365, 0.8685248286486213, 0.9946122411263504, 0.6579967715344941, 0.7530851467502537, 0.9326847210268294, 0.8023167028372629, 0.6618944648837215, 0.8557498331832258, 0.2863006560325285, 0.5264790063880695], "operator": "crossover", "theta_sampled": 0.1093513648139155, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "e67d206f-d7f9-4c90-8814-b094bc8ff873", "fitness": 0.4062698164489163, "name": "CauchyAdaptiveSearch", "description": "Population-based algorithm with Cauchy mutation and adaptive step size control, focusing on exploration and exploitation balance.", "code": "import numpy as np\n\nclass CauchyAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        step_size = self.initial_step_size\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                z = np.random.standard_cauchy(size=self.dim)\n                mutation = population[i] + step_size * z\n\n                # Clip to bounds\n                mutation = np.clip(mutation, self.lb, self.ub)\n\n                # Evaluate mutated solution\n                f_mutation = func(mutation)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection: Greedy selection\n                if f_mutation < fitness[i]:\n                    fitness[i] = f_mutation\n                    new_population[i] = mutation\n\n                    if f_mutation < self.f_opt:\n                        self.f_opt = f_mutation\n                        self.x_opt = mutation\n\n            # Adaptive step size control\n            if generation % 10 == 0:\n                delta = np.mean(np.linalg.norm(new_population - population, axis=1))\n                if delta < 0.01:\n                    step_size *= 1.2  # Increase exploration\n                else:\n                    step_size *= 0.8  # Increase exploitation\n\n            population = new_population\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyAdaptiveSearch scored 0.406 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with Cauchy mutation and adaptive step size control, focusing on exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        step_size = self.initial_step_size\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                z = np.random.standard_cauchy(size=self.dim)\n                mutation = population[i] + step_size * z\n\n                # Clip to bounds\n                mutation = np.clip(mutation, self.lb, self.ub)\n\n                # Evaluate mutated solution\n                f_mutation = func(mutation)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection: Greedy selection\n                if f_mutation < fitness[i]:\n                    fitness[i] = f_mutation\n                    new_population[i] = mutation\n\n                    if f_mutation < self.f_opt:\n                        self.f_opt = f_mutation\n                        self.x_opt = mutation\n\n            # Adaptive step size control\n            if generation % 10 == 0:\n                delta = np.mean(np.linalg.norm(new_population - population, axis=1))\n                if delta < 0.01:\n                    step_size *= 1.2  # Increase exploration\n                else:\n                    step_size *= 0.8  # Increase exploitation\n\n            population = new_population\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.16071796601108113, 0.20687530724422054, 0.4061119510759129, 0.7046502378446574, 0.2684929801196285, 0.4205107642177316, 0.2934255216476951, 0.3564209190265547, 0.3691793605663153, 0.17365394557853564, 0.4951036169964904, 0.9987393213262856, 0.26941499297865157, 0.3072508875903327, 0.7931930086828509, 0.3713410819888967, 0.3251317367399774, 0.5151283102070383, 0.19505201032923714, 0.4950024088062327], "operator": "random_new", "theta_sampled": 0.2906827486850609, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "3505cf5f-9870-4693-8dbb-40c590d18c9e", "fitness": 0.36996915074768705, "name": "ShrinkingHypersphere", "description": "A population-based algorithm employing a shrinking hypersphere search space and dynamically adjusting step size based on fitness improvement to encourage exploration and exploitation.", "code": "import numpy as np\n\nclass ShrinkingHypersphere:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within hypersphere\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        \n        # Initialize center with a random point\n        center = np.random.uniform(lb, ub)\n        radius = self.initial_radius\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = 0.1  # Initial step size for movement\n\n        while self.budget > 0:\n            # Generate candidate solutions within shrinking hypersphere\n            new_population = []\n            for i in range(self.pop_size):\n                # Move towards the center with a probability\n                if np.random.rand() < 0.5:\n                    direction = center - population[i]\n                    direction /= np.linalg.norm(direction) + 1e-8\n                    new_solution = population[i] + step_size * direction\n                else:\n                     # Or move randomly within the hypersphere\n                    random_direction = np.random.randn(self.dim)\n                    random_direction /= np.linalg.norm(random_direction) + 1e-8\n                    new_solution = population[i] + radius * random_direction\n\n                new_solution = np.clip(new_solution, lb, ub)\n                new_population.append(new_solution)\n\n            new_population = np.array(new_population)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update population and center\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                # Adjust step size if improvement\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Update center (move towards the best solution)\n            center = population[best_index] \n\n            # Shrink the radius\n            radius *= 0.99\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ShrinkingHypersphere scored 0.370 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm employing a shrinking hypersphere search space and dynamically adjusting step size based on fitness improvement to encourage exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass ShrinkingHypersphere:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population within hypersphere\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        \n        # Initialize center with a random point\n        center = np.random.uniform(lb, ub)\n        radius = self.initial_radius\n        \n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = 0.1  # Initial step size for movement\n\n        while self.budget > 0:\n            # Generate candidate solutions within shrinking hypersphere\n            new_population = []\n            for i in range(self.pop_size):\n                # Move towards the center with a probability\n                if np.random.rand() < 0.5:\n                    direction = center - population[i]\n                    direction /= np.linalg.norm(direction) + 1e-8\n                    new_solution = population[i] + step_size * direction\n                else:\n                     # Or move randomly within the hypersphere\n                    random_direction = np.random.randn(self.dim)\n                    random_direction /= np.linalg.norm(random_direction) + 1e-8\n                    new_solution = population[i] + radius * random_direction\n\n                new_solution = np.clip(new_solution, lb, ub)\n                new_population.append(new_solution)\n\n            new_population = np.array(new_population)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update population and center\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                # Adjust step size if improvement\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Update center (move towards the best solution)\n            center = population[best_index] \n\n            # Shrink the radius\n            radius *= 0.99\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12652991479822262, 0.1925279010574975, 0.4154584963971373, 0.2668004446696238, 0.18464069369784208, 0.383960023944918, 0.2294454078972773, 0.3646140194617349, 0.3470481714225667, 0.1729456129509085, 0.6399287265163099, 0.9992661754149066, 0.3089968658299701, 0.22703696246668192, 0.822140973145459, 0.3205667275364743, 0.2417448725828789, 0.49964152404364426, 0.20212039012522887, 0.4539691109944579], "operator": "random_new", "theta_sampled": 0.20943971940229866, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "b8184d2b-bf20-405a-848d-277b9b76a0f9", "fitness": 0.0, "name": "EnhancedHybridAdaptiveDE", "description": "An enhanced Hybrid Adaptive DE with a self-adaptive mutation factor, population diversity maintenance, and Cauchy mutation enhancement.", "code": "import numpy as np\n\nclass EnhancedHybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_base=0.5, cr=0.9, num_ensemble=3, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base  # Base Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n        self.diversity_threshold = diversity_threshold # Threshold for triggering diversity maintenance\n        self.F = self.F_base # Adaptive Mutation Factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def check_diversity(self):\n        # Calculate average distance between individuals\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        \n        if distances:\n            avg_distance = np.mean(distances)\n            # If diversity is low, re-initialize a portion of the population\n            if avg_distance < self.diversity_threshold:\n                num_to_reinitialize = int(self.pop_size * 0.2)  # Re-initialize 20% of the population\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n                return indices_to_reinitialize\n        return []\n    \n    def reinitialize_population(self, func, indices):\n        for i in indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def adapt_mutation_factor(self):\n        #Adapt the mutation factor based on the success rate\n        success_rate = np.mean([len(history) for history in self.success_history]) / self.pop_size\n        if success_rate > 0.2: # High success rate, decrease exploration\n            self.F = max(0.1, self.F * 0.95)\n        else: #Low success rate, increase exploration\n            self.F = min(0.9, self.F * 1.05)\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            #Adapt Mutation Factor\n            self.adapt_mutation_factor()\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n\n            #Diversity Check and Re-initialization\n            indices_to_reinitialize = self.check_diversity()\n            if indices_to_reinitialize:\n                self.reinitialize_population(func, indices_to_reinitialize)\n                eval_count += len(indices_to_reinitialize)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An enhanced Hybrid Adaptive DE with a self-adaptive mutation factor, population diversity maintenance, and Cauchy mutation enhancement.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_base=0.5, cr=0.9, num_ensemble=3, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_base = F_base  # Base Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n        self.diversity_threshold = diversity_threshold # Threshold for triggering diversity maintenance\n        self.F = self.F_base # Adaptive Mutation Factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def check_diversity(self):\n        # Calculate average distance between individuals\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.population[i] - self.population[j]))\n        \n        if distances:\n            avg_distance = np.mean(distances)\n            # If diversity is low, re-initialize a portion of the population\n            if avg_distance < self.diversity_threshold:\n                num_to_reinitialize = int(self.pop_size * 0.2)  # Re-initialize 20% of the population\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n                return indices_to_reinitialize\n        return []\n    \n    def reinitialize_population(self, func, indices):\n        for i in indices:\n            self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            self.fitness[i] = func(self.population[i])\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def adapt_mutation_factor(self):\n        #Adapt the mutation factor based on the success rate\n        success_rate = np.mean([len(history) for history in self.success_history]) / self.pop_size\n        if success_rate > 0.2: # High success rate, decrease exploration\n            self.F = max(0.1, self.F * 0.95)\n        else: #Low success rate, increase exploration\n            self.F = min(0.9, self.F * 1.05)\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            #Adapt Mutation Factor\n            self.adapt_mutation_factor()\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n\n            #Diversity Check and Re-initialization\n            indices_to_reinitialize = self.check_diversity()\n            if indices_to_reinitialize:\n                self.reinitialize_population(func, indices_to_reinitialize)\n                eval_count += len(indices_to_reinitialize)\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.007820386058416628, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "3251b155-8495-4291-9f7c-3dc3d9a5800a", "fitness": 0.7094031090431565, "name": "HybridAdaptiveDEv2", "description": "A hybrid Differential Evolution algorithm that combines multiple mutation strategies, ensemble adaptation, Cauchy mutation, and dynamic parameter control for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDEv2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = []\n        self.archive_size = archive_size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.archive = list(self.population) # Copy initial population to archive\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        # Mutation using the archive\n        if len(self.archive) < 2:\n            return self.mutate_rand1(pop, i)\n\n        idx_archive = np.random.randint(0, len(self.archive))\n        archived_vector = self.archive[idx_archive]\n\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (archived_vector - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            self.update_archive(trial)\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def update_archive(self, vector):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(vector)\n        else:\n            # Replace a random element in the archive\n            idx_to_replace = np.random.randint(0, len(self.archive))\n            self.archive[idx_to_replace] = vector\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                elif np.random.rand() < 0.2:  # Probability of applying archive mutation (20%)\n                    mutant = self.mutate_archive(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > 0.2 :\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEv2 scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid Differential Evolution algorithm that combines multiple mutation strategies, ensemble adaptation, Cauchy mutation, and dynamic parameter control for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEv2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = []\n        self.archive_size = archive_size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.archive = list(self.population) # Copy initial population to archive\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        # Mutation using the archive\n        if len(self.archive) < 2:\n            return self.mutate_rand1(pop, i)\n\n        idx_archive = np.random.randint(0, len(self.archive))\n        archived_vector = self.archive[idx_archive]\n\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (archived_vector - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            self.update_archive(trial)\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def update_archive(self, vector):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(vector)\n        else:\n            # Replace a random element in the archive\n            idx_to_replace = np.random.randint(0, len(self.archive))\n            self.archive[idx_to_replace] = vector\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                elif np.random.rand() < 0.2:  # Probability of applying archive mutation (20%)\n                    mutant = self.mutate_archive(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > 0.2 :\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.29750016807591395, 0.7224809241306505, 0.7505258717864464, 0.8848185369240081, 0.7798598853119991, 0.8153871243429209, 0.6104455569907518, 0.6774885333895462, 0.7742152036190223, 0.3306404577736999, 0.8823100642748376, 0.9994013607043626, 0.656648866571095, 0.7694732935041897, 0.9281273570831784, 0.8094443463006082, 0.6706541869926015, 0.8652108806808058, 0.44272741195929355, 0.5207021504471971], "operator": "crossover", "theta_sampled": 0.14576277233392781, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "ad2920f8-7086-48dd-b149-1bee8fb1425e", "fitness": 0.0, "name": "AdaptiveHybridDE", "description": "Adaptive Hybrid DE with improved exploration via orthogonal design and periodic restarts for better coverage and convergence.", "code": "import numpy as np\nfrom scipy.stats import qmc\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, restart_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble\n        self.success_history = [[] for _ in range(num_ensemble)]\n        self.step_size = 0.1\n        self.cr_history = []\n        self.cauchy_prob = cauchy_prob\n        self.step_size_reduction = step_size_reduction\n        self.archive = []\n        self.archive_size = pop_size\n        self.restart_frequency = restart_frequency\n        self.eval_count = 0\n        self.orthogonal_matrix = self.generate_orthogonal_array(dim)\n\n\n    def generate_orthogonal_array(self, dim, num_levels=3):\n        # Generate an orthogonal array using Latin hypercube sampling\n        engine = qmc.LatinHypercube(d=dim)\n        sample = engine.random(n=self.pop_size)\n        l_bounds = np.zeros(dim)\n        u_bounds = np.ones(dim)\n\n        oa = qmc.scale(sample, l_bounds, u_bounds)\n        return oa\n\n\n    def initialize_population(self, func):\n        # Use orthogonal array to sample the initial population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = lb + self.orthogonal_matrix * (ub - lb) #np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n        best_idx = np.argmin(self.fitness)\n        idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        self.eval_count += 1\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def restart_population(self, func):\n        # Re-initialize population using orthogonal array sampling\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.orthogonal_matrix = self.generate_orthogonal_array(self.dim) # Generate a new OA matrix\n        new_population = lb + self.orthogonal_matrix * (ub - lb)\n        new_fitness = np.array([func(x) for x in new_population])\n        self.eval_count += self.pop_size\n\n        # Combine old and new populations, then select the best\n        combined_population = np.vstack((self.population, new_population))\n        combined_fitness = np.hstack((self.fitness, new_fitness))\n        \n        best_indices = np.argsort(combined_fitness)[:self.pop_size]\n        self.population = combined_population[best_indices]\n        self.fitness = combined_fitness[best_indices]\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if self.eval_count % self.restart_frequency == 0:\n                self.restart_population(func)\n\n            self.adapt_ensemble_probabilities()\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'qmc' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Hybrid DE with improved exploration via orthogonal design and periodic restarts for better coverage and convergence.\n# Code: \n```python\nimport numpy as np\nfrom scipy.stats import qmc\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, restart_frequency=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble\n        self.success_history = [[] for _ in range(num_ensemble)]\n        self.step_size = 0.1\n        self.cr_history = []\n        self.cauchy_prob = cauchy_prob\n        self.step_size_reduction = step_size_reduction\n        self.archive = []\n        self.archive_size = pop_size\n        self.restart_frequency = restart_frequency\n        self.eval_count = 0\n        self.orthogonal_matrix = self.generate_orthogonal_array(dim)\n\n\n    def generate_orthogonal_array(self, dim, num_levels=3):\n        # Generate an orthogonal array using Latin hypercube sampling\n        engine = qmc.LatinHypercube(d=dim)\n        sample = engine.random(n=self.pop_size)\n        l_bounds = np.zeros(dim)\n        u_bounds = np.ones(dim)\n\n        oa = qmc.scale(sample, l_bounds, u_bounds)\n        return oa\n\n\n    def initialize_population(self, func):\n        # Use orthogonal array to sample the initial population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = lb + self.orthogonal_matrix * (ub - lb) #np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n        best_idx = np.argmin(self.fitness)\n        idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        self.eval_count += 1\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def restart_population(self, func):\n        # Re-initialize population using orthogonal array sampling\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.orthogonal_matrix = self.generate_orthogonal_array(self.dim) # Generate a new OA matrix\n        new_population = lb + self.orthogonal_matrix * (ub - lb)\n        new_fitness = np.array([func(x) for x in new_population])\n        self.eval_count += self.pop_size\n\n        # Combine old and new populations, then select the best\n        combined_population = np.vstack((self.population, new_population))\n        combined_fitness = np.hstack((self.fitness, new_fitness))\n        \n        best_indices = np.argsort(combined_fitness)[:self.pop_size]\n        self.population = combined_population[best_indices]\n        self.fitness = combined_fitness[best_indices]\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            if self.eval_count % self.restart_frequency == 0:\n                self.restart_population(func)\n\n            self.adapt_ensemble_probabilities()\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": -0.007657821986270234, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "3a3e9275-ca48-4ad2-9beb-c505328dd359", "fitness": 0.7313348810398708, "name": "EnsembleAdaptiveDEPlusCauchy", "description": "Combines ensemble adaptive DE with Cauchy mutation and a success-rate based mutation factor adaptation.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnsembleAdaptiveDEPlusCauchy scored 0.731 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines ensemble adaptive DE with Cauchy mutation and a success-rate based mutation factor adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass EnsembleAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3514081808719538, 0.7310087492344467, 0.7305750294900211, 0.8874817446086951, 0.7680341067904393, 0.8124046690726827, 0.6576525235473631, 0.681977562546505, 0.7787176762720447, 0.7233656982401506, 0.8929537408266484, 0.9959685157233138, 0.6860989229656992, 0.7352619311471027, 0.9101521731827028, 0.8007982936040886, 0.6764436209269737, 0.8632410779908017, 0.22852123766158017, 0.7146321660942008], "operator": "crossover", "theta_sampled": 0.23799310533790263, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "3abc93a6-bfcd-4283-af53-3166fc195401", "fitness": 0.0, "name": "AdaptiveHybridDE", "description": "Adaptive Hybrid DE with orthogonal learning to enhance population diversity and convergence speed.", "code": "import numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, orthogonal_learning_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = [] # Archive for storing potentially useful solutions\n        self.archive_size = pop_size # Size of the archive\n        self.orthogonal_learning_rate = orthogonal_learning_rate  # Learning rate for orthogonal learning\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx1].copy(), self.population[idx2].copy()\n\n        # Generate orthogonal directions\n        direction = x2 - x1\n        norm = np.linalg.norm(direction)\n        if norm == 0:\n            return  # Skip if individuals are identical\n\n        orthogonal_basis = direction / norm\n\n        # Generate new solution based on orthogonal direction\n        new_solution = x1 + self.orthogonal_learning_rate * orthogonal_basis * np.random.normal(0, 1, self.dim)  # Gaussian noise for exploration\n        new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n\n        # Evaluate the new solution\n        f_new = func(new_solution)\n\n        # Replace a random individual with the new solution if it's better\n        replace_idx = np.random.randint(0, self.pop_size)\n        if f_new < self.fitness[replace_idx]:\n\n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[replace_idx].copy())\n            else:\n                # Replace a random element in the archive\n                archive_idx = np.random.randint(0, self.archive_size)\n                self.archive[archive_idx] = self.population[replace_idx].copy()\n\n            self.fitness[replace_idx] = f_new\n            self.population[replace_idx] = new_solution\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_solution\n\n\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    # Use archive information to guide mutation\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.orthogonal_learning(func)  # Apply orthogonal learning\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive Hybrid DE with orthogonal learning to enhance population diversity and convergence speed.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, orthogonal_learning_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.archive = [] # Archive for storing potentially useful solutions\n        self.archive_size = pop_size # Size of the archive\n        self.orthogonal_learning_rate = orthogonal_learning_rate  # Learning rate for orthogonal learning\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx1, idx2 = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx1].copy(), self.population[idx2].copy()\n\n        # Generate orthogonal directions\n        direction = x2 - x1\n        norm = np.linalg.norm(direction)\n        if norm == 0:\n            return  # Skip if individuals are identical\n\n        orthogonal_basis = direction / norm\n\n        # Generate new solution based on orthogonal direction\n        new_solution = x1 + self.orthogonal_learning_rate * orthogonal_basis * np.random.normal(0, 1, self.dim)  # Gaussian noise for exploration\n        new_solution = np.clip(new_solution, func.bounds.lb, func.bounds.ub)\n\n        # Evaluate the new solution\n        f_new = func(new_solution)\n\n        # Replace a random individual with the new solution if it's better\n        replace_idx = np.random.randint(0, self.pop_size)\n        if f_new < self.fitness[replace_idx]:\n\n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[replace_idx].copy())\n            else:\n                # Replace a random element in the archive\n                archive_idx = np.random.randint(0, self.archive_size)\n                self.archive[archive_idx] = self.population[replace_idx].copy()\n\n            self.fitness[replace_idx] = f_new\n            self.population[replace_idx] = new_solution\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_solution\n\n\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            \n            # Archive the replaced solution\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                # Replace a random element in the archive\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = self.population[i].copy()\n\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                    # Use archive information to guide mutation\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:  # 10% chance\n                        archive_idx = np.random.randint(0, len(self.archive))\n                        mutant += self.F * (self.archive[archive_idx] - self.population[i])\n\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.orthogonal_learning(func)  # Apply orthogonal learning\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": -0.00021953430476265084, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "b81cf89a-0c14-4835-971e-f68ea9f81783", "fitness": 0.7251641111365799, "name": "AdaptiveEnsembleDE", "description": "Adaptive ensemble of mutation strategies with self-adaptive parameters and archive-based exploration to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveEnsembleDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n        self.archive = []\n        self.archive_size = archive_size\n        self.archive_f = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        if len(self.archive) == 0:\n            return self.mutate_rand1(pop, i)\n        \n        archive_idx = np.random.randint(len(self.archive))\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n\n        mutant = pop[i] + self.F * (self.archive[archive_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n\n            # Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(trial)\n                self.archive_f.append(f_trial)\n            else:\n                max_archive_idx = np.argmax(self.archive_f)\n                if f_trial < self.archive_f[max_archive_idx]:\n                    self.archive[max_archive_idx] = trial\n                    self.archive_f[max_archive_idx] = f_trial\n\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        mutation_strategies_extended = self.mutation_strategies + [self.mutate_archive]\n        num_ensemble_extended = self.num_ensemble + 1\n        ensemble_probs_extended = np.concatenate((self.ensemble_probs, [0.05]))  #Small probability for archive mutation\n        ensemble_probs_extended /= np.sum(ensemble_probs_extended)\n        success_history_extended = [[] for _ in range(num_ensemble_extended)]\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            ensemble_probs_extended[:self.num_ensemble] = self.ensemble_probs\n            ensemble_probs_extended /= np.sum(ensemble_probs_extended)\n\n            mutation_indices = np.random.choice(num_ensemble_extended, size=self.pop_size, p=ensemble_probs_extended)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = mutation_strategies_extended[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         success_history_extended[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.success_history = success_history_extended[:self.num_ensemble] #Only adapt history of non-archive mutations\n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveEnsembleDE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Adaptive ensemble of mutation strategies with self-adaptive parameters and archive-based exploration to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveEnsembleDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = 0.1 # Probability of applying cauchy mutation\n        self.step_size_reduction = 0.9 # Reduction factor for step size adaptation\n        self.archive = []\n        self.archive_size = archive_size\n        self.archive_f = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        if len(self.archive) == 0:\n            return self.mutate_rand1(pop, i)\n        \n        archive_idx = np.random.randint(len(self.archive))\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n\n        mutant = pop[i] + self.F * (self.archive[archive_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n\n            # Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(trial)\n                self.archive_f.append(f_trial)\n            else:\n                max_archive_idx = np.argmax(self.archive_f)\n                if f_trial < self.archive_f[max_archive_idx]:\n                    self.archive[max_archive_idx] = trial\n                    self.archive_f[max_archive_idx] = f_trial\n\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        mutation_strategies_extended = self.mutation_strategies + [self.mutate_archive]\n        num_ensemble_extended = self.num_ensemble + 1\n        ensemble_probs_extended = np.concatenate((self.ensemble_probs, [0.05]))  #Small probability for archive mutation\n        ensemble_probs_extended /= np.sum(ensemble_probs_extended)\n        success_history_extended = [[] for _ in range(num_ensemble_extended)]\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            ensemble_probs_extended[:self.num_ensemble] = self.ensemble_probs\n            ensemble_probs_extended /= np.sum(ensemble_probs_extended)\n\n            mutation_indices = np.random.choice(num_ensemble_extended, size=self.pop_size, p=ensemble_probs_extended)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = mutation_strategies_extended[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         success_history_extended[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.success_history = success_history_extended[:self.num_ensemble] #Only adapt history of non-archive mutations\n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.34383677305726046, 0.7053940428056109, 0.7510349553602258, 0.8974241779064196, 0.7787152196374159, 0.8087071108034962, 0.633592887755652, 0.6888442549970183, 0.7754265827096604, 0.7143286011108028, 0.8988451027812852, 0.990805516398829, 0.6909296777354564, 0.7759164733262605, 0.9353549691156116, 0.8041992560002962, 0.6661617941861226, 0.8779781197426673, 0.2416695546054568, 0.5241171526960483], "operator": "mutation", "theta_sampled": 0.007822507962019604, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "1abd9cc9-7c6e-45ce-bc0e-efad9be7c6a2", "fitness": 0.0, "name": "EnhancedAdaptiveDE", "description": "An adaptive differential evolution strategy that combines ensemble mutation strategies, Cauchy mutation for exploration, and parameter adaptation based on success history.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble\n        self.success_history = [[] for _ in range(num_ensemble)]\n        self.step_size = 0.1\n        self.cr_history = []\n        self.cauchy_prob = cauchy_prob\n        self.step_size_reduction = step_size_reduction\n        self.levy_flight_prob = 0.05 # Probability of applying Levy flight mutation\n        self.archive = [] # Archive of past solutions\n        self.archive_size = 10\n        self.archive_prob = 0.1 # Probability of using archive vector for mutation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.archive = list(self.population) # Initial archive\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def levy_flight(self, pop, i, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / beta)\n        mutant = pop[i] + self.step_size * step\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        idx = np.random.randint(0, len(self.archive))\n        archived_vector = self.archive[idx]\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (archived_vector - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            \n            #Update Archive\n            if trial.tolist() not in [x.tolist() for x in self.archive]: # check duplicates\n                self.archive.append(trial)\n                if len(self.archive) > self.archive_size:\n                    self.archive.pop(0)\n\n            return True, np.linalg.norm(self.population[i] - trial), self.cr\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs)\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = []\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities()\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                # Apply Levy flight mutation\n                elif np.random.rand() < self.levy_flight_prob:\n                    mutant = self.levy_flight(self.population, i)\n                # Apply archive mutation\n                elif np.random.rand() < self.archive_prob and len(self.archive) > 1:\n                    mutant = self.mutate_archive(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > self.levy_flight_prob and np.random.rand() > self.archive_prob: # Distinguish the history\n                        mutation_idx = mutation_indices[i]\n                        self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy that combines ensemble mutation strategies, Cauchy mutation for exploration, and parameter adaptation based on success history.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble\n        self.success_history = [[] for _ in range(num_ensemble)]\n        self.step_size = 0.1\n        self.cr_history = []\n        self.cauchy_prob = cauchy_prob\n        self.step_size_reduction = step_size_reduction\n        self.levy_flight_prob = 0.05 # Probability of applying Levy flight mutation\n        self.archive = [] # Archive of past solutions\n        self.archive_size = 10\n        self.archive_prob = 0.1 # Probability of using archive vector for mutation\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.archive = list(self.population) # Initial archive\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def levy_flight(self, pop, i, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / beta)\n        mutant = pop[i] + self.step_size * step\n        return mutant\n\n    def mutate_archive(self, pop, i):\n        idx = np.random.randint(0, len(self.archive))\n        archived_vector = self.archive[idx]\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        mutant = pop[i] + self.F * (archived_vector - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            \n            #Update Archive\n            if trial.tolist() not in [x.tolist() for x in self.archive]: # check duplicates\n                self.archive.append(trial)\n                if len(self.archive) > self.archive_size:\n                    self.archive.pop(0)\n\n            return True, np.linalg.norm(self.population[i] - trial), self.cr\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs)\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = []\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities()\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                # Apply Levy flight mutation\n                elif np.random.rand() < self.levy_flight_prob:\n                    mutant = self.levy_flight(self.population, i)\n                # Apply archive mutation\n                elif np.random.rand() < self.archive_prob and len(self.archive) > 1:\n                    mutant = self.mutate_archive(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    if np.random.rand() > self.cauchy_prob and np.random.rand() > self.levy_flight_prob and np.random.rand() > self.archive_prob: # Distinguish the history\n                        mutation_idx = mutation_indices[i]\n                        self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.022328999323122895, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "5c1563ae-11d7-4c29-a655-091d79e7d29c", "fitness": 0.22860922487204016, "name": "AdaptiveGaussianMomentum", "description": "Population-based algorithm with adaptive local search refinement using Gaussian perturbations and momentum-based updating.", "code": "import numpy as np\n\nclass AdaptiveGaussianMomentum:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.01, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.momentum = momentum\n        self.velocity = None  # Initialize velocity for momentum\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Reduce budget by initial population evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        if self.velocity is None:\n            self.velocity = np.zeros_like(population) # Initialize velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive Gaussian local search\n                std = np.std(population[i]) # Adapt step size based on local diversity.\n                perturbation = np.random.normal(0, std, size=self.dim)\n                \n                # Update position with momentum\n                x_new = population[i] + self.lr * perturbation\n                \n                # Clip to bounds\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                \n\n                f_new = func(x_new)\n                self.budget -= 1\n\n                if f_new < fitness[i]:\n                    # Update velocity\n                    self.velocity[i] = self.momentum * self.velocity[i] + (x_new - population[i])  # Correct velocity update\n\n                    population[i] = x_new\n                    fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianMomentum scored 0.229 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive local search refinement using Gaussian perturbations and momentum-based updating.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianMomentum:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.01, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.momentum = momentum\n        self.velocity = None  # Initialize velocity for momentum\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Reduce budget by initial population evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        if self.velocity is None:\n            self.velocity = np.zeros_like(population) # Initialize velocity\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive Gaussian local search\n                std = np.std(population[i]) # Adapt step size based on local diversity.\n                perturbation = np.random.normal(0, std, size=self.dim)\n                \n                # Update position with momentum\n                x_new = population[i] + self.lr * perturbation\n                \n                # Clip to bounds\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                \n\n                f_new = func(x_new)\n                self.budget -= 1\n\n                if f_new < fitness[i]:\n                    # Update velocity\n                    self.velocity[i] = self.momentum * self.velocity[i] + (x_new - population[i])  # Correct velocity update\n\n                    population[i] = x_new\n                    fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10883881387271499, 0.14296886779885276, 0.23644337901130685, 0.15217209439135715, 0.14802661620470803, 0.17631388831151595, 0.2096345874488551, 0.14896080178961513, 0.16568009233685865, 0.13605108102327834, 0.144262065814724, 0.9085429979659413, 0.26325290339145735, 0.20095029616518512, 0.15488599162995487, 0.24273128563921254, 0.1931464176319736, 0.2098917236121658, 0.17184101038907118, 0.45758958301205443], "operator": "random_new", "theta_sampled": 0.020221501022070293, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "f7cfc6c0-2709-4a79-91cf-2a491ea7bd3a", "fitness": 0.0, "name": "GPSurrogateOptimizer", "description": "A population-based algorithm using a Gaussian process surrogate model to guide exploration and exploitation, balancing global search with local refinement.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogateOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def _acquisition(self, X):\n        \"\"\"\n        Compute the acquisition function value.\n        Here, we use Upper Confidence Bound (UCB).\n        \"\"\"\n        mu, sigma = self.gpr.predict(X, return_std=True)\n        return mu - self.exploration_weight * sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial exploration\n        X_initial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n\n        self.X = X_initial\n        self.y = y_initial\n\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        \n        # Gaussian process regression\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n        for i in range(self.budget - self.n_initial):\n            self.gpr.fit(self.X, self.y)\n\n            # Find the next point to evaluate using the acquisition function\n            X_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(100, self.dim)) # Sample candidate points\n\n            acquisition_values = self._acquisition(X_sample)\n            x_next = X_sample[np.argmin(acquisition_values)]  # Choose the point with minimum acquisition value\n            \n            f_next = func(x_next)\n            \n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            \n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'C' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A population-based algorithm using a Gaussian process surrogate model to guide exploration and exploitation, balancing global search with local refinement.\n# Code:\n```python\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogateOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def _acquisition(self, X):\n        \"\"\"\n        Compute the acquisition function value.\n        Here, we use Upper Confidence Bound (UCB).\n        \"\"\"\n        mu, sigma = self.gpr.predict(X, return_std=True)\n        return mu - self.exploration_weight * sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial exploration\n        X_initial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n\n        self.X = X_initial\n        self.y = y_initial\n\n        self.f_opt = np.min(self.y)\n        self.x_opt = self.X[np.argmin(self.y)]\n        \n        # Gaussian process regression\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n        for i in range(self.budget - self.n_initial):\n            self.gpr.fit(self.X, self.y)\n\n            # Find the next point to evaluate using the acquisition function\n            X_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(100, self.dim)) # Sample candidate points\n\n            acquisition_values = self._acquisition(X_sample)\n            x_next = X_sample[np.argmin(acquisition_values)]  # Choose the point with minimum acquisition value\n            \n            f_next = func(x_next)\n            \n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            \n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.3789578855130322, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "6afdf2fd-7bbd-4a0e-aa1a-7ddc7818decd", "fitness": 0.7179747167555981, "name": "EnhancedAdaptiveDE", "description": "Combines ensemble adaptive DE with Cauchy mutation and step size adaptation, dynamically adjusting mutation strategy probabilities and parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.gamma = 0.1 # Cauchy mutation scaling factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        mutation = self.gamma * self.step_size * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                    mutation_idx = -1 # Mark Cauchy mutation\n                else:\n                    mutation_indices = np.random.choice(self.num_ensemble, size=1, p=self.ensemble_probs)[0]\n                    mutation_idx = mutation_indices\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    # Distinguish the step size history for ensemble methods\n                    if mutation_idx != -1:\n                        self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_parameters() # Adjust parameters every generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.718 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines ensemble adaptive DE with Cauchy mutation and step size adaptation, dynamically adjusting mutation strategy probabilities and parameters for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.gamma = 0.1 # Cauchy mutation scaling factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        mutation = self.gamma * self.step_size * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr  # Indicate success\n        return False, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                    mutation_idx = -1 # Mark Cauchy mutation\n                else:\n                    mutation_indices = np.random.choice(self.num_ensemble, size=1, p=self.ensemble_probs)[0]\n                    mutation_idx = mutation_indices\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val = self.selection(func, trial, i)\n                if is_successful:\n                    # Distinguish the step size history for ensemble methods\n                    if mutation_idx != -1:\n                        self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            self.adapt_parameters() # Adjust parameters every generation\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.31172242363020575, 0.6783944473002169, 0.7413955720614344, 0.8972824916231251, 0.7844502526937591, 0.8106953742545594, 0.6717002690372733, 0.684402181471182, 0.7638642891697713, 0.7416333261340946, 0.891317184219334, 0.9864737967363925, 0.6657709681613915, 0.7176846643703317, 0.9358148677849671, 0.7997540262203453, 0.6731430538967267, 0.865322158556626, 0.2126436082561849, 0.5260293795340403], "operator": "crossover", "theta_sampled": 0.1785980731497371, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "74d9d449-24e7-4aec-ae4d-8a139230065f", "fitness": 0.16022121807525683, "name": "AdaptiveGaussianHillClimber", "description": "A self-adjusting Gaussian mutation hill climber that adapts its step size based on success rate.", "code": "import numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate = 0.5  # Initial guess for success rate\n        self.success_history_size = 10 #Number of recent successes to track\n        self.successes = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize at a random point\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a candidate solution using Gaussian mutation\n            x_candidate = self.x_opt + np.random.normal(0, self.step_size, self.dim)\n\n            # Clip the candidate solution to stay within bounds\n            x_candidate = np.clip(x_candidate, func.bounds.lb, func.bounds.ub)\n\n            f_candidate = func(x_candidate)\n            eval_count += 1\n\n            if f_candidate < self.f_opt:\n                # Accept the candidate if it's better\n                self.f_opt = f_candidate\n                self.x_opt = x_candidate\n                self.successes.append(1)\n            else:\n                self.successes.append(0)\n\n            # Update success rate\n            if len(self.successes) > self.success_history_size:\n                self.successes.pop(0) #Keep success_history_size elements\n            self.success_rate = np.mean(self.successes)\n\n            # Adjust step size based on success rate\n            if self.success_rate > 0.6:\n                self.step_size *= 1.1  # Increase step size if success rate is high\n            elif self.success_rate < 0.4:\n                self.step_size *= 0.9  # Decrease step size if success rate is low\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianHillClimber scored 0.160 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A self-adjusting Gaussian mutation hill climber that adapts its step size based on success rate.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate = 0.5  # Initial guess for success rate\n        self.success_history_size = 10 #Number of recent successes to track\n        self.successes = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize at a random point\n        self.f_opt = func(self.x_opt)\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a candidate solution using Gaussian mutation\n            x_candidate = self.x_opt + np.random.normal(0, self.step_size, self.dim)\n\n            # Clip the candidate solution to stay within bounds\n            x_candidate = np.clip(x_candidate, func.bounds.lb, func.bounds.ub)\n\n            f_candidate = func(x_candidate)\n            eval_count += 1\n\n            if f_candidate < self.f_opt:\n                # Accept the candidate if it's better\n                self.f_opt = f_candidate\n                self.x_opt = x_candidate\n                self.successes.append(1)\n            else:\n                self.successes.append(0)\n\n            # Update success rate\n            if len(self.successes) > self.success_history_size:\n                self.successes.pop(0) #Keep success_history_size elements\n            self.success_rate = np.mean(self.successes)\n\n            # Adjust step size based on success rate\n            if self.success_rate > 0.6:\n                self.step_size *= 1.1  # Increase step size if success rate is high\n            elif self.success_rate < 0.4:\n                self.step_size *= 0.9  # Decrease step size if success rate is low\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.030265043935212788, 0.04366621371561763, 0.12635728697246884, 0.12671906387748477, 0.11906723465946922, 0.11438699919889928, 0.17114249602199694, 0.19767883259882402, 0.15619267079863353, 0.12168560022078023, 0.11734162389623726, 0.13069651647355096, 0.24048452203315274, 0.1670687255859955, 0.517377660503656, 0.2529040835133157, 0.18157124308287875, 0.15567653722539831, 0.07128027266076897, 0.16286173453079522], "operator": "random_new", "theta_sampled": 0.14519817740361468, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "46b3f164-dfb9-48f5-b93d-cfd068a5a191", "fitness": 0.7246945174094337, "name": "EnhancedAdaptiveDE", "description": "Combines ensemble-based adaptive DE with Cauchy mutation and step-size adaptation, dynamically adjusting probabilities and parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def local_search(self, x, func):\n        # Perturb each dimension with a small random value\n        x_perturbed = x + np.random.normal(0, 0.01 * self.step_size, self.dim)\n        x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n        return x_perturbed\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Apply Local Search with a certain probability\n                if np.random.rand() < self.local_search_prob:\n                    mutant = self.local_search(mutant, func)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines ensemble-based adaptive DE with Cauchy mutation and step-size adaptation, dynamically adjusting probabilities and parameters for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def local_search(self, x, func):\n        # Perturb each dimension with a small random value\n        x_perturbed = x + np.random.normal(0, 0.01 * self.step_size, self.dim)\n        x_perturbed = np.clip(x_perturbed, func.bounds.lb, func.bounds.ub)\n        return x_perturbed\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Apply Local Search with a certain probability\n                if np.random.rand() < self.local_search_prob:\n                    mutant = self.local_search(mutant, func)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3055631728032959, 0.7078969408004071, 0.7590190239852036, 0.8952872360845223, 0.7585492713174453, 0.8097145713772029, 0.6667910498003655, 0.6788091697927313, 0.7743415793245714, 0.7367770527516648, 0.8892632552730015, 0.9945203500054268, 0.6853490059707317, 0.7645094869053517, 0.9331605556868636, 0.8044919516526818, 0.66666777583878, 0.8612206491724435, 0.28258407852299205, 0.519374171122992], "operator": "crossover", "theta_sampled": 0.09659262946155495, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "9a190943-be3d-4ded-a75b-ade449c07bda", "fitness": 0.0, "name": "EnsembleAdaptiveDifferentialEvolutionMirroredSampling", "description": "Ensemble Adaptive Differential Evolution with a mirrored sampling technique for mutation and a self-adaptive mutation factor based on the success rate.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDifferentialEvolutionMirroredSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.F_history = []  # Store successful F values\n        self.F_values = np.array([0.3, 0.5, 0.7]) # Candidate F values\n        self.F_probs = np.ones(3) / 3\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        # Mirrored sampling\n        mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n        mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n         # Mirrored sampling\n         mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n         mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        # Mirrored sampling\n        mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n        mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n        # Adapt F value\n        if len(self.F_history) > 0:\n            # Use the median of successful F values\n            self.F = np.median(self.F_history)\n            self.F_history = []\n        else:\n            # Randomly select an F value if no successful F values recorded\n            self.F = np.random.choice(self.F_values)\n\n        self.F = np.clip(self.F, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                mutation_idx = mutation_indices[i]\n                mutator = self.mutation_strategies[mutation_idx]\n                self.F = np.random.choice(self.F_values, p=self.F_probs) # select F\n                mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Ensemble Adaptive Differential Evolution with a mirrored sampling technique for mutation and a self-adaptive mutation factor based on the success rate.\n# Code: \n```python\nimport numpy as np\n\nclass EnsembleAdaptiveDifferentialEvolutionMirroredSampling:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.F_history = []  # Store successful F values\n        self.F_values = np.array([0.3, 0.5, 0.7]) # Candidate F values\n        self.F_probs = np.ones(3) / 3\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        # Mirrored sampling\n        mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n        mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n         # Mirrored sampling\n         mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n         mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n\n        # Mirrored sampling\n        mutant = np.where(mutant < func.bounds.lb, 2 * func.bounds.lb - mutant, mutant)\n        mutant = np.where(mutant > func.bounds.ub, 2 * func.bounds.ub - mutant, mutant)\n        return mutant\n\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n        # Adapt F value\n        if len(self.F_history) > 0:\n            # Use the median of successful F values\n            self.F = np.median(self.F_history)\n            self.F_history = []\n        else:\n            # Randomly select an F value if no successful F values recorded\n            self.F = np.random.choice(self.F_values)\n\n        self.F = np.clip(self.F, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                mutation_idx = mutation_indices[i]\n                mutator = self.mutation_strategies[mutation_idx]\n                self.F = np.random.choice(self.F_values, p=self.F_probs) # select F\n                mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": -0.0017858067363520655, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2879b148-bb6a-4cf2-bd94-e3f2d2dd8447", "fitness": 0.0, "name": "PSOSimulatedAnnealing", "description": "A hybrid algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass PSOSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, n_particles=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.n_particles = n_particles\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.temperature = self.initial_temp\n\n    def initialize_particles(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.n_particles, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.n_particles, self.dim)) # Smaller velocities initially\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_values = np.array([np.inf] * self.n_particles)\n\n        for i in range(self.n_particles):\n            f = func(self.particles[i])\n            if f < self.personal_best_values[i]:\n                self.personal_best_values[i] = f\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def update_particle(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia * self.velocities[i] +\n                              self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                              self.social_coeff * r2 * (self.global_best_position - self.particles[i]))\n\n        # Limit velocity to prevent explosion\n        self.velocities[i] = np.clip(self.velocities[i], -abs(ub-lb)/5, abs(ub-lb)/5) # Reduced velocity clipping\n\n        # Update position\n        self.particles[i] = self.particles[i] + self.velocities[i]\n\n        # Handle boundary constraints (bounce back)\n        for d in range(self.dim):\n            if self.particles[i, d] < lb:\n                self.particles[i, d] = lb + np.random.rand() * (ub - lb)/100  # Slightly push inside\n                self.velocities[i, d] = -self.velocities[i, d] * 0.5 # Reflect and dampen\n            elif self.particles[i, d] > ub:\n                self.particles[i, d] = ub - np.random.rand() * (ub - lb)/100 # Slightly push inside\n                self.velocities[i, d] = -self.velocities[i, d] * 0.5 # Reflect and dampen\n\n\n        f = func(self.particles[i])\n\n        # Simulated Annealing acceptance criterion\n        delta_e = f - self.personal_best_values[i]\n        if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temperature):\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_particles(func)\n        eval_count += self.n_particles\n\n        while eval_count < self.budget:\n            for i in range(self.n_particles):\n                if eval_count < self.budget:\n                    self.update_particle(i, func)\n                    eval_count += 1\n                else:\n                    break\n\n            self.temperature *= self.cooling_rate  #Cooling\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass PSOSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, n_particles=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.n_particles = n_particles\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.temperature = self.initial_temp\n\n    def initialize_particles(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.n_particles, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb)/10, abs(ub-lb)/10, size=(self.n_particles, self.dim)) # Smaller velocities initially\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_values = np.array([np.inf] * self.n_particles)\n\n        for i in range(self.n_particles):\n            f = func(self.particles[i])\n            if f < self.personal_best_values[i]:\n                self.personal_best_values[i] = f\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def update_particle(self, i, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.inertia * self.velocities[i] +\n                              self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                              self.social_coeff * r2 * (self.global_best_position - self.particles[i]))\n\n        # Limit velocity to prevent explosion\n        self.velocities[i] = np.clip(self.velocities[i], -abs(ub-lb)/5, abs(ub-lb)/5) # Reduced velocity clipping\n\n        # Update position\n        self.particles[i] = self.particles[i] + self.velocities[i]\n\n        # Handle boundary constraints (bounce back)\n        for d in range(self.dim):\n            if self.particles[i, d] < lb:\n                self.particles[i, d] = lb + np.random.rand() * (ub - lb)/100  # Slightly push inside\n                self.velocities[i, d] = -self.velocities[i, d] * 0.5 # Reflect and dampen\n            elif self.particles[i, d] > ub:\n                self.particles[i, d] = ub - np.random.rand() * (ub - lb)/100 # Slightly push inside\n                self.velocities[i, d] = -self.velocities[i, d] * 0.5 # Reflect and dampen\n\n\n        f = func(self.particles[i])\n\n        # Simulated Annealing acceptance criterion\n        delta_e = f - self.personal_best_values[i]\n        if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temperature):\n            self.personal_best_values[i] = f\n            self.personal_best_positions[i] = self.particles[i].copy()\n\n            if f < self.global_best_value:\n                self.global_best_value = f\n                self.global_best_position = self.particles[i].copy()\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_particles(func)\n        eval_count += self.n_particles\n\n        while eval_count < self.budget:\n            for i in range(self.n_particles):\n                if eval_count < self.budget:\n                    self.update_particle(i, func)\n                    eval_count += 1\n                else:\n                    break\n\n            self.temperature *= self.cooling_rate  #Cooling\n            if self.global_best_value < self.f_opt:\n                self.f_opt = self.global_best_value\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.40631673144555913, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "50cd6556-c8fd-4bfb-9596-2529f6d10897", "fitness": 0.23773236162325126, "name": "GravitationalSearch", "description": "Population-based algorithm with a novel \"Gravitational Attraction\" mechanism, where individuals move towards better solutions based on a calculated attraction force and a repulsive force from crowded regions.", "code": "import numpy as np\n\nclass GravitationalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, G=100, epsilon=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.G = G  # Gravitational constant\n        self.epsilon = epsilon # small value to avoid division by zero\n        self.positions = None\n        self.fitness = None\n        self.velocities = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.zeros_like(self.positions)\n        self.fitness = np.array([func(x) for x in self.positions])\n\n    def calculate_masses(self):\n        best_fitness = np.min(self.fitness)\n        worst_fitness = np.max(self.fitness)\n        masses = (self.fitness - worst_fitness) / (best_fitness - worst_fitness + self.epsilon)\n        masses = np.exp(-masses)  # Apply exponential decay\n        masses = masses / np.sum(masses)\n        return masses\n\n    def calculate_forces(self, masses):\n        forces = np.zeros_like(self.positions)\n        for i in range(self.pop_size):\n            for j in range(self.pop_size):\n                if i != j:\n                    R = np.linalg.norm(self.positions[j] - self.positions[i]) + self.epsilon\n                    forces[i] += self.G * masses[j] * (self.positions[j] - self.positions[i]) / R\n        return forces\n\n    def apply_repulsion(self):\n        \"\"\"Applies repulsion to avoid crowding.\"\"\"\n        for i in range(self.pop_size):\n            distances = np.linalg.norm(self.positions - self.positions[i], axis=1)\n            crowded_indices = np.where(distances < 0.1)[0]  # Define crowding radius\n            if len(crowded_indices) > 1: # more than itself is crowded\n                repulsion_direction = np.random.uniform(-1, 1, size=self.dim)\n                repulsion_direction /= np.linalg.norm(repulsion_direction)\n                self.velocities[i] -= 0.1 * repulsion_direction  # Apply small repulsion\n                \n\n    def update_positions(self, forces):\n        self.velocities = 0.5 * self.velocities + forces\n        self.positions += self.velocities\n        self.positions = np.clip(self.positions, self.lb, self.ub) #Clip to bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        f_opt = np.min(self.fitness)\n        x_opt = self.positions[np.argmin(self.fitness)]\n        eval_count = self.pop_size  # Initial evaluation\n\n        while eval_count < self.budget:\n            masses = self.calculate_masses()\n            forces = self.calculate_forces(masses)\n            self.apply_repulsion()\n            self.update_positions(forces)\n            \n            #Evaluate new positions\n            for i in range(self.pop_size):\n                self.fitness[i] = func(self.positions[i])\n                eval_count +=1\n                if self.fitness[i] < f_opt:\n                    f_opt = self.fitness[i]\n                    x_opt = self.positions[i]\n\n                if eval_count >= self.budget:\n                   break #Stop when budget is exceeded\n\n        return f_opt, x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GravitationalSearch scored 0.238 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with a novel \"Gravitational Attraction\" mechanism, where individuals move towards better solutions based on a calculated attraction force and a repulsive force from crowded regions.\n# Code:\n```python\nimport numpy as np\n\nclass GravitationalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, G=100, epsilon=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.G = G  # Gravitational constant\n        self.epsilon = epsilon # small value to avoid division by zero\n        self.positions = None\n        self.fitness = None\n        self.velocities = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.zeros_like(self.positions)\n        self.fitness = np.array([func(x) for x in self.positions])\n\n    def calculate_masses(self):\n        best_fitness = np.min(self.fitness)\n        worst_fitness = np.max(self.fitness)\n        masses = (self.fitness - worst_fitness) / (best_fitness - worst_fitness + self.epsilon)\n        masses = np.exp(-masses)  # Apply exponential decay\n        masses = masses / np.sum(masses)\n        return masses\n\n    def calculate_forces(self, masses):\n        forces = np.zeros_like(self.positions)\n        for i in range(self.pop_size):\n            for j in range(self.pop_size):\n                if i != j:\n                    R = np.linalg.norm(self.positions[j] - self.positions[i]) + self.epsilon\n                    forces[i] += self.G * masses[j] * (self.positions[j] - self.positions[i]) / R\n        return forces\n\n    def apply_repulsion(self):\n        \"\"\"Applies repulsion to avoid crowding.\"\"\"\n        for i in range(self.pop_size):\n            distances = np.linalg.norm(self.positions - self.positions[i], axis=1)\n            crowded_indices = np.where(distances < 0.1)[0]  # Define crowding radius\n            if len(crowded_indices) > 1: # more than itself is crowded\n                repulsion_direction = np.random.uniform(-1, 1, size=self.dim)\n                repulsion_direction /= np.linalg.norm(repulsion_direction)\n                self.velocities[i] -= 0.1 * repulsion_direction  # Apply small repulsion\n                \n\n    def update_positions(self, forces):\n        self.velocities = 0.5 * self.velocities + forces\n        self.positions += self.velocities\n        self.positions = np.clip(self.positions, self.lb, self.ub) #Clip to bounds\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        f_opt = np.min(self.fitness)\n        x_opt = self.positions[np.argmin(self.fitness)]\n        eval_count = self.pop_size  # Initial evaluation\n\n        while eval_count < self.budget:\n            masses = self.calculate_masses()\n            forces = self.calculate_forces(masses)\n            self.apply_repulsion()\n            self.update_positions(forces)\n            \n            #Evaluate new positions\n            for i in range(self.pop_size):\n                self.fitness[i] = func(self.positions[i])\n                eval_count +=1\n                if self.fitness[i] < f_opt:\n                    f_opt = self.fitness[i]\n                    x_opt = self.positions[i]\n\n                if eval_count >= self.budget:\n                   break #Stop when budget is exceeded\n\n        return f_opt, x_opt\n```", "aucs": [0.08837931701916169, 0.10676672462862025, 0.2262509005339408, 0.17860855198314074, 0.13062690297944135, 0.16540105855853293, 0.19374380138377723, 0.15551398597469324, 0.1667564745785146, 0.11611688777268114, 0.20812298091816417, 0.9982437778220454, 0.16724391526550064, 0.1614982988260143, 0.5457313888635942, 0.21071332272799181, 0.19354630663475858, 0.17651990567449816, 0.1314409714088428, 0.43342175891111223], "operator": "random_new", "theta_sampled": 0.2397239279491219, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "4db1232b-9f89-4111-bc4a-c11b8f107671", "fitness": 0.7062997253030925, "name": "HybridAdaptiveDEPlusCMA", "description": "Combines adaptive ensemble DE with Cauchy mutation and covariance matrix adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDEPlusCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.cma_learning_rate = cma_learning_rate # Learning rate for CMA\n\n        # CMA-ES parameters initialization\n        self.mean = None\n        self.covariance = None\n        self.eigenvalues = None\n        self.eigenvectors = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.mu = None\n        self.weights = None\n        self.selection_indices = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.mean = np.mean(self.population, axis=0)\n        self.covariance = np.eye(self.dim)\n        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.covariance)\n        self.c_sigma = 0.3  # Learning rate for step size\n        self.d_sigma = 1.0  # Damping factor for step size\n        self.mu = self.pop_size // 4  # Number of individuals for recombination\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def update_cma(self):\n        # Select the best individuals for recombination\n        self.selection_indices = np.argsort(self.fitness)[:self.mu]\n        selected_population = self.population[self.selection_indices]\n\n        # Update the mean\n        new_mean = np.sum(self.weights[:, np.newaxis] * selected_population, axis=0)\n\n        # Update the covariance matrix\n        diff = selected_population - self.mean\n        self.covariance = (1 - self.cma_learning_rate) * self.covariance + \\\n                          self.cma_learning_rate * np.sum(self.weights[:, np.newaxis, np.newaxis] * diff[:, :, np.newaxis] * diff[:, np.newaxis, :], axis=0)\n\n        #Update mean\n        self.mean = new_mean\n\n        # Eigenvalue decomposition of the covariance matrix\n        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.covariance)\n\n\n    def sample_cma(self):\n        # Sample from a multivariate normal distribution using CMA\n        z = np.random.randn(self.dim)\n        sampled_solution = self.mean + self.step_size * self.eigenvectors @ np.diag(np.sqrt(self.eigenvalues)) @ z\n        return sampled_solution\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                #Apply CMA mutation with a certain probability\n                if np.random.rand() < 0.1:\n                    mutant = self.sample_cma()\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.update_cma() # Update CMA parameters\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEPlusCMA scored 0.706 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines adaptive ensemble DE with Cauchy mutation and covariance matrix adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPlusCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.cma_learning_rate = cma_learning_rate # Learning rate for CMA\n\n        # CMA-ES parameters initialization\n        self.mean = None\n        self.covariance = None\n        self.eigenvalues = None\n        self.eigenvectors = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.mu = None\n        self.weights = None\n        self.selection_indices = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        # CMA-ES Initialization\n        self.mean = np.mean(self.population, axis=0)\n        self.covariance = np.eye(self.dim)\n        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.covariance)\n        self.c_sigma = 0.3  # Learning rate for step size\n        self.d_sigma = 1.0  # Damping factor for step size\n        self.mu = self.pop_size // 4  # Number of individuals for recombination\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def update_cma(self):\n        # Select the best individuals for recombination\n        self.selection_indices = np.argsort(self.fitness)[:self.mu]\n        selected_population = self.population[self.selection_indices]\n\n        # Update the mean\n        new_mean = np.sum(self.weights[:, np.newaxis] * selected_population, axis=0)\n\n        # Update the covariance matrix\n        diff = selected_population - self.mean\n        self.covariance = (1 - self.cma_learning_rate) * self.covariance + \\\n                          self.cma_learning_rate * np.sum(self.weights[:, np.newaxis, np.newaxis] * diff[:, :, np.newaxis] * diff[:, np.newaxis, :], axis=0)\n\n        #Update mean\n        self.mean = new_mean\n\n        # Eigenvalue decomposition of the covariance matrix\n        self.eigenvalues, self.eigenvectors = np.linalg.eig(self.covariance)\n\n\n    def sample_cma(self):\n        # Sample from a multivariate normal distribution using CMA\n        z = np.random.randn(self.dim)\n        sampled_solution = self.mean + self.step_size * self.eigenvectors @ np.diag(np.sqrt(self.eigenvalues)) @ z\n        return sampled_solution\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n\n                #Apply CMA mutation with a certain probability\n                if np.random.rand() < 0.1:\n                    mutant = self.sample_cma()\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.update_cma() # Update CMA parameters\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.460144798965629, 0.3614545125945102, 0.8028664554857559, 0.7954232457063354, 0.7986904297049783, 0.8563996483069668, 0.762283074159954, 0.7635005038157555, 0.8171387179486489, 0.42604930922814244, 0.9201810669459445, 0.9892138033606231, 0.4414285489696067, 0.8174862713154236, 0.941704127866517, 0.8542683282738496, 0.6162962094327284, 0.913363577130812, 0.2777122644877835, 0.5103896123618834], "operator": "crossover", "theta_sampled": 0.031349213903162414, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2e70bb6d-1286-4fff-8192-234af58e9bc2", "fitness": 0.0, "name": "HybridAdaptiveDEPlusCauchy", "description": "An ensemble of adaptive DE strategies combined with Cauchy mutation and a self-adaptive mechanism to control mutation strength and strategy probabilities.", "code": "import numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=4, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2, self.mutate_current_rand1]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.archive = [] #Archive of potentially good solutions\n        self.archive_size = archive_size #Size of the archive\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n    \n    def mutate_current_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[i] + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            delta = self.fitness[i] - f_trial\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            \n            #Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(trial)\n            else:\n                worst_idx = np.argmax([func(x) for x in self.archive])\n                if f_trial < func(self.archive[worst_idx]):\n                    self.archive[worst_idx] = trial\n            \n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F, delta  # Indicate success\n        return False, None, None, None, 0\n\n    def adapt_ensemble_probabilities(self, deltas):\n        # Update probabilities based on success history and fitness improvement\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] += 0.05 * np.mean(deltas) # increase probability if successful and good fitness improvement\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n        self.ensemble_probs = np.clip(self.ensemble_probs, 0.05, 0.95)\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        deltas = []\n\n        while eval_count < self.budget:\n            if len(deltas) > 5:\n                 self.adapt_ensemble_probabilities(deltas) # Adjust strategy probabilities\n                 deltas = []\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val, delta = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n                    deltas.append(delta)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEPlusCauchy scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An ensemble of adaptive DE strategies combined with Cauchy mutation and a self-adaptive mechanism to control mutation strength and strategy probabilities.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=4, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2, self.mutate_current_rand1]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.archive = [] #Archive of potentially good solutions\n        self.archive_size = archive_size #Size of the archive\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n    \n    def mutate_current_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[i] + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            delta = self.fitness[i] - f_trial\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            \n            #Update archive\n            if len(self.archive) < self.archive_size:\n                self.archive.append(trial)\n            else:\n                worst_idx = np.argmax([func(x) for x in self.archive])\n                if f_trial < func(self.archive[worst_idx]):\n                    self.archive[worst_idx] = trial\n            \n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F, delta  # Indicate success\n        return False, None, None, None, 0\n\n    def adapt_ensemble_probabilities(self, deltas):\n        # Update probabilities based on success history and fitness improvement\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] += 0.05 * np.mean(deltas) # increase probability if successful and good fitness improvement\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n        self.ensemble_probs = np.clip(self.ensemble_probs, 0.05, 0.95)\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        deltas = []\n\n        while eval_count < self.budget:\n            if len(deltas) > 5:\n                 self.adapt_ensemble_probabilities(deltas) # Adjust strategy probabilities\n                 deltas = []\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val, delta = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n                    deltas.append(delta)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.27560812193374307, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "374cc732-6295-44f5-b9dc-d085aa282f0c", "fitness": 0.7109209133901105, "name": "HybridAdaptiveDEPlusCauchy", "description": "A hybrid DE algorithm that combines adaptive ensemble mutation strategies with Cauchy mutation and parameter adaptation, focusing on successful step sizes and diversifying search behavior.", "code": "import numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.archive = [] # Archive for storing diverse solutions\n        self.archive_size = archive_size\n        self.archive_fitness = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            self.update_archive(trial, f_trial) # Update archive if the solution is good\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        else:\n            # Learn from the archive.\n            if len(self.archive) > 0 and np.random.rand() < 0.05:  # Small probability to replace\n                idx = np.random.randint(0, len(self.archive))\n                if f_trial < self.archive_fitness[idx]:  # If trial is better than a random archive member\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.update_archive(trial, f_trial)\n\n        return False, None, None, None\n\n    def update_archive(self, x, fx):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(fx)\n        else:\n            # Replace the worst member in the archive\n            worst_idx = np.argmax(self.archive_fitness)\n            if fx < self.archive_fitness[worst_idx]:\n                self.archive[worst_idx] = x\n                self.archive_fitness[worst_idx] = fx\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEPlusCauchy scored 0.711 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid DE algorithm that combines adaptive ensemble mutation strategies with Cauchy mutation and parameter adaptation, focusing on successful step sizes and diversifying search behavior.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.archive = [] # Archive for storing diverse solutions\n        self.archive_size = archive_size\n        self.archive_fitness = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            self.update_archive(trial, f_trial) # Update archive if the solution is good\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        else:\n            # Learn from the archive.\n            if len(self.archive) > 0 and np.random.rand() < 0.05:  # Small probability to replace\n                idx = np.random.randint(0, len(self.archive))\n                if f_trial < self.archive_fitness[idx]:  # If trial is better than a random archive member\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    self.update_archive(trial, f_trial)\n\n        return False, None, None, None\n\n    def update_archive(self, x, fx):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(x)\n            self.archive_fitness.append(fx)\n        else:\n            # Replace the worst member in the archive\n            worst_idx = np.argmax(self.archive_fitness)\n            if fx < self.archive_fitness[worst_idx]:\n                self.archive[worst_idx] = x\n                self.archive_fitness[worst_idx] = fx\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3009419008087513, 0.7245596030486874, 0.7202023569238383, 0.840287555536516, 0.7678338165596418, 0.8125318625608925, 0.6528264195394223, 0.6805306737513566, 0.7756094338271661, 0.6483290130376851, 0.8684144754062245, 0.9980716942314752, 0.6834124824820961, 0.7462529787953542, 0.9308564665674846, 0.8005025127951335, 0.648507761110179, 0.871784629137295, 0.221356487603952, 0.5256061440790573], "operator": "crossover", "theta_sampled": 0.17381086854563133, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "75546310-88eb-4926-b401-728a2e615ccb", "fitness": 0.04469875306184612, "name": "GradientEnhancedTrustRegion", "description": "Population-based algorithm with gradient estimation and adaptive step size control using a trust-region approach.", "code": "import numpy as np\n\nclass GradientEnhancedTrustRegion:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, trust_region_factor=2.0, shrink_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.trust_region_factor = trust_region_factor\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = self.initial_step_size\n        \n        while self.budget > 0:\n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = self.x_opt.copy()\n                x_minus = self.x_opt.copy()\n                \n                delta = 0.001 # Small perturbation for gradient estimation\n                x_plus[i] += delta\n                x_minus[i] -= delta\n                \n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                \n                f_plus = func(x_plus) if self.budget > 0 else np.inf\n                self.budget -= 1 if self.budget > 0 else 0\n                f_minus = func(x_minus) if self.budget > 0 else np.inf\n                self.budget -= 1 if self.budget > 0 else 0\n                \n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n            \n            # Normalize gradient\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                gradient = gradient / gradient_norm\n            \n            # Take a step in the direction of the negative gradient\n            x_new = self.x_opt - step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new) if self.budget > 0 else np.inf\n            self.budget -= 1 if self.budget > 0 else 0\n            \n            # Trust-region update\n            if f_new < self.f_opt:\n                # Successful step\n                self.f_opt = f_new\n                self.x_opt = x_new\n                step_size *= self.trust_region_factor  # Expand trust region\n                \n                #Update population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size if self.budget > self.pop_size else self.budget\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n            else:\n                # Unsuccessful step\n                step_size *= self.shrink_factor  # Shrink trust region\n                \n                \n            if step_size < 1e-6:\n                break #stop if stepsize too small.\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GradientEnhancedTrustRegion scored 0.045 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with gradient estimation and adaptive step size control using a trust-region approach.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedTrustRegion:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, trust_region_factor=2.0, shrink_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.trust_region_factor = trust_region_factor\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        step_size = self.initial_step_size\n        \n        while self.budget > 0:\n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = self.x_opt.copy()\n                x_minus = self.x_opt.copy()\n                \n                delta = 0.001 # Small perturbation for gradient estimation\n                x_plus[i] += delta\n                x_minus[i] -= delta\n                \n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n                \n                f_plus = func(x_plus) if self.budget > 0 else np.inf\n                self.budget -= 1 if self.budget > 0 else 0\n                f_minus = func(x_minus) if self.budget > 0 else np.inf\n                self.budget -= 1 if self.budget > 0 else 0\n                \n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n            \n            # Normalize gradient\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                gradient = gradient / gradient_norm\n            \n            # Take a step in the direction of the negative gradient\n            x_new = self.x_opt - step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new) if self.budget > 0 else np.inf\n            self.budget -= 1 if self.budget > 0 else 0\n            \n            # Trust-region update\n            if f_new < self.f_opt:\n                # Successful step\n                self.f_opt = f_new\n                self.x_opt = x_new\n                step_size *= self.trust_region_factor  # Expand trust region\n                \n                #Update population\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size if self.budget > self.pop_size else self.budget\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n            else:\n                # Unsuccessful step\n                step_size *= self.shrink_factor  # Shrink trust region\n                \n                \n            if step_size < 1e-6:\n                break #stop if stepsize too small.\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0.08939750612369224, 0], "operator": "random_new", "theta_sampled": 0.1658878133495949, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "e621ed1a-2175-41c0-bbbb-c882c21251de", "fitness": 0.0, "name": "OrthogonalLearningSearch", "description": "Population-based algorithm with orthogonal learning, where orthogonal array sampling creates diverse offspring, and a local search refines promising solutions.", "code": "import numpy as np\nfrom scipy.stats import norm\n\nclass OrthogonalLearningSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_array_size=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_array_size = min(orthogonal_array_size, pop_size) # Ensure orthogonal_array_size <= pop_size\n        self.local_search_iterations = local_search_iterations\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0 # Keep track of function evaluations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n    def generate_orthogonal_array(self, levels):\n        # Simplified orthogonal array generation (L9 array)\n        if levels == 3:  # Create a simple L9 orthogonal array. Can be extended to others.\n            return np.array([\n                [0, 0, 0, 0],\n                [0, 1, 1, 1],\n                [0, 2, 2, 2],\n                [1, 0, 1, 2],\n                [1, 1, 2, 0],\n                [1, 2, 0, 1],\n                [2, 0, 2, 1],\n                [2, 1, 0, 2],\n                [2, 2, 1, 0]\n            ])\n        else:\n             return np.random.randint(0, levels, size=(9, 4))  # Return random array if L9 not wanted\n\n\n    def orthogonal_crossover(self, func):\n        parents_indices = np.random.choice(self.pop_size, size=self.orthogonal_array_size, replace=False)\n        parents = self.population[parents_indices]\n\n        orthogonal_array = self.generate_orthogonal_array(levels=3)\n        num_factors = orthogonal_array.shape[1] #Use the shape of the orthogonal array\n        num_runs = orthogonal_array.shape[0] #Use the shape of the orthogonal array\n\n        for i in range(num_runs):\n            child = np.copy(parents[0]) # Copy a parent, and perturb.\n            for j in range(min(num_factors, self.dim)): #limit the dimensions that can be changed to the orthogonal array size.\n                level = orthogonal_array[i, j % num_factors] #Loop in the dimensions, if out of range, then go back to the start\n                \n                # Perturb dimension j based on orthogonal array level. Can be generalized.\n                delta = 0.1 * (level - 1)  # Simple perturbation: -0.1, 0, 0.1\n                child[j] = np.clip(parents[0][j] + delta, func.bounds.lb[j], func.bounds.ub[j])  # Bound each dimension\n\n            f_child = func(child)\n            self.eval_count += 1\n\n            if f_child < self.f_opt:\n                self.f_opt = f_child\n                self.x_opt = child\n\n            worst_index = np.argmax(self.fitness)\n            if f_child < self.fitness[worst_index]:\n                self.population[worst_index] = child\n                self.fitness[worst_index] = f_child\n\n\n    def local_search(self, func):\n        for _ in range(self.local_search_iterations):\n            # Select a promising solution (e.g., best in population)\n            index = np.argmin(self.fitness)\n            x = self.population[index].copy()\n\n            # Perturb each dimension with a small Gaussian noise\n            noise = np.random.normal(0, 0.05, size=self.dim)  # Adjust noise scale as needed\n            x_new = np.clip(x + noise, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            if f_new < self.fitness[index]:\n                self.population[index] = x_new\n                self.fitness[index] = f_new\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.orthogonal_crossover(func)\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OrthogonalLearningSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Population-based algorithm with orthogonal learning, where orthogonal array sampling creates diverse offspring, and a local search refines promising solutions.\n# Code: \n```python\nimport numpy as np\nfrom scipy.stats import norm\n\nclass OrthogonalLearningSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_array_size=10, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_array_size = min(orthogonal_array_size, pop_size) # Ensure orthogonal_array_size <= pop_size\n        self.local_search_iterations = local_search_iterations\n\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0 # Keep track of function evaluations\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n\n    def generate_orthogonal_array(self, levels):\n        # Simplified orthogonal array generation (L9 array)\n        if levels == 3:  # Create a simple L9 orthogonal array. Can be extended to others.\n            return np.array([\n                [0, 0, 0, 0],\n                [0, 1, 1, 1],\n                [0, 2, 2, 2],\n                [1, 0, 1, 2],\n                [1, 1, 2, 0],\n                [1, 2, 0, 1],\n                [2, 0, 2, 1],\n                [2, 1, 0, 2],\n                [2, 2, 1, 0]\n            ])\n        else:\n             return np.random.randint(0, levels, size=(9, 4))  # Return random array if L9 not wanted\n\n\n    def orthogonal_crossover(self, func):\n        parents_indices = np.random.choice(self.pop_size, size=self.orthogonal_array_size, replace=False)\n        parents = self.population[parents_indices]\n\n        orthogonal_array = self.generate_orthogonal_array(levels=3)\n        num_factors = orthogonal_array.shape[1] #Use the shape of the orthogonal array\n        num_runs = orthogonal_array.shape[0] #Use the shape of the orthogonal array\n\n        for i in range(num_runs):\n            child = np.copy(parents[0]) # Copy a parent, and perturb.\n            for j in range(min(num_factors, self.dim)): #limit the dimensions that can be changed to the orthogonal array size.\n                level = orthogonal_array[i, j % num_factors] #Loop in the dimensions, if out of range, then go back to the start\n                \n                # Perturb dimension j based on orthogonal array level. Can be generalized.\n                delta = 0.1 * (level - 1)  # Simple perturbation: -0.1, 0, 0.1\n                child[j] = np.clip(parents[0][j] + delta, func.bounds.lb[j], func.bounds.ub[j])  # Bound each dimension\n\n            f_child = func(child)\n            self.eval_count += 1\n\n            if f_child < self.f_opt:\n                self.f_opt = f_child\n                self.x_opt = child\n\n            worst_index = np.argmax(self.fitness)\n            if f_child < self.fitness[worst_index]:\n                self.population[worst_index] = child\n                self.fitness[worst_index] = f_child\n\n\n    def local_search(self, func):\n        for _ in range(self.local_search_iterations):\n            # Select a promising solution (e.g., best in population)\n            index = np.argmin(self.fitness)\n            x = self.population[index].copy()\n\n            # Perturb each dimension with a small Gaussian noise\n            noise = np.random.normal(0, 0.05, size=self.dim)  # Adjust noise scale as needed\n            x_new = np.clip(x + noise, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            if f_new < self.fitness[index]:\n                self.population[index] = x_new\n                self.fitness[index] = f_new\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.orthogonal_crossover(func)\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.25259946803331845, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "dbc6e138-4ae9-42a3-8fa8-817a96a1c2f3", "fitness": 0.7231541600624483, "name": "HybridAdaptiveDEPlusCauchy", "description": "A hybrid DE algorithm that combines adaptive ensemble mutation strategies with Cauchy mutation and parameter adaptation, focusing on diversifying the search and balancing exploration/exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, F_adapt_freq = 5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.F_adapt_freq = F_adapt_freq\n        self.generation_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor every F_adapt_freq generations\n        if self.generation_count % self.F_adapt_freq == 0:\n            if len(self.F_history) > 0:\n                self.F = np.mean(self.F_history)\n                self.F_history = []\n            else:\n                self.F *= 0.95\n            self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        self.generation_count = 0\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.generation_count += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEPlusCauchy scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid DE algorithm that combines adaptive ensemble mutation strategies with Cauchy mutation and parameter adaptation, focusing on diversifying the search and balancing exploration/exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, F_adapt_freq = 5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.F_adapt_freq = F_adapt_freq\n        self.generation_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor every F_adapt_freq generations\n        if self.generation_count % self.F_adapt_freq == 0:\n            if len(self.F_history) > 0:\n                self.F = np.mean(self.F_history)\n                self.F_history = []\n            else:\n                self.F *= 0.95\n            self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        self.generation_count = 0\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            self.generation_count += 1\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.32945699761148617, 0.7144338693934613, 0.7463752636057082, 0.8945043887174559, 0.7865546735943025, 0.8172871651665213, 0.6183166778936866, 0.6913858391898011, 0.7721758081298691, 0.7241485575616697, 0.8649908130847799, 0.9880451659802071, 0.6552123646053978, 0.7478886827672655, 0.9227406550611219, 0.7910104484648246, 0.6821227012768747, 0.8644960710900073, 0.3346404608654392, 0.5172965971890857], "operator": "crossover", "theta_sampled": 0.11150424162264752, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "5c727653-2266-42a9-817c-a03ed0f866dd", "fitness": 0.0, "name": "EnhancedAdaptiveDE", "description": "An ensemble of adaptive differential evolution strategies, enhanced with Cauchy mutation and step size adaptation based on successful moves, combined with a mirrored sampling approach to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, mirror_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.mirror_prob = mirror_prob # Probability of applying mirrored sampling\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n    \n    def mirror_sampling(self, x, func):\n        x_mirrored = func.bounds.lb + func.bounds.ub - x\n        return x_mirrored\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                # Apply mirrored sampling with a certain probability\n                if np.random.rand() < self.mirror_prob:\n                    trial_mirrored = self.mirror_sampling(trial, func)\n                    f_trial_mirrored = func(trial_mirrored)\n                    eval_count += 1\n                    if f_trial_mirrored < func(trial):\n                        trial = trial_mirrored\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: An ensemble of adaptive differential evolution strategies, enhanced with Cauchy mutation and step size adaptation based on successful moves, combined with a mirrored sampling approach to enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, mirror_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.mirror_prob = mirror_prob # Probability of applying mirrored sampling\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n    \n    def mirror_sampling(self, x, func):\n        x_mirrored = func.bounds.lb + func.bounds.ub - x\n        return x_mirrored\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                # Apply mirrored sampling with a certain probability\n                if np.random.rand() < self.mirror_prob:\n                    trial_mirrored = self.mirror_sampling(trial, func)\n                    f_trial_mirrored = func(trial_mirrored)\n                    eval_count += 1\n                    if f_trial_mirrored < func(trial):\n                        trial = trial_mirrored\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.07100169901138594, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "d7139937-f7b0-408e-a1e1-6974b2f2f9df", "fitness": 0.7132330669837808, "name": "HybridAdaptiveDEPlusCauchy", "description": "A hybrid DE algorithm that combines adaptive ensemble mutation strategies, Cauchy mutation for exploration, and parameter adaptation inspired by successful historical performance.", "code": "import numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, F_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store successful F values\n        self.F_decay = F_decay # Decay factor for F\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= self.F_decay\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEPlusCauchy scored 0.713 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: A hybrid DE algorithm that combines adaptive ensemble mutation strategies, Cauchy mutation for exploration, and parameter adaptation inspired by successful historical performance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPlusCauchy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, F_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store successful F values\n        self.F_decay = F_decay # Decay factor for F\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= self.F_decay\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.25350565013041904, 0.7146079990491997, 0.7479215213181998, 0.8769698801312763, 0.7596176440971958, 0.8167290931692325, 0.5576519509376288, 0.687923117176889, 0.7843134607210409, 0.7296636970049859, 0.88972136251395, 0.9942124694218819, 0.6838831402242678, 0.7599151810448947, 0.9369465169134675, 0.8003887602869908, 0.6596072588868995, 0.8529215906044818, 0.23010755035005603, 0.5280534956926584], "operator": "crossover", "theta_sampled": 0.2157932635322689, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "ffec53d8-9823-4e45-9dc9-762684912833", "fitness": 0.40970847412427913, "name": "HybridAdaptiveDEWithNiching", "description": "Combines adaptive ensemble DE strategies with Cauchy mutation and self-adaptive F and cr parameters, along with a niching strategy to promote diversity.", "code": "import numpy as np\n\nclass HybridAdaptiveDEWithNiching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, niching_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.niching_radius = niching_radius # Radius for niching\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n\n        # Niching: Penalize solutions that are too close to each other\n        for j in range(self.pop_size):\n            if i != j and np.linalg.norm(trial - self.population[j]) < self.niching_radius:\n                f_trial += abs(self.fitness[j] - f_trial) # Penalize based on fitness difference\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDEWithNiching scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"llm_response": "# Description: Combines adaptive ensemble DE strategies with Cauchy mutation and self-adaptive F and cr parameters, along with a niching strategy to promote diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveDEWithNiching:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, cr=0.9, num_ensemble=3, cauchy_prob=0.1, step_size_reduction=0.9, niching_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mutation_strategies = [self.mutate_rand1, self.mutate_current_to_best, self.mutate_rand2]\n        self.num_ensemble = num_ensemble\n        self.ensemble_probs = np.ones(num_ensemble) / num_ensemble  # Uniform initialization\n        self.success_history = [[] for _ in range(self.num_ensemble)] # Store successful step sizes for each strategy\n        self.step_size = 0.1 # Initial step size for mutation\n        self.cr_history = [] # Store successful crossover rates for adaptation\n        self.cauchy_prob = cauchy_prob # Probability of applying cauchy mutation\n        self.step_size_reduction = step_size_reduction # Reduction factor for step size adaptation\n        self.F_history = [] # Store F values\n        self.niching_radius = niching_radius # Radius for niching\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def mutate_rand1(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_current_to_best(self, pop, i):\n         best_idx = np.argmin(self.fitness)\n         idxs = [idx for idx in range(self.pop_size) if idx not in [i, best_idx]]\n         a, b = np.random.choice(idxs, 2, replace=False)\n         mutant = pop[i] + self.F * (self.population[best_idx] - pop[i]) + self.F * (pop[a] - pop[b]) + self.step_size * np.random.normal(0, 1, self.dim)\n         return mutant\n\n    def mutate_rand2(self, pop, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c, d, e = np.random.choice(idxs, 5, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.F * (pop[d] - pop[e]) + self.step_size * np.random.normal(0, 1, self.dim)\n        return mutant\n\n    def mutate_cauchy(self, pop, i):\n        gamma = 0.1 * self.step_size\n        mutation = gamma * np.tan(np.pi * (np.random.rand(self.dim) - 0.5))\n        mutant = pop[i] + mutation\n        return mutant\n\n    def crossover(self, pop, i, mutant, func):\n        trial = pop[i].copy()\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == np.random.randint(0, self.dim):\n                trial[j] = mutant[j]\n        trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n        return trial\n\n    def selection(self, func, trial, i):\n        f_trial = func(trial)\n\n        # Niching: Penalize solutions that are too close to each other\n        for j in range(self.pop_size):\n            if i != j and np.linalg.norm(trial - self.population[j]) < self.niching_radius:\n                f_trial += abs(self.fitness[j] - f_trial) # Penalize based on fitness difference\n\n        if f_trial < self.fitness[i]:\n            self.fitness[i] = f_trial\n            self.population[i] = trial\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial\n            return True, np.linalg.norm(self.population[i] - trial), self.cr, self.F  # Indicate success\n        return False, None, None, None\n\n    def adapt_ensemble_probabilities(self):\n        # Update probabilities based on success history\n        for i in range(self.num_ensemble):\n            if len(self.success_history[i]) > 0:\n                self.ensemble_probs[i] *= 1.1 # increase probability if successful\n\n        self.ensemble_probs /= np.sum(self.ensemble_probs) # Normalize probabilities\n\n    def adapt_parameters(self):\n        #Adapt Crossover Rate\n        if len(self.cr_history) > 0:\n            self.cr = np.mean(self.cr_history)\n            self.cr_history = [] # Reset history\n        else:\n             self.cr *= 0.95\n        \n        self.cr = np.clip(self.cr, 0.1, 0.99)\n\n        #Adapt Step Size\n        successful_steps = [np.mean(history) if len(history) > 0 else 0 for history in self.success_history]\n        if np.sum(successful_steps) > 0:\n            self.step_size = np.mean(successful_steps)\n        else:\n            self.step_size *= self.step_size_reduction\n        self.step_size = np.clip(self.step_size, 1e-6, 1)\n\n        #Adapt Mutation Factor\n        if len(self.F_history) > 0:\n            self.F = np.mean(self.F_history)\n            self.F_history = []\n        else:\n            self.F *= 0.95\n        self.F = np.clip(self.F, 0.1, 0.99)\n\n\n        self.success_history = [[] for _ in range(self.num_ensemble)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adapt_ensemble_probabilities() # Adjust strategy probabilities\n            mutation_indices = np.random.choice(self.num_ensemble, size=self.pop_size, p=self.ensemble_probs)\n\n            for i in range(self.pop_size):\n                # Apply Cauchy mutation with a certain probability\n                if np.random.rand() < self.cauchy_prob:\n                    mutant = self.mutate_cauchy(self.population, i)\n                else:\n                    mutation_idx = mutation_indices[i]\n                    mutator = self.mutation_strategies[mutation_idx]\n                    mutant = mutator(self.population, i)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                trial = self.crossover(self.population, i, mutant, func)\n\n                is_successful, step_size, cr_val, F_val = self.selection(func, trial, i)\n                if is_successful:\n                    #Distinguish the step size history for ensemble methods\n                    if np.random.rand() > self.cauchy_prob:\n                         mutation_idx = mutation_indices[i]\n                         self.success_history[mutation_idx].append(step_size)\n                    self.cr_history.append(cr_val)\n                    self.F_history.append(F_val)\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n            \n            self.adapt_parameters() # Adjust parameters every generation\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17634755619858766, 0.35735661807159746, 0.3863341657138526, 0.4473283667200053, 0.2999662690554109, 0.38331778427581487, 0.3241537501376147, 0.32800729156842634, 0.3076641651374441, 0.24787305168459484, 0.4577953162424172, 0.996506818007197, 0.4678416801571794, 0.3156556355433211, 0.7565497466445851, 0.40346927278577127, 0.3311495834787397, 0.47727639004231026, 0.21843923857221392, 0.5111367824484981], "operator": "crossover", "theta_sampled": 0.01812916559498007, "reward": 0.0, "generation": 6}, "task_prompt": ""}
