{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 4.352528431003447, "mean": 0.008482050290402193, "var": 0.00010774229482614124, "std": 0.010379898594212818, "theta": 0.014498022143012126, "pulls": 19}, "crossover": {"count": 2.613368695284945, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.30573533780083323, "pulls": 11}, "random_new": {"count": 2.955551201598821, "mean": 0.0020807273907766806, "var": 0.00010282326264036195, "std": 0.010140180601959807, "theta": 0.005000209908764574, "pulls": 16}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "eb6fe76e-a959-4125-901c-2989fa4f096a", "fitness": 0.7094004168672018, "name": "HybridCMAES_ACS", "description": "Combines CMA-ES with a velocity-clamping ACS and a restart mechanism triggered by stagnation in the CMA-ES covariance matrix adaptation.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3,\n                 velocity_clamp=0.5): # Added velocity clamp\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp  # Added velocity clamp\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C_trace_history = []\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n        stagnation_counter = 0 # Counter for stagnation\n        max_stagnation = 50 # Restart after this many iterations of no improvement\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter += 1\n\n            # Restart mechanism\n            if stagnation_counter > max_stagnation:\n                # Reset CMA-ES parameters\n                m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.sigma = 0.5  # Reset sigma too\n                stagnation_counter = 0\n                print(\"Restarting CMA-ES due to stagnation.\")\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCMAES_ACS scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3be0900-a9f9-4f06-a39a-f7ea0a20a18c"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines CMA-ES with a velocity-clamping ACS and a restart mechanism triggered by stagnation in the CMA-ES covariance matrix adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3,\n                 velocity_clamp=0.5): # Added velocity clamp\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp  # Added velocity clamp\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C_trace_history = []\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n        stagnation_counter = 0 # Counter for stagnation\n        max_stagnation = 50 # Restart after this many iterations of no improvement\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter += 1\n\n            # Restart mechanism\n            if stagnation_counter > max_stagnation:\n                # Reset CMA-ES parameters\n                m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.sigma = 0.5  # Reset sigma too\n                stagnation_counter = 0\n                print(\"Restarting CMA-ES due to stagnation.\")\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19138203283762933, 0.8353775855695146, 0.9484311657084894, 0.6530475295322282, 0.9651570823969099, 0.9716935126508321, 0.31361417838977446, 0.9415957643697609, 0.9527959174094808, 0.261530867650962, 0.9686273142211086, 0.9764639554824676, 0.2505304213074895, 0.9548488108352512, 0.9550487437477689, 0.5342784252923245, 0.7440151146204005, 0.9672836313084542, 0.3019152900203228, 0.5003709939928646], "operator": "mutation", "theta_sampled": 0.012377778284226459, "reward": 0.045822083792120494, "generation": 6}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-0", "seed": 0}
