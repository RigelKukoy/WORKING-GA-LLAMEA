{"id": "9e0039b0-68af-4cbf-8012-27a355688952", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution strategy with population diversity maintenance and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, CR=0.9, local_search_probability=0.1):\n        \"\"\"\n        Initializes the Adaptive Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The mutation factor.\n            CR (float): The crossover rate.\n            local_search_probability (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()  # Important to copy!\n\n                # Local Search (occasional refinement)\n                if np.random.rand() < self.local_search_probability:\n                    x_local = self.local_search(func, self.population[i])\n                    f_local = func(x_local)\n                    self.evals += 1\n                    if f_local < self.fitness[i]:\n                         self.fitness[i] = f_local\n                         self.population[i] = x_local\n                         if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n\n                if self.evals >= self.budget:\n                   break\n\n            # Adaptive F and CR (Optional - can be beneficial for some functions)\n            self.F = 0.5 * (1 + np.random.randn() * 0.1) # Example adaptation\n            self.CR = 0.9 + np.random.randn() * 0.05\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n            # Population diversity maintenance (Restart if population converges)\n            if self.population_diversity() < 0.01:  # Threshold can be tuned\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy with population diversity maintenance and local search refinement.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, CR=0.9, local_search_probability=0.1):\n        \"\"\"\n        Initializes the Adaptive Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): The mutation factor.\n            CR (float): The crossover rate.\n            local_search_probability (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()  # Important to copy!\n\n                # Local Search (occasional refinement)\n                if np.random.rand() < self.local_search_probability:\n                    x_local = self.local_search(func, self.population[i])\n                    f_local = func(x_local)\n                    self.evals += 1\n                    if f_local < self.fitness[i]:\n                         self.fitness[i] = f_local\n                         self.population[i] = x_local\n                         if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n\n                if self.evals >= self.budget:\n                   break\n\n            # Adaptive F and CR (Optional - can be beneficial for some functions)\n            self.F = 0.5 * (1 + np.random.randn() * 0.1) # Example adaptation\n            self.CR = 0.9 + np.random.randn() * 0.05\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n            # Population diversity maintenance (Restart if population converges)\n            if self.population_diversity() < 0.01:  # Threshold can be tuned\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "21193bfb-4977-4836-8779-37248b5e2740", "fitness": 0.2741804604135224, "name": "AdaptiveShrinkingHypercubeSearch", "description": "A population-based algorithm with a shrinking search space and adaptive mutation rates.", "code": "import numpy as np\n\nclass AdaptiveShrinkingHypercubeSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, initial_shrink_rate=0.95, min_shrink_rate = 0.8):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.budget > 0:\n            # Select parents based on fitness (lower fitness is better)\n            probabilities = np.max(fitness) - fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n            \n            # Create offspring via weighted average of parents\n            parents_indices = np.random.choice(self.population_size, size=(self.population_size, 2), replace=True, p=probabilities)\n            offspring = (population[parents_indices[:, 0]] + population[parents_indices[:, 1]]) / 2\n\n            # Mutation: Add noise scaled by current search space size\n            mutation_scale = (ub - lb) * shrink_rate  # Adaptive mutation\n            mutation = np.random.normal(0, mutation_scale, size=offspring.shape)\n            offspring += mutation\n            \n            # Clip offspring to respect boundaries\n            offspring = np.clip(offspring, lb, ub)\n            \n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update best solution\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace the worst individuals in the population with the offspring (elitism)\n            worst_indices = np.argsort(fitness)[-self.population_size//2:] # replace half the population\n\n            population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.population_size//2]] # Replace worst half of population with best half of offspring.\n            fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.population_size//2]]\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate) #Reduce shrink rate over time to avoid getting stuck in local optima\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveShrinkingHypercubeSearch scored 0.274 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm with a shrinking search space and adaptive mutation rates.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveShrinkingHypercubeSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, initial_shrink_rate=0.95, min_shrink_rate = 0.8):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within the bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.budget > 0:\n            # Select parents based on fitness (lower fitness is better)\n            probabilities = np.max(fitness) - fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n            \n            # Create offspring via weighted average of parents\n            parents_indices = np.random.choice(self.population_size, size=(self.population_size, 2), replace=True, p=probabilities)\n            offspring = (population[parents_indices[:, 0]] + population[parents_indices[:, 1]]) / 2\n\n            # Mutation: Add noise scaled by current search space size\n            mutation_scale = (ub - lb) * shrink_rate  # Adaptive mutation\n            mutation = np.random.normal(0, mutation_scale, size=offspring.shape)\n            offspring += mutation\n            \n            # Clip offspring to respect boundaries\n            offspring = np.clip(offspring, lb, ub)\n            \n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update best solution\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace the worst individuals in the population with the offspring (elitism)\n            worst_indices = np.argsort(fitness)[-self.population_size//2:] # replace half the population\n\n            population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.population_size//2]] # Replace worst half of population with best half of offspring.\n            fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.population_size//2]]\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate) #Reduce shrink rate over time to avoid getting stuck in local optima\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.09576894404738301, 0.1655262932417112, 0.23137441575557804, 0.20769916406573474, 0.21230927637844854, 0.22806990993769216, 0.221608709643221, 0.18088433464271414, 0.1739433291974799, 0.15789658131241036, 0.20644947960945914, 0.99513732676049, 0.23354306493078103, 0.21137069682563425, 0.6166821620422467, 0.2751675293139175, 0.2135888812448602, 0.25870712350790037, 0.15552961303552126, 0.44235237277726347], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "760ffbac-6199-4efc-86d0-18ca951269f5", "fitness": 0.0, "name": "AdaptiveVelocityPSO", "description": "A population-based algorithm employing a velocity-based update rule with adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.pop_size, self.dim))  # Initialize velocities with a fraction of the range\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        \n        # Adaptive parameters\n        exploration_rate = 0.5  # Initial exploration rate\n        exploration_decay = 0.995 # Decay factor for exploration\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            # Adaptive Inertia Weight (linearly decreasing)\n            inertia = self.inertia * (1 - (1 - (self.budget / 10000.0 if self.budget < 10000.0 else 1.0)))\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n\n            # Apply velocity clamping to prevent explosion\n            v_max = abs(ub-lb)/2 # Maximum velocity\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            # Apply exploration with probability exploration_rate\n            exploration_mask = np.random.rand(self.pop_size, self.dim) < exploration_rate\n            population[exploration_mask] = np.random.uniform(lb, ub, size=np.sum(exploration_mask))\n\n            population = population + velocities\n            \n\n            # Boundary handling (wrap-around)\n            population = np.where(population < lb, lb + (population - lb) % (ub - lb), population)\n            population = np.where(population > ub, lb + (population - lb) % (ub - lb), population)\n\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n\n            # Update personal best positions and fitnesses\n            improvement_mask = new_fitness < personal_best_fitness\n            personal_best_positions[improvement_mask] = population[improvement_mask].copy()\n            personal_best_fitness[improvement_mask] = new_fitness[improvement_mask].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n            \n            # Update exploration rate\n            exploration_rate *= exploration_decay\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (50,) and arg 1 with shape (2,).", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm employing a velocity-based update rule with adaptive exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveVelocityPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/5, abs(ub-lb)/5, size=(self.pop_size, self.dim))  # Initialize velocities with a fraction of the range\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n        \n        \n        # Adaptive parameters\n        exploration_rate = 0.5  # Initial exploration rate\n        exploration_decay = 0.995 # Decay factor for exploration\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            # Adaptive Inertia Weight (linearly decreasing)\n            inertia = self.inertia * (1 - (1 - (self.budget / 10000.0 if self.budget < 10000.0 else 1.0)))\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n\n            # Apply velocity clamping to prevent explosion\n            v_max = abs(ub-lb)/2 # Maximum velocity\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            # Apply exploration with probability exploration_rate\n            exploration_mask = np.random.rand(self.pop_size, self.dim) < exploration_rate\n            population[exploration_mask] = np.random.uniform(lb, ub, size=np.sum(exploration_mask))\n\n            population = population + velocities\n            \n\n            # Boundary handling (wrap-around)\n            population = np.where(population < lb, lb + (population - lb) % (ub - lb), population)\n            population = np.where(population > ub, lb + (population - lb) % (ub - lb), population)\n\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            \n\n            # Update personal best positions and fitnesses\n            improvement_mask = new_fitness < personal_best_fitness\n            personal_best_positions[improvement_mask] = population[improvement_mask].copy()\n            personal_best_fitness[improvement_mask] = new_fitness[improvement_mask].copy()\n\n            # Update global best position and fitness\n            best_index = np.argmin(new_fitness)\n            if new_fitness[best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index]\n                global_best_position = population[best_index].copy()\n            \n            # Update exploration rate\n            exploration_rate *= exploration_decay\n\n        return global_best_fitness, global_best_position\n```"}, "task_prompt": ""}
{"id": "9879223c-b757-4525-99c8-19b30a1bab21", "fitness": 0.0, "name": "AdaptiveDE", "description": "An adaptive Differential Evolution strategy with self-adaptive parameters and restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = [F]  # Memory for F values\n        self.Cr_memory = [Cr]  # Memory for Cr values\n        self.memory_size = 5\n        self.restart_trigger = 1.05 #restart the population if the improvement is less than this factor \n        self.num_restarts = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        best_fitness_history = [self.f_opt]\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.population[i])\n                trial[crossover_mask] = mutant[crossover_mask]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n                    \n            best_fitness_history.append(self.f_opt)\n            #Adapt F and CR\n            self.F = np.mean(self.F_memory) if self.F_memory else 0.5\n            self.Cr = np.mean(self.Cr_memory) if self.Cr_memory else 0.9\n            \n            # Adapt F and Cr (simple approach)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n            self.F_memory.append(self.F)\n            self.Cr_memory.append(self.Cr)\n            if len(self.F_memory) > self.memory_size:\n                self.F_memory.pop(0)\n            if len(self.Cr_memory) > self.memory_size:\n                self.Cr_memory.pop(0)\n            \n            #Restart mechanism\n            if self.f_opt > (best_fitness_history[-2] / self.restart_trigger) and len(best_fitness_history) > 2:\n                self.num_restarts += 1\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                \n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                \n                best_fitness_history.append(self.f_opt)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution strategy with self-adaptive parameters and restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = [F]  # Memory for F values\n        self.Cr_memory = [Cr]  # Memory for Cr values\n        self.memory_size = 5\n        self.restart_trigger = 1.05 #restart the population if the improvement is less than this factor \n        self.num_restarts = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        best_fitness_history = [self.f_opt]\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.population[i])\n                trial[crossover_mask] = mutant[crossover_mask]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n                    \n            best_fitness_history.append(self.f_opt)\n            #Adapt F and CR\n            self.F = np.mean(self.F_memory) if self.F_memory else 0.5\n            self.Cr = np.mean(self.Cr_memory) if self.Cr_memory else 0.9\n            \n            # Adapt F and Cr (simple approach)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n            self.F_memory.append(self.F)\n            self.Cr_memory.append(self.Cr)\n            if len(self.F_memory) > self.memory_size:\n                self.F_memory.pop(0)\n            if len(self.Cr_memory) > self.memory_size:\n                self.Cr_memory.pop(0)\n            \n            #Restart mechanism\n            if self.f_opt > (best_fitness_history[-2] / self.restart_trigger) and len(best_fitness_history) > 2:\n                self.num_restarts += 1\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                \n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                \n                best_fitness_history.append(self.f_opt)\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "023ee195-3e3c-4cff-9e75-b8882b7c4ef7", "fitness": 0.0, "name": "AdaptiveCMAHypercubeSearch", "description": "An adaptive shrinking hypercube search with a CMA-ES inspired mutation and dynamic population sizing.", "code": "import numpy as np\n\nclass AdaptiveCMAHypercubeSearch:\n    def __init__(self, budget=10000, dim=10, initial_population_size=20, initial_shrink_rate=0.95, min_shrink_rate = 0.8, cma_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = initial_population_size\n        self.population_size = initial_population_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = None\n        self.covariance = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize mean and covariance\n        if self.mean is None:\n            self.mean = np.random.uniform(lb, ub, size=self.dim)\n        if self.covariance is None:\n            self.covariance = np.eye(self.dim) * ((ub - lb) / 5)**2  # Initialize covariance with reasonable scaling\n\n        # Initialize population within the bounds\n        population = np.random.multivariate_normal(self.mean, self.covariance, size=self.population_size)\n        population = np.clip(population, lb, ub)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.budget > 0:\n            # Select parents based on fitness (lower fitness is better)\n            probabilities = np.max(fitness) - fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n            \n            # Create offspring via weighted average of parents (similar to previous approach, but less crucial now)\n            parents_indices = np.random.choice(self.population_size, size=(self.population_size, 2), replace=True, p=probabilities)\n            offspring = (population[parents_indices[:, 0]] + population[parents_indices[:, 1]]) / 2\n\n            # Mutation: Use CMA-ES-like adaptation with multivariate normal distribution\n            offspring = np.random.multivariate_normal(self.mean, self.covariance, size=self.population_size)\n\n            # Clip offspring to respect boundaries\n            offspring = np.clip(offspring, lb, ub)\n            \n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update best solution\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace the worst individuals in the population with the offspring (elitism)\n            worst_indices = np.argsort(fitness)[-self.population_size//2:] # replace half the population\n\n            population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.population_size//2]] # Replace worst half of population with best half of offspring.\n            fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.population_size//2]]\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # CMA-ES adaptation: Update mean and covariance\n            self.mean = np.mean(population, axis=0)\n            diff = population - self.mean\n            self.covariance = (1 - self.cma_learning_rate) * self.covariance + self.cma_learning_rate * (diff.T @ diff) / self.population_size\n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate) #Reduce shrink rate over time to avoid getting stuck in local optima\n\n            # Dynamic population sizing (adaptive)\n            if self.f_opt == fitness.min():\n              self.population_size = min(self.initial_population_size * 2, self.budget//2)\n            else:\n              self.population_size = self.initial_population_size\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: 'a' and 'p' must have same size", "parent_ids": ["21193bfb-4977-4836-8779-37248b5e2740"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive shrinking hypercube search with a CMA-ES inspired mutation and dynamic population sizing.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAHypercubeSearch:\n    def __init__(self, budget=10000, dim=10, initial_population_size=20, initial_shrink_rate=0.95, min_shrink_rate = 0.8, cma_learning_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = initial_population_size\n        self.population_size = initial_population_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = None\n        self.covariance = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize mean and covariance\n        if self.mean is None:\n            self.mean = np.random.uniform(lb, ub, size=self.dim)\n        if self.covariance is None:\n            self.covariance = np.eye(self.dim) * ((ub - lb) / 5)**2  # Initialize covariance with reasonable scaling\n\n        # Initialize population within the bounds\n        population = np.random.multivariate_normal(self.mean, self.covariance, size=self.population_size)\n        population = np.clip(population, lb, ub)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.budget > 0:\n            # Select parents based on fitness (lower fitness is better)\n            probabilities = np.max(fitness) - fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n            \n            # Create offspring via weighted average of parents (similar to previous approach, but less crucial now)\n            parents_indices = np.random.choice(self.population_size, size=(self.population_size, 2), replace=True, p=probabilities)\n            offspring = (population[parents_indices[:, 0]] + population[parents_indices[:, 1]]) / 2\n\n            # Mutation: Use CMA-ES-like adaptation with multivariate normal distribution\n            offspring = np.random.multivariate_normal(self.mean, self.covariance, size=self.population_size)\n\n            # Clip offspring to respect boundaries\n            offspring = np.clip(offspring, lb, ub)\n            \n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.population_size\n\n            # Update best solution\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace the worst individuals in the population with the offspring (elitism)\n            worst_indices = np.argsort(fitness)[-self.population_size//2:] # replace half the population\n\n            population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.population_size//2]] # Replace worst half of population with best half of offspring.\n            fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.population_size//2]]\n            \n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            # CMA-ES adaptation: Update mean and covariance\n            self.mean = np.mean(population, axis=0)\n            diff = population - self.mean\n            self.covariance = (1 - self.cma_learning_rate) * self.covariance + self.cma_learning_rate * (diff.T @ diff) / self.population_size\n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate) #Reduce shrink rate over time to avoid getting stuck in local optima\n\n            # Dynamic population sizing (adaptive)\n            if self.f_opt == fitness.min():\n              self.population_size = min(self.initial_population_size * 2, self.budget//2)\n            else:\n              self.population_size = self.initial_population_size\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.07311696138177348, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "71a3ad96-717e-40e9-9250-16ae45292952", "fitness": 0.0, "name": "SelfAdaptiveDE", "description": "A self-adaptive Differential Evolution with a modified mutation strategy that combines best-so-far and current-to-best mutation, along with dynamic parameter adaptation and a restart mechanism for diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, CR=0.9, local_search_probability=0.1):\n        \"\"\"\n        Initializes the Self-Adaptive Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): Initial mutation factor.\n            CR (float): Initial crossover rate.\n            local_search_probability (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = int(self.pop_size * 0.2)  # Archive size, e.g., 20% of pop_size\n        self.archive = []\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        # Initialize F and CR for each individual\n        self.F_values = np.full(self.pop_size, self.F)\n        self.CR_values = np.full(self.pop_size, self.CR)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Self-adaptation of F and CR\n                self.F_values[i] = np.clip(np.random.normal(self.F_values[i], 0.1), 0.1, 1.0)\n                self.CR_values[i] = np.clip(np.random.normal(self.CR_values[i], 0.1), 0.1, 1.0)\n                \n                # Mutation Strategy: Current-to-best with archive\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.population[idxs]\n\n                if self.x_opt is None:\n                    x_best = self.population[np.argmin(self.fitness)]\n                else:\n                    x_best = self.x_opt\n\n                x_mutated = self.population[i] + self.F_values[i] * (x_best - self.population[i]) + self.F_values[i] * (x_r1 - x_r2) # current-to-best\n\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR_values[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update individual and potentially global best\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n                        \n                    # Update archive: Add the replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                         idx_to_replace = np.random.randint(self.archive_size)\n                         self.archive[idx_to_replace] = self.population[i]\n\n                # Local Search (occasional refinement)\n                if np.random.rand() < self.local_search_probability:\n                    x_local = self.local_search(func, self.population[i])\n                    f_local = func(x_local)\n                    self.evals += 1\n                    if f_local < self.fitness[i]:\n                         self.fitness[i] = f_local\n                         self.population[i] = x_local\n                         if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n\n                if self.evals >= self.budget:\n                   break\n\n            # Population diversity maintenance (Restart if population converges)\n            if self.population_diversity() < 0.01:  # Threshold can be tuned\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.F_values = np.full(self.pop_size, self.F) # reset self-adaptive parameters\n                self.CR_values = np.full(self.pop_size, self.CR)\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9e0039b0-68af-4cbf-8012-27a355688952"], "operator": "mutation", "metadata": {"llm_response": "# Description: A self-adaptive Differential Evolution with a modified mutation strategy that combines best-so-far and current-to-best mutation, along with dynamic parameter adaptation and a restart mechanism for diversity.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.7, CR=0.9, local_search_probability=0.1):\n        \"\"\"\n        Initializes the Self-Adaptive Differential Evolution optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            F (float): Initial mutation factor.\n            CR (float): Initial crossover rate.\n            local_search_probability (float): Probability of applying local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = int(self.pop_size * 0.2)  # Archive size, e.g., 20% of pop_size\n        self.archive = []\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using Self-Adaptive Differential Evolution.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        # Initialize F and CR for each individual\n        self.F_values = np.full(self.pop_size, self.F)\n        self.CR_values = np.full(self.pop_size, self.CR)\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Self-adaptation of F and CR\n                self.F_values[i] = np.clip(np.random.normal(self.F_values[i], 0.1), 0.1, 1.0)\n                self.CR_values[i] = np.clip(np.random.normal(self.CR_values[i], 0.1), 0.1, 1.0)\n                \n                # Mutation Strategy: Current-to-best with archive\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = self.population[idxs]\n\n                if self.x_opt is None:\n                    x_best = self.population[np.argmin(self.fitness)]\n                else:\n                    x_best = self.x_opt\n\n                x_mutated = self.population[i] + self.F_values[i] * (x_best - self.population[i]) + self.F_values[i] * (x_r1 - x_r2) # current-to-best\n\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR_values[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    # Update individual and potentially global best\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n                        \n                    # Update archive: Add the replaced individual to archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i])\n                    else:\n                         idx_to_replace = np.random.randint(self.archive_size)\n                         self.archive[idx_to_replace] = self.population[i]\n\n                # Local Search (occasional refinement)\n                if np.random.rand() < self.local_search_probability:\n                    x_local = self.local_search(func, self.population[i])\n                    f_local = func(x_local)\n                    self.evals += 1\n                    if f_local < self.fitness[i]:\n                         self.fitness[i] = f_local\n                         self.population[i] = x_local\n                         if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local.copy()\n\n                if self.evals >= self.budget:\n                   break\n\n            # Population diversity maintenance (Restart if population converges)\n            if self.population_diversity() < 0.01:  # Threshold can be tuned\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.evals += self.pop_size\n                self.F_values = np.full(self.pop_size, self.F) # reset self-adaptive parameters\n                self.CR_values = np.full(self.pop_size, self.CR)\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.04102340515371437, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "d3d5d702-2a07-4262-b2dd-4c2d12ea070c", "fitness": 0.0, "name": "HybridAdaptiveSearch", "description": "A hybrid approach combining adaptive hypercube shrinking with differential evolution for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, initial_shrink_rate=0.95, min_shrink_rate = 0.8, F=0.7, CR=0.9, local_search_probability=0.1, de_frequency=0.2):\n        \"\"\"\n        Initializes the Hybrid Adaptive Search optimizer, combining shrinking hypercubes and differential evolution.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            initial_shrink_rate (float): Initial rate for shrinking the hypercube.\n\t\t\tmin_shrink_rate (float): Minimum shrinking rate to avoid premature convergence.\n            F (float): The mutation factor for DE.\n            CR (float): The crossover rate for DE.\n            local_search_probability (float): Probability of applying local search.\n            de_frequency (float): Frequency of applying DE updates.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.de_frequency = de_frequency\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the hybrid approach.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.evals < self.budget:\n            # Shrinking Hypercube Search component\n            probabilities = np.max(self.fitness) - self.fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n\n            # Create offspring via weighted average of parents (similar to ASHS)\n            parents_indices = np.random.choice(self.pop_size, size=(self.pop_size, 2), replace=True, p=probabilities)\n            offspring = (self.population[parents_indices[:, 0]] + self.population[parents_indices[:, 1]]) / 2\n\n            # Mutation (adaptive scaling)\n            mutation_scale = (self.ub - self.lb) * shrink_rate\n            mutation = np.random.normal(0, mutation_scale, size=offspring.shape)\n            offspring += mutation\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.evals += self.pop_size\n\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace worst individuals with best offspring (elitism)\n            worst_indices = np.argsort(self.fitness)[-self.pop_size//2:]\n            self.population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.pop_size//2]]\n            self.fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.pop_size//2]]\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n            # Differential Evolution component (applied probabilistically)\n            if np.random.rand() < self.de_frequency:\n                for i in range(self.pop_size):\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.evals += 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = x_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial.copy()\n\n                    # Local Search (occasional refinement)\n                    if np.random.rand() < self.local_search_probability:\n                        x_local = self.local_search(func, self.population[i])\n                        f_local = func(x_local)\n                        self.evals += 1\n                        if f_local < self.fitness[i]:\n                            self.fitness[i] = f_local\n                            self.population[i] = x_local\n                            if f_local < self.f_opt:\n                                self.f_opt = f_local\n                                self.x_opt = x_local.copy()\n                    if self.evals >= self.budget:\n                        break\n\n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate)\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)", "configspace": "", "generation": 1, "feedback": "The algorithm HybridAdaptiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["21193bfb-4977-4836-8779-37248b5e2740", "9e0039b0-68af-4cbf-8012-27a355688952"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid approach combining adaptive hypercube shrinking with differential evolution for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, initial_shrink_rate=0.95, min_shrink_rate = 0.8, F=0.7, CR=0.9, local_search_probability=0.1, de_frequency=0.2):\n        \"\"\"\n        Initializes the Hybrid Adaptive Search optimizer, combining shrinking hypercubes and differential evolution.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            initial_shrink_rate (float): Initial rate for shrinking the hypercube.\n\t\t\tmin_shrink_rate (float): Minimum shrinking rate to avoid premature convergence.\n            F (float): The mutation factor for DE.\n            CR (float): The crossover rate for DE.\n            local_search_probability (float): Probability of applying local search.\n            de_frequency (float): Frequency of applying DE updates.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_shrink_rate = initial_shrink_rate\n        self.min_shrink_rate = min_shrink_rate\n        self.F = F\n        self.CR = CR\n        self.local_search_probability = local_search_probability\n        self.de_frequency = de_frequency\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the hybrid approach.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size  # Initialize evaluation counter\n\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        shrink_rate = self.initial_shrink_rate\n\n        while self.evals < self.budget:\n            # Shrinking Hypercube Search component\n            probabilities = np.max(self.fitness) - self.fitness + 1e-9  # Add a small value to avoid division by zero\n            probabilities /= np.sum(probabilities)\n\n            # Create offspring via weighted average of parents (similar to ASHS)\n            parents_indices = np.random.choice(self.pop_size, size=(self.pop_size, 2), replace=True, p=probabilities)\n            offspring = (self.population[parents_indices[:, 0]] + self.population[parents_indices[:, 1]]) / 2\n\n            # Mutation (adaptive scaling)\n            mutation_scale = (self.ub - self.lb) * shrink_rate\n            mutation = np.random.normal(0, mutation_scale, size=offspring.shape)\n            offspring += mutation\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.evals += self.pop_size\n\n            best_offspring_index = np.argmin(offspring_fitness)\n            if offspring_fitness[best_offspring_index] < self.f_opt:\n                self.f_opt = offspring_fitness[best_offspring_index]\n                self.x_opt = offspring[best_offspring_index]\n\n            # Replace worst individuals with best offspring (elitism)\n            worst_indices = np.argsort(self.fitness)[-self.pop_size//2:]\n            self.population[worst_indices] = offspring[np.argsort(offspring_fitness)[:self.pop_size//2]]\n            self.fitness[worst_indices] = offspring_fitness[np.argsort(offspring_fitness)[:self.pop_size//2]]\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n            # Differential Evolution component (applied probabilistically)\n            if np.random.rand() < self.de_frequency:\n                for i in range(self.pop_size):\n                    # Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                    x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                    # Crossover\n                    x_trial = np.copy(self.population[i])\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            x_trial[j] = x_mutated[j]\n\n                    # Selection\n                    f_trial = func(x_trial)\n                    self.evals += 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = x_trial\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = x_trial.copy()\n\n                    # Local Search (occasional refinement)\n                    if np.random.rand() < self.local_search_probability:\n                        x_local = self.local_search(func, self.population[i])\n                        f_local = func(x_local)\n                        self.evals += 1\n                        if f_local < self.fitness[i]:\n                            self.fitness[i] = f_local\n                            self.population[i] = x_local\n                            if f_local < self.f_opt:\n                                self.f_opt = f_local\n                                self.x_opt = x_local.copy()\n                    if self.evals >= self.budget:\n                        break\n\n\n            # Shrink the search space dynamically based on convergence\n            shrink_rate = max(self.min_shrink_rate, shrink_rate * self.initial_shrink_rate)\n\n            if self.evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x, step_size=0.1, num_steps=5):\n        \"\"\"\n        Performs a simple local search around a given solution.\n        \"\"\"\n        x_best = x.copy()\n        f_best = func(x)\n        \n        for _ in range(num_steps):\n            x_neighbor = x_best + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_neighbor = np.clip(x_neighbor, self.lb, self.ub)\n            f_neighbor = func(x_neighbor)\n            if f_neighbor < f_best:\n                f_best = f_neighbor\n                x_best = x_neighbor.copy()\n        return x_best\n\n    def population_diversity(self):\n        \"\"\"\n        Calculates the average distance of individuals from the population mean.\n        \"\"\"\n        mean = np.mean(self.population, axis=0)\n        distances = np.linalg.norm(self.population - mean, axis=1)\n        return np.mean(distances)\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.21430345748061216, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "3b9e8e4f-1b68-454f-b39d-f63f6757179f", "fitness": 0.2795692197013667, "name": "HybridPSOSA", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) with simulated annealing (SA) for exploration and exploitation, adapting inertia and temperature parameters based on population diversity and function evaluations.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, initial_temp=100.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = initial_inertia\n        self.temp = initial_temp\n        self.initial_temp = initial_temp  # Store for resetting\n        self.particles = None\n        self.velocities = None\n        self.local_best_positions = None\n        self.local_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n        self.diversity_threshold = 0.01 # Threshold for diversity check\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) / 2, abs(ub - lb) / 2, size=(self.pop_size, self.dim))\n        self.local_best_positions = self.particles.copy()\n        self.local_best_values = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.local_best_positions[np.argmin(self.local_best_values)]\n        self.global_best_value = np.min(self.local_best_values)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Update inertia and temperature based on evaluation progress\n            progress = self.eval_count / self.budget\n            self.inertia = 0.9 - 0.7 * progress\n            self.temp = self.initial_temp * np.exp(-5 * progress)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.inertia * self.velocities[i] + r1 * (self.local_best_positions[i] - self.particles[i]) + r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = cognitive_velocity\n\n                # Update position\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub) # Clip to bounds\n\n                # Simulated Annealing acceptance criterion\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                delta_e = new_fitness - self.local_best_values[i]\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                    self.particles[i] = new_position\n                    self.local_best_values[i] = new_fitness\n                    self.local_best_positions[i] = new_position\n\n                    if new_fitness < self.global_best_value:\n                        self.global_best_value = new_fitness\n                        self.global_best_position = new_position\n\n                if self.eval_count >= self.budget:\n                    break # Ensure budget is not exceeded\n\n        return self.global_best_value, self.global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOSA scored 0.280 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) with simulated annealing (SA) for exploration and exploitation, adapting inertia and temperature parameters based on population diversity and function evaluations.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, initial_temp=100.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = initial_inertia\n        self.temp = initial_temp\n        self.initial_temp = initial_temp  # Store for resetting\n        self.particles = None\n        self.velocities = None\n        self.local_best_positions = None\n        self.local_best_values = None\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n        self.diversity_threshold = 0.01 # Threshold for diversity check\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb) / 2, abs(ub - lb) / 2, size=(self.pop_size, self.dim))\n        self.local_best_positions = self.particles.copy()\n        self.local_best_values = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.local_best_positions[np.argmin(self.local_best_values)]\n        self.global_best_value = np.min(self.local_best_values)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Update inertia and temperature based on evaluation progress\n            progress = self.eval_count / self.budget\n            self.inertia = 0.9 - 0.7 * progress\n            self.temp = self.initial_temp * np.exp(-5 * progress)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.inertia * self.velocities[i] + r1 * (self.local_best_positions[i] - self.particles[i]) + r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = cognitive_velocity\n\n                # Update position\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub) # Clip to bounds\n\n                # Simulated Annealing acceptance criterion\n                new_fitness = func(new_position)\n                self.eval_count += 1\n\n                delta_e = new_fitness - self.local_best_values[i]\n\n                if delta_e < 0 or np.random.rand() < np.exp(-delta_e / self.temp):\n                    self.particles[i] = new_position\n                    self.local_best_values[i] = new_fitness\n                    self.local_best_positions[i] = new_position\n\n                    if new_fitness < self.global_best_value:\n                        self.global_best_value = new_fitness\n                        self.global_best_position = new_position\n\n                if self.eval_count >= self.budget:\n                    break # Ensure budget is not exceeded\n\n        return self.global_best_value, self.global_best_position\n```", "aucs": [0.1679963992125224, 0.2058778935303629, 0.24002769390719692, 0.21045815390943423, 0.254899898460503, 0.16688857918931377, 0.25492686555423305, 0.21871609836118744, 0.1955824035101137, 0.12345622995526606, 0.28557062322498883, 0.9973313249708515, 0.2024744916120178, 0.25908689360632153, 0.56350726523493, 0.22424778516797794, 0.1963834978697272, 0.21520403136034327, 0.17949657963208032, 0.42925168575796246], "operator": "random_new", "theta_sampled": -0.10602248124219203, "reward": 0.005388759287844325, "generation": 1}, "task_prompt": ""}
{"id": "7dac6bda-068a-4f9a-8a96-579240ccebc4", "fitness": 0.36777046101512073, "name": "AdaptivePopulationSearch", "description": "An adaptive population-based algorithm that dynamically adjusts its search strategy based on the observed landscape. It uses a combination of global exploration with local exploitation, and dynamically tune its exploration range and step size.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, population_size=50, exploration_factor=0.5, exploitation_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.exploration_factor = exploration_factor  # Controls global search range\n        self.exploitation_factor = exploitation_factor # Controls local search step\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.zeros(self.population_size)\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def evolve(self, func):\n        # Adaptive Exploration and Exploitation\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random individual for differential mutation\n            j = np.random.randint(self.population_size)\n            while j == i:\n                j = np.random.randint(self.population_size)\n\n            # Select another random individual for differential mutation\n            k = np.random.randint(self.population_size)\n            while k == i or k == j:\n                k = np.random.randint(self.population_size)\n\n            # Exploration: Create a new candidate solution based on differential evolution with a larger step\n            exploration_candidate = self.population[i] + self.exploration_factor * (self.population[j] - self.population[k])\n            exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n\n            # Exploitation: Create a new candidate solution based on small random perturbation around the current solution\n            exploitation_candidate = self.population[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n            exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n\n            # Choose either exploration or exploitation candidate randomly\n            if np.random.rand() < 0.5:\n                candidate = exploration_candidate\n            else:\n                candidate = exploitation_candidate\n\n\n            f_candidate = func(candidate)\n            self.eval_count += 1\n            if f_candidate < self.fitness[i]:\n                self.population[i] = candidate\n                self.fitness[i] = f_candidate\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePopulationSearch scored 0.368 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that dynamically adjusts its search strategy based on the observed landscape. It uses a combination of global exploration with local exploitation, and dynamically tune its exploration range and step size.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, population_size=50, exploration_factor=0.5, exploitation_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.exploration_factor = exploration_factor  # Controls global search range\n        self.exploitation_factor = exploitation_factor # Controls local search step\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.fitness = np.zeros(self.population_size)\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def evolve(self, func):\n        # Adaptive Exploration and Exploitation\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Select a random individual for differential mutation\n            j = np.random.randint(self.population_size)\n            while j == i:\n                j = np.random.randint(self.population_size)\n\n            # Select another random individual for differential mutation\n            k = np.random.randint(self.population_size)\n            while k == i or k == j:\n                k = np.random.randint(self.population_size)\n\n            # Exploration: Create a new candidate solution based on differential evolution with a larger step\n            exploration_candidate = self.population[i] + self.exploration_factor * (self.population[j] - self.population[k])\n            exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n\n            # Exploitation: Create a new candidate solution based on small random perturbation around the current solution\n            exploitation_candidate = self.population[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n            exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n\n            # Choose either exploration or exploitation candidate randomly\n            if np.random.rand() < 0.5:\n                candidate = exploration_candidate\n            else:\n                candidate = exploitation_candidate\n\n\n            f_candidate = func(candidate)\n            self.eval_count += 1\n            if f_candidate < self.fitness[i]:\n                self.population[i] = candidate\n                self.fitness[i] = f_candidate\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13670015462891638, 0.2678023424268131, 0.35954250269415766, 0.35782441107552987, 0.27680212663042936, 0.35266264908100775, 0.2813611087330218, 0.31280950794677154, 0.2587478615798844, 0.21792415123597564, 0.3977189638426436, 0.998476177634901, 0.37781252849557445, 0.27328949429318916, 0.7321136100308181, 0.38298340331184977, 0.2905825421947562, 0.4316147078102881, 0.1729537781387468, 0.47568719851713925], "operator": "random_new", "theta_sampled": -0.04891288516892185, "reward": 0.09359000060159833, "generation": 1}, "task_prompt": ""}
{"id": "efc9acf1-48ec-4263-8413-ad975ece5f07", "fitness": 0.5006845251321462, "name": "CooperativeSwarmElitistLearning", "description": "Cooperative Swarm with Elitist Learning: Employs a swarm of particles that interact cooperatively, with elitist learning guiding the swarm towards promising regions, while incorporating exploration to avoid premature convergence.", "code": "import numpy as np\n\nclass CooperativeSwarmElitistLearning:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm CooperativeSwarmElitistLearning scored 0.501 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Cooperative Swarm with Elitist Learning: Employs a swarm of particles that interact cooperatively, with elitist learning guiding the swarm towards promising regions, while incorporating exploration to avoid premature convergence.\n# Code: \n```python\nimport numpy as np\n\nclass CooperativeSwarmElitistLearning:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.22399673584269308, 0.19288618261904344, 0.8985028579430537, 0.17257893894041587, 0.3136747873910207, 0.9303149928664448, 0.3080979988418705, 0.5653355504445972, 0.22530527989430327, 0.20800612532949403, 0.23273824454044512, 0.9970698435842863, 0.25948979305233977, 0.32669880260753825, 0.7421960408187407, 0.9347882001571617, 0.8378404454531225, 0.9357423749837623, 0.21332254256178163, 0.4951047647708092], "operator": "random_new", "theta_sampled": 0.04399246486046304, "reward": 0.22650406471862383, "generation": 1}, "task_prompt": ""}
{"id": "be0a8c6b-b6c9-4cf8-a511-6ca7fc147284", "fitness": 0.36508069983056923, "name": "AdaptiveEvolutionaryStrategy", "description": "An evolutionary strategy that uses a population of solutions, Gaussian mutation with adaptive step size control, and truncation selection to improve solutions over time.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, tau=0.1, tau_prime=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.tau = tau\n        self.tau_prime = tau_prime\n\n    def __call__(self, func):\n        # Initialize population and step sizes\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.ones((self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find the best solution in the initial population\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Main optimization loop\n        while self.budget > 0:\n            # Create offspring by mutating the population\n            offspring = population + step_sizes * np.random.normal(0, 1, size=(self.pop_size, self.dim))\n\n            # Adapt step sizes\n            global_factor = np.exp(self.tau_prime * np.random.normal(0, 1, size=self.pop_size))[:, np.newaxis]\n            local_factors = np.exp(self.tau * np.random.normal(0, 1, size=(self.pop_size, self.dim)))\n            step_sizes = step_sizes * global_factor * local_factors\n\n            # Clip offspring to the search space\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Truncation selection: Combine parents and offspring, select the best\n            combined_population = np.concatenate((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            indices = np.argsort(combined_fitness)[:self.pop_size]\n            population = combined_population[indices]\n            fitness = combined_fitness[indices]\n\n\n            # Update the best solution found so far\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveEvolutionaryStrategy scored 0.365 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An evolutionary strategy that uses a population of solutions, Gaussian mutation with adaptive step size control, and truncation selection to improve solutions over time.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, tau=0.1, tau_prime=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.tau = tau\n        self.tau_prime = tau_prime\n\n    def __call__(self, func):\n        # Initialize population and step sizes\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.ones((self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find the best solution in the initial population\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Main optimization loop\n        while self.budget > 0:\n            # Create offspring by mutating the population\n            offspring = population + step_sizes * np.random.normal(0, 1, size=(self.pop_size, self.dim))\n\n            # Adapt step sizes\n            global_factor = np.exp(self.tau_prime * np.random.normal(0, 1, size=self.pop_size))[:, np.newaxis]\n            local_factors = np.exp(self.tau * np.random.normal(0, 1, size=(self.pop_size, self.dim)))\n            step_sizes = step_sizes * global_factor * local_factors\n\n            # Clip offspring to the search space\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Truncation selection: Combine parents and offspring, select the best\n            combined_population = np.concatenate((population, offspring))\n            combined_fitness = np.concatenate((fitness, offspring_fitness))\n            \n            indices = np.argsort(combined_fitness)[:self.pop_size]\n            population = combined_population[indices]\n            fitness = combined_fitness[indices]\n\n\n            # Update the best solution found so far\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17320774174385056, 0.2785912924318572, 0.3398915105965492, 0.4035494409302838, 0.27880149422498757, 0.393331102492546, 0.2790195084525049, 0.2947981369290731, 0.28080765911382133, 0.20644677507979237, 0.34735505191864835, 0.9977937923997016, 0.2864031056096744, 0.2851451896142192, 0.7063911004819466, 0.3429280111946911, 0.3022200983109984, 0.41834342280333303, 0.2002994814778627, 0.4862900808050419], "operator": "random_new", "theta_sampled": 0.06564797308374953, "reward": 0.09090023941704684, "generation": 1}, "task_prompt": ""}
{"id": "149fe6f3-bc38-4f07-b583-69788f76049f", "fitness": 0.25822734283385657, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with improved parameter adaptation, stagnation detection using multiple criteria and a more aggressive restart strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.9, stagnation_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = [F]  # Memory for F values\n        self.Cr_memory = [Cr]  # Memory for Cr values\n        self.memory_size = 5\n        self.stagnation_threshold = stagnation_threshold\n        self.num_restarts = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.min_successes = 5  # Minimum number of successful F/Cr values to consider for adaptation\n        self.stagnation_counter = 0\n        self.max_stagnation = 20 #Maximum allowed stagnation before restart\n        self.improvement_history = []\n        self.improvement_window = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        best_fitness_history = [self.f_opt]\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.population[i])\n                trial[crossover_mask] = mutant[crossover_mask]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    \n                    delta_f = self.fitness[i] - f_trial\n                    \n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.success_F.append(self.F)\n                        self.success_Cr.append(self.Cr)\n\n                if self.budget <= 0:\n                    break\n                    \n            best_fitness_history.append(self.f_opt)\n            \n            #Adapt F and CR using successful values\n            if len(self.success_F) >= self.min_successes:\n                self.F = np.median(self.success_F)\n                self.Cr = np.median(self.success_Cr)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n            self.success_F = []\n            self.success_Cr = []\n\n            # Update memory\n            self.F_memory.append(self.F)\n            self.Cr_memory.append(self.Cr)\n            if len(self.F_memory) > self.memory_size:\n                self.F_memory.pop(0)\n            if len(self.Cr_memory) > self.memory_size:\n                self.Cr_memory.pop(0)\n            \n            #Stagnation detection\n            improvement = abs(old_f_opt - self.f_opt)\n            self.improvement_history.append(improvement)\n            if len(self.improvement_history) > self.improvement_window:\n                self.improvement_history.pop(0)\n            \n            mean_improvement = np.mean(self.improvement_history)\n            \n            if improvement < self.stagnation_threshold or mean_improvement < self.stagnation_threshold:\n                self.stagnation_counter +=1\n            else:\n                self.stagnation_counter = 0\n            \n            #Restart mechanism: more aggressive\n            if self.stagnation_counter > self.max_stagnation:\n                self.num_restarts += 1\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0 #Reset stagnation\n                self.improvement_history = [] #Reset improvement history\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                \n                best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDE scored 0.258 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9879223c-b757-4525-99c8-19b30a1bab21"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with improved parameter adaptation, stagnation detection using multiple criteria and a more aggressive restart strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.9, stagnation_threshold=1e-6):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.Cr = Cr\n        self.F_memory = [F]  # Memory for F values\n        self.Cr_memory = [Cr]  # Memory for Cr values\n        self.memory_size = 5\n        self.stagnation_threshold = stagnation_threshold\n        self.num_restarts = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.min_successes = 5  # Minimum number of successful F/Cr values to consider for adaptation\n        self.stagnation_counter = 0\n        self.max_stagnation = 20 #Maximum allowed stagnation before restart\n        self.improvement_history = []\n        self.improvement_window = 10\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        best_fitness_history = [self.f_opt]\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.Cr\n                trial = np.copy(self.population[i])\n                trial[crossover_mask] = mutant[crossover_mask]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    \n                    delta_f = self.fitness[i] - f_trial\n                    \n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.success_F.append(self.F)\n                        self.success_Cr.append(self.Cr)\n\n                if self.budget <= 0:\n                    break\n                    \n            best_fitness_history.append(self.f_opt)\n            \n            #Adapt F and CR using successful values\n            if len(self.success_F) >= self.min_successes:\n                self.F = np.median(self.success_F)\n                self.Cr = np.median(self.success_Cr)\n            else:\n                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n                self.Cr = np.clip(np.random.normal(0.9, 0.2), 0.1, 1.0)\n            self.success_F = []\n            self.success_Cr = []\n\n            # Update memory\n            self.F_memory.append(self.F)\n            self.Cr_memory.append(self.Cr)\n            if len(self.F_memory) > self.memory_size:\n                self.F_memory.pop(0)\n            if len(self.Cr_memory) > self.memory_size:\n                self.Cr_memory.pop(0)\n            \n            #Stagnation detection\n            improvement = abs(old_f_opt - self.f_opt)\n            self.improvement_history.append(improvement)\n            if len(self.improvement_history) > self.improvement_window:\n                self.improvement_history.pop(0)\n            \n            mean_improvement = np.mean(self.improvement_history)\n            \n            if improvement < self.stagnation_threshold or mean_improvement < self.stagnation_threshold:\n                self.stagnation_counter +=1\n            else:\n                self.stagnation_counter = 0\n            \n            #Restart mechanism: more aggressive\n            if self.stagnation_counter > self.max_stagnation:\n                self.num_restarts += 1\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0 #Reset stagnation\n                self.improvement_history = [] #Reset improvement history\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n                \n                best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21745838699137443, 0.5572236415101952, 0], "operator": "mutation", "theta_sampled": 0.18981986484226, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "e460bb5f-d773-480a-92d2-f50170d7fd42", "fitness": 0.0, "name": "HybridDE_NM", "description": "A hybrid algorithm combining aspects of differential evolution and Nelder-Mead simplex, dynamically adapting the search based on success rates.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, de_pop_size=15, nm_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.de_pop_size = de_pop_size\n        self.nm_iters = nm_iters  # Number of Nelder-Mead iterations per DE individual\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        # Initialize Differential Evolution population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.de_pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals_used += self.de_pop_size\n\n        # Main loop\n        generation = 0\n        while evals_used < self.budget:\n            generation += 1\n            for i in range(self.de_pop_size):\n                # Differential Evolution mutation and crossover\n                idxs = np.random.choice(self.de_pop_size, 3, replace=False)\n                x_a, x_b, x_c = population[idxs]\n                mutant = population[i] + 0.5 * (x_b - x_c)  # DE/rand/1 mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n\n                crossover_mask = np.random.rand(self.dim) < 0.9  # Crossover rate 0.9\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n\n                # Nelder-Mead refinement\n                nm_result = minimize(func, trial_vector, method='Nelder-Mead', \n                                    options={'maxiter': self.nm_iters, 'maxfev': self.budget - evals_used})\n\n                trial_fitness = nm_result.fun #func(trial_vector)\n                trial_vector = nm_result.x\n\n                evals_used += nm_result.nfev #func.evaluations - evals_used\n\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = trial_vector\n\n\n            # Early stopping condition if no improvement for a while:\n            if generation > 50 and np.std(fitness) < 1e-8:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid algorithm combining aspects of differential evolution and Nelder-Mead simplex, dynamically adapting the search based on success rates.\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, de_pop_size=15, nm_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.de_pop_size = de_pop_size\n        self.nm_iters = nm_iters  # Number of Nelder-Mead iterations per DE individual\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        # Initialize Differential Evolution population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.de_pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals_used += self.de_pop_size\n\n        # Main loop\n        generation = 0\n        while evals_used < self.budget:\n            generation += 1\n            for i in range(self.de_pop_size):\n                # Differential Evolution mutation and crossover\n                idxs = np.random.choice(self.de_pop_size, 3, replace=False)\n                x_a, x_b, x_c = population[idxs]\n                mutant = population[i] + 0.5 * (x_b - x_c)  # DE/rand/1 mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n\n                crossover_mask = np.random.rand(self.dim) < 0.9  # Crossover rate 0.9\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n\n                # Nelder-Mead refinement\n                nm_result = minimize(func, trial_vector, method='Nelder-Mead', \n                                    options={'maxiter': self.nm_iters, 'maxfev': self.budget - evals_used})\n\n                trial_fitness = nm_result.fun #func(trial_vector)\n                trial_vector = nm_result.x\n\n                evals_used += nm_result.nfev #func.evaluations - evals_used\n\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = trial_vector\n\n\n            # Early stopping condition if no improvement for a while:\n            if generation > 50 and np.std(fitness) < 1e-8:\n                break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.09237666355735355, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "d63e1117-3197-4b00-8bee-4a1c723ac8e4", "fitness": 0.4599109140440924, "name": "HybridSwarmAdaptiveSearch", "description": "Combines Cooperative Swarm Elitist Learning with Adaptive Population Search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1,\n                 exploration_factor=0.5, exploitation_factor=0.1, adaptive_frequency = 5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.adaptive_frequency = adaptive_frequency #How often to perform adaptive search\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.eval_count = 0\n        self.adaptive_search_counter = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            self.fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.swarm[i].copy()\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def swarm_step(self, func):\n        # Update velocities and positions\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n\n        self.velocities = (self.inertia * self.velocities +\n                          self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                          self.social_coeff * r2 * (self.global_best_position - self.swarm))\n        \n        self.swarm = self.swarm + self.velocities\n\n        # Clip to bounds\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        # Evaluate new positions\n        new_fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            new_fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n\n        # Update personal bests\n        improvement = new_fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = new_fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        # Update global best\n        best_index_in_batch = np.argmin(new_fitness)\n\n        if new_fitness[best_index_in_batch] < self.global_best_fitness:\n            self.global_best_fitness = new_fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n            \n        # Elitist learning: Move some particles towards the elite\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n        \n        # Move non-elite particles closer to elite particles (exploration)\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i]) #Move towards an elite\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n    def adaptive_search(self, func):\n         for i in range(self.swarm_size):\n\n            # Select a random individual for differential mutation\n            j = np.random.randint(self.swarm_size)\n            while j == i:\n                j = np.random.randint(self.swarm_size)\n\n            # Select another random individual for differential mutation\n            k = np.random.randint(self.swarm_size)\n            while k == i or k == j:\n                k = np.random.randint(self.swarm_size)\n\n            # Exploration: Create a new candidate solution based on differential evolution with a larger step\n            exploration_candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n            exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n\n            # Exploitation: Create a new candidate solution based on small random perturbation around the current solution\n            exploitation_candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n            exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n\n            # Choose either exploration or exploitation candidate randomly\n            if np.random.rand() < 0.5:\n                candidate = exploration_candidate\n            else:\n                candidate = exploitation_candidate\n            \n            f_candidate = func(candidate)\n            self.eval_count += 1\n\n            if f_candidate < self.fitness[i]:\n                self.swarm[i] = candidate\n                self.fitness[i] = f_candidate\n                self.personal_best_positions[i] = candidate.copy()\n                self.personal_best_fitness[i] = f_candidate\n                if f_candidate < self.global_best_fitness:\n                    self.global_best_fitness = f_candidate\n                    self.global_best_position = candidate.copy()\n\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.swarm_step(func)\n            self.adaptive_search_counter += 1\n            if self.adaptive_search_counter % self.adaptive_frequency == 0:\n                self.adaptive_search(func)\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSwarmAdaptiveSearch scored 0.460 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07", "7dac6bda-068a-4f9a-8a96-579240ccebc4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Cooperative Swarm Elitist Learning with Adaptive Population Search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1,\n                 exploration_factor=0.5, exploitation_factor=0.1, adaptive_frequency = 5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.adaptive_frequency = adaptive_frequency #How often to perform adaptive search\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.eval_count = 0\n        self.adaptive_search_counter = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            self.fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.swarm[i].copy()\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def swarm_step(self, func):\n        # Update velocities and positions\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n\n        self.velocities = (self.inertia * self.velocities +\n                          self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                          self.social_coeff * r2 * (self.global_best_position - self.swarm))\n        \n        self.swarm = self.swarm + self.velocities\n\n        # Clip to bounds\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        # Evaluate new positions\n        new_fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            new_fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n\n        # Update personal bests\n        improvement = new_fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = new_fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        # Update global best\n        best_index_in_batch = np.argmin(new_fitness)\n\n        if new_fitness[best_index_in_batch] < self.global_best_fitness:\n            self.global_best_fitness = new_fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n            \n        # Elitist learning: Move some particles towards the elite\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n        \n        # Move non-elite particles closer to elite particles (exploration)\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i]) #Move towards an elite\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n    def adaptive_search(self, func):\n         for i in range(self.swarm_size):\n\n            # Select a random individual for differential mutation\n            j = np.random.randint(self.swarm_size)\n            while j == i:\n                j = np.random.randint(self.swarm_size)\n\n            # Select another random individual for differential mutation\n            k = np.random.randint(self.swarm_size)\n            while k == i or k == j:\n                k = np.random.randint(self.swarm_size)\n\n            # Exploration: Create a new candidate solution based on differential evolution with a larger step\n            exploration_candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n            exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n\n            # Exploitation: Create a new candidate solution based on small random perturbation around the current solution\n            exploitation_candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n            exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n\n            # Choose either exploration or exploitation candidate randomly\n            if np.random.rand() < 0.5:\n                candidate = exploration_candidate\n            else:\n                candidate = exploitation_candidate\n            \n            f_candidate = func(candidate)\n            self.eval_count += 1\n\n            if f_candidate < self.fitness[i]:\n                self.swarm[i] = candidate\n                self.fitness[i] = f_candidate\n                self.personal_best_positions[i] = candidate.copy()\n                self.personal_best_fitness[i] = f_candidate\n                if f_candidate < self.global_best_fitness:\n                    self.global_best_fitness = f_candidate\n                    self.global_best_position = candidate.copy()\n\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.swarm_step(func)\n            self.adaptive_search_counter += 1\n            if self.adaptive_search_counter % self.adaptive_frequency == 0:\n                self.adaptive_search(func)\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.16120688368639835, 0.16856646731370584, 0.8635452288913206, 0.18003803301318988, 0.2968026426559126, 0.2910236085450296, 0.3457835151630806, 0.5189694595120886, 0.8945611678884307, 0.8295740188339397, 0.2337391964762654, 0.9990034449235463, 0.27826737181533434, 0.2523143300691688, 0.5889916900172717, 0.3623024635515223, 0.3107384291655684, 0.9256008279347717, 0.17379748182405508, 0.523392019601248], "operator": "crossover", "theta_sampled": 0.057433845141489984, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "db0e714a-fd5e-4126-8460-d67e0d35db29", "fitness": 0.0, "name": "HybridSwarmAdaptiveSearch", "description": "Combines Cooperative Swarm Elitist Learning with Adaptive Population Search, dynamically adjusting exploration/exploitation balance based on swarm diversity and global best improvement rate.", "code": "import numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1,\n                 exploration_factor=0.5, exploitation_factor=0.1, diversity_threshold=0.1, improvement_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.diversity_threshold = diversity_threshold\n        self.improvement_threshold = improvement_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = None\n        self.last_global_best = np.inf\n\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.eval_count += self.swarm_size\n\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.swarm[global_best_index].copy()\n        self.global_best_fitness = self.fitness[global_best_index].copy()\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the swarm.\"\"\"\n        centroid = np.mean(self.swarm, axis=0)\n        distances = np.linalg.norm(self.swarm - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def should_increase_exploration(self):\n         \"\"\"Decides whether to increase exploration based on swarm diversity and global best improvement.\"\"\"\n         diversity = self.calculate_diversity()\n         improvement = (self.last_global_best - self.global_best_fitness) / self.last_global_best if self.last_global_best != 0 else 0\n\n         if diversity < self.diversity_threshold or improvement < self.improvement_threshold:\n             return True\n         return False\n    \n    def evolve(self, func):\n        # Update velocities and positions (PSO core)\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n\n        self.velocities = (self.inertia * self.velocities +\n                          self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                          self.social_coeff * r2 * (self.global_best_position - self.swarm))\n            \n        self.swarm = self.swarm + self.velocities\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        # Adaptive Exploration/Exploitation\n        if self.should_increase_exploration():\n            # Differential Evolution inspired exploration\n            for i in range(self.swarm_size):\n                j = np.random.randint(self.swarm_size)\n                while j == i:\n                    j = np.random.randint(self.swarm_size)\n                k = np.random.randint(self.swarm_size)\n                while k == i or k == j:\n                    k = np.random.randint(self.swarm_size)\n                \n                candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                f_candidate = func(candidate)\n                self.eval_count +=1\n\n                if f_candidate < self.fitness[i]:\n                    self.swarm[i] = candidate\n                    self.fitness[i] = f_candidate\n        else:\n            # Local exploitation around current positions\n            for i in range(self.swarm_size):\n                candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                f_candidate = func(candidate)\n                self.eval_count += 1\n                if f_candidate < self.fitness[i]:\n                    self.swarm[i] = candidate\n                    self.fitness[i] = f_candidate\n                    \n\n        # Evaluate new positions using the function\n        new_fitness = np.array([func(x) if self.eval_count <= self.budget else np.inf for x in self.swarm])\n        eval_count = np.sum(new_fitness != np.inf)\n        self.eval_count += eval_count\n\n        # Update personal bests\n        improvement = new_fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = new_fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        # Update global best\n        best_index_in_batch = np.argmin(new_fitness)\n\n        if new_fitness[best_index_in_batch] < self.global_best_fitness:\n            self.last_global_best = self.global_best_fitness\n            self.global_best_fitness = new_fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n            self.f_opt = self.global_best_fitness\n            self.x_opt = self.global_best_position\n\n        # Elitist learning\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i])\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridSwarmAdaptiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07", "7dac6bda-068a-4f9a-8a96-579240ccebc4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Cooperative Swarm Elitist Learning with Adaptive Population Search, dynamically adjusting exploration/exploitation balance based on swarm diversity and global best improvement rate.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1,\n                 exploration_factor=0.5, exploitation_factor=0.1, diversity_threshold=0.1, improvement_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.diversity_threshold = diversity_threshold\n        self.improvement_threshold = improvement_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.swarm = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = None\n        self.last_global_best = np.inf\n\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.array([func(x) for x in self.swarm])\n        self.eval_count += self.swarm_size\n\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.swarm[global_best_index].copy()\n        self.global_best_fitness = self.fitness[global_best_index].copy()\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the swarm.\"\"\"\n        centroid = np.mean(self.swarm, axis=0)\n        distances = np.linalg.norm(self.swarm - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def should_increase_exploration(self):\n         \"\"\"Decides whether to increase exploration based on swarm diversity and global best improvement.\"\"\"\n         diversity = self.calculate_diversity()\n         improvement = (self.last_global_best - self.global_best_fitness) / self.last_global_best if self.last_global_best != 0 else 0\n\n         if diversity < self.diversity_threshold or improvement < self.improvement_threshold:\n             return True\n         return False\n    \n    def evolve(self, func):\n        # Update velocities and positions (PSO core)\n        r1 = np.random.rand(self.swarm_size, self.dim)\n        r2 = np.random.rand(self.swarm_size, self.dim)\n\n        self.velocities = (self.inertia * self.velocities +\n                          self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                          self.social_coeff * r2 * (self.global_best_position - self.swarm))\n            \n        self.swarm = self.swarm + self.velocities\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        # Adaptive Exploration/Exploitation\n        if self.should_increase_exploration():\n            # Differential Evolution inspired exploration\n            for i in range(self.swarm_size):\n                j = np.random.randint(self.swarm_size)\n                while j == i:\n                    j = np.random.randint(self.swarm_size)\n                k = np.random.randint(self.swarm_size)\n                while k == i or k == j:\n                    k = np.random.randint(self.swarm_size)\n                \n                candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                f_candidate = func(candidate)\n                self.eval_count +=1\n\n                if f_candidate < self.fitness[i]:\n                    self.swarm[i] = candidate\n                    self.fitness[i] = f_candidate\n        else:\n            # Local exploitation around current positions\n            for i in range(self.swarm_size):\n                candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                \n                f_candidate = func(candidate)\n                self.eval_count += 1\n                if f_candidate < self.fitness[i]:\n                    self.swarm[i] = candidate\n                    self.fitness[i] = f_candidate\n                    \n\n        # Evaluate new positions using the function\n        new_fitness = np.array([func(x) if self.eval_count <= self.budget else np.inf for x in self.swarm])\n        eval_count = np.sum(new_fitness != np.inf)\n        self.eval_count += eval_count\n\n        # Update personal bests\n        improvement = new_fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = new_fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        # Update global best\n        best_index_in_batch = np.argmin(new_fitness)\n\n        if new_fitness[best_index_in_batch] < self.global_best_fitness:\n            self.last_global_best = self.global_best_fitness\n            self.global_best_fitness = new_fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n            self.f_opt = self.global_best_fitness\n            self.x_opt = self.global_best_position\n\n        # Elitist learning\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i])\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n\n\n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.15792360303157765, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "635066fc-449f-48af-a2d9-ae238a92d293", "fitness": 0.0, "name": "HybridSwarmAdaptiveSearch", "description": "A hybrid approach combining Cooperative Swarm Elitist Learning's particle swarm optimization with Adaptive Population Search's adaptive exploration/exploitation strategy for enhanced search diversity and convergence.", "code": "import numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, exploration_factor=0.3, exploitation_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            self.fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.swarm[i]\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.swarm[self.global_best_index].copy()\n        self.global_best_fitness = self.fitness[self.global_best_index].copy()\n\n    def evolve(self, func):\n        for i in range(self.swarm_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Standard PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            self.velocities[i] = (self.inertia * self.velocities[i] +\n                                  self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                  self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n            \n            self.swarm[i] = self.swarm[i] + self.velocities[i]\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Exploration/Exploitation\n            if np.random.rand() < 0.5:\n                # Exploration: Differential Evolution-inspired exploration\n                j = np.random.randint(self.swarm_size)\n                while j == i:\n                    j = np.random.randint(self.swarm_size)\n                k = np.random.randint(self.swarm_size)\n                while k == i or k == j:\n                    k = np.random.randint(self.swarm_size)\n                candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            else:\n                # Exploitation: Small random perturbation\n                candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n            f_candidate = func(candidate)\n            self.eval_count += 1\n\n            if f_candidate < self.fitness[i]:\n                self.swarm[i] = candidate\n                self.fitness[i] = f_candidate\n                if f_candidate < self.personal_best_fitness[i]:\n                    self.personal_best_positions[i] = candidate\n                    self.personal_best_fitness[i] = f_candidate\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n                    self.global_best_position = candidate.copy()\n                    self.global_best_fitness = f_candidate.copy()\n\n        #Elitist Learning: Move some particles towards the elite\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i])\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n            \n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: 'float' object has no attribute 'copy'", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07", "7dac6bda-068a-4f9a-8a96-579240ccebc4"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid approach combining Cooperative Swarm Elitist Learning's particle swarm optimization with Adaptive Population Search's adaptive exploration/exploitation strategy for enhanced search diversity and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSwarmAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, exploration_factor=0.3, exploitation_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros_like(self.swarm)\n        self.fitness = np.zeros(self.swarm_size)\n        for i in range(self.swarm_size):\n            self.fitness[i] = func(self.swarm[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.swarm[i]\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.swarm[self.global_best_index].copy()\n        self.global_best_fitness = self.fitness[self.global_best_index].copy()\n\n    def evolve(self, func):\n        for i in range(self.swarm_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Standard PSO update\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            self.velocities[i] = (self.inertia * self.velocities[i] +\n                                  self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.swarm[i]) +\n                                  self.social_coeff * r2 * (self.global_best_position - self.swarm[i]))\n            \n            self.swarm[i] = self.swarm[i] + self.velocities[i]\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Exploration/Exploitation\n            if np.random.rand() < 0.5:\n                # Exploration: Differential Evolution-inspired exploration\n                j = np.random.randint(self.swarm_size)\n                while j == i:\n                    j = np.random.randint(self.swarm_size)\n                k = np.random.randint(self.swarm_size)\n                while k == i or k == j:\n                    k = np.random.randint(self.swarm_size)\n                candidate = self.swarm[i] + self.exploration_factor * (self.swarm[j] - self.swarm[k])\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            else:\n                # Exploitation: Small random perturbation\n                candidate = self.swarm[i] + self.exploitation_factor * np.random.uniform(-1, 1, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n            f_candidate = func(candidate)\n            self.eval_count += 1\n\n            if f_candidate < self.fitness[i]:\n                self.swarm[i] = candidate\n                self.fitness[i] = f_candidate\n                if f_candidate < self.personal_best_fitness[i]:\n                    self.personal_best_positions[i] = candidate\n                    self.personal_best_fitness[i] = f_candidate\n                if f_candidate < self.f_opt:\n                    self.f_opt = f_candidate\n                    self.x_opt = candidate\n                    self.global_best_position = candidate.copy()\n                    self.global_best_fitness = f_candidate.copy()\n\n        #Elitist Learning: Move some particles towards the elite\n        num_elites = int(self.elite_proportion * self.swarm_size)\n        elite_indices = np.argsort(self.personal_best_fitness)[:num_elites]\n\n        non_elite_indices = np.argsort(self.personal_best_fitness)[num_elites:]\n        for i in non_elite_indices:\n            elite_idx = np.random.choice(elite_indices)\n            self.swarm[i] = self.swarm[i] + 0.1 * (self.personal_best_positions[elite_idx] - self.swarm[i])\n            self.swarm[i] = np.clip(self.swarm[i], func.bounds.lb, func.bounds.ub)\n            \n    def __call__(self, func):\n        self.initialize_swarm(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.3201292480193934, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "bf86f957-245b-4297-9044-93b8c29bdc2d", "fitness": 0.24000960662338425, "name": "AdaptiveNeighborhoodSearch", "description": "A population-based algorithm that iteratively adjusts individual positions based on a combination of global best, local neighborhood best, and random exploration, with an adaptive step size.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.step_size = 0.1  # Initial step size\n        self.step_decay = 0.995 # Decay step size over time.\n        self.min_step_size = 0.001\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Define neighborhood (wrap around if necessary)\n                neighborhood_indices = [(i + j) % self.pop_size for j in range(-self.neighborhood_size // 2, self.neighborhood_size // 2 + 1)]\n                neighborhood_fitness = fitness[neighborhood_indices]\n                local_best_index = neighborhood_indices[np.argmin(neighborhood_fitness)]\n\n                # Calculate movement vector\n                to_global_best = self.x_opt - population[i]\n                to_local_best = population[local_best_index] - population[i]\n                random_direction = np.random.uniform(-1, 1, size=self.dim)\n\n                # Combine influences\n                movement = (0.4 * to_global_best + 0.4 * to_local_best + 0.2 * random_direction) * self.step_size\n                \n                # Ensure the step is inside the bounds by clipping\n                new_position = population[i] + movement\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            #Adapt step size\n            self.step_size *= self.step_decay\n            self.step_size = max(self.step_size, self.min_step_size)\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveNeighborhoodSearch scored 0.240 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that iteratively adjusts individual positions based on a combination of global best, local neighborhood best, and random exploration, with an adaptive step size.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.neighborhood_size = neighborhood_size\n        self.step_size = 0.1  # Initial step size\n        self.step_decay = 0.995 # Decay step size over time.\n        self.min_step_size = 0.001\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Define neighborhood (wrap around if necessary)\n                neighborhood_indices = [(i + j) % self.pop_size for j in range(-self.neighborhood_size // 2, self.neighborhood_size // 2 + 1)]\n                neighborhood_fitness = fitness[neighborhood_indices]\n                local_best_index = neighborhood_indices[np.argmin(neighborhood_fitness)]\n\n                # Calculate movement vector\n                to_global_best = self.x_opt - population[i]\n                to_local_best = population[local_best_index] - population[i]\n                random_direction = np.random.uniform(-1, 1, size=self.dim)\n\n                # Combine influences\n                movement = (0.4 * to_global_best + 0.4 * to_local_best + 0.2 * random_direction) * self.step_size\n                \n                # Ensure the step is inside the bounds by clipping\n                new_position = population[i] + movement\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            #Adapt step size\n            self.step_size *= self.step_decay\n            self.step_size = max(self.step_size, self.min_step_size)\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.16006872410615602, 0.18826680343232605, 0.2840917393377639, 0.1544317602189389, 0.1407077075104054, 0.20538675406746731, 0.20822549953788239, 0.17223724217160363, 0.1885598867197804, 0.13533019113794875, 0.1789282309086746, 0.9986732057036682, 0.25470207451695737, 0.13158255548621256, 0.16831621501132032, 0.23166807477203333, 0.23901468618316546, 0.19121658551632326, 0.14624672235983416, 0.4225374737692231], "operator": "random_new", "theta_sampled": 0.15583009619271646, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "fitness": 0.6635783330750813, "name": "CMAES_OAx", "description": "Adaptive Evolutionary Strategy with covariance matrix adaptation and orthogonal crossover for improved exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES_OAx:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CMAES_OAx scored 0.664 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["be0a8c6b-b6c9-4cf8-a511-6ca7fc147284"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Evolutionary Strategy with covariance matrix adaptation and orthogonal crossover for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES_OAx:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.263296877848039, 0.4106444563608399, 0.9430599871944375, 0.17292613379644006, 0.9516115224193774, 0.9590093214531553, 0.3771645743974267, 0.9400656567461136, 0.952299411254938, 0.16732332573356112, 0.9681974952118724, 0.9950977481365042, 0.2549891598506855, 0.9486487606245241, 0.9657540494710343, 0.9294271516495244, 0.4249250335524515, 0.9660238725568281, 0.17573327236791814, 0.5053688508759547], "operator": "mutation", "theta_sampled": 0.11598900677709481, "reward": 0.16289380794293506, "generation": 2}, "task_prompt": ""}
{"id": "4d23b3ee-7bc6-4b92-8e60-3f40393dbc89", "fitness": 0.0, "name": "HybridCooperativeAdaptiveSearch", "description": "Hybrid algorithm combining Cooperative Swarm with Elitist Learning and Adaptive Population Search's exploration/exploitation balance for enhanced global search.", "code": "import numpy as np\n\nclass HybridCooperativeAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, exploration_factor=0.3, exploitation_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Exploration and Exploitation for each particle\n            for i in range(self.swarm_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Exploration: Create a new candidate solution\n                exploration_candidate = swarm[i] + self.exploration_factor * np.random.uniform(func.bounds.lb - swarm[i], func.bounds.ub - swarm[i], size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n                # Exploitation: Create a new candidate solution\n                exploitation_candidate = swarm[i] + self.exploitation_factor * np.random.normal(0, 1, size=self.dim)\n                exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate both candidates\n                f_exploration = func(exploration_candidate)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                \n                f_exploitation = func(exploitation_candidate)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                    \n                # Choose the better candidate\n                if f_exploration < f_exploitation:\n                    candidate = exploration_candidate\n                    f_candidate = f_exploration\n                else:\n                    candidate = exploitation_candidate\n                    f_candidate = f_exploitation\n\n                # Update swarm and personal best\n                if f_candidate < fitness[i]:\n                    swarm[i] = candidate\n                    fitness[i] = f_candidate\n                    if f_candidate < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_candidate\n                        personal_best_positions[i] = candidate.copy()\n                \n                # Update global best\n                if f_candidate < global_best_fitness:\n                    global_best_fitness = f_candidate\n                    global_best_position = candidate.copy()\n                    self.f_opt = global_best_fitness\n                    self.x_opt = global_best_position\n\n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i])\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub)\n                \n                f_temp = func(swarm[i])\n                self.eval_count += 1\n                \n                if f_temp < fitness[i]:\n                    fitness[i] = f_temp\n                    if f_temp < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_temp\n                        personal_best_positions[i] = swarm[i].copy()\n                    if f_temp < global_best_fitness:\n                        global_best_fitness = f_temp\n                        global_best_position = swarm[i].copy()\n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridCooperativeAdaptiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07", "7dac6bda-068a-4f9a-8a96-579240ccebc4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Hybrid algorithm combining Cooperative Swarm with Elitist Learning and Adaptive Population Search's exploration/exploitation balance for enhanced global search.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCooperativeAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, swarm_size=30, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, exploration_factor=0.3, exploitation_factor=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.exploration_factor = exploration_factor\n        self.exploitation_factor = exploitation_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.eval_count += self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Exploration and Exploitation for each particle\n            for i in range(self.swarm_size):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Exploration: Create a new candidate solution\n                exploration_candidate = swarm[i] + self.exploration_factor * np.random.uniform(func.bounds.lb - swarm[i], func.bounds.ub - swarm[i], size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, func.bounds.lb, func.bounds.ub)\n\n                # Exploitation: Create a new candidate solution\n                exploitation_candidate = swarm[i] + self.exploitation_factor * np.random.normal(0, 1, size=self.dim)\n                exploitation_candidate = np.clip(exploitation_candidate, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate both candidates\n                f_exploration = func(exploration_candidate)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                \n                f_exploitation = func(exploitation_candidate)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                    \n                # Choose the better candidate\n                if f_exploration < f_exploitation:\n                    candidate = exploration_candidate\n                    f_candidate = f_exploration\n                else:\n                    candidate = exploitation_candidate\n                    f_candidate = f_exploitation\n\n                # Update swarm and personal best\n                if f_candidate < fitness[i]:\n                    swarm[i] = candidate\n                    fitness[i] = f_candidate\n                    if f_candidate < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_candidate\n                        personal_best_positions[i] = candidate.copy()\n                \n                # Update global best\n                if f_candidate < global_best_fitness:\n                    global_best_fitness = f_candidate\n                    global_best_position = candidate.copy()\n                    self.f_opt = global_best_fitness\n                    self.x_opt = global_best_position\n\n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i])\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub)\n                \n                f_temp = func(swarm[i])\n                self.eval_count += 1\n                \n                if f_temp < fitness[i]:\n                    fitness[i] = f_temp\n                    if f_temp < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_temp\n                        personal_best_positions[i] = swarm[i].copy()\n                    if f_temp < global_best_fitness:\n                        global_best_fitness = f_temp\n                        global_best_position = swarm[i].copy()\n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.2557646860683257, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "394201bd-9623-4f78-ae2a-ed331d5282e9", "fitness": 0.6014508813241657, "name": "AdaptiveCooperativeSwarm", "description": "Adaptive Cooperative Swarm with Neighborhood Best Influence and Dynamic Inertia, focusing on balancing exploration and exploitation by adaptively adjusting inertia and incorporating neighborhood best information.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / self.budget) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCooperativeSwarm scored 0.601 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with Neighborhood Best Influence and Dynamic Inertia, focusing on balancing exploration and exploitation by adaptively adjusting inertia and incorporating neighborhood best information.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / self.budget) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.1831828584484324, 0.33450133520573777, 0.7817373517785763, 0.9040222610620816, 0.8315010259627789, 0.9019016421564787, 0.34137376032747735, 0.6197099883123269, 0.720829924431831, 0.22616010248826368, 0.7636324776757304, 0.999741468190153, 0.26477951622588325, 0.5339108650998508, 0.7389618324514858, 0.9029138920422324, 0.3364109939744542, 0.9018006223496462, 0.2345699591846444, 0.5073757491152484], "operator": "mutation", "theta_sampled": 0.0903455939866938, "reward": 0.10076635619201946, "generation": 2}, "task_prompt": ""}
{"id": "a058cb10-aaa2-4c21-9f99-61931c82be08", "fitness": 0.5707152385741654, "name": "AdaptiveCooperativeSwarmEnhanced", "description": "Adaptive Cooperative Swarm with Velocity Scaling and Exploration Enhancement, dynamically adjusting particle velocity and introducing a random walk to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarmEnhanced:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, velocity_scale=0.1, exploration_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.velocity_scale = velocity_scale\n        self.exploration_prob = exploration_prob  # Probability of random walk\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            # Adaptive Inertia Weight\n            inertia = self.inertia - (self.inertia * iteration) / (self.budget / self.swarm_size + iteration)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            # Scale velocities to prevent premature convergence\n            velocities = np.clip(velocities, -self.velocity_scale * (func.bounds.ub - func.bounds.lb), self.velocity_scale * (func.bounds.ub - func.bounds.lb))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Exploration: Random Walk\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.exploration_prob:\n                    swarm[i] = swarm[i] + np.random.uniform(-0.1, 0.1, size=self.dim) * (func.bounds.ub - func.bounds.lb)\n                    swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCooperativeSwarmEnhanced scored 0.571 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with Velocity Scaling and Exploration Enhancement, dynamically adjusting particle velocity and introducing a random walk to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarmEnhanced:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, velocity_scale=0.1, exploration_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.velocity_scale = velocity_scale\n        self.exploration_prob = exploration_prob  # Probability of random walk\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            # Adaptive Inertia Weight\n            inertia = self.inertia - (self.inertia * iteration) / (self.budget / self.swarm_size + iteration)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            # Scale velocities to prevent premature convergence\n            velocities = np.clip(velocities, -self.velocity_scale * (func.bounds.ub - func.bounds.lb), self.velocity_scale * (func.bounds.ub - func.bounds.lb))\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Exploration: Random Walk\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.exploration_prob:\n                    swarm[i] = swarm[i] + np.random.uniform(-0.1, 0.1, size=self.dim) * (func.bounds.ub - func.bounds.lb)\n                    swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.14172856682253532, 0.17634446720011643, 0.791592427274409, 0.17246743615642646, 0.8991911015332806, 0.9096648066154176, 0.339799243437523, 0.6538667121035298, 0.8266851456909012, 0.32620189533276645, 0.9334772390408583, 0.9969067431237344, 0.2714202679123179, 0.4478610778100808, 0.5861626301501529, 0.8620151799694894, 0.3629775365266532, 0.9310576823882382, 0.2849772580939123, 0.4999073543009638], "operator": "mutation", "theta_sampled": 0.0900881042306537, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "5153ed8e-1255-4646-8cd0-923827138465", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "Population-based algorithm with adaptive mutation and crossover rates based on population diversity, combined with a local search to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        for i in range(self.budget // self.pop_size):\n            # Adaptive mutation and crossover rates\n            diversity = np.std(self.population)\n            mutation_rate = 0.5 + 0.5 * np.exp(-diversity)\n            crossover_rate = 0.1 + 0.8 * np.exp(-diversity)\n\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Differential evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Mutation\n                mutated = self.population[j] + mutation_rate * (x_r1 - x_r2)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < crossover_rate\n                trial_vector = np.where(crossover_mask, mutated, self.population[j])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f = func(trial_vector)\n                \n                if self.budget > 0: # Ensure we don't exceed the budget\n                  self.budget -= 1\n                else:\n                  break\n\n                # Selection\n                if f < self.fitness[j]:\n                    new_population[j] = trial_vector\n                    new_fitness[j] = f\n                else:\n                    f = self.fitness[j] # Keep the old fitness\n\n                # Update optimal solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_population[j]\n\n            self.population = new_population\n            self.fitness = new_fitness\n        \n        # Local search refinement on the best solution\n        if self.x_opt is not None:\n            x_local = self.x_opt.copy()\n            f_local = self.f_opt\n            \n            for _ in range(self.local_search_iterations):\n                for k in range(self.dim):\n                    # Perturb each dimension slightly\n                    x_perturbed = x_local.copy()\n                    perturbation = np.random.uniform(-0.1, 0.1)  # Small perturbation\n                    x_perturbed[k] += perturbation\n                    x_perturbed[k] = np.clip(x_perturbed[k], func.bounds.lb, func.bounds.ub)\n                    \n                    f_perturbed = func(x_perturbed)\n\n                    if self.budget > 0: # Ensure we don't exceed the budget\n                      self.budget -= 1\n                    else:\n                      break\n                    \n                    if f_perturbed < f_local:\n                        x_local = x_perturbed\n                        f_local = f_perturbed\n                        self.x_opt = x_perturbed\n                        self.f_opt = f_perturbed\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive mutation and crossover rates based on population diversity, combined with a local search to refine promising solutions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        for i in range(self.budget // self.pop_size):\n            # Adaptive mutation and crossover rates\n            diversity = np.std(self.population)\n            mutation_rate = 0.5 + 0.5 * np.exp(-diversity)\n            crossover_rate = 0.1 + 0.8 * np.exp(-diversity)\n\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n\n            for j in range(self.pop_size):\n                # Differential evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                # Mutation\n                mutated = self.population[j] + mutation_rate * (x_r1 - x_r2)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < crossover_rate\n                trial_vector = np.where(crossover_mask, mutated, self.population[j])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluation\n                f = func(trial_vector)\n                \n                if self.budget > 0: # Ensure we don't exceed the budget\n                  self.budget -= 1\n                else:\n                  break\n\n                # Selection\n                if f < self.fitness[j]:\n                    new_population[j] = trial_vector\n                    new_fitness[j] = f\n                else:\n                    f = self.fitness[j] # Keep the old fitness\n\n                # Update optimal solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_population[j]\n\n            self.population = new_population\n            self.fitness = new_fitness\n        \n        # Local search refinement on the best solution\n        if self.x_opt is not None:\n            x_local = self.x_opt.copy()\n            f_local = self.f_opt\n            \n            for _ in range(self.local_search_iterations):\n                for k in range(self.dim):\n                    # Perturb each dimension slightly\n                    x_perturbed = x_local.copy()\n                    perturbation = np.random.uniform(-0.1, 0.1)  # Small perturbation\n                    x_perturbed[k] += perturbation\n                    x_perturbed[k] = np.clip(x_perturbed[k], func.bounds.lb, func.bounds.ub)\n                    \n                    f_perturbed = func(x_perturbed)\n\n                    if self.budget > 0: # Ensure we don't exceed the budget\n                      self.budget -= 1\n                    else:\n                      break\n                    \n                    if f_perturbed < f_local:\n                        x_local = x_perturbed\n                        f_local = f_perturbed\n                        self.x_opt = x_perturbed\n                        self.f_opt = f_perturbed\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.13332730449077132, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "6ef34add-92f9-4a6f-af51-ce8fb7e59059", "fitness": 0.1775088811352516, "name": "AdaptiveConcentratedSearch", "description": "A population-based algorithm that adapts both its search range and step size based on the success rate of individuals in finding improvements, focusing on concentrated searches around promising regions.", "code": "import numpy as np\n\nclass AdaptiveConcentratedSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n        \n        success_rate = 0.5  #Initial success rate\n\n        while evals < self.budget:\n            # Generate offspring by adding noise to each individual\n            offspring = population + np.random.normal(0, self.step_size, size=(self.pop_size, self.dim))\n\n            # Clip offspring to stay within bounds\n            offspring = np.clip(offspring, self.lb, self.ub)\n            \n            offspring_fitness = np.array([func(x) for x in offspring])\n            evals += self.pop_size\n            \n            # Selection: Replace parents with better offspring\n            improvement_count = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i].copy()\n                    improvement_count += 1\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx].copy()\n            \n            # Adapt step size based on success rate\n            success_rate = improvement_count / self.pop_size\n            if success_rate > 0.3:\n                self.step_size *= 1.1  # Increase step size if doing well\n            else:\n                self.step_size *= 0.9  # Decrease step size if not improving\n\n            # Adapt search range towards the best solution: focus the search\n            mean_position = np.mean(population, axis=0)\n            range_adaptation_factor = 0.1 # how much to shrink the search space\n            self.lb = self.x_opt - range_adaptation_factor * np.abs(self.x_opt - mean_position)\n            self.ub = self.x_opt + range_adaptation_factor * np.abs(self.x_opt - mean_position)\n\n            # Ensure search range stays within the global bounds\n            self.lb = np.maximum(self.lb, -5.0)\n            self.ub = np.minimum(self.ub, 5.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveConcentratedSearch scored 0.178 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adapts both its search range and step size based on the success rate of individuals in finding improvements, focusing on concentrated searches around promising regions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveConcentratedSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n        \n        success_rate = 0.5  #Initial success rate\n\n        while evals < self.budget:\n            # Generate offspring by adding noise to each individual\n            offspring = population + np.random.normal(0, self.step_size, size=(self.pop_size, self.dim))\n\n            # Clip offspring to stay within bounds\n            offspring = np.clip(offspring, self.lb, self.ub)\n            \n            offspring_fitness = np.array([func(x) for x in offspring])\n            evals += self.pop_size\n            \n            # Selection: Replace parents with better offspring\n            improvement_count = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i].copy()\n                    improvement_count += 1\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx].copy()\n            \n            # Adapt step size based on success rate\n            success_rate = improvement_count / self.pop_size\n            if success_rate > 0.3:\n                self.step_size *= 1.1  # Increase step size if doing well\n            else:\n                self.step_size *= 0.9  # Decrease step size if not improving\n\n            # Adapt search range towards the best solution: focus the search\n            mean_position = np.mean(population, axis=0)\n            range_adaptation_factor = 0.1 # how much to shrink the search space\n            self.lb = self.x_opt - range_adaptation_factor * np.abs(self.x_opt - mean_position)\n            self.ub = self.x_opt + range_adaptation_factor * np.abs(self.x_opt - mean_position)\n\n            # Ensure search range stays within the global bounds\n            self.lb = np.maximum(self.lb, -5.0)\n            self.ub = np.minimum(self.ub, 5.0)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10466834930136593, 0.15866676928510393, 0.25238792363194973, 0.19441566709473834, 0.1474321269647646, 0.13623778813923804, 0.1598100014675614, 0.12753006727218763, 0.16096385625865894, 0.12635427111530995, 0.15777421135477798, 0.1881698206629121, 0.2285433859138789, 0.14826355971560057, 0.12556204738150756, 0.22167422583813867, 0.18392361063520024, 0.16159917101876764, 0.12535371839979415, 0.44084705125357515], "operator": "random_new", "theta_sampled": 0.0434866248291275, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "7ebdcd3d-beb9-4b83-987b-4e1abe04ada9", "fitness": 0.3066678547008656, "name": "AdaptiveCooperativeSwarmAging", "description": "Adaptive Cooperative Swarm with Aging and Dynamic Inertia, encouraging exploration in early stages and exploitation later by dynamically adjusting inertia and using particle age to influence movement.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarmAging:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.2,\n                 cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, aging_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.aging_rate = aging_rate\n        self.ages = np.zeros(self.swarm_size)\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Dynamic Inertia: Linearly decrease inertia over time\n            remaining_ratio = self.budget / 10000  # Normalized remaining budget\n            inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * remaining_ratio\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Aging-based Exploration: Older particles explore more\n            age_factor = 1 + self.ages * self.aging_rate  # Older -> larger factor\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm)) * age_factor[:, None]\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n                self.ages[:] = 0  # Reset ages upon global best improvement\n            else:\n                self.ages += 1  # Increment ages\n\n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCooperativeSwarmAging scored 0.307 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with Aging and Dynamic Inertia, encouraging exploration in early stages and exploitation later by dynamically adjusting inertia and using particle age to influence movement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarmAging:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.2,\n                 cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, aging_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.aging_rate = aging_rate\n        self.ages = np.zeros(self.swarm_size)\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Dynamic Inertia: Linearly decrease inertia over time\n            remaining_ratio = self.budget / 10000  # Normalized remaining budget\n            inertia = self.inertia_min + (self.inertia_max - self.inertia_min) * remaining_ratio\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Aging-based Exploration: Older particles explore more\n            age_factor = 1 + self.ages * self.aging_rate  # Older -> larger factor\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm)) * age_factor[:, None]\n            \n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n                self.ages[:] = 0  # Reset ages upon global best improvement\n            else:\n                self.ages += 1  # Increment ages\n\n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n            for i in non_elite_indices:\n                elite_idx = np.random.choice(elite_indices)\n                swarm[i] = swarm[i] + 0.1 * (personal_best_positions[elite_idx] - swarm[i]) #Move towards an elite\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.11649548417749356, 0.15775549985125037, 0.2865558249505793, 0.22653018022818128, 0.23633869768436178, 0.24364758074714055, 0.2584224258883293, 0.29210570550091386, 0.25478096918020887, 0.1867002336996728, 0.27654332874232135, 0.9958514778289661, 0.25247737734003073, 0.22803485135568324, 0.6460280436128815, 0.3282334224074681, 0.2623840843625078, 0.2851748364433965, 0.15238487130299194, 0.4469121987129324], "operator": "mutation", "theta_sampled": 0.11855244508619393, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "f41fb13d-16f3-472d-9477-5b1076c40fea", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "CMA-ES with adaptive population size, active covariance matrix update and mirrored sampling for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, active_update=True, mirrored_sampling=True):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.active_update = active_update  # Use active covariance update\n        self.mirrored_sampling = mirrored_sampling\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.min_pop_size = 4 + int(3 * np.log(self.dim))\n        self.max_pop_size = 2 * (4 + int(3 * np.log(self.dim)))\n\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        evals = 0\n\n        while self.budget - evals > 0:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n\n            if self.mirrored_sampling:\n                z = np.vstack((z, -z))\n            \n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            evals += len(x)\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            \n            if self.mirrored_sampling:\n                indices = indices[:self.pop_size]  # Only select the best half\n            \n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            if self.active_update:\n                # Active covariance update\n                neg_indices = indices[self.mu:self.pop_size]\n                z_neg = z[neg_indices]\n                weights_neg = min(0.1, self.mu / self.pop_size) * np.ones(len(z_neg)) / len(z_neg)\n                C -= self.ccovmu * np.sum(weights_neg.reshape(-1, 1, 1) * (z_neg[:, :, np.newaxis] @ z_neg[:, np.newaxis, :]), axis=0)\n                \n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adjust population size\n            if evals > self.budget * 0.75 and self.pop_size > self.min_pop_size:\n                self.pop_size = max(self.min_pop_size, self.pop_size // 2)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            elif self.sigma < 1e-6 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.max_pop_size, self.pop_size * 2)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85"], "operator": "mutation", "metadata": {"llm_response": "# Description: CMA-ES with adaptive population size, active covariance matrix update and mirrored sampling for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, active_update=True, mirrored_sampling=True):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.active_update = active_update  # Use active covariance update\n        self.mirrored_sampling = mirrored_sampling\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        self.min_pop_size = 4 + int(3 * np.log(self.dim))\n        self.max_pop_size = 2 * (4 + int(3 * np.log(self.dim)))\n\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        evals = 0\n\n        while self.budget - evals > 0:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n\n            if self.mirrored_sampling:\n                z = np.vstack((z, -z))\n            \n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            evals += len(x)\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            \n            if self.mirrored_sampling:\n                indices = indices[:self.pop_size]  # Only select the best half\n            \n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            if self.active_update:\n                # Active covariance update\n                neg_indices = indices[self.mu:self.pop_size]\n                z_neg = z[neg_indices]\n                weights_neg = min(0.1, self.mu / self.pop_size) * np.ones(len(z_neg)) / len(z_neg)\n                C -= self.ccovmu * np.sum(weights_neg.reshape(-1, 1, 1) * (z_neg[:, :, np.newaxis] @ z_neg[:, np.newaxis, :]), axis=0)\n                \n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adjust population size\n            if evals > self.budget * 0.75 and self.pop_size > self.min_pop_size:\n                self.pop_size = max(self.min_pop_size, self.pop_size // 2)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            elif self.sigma < 1e-6 and self.pop_size < self.max_pop_size:\n                self.pop_size = min(self.max_pop_size, self.pop_size * 2)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.011489359848634036, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "9d35c5cb-a185-4701-aa5e-ffb82fee1af6", "fitness": 0.0, "name": "OrthogonalCMAES", "description": "Evolutionary strategy with covariance matrix adaptation and orthogonal crossover, focusing on diversity and convergence.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, damps=None, c_cov=None, mu_factor=4, orthogonal_factor = 0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max([0, np.log((dim + 1) / 3) / 2])\n        self.mu = self.pop_size // mu_factor \n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.c_cov = c_cov if c_cov is not None else 2 / (dim**2 + np.sqrt(2*dim)) # Learning rate for rank-one update\n        self.orthogonal_factor = orthogonal_factor\n\n        self.C = np.eye(dim)\n        self.p_sigma = np.zeros(dim)\n        self.p_c = np.zeros(dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            B, s = np.linalg.eig(self.C)\n            s = np.sqrt(s)\n            x = np.zeros((self.dim, self.pop_size))\n            for k in range(self.pop_size):\n                x[:, k] = func.bounds.lb + (func.bounds.ub - func.bounds.lb) / 2 + self.sigma * (B @ (s * z[:, k]))\n\n            # 2. Evaluate population and clip to bounds\n            f = np.zeros(self.pop_size)\n            for k in range(self.pop_size):\n                x_k = np.clip(x[:, k], func.bounds.lb, func.bounds.ub) \n                f[k] = func(x_k)\n                self.eval_count += 1\n                if f[k] < self.f_opt:\n                    self.f_opt = f[k]\n                    self.x_opt = x_k\n\n            # Early termination\n            if self.eval_count >= self.budget:\n                break\n            \n            # 3. Selection and Recombination\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n\n            # Orthogonal crossover: Create new offspring by recombining the best solutions using an orthogonal matrix\n            if self.orthogonal_factor > 0:\n               orthogonal_matrix = np.random.randn(self.mu, self.mu)\n               Q, _ = np.linalg.qr(orthogonal_matrix)\n               x_orthogonal = np.zeros_like(x_mu)\n               for i in range(self.dim):\n                   x_orthogonal[i,:] = np.dot(x_mu[i,:], Q)\n\n               x_mu = (1 - self.orthogonal_factor) * x_mu + self.orthogonal_factor * x_orthogonal\n            \n\n            x_mean = np.sum(x_mu * self.weights.reshape(1,-1), axis=1)\n            z_mean = (x_mean - (func.bounds.lb + (func.bounds.ub - func.bounds.lb) / 2)) / self.sigma\n\n            # 4. Update Evolution Path\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * z_mean\n            self.p_c = (1 - self.cs) * self.p_c + np.sqrt(self.cs * (2 - self.cs)) * np.sqrt(np.sum(self.weights**2)) * B @ (s * z_mean)\n\n\n            # 5. Update Covariance Matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.p_c[:,None] @ self.p_c[None,:])\n\n            # Ensure positive definiteness\n            try:\n              np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n              self.C = self.C + 1e-6 * np.eye(self.dim) \n\n            # 6. Update Step Size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: Array must not contain infs or NaNs", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Evolutionary strategy with covariance matrix adaptation and orthogonal crossover, focusing on diversity and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, cs=0.3, damps=None, c_cov=None, mu_factor=4, orthogonal_factor = 0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * np.max([0, np.log((dim + 1) / 3) / 2])\n        self.mu = self.pop_size // mu_factor \n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.c_cov = c_cov if c_cov is not None else 2 / (dim**2 + np.sqrt(2*dim)) # Learning rate for rank-one update\n        self.orthogonal_factor = orthogonal_factor\n\n        self.C = np.eye(dim)\n        self.p_sigma = np.zeros(dim)\n        self.p_c = np.zeros(dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # 1. Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            B, s = np.linalg.eig(self.C)\n            s = np.sqrt(s)\n            x = np.zeros((self.dim, self.pop_size))\n            for k in range(self.pop_size):\n                x[:, k] = func.bounds.lb + (func.bounds.ub - func.bounds.lb) / 2 + self.sigma * (B @ (s * z[:, k]))\n\n            # 2. Evaluate population and clip to bounds\n            f = np.zeros(self.pop_size)\n            for k in range(self.pop_size):\n                x_k = np.clip(x[:, k], func.bounds.lb, func.bounds.ub) \n                f[k] = func(x_k)\n                self.eval_count += 1\n                if f[k] < self.f_opt:\n                    self.f_opt = f[k]\n                    self.x_opt = x_k\n\n            # Early termination\n            if self.eval_count >= self.budget:\n                break\n            \n            # 3. Selection and Recombination\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:self.mu]]\n\n            # Orthogonal crossover: Create new offspring by recombining the best solutions using an orthogonal matrix\n            if self.orthogonal_factor > 0:\n               orthogonal_matrix = np.random.randn(self.mu, self.mu)\n               Q, _ = np.linalg.qr(orthogonal_matrix)\n               x_orthogonal = np.zeros_like(x_mu)\n               for i in range(self.dim):\n                   x_orthogonal[i,:] = np.dot(x_mu[i,:], Q)\n\n               x_mu = (1 - self.orthogonal_factor) * x_mu + self.orthogonal_factor * x_orthogonal\n            \n\n            x_mean = np.sum(x_mu * self.weights.reshape(1,-1), axis=1)\n            z_mean = (x_mean - (func.bounds.lb + (func.bounds.ub - func.bounds.lb) / 2)) / self.sigma\n\n            # 4. Update Evolution Path\n            self.p_sigma = (1 - self.cs) * self.p_sigma + np.sqrt(self.cs * (2 - self.cs)) * z_mean\n            self.p_c = (1 - self.cs) * self.p_c + np.sqrt(self.cs * (2 - self.cs)) * np.sqrt(np.sum(self.weights**2)) * B @ (s * z_mean)\n\n\n            # 5. Update Covariance Matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.p_c[:,None] @ self.p_c[None,:])\n\n            # Ensure positive definiteness\n            try:\n              np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n              self.C = self.C + 1e-6 * np.eye(self.dim) \n\n            # 6. Update Step Size\n            self.sigma = self.sigma * np.exp((self.cs / self.damps) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.060808058216130355, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "569dac9f-207e-4840-8c72-53f1a9fc008a", "fitness": 0.20791800134255398, "name": "HybridCMAES_ACS", "description": "A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's adaptive inertia and neighborhood best influence.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarm from CMA-ES's mean\n        swarm = np.random.normal(m, self.sigma, size=(self.pop_size, self.dim))\n        swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial swarm\n        fitness = np.array([func(xi) for xi in swarm])\n        self.budget -= self.pop_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            # Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities and positions using swarm dynamics\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            new_fitness = np.array([func(xi) for xi in swarm])\n            self.budget -= self.pop_size\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            # Selection and recombination (CMA-ES part)\n            indices = np.argsort(new_fitness)\n            x_mu = swarm[indices[:self.mu]]\n            z_mu = np.random.normal(0, 1, size=(self.mu, self.dim)) # Replace noise with new samples\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n\n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Update swarm center based on CMA-ES mean\n            swarm = np.random.normal(m, self.sigma, size=(self.pop_size, self.dim))\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridCMAES_ACS scored 0.208 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's adaptive inertia and neighborhood best influence.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize swarm from CMA-ES's mean\n        swarm = np.random.normal(m, self.sigma, size=(self.pop_size, self.dim))\n        swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial swarm\n        fitness = np.array([func(xi) for xi in swarm])\n        self.budget -= self.pop_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            # Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities and positions using swarm dynamics\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate offspring\n            new_fitness = np.array([func(xi) for xi in swarm])\n            self.budget -= self.pop_size\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            # Selection and recombination (CMA-ES part)\n            indices = np.argsort(new_fitness)\n            x_mu = swarm[indices[:self.mu]]\n            z_mu = np.random.normal(0, 1, size=(self.mu, self.dim)) # Replace noise with new samples\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n\n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Update swarm center based on CMA-ES mean\n            swarm = np.random.normal(m, self.sigma, size=(self.pop_size, self.dim))\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.049030279689971756, 0.06709264242556123, 0.20299824525948706, 0.09324803329384956, 0.09682545313001223, 0.1650193827426385, 0.20205696114062388, 0.07287212060398907, 0.15905707257969404, 0.10647790527299639, 0.15837470821502098, 0.9944640609133378, 0.2216306449291514, 0.22798820238495732, 0.14308434029635664, 0.22450510332006068, 0.17832258729572714, 0.26346927504792406, 0.1536922984278788, 0.3781507098818415], "operator": "crossover", "theta_sampled": 0.21553161972487833, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "a003f12d-223c-4870-b934-ea0e22384cf0", "fitness": 0.0, "name": "GaussianProcessThompsonSampling", "description": "Employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation using Thompson sampling.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessThompsonSampling:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def _initial_sample(self, func):\n        X_init = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        return X_init, y_init\n\n    def _train_gp(self, X, y):\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")  # RBF kernel\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, alpha=1e-5)\n        self.gpr.fit(X, y)\n\n    def _thompson_sampling(self, func, num_samples=1000):\n        # Generate random samples in the search space\n        X_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_samples, self.dim))\n\n        # Predict mean and standard deviation using the Gaussian process\n        mu, sigma = self.gpr.predict(X_samples, return_std=True)\n\n        # Sample from a Gaussian distribution with the predicted mean and standard deviation\n        y_samples = np.random.normal(mu, sigma)\n\n        # Select the sample with the minimum value\n        best_index = np.argmin(y_samples)\n        x_next = X_samples[best_index]\n        return x_next\n\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init, y_init = self._initial_sample(func)\n        self.X = X_init\n        self.y = y_init\n\n        # Update optimal value\n        best_index = np.argmin(self.y)\n        if self.y[best_index] < self.f_opt:\n            self.f_opt = self.y[best_index]\n            self.x_opt = self.X[best_index]\n\n        # Main optimization loop\n        num_evals = self.n_initial_samples\n        while num_evals < self.budget:\n            # Train Gaussian process\n            self._train_gp(self.X, self.y)\n\n            # Thompson sampling to select the next point to evaluate\n            x_next = self._thompson_sampling(func)\n\n            # Evaluate the function at the selected point\n            f_next = func(x_next)\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update optimal value\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n            \n            num_evals += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: name 'C' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Employs a Gaussian process surrogate model to guide the search, balancing exploration and exploitation using Thompson sampling.\n# Code:\n```python\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessThompsonSampling:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def _initial_sample(self, func):\n        X_init = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        return X_init, y_init\n\n    def _train_gp(self, X, y):\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")  # RBF kernel\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, alpha=1e-5)\n        self.gpr.fit(X, y)\n\n    def _thompson_sampling(self, func, num_samples=1000):\n        # Generate random samples in the search space\n        X_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_samples, self.dim))\n\n        # Predict mean and standard deviation using the Gaussian process\n        mu, sigma = self.gpr.predict(X_samples, return_std=True)\n\n        # Sample from a Gaussian distribution with the predicted mean and standard deviation\n        y_samples = np.random.normal(mu, sigma)\n\n        # Select the sample with the minimum value\n        best_index = np.argmin(y_samples)\n        x_next = X_samples[best_index]\n        return x_next\n\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init, y_init = self._initial_sample(func)\n        self.X = X_init\n        self.y = y_init\n\n        # Update optimal value\n        best_index = np.argmin(self.y)\n        if self.y[best_index] < self.f_opt:\n            self.f_opt = self.y[best_index]\n            self.x_opt = self.X[best_index]\n\n        # Main optimization loop\n        num_evals = self.n_initial_samples\n        while num_evals < self.budget:\n            # Train Gaussian process\n            self._train_gp(self.X, self.y)\n\n            # Thompson sampling to select the next point to evaluate\n            x_next = self._thompson_sampling(func)\n\n            # Evaluate the function at the selected point\n            f_next = func(x_next)\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update optimal value\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n            \n            num_evals += 1\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.044679158153096483, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "8cdc3fad-d92e-455f-a2a0-c266373e2218", "fitness": 0.1440312666998032, "name": "AdaptiveCooperativeSwarmEnhanced2", "description": "Adaptive Cooperative Swarm with dynamic neighborhood size and velocity clamping to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarmEnhanced2:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        # Adaptive Neighborhood Size\n        neighborhood_size = self.initial_neighborhood_size\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing\n\n            # Adaptive Neighborhood Size update\n            neighborhood_size = min(self.swarm_size - 1, max(1, int(self.initial_neighborhood_size * (1 + 2 * (global_best_fitness - np.mean(fitness)))))) # Increase if global best is far from the average fitness, decrease otherwise.\n\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - neighborhood_size // 2), min(self.swarm_size, i + neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCooperativeSwarmEnhanced2 scored 0.144 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with dynamic neighborhood size and velocity clamping to improve exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarmEnhanced2:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        # Adaptive Neighborhood Size\n        neighborhood_size = self.initial_neighborhood_size\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing\n\n            # Adaptive Neighborhood Size update\n            neighborhood_size = min(self.swarm_size - 1, max(1, int(self.initial_neighborhood_size * (1 + 2 * (global_best_fitness - np.mean(fitness)))))) # Increase if global best is far from the average fitness, decrease otherwise.\n\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - neighborhood_size // 2), min(self.swarm_size, i + neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.034282055829820246, 0.03342766728158875, 0.2115693303583206, 0.12114412810303143, 0.08307662582069075, 0.13887883505622267, 0.1702564294626716, 0.13500487066786138, 0.13216016095442917, 0.11890198321572898, 0.16555532361515068, 0.155473836066212, 0.03638949603285058, 0.14256476993915745, 0.13073217609697463, 0.17957995509914249, 0.16661998697650504, 0.2389216720030347, 0.10901918904059416, 0.37706684237607624], "operator": "mutation", "theta_sampled": 0.018166824700922367, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "d504fa01-8f83-4ef2-bbf6-180e795e3286", "fitness": 0.6319372366336079, "name": "HybridCMAES_ACS", "description": "A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's adaptive inertia and neighborhood search, enhancing exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, swarm_size_ratio=2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.swarm_size = int(dim * swarm_size_ratio)  #Adaptive swarm size based on dimensionality\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # Initialize the swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        eval_count = 0  # Keep track of evaluations\n\n        # Evaluate initial swarm positions\n        fitness = np.array([func(x) for x in swarm])\n        eval_count += self.swarm_size\n        if eval_count > self.budget:\n            return self.f_opt, self.x_opt\n\n        # Find the global best within swarm\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n\n        # Initialize personal bests for swarm\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        inertia = self.inertia_max  #Adaptive Inertia Initialization\n\n        while eval_count < self.budget:\n            # CMA-ES Generation and Evaluation\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness_cmaes = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            if eval_count > self.budget:\n                return self.f_opt, self.x_opt\n\n            # Update best solution based on CMA-ES results\n            best_index_cmaes = np.argmin(fitness_cmaes)\n            if fitness_cmaes[best_index_cmaes] < self.f_opt:\n                self.f_opt = fitness_cmaes[best_index_cmaes]\n                self.x_opt = x[best_index_cmaes]\n\n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness_cmaes)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n\n            #Adaptive Cooperative Swarm update\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new swarm positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count += self.swarm_size\n            if eval_count > self.budget:\n                return self.f_opt, self.x_opt\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best (within swarm) and compare with current best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridCMAES_ACS scored 0.632 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's adaptive inertia and neighborhood search, enhancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, swarm_size_ratio=2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.swarm_size = int(dim * swarm_size_ratio)  #Adaptive swarm size based on dimensionality\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # Initialize the swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        eval_count = 0  # Keep track of evaluations\n\n        # Evaluate initial swarm positions\n        fitness = np.array([func(x) for x in swarm])\n        eval_count += self.swarm_size\n        if eval_count > self.budget:\n            return self.f_opt, self.x_opt\n\n        # Find the global best within swarm\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n\n        # Initialize personal bests for swarm\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        inertia = self.inertia_max  #Adaptive Inertia Initialization\n\n        while eval_count < self.budget:\n            # CMA-ES Generation and Evaluation\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            fitness_cmaes = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            if eval_count > self.budget:\n                return self.f_opt, self.x_opt\n\n            # Update best solution based on CMA-ES results\n            best_index_cmaes = np.argmin(fitness_cmaes)\n            if fitness_cmaes[best_index_cmaes] < self.f_opt:\n                self.f_opt = fitness_cmaes[best_index_cmaes]\n                self.x_opt = x[best_index_cmaes]\n\n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness_cmaes)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n\n            #Adaptive Cooperative Swarm update\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget)\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new swarm positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count += self.swarm_size\n            if eval_count > self.budget:\n                return self.f_opt, self.x_opt\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best (within swarm) and compare with current best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2501343764063826, 0.19625796638235038, 0.88349559487684, 0.9373004478936592, 0.8904119747376702, 0.9131197948505856, 0.3344153182897648, 0.857179562387046, 0.8886280657414121, 0.21406653658225394, 0.9512428763440886, 1.0, 0.32709954324057267, 0.6001573000655744, 0.9013804390250381, 0.3593978720630677, 0.40645138138344505, 0.9410090181293402, 0.270883913565218, 0.5161127507078487], "operator": "crossover", "theta_sampled": 0.20263384161069642, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "52d067a4-e7b5-4e91-9b42-36188318b630", "fitness": 0.0, "name": "AdaptiveCooperativeSwarmImproved", "description": "Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size, combined with mutation.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarmImproved:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        #Dynamic Neighborhood Size\n        neighborhood_size = self.neighborhood_size\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / (self.budget+self.swarm_size))) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - neighborhood_size // 2), min(self.swarm_size, i + neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Mutation\n            mutation_mask = np.random.rand(self.swarm_size, self.dim) < self.mutation_rate\n            swarm[mutation_mask] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=np.sum(mutation_mask))\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            # Adjust neighborhood size (example: reduce if no improvement)\n            if np.sum(improvement) == 0 and neighborhood_size > 1:\n                neighborhood_size = max(1, neighborhood_size - 1)  # Ensure it doesn't go below 1\n            elif np.sum(improvement) > self.swarm_size // 4 and neighborhood_size < self.swarm_size:\n                neighborhood_size = min(self.swarm_size, neighborhood_size + 1)\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: Output size (1,) is not compatible with broadcast dimensions of inputs (2,).", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size, combined with mutation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarmImproved:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        #Dynamic Neighborhood Size\n        neighborhood_size = self.neighborhood_size\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / (self.budget+self.swarm_size))) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - neighborhood_size // 2), min(self.swarm_size, i + neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Mutation\n            mutation_mask = np.random.rand(self.swarm_size, self.dim) < self.mutation_rate\n            swarm[mutation_mask] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=np.sum(mutation_mask))\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            # Adjust neighborhood size (example: reduce if no improvement)\n            if np.sum(improvement) == 0 and neighborhood_size > 1:\n                neighborhood_size = max(1, neighborhood_size - 1)  # Ensure it doesn't go below 1\n            elif np.sum(improvement) > self.swarm_size // 4 and neighborhood_size < self.swarm_size:\n                neighborhood_size = min(self.swarm_size, neighborhood_size + 1)\n\n        return global_best_fitness, global_best_position\n```", "operator": "mutation", "theta_sampled": 0.035639309166783054, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "497aa6b4-89f2-4f84-9161-66f1cde79f01", "fitness": 0.0, "name": "HybridCMAES_ACS", "description": "A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's neighborhood-based learning and adaptive inertia, focusing on both global and local exploration.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # Initialize swarm-related variables\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))  # Using pop_size as swarm size\n        self.velocities = np.zeros_like(self.swarm)\n        fitness = np.array([func(x) for x in self.swarm])\n        self.budget -= self.pop_size\n\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index].copy()\n            self.global_best_position = self.swarm[best_index].copy()\n\n    def update_swarm(self, func, inertia):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Neighborhood best influence\n        neighborhood_best_positions = np.zeros_like(self.swarm)\n        for i in range(self.pop_size):\n            neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n            neighborhood_fitnesses = self.personal_best_fitness[neighborhood_indices]\n            best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n            neighborhood_best_positions[i] = self.personal_best_positions[best_index_in_neighborhood].copy()\n\n        self.velocities = (inertia * self.velocities +\n                           self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                           self.social_coeff * r2 * (neighborhood_best_positions - self.swarm))\n\n        self.swarm = self.swarm + self.velocities\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        fitness = np.array([func(x) for x in self.swarm])\n        self.budget -= self.pop_size\n\n        improvement = fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        best_index_in_batch = np.argmin(fitness)\n\n        if fitness[best_index_in_batch] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n\n        return fitness\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_swarm(func)\n\n        while self.budget > 0:\n            # Generate and evaluate offspring using CMA-ES\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Integrate swarm's best knowledge into CMA-ES offspring\n            x[:self.pop_size] = self.swarm.copy()  # Replace first part of offspring with current swarm positions\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n\n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n\n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Adaptive Cooperative Swarm update\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n            swarm_fitness = self.update_swarm(func, inertia)\n\n            #Update the CMAES mean with the global best from the swarm\n            m = self.global_best_position\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: division by zero", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's neighborhood-based learning and adaptive inertia, focusing on both global and local exploration.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # Initialize swarm-related variables\n        self.swarm = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_swarm(self, func):\n        self.swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))  # Using pop_size as swarm size\n        self.velocities = np.zeros_like(self.swarm)\n        fitness = np.array([func(x) for x in self.swarm])\n        self.budget -= self.pop_size\n\n        self.personal_best_positions = self.swarm.copy()\n        self.personal_best_fitness = fitness.copy()\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index].copy()\n            self.global_best_position = self.swarm[best_index].copy()\n\n    def update_swarm(self, func, inertia):\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        # Neighborhood best influence\n        neighborhood_best_positions = np.zeros_like(self.swarm)\n        for i in range(self.pop_size):\n            neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n            neighborhood_fitnesses = self.personal_best_fitness[neighborhood_indices]\n            best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n            neighborhood_best_positions[i] = self.personal_best_positions[best_index_in_neighborhood].copy()\n\n        self.velocities = (inertia * self.velocities +\n                           self.cognitive_coeff * r1 * (self.personal_best_positions - self.swarm) +\n                           self.social_coeff * r2 * (neighborhood_best_positions - self.swarm))\n\n        self.swarm = self.swarm + self.velocities\n        self.swarm = np.clip(self.swarm, func.bounds.lb, func.bounds.ub)\n\n        fitness = np.array([func(x) for x in self.swarm])\n        self.budget -= self.pop_size\n\n        improvement = fitness < self.personal_best_fitness\n        self.personal_best_fitness[improvement] = fitness[improvement]\n        self.personal_best_positions[improvement] = self.swarm[improvement].copy()\n\n        best_index_in_batch = np.argmin(fitness)\n\n        if fitness[best_index_in_batch] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index_in_batch].copy()\n            self.global_best_position = self.swarm[best_index_in_batch].copy()\n\n        return fitness\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_swarm(func)\n\n        while self.budget > 0:\n            # Generate and evaluate offspring using CMA-ES\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Integrate swarm's best knowledge into CMA-ES offspring\n            x[:self.pop_size] = self.swarm.copy()  # Replace first part of offspring with current swarm positions\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n\n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n\n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Adaptive Cooperative Swarm update\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n            swarm_fitness = self.update_swarm(func, inertia)\n\n            #Update the CMAES mean with the global best from the swarm\n            m = self.global_best_position\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.19516017761097357, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "51cf81ee-677f-42fc-af0d-f6cf168094d8", "fitness": 0.552539336319233, "name": "AdaptiveCooperativeSwarmV2", "description": "Adaptive Cooperative Swarm with Velocity Dampening and Neighborhood Learning to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarmV2:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, velocity_dampening=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.velocity_dampening = velocity_dampening\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Adaptive Inertia (linearly decreasing)\n            inertia = self.inertia * (self.budget / 10000 if self.budget <= 10000 else 1.0)  #Example of adaptation\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            # Velocity dampening: Prevents excessive velocity build-up\n            velocities *= self.velocity_dampening\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n\n            #Neighborhood Learning: Learn from a random neighbor\n            for i in non_elite_indices:\n                neighbor_idx = np.random.choice(self.swarm_size)\n                swarm[i] = swarm[i] + 0.05 * (personal_best_positions[neighbor_idx] - swarm[i]) #Move towards neighbor\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCooperativeSwarmV2 scored 0.553 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["efc9acf1-48ec-4263-8413-ad975ece5f07"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with Velocity Dampening and Neighborhood Learning to improve exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarmV2:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, elite_proportion=0.1, velocity_dampening=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.elite_proportion = elite_proportion\n        self.velocity_dampening = velocity_dampening\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)  # Initialize velocities\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        while self.budget > 0:\n            # Adaptive Inertia (linearly decreasing)\n            inertia = self.inertia * (self.budget / 10000 if self.budget <= 10000 else 1.0)  #Example of adaptation\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (global_best_position - swarm))\n            \n            # Velocity dampening: Prevents excessive velocity build-up\n            velocities *= self.velocity_dampening\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            # Elitist learning: Move some particles towards the elite\n            num_elites = int(self.elite_proportion * self.swarm_size)\n            elite_indices = np.argsort(personal_best_fitness)[:num_elites]\n            \n            # Move non-elite particles closer to elite particles (exploration)\n            non_elite_indices = np.argsort(personal_best_fitness)[num_elites:]\n\n            #Neighborhood Learning: Learn from a random neighbor\n            for i in non_elite_indices:\n                neighbor_idx = np.random.choice(self.swarm_size)\n                swarm[i] = swarm[i] + 0.05 * (personal_best_positions[neighbor_idx] - swarm[i]) #Move towards neighbor\n                swarm[i] = np.clip(swarm[i], func.bounds.lb, func.bounds.ub) #Clip them again.\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.15937151579870557, 0.20025061292243596, 0.9188316928079493, 0.97087673301623, 0.30476507873365577, 0.9476724229590956, 0.34786445979810643, 0.822855324950715, 0.31353057330502165, 0.9272817150047641, 0.6042297898351197, 0.9960232203040188, 0.2485621804689473, 0.32524142744110585, 0.5872568440835071, 0.36425174591063436, 0.2809807242400647, 0.9596656111141548, 0.2509041202594895, 0.5203709334309385], "operator": "mutation", "theta_sampled": 0.05168426895603574, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "62fa06dc-4dfe-432f-abad-3cae18ed20be", "fitness": 0.24585107418634236, "name": "HybridDEPSO", "description": "An adaptive population-based algorithm that combines elements of differential evolution and particle swarm optimization, dynamically adjusting exploration and exploitation based on population diversity.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, de_scaling_factor=0.5, de_crossover_rate=0.7, pso_inertia=0.7, pso_cognitive=1.5, pso_social=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_scaling_factor = de_scaling_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_inertia = pso_inertia\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size #Update the budget\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        velocities = np.zeros((self.pop_size, self.dim)) #PSO part.\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            # Adjust DE and PSO parameters based on diversity\n            adjusted_de_scaling_factor = self.de_scaling_factor * (1 + diversity)\n            adjusted_de_crossover_rate = self.de_crossover_rate * (1 - diversity)\n            adjusted_pso_inertia = self.pso_inertia * (1 - diversity)\n            adjusted_pso_cognitive = self.pso_cognitive * (1 + diversity)\n            adjusted_pso_social = self.pso_social * (1 + diversity)\n\n\n            # Differential Evolution (DE) part\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + adjusted_de_scaling_factor * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) #Clip to search space\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < adjusted_de_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1 #Update the budget\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Particle Swarm Optimization (PSO) part\n            for i in range(self.pop_size):\n                # Update velocity\n                r1, r2 = np.random.rand(2)\n                cognitive_component = adjusted_pso_cognitive * r1 * (self.x_opt - population[i])\n                social_component = adjusted_pso_social * r2 * (population[np.argmin(fitness)] - population[i]) #Using best of current population as local best\n\n                velocities[i] = adjusted_pso_inertia * velocities[i] + cognitive_component + social_component\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate fitness\n                f_i = func(population[i])\n                self.budget -= 1 #Update the budget\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                if f_i < fitness[i]:\n                    fitness[i] = f_i\n                    \n                    if f_i < self.f_opt:\n                        self.f_opt = f_i\n                        self.x_opt = population[i]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSO scored 0.246 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines elements of differential evolution and particle swarm optimization, dynamically adjusting exploration and exploitation based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, de_scaling_factor=0.5, de_crossover_rate=0.7, pso_inertia=0.7, pso_cognitive=1.5, pso_social=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_scaling_factor = de_scaling_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_inertia = pso_inertia\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size #Update the budget\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        velocities = np.zeros((self.pop_size, self.dim)) #PSO part.\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            # Adjust DE and PSO parameters based on diversity\n            adjusted_de_scaling_factor = self.de_scaling_factor * (1 + diversity)\n            adjusted_de_crossover_rate = self.de_crossover_rate * (1 - diversity)\n            adjusted_pso_inertia = self.pso_inertia * (1 - diversity)\n            adjusted_pso_cognitive = self.pso_cognitive * (1 + diversity)\n            adjusted_pso_social = self.pso_social * (1 + diversity)\n\n\n            # Differential Evolution (DE) part\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + adjusted_de_scaling_factor * (b - c)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub) #Clip to search space\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < adjusted_de_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1 #Update the budget\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Particle Swarm Optimization (PSO) part\n            for i in range(self.pop_size):\n                # Update velocity\n                r1, r2 = np.random.rand(2)\n                cognitive_component = adjusted_pso_cognitive * r1 * (self.x_opt - population[i])\n                social_component = adjusted_pso_social * r2 * (population[np.argmin(fitness)] - population[i]) #Using best of current population as local best\n\n                velocities[i] = adjusted_pso_inertia * velocities[i] + cognitive_component + social_component\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate fitness\n                f_i = func(population[i])\n                self.budget -= 1 #Update the budget\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                if f_i < fitness[i]:\n                    fitness[i] = f_i\n                    \n                    if f_i < self.f_opt:\n                        self.f_opt = f_i\n                        self.x_opt = population[i]\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07803663567709007, 0.11579398752063774, 0.24466402744586113, 0.18898887395090314, 0.16448721927699894, 0.17970187013250893, 0.1882829675151938, 0.19276262813698075, 0.17874646172414144, 0.129875383917048, 0.17915968845689845, 0.9973863549394365, 0.18881637110364657, 0.1941442265420179, 0.538098988188471, 0.2400992886175326, 0.19031045059906082, 0.17807473308478217, 0.10955640083382445, 0.4400349260638138], "operator": "random_new", "theta_sampled": 0.035257592186548864, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "f0ab6741-d4bf-4cf8-beca-a063b23db096", "fitness": 0.0, "name": "AdaptiveCMAES_OAx", "description": "CMA-ES variant with adaptive population size based on budget and dimension, combined with orthogonal crossover and covariance matrix adaptation that includes rank-one and rank-mu updates alongside step-size adaptation.", "code": "import numpy as np\n\nclass AdaptiveCMAES_OAx:\n    def __init__(self, budget=10000, dim=10, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, pop_multiplier=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.pop_multiplier = pop_multiplier  # Allows scaling of population size\n\n        # Adaptive population size based on budget and dimension\n        self.pop_size = int(self.pop_multiplier * (4 + int(3 * np.log(self.dim)) + int(np.sqrt(self.budget / self.dim))))\n        self.pop_size = max(2, self.pop_size)  # Ensure population size is at least 2\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        eval_count = 0  # Track function evaluations\n\n        while eval_count < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring (perturbation scaled by sigma)\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + self.sigma * np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Ensure C remains positive definite\n            C = np.triu(C) + np.triu(C, 1).T\n            eigvals = np.linalg.eigvalsh(C)\n            if np.any(eigvals < 1e-10):\n                C += (1e-10 - np.min(eigvals)) * np.eye(self.dim)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveCMAES_OAx scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85"], "operator": "mutation", "metadata": {"llm_response": "# Description: CMA-ES variant with adaptive population size based on budget and dimension, combined with orthogonal crossover and covariance matrix adaptation that includes rank-one and rank-mu updates alongside step-size adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES_OAx:\n    def __init__(self, budget=10000, dim=10, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, pop_multiplier=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.pop_multiplier = pop_multiplier  # Allows scaling of population size\n\n        # Adaptive population size based on budget and dimension\n        self.pop_size = int(self.pop_multiplier * (4 + int(3 * np.log(self.dim)) + int(np.sqrt(self.budget / self.dim))))\n        self.pop_size = max(2, self.pop_size)  # Ensure population size is at least 2\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        eval_count = 0  # Track function evaluations\n\n        while eval_count < self.budget:\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring (perturbation scaled by sigma)\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + self.sigma * np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n            \n            # Ensure C remains positive definite\n            C = np.triu(C) + np.triu(C, 1).T\n            eigvals = np.linalg.eigvalsh(C)\n            if np.any(eigvals < 1e-10):\n                C += (1e-10 - np.min(eigvals)) * np.eye(self.dim)\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.01089429606585903, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "f3be0900-a9f9-4f06-a39a-f7ea0a20a18c", "fitness": 0.6387336711274425, "name": "HybridCMAES_ACS", "description": "Combines CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's social learning and adaptive inertia for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridCMAES_ACS scored 0.639 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines CMA-ES's covariance matrix adaptation with Adaptive Cooperative Swarm's social learning and adaptive inertia for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23603556032276296, 0.1674607302252572, 0.9450268032807768, 0.972131786038386, 0.9536465766424277, 0.9589587125399542, 0.28835246332969455, 0.941389332251446, 0.9451563103786187, 0.15519650906686422, 0.9703104735090495, 0.9943168140352986, 0.2736550477800651, 0.9539615490654811, 0.9477456962712811, 0.35351870152445986, 0.9235497771381564, 0.14825577450500915, 0.13726492244590194, 0.5087398821979607], "operator": "crossover", "theta_sampled": 0.3236076763825924, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "0abc966d-03c8-42de-a335-a9ba00746f31", "fitness": 0.4533829381108686, "name": "AdaptiveCooperativeSwarm", "description": "Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = 1.0  # Clamp velocities to this value\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (generation / (self.budget + generation)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Dynamic Neighborhood size adjustment based on global best improvement\n            if np.random.rand() < 0.1:  # Probability to change neighborhood size\n                if global_best_fitness == np.min(personal_best_fitness): #If no improvement\n                    self.neighborhood_size = min(self.swarm_size, self.neighborhood_size + 1)\n                else:\n                    self.neighborhood_size = max(1, self.neighborhood_size - 1) #Shrink neighborhood\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveCooperativeSwarm scored 0.453 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_size = initial_neighborhood_size\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = 1.0  # Clamp velocities to this value\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (generation / (self.budget + generation)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Dynamic Neighborhood size adjustment based on global best improvement\n            if np.random.rand() < 0.1:  # Probability to change neighborhood size\n                if global_best_fitness == np.min(personal_best_fitness): #If no improvement\n                    self.neighborhood_size = min(self.swarm_size, self.neighborhood_size + 1)\n                else:\n                    self.neighborhood_size = max(1, self.neighborhood_size - 1) #Shrink neighborhood\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.22441302866666912, 0.2658553199417816, 0.4287273331447121, 0.6112568817533096, 0.38168815898657227, 0.4654923214204879, 0.30886785622803614, 0.373601168200427, 0.39654924866694097, 0.3276934944768606, 0.5974366900663605, 0.9989478208743835, 0.3704213511060228, 0.3606723576983235, 0.7267254940852077, 0.48646960830194386, 0.35886037450940156, 0.5920977252701962, 0.2496635707949777, 0.5422189580247572], "operator": "mutation", "theta_sampled": 0.03267070328486231, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "bd55adfc-44e6-4acb-86ce-4abed4299722", "fitness": 0.29867368833167357, "name": "AdaptiveCooperativeSwarm", "description": "Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size adjustment based on swarm diversity.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing.  Was bugged.\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            #Dynamic Neighborhood Size Adjustment\n            diversity = np.std(swarm)\n            if diversity < 0.01:\n                self.neighborhood_size = min(self.swarm_size, self.neighborhood_size + 1)  # Increase neighborhood size if swarm is too concentrated\n            elif diversity > 1:\n                self.neighborhood_size = max(1, self.neighborhood_size - 1)   # Decrease neighborhood size if swarm is too diverse\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveCooperativeSwarm scored 0.299 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with velocity clamping and dynamic neighborhood size adjustment based on swarm diversity.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size\n        self.velocity_clamp = velocity_clamp\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing.  Was bugged.\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n            \n            #Dynamic Neighborhood Size Adjustment\n            diversity = np.std(swarm)\n            if diversity < 0.01:\n                self.neighborhood_size = min(self.swarm_size, self.neighborhood_size + 1)  # Increase neighborhood size if swarm is too concentrated\n            elif diversity > 1:\n                self.neighborhood_size = max(1, self.neighborhood_size - 1)   # Decrease neighborhood size if swarm is too diverse\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.08884878439799193, 0.1935418937201332, 0.30255684437573627, 0.6798921982774202, 0.15831978284931447, 0.1931405071856961, 0.21867948687565253, 0.21362821809145038, 0.181109846697042, 0.17318842058500372, 0.21822973330196616, 0.997546573573054, 0.274358617475438, 0.18262068541487764, 0.5359429975887972, 0.2800995368670075, 0.2874176798485355, 0.18767792175543585, 0.14179218981263875, 0.4648818479402801], "operator": "mutation", "theta_sampled": 0.006718484124850099, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "e13822a2-c6fc-4643-be47-86d5a79a780f", "fitness": 0.35286079546698784, "name": "AdaptiveNeighborhoodCMAES", "description": "Integrates a self-adaptive radius neighborhood-based ACS with CMA-ES, dynamically adjusting search intensity based on function evaluations and using a more robust covariance matrix adaptation strategy.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_radius=1.0, radius_decay=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_radius = initial_neighborhood_radius\n        self.radius_decay = radius_decay\n        self.neighborhood_radius = initial_neighborhood_radius\n\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        B = np.eye(self.dim)  # Eigenvectors of C\n        D = np.ones(self.dim)   # Eigenvalues of C\n        invsqrtC = np.eye(self.dim) # C^-1/2\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = np.full(self.pop_size, np.inf)\n\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = m + self.sigma * z @ invsqrtC.T #Using precomputed inverse square root\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma @ invsqrtC\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Robust Covariance Matrix Adaptation using eigenvalue decomposition\n            try:\n                D, B = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                D = np.diag(C) #Fall back to diagonal if needed\n                B = np.eye(self.dim) #Identity matrix\n            \n            D = np.maximum(D, 1e-8)  # Avoid zero eigenvalues\n            C = B @ np.diag(D) @ B.T  # Reconstruct C\n            invsqrtC = B @ np.diag(D**(-0.5)) @ B.T #Precompute inverse sqrt\n\n            # Adaptive Cooperative Swarm Component\n            # Update personal bests\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = x[i].copy()\n\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / (func.max_evaluations if hasattr(func, 'max_evaluations') and func.max_evaluations else self.budget))  if (hasattr(func, 'max_evaluations') and func.max_evaluations) or self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence with radius\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(personal_best_positions - personal_best_positions[i], axis=1)\n                neighborhood_indices = np.where(distances <= self.neighborhood_radius)[0]\n                if len(neighborhood_indices) > 0:\n                    neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                    best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                    neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n                else:\n                     neighborhood_best_positions[i] = personal_best_positions[i].copy() #Use self if no neighbors\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Update Neighborhood Radius\n            self.neighborhood_radius *= self.radius_decay\n\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\".\n            m = np.mean(swarm, axis=0) #Reset mean using swarm\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveNeighborhoodCMAES scored 0.353 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3be0900-a9f9-4f06-a39a-f7ea0a20a18c"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive radius neighborhood-based ACS with CMA-ES, dynamically adjusting search intensity based on function evaluations and using a more robust covariance matrix adaptation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveNeighborhoodCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_radius=1.0, radius_decay=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.initial_neighborhood_radius = initial_neighborhood_radius\n        self.radius_decay = radius_decay\n        self.neighborhood_radius = initial_neighborhood_radius\n\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        B = np.eye(self.dim)  # Eigenvectors of C\n        D = np.ones(self.dim)   # Eigenvalues of C\n        invsqrtC = np.eye(self.dim) # C^-1/2\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = np.full(self.pop_size, np.inf)\n\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = m + self.sigma * z @ invsqrtC.T #Using precomputed inverse square root\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma @ invsqrtC\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Robust Covariance Matrix Adaptation using eigenvalue decomposition\n            try:\n                D, B = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                D = np.diag(C) #Fall back to diagonal if needed\n                B = np.eye(self.dim) #Identity matrix\n            \n            D = np.maximum(D, 1e-8)  # Avoid zero eigenvalues\n            C = B @ np.diag(D) @ B.T  # Reconstruct C\n            invsqrtC = B @ np.diag(D**(-0.5)) @ B.T #Precompute inverse sqrt\n\n            # Adaptive Cooperative Swarm Component\n            # Update personal bests\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = x[i].copy()\n\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / (func.max_evaluations if hasattr(func, 'max_evaluations') and func.max_evaluations else self.budget))  if (hasattr(func, 'max_evaluations') and func.max_evaluations) or self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence with radius\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(personal_best_positions - personal_best_positions[i], axis=1)\n                neighborhood_indices = np.where(distances <= self.neighborhood_radius)[0]\n                if len(neighborhood_indices) > 0:\n                    neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                    best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                    neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n                else:\n                     neighborhood_best_positions[i] = personal_best_positions[i].copy() #Use self if no neighbors\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Update Neighborhood Radius\n            self.neighborhood_radius *= self.radius_decay\n\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\".\n            m = np.mean(swarm, axis=0) #Reset mean using swarm\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07580465348583909, 0.28189693172502717, 0.4205456636087117, 0.46072025488548685, 0.3798653252673816, 0.3804644470789391, 0.2944556555212404, 0.33541392748996346, 0.28854556323051284, 0.17375075754719305, 0.35825229347842524, 0.9992738317868549, 0.20743431447347893, 0.3121189966605028, 0.7031105484977442, 0.26742823593746645, 0.3688810814620632, 0.1477077720765364, 0.14978076244603122, 0.45176489268035824], "operator": "mutation", "theta_sampled": 0.03691828310139558, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "a2888880-2403-4e30-b4cd-af6eb5865f9a", "fitness": 0.0, "name": "AdaptivePopulationSearch", "description": "Population-based search with adaptive mutation and crossover operators, guided by fitness landscape characteristics.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def mutate(self, individual, func):\n        mutated_individual = individual.copy()\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                mutated_individual[i] += np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb))  # Adaptive mutation step size\n                mutated_individual[i] = np.clip(mutated_individual[i], func.bounds.lb, func.bounds.ub)\n        return mutated_individual\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        else:\n            child = parent1  # No crossover\n        return child\n\n    def selection(self):\n        # Tournament selection\n        tournament_size = 3\n        selected_indices = []\n        for _ in range(self.pop_size):\n            candidates = np.random.choice(self.pop_size, tournament_size, replace=False)\n            winner = candidates[np.argmin(self.fitness[candidates])]\n            selected_indices.append(winner)\n        return selected_indices\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            selected_indices = self.selection()\n            new_population = []\n            new_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                parent1 = self.population[selected_indices[i]]\n                parent2_index = np.random.choice(self.pop_size)\n                parent2 = self.population[selected_indices[parent2_index]]\n\n                child = self.crossover(parent1, parent2)\n                mutated_child = self.mutate(child, func)\n\n                f = func(mutated_child)\n                self.eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = mutated_child\n\n                new_population.append(mutated_child)\n                new_fitness[i] = f\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.population = np.array(new_population)\n            self.fitness = new_fitness\n            \n            # Adaptive Mutation Rate Adjustment (example - can be improved):\n            if np.std(self.fitness) < 1e-3:  #Stagnation detection.\n                self.mutation_rate = min(0.5, self.mutation_rate * 1.2)  #Increase exploration if stagnating\n            else:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.95) #Reduce if doing well\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with adaptive mutation and crossover operators, guided by fitness landscape characteristics.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def mutate(self, individual, func):\n        mutated_individual = individual.copy()\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                mutated_individual[i] += np.random.normal(0, 0.1 * (func.bounds.ub - func.bounds.lb))  # Adaptive mutation step size\n                mutated_individual[i] = np.clip(mutated_individual[i], func.bounds.lb, func.bounds.ub)\n        return mutated_individual\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        else:\n            child = parent1  # No crossover\n        return child\n\n    def selection(self):\n        # Tournament selection\n        tournament_size = 3\n        selected_indices = []\n        for _ in range(self.pop_size):\n            candidates = np.random.choice(self.pop_size, tournament_size, replace=False)\n            winner = candidates[np.argmin(self.fitness[candidates])]\n            selected_indices.append(winner)\n        return selected_indices\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            selected_indices = self.selection()\n            new_population = []\n            new_fitness = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                parent1 = self.population[selected_indices[i]]\n                parent2_index = np.random.choice(self.pop_size)\n                parent2 = self.population[selected_indices[parent2_index]]\n\n                child = self.crossover(parent1, parent2)\n                mutated_child = self.mutate(child, func)\n\n                f = func(mutated_child)\n                self.eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = mutated_child\n\n                new_population.append(mutated_child)\n                new_fitness[i] = f\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.population = np.array(new_population)\n            self.fitness = new_fitness\n            \n            # Adaptive Mutation Rate Adjustment (example - can be improved):\n            if np.std(self.fitness) < 1e-3:  #Stagnation detection.\n                self.mutation_rate = min(0.5, self.mutation_rate * 1.2)  #Increase exploration if stagnating\n            else:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.95) #Reduce if doing well\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.027009778668111117, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "f17ee9ce-ef6a-4da3-b104-986decf87dd4", "fitness": 0.4481266528689716, "name": "AdaptiveDES", "description": "An adaptive differential evolution strategy with a self-adjusting population size based on the function's landscape.", "code": "import numpy as np\n\nclass AdaptiveDES:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor  # initial population size factor\n        self.pop_size = int(self.dim * self.pop_size_factor)\n        self.cr = 0.7  # Crossover rate\n        self.f = 0.8   # Mutation factor\n        self.min_pop_size = 4 # Ensure sufficient diversity, needed for DE\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adaptive population size adjustment\n            if self.evals > self.budget / 2:\n                 self.pop_size = max(self.min_pop_size, int(self.pop_size_factor * self.dim * (1 - (self.evals - self.budget/2) / (self.budget/2)))) # Reduce pop size linearly\n                 self.population = self.population[:self.pop_size]\n                 self.fitness = self.fitness[:self.pop_size]\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                  idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.f * (x2 - x3) # Ensure the individual contributes by adding it\n\n                # Crossover\n                u = np.copy(self.population[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        u[j] = v[j]\n\n                # Boundary check\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(u)\n                self.evals += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = u\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDES scored 0.448 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy with a self-adjusting population size based on the function's landscape.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDES:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor  # initial population size factor\n        self.pop_size = int(self.dim * self.pop_size_factor)\n        self.cr = 0.7  # Crossover rate\n        self.f = 0.8   # Mutation factor\n        self.min_pop_size = 4 # Ensure sufficient diversity, needed for DE\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            # Adaptive population size adjustment\n            if self.evals > self.budget / 2:\n                 self.pop_size = max(self.min_pop_size, int(self.pop_size_factor * self.dim * (1 - (self.evals - self.budget/2) / (self.budget/2)))) # Reduce pop size linearly\n                 self.population = self.population[:self.pop_size]\n                 self.fitness = self.fitness[:self.pop_size]\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                  idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.f * (x2 - x3) # Ensure the individual contributes by adding it\n\n                # Crossover\n                u = np.copy(self.population[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        u[j] = v[j]\n\n                # Boundary check\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f = func(u)\n                self.evals += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = u\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = u\n\n                if self.evals >= self.budget:\n                    break\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14618832537315662, 0.2815866827906047, 0.4339321035268887, 0.585310138229038, 0.39497268090923776, 0.5767869294281, 0.3138135702196744, 0.38244250462076657, 0.3536234447384453, 0.19709254597462522, 0.6339293534433497, 0.9985233543119713, 0.31126402224868577, 0.31913300193379057, 0.833179391969123, 0.5068925556855075, 0.3443391140521084, 0.6788884406941071, 0.18286228147603212, 0.4877726157542188], "operator": "random_new", "theta_sampled": 0.004207001408960105, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "5f01b7b3-5f22-40b5-8562-e0e2bd57b92a", "fitness": 0.16319582410796896, "name": "AdaptiveShrinkingDE", "description": "Adaptive Differential Evolution with shrinking population and local search injection, focusing on exploration early and exploitation later in the optimization process.", "code": "import numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.7, cr=0.5, local_search_frequency=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.f = f\n        self.cr = cr\n        self.local_search_frequency = local_search_frequency\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            # Adaptive F and CR (SADE inspired)\n            f = np.random.normal(self.f, 0.1, self.pop_size)\n            f = np.clip(f, 0.1, 1.0)  # Ensure F is within reasonable bounds\n\n            cr = np.random.normal(self.cr, 0.1, self.pop_size)\n            cr = np.clip(cr, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + f[i] * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                x_trial = np.clip(x_trial, lb, ub)\n\n                # Local search injection (randomly)\n                if np.random.rand() < self.local_search_frequency:\n                    x_trial = self.local_search(func, x_trial, lb, ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Shrink population size (linear reduction)\n            reduction_factor = 1 - (self.eval_count / self.budget)\n            new_pop_size = int(self.pop_size * reduction_factor)\n            if new_pop_size > 2*self.dim and new_pop_size < self.pop_size:\n                best_indices = np.argsort(self.fitness)[:new_pop_size]\n                self.pop = self.pop[best_indices]\n                self.fitness = self.fitness[best_indices]\n                self.pop_size = new_pop_size\n\n\n        return self.f_opt, self.x_opt\n    \n    def local_search(self, func, x, lb, ub, step_size=0.1):\n        \"\"\"Performs a simple local search around a given solution.\"\"\"\n        x_best = x\n        f_best = func(x)\n        self.eval_count +=1\n        for _ in range(5): # Few iterations\n            x_neighbor = x + np.random.uniform(-step_size, step_size, self.dim)\n            x_neighbor = np.clip(x_neighbor, lb, ub)\n            f_neighbor = func(x_neighbor)\n            self.eval_count +=1\n            if f_neighbor < f_best and self.eval_count < self.budget:\n                f_best = f_neighbor\n                x_best = x_neighbor\n        \n        return x_best", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveShrinkingDE scored 0.163 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with shrinking population and local search injection, focusing on exploration early and exploitation later in the optimization process.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.7, cr=0.5, local_search_frequency=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.f = f\n        self.cr = cr\n        self.local_search_frequency = local_search_frequency\n        self.eval_count = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            # Adaptive F and CR (SADE inspired)\n            f = np.random.normal(self.f, 0.1, self.pop_size)\n            f = np.clip(f, 0.1, 1.0)  # Ensure F is within reasonable bounds\n\n            cr = np.random.normal(self.cr, 0.1, self.pop_size)\n            cr = np.clip(cr, 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + f[i] * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                x_trial = np.clip(x_trial, lb, ub)\n\n                # Local search injection (randomly)\n                if np.random.rand() < self.local_search_frequency:\n                    x_trial = self.local_search(func, x_trial, lb, ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            # Shrink population size (linear reduction)\n            reduction_factor = 1 - (self.eval_count / self.budget)\n            new_pop_size = int(self.pop_size * reduction_factor)\n            if new_pop_size > 2*self.dim and new_pop_size < self.pop_size:\n                best_indices = np.argsort(self.fitness)[:new_pop_size]\n                self.pop = self.pop[best_indices]\n                self.fitness = self.fitness[best_indices]\n                self.pop_size = new_pop_size\n\n\n        return self.f_opt, self.x_opt\n    \n    def local_search(self, func, x, lb, ub, step_size=0.1):\n        \"\"\"Performs a simple local search around a given solution.\"\"\"\n        x_best = x\n        f_best = func(x)\n        self.eval_count +=1\n        for _ in range(5): # Few iterations\n            x_neighbor = x + np.random.uniform(-step_size, step_size, self.dim)\n            x_neighbor = np.clip(x_neighbor, lb, ub)\n            f_neighbor = func(x_neighbor)\n            self.eval_count +=1\n            if f_neighbor < f_best and self.eval_count < self.budget:\n                f_best = f_neighbor\n                x_best = x_neighbor\n        \n        return x_best\n```", "aucs": [0.1844382780588636, 0.3051491942650433, 0], "operator": "random_new", "theta_sampled": -0.003081306612838161, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "9a92ab6d-cefc-4c91-9ffd-589e8c32ed30", "fitness": 0.15366241149013912, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success rate of previous generations, combined with a restart strategy to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                        \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    new_population[i] = x_trial\n                    new_fitness[i] = f_trial\n                else:\n                    new_population[i] = self.population[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = np.where(new_fitness < self.fitness)[0]\n            if len(success_indices) > 0:\n                F_success = self.F\n                Cr_success = self.Cr\n                #if len(success_indices) > 0:\n                #    F_success = np.mean([self.F for i in success_indices])\n                #    Cr_success = np.mean([self.Cr for i in success_indices])\n                self.F = 0.9 * self.F + 0.1 * F_success\n                self.Cr = 0.9 * self.Cr + 0.1 * Cr_success\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Restart strategy\n            if np.random.rand() < self.restart_prob:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.154 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success rate of previous generations, combined with a restart strategy to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, restart_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                        \n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    new_population[i] = x_trial\n                    new_fitness[i] = f_trial\n                else:\n                    new_population[i] = self.population[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive F and Cr (adjust based on success)\n            success_indices = np.where(new_fitness < self.fitness)[0]\n            if len(success_indices) > 0:\n                F_success = self.F\n                Cr_success = self.Cr\n                #if len(success_indices) > 0:\n                #    F_success = np.mean([self.F for i in success_indices])\n                #    Cr_success = np.mean([self.Cr for i in success_indices])\n                self.F = 0.9 * self.F + 0.1 * F_success\n                self.Cr = 0.9 * self.Cr + 0.1 * Cr_success\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Restart strategy\n            if np.random.rand() < self.restart_prob:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                if np.min(self.fitness) < self.f_opt:\n                    self.f_opt = np.min(self.fitness)\n                    self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11492618659430665, 0.2023213263473157, 0.29740213301893414, 0], "operator": "random_new", "theta_sampled": 0.020284366837109293, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "8f90810f-1d69-4376-a146-93892a6f7e8a", "fitness": 0.0, "name": "AdaptiveCooperativeSwarm", "description": "Adaptive Cooperative Swarm with velocity clamping, dynamic neighborhood size, and mutation to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size # Initial Neighborhood size\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (generation / (self.budget + generation)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                #Dynamic neighborhood size\n                current_neighborhood_size = min(self.swarm_size, max(1, int(self.neighborhood_size * (1 + np.random.normal(0, 0.1))))) # Small random adjustments\n\n                neighborhood_indices = np.arange(max(0, i - current_neighborhood_size // 2), min(self.swarm_size, i + current_neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            #Mutation\n            mutation_mask = np.random.rand(self.swarm_size, self.dim) < self.mutation_rate\n            swarm[mutation_mask] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=np.sum(mutation_mask))\n\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Cooperative Swarm with velocity clamping, dynamic neighborhood size, and mutation to enhance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, initial_neighborhood_size=3, velocity_clamp=0.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = initial_neighborhood_size # Initial Neighborhood size\n        self.velocity_clamp = velocity_clamp\n        self.mutation_rate = mutation_rate\n\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (generation / (self.budget + generation)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                #Dynamic neighborhood size\n                current_neighborhood_size = min(self.swarm_size, max(1, int(self.neighborhood_size * (1 + np.random.normal(0, 0.1))))) # Small random adjustments\n\n                neighborhood_indices = np.arange(max(0, i - current_neighborhood_size // 2), min(self.swarm_size, i + current_neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            #Mutation\n            mutation_mask = np.random.rand(self.swarm_size, self.dim) < self.mutation_rate\n            swarm[mutation_mask] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=np.sum(mutation_mask))\n\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n        return global_best_fitness, global_best_position\n```", "operator": "mutation", "theta_sampled": 0.0039627213301383244, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "eb6fe76e-a959-4125-901c-2989fa4f096a", "fitness": 0.7094004168672018, "name": "HybridCMAES_ACS", "description": "Combines CMA-ES with a velocity-clamping ACS and a restart mechanism triggered by stagnation in the CMA-ES covariance matrix adaptation.", "code": "import numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3,\n                 velocity_clamp=0.5): # Added velocity clamp\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp  # Added velocity clamp\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C_trace_history = []\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n        stagnation_counter = 0 # Counter for stagnation\n        max_stagnation = 50 # Restart after this many iterations of no improvement\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter += 1\n\n            # Restart mechanism\n            if stagnation_counter > max_stagnation:\n                # Reset CMA-ES parameters\n                m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.sigma = 0.5  # Reset sigma too\n                stagnation_counter = 0\n                print(\"Restarting CMA-ES due to stagnation.\")\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCMAES_ACS scored 0.709 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3be0900-a9f9-4f06-a39a-f7ea0a20a18c"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines CMA-ES with a velocity-clamping ACS and a restart mechanism triggered by stagnation in the CMA-ES covariance matrix adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3,\n                 velocity_clamp=0.5): # Added velocity clamp\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp  # Added velocity clamp\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C_trace_history = []\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n        stagnation_counter = 0 # Counter for stagnation\n        max_stagnation = 50 # Restart after this many iterations of no improvement\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                stagnation_counter = 0 # Reset stagnation counter\n            else:\n                stagnation_counter += 1\n\n            # Restart mechanism\n            if stagnation_counter > max_stagnation:\n                # Reset CMA-ES parameters\n                m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.sigma = 0.5  # Reset sigma too\n                stagnation_counter = 0\n                print(\"Restarting CMA-ES due to stagnation.\")\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n            \n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n            # Velocity Clamping\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19138203283762933, 0.8353775855695146, 0.9484311657084894, 0.6530475295322282, 0.9651570823969099, 0.9716935126508321, 0.31361417838977446, 0.9415957643697609, 0.9527959174094808, 0.261530867650962, 0.9686273142211086, 0.9764639554824676, 0.2505304213074895, 0.9548488108352512, 0.9550487437477689, 0.5342784252923245, 0.7440151146204005, 0.9672836313084542, 0.3019152900203228, 0.5003709939928646], "operator": "mutation", "theta_sampled": 0.012377778284226459, "reward": 0.045822083792120494, "generation": 6}, "task_prompt": ""}
{"id": "875d4b19-65c2-45e5-b5d8-b0190b837b58", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "Implements a CMA-ES variant with orthogonal crossover, adaptive population sizing, and covariance matrix regularization for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, adaptive_popsize=True, min_popsize=4):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.adaptive_popsize = adaptive_popsize\n        self.min_popsize = min_popsize\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive Population Sizing\n            if self.adaptive_popsize:\n                # dynamically adjust pop_size based on budget and iteration\n                remaining_budget_ratio = self.budget / 10000  # Assuming initial budget is 10000\n                self.pop_size = max(self.min_popsize, int((4 + 3 * np.log(self.dim)) * remaining_budget_ratio + 1))  # Ensuring a minimum pop_size\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n                self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Regularize covariance matrix to prevent it from becoming ill-conditioned\n            C = np.linalg.MatrixRankWarning(C)\n            min_eig = np.min(np.linalg.eigvalsh(C))\n            if min_eig < 1e-10:\n               C += (1e-10 - min_eig) * np.eye(self.dim)\n\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: module 'numpy.linalg' has no attribute 'MatrixRankWarning'", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements a CMA-ES variant with orthogonal crossover, adaptive population sizing, and covariance matrix regularization for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25, adaptive_popsize=True, min_popsize=4):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.mu_ratio = mu_ratio\n        self.adaptive_popsize = adaptive_popsize\n        self.min_popsize = min_popsize\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        self.f_opt = np.inf\n        self.x_opt = None\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive Population Sizing\n            if self.adaptive_popsize:\n                # dynamically adjust pop_size based on budget and iteration\n                remaining_budget_ratio = self.budget / 10000  # Assuming initial budget is 10000\n                self.pop_size = max(self.min_popsize, int((4 + 3 * np.log(self.dim)) * remaining_budget_ratio + 1))  # Ensuring a minimum pop_size\n                self.mu = int(self.pop_size * self.mu_ratio)\n                self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n                self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n\n            # Generate and evaluate offspring\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n                \n            # Selection and recombination\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc # Prevents division by zero\n            \n            # Update covariance matrix\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Regularize covariance matrix to prevent it from becoming ill-conditioned\n            C = np.linalg.MatrixRankWarning(C)\n            min_eig = np.min(np.linalg.eigvalsh(C))\n            if min_eig < 1e-10:\n               C += (1e-10 - min_eig) * np.eye(self.dim)\n\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.010346005067340621, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "1b06efd6-294b-4c9a-8dec-5306f2993bc2", "fitness": 0.3306098078065084, "name": "AdaptiveHybridDEPSO", "description": "Population-based algorithm that combines aspects of differential evolution and particle swarm optimization, adaptively adjusting parameters based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7 # Crossover rate\n        self.w = 0.7  # Inertia weight (PSO)\n        self.c1 = 1.5  # Cognitive coefficient (PSO)\n        self.c2 = 1.5  # Social coefficient (PSO)\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive parameter adjustment based on population diversity\n            diversity = np.std(population)\n            self.F = 0.3 + 0.7 * np.exp(-diversity) #Adapt F based on diversity\n            self.CR = 0.1 + 0.8 * np.exp(-diversity) #Adapt CR based on diversity\n            self.w = 0.4 + 0.5 * np.exp(-diversity) # Adapt w based on diversity\n\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                v_i = population[i] + self.F * (x_r2 - x_r3)\n                v_i = np.clip(v_i, self.lb, self.ub) #Clip values\n\n\n                # Crossover\n                u_i = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.CR or j == np.random.randint(0, self.dim):\n                        u_i[j] = v_i[j]\n                    else:\n                        u_i[j] = population[i][j]\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = self.w * (u_i - population[i]) + self.c1 * np.random.rand() * (personal_best_positions[i] - u_i) + self.c2 * np.random.rand() * (global_best_position - u_i)\n\n                # Update position\n                new_position = u_i + velocity\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break # Break out of inner loop if budget is exhausted\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n                \n                population[i] = new_position #update population\n                fitness[i] = new_fitness\n\n            if self.budget <= 0:\n                break  # Break out of outer loop if budget is exhausted\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridDEPSO scored 0.331 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines aspects of differential evolution and particle swarm optimization, adaptively adjusting parameters based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7 # Crossover rate\n        self.w = 0.7  # Inertia weight (PSO)\n        self.c1 = 1.5  # Cognitive coefficient (PSO)\n        self.c2 = 1.5  # Social coefficient (PSO)\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive parameter adjustment based on population diversity\n            diversity = np.std(population)\n            self.F = 0.3 + 0.7 * np.exp(-diversity) #Adapt F based on diversity\n            self.CR = 0.1 + 0.8 * np.exp(-diversity) #Adapt CR based on diversity\n            self.w = 0.4 + 0.5 * np.exp(-diversity) # Adapt w based on diversity\n\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                v_i = population[i] + self.F * (x_r2 - x_r3)\n                v_i = np.clip(v_i, self.lb, self.ub) #Clip values\n\n\n                # Crossover\n                u_i = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() <= self.CR or j == np.random.randint(0, self.dim):\n                        u_i[j] = v_i[j]\n                    else:\n                        u_i[j] = population[i][j]\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = self.w * (u_i - population[i]) + self.c1 * np.random.rand() * (personal_best_positions[i] - u_i) + self.c2 * np.random.rand() * (global_best_position - u_i)\n\n                # Update position\n                new_position = u_i + velocity\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break # Break out of inner loop if budget is exhausted\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position.copy()\n\n                # Update global best\n                if new_fitness < global_best_fitness:\n                    global_best_fitness = new_fitness\n                    global_best_position = new_position.copy()\n                \n                population[i] = new_position #update population\n                fitness[i] = new_fitness\n\n            if self.budget <= 0:\n                break  # Break out of outer loop if budget is exhausted\n\n        return global_best_fitness, global_best_position\n```", "aucs": [0.17712803512911268, 0.18835378365213096, 0.2755776963390367, 0.1729372224294935, 0.1928678198005136, 0.4144163598614402, 0.2667957842468788, 0.31330772902318926, 0.23376151126452072, 0.19995453190111956, 0.30792995212138186, 0.9955485150831881, 0.20166192556213902, 0.33643616522748265, 0.5785886820190993, 0.5877431304708031, 0.226466958715285, 0.3034662100597084, 0.2242968595973106, 0.4149572836263338], "operator": "random_new", "theta_sampled": 0.007408104592497111, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "9729c86b-abb3-43dc-b8a7-680f3934e6e4", "fitness": 0.0, "name": "SelfAdaptiveCooperativeSwarm", "description": "Implements a self-adaptive cooperative swarm with velocity clamping and dynamic parameter adjustments based on swarm diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp #Clamp on the velocities, to prevent explosion\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            #Self-adaptive parameters (adjusting cognitive/social coefficients based on swarm diversity)\n            diversity = np.std(swarm)\n            if diversity < 0.1 * (func.bounds.ub - func.bounds.lb): #If swarm is too concentrated\n                self.cognitive_coeff *= 1.05 #Increase cognitive to promote exploration\n                self.social_coeff *= 0.95    #Decrease social to reduce convergence\n            elif diversity > 0.5 * (func.bounds.ub - func.bounds.lb): #If swarm is too diverse\n                self.cognitive_coeff *= 0.95 #Decrease cognitive to promote convergence\n                self.social_coeff *= 1.05    #Increase social to enhance convergence\n\n            self.cognitive_coeff = np.clip(self.cognitive_coeff, 1.0, 2.5)\n            self.social_coeff = np.clip(self.social_coeff, 1.0, 2.5)\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["394201bd-9623-4f78-ae2a-ed331d5282e9"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements a self-adaptive cooperative swarm with velocity clamping and dynamic parameter adjustments based on swarm diversity.\n# Code:\n```python\nimport numpy as np\n\nclass SelfAdaptiveCooperativeSwarm:\n    def __init__(self, budget=10000, dim=10, swarm_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.velocity_clamp = velocity_clamp #Clamp on the velocities, to prevent explosion\n\n    def __call__(self, func):\n        # Initialize the swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        # Evaluate initial positions\n        fitness = np.array([func(x) for x in swarm])\n        self.budget -= self.swarm_size\n\n        # Find the global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = swarm[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index].copy()\n\n        # Initialize personal bests\n        personal_best_positions = swarm.copy()\n        personal_best_fitness = fitness.copy()\n\n        #Adaptive Inertia\n        inertia = self.inertia_max\n\n        while self.budget > 0:\n            #Update inertia adaptively\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - (self.budget / self.budget)) #Linear decreasing\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.swarm_size, self.dim)\n            r2 = np.random.rand(self.swarm_size, self.dim)\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.swarm_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.swarm_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm)) #Neighborhood best replaces global best\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n\n\n            swarm = swarm + velocities\n\n            # Clip to bounds\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate new positions\n            new_fitness = np.array([func(x) for x in swarm])\n            eval_count = len(new_fitness)\n            self.budget -= eval_count\n\n            # Update personal bests\n            improvement = new_fitness < personal_best_fitness\n            personal_best_fitness[improvement] = new_fitness[improvement]\n            personal_best_positions[improvement] = swarm[improvement].copy()\n\n            # Update global best\n            best_index_in_batch = np.argmin(new_fitness)\n\n            if new_fitness[best_index_in_batch] < global_best_fitness:\n                global_best_fitness = new_fitness[best_index_in_batch].copy()\n                global_best_position = swarm[best_index_in_batch].copy()\n\n            #Self-adaptive parameters (adjusting cognitive/social coefficients based on swarm diversity)\n            diversity = np.std(swarm)\n            if diversity < 0.1 * (func.bounds.ub - func.bounds.lb): #If swarm is too concentrated\n                self.cognitive_coeff *= 1.05 #Increase cognitive to promote exploration\n                self.social_coeff *= 0.95    #Decrease social to reduce convergence\n            elif diversity > 0.5 * (func.bounds.ub - func.bounds.lb): #If swarm is too diverse\n                self.cognitive_coeff *= 0.95 #Decrease cognitive to promote convergence\n                self.social_coeff *= 1.05    #Increase social to enhance convergence\n\n            self.cognitive_coeff = np.clip(self.cognitive_coeff, 1.0, 2.5)\n            self.social_coeff = np.clip(self.social_coeff, 1.0, 2.5)\n\n        return global_best_fitness, global_best_position\n```", "operator": "mutation", "theta_sampled": 0.01944706597788531, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "00fac12e-f257-4e05-9626-12693f4c7107", "fitness": 0.40047159256090736, "name": "HybridCMAES_ACS_OAx", "description": "A hybrid CMA-ES and Adaptive Cooperative Swarm algorithm with orthogonal crossover and a dynamic population size based on budget.", "code": "import numpy as np\n\nclass HybridCMAES_ACS_OAx:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=3, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, oa_perturbation=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.oa_perturbation = oa_perturbation\n        self.pop_size_factor = pop_size_factor\n\n        # Dynamic population size based on remaining budget\n        self.pop_size = max(4, int(self.pop_size_factor * np.log(self.dim)))  # Initial pop size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Adjust population size dynamically\n            self.pop_size = min(self.budget, max(4, int(self.pop_size_factor * np.log(self.dim))))\n            self.mu = int(self.pop_size * self.mu_ratio)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            \n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, self.oa_perturbation, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * xo, axis=0) # Use xo instead of x_mu\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridCMAES_ACS_OAx scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "f3be0900-a9f9-4f06-a39a-f7ea0a20a18c"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid CMA-ES and Adaptive Cooperative Swarm algorithm with orthogonal crossover and a dynamic population size based on budget.\n# Code: \n```python\nimport numpy as np\n\nclass HybridCMAES_ACS_OAx:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=3, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, oa_perturbation=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.oa_perturbation = oa_perturbation\n        self.pop_size_factor = pop_size_factor\n\n        # Dynamic population size based on remaining budget\n        self.pop_size = max(4, int(self.pop_size_factor * np.log(self.dim)))  # Initial pop size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Adjust population size dynamically\n            self.pop_size = min(self.budget, max(4, int(self.pop_size_factor * np.log(self.dim))))\n            self.mu = int(self.pop_size * self.mu_ratio)\n            self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            self.weights = self.weights / np.sum(self.weights)\n            self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n            \n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, self.oa_perturbation, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * xo, axis=0) # Use xo instead of x_mu\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # The next CMA-ES iteration now starts with the updated swarm \"swarm\", which is based on both CMA-ES evolution and ACS-based social learning.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1866274411342782, 0.33531944545412773, 0.4074644118252342, 0.4974531833965461, 0.33712125463602616, 0.4239477100246387, 0.3099253191721921, 0.34073373044763344, 0.33601624258977536, 0.2320381312774339, 0.4564456864111518, 0.9919941538076512, 0.2569018038434083, 0.3489694218665862, 0.5855627753829837, 0.36789081756619, 0.3339732633283504, 0.5294514090685121, 0.227192956752581, 0.5044026932328474], "operator": "crossover", "theta_sampled": 0.05484926570329851, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "4ba2dc50-7d30-4efc-b157-ea519987bb3c", "fitness": 0.6363148426644459, "name": "CMAES_OAx_ACS", "description": "Integrates Orthogonal Crossover (OAx) from CMA-ES with an Adaptive Cooperative Swarm (ACS) to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass CMAES_OAx_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, oax_weight=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.oax_weight = oax_weight  # Weight for incorporating OAx solutions\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions.  Introduce OAx solutions into the swarm.\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Incorporate OAx solutions into the swarm\n            num_oax_to_incorporate = min(self.mu, self.pop_size)  # Incorporate at most mu OAx solutions\n            swarm[:num_oax_to_incorporate] = self.oax_weight * xo[:num_oax_to_incorporate] + (1 - self.oax_weight) * swarm[:num_oax_to_incorporate]\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm CMAES_OAx_ACS scored 0.636 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6cb5a7f2-badf-4c94-ab1b-f26c9e02bd85", "f3be0900-a9f9-4f06-a39a-f7ea0a20a18c"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Orthogonal Crossover (OAx) from CMA-ES with an Adaptive Cooperative Swarm (ACS) to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES_OAx_ACS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, mu_ratio=0.25,\n                 inertia_max=0.9, inertia_min=0.4, cognitive_coeff=1.8, social_coeff=1.8, neighborhood_size=3, oax_weight=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs  # Cumulation for step-size\n        self.damps = damps  # Damping for step-size\n        self.mu_ratio = mu_ratio\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.neighborhood_size = neighborhood_size\n        self.oax_weight = oax_weight  # Weight for incorporating OAx solutions\n\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n\n        self.mu = int(self.pop_size * self.mu_ratio)  # Number of parents/selected points\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        if ccov1 is None:\n            self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        else:\n            self.ccov1 = ccov1\n\n        if ccovmu is None:\n            self.ccovmu = 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        else:\n            self.ccovmu = ccovmu\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize mean, covariance matrix, and evolution paths (CMA-ES)\n        m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # Initialize swarm (ACS)\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(swarm)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0 # Keep track of evaluations\n\n        while self.budget > 0:\n            # Generate and evaluate offspring (CMA-ES-inspired sampling)\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n            except np.linalg.LinAlgError:\n                # Handle non-positive definite covariance matrix\n                C = C + 1e-8 * np.eye(self.dim)\n                A = np.linalg.cholesky(C)\n                x = m + self.sigma * z @ A.T\n\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            eval_count += self.pop_size\n            self.budget -= self.pop_size\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = x[best_index]\n            \n            # Selection and recombination (CMA-ES)\n            indices = np.argsort(fitness)\n            x_mu = x[indices[:self.mu]]\n            z_mu = z[indices[:self.mu]]\n\n            # Orthogonal Crossover (OAx) - Create new offspring\n            xo = np.zeros((self.mu, self.dim))\n            for i in range(self.mu):\n                xo[i] = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0) + np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n\n            # Calculate new mean\n            m_old = m.copy()\n            m = np.sum(self.weights.reshape(-1, 1) * x_mu, axis=0)\n\n            # Update evolution paths (CMA-ES)\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (m - m_old) / self.sigma\n            pc = (1 - self.cc) * pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (m - m_old) / self.sigma / np.sqrt(np.sum(ps**2)) if np.sum(ps**2) > 0 else (1 - self.cc) * pc\n            \n            # Update covariance matrix (CMA-ES)\n            C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc)\n            C += self.ccovmu * np.sum(self.weights.reshape(-1, 1, 1) * (z_mu[:, :, np.newaxis] @ z_mu[:, np.newaxis, :]), axis=0)\n\n            # Adapt step size (CMA-ES)\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Adaptive Cooperative Swarm Component\n            # Calculate personal bests (swarm is same as x after CMA-ES update)\n            personal_best_positions = x.copy()\n            personal_best_fitness = fitness.copy()\n\n            # Adaptive Inertia\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (eval_count / self.budget) if self.budget > 0 else self.inertia_min # Linear decreasing\n\n            # Neighborhood best influence\n            neighborhood_best_positions = np.zeros_like(swarm)\n            for i in range(self.pop_size):\n                neighborhood_indices = np.arange(max(0, i - self.neighborhood_size // 2), min(self.pop_size, i + self.neighborhood_size // 2 + 1))\n                neighborhood_fitnesses = personal_best_fitness[neighborhood_indices]\n                best_index_in_neighborhood = neighborhood_indices[np.argmin(neighborhood_fitnesses)]\n                neighborhood_best_positions[i] = personal_best_positions[best_index_in_neighborhood].copy()\n\n            # Update velocities\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - swarm) +\n                          self.social_coeff * r2 * (neighborhood_best_positions - swarm))\n\n            # Update swarm positions.  Introduce OAx solutions into the swarm.\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n            # Incorporate OAx solutions into the swarm\n            num_oax_to_incorporate = min(self.mu, self.pop_size)  # Incorporate at most mu OAx solutions\n            swarm[:num_oax_to_incorporate] = self.oax_weight * xo[:num_oax_to_incorporate] + (1 - self.oax_weight) * swarm[:num_oax_to_incorporate]\n            swarm = np.clip(swarm, func.bounds.lb, func.bounds.ub)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21699328889775726, 0.18155839042438515, 0.9472909760040564, 0.9662455353845445, 0.9454921675895329, 0.9581215238952083, 0.35195058469134577, 0.9369451397878739, 0.9453468069674924, 0.11353197892772338, 0.9322938724957689, 0.9903235266830016, 0.25389708368113206, 0.9519100219035771, 0.5862975413317673, 0.3853104119553835, 0.34442456655678044, 0.9709987547815343, 0.2570625074797318, 0.49030217385031916], "operator": "crossover", "theta_sampled": 0.30573533780083323, "reward": 0.0, "generation": 6}, "task_prompt": ""}
