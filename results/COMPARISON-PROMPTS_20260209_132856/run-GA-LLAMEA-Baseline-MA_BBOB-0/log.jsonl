{"id": "90ae0375-63c4-43ab-8641-7ae0ddae914d", "fitness": 0.1914405620483372, "name": "AdaptiveBacterialForaging", "description": "Population-based algorithm inspired by bacterial foraging optimization, incorporating a velocity update mechanism and adaptive step sizes.", "code": "import numpy as np\n\nclass AdaptiveBacterialForaging:\n    def __init__(self, budget=10000, dim=10, pop_size=20, tumble_prob=0.1, step_size_init=0.1, attract_repel_strength=0.01, dampening_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.tumble_prob = tumble_prob\n        self.step_size = step_size_init\n        self.attract_repel_strength = attract_repel_strength\n        self.dampening_factor = dampening_factor\n        self.positions = None\n        self.fitness = None\n        self.velocities = None\n        self.lb = None\n        self.ub = None\n\n    def _initialize_population(self):\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n        self.eval_count = 0\n    \n    def _evaluate_fitness(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf:  # Evaluate only if not yet evaluated\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.positions[i])\n                    self.eval_count += 1\n\n    def _tumble(self):\n        return np.random.uniform(-1, 1, size=self.dim)\n\n    def _chemotaxis(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.tumble_prob:\n                tumble_direction = self._tumble()\n                \n                new_position = self.positions[i] + self.step_size * tumble_direction\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                if self.eval_count < self.budget:\n                    new_fitness = func(new_position)\n                    self.eval_count += 1\n                    if new_fitness < self.fitness[i]:\n                        self.positions[i] = new_position\n                        self.fitness[i] = new_fitness\n        \n\n    def _attract_repel(self):\n        for i in range(self.pop_size):\n            sum_distance = np.zeros(self.dim)\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    sum_distance += distance / (np.linalg.norm(distance) + 1e-8)  # Avoid division by zero\n            \n            self.velocities[i] = self.velocities[i] * self.dampening_factor + self.attract_repel_strength * sum_distance\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], self.lb, self.ub)\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self._initialize_population()\n        \n        while self.eval_count < self.budget:\n            self._evaluate_fitness(func)\n            self._chemotaxis(func)\n            self._attract_repel()\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.positions[best_index]\n            \n            self.step_size *= self.dampening_factor \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveBacterialForaging scored 0.191 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Population-based algorithm inspired by bacterial foraging optimization, incorporating a velocity update mechanism and adaptive step sizes.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveBacterialForaging:\n    def __init__(self, budget=10000, dim=10, pop_size=20, tumble_prob=0.1, step_size_init=0.1, attract_repel_strength=0.01, dampening_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.tumble_prob = tumble_prob\n        self.step_size = step_size_init\n        self.attract_repel_strength = attract_repel_strength\n        self.dampening_factor = dampening_factor\n        self.positions = None\n        self.fitness = None\n        self.velocities = None\n        self.lb = None\n        self.ub = None\n\n    def _initialize_population(self):\n        self.positions = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.fitness = np.full(self.pop_size, np.inf)\n        self.eval_count = 0\n    \n    def _evaluate_fitness(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == np.inf:  # Evaluate only if not yet evaluated\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.positions[i])\n                    self.eval_count += 1\n\n    def _tumble(self):\n        return np.random.uniform(-1, 1, size=self.dim)\n\n    def _chemotaxis(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.tumble_prob:\n                tumble_direction = self._tumble()\n                \n                new_position = self.positions[i] + self.step_size * tumble_direction\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                if self.eval_count < self.budget:\n                    new_fitness = func(new_position)\n                    self.eval_count += 1\n                    if new_fitness < self.fitness[i]:\n                        self.positions[i] = new_position\n                        self.fitness[i] = new_fitness\n        \n\n    def _attract_repel(self):\n        for i in range(self.pop_size):\n            sum_distance = np.zeros(self.dim)\n            for j in range(self.pop_size):\n                if i != j:\n                    distance = self.positions[j] - self.positions[i]\n                    sum_distance += distance / (np.linalg.norm(distance) + 1e-8)  # Avoid division by zero\n            \n            self.velocities[i] = self.velocities[i] * self.dampening_factor + self.attract_repel_strength * sum_distance\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], self.lb, self.ub)\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self._initialize_population()\n        \n        while self.eval_count < self.budget:\n            self._evaluate_fitness(func)\n            self._chemotaxis(func)\n            self._attract_repel()\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.positions[best_index]\n            \n            self.step_size *= self.dampening_factor \n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0.05979916583832179, 0.15892167712132688, 0.25672719693798185, 0.15029800262373172, 0.16135533591273343, 0.16279687448803704, 0.22075620275467978, 0.14345907226201104, 0.15964423397722016, 0.15451313372453168, 0.1566974067910465, 0.26258863721464465, 0.24851824953444024, 0.14817251936005937, 0.15181963756908445, 0.24220170503273386, 0.2272034351336104, 0.17125807160594253, 0.16807366057216278, 0.42400702251244415]}, "task_prompt": ""}
{"id": "d6ee9303-1b2a-4b17-a21c-95caff4cacc4", "fitness": 0.429307165349252, "name": "AdaptivePopulationSearch", "description": "A population-based algorithm with a novel exploration-exploitation balance using a dynamic adaptation of step size based on population diversity and individual success.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size #track function evals\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n\n        while evals < self.budget:\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            # Update individuals\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n                # Exploration: Random perturbation\n                exploration_candidate = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, lb, ub)\n                exploration_fitness = func(exploration_candidate)\n                evals += 1\n\n                # Exploitation: Move towards best\n                exploitation_candidate = population[i] + step_size[i] * (x_opt - population[i])\n                exploitation_candidate = np.clip(exploitation_candidate, lb, ub)\n                exploitation_fitness = func(exploitation_candidate)\n                evals += 1\n\n                # Selection: Choose the better candidate or keep the current one\n                if exploration_fitness < exploitation_fitness and exploration_fitness < fitness[i]:\n                    population[i] = exploration_candidate\n                    fitness[i] = exploration_fitness\n                    success = True\n                elif exploitation_fitness < exploration_fitness and exploitation_fitness < fitness[i]:\n                    population[i] = exploitation_candidate\n                    fitness[i] = exploitation_fitness\n                    success = True\n                else:\n                    success = False\n\n                # Adapt step size\n                if success:\n                    step_size[i] *= 1.1  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.9  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n\n        return f_opt, x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePopulationSearch scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm with a novel exploration-exploitation balance using a dynamic adaptation of step size based on population diversity and individual success.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size #track function evals\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n\n        while evals < self.budget:\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            # Update individuals\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n                # Exploration: Random perturbation\n                exploration_candidate = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, lb, ub)\n                exploration_fitness = func(exploration_candidate)\n                evals += 1\n\n                # Exploitation: Move towards best\n                exploitation_candidate = population[i] + step_size[i] * (x_opt - population[i])\n                exploitation_candidate = np.clip(exploitation_candidate, lb, ub)\n                exploitation_fitness = func(exploitation_candidate)\n                evals += 1\n\n                # Selection: Choose the better candidate or keep the current one\n                if exploration_fitness < exploitation_fitness and exploration_fitness < fitness[i]:\n                    population[i] = exploration_candidate\n                    fitness[i] = exploration_fitness\n                    success = True\n                elif exploitation_fitness < exploration_fitness and exploitation_fitness < fitness[i]:\n                    population[i] = exploitation_candidate\n                    fitness[i] = exploitation_fitness\n                    success = True\n                else:\n                    success = False\n\n                # Adapt step size\n                if success:\n                    step_size[i] *= 1.1  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.9  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n\n        return f_opt, x_opt\n```", "generation": 0, "operator": "init", "aucs": [0.1456092909679566, 0.19233813365442676, 0.4540211704290167, 0.7730950526363037, 0.25190855410693735, 0.5274129289993946, 0.27090552212062347, 0.41471386758916984, 0.39107361913747196, 0.1983320546010925, 0.747622379780828, 0.9969634013549951, 0.27310883624621096, 0.29414843771070254, 0.7188582503346117, 0.3379555332030716, 0.37531269230854114, 0.558653076174195, 0.20774923468551632, 0.4563612709439735]}, "task_prompt": ""}
{"id": "9731aa0e-bf0d-45df-a715-bda92334f620", "fitness": "-inf", "name": "AdaptiveDE", "description": "An adaptive differential evolution strategy that adjusts mutation and crossover rates based on function evaluation success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_CR = []\n        self.success_fitness_diff = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v = self.pop[i] + self.F * (x_r1 - x_r2)\n            # Clip the mutated vector to the bounds\n            v = np.clip(v, func.bounds.lb, func.bounds.ub)\n            yield v\n\n    def crossover(self, mutant, i):\n        trial = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def adapt_parameters(self):\n        if self.success_fitness_diff:  # Only adapt if there were successful generations\n            # Update mutation factor F (using Lehmer mean)\n            self.F = np.mean(np.square(self.success_F)) / np.mean(self.success_F) if np.any(self.success_F) else 0.5\n\n            # Update crossover rate CR (using arithmetic mean)\n            self.CR = np.mean(self.success_CR)\n\n            # Reset success memory\n            self.success_F = []\n            self.success_CR = []\n            self.success_fitness_diff = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutants = list(self.mutate())\n\n            for i, mutant in enumerate(mutants):\n                trial = self.crossover(mutant, i)\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful parameters\n                    self.success_fitness_diff.append(self.fitness[i] - f_trial)\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            self.adapt_parameters()\n            # Adjust F and CR to be within reasonable bounds.\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.0, 1.0)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 32, in mutate, the following error occurred:\nNameError: name 'func' is not defined\nOn line: v = np.clip(v, func.bounds.lb, func.bounds.ub)", "error": "In the code, line 32, in mutate, the following error occurred:\nNameError: name 'func' is not defined\nOn line: v = np.clip(v, func.bounds.lb, func.bounds.ub)", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy that adjusts mutation and crossover rates based on function evaluation success.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_CR = []\n        self.success_fitness_diff = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            v = self.pop[i] + self.F * (x_r1 - x_r2)\n            # Clip the mutated vector to the bounds\n            v = np.clip(v, func.bounds.lb, func.bounds.ub)\n            yield v\n\n    def crossover(self, mutant, i):\n        trial = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def adapt_parameters(self):\n        if self.success_fitness_diff:  # Only adapt if there were successful generations\n            # Update mutation factor F (using Lehmer mean)\n            self.F = np.mean(np.square(self.success_F)) / np.mean(self.success_F) if np.any(self.success_F) else 0.5\n\n            # Update crossover rate CR (using arithmetic mean)\n            self.CR = np.mean(self.success_CR)\n\n            # Reset success memory\n            self.success_F = []\n            self.success_CR = []\n            self.success_fitness_diff = []\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            mutants = list(self.mutate())\n\n            for i, mutant in enumerate(mutants):\n                trial = self.crossover(mutant, i)\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful parameters\n                    self.success_fitness_diff.append(self.fitness[i] - f_trial)\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            self.adapt_parameters()\n            # Adjust F and CR to be within reasonable bounds.\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.0, 1.0)\n            \n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "107a35c8-97e8-4c7e-9331-0bc91e121da7", "fitness": "-inf", "name": "AdaptiveDE", "description": "An adaptive Differential Evolution algorithm with self-adaptive parameters and a local search component to enhance exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.archive_rate = 0.1\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0:\n                    indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                    if indices[0] < self.pop_size:\n                        x1 = self.population[indices[0]]\n                    else:\n                        x1 = self.archive[indices[0]-self.pop_size]\n                    if indices[1] < self.pop_size:\n                        x2 = self.population[indices[1]]\n                    else:\n                        x2 = self.archive[indices[1]-self.pop_size]\n                    if indices[2] < self.pop_size:\n                        x3 = self.population[indices[2]]\n                    else:\n                        x3 = self.archive[indices[2]-self.pop_size]\n                else:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[indices[0]], self.population[indices[1]], self.population[indices[2]]\n\n                F = np.random.normal(self.F, 0.1, 1)[0]\n                F = np.clip(F, 0.1, 1.0)\n\n                v = self.population[i] + F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    Cr = np.random.normal(self.Cr, 0.1, 1)[0]\n                    Cr = np.clip(Cr, 0.1, 1.0)\n\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    u_local = np.copy(u)\n                    j_local = np.random.randint(self.dim)\n                    u_local[j_local] += np.random.uniform(-step_size, step_size)\n                    u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                    u = u_local\n\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if f_u < self.fitness[i]:\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.population[i])\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 68, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: u_local[j_local] += np.random.uniform(-step_size, step_size)", "error": "In the code, line 68, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: u_local[j_local] += np.random.uniform(-step_size, step_size)", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm with self-adaptive parameters and a local search component to enhance exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.archive_rate = 0.1\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0:\n                    indices = np.random.choice(self.pop_size + len(self.archive), 3, replace=False)\n                    if indices[0] < self.pop_size:\n                        x1 = self.population[indices[0]]\n                    else:\n                        x1 = self.archive[indices[0]-self.pop_size]\n                    if indices[1] < self.pop_size:\n                        x2 = self.population[indices[1]]\n                    else:\n                        x2 = self.archive[indices[1]-self.pop_size]\n                    if indices[2] < self.pop_size:\n                        x3 = self.population[indices[2]]\n                    else:\n                        x3 = self.archive[indices[2]-self.pop_size]\n                else:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[indices[0]], self.population[indices[1]], self.population[indices[2]]\n\n                F = np.random.normal(self.F, 0.1, 1)[0]\n                F = np.clip(F, 0.1, 1.0)\n\n                v = self.population[i] + F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    Cr = np.random.normal(self.Cr, 0.1, 1)[0]\n                    Cr = np.clip(Cr, 0.1, 1.0)\n\n                    if np.random.rand() < Cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    u_local = np.copy(u)\n                    j_local = np.random.randint(self.dim)\n                    u_local[j_local] += np.random.uniform(-step_size, step_size)\n                    u_local = np.clip(u_local, func.bounds.lb, func.bounds.ub)\n                    u = u_local\n\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if f_u < self.fitness[i]:\n                    if np.random.rand() < self.archive_rate:\n                        self.archive.append(self.population[i])\n                        if len(self.archive) > self.pop_size:\n                            self.archive.pop(0)\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "439a288b-573e-4ed6-8d65-be0a1cdbf028", "fitness": "-inf", "name": "AdaptiveDifferentialEvolution", "description": "A population-based algorithm with adaptive mutation and crossover operators, focusing on exploration and exploitation based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.archive_rate = 0.1\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0 and np.random.rand() < self.archive_rate:\n                    # Pick from archive sometimes to enhance exploration\n                    indices = np.random.choice(len(self.archive), 2, replace=False)\n                    x1 = self.archive[indices[0]]\n                    x2 = self.archive[indices[1]]\n                else:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[indices]\n                \n                mutant = self.population[i] + self.F * (x1 - x2)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant, self.population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    if len(self.archive) < self.pop_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        # Replace a random archive member\n                        idx = np.random.randint(self.pop_size)\n                        self.archive[idx] = self.population[i].copy()\n\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "error": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive mutation and crossover operators, focusing on exploration and exploitation based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.archive_rate = 0.1\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                if len(self.archive) > 0 and np.random.rand() < self.archive_rate:\n                    # Pick from archive sometimes to enhance exploration\n                    indices = np.random.choice(len(self.archive), 2, replace=False)\n                    x1 = self.archive[indices[0]]\n                    x2 = self.archive[indices[1]]\n                else:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[indices]\n                \n                mutant = self.population[i] + self.F * (x1 - x2)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant, self.population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    if len(self.archive) < self.pop_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        # Replace a random archive member\n                        idx = np.random.randint(self.pop_size)\n                        self.archive[idx] = self.population[i].copy()\n\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.4863861752718879, "generation": 1}, "task_prompt": ""}
{"id": "124cf7b7-45d9-4015-8a3d-bc62139a795a", "fitness": 0.3570961277671859, "name": "SelfAdaptiveDE", "description": "Implements a self-adaptive Differential Evolution strategy with dynamically adjusted population size and step size based on success rate.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1, min_pop_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.min_pop_size = min_pop_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n        success_rate = np.zeros(self.pop_size)\n\n        while evals < self.budget:\n            # Adaptive population size adjustment\n            if np.mean(success_rate) > 0.2 and self.pop_size < 50:\n                self.pop_size += 1\n                population = np.vstack((population, np.random.uniform(lb, ub, size=(1, self.dim))))\n                fitness = np.append(fitness, func(population[-1]))\n                step_size = np.append(step_size, self.initial_step_size)\n                success_rate = np.append(success_rate, 0)\n                evals += 1\n\n            elif np.mean(success_rate) < 0.05 and self.pop_size > self.min_pop_size:\n                worst_index = np.argmax(fitness)\n                population = np.delete(population, worst_index, axis=0)\n                fitness = np.delete(fitness, worst_index)\n                step_size = np.delete(step_size, worst_index)\n                success_rate = np.delete(success_rate, worst_index)\n                self.pop_size -= 1\n\n\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n\n                # Differential Evolution mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                mutant = population[i] + step_size[i] * (x_r1 - x_r2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < 0.9\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial_vector)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n                    success_rate[i] = 1\n                else:\n                    success_rate[i] = 0\n\n                # Adapt step size\n                if success_rate[i] == 1:\n                    step_size[i] *= 1.05  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.95  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n        return f_opt, x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm SelfAdaptiveDE scored 0.357 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d6ee9303-1b2a-4b17-a21c-95caff4cacc4"], "operator": "simplify", "metadata": {"llm_response": "# Description: Implements a self-adaptive Differential Evolution strategy with dynamically adjusted population size and step size based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1, min_pop_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.min_pop_size = min_pop_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n        success_rate = np.zeros(self.pop_size)\n\n        while evals < self.budget:\n            # Adaptive population size adjustment\n            if np.mean(success_rate) > 0.2 and self.pop_size < 50:\n                self.pop_size += 1\n                population = np.vstack((population, np.random.uniform(lb, ub, size=(1, self.dim))))\n                fitness = np.append(fitness, func(population[-1]))\n                step_size = np.append(step_size, self.initial_step_size)\n                success_rate = np.append(success_rate, 0)\n                evals += 1\n\n            elif np.mean(success_rate) < 0.05 and self.pop_size > self.min_pop_size:\n                worst_index = np.argmax(fitness)\n                population = np.delete(population, worst_index, axis=0)\n                fitness = np.delete(fitness, worst_index)\n                step_size = np.delete(step_size, worst_index)\n                success_rate = np.delete(success_rate, worst_index)\n                self.pop_size -= 1\n\n\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n\n                # Differential Evolution mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                mutant = population[i] + step_size[i] * (x_r1 - x_r2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < 0.9\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial_vector)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n                    success_rate[i] = 1\n                else:\n                    success_rate[i] = 0\n\n                # Adapt step size\n                if success_rate[i] == 1:\n                    step_size[i] *= 1.05  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.95  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n        return f_opt, x_opt\n```", "operator": "simplify", "theta_sampled": 0.36033963472911523, "generation": 1, "aucs": [0.12791060172609336, 0.20654182928910825, 0.3798836570826858, 0.20718730220285475, 0.2377638353200775, 0.44746049757368256, 0.24073609929397788, 0.23431244469169588, 0.22473217610789487, 0.18673916130156254, 0.4520846441710674, 0.9653296593609646, 0.366015056909786, 0.24178039683370656, 0.7002152281041559, 0.32730385212753954, 0.3774173602977454, 0.49220159387989715, 0.25647588296642565, 0.46983127610279773]}, "task_prompt": ""}
{"id": "61f6ea67-e86d-496a-8857-1b9d29ff0b80", "fitness": "-inf", "name": "AdaptivePopulationAttractionSearch", "description": "Combines adaptive population search with bacterial foraging's attraction-repulsion mechanism for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePopulationAttractionSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, attract_repel_strength=0.01, dampening_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.attract_repel_strength = attract_repel_strength\n        self.dampening_factor = dampening_factor\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size #track function evals\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n\n        while evals < self.budget:\n            # Attraction-Repulsion\n            velocities = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                sum_distance = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = population[j] - population[i]\n                        sum_distance += distance / (np.linalg.norm(distance) + 1e-8)  # Avoid division by zero\n                velocities[i] = velocities[i] * self.dampening_factor + self.attract_repel_strength * sum_distance\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n            # Evaluate fitness after attraction-repulsion\n            new_fitness = np.array([func(x) for i, x in enumerate(population)])\n            evals += self.pop_size\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < f_opt:\n                f_opt = fitness[best_index]\n                x_opt = population[best_index]\n\n            # Update individuals (Exploration & Exploitation)\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n                # Exploration: Random perturbation\n                exploration_candidate = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, lb, ub)\n                exploration_fitness = func(exploration_candidate)\n                evals += 1\n\n                # Exploitation: Move towards best\n                exploitation_candidate = population[i] + step_size[i] * (x_opt - population[i])\n                exploitation_candidate = np.clip(exploitation_candidate, lb, ub)\n                exploitation_fitness = func(exploitation_candidate)\n                evals += 1\n\n                # Selection: Choose the better candidate or keep the current one\n                if exploration_fitness < exploitation_fitness and exploration_fitness < fitness[i]:\n                    population[i] = exploration_candidate\n                    fitness[i] = exploration_fitness\n                    success = True\n                elif exploitation_fitness < exploration_fitness and exploitation_fitness < fitness[i]:\n                    population[i] = exploitation_candidate\n                    fitness[i] = exploitation_fitness\n                    success = True\n                else:\n                    success = False\n\n                # Adapt step size\n                if success:\n                    step_size[i] *= 1.1  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.9  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n\n        return f_opt, x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["d6ee9303-1b2a-4b17-a21c-95caff4cacc4", "90ae0375-63c4-43ab-8641-7ae0ddae914d"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive population search with bacterial foraging's attraction-repulsion mechanism for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationAttractionSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.5, attract_repel_strength=0.01, dampening_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.attract_repel_strength = attract_repel_strength\n        self.dampening_factor = dampening_factor\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size #track function evals\n\n        # Initial best\n        best_index = np.argmin(fitness)\n        f_opt = fitness[best_index]\n        x_opt = population[best_index]\n\n        step_size = np.full(self.pop_size, self.initial_step_size)\n\n        while evals < self.budget:\n            # Attraction-Repulsion\n            velocities = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                sum_distance = np.zeros(self.dim)\n                for j in range(self.pop_size):\n                    if i != j:\n                        distance = population[j] - population[i]\n                        sum_distance += distance / (np.linalg.norm(distance) + 1e-8)  # Avoid division by zero\n                velocities[i] = velocities[i] * self.dampening_factor + self.attract_repel_strength * sum_distance\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n            # Evaluate fitness after attraction-repulsion\n            new_fitness = np.array([func(x) for i, x in enumerate(population)])\n            evals += self.pop_size\n            fitness = new_fitness\n\n            # Update best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < f_opt:\n                f_opt = fitness[best_index]\n                x_opt = population[best_index]\n\n            # Update individuals (Exploration & Exploitation)\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n                # Exploration: Random perturbation\n                exploration_candidate = population[i] + step_size[i] * np.random.normal(0, 1, size=self.dim)\n                exploration_candidate = np.clip(exploration_candidate, lb, ub)\n                exploration_fitness = func(exploration_candidate)\n                evals += 1\n\n                # Exploitation: Move towards best\n                exploitation_candidate = population[i] + step_size[i] * (x_opt - population[i])\n                exploitation_candidate = np.clip(exploitation_candidate, lb, ub)\n                exploitation_fitness = func(exploitation_candidate)\n                evals += 1\n\n                # Selection: Choose the better candidate or keep the current one\n                if exploration_fitness < exploitation_fitness and exploration_fitness < fitness[i]:\n                    population[i] = exploration_candidate\n                    fitness[i] = exploration_fitness\n                    success = True\n                elif exploitation_fitness < exploration_fitness and exploitation_fitness < fitness[i]:\n                    population[i] = exploitation_candidate\n                    fitness[i] = exploitation_fitness\n                    success = True\n                else:\n                    success = False\n\n                # Adapt step size\n                if success:\n                    step_size[i] *= 1.1  # Increase step size if successful\n                else:\n                    step_size[i] *= 0.9  # Decrease step size if unsuccessful\n                step_size[i] = np.clip(step_size[i], 0.0001, 1.0) #bound the step size\n\n                # Update best\n                if fitness[i] < f_opt:\n                    f_opt = fitness[i]\n                    x_opt = population[i]\n\n        return f_opt, x_opt\n```", "operator": "crossover", "theta_sampled": 0.0022633274863819654, "generation": 1}, "task_prompt": ""}
{"id": "b1f555cc-7c96-47c1-8f94-205afdf16ea3", "fitness": "-inf", "name": "GaussianMixtureOptimization", "description": "A population-based algorithm using a Gaussian Mixture Model to sample new candidate solutions based on the promising regions found so far, while also incorporating a mutation operator for exploration.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, n_components=5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = min(100, budget // 10)  # Adjust population size based on budget\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Train Gaussian Mixture Model\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=10, random_state=42, n_init=1)\n            gmm.fit(population)\n\n            # Sample new candidates\n            new_candidates = gmm.sample(self.population_size)[0]\n\n            # Mutation: Add random perturbation to some candidates\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            new_candidates += np.random.normal(0, 0.5, size=(self.population_size, self.dim)) * mutation_mask\n\n            # Clip to bounds\n            new_candidates = np.clip(new_candidates, self.lb, self.ub)\n\n            # Evaluate new candidates\n            new_fitness = np.array([func(x) for x in new_candidates])\n            self.budget -= self.population_size\n\n            # Update population\n            combined_population = np.concatenate((population, new_candidates))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n            \n            indices = np.argsort(combined_fitness)[:self.population_size]  # Keep the best individuals\n            population = combined_population[indices]\n            fitness = combined_fitness[indices]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            if self.budget <= 0:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Validation failed: Forbidden import: 'sklearn' is not available in the evaluation environment", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm using a Gaussian Mixture Model to sample new candidate solutions based on the promising regions found so far, while also incorporating a mutation operator for exploration.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, n_components=5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = min(100, budget // 10)  # Adjust population size based on budget\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Train Gaussian Mixture Model\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=10, random_state=42, n_init=1)\n            gmm.fit(population)\n\n            # Sample new candidates\n            new_candidates = gmm.sample(self.population_size)[0]\n\n            # Mutation: Add random perturbation to some candidates\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            new_candidates += np.random.normal(0, 0.5, size=(self.population_size, self.dim)) * mutation_mask\n\n            # Clip to bounds\n            new_candidates = np.clip(new_candidates, self.lb, self.ub)\n\n            # Evaluate new candidates\n            new_fitness = np.array([func(x) for x in new_candidates])\n            self.budget -= self.population_size\n\n            # Update population\n            combined_population = np.concatenate((population, new_candidates))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n            \n            indices = np.argsort(combined_fitness)[:self.population_size]  # Keep the best individuals\n            population = combined_population[indices]\n            fitness = combined_fitness[indices]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            if self.budget <= 0:\n                break\n\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "e99f0d40-edc1-4afb-9afe-786c91228e8a", "fitness": "-inf", "name": "EnhancedDifferentialEvolution", "description": "A population-based algorithm that combines global search with local refinement using a dynamic adaptation of exploration and exploitation based on population diversity.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        \n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            \n    def mutate(self, pop):\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutated_pop[i] = pop[a] + self.F * (pop[b] - pop[c])\n            mutated_pop[i] = np.clip(mutated_pop[i], self.bounds_lb, self.bounds_ub)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop):\n        trial_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() <= self.CR or j == np.random.randint(0, self.dim):\n                    trial_pop[i, j] = mutated_pop[i, j]\n                else:\n                    trial_pop[i, j] = pop[i, j]\n        return trial_pop\n    \n    def selection(self, pop, trial_pop, func):\n        trial_fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            trial_fitness[i] = func(trial_pop[i])\n            if trial_fitness[i] < self.fitness[i]:\n                pop[i] = trial_pop[i]\n                self.fitness[i] = trial_fitness[i]\n\n        return pop\n\n    def __call__(self, func):\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        \n        self.initialize_population()\n        self.evaluate_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        \n        eval_count = self.pop_size  # Account for initial population evaluation\n        \n        while eval_count < self.budget:\n            mutated_pop = self.mutate(self.pop)\n            trial_pop = self.crossover(self.pop, mutated_pop)\n            self.pop = self.selection(self.pop, trial_pop, func)\n            eval_count += self.pop_size\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.pop[current_best_index]\n\n            # Dynamic Adaptation (Example: Adjust F and CR based on diversity)\n            diversity = np.std(self.pop)\n            self.F = 0.5 + 0.5 * (diversity / (self.bounds_ub[0] - self.bounds_lb[0]))\n            self.CR = 0.7 + 0.2 * (diversity / (self.bounds_ub[0] - self.bounds_lb[0]))\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n            # Early stopping if improvement stalls\n            if eval_count > 0.8 * self.budget and diversity < 1e-6:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines global search with local refinement using a dynamic adaptation of exploration and exploitation based on population diversity.\n\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        \n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.pop[i])\n            \n    def mutate(self, pop):\n        mutated_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutated_pop[i] = pop[a] + self.F * (pop[b] - pop[c])\n            mutated_pop[i] = np.clip(mutated_pop[i], self.bounds_lb, self.bounds_ub)\n        return mutated_pop\n\n    def crossover(self, pop, mutated_pop):\n        trial_pop = np.zeros_like(pop)\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() <= self.CR or j == np.random.randint(0, self.dim):\n                    trial_pop[i, j] = mutated_pop[i, j]\n                else:\n                    trial_pop[i, j] = pop[i, j]\n        return trial_pop\n    \n    def selection(self, pop, trial_pop, func):\n        trial_fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            trial_fitness[i] = func(trial_pop[i])\n            if trial_fitness[i] < self.fitness[i]:\n                pop[i] = trial_pop[i]\n                self.fitness[i] = trial_fitness[i]\n\n        return pop\n\n    def __call__(self, func):\n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n        \n        self.initialize_population()\n        self.evaluate_population(func)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        \n        eval_count = self.pop_size  # Account for initial population evaluation\n        \n        while eval_count < self.budget:\n            mutated_pop = self.mutate(self.pop)\n            trial_pop = self.crossover(self.pop, mutated_pop)\n            self.pop = self.selection(self.pop, trial_pop, func)\n            eval_count += self.pop_size\n            \n            current_best_fitness = np.min(self.fitness)\n            current_best_index = np.argmin(self.fitness)\n            if current_best_fitness < self.f_opt:\n                self.f_opt = current_best_fitness\n                self.x_opt = self.pop[current_best_index]\n\n            # Dynamic Adaptation (Example: Adjust F and CR based on diversity)\n            diversity = np.std(self.pop)\n            self.F = 0.5 + 0.5 * (diversity / (self.bounds_ub[0] - self.bounds_lb[0]))\n            self.CR = 0.7 + 0.2 * (diversity / (self.bounds_ub[0] - self.bounds_lb[0]))\n            self.F = np.clip(self.F, 0.1, 1.0)\n            self.CR = np.clip(self.CR, 0.1, 1.0)\n\n            # Early stopping if improvement stalls\n            if eval_count > 0.8 * self.budget and diversity < 1e-6:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.40071168864685175, "generation": 1}, "task_prompt": ""}
{"id": "07bfa263-3fe5-41df-a015-708a38a27fe7", "fitness": 0.5991734242200926, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm with a self-adaptive mutation rate and a population diversity-based restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive Mutation Factor\n                F_i = self.F * np.random.normal(1, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n\n                # Select three distinct individuals\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Mutation\n                v_i = self.population[i] + F_i * (x_r2 - x_r3)\n                v_i = np.clip(v_i, self.lb, self.ub)\n\n                # Crossover\n                u_i = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u_i[j] = v_i[j]\n\n                # Evaluation\n                f_u_i = func(u_i)\n                self.budget -= 1\n                \n                if f_u_i < self.fitness[i]:\n                    self.fitness[i] = f_u_i\n                    self.population[i] = u_i\n\n                    if f_u_i < self.f_opt:\n                        self.f_opt = f_u_i\n                        self.x_opt = u_i\n            \n            # Diversity check and restart mechanism\n            diversity = np.std(self.population)\n            if diversity < 0.01: # Threshold for diversity\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size # Update budget after restart\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm with a self-adaptive mutation rate and a population diversity-based restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive Mutation Factor\n                F_i = self.F * np.random.normal(1, 0.1)\n                F_i = np.clip(F_i, 0.1, 1.0)\n\n                # Select three distinct individuals\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                # Mutation\n                v_i = self.population[i] + F_i * (x_r2 - x_r3)\n                v_i = np.clip(v_i, self.lb, self.ub)\n\n                # Crossover\n                u_i = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u_i[j] = v_i[j]\n\n                # Evaluation\n                f_u_i = func(u_i)\n                self.budget -= 1\n                \n                if f_u_i < self.fitness[i]:\n                    self.fitness[i] = f_u_i\n                    self.population[i] = u_i\n\n                    if f_u_i < self.f_opt:\n                        self.f_opt = f_u_i\n                        self.x_opt = u_i\n            \n            # Diversity check and restart mechanism\n            diversity = np.std(self.population)\n            if diversity < 0.01: # Threshold for diversity\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size # Update budget after restart\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.23254094861578545, "generation": 1, "aucs": [0.17385118766678465, 0.6184783361119922, 0.5944715930333162, 0.8152135489081058, 0.6348052496803265, 0.7648293316633256, 0.35532145177869157, 0.5697693474141434, 0.6396308358274825, 0.19794925668960317, 0.8504107307018037, 0.9856985248371432, 0.6473607766037834, 0.5028879104789996, 0.911804586862026, 0.7138444938274499, 0.46327723175155366, 0.8372625081315019, 0.20055120041047025, 0.5060503820233511]}, "task_prompt": ""}
{"id": "414dd85c-358d-4c93-8769-042881397968", "fitness": 0.5996121370057697, "name": "AdaptiveCauchyDifferentialEvolution", "description": "A population-based algorithm that uses a combination of global exploration and local exploitation based on an adaptive Cauchy mutation and a differential evolution crossover, with a shrinking search space.", "code": "import numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999  # Shrink the search space slightly each generation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb \n            self.ub = self.shrink_factor * self.ub\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveCauchyDifferentialEvolution scored 0.600 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of global exploration and local exploitation based on an adaptive Cauchy mutation and a differential evolution crossover, with a shrinking search space.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999  # Shrink the search space slightly each generation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb \n            self.ub = self.shrink_factor * self.ub\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.35752594827341244, "generation": 1, "aucs": [0.21261507700015558, 0.44578165047159757, 0.5921669430885981, 0.8331352333542288, 0.5028901286669485, 0.753786147315448, 0.5732332744405206, 0.5837048766532633, 0.689023054388078, 0.35116156111264574, 0.8037701729850373, 0.9992375025419294, 0.31245610163829174, 0.5616651649225329, 0.8636296284773588, 0.7675679498869536, 0.5027915236851959, 0.8163767425962664, 0.3181628999069519, 0.5090871069833902]}, "task_prompt": ""}
{"id": "1134dbdb-5437-405d-bc29-b9651c80b786", "fitness": 0.570751969396148, "name": "HybridDE", "description": "A population-based algorithm that uses a combination of differential evolution and a local search to refine promising solutions.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local Search on best solution\n            for _ in range(min(self.local_search_iterations, self.budget)):\n                x_local = self.x_opt.copy()\n                delta = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                x_local = np.clip(x_local + delta, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDE scored 0.571 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of differential evolution and a local search to refine promising solutions.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, Cr=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.Cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Local Search on best solution\n            for _ in range(min(self.local_search_iterations, self.budget)):\n                x_local = self.x_opt.copy()\n                delta = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                x_local = np.clip(x_local + delta, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.2669845812582643, "generation": 1, "aucs": [0.1964703771417926, 0.4136283838934849, 0.504225415533984, 0.8432712578916178, 0.6012634761741169, 0.6439878000164564, 0.38269477575664357, 0.47119426096080885, 0.5291205015469556, 0.4880455179864802, 0.8450678392761117, 0.9979970234894647, 0.45415906848633025, 0.5619534147854255, 0.9171451426324736, 0.6510823979877289, 0.4493442977154436, 0.7492819959019432, 0.20020060020584252, 0.5149058405398532]}, "task_prompt": ""}
{"id": "0964e7a4-b9e8-4426-9672-5538d7c21dee", "fitness": "-inf", "name": "AdaptiveSimplexDE", "description": "An adaptive metaheuristic that combines aspects of Nelder-Mead simplex and Differential Evolution (DE), dynamically adjusting the simplex size and DE parameters based on function evaluation history.", "code": "import numpy as np\n\nclass AdaptiveSimplexDE:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, de_F=0.5, de_CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size  # Fraction of search space\n        self.de_F = de_F  # Differential Evolution mutation factor\n        self.de_CR = de_CR  # Differential Evolution crossover rate\n        self.simplex_size_decay = 0.999  # Decay rate for simplex size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialize a simplex (Nelder-Mead inspired)\n        simplex = []\n        values = []\n        for i in range(self.dim + 1):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            simplex.append(x)\n            f = func(x)\n            values.append(f)\n            eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        simplex = np.array(simplex)\n        values = np.array(values)\n        simplex_size = self.initial_simplex_size * (func.bounds.ub - func.bounds.lb)\n\n        while eval_count < self.budget:\n            # Sort simplex points by value (ascending)\n            sorted_indices = np.argsort(values)\n            simplex = simplex[sorted_indices]\n            values = values[sorted_indices]\n\n            # 1. Nelder-Mead-like reflection\n            centroid = np.mean(simplex[:-1], axis=0)\n            reflection_point = centroid + (centroid - simplex[-1])\n            reflection_point = np.clip(reflection_point, func.bounds.lb, func.bounds.ub)\n            f_reflection = func(reflection_point)\n            eval_count += 1\n\n            if f_reflection < values[0]:  # Better than the best\n                expansion_point = centroid + 2 * (reflection_point - centroid)\n                expansion_point = np.clip(expansion_point, func.bounds.lb, func.bounds.ub)\n                f_expansion = func(expansion_point)\n                eval_count += 1\n                if f_expansion < f_reflection:\n                    simplex[-1] = expansion_point\n                    values[-1] = f_expansion\n                else:\n                    simplex[-1] = reflection_point\n                    values[-1] = f_reflection\n\n            elif f_reflection < values[-2]:  # Better than the second worst\n                simplex[-1] = reflection_point\n                values[-1] = f_reflection\n            else:  # Worse than the second worst\n                contraction_point = centroid + 0.5 * (simplex[-1] - centroid)\n                contraction_point = np.clip(contraction_point, func.bounds.lb, func.bounds.ub)\n                f_contraction = func(contraction_point)\n                eval_count += 1\n\n                if f_contraction < values[-1]:\n                    simplex[-1] = contraction_point\n                    values[-1] = f_contraction\n                else:\n                    # Shrink the simplex towards the best point\n                    for i in range(1, self.dim + 1):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                        values[i] = func(simplex[i])\n                        eval_count += 1\n\n            # 2. Differential Evolution step\n            for i in range(self.dim + 1):\n                if eval_count >= self.budget:\n                    break\n                \n                # Select three distinct simplex points (excluding the current one)\n                indices = list(range(self.dim + 1))\n                indices.remove(i)\n                r1, r2, r3 = np.random.choice(indices, 3, replace=False)\n\n                # Mutation\n                mutant = simplex[r1] + self.de_F * (simplex[r2] - simplex[r3])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial_vector = np.copy(simplex[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_CR:\n                        trial_vector[j] = mutant[j]\n                \n                f_trial = func(trial_vector)\n                eval_count += 1\n                \n                if f_trial < values[i]:\n                    simplex[i] = trial_vector\n                    values[i] = f_trial\n\n            # Update best solution\n            if np.min(values) < self.f_opt:\n                self.f_opt = np.min(values)\n                self.x_opt = simplex[np.argmin(values)]\n                \n            # Decay simplex size\n            simplex_size *= self.simplex_size_decay\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "error": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive metaheuristic that combines aspects of Nelder-Mead simplex and Differential Evolution (DE), dynamically adjusting the simplex size and DE parameters based on function evaluation history.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveSimplexDE:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1, de_F=0.5, de_CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size  # Fraction of search space\n        self.de_F = de_F  # Differential Evolution mutation factor\n        self.de_CR = de_CR  # Differential Evolution crossover rate\n        self.simplex_size_decay = 0.999  # Decay rate for simplex size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        # Initialize a simplex (Nelder-Mead inspired)\n        simplex = []\n        values = []\n        for i in range(self.dim + 1):\n            x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            simplex.append(x)\n            f = func(x)\n            values.append(f)\n            eval_count += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        simplex = np.array(simplex)\n        values = np.array(values)\n        simplex_size = self.initial_simplex_size * (func.bounds.ub - func.bounds.lb)\n\n        while eval_count < self.budget:\n            # Sort simplex points by value (ascending)\n            sorted_indices = np.argsort(values)\n            simplex = simplex[sorted_indices]\n            values = values[sorted_indices]\n\n            # 1. Nelder-Mead-like reflection\n            centroid = np.mean(simplex[:-1], axis=0)\n            reflection_point = centroid + (centroid - simplex[-1])\n            reflection_point = np.clip(reflection_point, func.bounds.lb, func.bounds.ub)\n            f_reflection = func(reflection_point)\n            eval_count += 1\n\n            if f_reflection < values[0]:  # Better than the best\n                expansion_point = centroid + 2 * (reflection_point - centroid)\n                expansion_point = np.clip(expansion_point, func.bounds.lb, func.bounds.ub)\n                f_expansion = func(expansion_point)\n                eval_count += 1\n                if f_expansion < f_reflection:\n                    simplex[-1] = expansion_point\n                    values[-1] = f_expansion\n                else:\n                    simplex[-1] = reflection_point\n                    values[-1] = f_reflection\n\n            elif f_reflection < values[-2]:  # Better than the second worst\n                simplex[-1] = reflection_point\n                values[-1] = f_reflection\n            else:  # Worse than the second worst\n                contraction_point = centroid + 0.5 * (simplex[-1] - centroid)\n                contraction_point = np.clip(contraction_point, func.bounds.lb, func.bounds.ub)\n                f_contraction = func(contraction_point)\n                eval_count += 1\n\n                if f_contraction < values[-1]:\n                    simplex[-1] = contraction_point\n                    values[-1] = f_contraction\n                else:\n                    # Shrink the simplex towards the best point\n                    for i in range(1, self.dim + 1):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                        values[i] = func(simplex[i])\n                        eval_count += 1\n\n            # 2. Differential Evolution step\n            for i in range(self.dim + 1):\n                if eval_count >= self.budget:\n                    break\n                \n                # Select three distinct simplex points (excluding the current one)\n                indices = list(range(self.dim + 1))\n                indices.remove(i)\n                r1, r2, r3 = np.random.choice(indices, 3, replace=False)\n\n                # Mutation\n                mutant = simplex[r1] + self.de_F * (simplex[r2] - simplex[r3])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                trial_vector = np.copy(simplex[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_CR:\n                        trial_vector[j] = mutant[j]\n                \n                f_trial = func(trial_vector)\n                eval_count += 1\n                \n                if f_trial < values[i]:\n                    simplex[i] = trial_vector\n                    values[i] = f_trial\n\n            # Update best solution\n            if np.min(values) < self.f_opt:\n                self.f_opt = np.min(values)\n                self.x_opt = simplex[np.argmin(values)]\n                \n            # Decay simplex size\n            simplex_size *= self.simplex_size_decay\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.23939748257386634, "generation": 2}, "task_prompt": ""}
{"id": "ec1d4877-d5c2-4e7b-9cf1-c976491b3c8a", "fitness": "-inf", "name": "AdaptiveCauchyDifferentialEvolution2", "description": "Combines Cauchy mutation and differential evolution with an adaptive population size and a novel self-adaptive parameter control mechanism based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_F=0.5, initial_CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = initial_F  # Mutation factor\n        self.CR = initial_CR  # Crossover rate\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            \n            # Adaptive population size\n            if len(self.best_fitness_history) > 50:\n                std_fitness = np.std(self.best_fitness_history[-50:])\n                if std_fitness < 1e-6 and self.pop_size > 10:\n                    self.pop_size = max(10, int(self.pop_size * 0.9))  # Reduce pop size if stagnating\n                    self.pop = self.pop[:self.pop_size]\n                    self.fitness = self.fitness[:self.pop_size]\n                elif std_fitness > 1e-3 and self.pop_size < 100:\n                     self.pop_size = min(100, int(self.pop_size * 1.1))\n                     new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                     new_fitness = np.array([func(x) for x in new_pop])\n                     self.pop = np.concatenate((self.pop, new_pop))\n                     self.fitness = np.concatenate((self.fitness, new_fitness))\n                     eval_count += len(new_pop)\n\n\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i, self.F, self.CR)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        # Adjust F and CR based on success\n                        self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0, 1)\n                        self.CR = np.clip(self.CR + 0.1 * np.random.normal(0, 1), 0, 1)\n                else:\n                    # If no improvement, slightly perturb F and CR to encourage exploration\n                    self.F = np.clip(self.F + 0.05 * np.random.normal(0, 1), 0, 1)\n                    self.CR = np.clip(self.CR + 0.05 * np.random.normal(0, 1), 0, 1)\n                \n                if eval_count >= self.budget:\n                    break\n\n            self.best_fitness_history.append(self.f_opt)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines Cauchy mutation and differential evolution with an adaptive population size and a novel self-adaptive parameter control mechanism based on fitness improvement.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_F=0.5, initial_CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = initial_F  # Mutation factor\n        self.CR = initial_CR  # Crossover rate\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            \n            # Adaptive population size\n            if len(self.best_fitness_history) > 50:\n                std_fitness = np.std(self.best_fitness_history[-50:])\n                if std_fitness < 1e-6 and self.pop_size > 10:\n                    self.pop_size = max(10, int(self.pop_size * 0.9))  # Reduce pop size if stagnating\n                    self.pop = self.pop[:self.pop_size]\n                    self.fitness = self.fitness[:self.pop_size]\n                elif std_fitness > 1e-3 and self.pop_size < 100:\n                     self.pop_size = min(100, int(self.pop_size * 1.1))\n                     new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.pop), self.dim))\n                     new_fitness = np.array([func(x) for x in new_pop])\n                     self.pop = np.concatenate((self.pop, new_pop))\n                     self.fitness = np.concatenate((self.fitness, new_fitness))\n                     eval_count += len(new_pop)\n\n\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i, self.F, self.CR)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        # Adjust F and CR based on success\n                        self.F = np.clip(self.F + 0.1 * np.random.normal(0, 1), 0, 1)\n                        self.CR = np.clip(self.CR + 0.1 * np.random.normal(0, 1), 0, 1)\n                else:\n                    # If no improvement, slightly perturb F and CR to encourage exploration\n                    self.F = np.clip(self.F + 0.05 * np.random.normal(0, 1), 0, 1)\n                    self.CR = np.clip(self.CR + 0.05 * np.random.normal(0, 1), 0, 1)\n                \n                if eval_count >= self.budget:\n                    break\n\n            self.best_fitness_history.append(self.f_opt)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.2087543131458618, "generation": 2}, "task_prompt": ""}
{"id": "230b0273-fab8-4791-bb65-e9d8ead4b3b0", "fitness": 0.0, "name": "EnhancedACDE", "description": "Combines Adaptive Cauchy Differential Evolution with a local search component focused on intensifying the search around the best-found solution.", "code": "import numpy as np\n\nclass EnhancedACDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999\n        self.local_search_iterations = local_search_iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def local_search(self, func):\n        for _ in range(min(self.local_search_iterations, self.budget)):\n            x_local = self.x_opt.copy()\n            delta = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n            x_local = np.clip(x_local + delta, self.lb, self.ub)\n            f_local = func(x_local)\n\n            if f_local < self.f_opt:\n                self.f_opt = f_local\n                self.x_opt = x_local\n            self.budget -= 1\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb \n            self.ub = self.shrink_factor * self.ub\n            \n            #Local Search\n            self.local_search(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedACDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968", "1134dbdb-5437-405d-bc29-b9651c80b786"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive Cauchy Differential Evolution with a local search component focused on intensifying the search around the best-found solution.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedACDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999\n        self.local_search_iterations = local_search_iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def local_search(self, func):\n        for _ in range(min(self.local_search_iterations, self.budget)):\n            x_local = self.x_opt.copy()\n            delta = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n            x_local = np.clip(x_local + delta, self.lb, self.ub)\n            f_local = func(x_local)\n\n            if f_local < self.f_opt:\n                self.f_opt = f_local\n                self.x_opt = x_local\n            self.budget -= 1\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb \n            self.ub = self.shrink_factor * self.ub\n            \n            #Local Search\n            self.local_search(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.21843334058850214, "generation": 2, "aucs": [0]}, "task_prompt": ""}
{"id": "504438c2-3718-4eb0-b1da-687d02bc6ae8", "fitness": 0.0, "name": "PSOCMAES", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) and covariance matrix adaptation evolution strategy (CMA-ES) to adaptively adjust search direction and step size.", "code": "import numpy as np\n\nclass PSOCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, mu_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.mu_adapt = mu_adapt # Adaptation rate for CMA-ES like step size\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n\n        # CMA-ES like step size adaptation\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb) * np.ones(self.dim) # Individual step sizes\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            inertia_weight = 0.5 + np.random.uniform(0, 0.4)\n            for i in range(self.pop_size):\n                velocities[i] = inertia_weight * velocities[i] \\\n                                + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) \\\n                                + self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                pop[i] = pop[i] + sigma * velocities[i]  # Apply CMA-ES like step sizes\n\n                # Clip to bounds\n                pop[i] = np.clip(pop[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                f = func(pop[i])\n                self.budget -= 1\n\n                # Update pbest and gbest\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_pop[i] = pop[i].copy()\n\n                    if f < gbest_fitness:\n                        gbest_fitness = f\n                        gbest_x = pop[i].copy()\n\n            # Adapt step sizes (CMA-ES like)\n            for d in range(self.dim):\n                success_count = 0\n                for i in range(self.pop_size):\n                    if np.linalg.norm(velocities[i, d]) > 0.001:\n                      success_count += (pbest_fitness[i] < fitness[i])\n\n                success_rate = success_count / self.pop_size\n                if success_rate > 0.3:\n                    sigma[d] *= np.exp(self.mu_adapt * (success_rate - 0.3) / (1 - 0.3))  # Increase step size\n                elif success_rate < 0.1:\n                    sigma[d] *= np.exp(-self.mu_adapt * (0.1 - success_rate) / 0.1)  # Decrease step size\n            \n            fitness = np.array([func(x) for x in pop]) # Update current fitness for the step size adaptation\n            self.budget -= self.pop_size - self.pop_size # effectively zero\n\n        return gbest_fitness, gbest_x", "configspace": "", "generation": 2, "feedback": "The algorithm PSOCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) and covariance matrix adaptation evolution strategy (CMA-ES) to adaptively adjust search direction and step size.\n# Code: \n```python\nimport numpy as np\n\nclass PSOCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, mu_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # cognitive coefficient\n        self.c2 = c2  # social coefficient\n        self.mu_adapt = mu_adapt # Adaptation rate for CMA-ES like step size\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n\n        # CMA-ES like step size adaptation\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb) * np.ones(self.dim) # Individual step sizes\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update velocities and positions\n            inertia_weight = 0.5 + np.random.uniform(0, 0.4)\n            for i in range(self.pop_size):\n                velocities[i] = inertia_weight * velocities[i] \\\n                                + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) \\\n                                + self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                pop[i] = pop[i] + sigma * velocities[i]  # Apply CMA-ES like step sizes\n\n                # Clip to bounds\n                pop[i] = np.clip(pop[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                f = func(pop[i])\n                self.budget -= 1\n\n                # Update pbest and gbest\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_pop[i] = pop[i].copy()\n\n                    if f < gbest_fitness:\n                        gbest_fitness = f\n                        gbest_x = pop[i].copy()\n\n            # Adapt step sizes (CMA-ES like)\n            for d in range(self.dim):\n                success_count = 0\n                for i in range(self.pop_size):\n                    if np.linalg.norm(velocities[i, d]) > 0.001:\n                      success_count += (pbest_fitness[i] < fitness[i])\n\n                success_rate = success_count / self.pop_size\n                if success_rate > 0.3:\n                    sigma[d] *= np.exp(self.mu_adapt * (success_rate - 0.3) / (1 - 0.3))  # Increase step size\n                elif success_rate < 0.1:\n                    sigma[d] *= np.exp(-self.mu_adapt * (0.1 - success_rate) / 0.1)  # Decrease step size\n            \n            fitness = np.array([func(x) for x in pop]) # Update current fitness for the step size adaptation\n            self.budget -= self.pop_size - self.pop_size # effectively zero\n\n        return gbest_fitness, gbest_x\n```", "operator": "random_new", "theta_sampled": 0.3496385846101572, "generation": 2, "aucs": [0]}, "task_prompt": ""}
{"id": "72ea3596-49a0-4fe7-9458-ea71a0307ed7", "fitness": 0.19018645440543974, "name": "SelfAdjustingCauchyLocalSearch", "description": "A self-adjusting algorithm that combines a global search based on a Cauchy distribution with a local search around the best-found solution, dynamically adjusting the balance between exploration and exploitation based on the success rate.", "code": "import numpy as np\n\nclass SelfAdjustingCauchyLocalSearch:\n    def __init__(self, budget=10000, dim=10, exploration_rate=0.5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_rate = exploration_rate\n        self.local_search_radius = local_search_radius\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 20  # Keep track of the last 20 iterations\n        self.adjustment_rate = 0.05\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize x_opt to avoid unbound variables\n        self.f_opt = func(self.x_opt)\n        eval_count = 1 # Account for initial func evaluation\n\n        for i in range(1, self.budget):\n            if np.random.rand() < self.exploration_rate:\n                # Cauchy global search\n                x = self.x_opt + np.random.standard_cauchy(size=self.dim) * self.local_search_radius # Perturb from best solution\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Bound to ensure search space limits\n\n            else:\n                # Local search around the best solution\n                x = self.x_opt + np.random.normal(0, self.local_search_radius, size=self.dim) # Perturb from best solution\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Bound to ensure search space limits\n           \n            f = func(x)\n            eval_count +=1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n            \n            # Maintain history\n            if len(self.success_history) > self.history_length:\n                self.success_history.pop(0)\n\n            # Update exploration rate based on success\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.5:\n                self.exploration_rate = max(0.0, self.exploration_rate - self.adjustment_rate)\n                self.local_search_radius = min(5.0, self.local_search_radius * (1+self.adjustment_rate))\n            else:\n                self.exploration_rate = min(1.0, self.exploration_rate + self.adjustment_rate)\n                self.local_search_radius = max(0.00001, self.local_search_radius * (1-self.adjustment_rate)) # avoid the radius getting close to zero\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SelfAdjustingCauchyLocalSearch scored 0.190 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-adjusting algorithm that combines a global search based on a Cauchy distribution with a local search around the best-found solution, dynamically adjusting the balance between exploration and exploitation based on the success rate.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdjustingCauchyLocalSearch:\n    def __init__(self, budget=10000, dim=10, exploration_rate=0.5, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.exploration_rate = exploration_rate\n        self.local_search_radius = local_search_radius\n        self.success_rate = 0.0\n        self.success_history = []\n        self.history_length = 20  # Keep track of the last 20 iterations\n        self.adjustment_rate = 0.05\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize x_opt to avoid unbound variables\n        self.f_opt = func(self.x_opt)\n        eval_count = 1 # Account for initial func evaluation\n\n        for i in range(1, self.budget):\n            if np.random.rand() < self.exploration_rate:\n                # Cauchy global search\n                x = self.x_opt + np.random.standard_cauchy(size=self.dim) * self.local_search_radius # Perturb from best solution\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Bound to ensure search space limits\n\n            else:\n                # Local search around the best solution\n                x = self.x_opt + np.random.normal(0, self.local_search_radius, size=self.dim) # Perturb from best solution\n                x = np.clip(x, func.bounds.lb, func.bounds.ub) # Bound to ensure search space limits\n           \n            f = func(x)\n            eval_count +=1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n            \n            # Maintain history\n            if len(self.success_history) > self.history_length:\n                self.success_history.pop(0)\n\n            # Update exploration rate based on success\n            self.success_rate = np.mean(self.success_history)\n\n            if self.success_rate > 0.5:\n                self.exploration_rate = max(0.0, self.exploration_rate - self.adjustment_rate)\n                self.local_search_radius = min(5.0, self.local_search_radius * (1+self.adjustment_rate))\n            else:\n                self.exploration_rate = min(1.0, self.exploration_rate + self.adjustment_rate)\n                self.local_search_radius = max(0.00001, self.local_search_radius * (1-self.adjustment_rate)) # avoid the radius getting close to zero\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.24310098077253198, "generation": 2, "aucs": [9.999999999998899e-05, 0.16497815222732648, 0.18489815649026287, 0.1987030379456326, 0.13786011723548364, 0.1318360525842559, 0.22774883027599746, 0.15723384559534903, 0.15213367812071155, 0.10242020063502699, 0.18032394917797134, 0.21110909397726219, 0.228711875984694, 0.21782920663366145, 0.17367352698270588, 0.2988095781233824, 0.11054844271542952, 0.4523692742578962, 0.08773975908497744, 0.3847023100607675]}, "task_prompt": ""}
{"id": "a877a5f2-6afb-4699-83cd-3ed93bf2c19a", "fitness": 0.602943563115519, "name": "AdaptiveCauchyDE_with_Restart", "description": "Adaptive Cauchy Differential Evolution with diversity-based restart.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE_with_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999\n        self.diversity_threshold = 0.01\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def check_diversity(self):\n        diversity = np.std(self.pop)\n        return diversity < self.diversity_threshold\n\n    def restart_population(self, func):\n         self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.pop])\n         self.f_opt = np.min(self.fitness)\n         self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            self.lb = self.shrink_factor * self.lb\n            self.ub = self.shrink_factor * self.ub\n            \n            # Check diversity and restart if needed\n            if self.check_diversity():\n                self.restart_population(func)\n                eval_count += self.pop_size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCauchyDE_with_Restart scored 0.603 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968", "07bfa263-3fe5-41df-a015-708a38a27fe7"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Cauchy Differential Evolution with diversity-based restart.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE_with_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.shrink_factor = 0.999\n        self.diversity_threshold = 0.01\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F=0.5, CR=0.7):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def check_diversity(self):\n        diversity = np.std(self.pop)\n        return diversity < self.diversity_threshold\n\n    def restart_population(self, func):\n         self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.pop])\n         self.f_opt = np.min(self.fitness)\n         self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n            \n            self.lb = self.shrink_factor * self.lb\n            self.ub = self.shrink_factor * self.ub\n            \n            # Check diversity and restart if needed\n            if self.check_diversity():\n                self.restart_population(func)\n                eval_count += self.pop_size\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.3066842508355631, "generation": 2, "aucs": [0.2152446149803653, 0.5524641577184941, 0.5765840774707565, 0.8455035359044354, 0.4197854463460099, 0.7630771103150934, 0.5722182604095354, 0.5820290472829335, 0.6807012650421822, 0.33285450995183596, 0.7917685905760472, 0.9877061415322463, 0.3154538742357902, 0.534628862212296, 0.8906331734193044, 0.7632707735579431, 0.5298511796083948, 0.8340270081317301, 0.36099799036047975, 0.5100716432545065]}, "task_prompt": ""}
{"id": "1ff1b49b-7f01-4dfb-a51d-a8b41dc68024", "fitness": 0.3828946513352978, "name": "AdaptiveCauchyDE", "description": "Combines Cauchy mutation with a simplified differential evolution strategy and an adaptive population size based on performance.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.7 # Fixed Crossover Rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b = np.random.choice(idx, 2, replace=False)  # Simplified: Using only two individuals\n        mutant = pop[i] + self.F * (pop[a] - pop[b]) # Simplified DE\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def adjust_population_size(self):\n        # Adaptive population size adjustment\n        if self.pop_size > self.min_pop_size and np.std(self.fitness) < 1e-3: # If fitness diversity is low reduce pop size.\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.8)) #Reduce the population size\n                self.pop = self.pop[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n        elif self.pop_size < 50 and np.std(self.fitness) > 0.5:  # If fitness diversity is high increase pop size up to limit.\n             self.pop_size = min(50, int(self.pop_size * 1.2))\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adjust_population_size() # Adjust the population size\n\n            for i in range(self.pop_size):\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCauchyDE scored 0.383 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines Cauchy mutation with a simplified differential evolution strategy and an adaptive population size based on performance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, min_pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.min_pop_size = min_pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = 0.5  # Fixed scaling factor\n        self.CR = 0.7 # Fixed Crossover Rate\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b = np.random.choice(idx, 2, replace=False)  # Simplified: Using only two individuals\n        mutant = pop[i] + self.F * (pop[a] - pop[b]) # Simplified DE\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def adjust_population_size(self):\n        # Adaptive population size adjustment\n        if self.pop_size > self.min_pop_size and np.std(self.fitness) < 1e-3: # If fitness diversity is low reduce pop size.\n                self.pop_size = max(self.min_pop_size, int(self.pop_size * 0.8)) #Reduce the population size\n                self.pop = self.pop[:self.pop_size]\n                self.fitness = self.fitness[:self.pop_size]\n        elif self.pop_size < 50 and np.std(self.fitness) > 0.5:  # If fitness diversity is high increase pop size up to limit.\n             self.pop_size = min(50, int(self.pop_size * 1.2))\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.adjust_population_size() # Adjust the population size\n\n            for i in range(self.pop_size):\n                scale = 0.1 * (self.ub - self.lb) # Adaptive Scale\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.3740632134599912, "generation": 2, "aucs": [0.15636630199422163, 0.24560340230104516, 0.3770492843653831, 0.3771090210702126, 0.2920743280031113, 0.401531112385613, 0.2969670252067944, 0.3318974843871624, 0.31141317270082247, 0.1863584337460069, 0.46905143277484973, 0.9974315370573706, 0.31651157927952667, 0.3064159217724919, 0.7213666289338474, 0.38374602972473804, 0.31118837150165446, 0.48925938515887724, 0.19979815188331218, 0.48675442245891487]}, "task_prompt": ""}
{"id": "e7e80a9f-4caa-43e4-95db-e39aec1d3fa2", "fitness": 0.5995990026093977, "name": "AdaptiveCauchyDifferentialEvolution", "description": "A simplified Adaptive Cauchy Differential Evolution with improved exploration by adjusting Cauchy scale and differential evolution parameters based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            # Calculate population diversity\n            diversity = np.std(self.fitness)\n\n            # Adapt Cauchy scale and DE parameters based on diversity\n            self.cauchy_scale = 0.1 + 0.9 * (diversity / np.abs(self.f_opt + 1e-8)) # Avoid division by zero\n            self.F = 0.1 + 0.8 * (1 - (diversity / np.abs(self.f_opt + 1e-8)))\n            self.CR = 0.1 + 0.8 * (diversity / np.abs(self.f_opt + 1e-8))\n            self.cauchy_scale = np.clip(self.cauchy_scale, 0.01, 1.0) # Ensure scale is within reasonable bounds\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCauchyDifferentialEvolution scored 0.600 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified Adaptive Cauchy Differential Evolution with improved exploration by adjusting Cauchy scale and differential evolution parameters based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        # Crossover\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n            \n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            # Calculate population diversity\n            diversity = np.std(self.fitness)\n\n            # Adapt Cauchy scale and DE parameters based on diversity\n            self.cauchy_scale = 0.1 + 0.9 * (diversity / np.abs(self.f_opt + 1e-8)) # Avoid division by zero\n            self.F = 0.1 + 0.8 * (1 - (diversity / np.abs(self.f_opt + 1e-8)))\n            self.CR = 0.1 + 0.8 * (diversity / np.abs(self.f_opt + 1e-8))\n            self.cauchy_scale = np.clip(self.cauchy_scale, 0.01, 1.0) # Ensure scale is within reasonable bounds\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                \n                # Cauchy Mutation with adaptive scale\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n\n                # Differential Evolution Crossover\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.2865903250369738, "generation": 2, "aucs": [0.2948068941222707, 0.20253729995817504, 0.6700346167061259, 0.4720813535492181, 0.7848872131003403, 0.7741586862347812, 0.457004653023681, 0.6542245214376108, 0.7557904559708953, 0.674382882182153, 0.7347283170619499, 0.9997418941674739, 0.2592004880485257, 0.7066372652439019, 0.6696976455116656, 0.8494961502685501, 0.48853572003201684, 0.7743899203696091, 0.26705697407386775, 0.5025871011251429]}, "task_prompt": ""}
{"id": "65a507f0-58ec-45f1-9dbc-99bac2a18532", "fitness": "-inf", "name": "CMAES_with_Adaptive_Restart", "description": "Covariance Matrix Adaptation Evolution Strategy with adaptive mutation strength based on success rate and a restart mechanism.", "code": "import numpy as np\n\nclass CMAES_with_Adaptive_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, mucov=10.0):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = 1 + 2 * np.max([0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.mucov = mucov\n        self.c1 = self.mucov / ((self.dim + self.mucov)**2)\n        self.cmu = min(1 - self.c1, self.mucov * self.mueff / ((self.dim + self.mucov)**2))\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.mean = None\n        self.sigma = 0.3 # Initial step-size\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_restarts = 0\n        self.max_restarts = 5\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample(self):\n        z = np.random.randn(self.dim, self.popsize)\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x.T, z\n\n    def update(self, x, z, fitness_values):\n        idx = np.argsort(fitness_values)\n        x = x[idx]\n        z = z[:, idx]\n\n        xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n        zmean = np.sum(z[:, :self.mu] * self.weights, axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n        self.pc = (1 - self.c1) * self.pc + np.sqrt(self.c1 * (2 - self.c1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2*self.budget/self.popsize)) < (1.4 + 2/(self.dim+1))*self.chiN\n        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + \\\n                   self.cmu * (z[:, :self.mu] * self.weights) @ z[:, :self.mu].T\n\n        self.mean = xmean\n        \n        # Adaptive step-size control based on success rate\n        delta_f = self.f_opt - np.min(fitness_values)\n        self.success_rate = delta_f / (self.f_opt + 1e-8)  # Avoid division by zero\n        self.success_history.append(self.success_rate)\n        if len(self.success_history) > 10:\n            self.success_history = self.success_history[-10:]\n        avg_success = np.mean(self.success_history)\n\n        if avg_success > 0.2:\n            self.sigma *= np.exp(0.05 + avg_success/5) # Increase sigma if successful\n        elif avg_success < 0.05:\n            self.sigma *= np.exp(-0.1 - avg_success/5) # Decrease sigma if not successful\n\n        self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/self.chiN - 1))\n\n        self.f_opt = min(self.f_opt, np.min(fitness_values))\n        if self.f_opt == np.min(fitness_values):\n            self.x_opt = x[np.argmin(fitness_values)]\n\n    def restart(self):\n        self.n_restarts += 1\n        print(f\"Restarting CMA-ES (Restart {self.n_restarts}/{self.max_restarts})\")\n        self.initialize()  # Re-initialize the algorithm\n\n    def __call__(self, func):\n        self.initialize()\n        evals = 0\n        \n        while evals < self.budget:\n            x, z = self.sample()\n            fitness_values = np.array([func(xi) for xi in x])\n            evals += self.popsize\n\n            self.update(x, z, fitness_values)\n            \n            # Restart mechanism\n            if evals >= self.budget and self.n_restarts < self.max_restarts:\n                self.restart()\n                evals = 0  # Reset evaluation counter after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with adaptive mutation strength based on success rate and a restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES_with_Adaptive_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, mucov=10.0):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = cs\n        self.damps = 1 + 2 * np.max([0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1]) + self.cs\n        self.mucov = mucov\n        self.c1 = self.mucov / ((self.dim + self.mucov)**2)\n        self.cmu = min(1 - self.c1, self.mucov * self.mueff / ((self.dim + self.mucov)**2))\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.mean = None\n        self.sigma = 0.3 # Initial step-size\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_restarts = 0\n        self.max_restarts = 5\n        self.success_rate = 0.0\n        self.success_history = []\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def sample(self):\n        z = np.random.randn(self.dim, self.popsize)\n        C_sqrt = np.linalg.cholesky(self.C)\n        x = self.mean[:, np.newaxis] + self.sigma * C_sqrt @ z\n        x = np.clip(x, self.lb, self.ub)\n        return x.T, z\n\n    def update(self, x, z, fitness_values):\n        idx = np.argsort(fitness_values)\n        x = x[idx]\n        z = z[:, idx]\n\n        xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n        zmean = np.sum(z[:, :self.mu] * self.weights, axis=1)\n\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n        self.pc = (1 - self.c1) * self.pc + np.sqrt(self.c1 * (2 - self.c1) * self.mueff) * (xmean - self.mean) / self.sigma\n\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2*self.budget/self.popsize)) < (1.4 + 2/(self.dim+1))*self.chiN\n        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + \\\n                   self.cmu * (z[:, :self.mu] * self.weights) @ z[:, :self.mu].T\n\n        self.mean = xmean\n        \n        # Adaptive step-size control based on success rate\n        delta_f = self.f_opt - np.min(fitness_values)\n        self.success_rate = delta_f / (self.f_opt + 1e-8)  # Avoid division by zero\n        self.success_history.append(self.success_rate)\n        if len(self.success_history) > 10:\n            self.success_history = self.success_history[-10:]\n        avg_success = np.mean(self.success_history)\n\n        if avg_success > 0.2:\n            self.sigma *= np.exp(0.05 + avg_success/5) # Increase sigma if successful\n        elif avg_success < 0.05:\n            self.sigma *= np.exp(-0.1 - avg_success/5) # Decrease sigma if not successful\n\n        self.sigma *= np.exp((self.cs/self.damps)*(np.linalg.norm(self.ps)/self.chiN - 1))\n\n        self.f_opt = min(self.f_opt, np.min(fitness_values))\n        if self.f_opt == np.min(fitness_values):\n            self.x_opt = x[np.argmin(fitness_values)]\n\n    def restart(self):\n        self.n_restarts += 1\n        print(f\"Restarting CMA-ES (Restart {self.n_restarts}/{self.max_restarts})\")\n        self.initialize()  # Re-initialize the algorithm\n\n    def __call__(self, func):\n        self.initialize()\n        evals = 0\n        \n        while evals < self.budget:\n            x, z = self.sample()\n            fitness_values = np.array([func(xi) for xi in x])\n            evals += self.popsize\n\n            self.update(x, z, fitness_values)\n            \n            # Restart mechanism\n            if evals >= self.budget and self.n_restarts < self.max_restarts:\n                self.restart()\n                evals = 0  # Reset evaluation counter after restart\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.22148416049812092, "generation": 3}, "task_prompt": ""}
{"id": "560358e9-a99b-4355-80af-2faa5b63b9bc", "fitness": "-inf", "name": "AdaptiveCauchyDE", "description": "Adaptive Differential Evolution with Cauchy mutation and dynamic parameter adaptation based on success history.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 10\n        self.p_best = 0.1\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        \n        if np.random.rand() < self.p_best:\n            # p-best strategy\n            indices = np.argsort(self.fitness)\n            p_best_index = indices[np.random.randint(0, int(self.p_best * self.pop_size) or 1)]\n            donor = self.pop[p_best_index]\n        else:\n           #random strategy\n           idx = [r for r in range(self.pop_size) if r != i]\n           a, b = np.random.choice(idx, 2, replace=False)\n           donor = self.pop[i] + F * (self.pop[a] - self.pop[b])\n\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, donor, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def update_parameters(self, success_F_val, success_CR_val):\n        if success_F_val is not None:\n            self.success_F.append(success_F_val)\n            if len(self.success_F) > self.memory_size:\n                self.success_F.pop(0)\n\n        if success_CR_val is not None:\n            self.success_CR.append(success_CR_val)\n            if len(self.success_CR) > self.memory_size:\n                self.success_CR.pop(0)\n        \n        if self.success_F:\n            self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n        if self.success_CR:\n            self.CR = np.clip(np.mean(self.success_CR), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Adaptive parameter generation\n                if self.success_F:\n                  F = np.clip(np.random.normal(np.mean(self.success_F), 0.1), 0.1, 0.9)\n                else:\n                  F = self.F\n                if self.success_CR:\n                  CR = np.clip(np.random.normal(np.mean(self.success_CR), 0.1), 0.1, 0.9)\n                else:\n                  CR = self.CR\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F, CR)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.update_parameters(F, CR)\n                    \n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and dynamic parameter adaptation based on success history.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.success_F = []\n        self.success_CR = []\n        self.memory_size = 10\n        self.p_best = 0.1\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        \n        if np.random.rand() < self.p_best:\n            # p-best strategy\n            indices = np.argsort(self.fitness)\n            p_best_index = indices[np.random.randint(0, int(self.p_best * self.pop_size) or 1)]\n            donor = self.pop[p_best_index]\n        else:\n           #random strategy\n           idx = [r for r in range(self.pop_size) if r != i]\n           a, b = np.random.choice(idx, 2, replace=False)\n           donor = self.pop[i] + F * (self.pop[a] - self.pop[b])\n\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, donor, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def update_parameters(self, success_F_val, success_CR_val):\n        if success_F_val is not None:\n            self.success_F.append(success_F_val)\n            if len(self.success_F) > self.memory_size:\n                self.success_F.pop(0)\n\n        if success_CR_val is not None:\n            self.success_CR.append(success_CR_val)\n            if len(self.success_CR) > self.memory_size:\n                self.success_CR.pop(0)\n        \n        if self.success_F:\n            self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n        if self.success_CR:\n            self.CR = np.clip(np.mean(self.success_CR), 0.1, 0.9)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Adaptive parameter generation\n                if self.success_F:\n                  F = np.clip(np.random.normal(np.mean(self.success_F), 0.1), 0.1, 0.9)\n                else:\n                  F = self.F\n                if self.success_CR:\n                  CR = np.clip(np.random.normal(np.mean(self.success_CR), 0.1), 0.1, 0.9)\n                else:\n                  CR = self.CR\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F, CR)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.update_parameters(F, CR)\n                    \n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.1500725740549239, "generation": 3}, "task_prompt": ""}
{"id": "4a16d346-80de-423e-bda8-489cecfa8f8f", "fitness": "-inf", "name": "PSO_DE", "description": "Population-based algorithm using a combination of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n\n    def initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1\n        return population, velocities\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_parameters(self, diversity, initial_diversity):\n        # Adapt inertia weight based on diversity\n        self.inertia_weight = 0.4 + 0.5 * (diversity / initial_diversity)\n\n        # Adapt mutation and crossover rates based on diversity\n        self.mutation_rate = 0.2 + 0.6 * (1 - (diversity / initial_diversity))\n        self.crossover_rate = 0.5 + 0.4 * (diversity / initial_diversity)\n\n    def differential_evolution(self, population, func):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = population[idxs]\n            mutant = a + self.mutation_rate * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = np.copy(population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate or j == np.random.randint(self.dim):\n                    trial[j] = mutant[j]\n\n            f_trial = func(trial)\n            if f_trial < self.fitness[i]:\n                population[i] = trial\n                self.fitness[i] = f_trial\n\n        return population\n\n    def particle_swarm_optimization(self, population, velocities, personal_best_positions, func):\n        global_best_position = personal_best_positions[np.argmin(self.fitness)]\n\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            velocities[i] = (self.inertia_weight * velocities[i] +\n                             self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                             self.social_coeff * r2 * (global_best_position - population[i]))\n\n            population[i] = population[i] + velocities[i]\n            population[i] = np.clip(population[i], self.lb, self.ub)\n\n            f = func(population[i])\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                personal_best_positions[i] = population[i]\n\n        return population, velocities, personal_best_positions\n    \n\n    def __call__(self, func):\n        population, velocities = self.initialize_population()\n        self.fitness = np.array([func(x) for x in population])\n        personal_best_positions = np.copy(population)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = population[np.argmin(self.fitness)]\n\n        initial_diversity = self.calculate_diversity(population)\n        \n        eval_count = self.pop_size #Initial evaluation\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.update_parameters(diversity, initial_diversity)\n\n            population = self.differential_evolution(population, func)\n            population, velocities, personal_best_positions = self.particle_swarm_optimization(population, velocities, personal_best_positions, func)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = population[best_index]\n                \n            eval_count = np.sum(self.fitness < np.inf)  #Count calls to func\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n\n    def initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1\n        return population, velocities\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        diversity = np.mean(distances)\n        return diversity\n\n    def update_parameters(self, diversity, initial_diversity):\n        # Adapt inertia weight based on diversity\n        self.inertia_weight = 0.4 + 0.5 * (diversity / initial_diversity)\n\n        # Adapt mutation and crossover rates based on diversity\n        self.mutation_rate = 0.2 + 0.6 * (1 - (diversity / initial_diversity))\n        self.crossover_rate = 0.5 + 0.4 * (diversity / initial_diversity)\n\n    def differential_evolution(self, population, func):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = population[idxs]\n            mutant = a + self.mutation_rate * (b - c)\n            mutant = np.clip(mutant, self.lb, self.ub)\n\n            # Crossover\n            trial = np.copy(population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate or j == np.random.randint(self.dim):\n                    trial[j] = mutant[j]\n\n            f_trial = func(trial)\n            if f_trial < self.fitness[i]:\n                population[i] = trial\n                self.fitness[i] = f_trial\n\n        return population\n\n    def particle_swarm_optimization(self, population, velocities, personal_best_positions, func):\n        global_best_position = personal_best_positions[np.argmin(self.fitness)]\n\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n\n            velocities[i] = (self.inertia_weight * velocities[i] +\n                             self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                             self.social_coeff * r2 * (global_best_position - population[i]))\n\n            population[i] = population[i] + velocities[i]\n            population[i] = np.clip(population[i], self.lb, self.ub)\n\n            f = func(population[i])\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                personal_best_positions[i] = population[i]\n\n        return population, velocities, personal_best_positions\n    \n\n    def __call__(self, func):\n        population, velocities = self.initialize_population()\n        self.fitness = np.array([func(x) for x in population])\n        personal_best_positions = np.copy(population)\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = population[np.argmin(self.fitness)]\n\n        initial_diversity = self.calculate_diversity(population)\n        \n        eval_count = self.pop_size #Initial evaluation\n\n        while eval_count < self.budget:\n            diversity = self.calculate_diversity(population)\n            self.update_parameters(diversity, initial_diversity)\n\n            population = self.differential_evolution(population, func)\n            population, velocities, personal_best_positions = self.particle_swarm_optimization(population, velocities, personal_best_positions, func)\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = population[best_index]\n                \n            eval_count = np.sum(self.fitness < np.inf)  #Count calls to func\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.11361468123193363, "generation": 3}, "task_prompt": ""}
{"id": "14691707-a837-4069-b3f9-3628e423d76b", "fitness": "-inf", "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7, restart_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.c1_init = c1_init\n        self.c2_init = c2_init\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.restart_freq = restart_freq  # Frequency of restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # update the budget after first evaluation\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        velocity = np.zeros((self.pop_size, self.dim))\n        personal_best_pos = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            # Adaptive Parameter Control (linear decrease)\n            w = self.w_init - (self.w_init - 0.4) * (generation / (self.budget + generation))\n            c1 = self.c1_init - (self.c1_init - 0.5) * (generation / (self.budget + generation))\n            c2 = self.c2_init - (self.c2_init - 0.5) * (generation / (self.budget + generation))\n            F = self.F_init - (self.F_init - 0.4) * (generation / (self.budget + generation))\n            CR = self.CR_init - (self.CR_init - 0.4) * (generation / (self.budget + generation))\n\n            for i in range(self.pop_size):\n                # PSO Update\n                velocity[i] = w * velocity[i] + \\\n                              c1 * np.random.rand(self.dim) * (personal_best_pos[i] - population[i]) + \\\n                              c2 * np.random.rand(self.dim) * (self.x_opt - population[i])\n\n                # DE Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                \n                # Ensure that the chosen indices are different from the current particle's index\n                while i in idxs:\n                  idxs = np.random.choice(self.pop_size, 3, replace=False)\n                  x_1, x_2, x_3 = population[idxs]\n\n\n                mutant = x_1 + F * (x_2 - x_3)\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                self.budget -= 1 # budget update\n\n                if f_trial < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_trial\n                    personal_best_pos[i] = trial_vector\n\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial_vector.copy()\n\n\n                # Selection: Trial vector replaces the current particle. \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n            \n            # Restart mechanism\n            if (generation+1) % self.restart_freq == 0:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                velocity = np.zeros((self.pop_size, self.dim))\n                personal_best_pos = population.copy()\n                personal_best_fitness = fitness.copy()\n\n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7, restart_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.c1_init = c1_init\n        self.c2_init = c2_init\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.restart_freq = restart_freq  # Frequency of restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # update the budget after first evaluation\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        velocity = np.zeros((self.pop_size, self.dim))\n        personal_best_pos = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            # Adaptive Parameter Control (linear decrease)\n            w = self.w_init - (self.w_init - 0.4) * (generation / (self.budget + generation))\n            c1 = self.c1_init - (self.c1_init - 0.5) * (generation / (self.budget + generation))\n            c2 = self.c2_init - (self.c2_init - 0.5) * (generation / (self.budget + generation))\n            F = self.F_init - (self.F_init - 0.4) * (generation / (self.budget + generation))\n            CR = self.CR_init - (self.CR_init - 0.4) * (generation / (self.budget + generation))\n\n            for i in range(self.pop_size):\n                # PSO Update\n                velocity[i] = w * velocity[i] + \\\n                              c1 * np.random.rand(self.dim) * (personal_best_pos[i] - population[i]) + \\\n                              c2 * np.random.rand(self.dim) * (self.x_opt - population[i])\n\n                # DE Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                \n                # Ensure that the chosen indices are different from the current particle's index\n                while i in idxs:\n                  idxs = np.random.choice(self.pop_size, 3, replace=False)\n                  x_1, x_2, x_3 = population[idxs]\n\n\n                mutant = x_1 + F * (x_2 - x_3)\n                \n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial_vector = np.where(cross_points, mutant, population[i])\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                self.budget -= 1 # budget update\n\n                if f_trial < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_trial\n                    personal_best_pos[i] = trial_vector\n\n                if f_trial < self.f_opt:\n                  self.f_opt = f_trial\n                  self.x_opt = trial_vector.copy()\n\n\n                # Selection: Trial vector replaces the current particle. \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n            \n            # Restart mechanism\n            if (generation+1) % self.restart_freq == 0:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n                velocity = np.zeros((self.pop_size, self.dim))\n                personal_best_pos = population.copy()\n                personal_best_fitness = fitness.copy()\n\n            generation += 1\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.09983653459809144, "generation": 3}, "task_prompt": ""}
{"id": "8ef51afb-5e34-4b7a-bb5d-21fa78416bfc", "fitness": "-inf", "name": "AdaptiveCMAES_DE", "description": "A population-based algorithm that combines the strengths of CMA-ES and Differential Evolution by adaptively adjusting its sampling strategy based on population fitness and diversity.", "code": "import numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cma_learning_rate=0.1, de_cr=0.9, de_f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.cma_learning_rate = cma_learning_rate\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = 0.5 * (ub - lb)  # Initial step size\n        C = np.eye(self.dim)  # Covariance matrix\n        \n        # Evolution path and step-size adaptation parameters\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        c_sig = 0.3  # Step-size damping\n        d_sig = 1 + (2 * max(0, np.sqrt((np.sum(self.weights)**2 - np.sum(self.weights**2))) - 1)) / (self.dim + 2) + c_sig\n        \n        # Covariance matrix adaptation parameters\n        c1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        cmu = min(1 - c1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        \n        B = None  # Eigenvectors of C\n        D = None  # Eigenvalues of C\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            if B is None or D is None:\n                x = mean[:, np.newaxis] + sigma * np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size).T\n            else:\n                 x = mean[:, np.newaxis] + sigma * (B @ (D * z))\n\n            x = np.clip(x, lb, ub)\n            \n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.pop_size)])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            for i in range(self.pop_size):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[:, i]\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n            \n            #Differential Evolution step\n            for i in range(self.pop_size):\n              if np.random.rand() < 0.5: #Adaptive probability to execute DE\n\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                x_mutated = x[:,r1] + self.de_f * (x[:,r2]- x[:,r3])\n                x_mutated = np.clip(x_mutated, lb, ub)\n                \n                j_rand = np.random.randint(self.dim)\n                x_trial = x[:, i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                f_trial = func(x_trial)\n                eval_count += 1\n\n                if f_trial < f[i]:\n                    x[:, i] = x_trial\n                    f[i] = f_trial\n\n                    if f[i] < self.f_opt:\n                      self.f_opt = f[i]\n                      self.x_opt = x[:, i]\n            \n            # Selection and update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = (x[:, :self.mu] - mean[:, np.newaxis]) / sigma\n            \n            # Update evolution paths\n            ps = (1 - c_sig) * ps + np.sqrt(c_sig * (2 - c_sig)) * (B @ y @ self.weights)\n            pc = (1 - c1) * pc + np.sqrt(c1 * (2 - c1)) * y @ self.weights if np.linalg.norm(ps) / chiN < 1.4 else (1 - c1) * pc\n            \n            # Update covariance matrix\n            C = (1 - c1 - cmu) * C + c1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) + cmu * (y @ np.diag(self.weights) @ y.T)\n            \n            # Update step size\n            sigma *= np.exp((c_sig / d_sig) * (np.linalg.norm(ps) / chiN - 1))\n            \n            # Update mean\n            mean = xmean\n            \n            # Eigendecomposition of C\n            if eval_count % (self.budget//10) == 0:\n                try:\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(np.maximum(D, 1e-16))\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim) # Reset covariance matrix if it becomes ill-conditioned\n                    B = None\n                    D = None\n            if eval_count >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "In the code, line 45, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = mean[:, np.newaxis] + sigma * np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size).T", "error": "In the code, line 45, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = mean[:, np.newaxis] + sigma * np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size).T", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines the strengths of CMA-ES and Differential Evolution by adaptively adjusting its sampling strategy based on population fitness and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cma_learning_rate=0.1, de_cr=0.9, de_f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.cma_learning_rate = cma_learning_rate\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.mu = self.pop_size // 2  # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = 0.5 * (ub - lb)  # Initial step size\n        C = np.eye(self.dim)  # Covariance matrix\n        \n        # Evolution path and step-size adaptation parameters\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        c_sig = 0.3  # Step-size damping\n        d_sig = 1 + (2 * max(0, np.sqrt((np.sum(self.weights)**2 - np.sum(self.weights**2))) - 1)) / (self.dim + 2) + c_sig\n        \n        # Covariance matrix adaptation parameters\n        c1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        cmu = min(1 - c1, 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        \n        B = None  # Eigenvectors of C\n        D = None  # Eigenvalues of C\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            if B is None or D is None:\n                x = mean[:, np.newaxis] + sigma * np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size).T\n            else:\n                 x = mean[:, np.newaxis] + sigma * (B @ (D * z))\n\n            x = np.clip(x, lb, ub)\n            \n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.pop_size)])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            for i in range(self.pop_size):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[:, i]\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n            \n            #Differential Evolution step\n            for i in range(self.pop_size):\n              if np.random.rand() < 0.5: #Adaptive probability to execute DE\n\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                x_mutated = x[:,r1] + self.de_f * (x[:,r2]- x[:,r3])\n                x_mutated = np.clip(x_mutated, lb, ub)\n                \n                j_rand = np.random.randint(self.dim)\n                x_trial = x[:, i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                f_trial = func(x_trial)\n                eval_count += 1\n\n                if f_trial < f[i]:\n                    x[:, i] = x_trial\n                    f[i] = f_trial\n\n                    if f[i] < self.f_opt:\n                      self.f_opt = f[i]\n                      self.x_opt = x[:, i]\n            \n            # Selection and update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = (x[:, :self.mu] - mean[:, np.newaxis]) / sigma\n            \n            # Update evolution paths\n            ps = (1 - c_sig) * ps + np.sqrt(c_sig * (2 - c_sig)) * (B @ y @ self.weights)\n            pc = (1 - c1) * pc + np.sqrt(c1 * (2 - c1)) * y @ self.weights if np.linalg.norm(ps) / chiN < 1.4 else (1 - c1) * pc\n            \n            # Update covariance matrix\n            C = (1 - c1 - cmu) * C + c1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) + cmu * (y @ np.diag(self.weights) @ y.T)\n            \n            # Update step size\n            sigma *= np.exp((c_sig / d_sig) * (np.linalg.norm(ps) / chiN - 1))\n            \n            # Update mean\n            mean = xmean\n            \n            # Eigendecomposition of C\n            if eval_count % (self.budget//10) == 0:\n                try:\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(np.maximum(D, 1e-16))\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim) # Reset covariance matrix if it becomes ill-conditioned\n                    B = None\n                    D = None\n            if eval_count >= self.budget:\n                break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0372476426394463, "generation": 3}, "task_prompt": ""}
{"id": "f9fee07e-fff5-4607-ae01-6c2df979ed5a", "fitness": 0.0, "name": "AdaptiveDE_Cauchy_Rejuvenation", "description": "Adaptive Differential Evolution with Cauchy mutation and periodic population rejuvenation to maintain diversity and escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE_Cauchy_Rejuvenation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, rejuvenation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.rejuvenation_rate = rejuvenation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        \n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        mutant = a + self.F * (b - c) + cauchy_mutation\n        return mutant\n    \n    def crossover(self, individual, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, individual)\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def rejuvenate_population(self):\n        num_to_rejuvenate = int(self.rejuvenation_rate * self.pop_size)\n        indices_to_rejuvenate = np.random.choice(self.pop_size, num_to_rejuvenate, replace=False)\n        self.pop[indices_to_rejuvenate] = np.random.uniform(self.lb, self.ub, size=(num_to_rejuvenate, self.dim))\n        return indices_to_rejuvenate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                mutant = self.bound_handling(mutant)\n                trial = self.crossover(self.pop[i], mutant)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n\n            rejuvenation_indices = self.rejuvenate_population()\n            self.fitness[rejuvenation_indices] = [func(x) for x in self.pop[rejuvenation_indices]]\n            eval_count += len(rejuvenation_indices)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE_Cauchy_Rejuvenation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and periodic population rejuvenation to maintain diversity and escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_Cauchy_Rejuvenation:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, rejuvenation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.rejuvenation_rate = rejuvenation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        \n        cauchy_mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        mutant = a + self.F * (b - c) + cauchy_mutation\n        return mutant\n    \n    def crossover(self, individual, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, individual)\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def rejuvenate_population(self):\n        num_to_rejuvenate = int(self.rejuvenation_rate * self.pop_size)\n        indices_to_rejuvenate = np.random.choice(self.pop_size, num_to_rejuvenate, replace=False)\n        self.pop[indices_to_rejuvenate] = np.random.uniform(self.lb, self.ub, size=(num_to_rejuvenate, self.dim))\n        return indices_to_rejuvenate\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                mutant = self.bound_handling(mutant)\n                trial = self.crossover(self.pop[i], mutant)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if eval_count >= self.budget:\n                    break\n\n            rejuvenation_indices = self.rejuvenate_population()\n            self.fitness[rejuvenation_indices] = [func(x) for x in self.pop[rejuvenation_indices]]\n            eval_count += len(rejuvenation_indices)\n            \n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n        \n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.004766879256747821, "generation": 3, "aucs": [0]}, "task_prompt": ""}
{"id": "40b1cc43-a50e-4acb-80f7-e84515f154cc", "fitness": "-inf", "name": "HybridPSO_DE", "description": "A population-based algorithm combining aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.c1_init = c1_init\n        self.c2_init = c2_init\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1  # Initialize velocities\n        self.fitness = np.zeros(self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        self.w = self.w_init\n        self.c1 = self.c1_init\n        self.c2 = self.c2_init\n        self.F = self.F_init\n        self.CR = self.CR_init\n\n\n    def __call__(self, func):\n        eval_count = 0\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if self.fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = self.fitness[i]\n                    self.global_best_position = self.population[i].copy()\n\n        while eval_count < self.budget:\n            # Diversity calculation\n            diversity = np.std(self.population)\n\n            # Parameter adaptation based on diversity\n            self.w = self.w_init - (self.w_init - 0.4) * (1 - diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))  # Inertia weight decreases with diversity\n            self.c1 = self.c1_init - (self.c1_init - 0.5) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))   # Cognitive coefficient decreases with diversity\n            self.c2 = self.c2_init + (3.5 - self.c2_init) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))    # Social coefficient increases with diversity\n            self.F = self.F_init - (self.F_init - 0.3) * (1 - diversity / ((self.ub - self.lb)*np.sqrt(self.dim))) #Mutation factor decreases with diversity\n            self.CR = self.CR_init + (0.95-self.CR_init) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))   #Crossover rate increases with diversity\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.population[i])\n\n                # Ensure velocities are within reasonable bounds\n                self.velocities[i] = np.clip(self.velocities[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n                \n                trial_vector = self.population[i] + self.velocities[i]\n\n                # DE crossover and mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                # Boundary handling\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector.copy()\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 3, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm combining aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.c1_init = c1_init\n        self.c2_init = c2_init\n        self.F_init = F_init\n        self.CR_init = CR_init\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (self.ub - self.lb) * 0.1  # Initialize velocities\n        self.fitness = np.zeros(self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n        self.w = self.w_init\n        self.c1 = self.c1_init\n        self.c2 = self.c2_init\n        self.F = self.F_init\n        self.CR = self.CR_init\n\n\n    def __call__(self, func):\n        eval_count = 0\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            eval_count += 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if self.fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = self.fitness[i]\n                    self.global_best_position = self.population[i].copy()\n\n        while eval_count < self.budget:\n            # Diversity calculation\n            diversity = np.std(self.population)\n\n            # Parameter adaptation based on diversity\n            self.w = self.w_init - (self.w_init - 0.4) * (1 - diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))  # Inertia weight decreases with diversity\n            self.c1 = self.c1_init - (self.c1_init - 0.5) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))   # Cognitive coefficient decreases with diversity\n            self.c2 = self.c2_init + (3.5 - self.c2_init) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))    # Social coefficient increases with diversity\n            self.F = self.F_init - (self.F_init - 0.3) * (1 - diversity / ((self.ub - self.lb)*np.sqrt(self.dim))) #Mutation factor decreases with diversity\n            self.CR = self.CR_init + (0.95-self.CR_init) * (diversity / ((self.ub - self.lb)*np.sqrt(self.dim)))   #Crossover rate increases with diversity\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.population[i])\n\n                # Ensure velocities are within reasonable bounds\n                self.velocities[i] = np.clip(self.velocities[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n                \n                trial_vector = self.population[i] + self.velocities[i]\n\n                # DE crossover and mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                # Boundary handling\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector.copy()\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n                \n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.044442521460281006, "generation": 3}, "task_prompt": ""}
{"id": "5688b583-bc74-4cb5-8ebc-3e2ec55b5698", "fitness": 0.6228604532979062, "name": "AdaptiveCauchyDE", "description": "Adaptive Differential Evolution with Cauchy mutation and a shrinking search space, dynamically adjusting mutation scale based on population diversity and performance.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9)) #Prevent division by zero\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveCauchyDE scored 0.623 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and a shrinking search space, dynamically adjusting mutation scale based on population diversity and performance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9)) #Prevent division by zero\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.08596452391240234, "generation": 3, "aucs": [0.20327155157947585, 0.3135395549357024, 0.6122687657102981, 0.836911771674555, 0.716879777194583, 0.7562013429273216, 0.519808353527821, 0.5763506119633344, 0.7077579400535927, 0.6012269605883733, 0.7859215229066654, 0.9945360620833147, 0.34764161569769036, 0.656627022294646, 0.8782536523264551, 0.7669921084185676, 0.515073298951727, 0.8129471433367346, 0.32738183162461565, 0.5276181781626502]}, "task_prompt": ""}
{"id": "0b5e25fe-c700-47d8-8696-dfedd6b5a2bc", "fitness": "-inf", "name": "EnhancedCauchyDE", "description": "An enhanced Differential Evolution strategy incorporating Cauchy mutation, adaptive parameter control, and periodic population restarts to maintain diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.cauchy_scale = cauchy_scale # Scale for Cauchy mutation\n        self.restart_trigger = restart_trigger # Diversity threshold for restarts\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_interval = 50 # Restart every n iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def check_diversity(self):\n        diversity = np.std(self.pop)\n        return diversity < self.restart_trigger\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.cauchy_scale = 0.1 # Reset Cauchy scale\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            generation += 1\n            # Adaptive Cauchy Scale\n            self.cauchy_scale *= 0.995\n\n            # Periodically Restart\n            if generation % self.restart_interval == 0 or self.check_diversity():\n                self.restart_population(func)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: An enhanced Differential Evolution strategy incorporating Cauchy mutation, adaptive parameter control, and periodic population restarts to maintain diversity and exploration.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.cauchy_scale = cauchy_scale # Scale for Cauchy mutation\n        self.restart_trigger = restart_trigger # Diversity threshold for restarts\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_interval = 50 # Restart every n iterations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def check_diversity(self):\n        diversity = np.std(self.pop)\n        return diversity < self.restart_trigger\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.cauchy_scale = 0.1 # Reset Cauchy scale\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            generation += 1\n            # Adaptive Cauchy Scale\n            self.cauchy_scale *= 0.995\n\n            # Periodically Restart\n            if generation % self.restart_interval == 0 or self.check_diversity():\n                self.restart_population(func)\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.017032666388125308, "generation": 4}, "task_prompt": ""}
{"id": "f146770d-5705-4e95-9035-0ed534d2209f", "fitness": "-inf", "name": "AdaptiveDEwithLocalSearch", "description": "Population-based algorithm using a combination of Differential Evolution and a local search operator based on gradient estimation, adaptively adjusting the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.9, de_f=0.7, ls_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.ls_step_size = ls_step_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = self.population[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.population[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Estimate gradient (very rough)\n            gradient = np.zeros(self.dim)\n            for j in range(self.dim):\n                x_plus = self.population[i].copy()\n                x_minus = self.population[i].copy()\n                x_plus[j] += self.ls_step_size\n                x_minus[j] -= self.ls_step_size\n                x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n                x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n\n                f_plus = func(x_plus)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                f_minus = func(x_minus)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                gradient[j] = (f_plus - f_minus) / (2 * self.ls_step_size)\n\n            # Take a step in the direction of the negative gradient\n            x_new = self.population[i] - self.ls_step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.eval_count += 1\n            \n            if f_new < self.fitness[i]:\n                self.fitness[i] = f_new\n                self.population[i] = x_new\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        de_prob = 0.7 # Probability of performing DE\n        \n        while self.eval_count < self.budget:\n            if np.random.rand() < de_prob:\n                self.differential_evolution(func)\n            else:\n                self.local_search(func)\n            \n            # Adaptive adjustment of probabilities (simplified)\n            if np.random.rand() < 0.1: # Adjust every 10% of budget\n              if np.random.rand() < 0.5:\n                de_prob = min(1.0, de_prob + 0.1) # Increase DE prob\n              else:\n                de_prob = max(0.0, de_prob - 0.1) # Decrease DE prob\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "In the code, line 60, in local_search, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)", "error": "In the code, line 60, in local_search, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of Differential Evolution and a local search operator based on gradient estimation, adaptively adjusting the balance between exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, de_cr=0.9, de_f=0.7, ls_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.ls_step_size = ls_step_size\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            x_mutated = x_r1 + self.de_f * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            j_rand = np.random.randint(self.dim)\n            x_trial = self.population[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.population[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Estimate gradient (very rough)\n            gradient = np.zeros(self.dim)\n            for j in range(self.dim):\n                x_plus = self.population[i].copy()\n                x_minus = self.population[i].copy()\n                x_plus[j] += self.ls_step_size\n                x_minus[j] -= self.ls_step_size\n                x_plus[j] = np.clip(x_plus[j], func.bounds.lb, func.bounds.ub)\n                x_minus[j] = np.clip(x_minus[j], func.bounds.lb, func.bounds.ub)\n\n                f_plus = func(x_plus)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n                f_minus = func(x_minus)\n                self.eval_count += 1\n                if self.eval_count >= self.budget:\n                    break\n\n                gradient[j] = (f_plus - f_minus) / (2 * self.ls_step_size)\n\n            # Take a step in the direction of the negative gradient\n            x_new = self.population[i] - self.ls_step_size * gradient\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.eval_count += 1\n            \n            if f_new < self.fitness[i]:\n                self.fitness[i] = f_new\n                self.population[i] = x_new\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        de_prob = 0.7 # Probability of performing DE\n        \n        while self.eval_count < self.budget:\n            if np.random.rand() < de_prob:\n                self.differential_evolution(func)\n            else:\n                self.local_search(func)\n            \n            # Adaptive adjustment of probabilities (simplified)\n            if np.random.rand() < 0.1: # Adjust every 10% of budget\n              if np.random.rand() < 0.5:\n                de_prob = min(1.0, de_prob + 0.1) # Increase DE prob\n              else:\n                de_prob = max(0.0, de_prob - 0.1) # Decrease DE prob\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.05088103239117889, "generation": 4}, "task_prompt": ""}
{"id": "a33cfece-aa53-45cb-8670-7d279fdad68b", "fitness": "-inf", "name": "AdaptiveCauchyDE_with_Dynamic_Params_and_Restart", "description": "Adaptive Cauchy Differential Evolution with dynamic F and CR, and a restart mechanism based on population stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE_with_Dynamic_Params_and_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_scale=0.1, stagnation_threshold=1e-6, stagnation_generations=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_generations = stagnation_generations\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy() # Added .copy() here\n        self.best_fitness_history.append(self.f_opt)\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def check_stagnation(self):\n        if len(self.best_fitness_history) < self.stagnation_generations:\n            return False\n        \n        recent_history = self.best_fitness_history[-self.stagnation_generations:]\n        return np.std(recent_history) < self.stagnation_threshold\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        # Update f_opt and x_opt only if the new population finds a better solution\n        new_f_opt = np.min(self.fitness)\n        new_x_opt = self.pop[np.argmin(self.fitness)].copy() # added .copy() here\n\n        if new_f_opt < self.f_opt:\n            self.f_opt = new_f_opt\n            self.x_opt = new_x_opt\n        self.best_fitness_history.append(self.f_opt)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        generation = 0\n\n        while self.eval_count < self.budget:\n            generation += 1\n            # Adaptive F and CR\n            F = 0.5 + 0.5 * np.random.rand()\n            CR = np.random.uniform(0.3, 0.9)\n\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F, CR)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy() # added .copy() here\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            self.best_fitness_history.append(self.f_opt)\n            \n            if self.check_stagnation():\n                self.restart_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698", "a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Cauchy Differential Evolution with dynamic F and CR, and a restart mechanism based on population stagnation detection.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE_with_Dynamic_Params_and_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_scale=0.1, stagnation_threshold=1e-6, stagnation_generations=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_generations = stagnation_generations\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy() # Added .copy() here\n        self.best_fitness_history.append(self.f_opt)\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F, CR):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def check_stagnation(self):\n        if len(self.best_fitness_history) < self.stagnation_generations:\n            return False\n        \n        recent_history = self.best_fitness_history[-self.stagnation_generations:]\n        return np.std(recent_history) < self.stagnation_threshold\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        # Update f_opt and x_opt only if the new population finds a better solution\n        new_f_opt = np.min(self.fitness)\n        new_x_opt = self.pop[np.argmin(self.fitness)].copy() # added .copy() here\n\n        if new_f_opt < self.f_opt:\n            self.f_opt = new_f_opt\n            self.x_opt = new_x_opt\n        self.best_fitness_history.append(self.f_opt)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        generation = 0\n\n        while self.eval_count < self.budget:\n            generation += 1\n            # Adaptive F and CR\n            F = 0.5 + 0.5 * np.random.rand()\n            CR = np.random.uniform(0.3, 0.9)\n\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F, CR)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy() # added .copy() here\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            self.best_fitness_history.append(self.f_opt)\n            \n            if self.check_stagnation():\n                self.restart_population(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.002871490335099269, "generation": 4}, "task_prompt": ""}
{"id": "368c1cc1-7466-44be-9a15-6eed172db9bf", "fitness": "-inf", "name": "AdaptiveMutationEvolutionStrategy", "description": "A population-based algorithm that adapts its mutation strategy based on the success rate of each individual, combined with a local search to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveMutationEvolutionStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.mutation_strengths = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.mutation_strengths = np.ones(self.pop_size) * 0.1  # Initialize mutation strengths\n\n    def mutate(self, x, mutation_strength, func):\n        noise = np.random.normal(0, mutation_strength, size=self.dim)\n        mutated_x = x + noise\n        mutated_x = np.clip(mutated_x, func.bounds.lb, func.bounds.ub)\n        return mutated_x\n\n    def local_search(self, x, func):\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a small random step\n            step = np.random.uniform(-0.1, 0.1, size=self.dim)\n            new_x = np.clip(best_x + step, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.eval_count += 1\n            \n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n                \n            if self.eval_count >= self.budget:\n                break\n\n        return best_x, best_f\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                mutated_x = self.mutate(self.population[i], self.mutation_strengths[i], func)\n                mutated_f = func(mutated_x)\n                self.eval_count += 1\n                \n                # Local Search\n                local_x, local_f = self.local_search(mutated_x, func)\n\n                if local_f < mutated_f:\n                    mutated_x = local_x\n                    mutated_f = local_f\n                    \n                # Selection (replace if better)\n                if mutated_f < self.fitness[i]:\n                    new_population[i] = mutated_x\n                    new_fitness[i] = mutated_f\n                    self.mutation_strengths[i] *= 1.1  # Increase mutation strength if successful\n                else:\n                    new_population[i] = self.population[i]  # Keep the old one\n                    new_fitness[i] = self.fitness[i]\n                    self.mutation_strengths[i] *= 0.9  # Decrease mutation strength if unsuccessful\n                    \n                self.mutation_strengths[i] = np.clip(self.mutation_strengths[i], 0.01, 1.0)  # Limit mutation strengths\n\n                if mutated_f < self.f_opt:\n                    self.f_opt = mutated_f\n                    self.x_opt = mutated_x\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n            \n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adapts its mutation strategy based on the success rate of each individual, combined with a local search to refine promising solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveMutationEvolutionStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.mutation_strengths = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.mutation_strengths = np.ones(self.pop_size) * 0.1  # Initialize mutation strengths\n\n    def mutate(self, x, mutation_strength, func):\n        noise = np.random.normal(0, mutation_strength, size=self.dim)\n        mutated_x = x + noise\n        mutated_x = np.clip(mutated_x, func.bounds.lb, func.bounds.ub)\n        return mutated_x\n\n    def local_search(self, x, func):\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            # Generate a small random step\n            step = np.random.uniform(-0.1, 0.1, size=self.dim)\n            new_x = np.clip(best_x + step, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.eval_count += 1\n            \n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n                \n            if self.eval_count >= self.budget:\n                break\n\n        return best_x, best_f\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        self.initialize_population(func)\n        \n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n\n        while self.eval_count < self.budget:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation\n                mutated_x = self.mutate(self.population[i], self.mutation_strengths[i], func)\n                mutated_f = func(mutated_x)\n                self.eval_count += 1\n                \n                # Local Search\n                local_x, local_f = self.local_search(mutated_x, func)\n\n                if local_f < mutated_f:\n                    mutated_x = local_x\n                    mutated_f = local_f\n                    \n                # Selection (replace if better)\n                if mutated_f < self.fitness[i]:\n                    new_population[i] = mutated_x\n                    new_fitness[i] = mutated_f\n                    self.mutation_strengths[i] *= 1.1  # Increase mutation strength if successful\n                else:\n                    new_population[i] = self.population[i]  # Keep the old one\n                    new_fitness[i] = self.fitness[i]\n                    self.mutation_strengths[i] *= 0.9  # Decrease mutation strength if unsuccessful\n                    \n                self.mutation_strengths[i] = np.clip(self.mutation_strengths[i], 0.01, 1.0)  # Limit mutation strengths\n\n                if mutated_f < self.f_opt:\n                    self.f_opt = mutated_f\n                    self.x_opt = mutated_x\n\n                if self.eval_count >= self.budget:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n            \n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03060368157644497, "generation": 4}, "task_prompt": ""}
{"id": "410c696e-a871-4db6-8035-7cb3a6ce901b", "fitness": 0.3326881358499797, "name": "AdaptiveVarianceGradientEstimation", "description": "An Adaptive Variance Gradient Estimation (AVGE) algorithm that estimates gradients using small perturbations and adjusts the variance of perturbations adaptively based on success.", "code": "import numpy as np\n\nclass AdaptiveVarianceGradientEstimation:\n    def __init__(self, budget=10000, dim=10, initial_variance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_variance = initial_variance\n        self.variance = initial_variance * np.ones(dim)\n        self.success_rate = np.zeros(dim)\n        self.learning_rate = 0.1\n        self.exploration_exploitation_tradeoff = 0.1\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x randomly\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        eval_count = 1\n\n        while eval_count < self.budget:\n            for i in range(self.dim):\n                # Generate a small perturbation\n                delta = np.zeros(self.dim)\n                delta[i] = np.random.normal(0, np.sqrt(self.variance[i]))\n\n                # Ensure the perturbed point remains within bounds\n                x_plus = np.clip(x + delta, func.bounds.lb, func.bounds.ub)\n                \n                if eval_count < self.budget:\n                    f_plus = func(x_plus)\n                    eval_count += 1\n                else:\n                    break # respect budget\n                \n                if f_plus < self.f_opt:\n                    self.f_opt = f_plus\n                    self.x_opt = x_plus\n                    x = x_plus\n                    f = f_plus\n                    self.success_rate[i] = (1 - self.learning_rate) * self.success_rate[i] + self.learning_rate # Update success rate.\n\n\n                    self.variance[i] *= (1 - self.exploration_exploitation_tradeoff + self.exploration_exploitation_tradeoff * self.success_rate[i])\n                    # Update the variance: if we improved, we decrease it.\n\n                else:\n                   self.success_rate[i] = (1 - self.learning_rate) * self.success_rate[i] # Update success rate.\n                   self.variance[i] *= (1 + self.exploration_exploitation_tradeoff)\n\n\n                self.variance = np.clip(self.variance, 1e-6, 1.0) #prevent variance from exploding or vanishing\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveVarianceGradientEstimation scored 0.333 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An Adaptive Variance Gradient Estimation (AVGE) algorithm that estimates gradients using small perturbations and adjusts the variance of perturbations adaptively based on success.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveVarianceGradientEstimation:\n    def __init__(self, budget=10000, dim=10, initial_variance=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_variance = initial_variance\n        self.variance = initial_variance * np.ones(dim)\n        self.success_rate = np.zeros(dim)\n        self.learning_rate = 0.1\n        self.exploration_exploitation_tradeoff = 0.1\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x randomly\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        eval_count = 1\n\n        while eval_count < self.budget:\n            for i in range(self.dim):\n                # Generate a small perturbation\n                delta = np.zeros(self.dim)\n                delta[i] = np.random.normal(0, np.sqrt(self.variance[i]))\n\n                # Ensure the perturbed point remains within bounds\n                x_plus = np.clip(x + delta, func.bounds.lb, func.bounds.ub)\n                \n                if eval_count < self.budget:\n                    f_plus = func(x_plus)\n                    eval_count += 1\n                else:\n                    break # respect budget\n                \n                if f_plus < self.f_opt:\n                    self.f_opt = f_plus\n                    self.x_opt = x_plus\n                    x = x_plus\n                    f = f_plus\n                    self.success_rate[i] = (1 - self.learning_rate) * self.success_rate[i] + self.learning_rate # Update success rate.\n\n\n                    self.variance[i] *= (1 - self.exploration_exploitation_tradeoff + self.exploration_exploitation_tradeoff * self.success_rate[i])\n                    # Update the variance: if we improved, we decrease it.\n\n                else:\n                   self.success_rate[i] = (1 - self.learning_rate) * self.success_rate[i] # Update success rate.\n                   self.variance[i] *= (1 + self.exploration_exploitation_tradeoff)\n\n\n                self.variance = np.clip(self.variance, 1e-6, 1.0) #prevent variance from exploding or vanishing\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.07307979944425763, "generation": 4, "aucs": [0.13546967627668216, 0.09586882396891849, 0.5438401990532699, 0.16672315145216965, 0.23844365937258027, 0.5823176882734582, 0.3164582410028489, 0.34206042066849074, 0.3259488710271171, 0.13971780513441612, 0.2896305433875316, 0.979488338467694, 0.23866234755389903, 0.22672982616028436, 0.667723570042863, 0.5997517072729548, 0.3236155985139112, 0.15406040904723284, 0.13067320675754546, 0.15657863356572665]}, "task_prompt": ""}
{"id": "8872ac6c-3712-4be3-b5d7-65c588779648", "fitness": 0.40176654942620693, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation, population diversity maintenance, and reduced parameter reliance for efficient black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.diversity_threshold = diversity_threshold\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutation(self, pop, i, scale):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + scale * np.random.standard_cauchy(size=self.dim)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the average Euclidean distance between population members.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.pop[i] - self.pop[j]))\n        return np.mean(distances) if distances else 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            scale = (self.ub - self.lb) * np.exp(-5 * diversity)  # Adaptive Cauchy scale\n\n            for i in range(self.pop_size):\n                mutated = self.mutation(self.pop, i, scale)\n                mutated = self.bound_handling(mutated)\n                trial = self.crossover(self.pop, i, mutated)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Diversity Maintenance (Restart if diversity is too low)\n            if diversity < self.diversity_threshold:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.pop[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.402 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation, population diversity maintenance, and reduced parameter reliance for efficient black-box optimization.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.diversity_threshold = diversity_threshold\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutation(self, pop, i, scale):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + scale * np.random.standard_cauchy(size=self.dim)\n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the average Euclidean distance between population members.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(self.pop[i] - self.pop[j]))\n        return np.mean(distances) if distances else 0\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            diversity = self.calculate_diversity()\n            scale = (self.ub - self.lb) * np.exp(-5 * diversity)  # Adaptive Cauchy scale\n\n            for i in range(self.pop_size):\n                mutated = self.mutation(self.pop, i, scale)\n                mutated = self.bound_handling(mutated)\n                trial = self.crossover(self.pop, i, mutated)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n\n            # Diversity Maintenance (Restart if diversity is too low)\n            if diversity < self.diversity_threshold:\n                self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.pop])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.pop[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.017248458014839534, "generation": 4, "aucs": [0.19691638389710087, 0.3249498035424365, 0.3673467651582091, 0.44134375066027465, 0.3115295677024916, 0.37469778798388065, 0.3192636353422361, 0.30743501316863253, 0.299551294552286, 0.24483930516604824, 0.4357950245887827, 0.997211566689656, 0.365277889547607, 0.2957574814334616, 0.7627708678899272, 0.40241149880155136, 0.31839005970022394, 0.4787506195942196, 0.28568758796857807, 0.505405085136535]}, "task_prompt": ""}
{"id": "b2285712-3594-4a10-b39a-7912bbf7f033", "fitness": 0.14186349625569997, "name": "SelfAdaptiveCMAES", "description": "A self-adaptive variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified adaptation rule and a population size that adapts to the budget remaining.", "code": "import numpy as np\n\nclass SelfAdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu = int(budget / 20) # Initial population size, adjust based on budget\n        if self.mu < 1:\n            self.mu = 1\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.used_budget = 0\n\n        while self.used_budget < self.budget:\n            #Adapt population size based on remaining budget\n            remaining_budget = self.budget - self.used_budget\n            self.mu = int(remaining_budget / 20)\n            if self.mu < 1:\n                self.mu = 1\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.mu, self.dim))\n            x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n            # Clip to bounds\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            self.used_budget += self.mu\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update mean\n            self.mean = np.mean(x[:self.mu//2], axis=0) \n\n            # Simplified rank-one update of covariance matrix\n            delta = (self.mean - self.mean) / self.sigma #Use zero vector to avoid division by zero error when the mean is the initial mean\n            \n            if np.linalg.norm(self.mean - self.mean) > 0: #Update covariance matrix only if the mean has been updated\n                delta = (self.mean - self.mean) / self.sigma\n                self.C = (1 - 0.1) * self.C + 0.1 * np.outer(delta, delta)\n\n            #Adapt Step Size\n            cs = 0.3\n            damps = 1 + (self.mu / self.dim)\n\n            self.sigma *= np.exp((cs / damps) * (np.mean(f) - self.f_opt) / np.std(f)) \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptiveCMAES scored 0.142 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-adaptive variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a simplified adaptation rule and a population size that adapts to the budget remaining.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu = int(budget / 20) # Initial population size, adjust based on budget\n        if self.mu < 1:\n            self.mu = 1\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.mean = np.random.uniform(lb, ub, self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.used_budget = 0\n\n        while self.used_budget < self.budget:\n            #Adapt population size based on remaining budget\n            remaining_budget = self.budget - self.used_budget\n            self.mu = int(remaining_budget / 20)\n            if self.mu < 1:\n                self.mu = 1\n\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.mu, self.dim))\n            x = self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n            # Clip to bounds\n            x = np.clip(x, lb, ub)\n\n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            self.used_budget += self.mu\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update mean\n            self.mean = np.mean(x[:self.mu//2], axis=0) \n\n            # Simplified rank-one update of covariance matrix\n            delta = (self.mean - self.mean) / self.sigma #Use zero vector to avoid division by zero error when the mean is the initial mean\n            \n            if np.linalg.norm(self.mean - self.mean) > 0: #Update covariance matrix only if the mean has been updated\n                delta = (self.mean - self.mean) / self.sigma\n                self.C = (1 - 0.1) * self.C + 0.1 * np.outer(delta, delta)\n\n            #Adapt Step Size\n            cs = 0.3\n            damps = 1 + (self.mu / self.dim)\n\n            self.sigma *= np.exp((cs / damps) * (np.mean(f) - self.f_opt) / np.std(f)) \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.01659379036017324, "generation": 4, "aucs": [0.0085921187466107, 0.15192227136016845, 0.23900250264616374, 0.10007346615131696, 0.09487042096692144, 0.16034184655638817, 0.13451162050242838, 0.13365952325123798, 0.16647346959190323, 0.13816689962541773, 0.10085280057317303, 0.23951305545998613, 0.0997324291587649, 0.16198604976792208, 0.18399055626283212, 0.15660124602172454, 0.17871120072808477, 0.13378568485256215, 0.07375536051329801, 0.1807274023770944]}, "task_prompt": ""}
{"id": "d00d9ef5-6b02-4669-b674-5f6bf37b48fe", "fitness": "-inf", "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution, with an adaptive mutation strategy and restart mechanism to enhance exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.F = F  # Mutation factor for DE\n        self.cr = cr  # Crossover rate for DE\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        \n        # Initialize velocities (small random values)\n        self.velocities = np.random.uniform(-0.1*(self.ub - self.lb), 0.1*(self.ub - self.lb), (self.pop_size, self.dim))\n\n        self.best_fitness = np.inf\n        self.best_position = None\n        for i in range(self.pop_size):\n            f = self.func(self.pop[i])\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = self.pop[i].copy()\n\n        self.personal_best_positions = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n    def update_particle(self, i):\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.w * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.pop[i]) +\n                              self.c2 * r2 * (self.best_position - self.pop[i]))\n\n        # Update position\n        self.pop[i] = self.pop[i] + self.velocities[i]\n\n        # Boundary handling\n        self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n\n    def differential_evolution(self, i):\n        # Choose three random indices, not including the current index\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while i in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x1, x2, x3 = self.pop[indices[0]], self.pop[indices[1]], self.pop[indices[2]]\n        \n        # Mutation\n        v = x1 + self.F * (x2 - x3)\n        v = np.clip(v, self.lb, self.ub)\n        \n        # Crossover\n        j_rand = np.random.randint(self.dim)\n        u = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                u[j] = v[j]\n\n        return u\n    \n    def local_search(self, x, func, step_size=0.1, num_steps=5):\n            best_x = x.copy()\n            best_f = func(x)\n\n            for _ in range(num_steps):\n                # Generate a random perturbation\n                perturbation = np.random.uniform(-step_size, step_size, self.dim)\n                new_x = np.clip(x + perturbation, self.lb, self.ub)\n                new_f = func(new_x)\n\n                if new_f < best_f:\n                    best_f = new_f\n                    best_x = new_x.copy()\n\n            return best_f, best_x\n\n    def restart(self):\n            # Reinitialize a portion of the population if stagnation is detected\n            num_to_restart = int(0.1 * self.pop_size)  # Restart 10% of population\n            indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n            for i in indices_to_restart:\n                self.pop[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                self.fitness[i] = self.func(self.pop[i])  # Recalculate fitness\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_position = self.pop[i].copy()\n                self.personal_best_positions[i] = self.pop[i].copy()\n                self.personal_best_fitness[i] = self.fitness[i]\n\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        self.initialize_population()\n\n        eval_count = self.pop_size  # Account for initial population evaluations\n        stagnation_counter = 0\n        \n        while eval_count < self.budget:\n            \n            for i in range(self.pop_size):\n                # Apply either PSO or DE with probability 0.5 each\n                if np.random.rand() < 0.5:\n                    self.update_particle(i)\n                else:\n                    u = self.differential_evolution(i)\n                    f_u = self.func(u)\n                    eval_count += 1\n\n                    if f_u < self.fitness[i]:\n                        self.pop[i] = u\n                        self.fitness[i] = f_u\n\n                        if f_u < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_u\n                            self.personal_best_positions[i] = self.pop[i].copy()\n                        \n                        if f_u < self.best_fitness:\n                            self.best_fitness = f_u\n                            self.best_position = self.pop[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate the updated particle and update personal/global best\n                if np.random.rand() < 0.5: # apply local search with probability 0.5\n                   f_local, x_local = self.local_search(self.pop[i], func)\n                   if f_local < self.fitness[i]:\n                        self.pop[i] = x_local\n                        self.fitness[i] = f_local\n                        eval_count+=5\n                        if eval_count > self.budget:\n                            break\n                else:\n                   f = self.func(self.pop[i])\n                   eval_count += 1\n                   self.fitness[i] = f\n\n                   if f < self.personal_best_fitness[i]:\n                       self.personal_best_fitness[i] = f\n                       self.personal_best_positions[i] = self.pop[i].copy()\n                   \n                   if f < self.best_fitness:\n                       self.best_fitness = f\n                       self.best_position = self.pop[i].copy()\n            # Stagnation check and restart\n            if self.best_fitness == self.last_best_fitness:\n                stagnation_counter += 1\n                if stagnation_counter > 50:  # If no improvement for 50 iterations, restart\n                    self.restart()\n                    stagnation_counter = 0\n            else:\n                stagnation_counter = 0\n\n            self.last_best_fitness = self.best_fitness\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 4, "feedback": "In the code, line 166, in __call__, the following error occurred:\nAttributeError: 'HybridPSO_DE' object has no attribute 'last_best_fitness'. Did you mean: 'best_fitness'?\nOn line: if self.best_fitness == self.last_best_fitness:", "error": "In the code, line 166, in __call__, the following error occurred:\nAttributeError: 'HybridPSO_DE' object has no attribute 'last_best_fitness'. Did you mean: 'best_fitness'?\nOn line: if self.best_fitness == self.last_best_fitness:", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and differential evolution, with an adaptive mutation strategy and restart mechanism to enhance exploration and exploitation capabilities.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, F=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.F = F  # Mutation factor for DE\n        self.cr = cr  # Crossover rate for DE\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        \n        # Initialize velocities (small random values)\n        self.velocities = np.random.uniform(-0.1*(self.ub - self.lb), 0.1*(self.ub - self.lb), (self.pop_size, self.dim))\n\n        self.best_fitness = np.inf\n        self.best_position = None\n        for i in range(self.pop_size):\n            f = self.func(self.pop[i])\n            self.fitness[i] = f\n            if f < self.best_fitness:\n                self.best_fitness = f\n                self.best_position = self.pop[i].copy()\n\n        self.personal_best_positions = self.pop.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n    def update_particle(self, i):\n        # Update velocity\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        self.velocities[i] = (self.w * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.pop[i]) +\n                              self.c2 * r2 * (self.best_position - self.pop[i]))\n\n        # Update position\n        self.pop[i] = self.pop[i] + self.velocities[i]\n\n        # Boundary handling\n        self.pop[i] = np.clip(self.pop[i], self.lb, self.ub)\n\n\n    def differential_evolution(self, i):\n        # Choose three random indices, not including the current index\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        while i in indices:\n            indices = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x1, x2, x3 = self.pop[indices[0]], self.pop[indices[1]], self.pop[indices[2]]\n        \n        # Mutation\n        v = x1 + self.F * (x2 - x3)\n        v = np.clip(v, self.lb, self.ub)\n        \n        # Crossover\n        j_rand = np.random.randint(self.dim)\n        u = np.copy(self.pop[i])\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                u[j] = v[j]\n\n        return u\n    \n    def local_search(self, x, func, step_size=0.1, num_steps=5):\n            best_x = x.copy()\n            best_f = func(x)\n\n            for _ in range(num_steps):\n                # Generate a random perturbation\n                perturbation = np.random.uniform(-step_size, step_size, self.dim)\n                new_x = np.clip(x + perturbation, self.lb, self.ub)\n                new_f = func(new_x)\n\n                if new_f < best_f:\n                    best_f = new_f\n                    best_x = new_x.copy()\n\n            return best_f, best_x\n\n    def restart(self):\n            # Reinitialize a portion of the population if stagnation is detected\n            num_to_restart = int(0.1 * self.pop_size)  # Restart 10% of population\n            indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n            for i in indices_to_restart:\n                self.pop[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                self.fitness[i] = self.func(self.pop[i])  # Recalculate fitness\n\n                if self.fitness[i] < self.best_fitness:\n                    self.best_fitness = self.fitness[i]\n                    self.best_position = self.pop[i].copy()\n                self.personal_best_positions[i] = self.pop[i].copy()\n                self.personal_best_fitness[i] = self.fitness[i]\n\n\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        self.initialize_population()\n\n        eval_count = self.pop_size  # Account for initial population evaluations\n        stagnation_counter = 0\n        \n        while eval_count < self.budget:\n            \n            for i in range(self.pop_size):\n                # Apply either PSO or DE with probability 0.5 each\n                if np.random.rand() < 0.5:\n                    self.update_particle(i)\n                else:\n                    u = self.differential_evolution(i)\n                    f_u = self.func(u)\n                    eval_count += 1\n\n                    if f_u < self.fitness[i]:\n                        self.pop[i] = u\n                        self.fitness[i] = f_u\n\n                        if f_u < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_u\n                            self.personal_best_positions[i] = self.pop[i].copy()\n                        \n                        if f_u < self.best_fitness:\n                            self.best_fitness = f_u\n                            self.best_position = self.pop[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate the updated particle and update personal/global best\n                if np.random.rand() < 0.5: # apply local search with probability 0.5\n                   f_local, x_local = self.local_search(self.pop[i], func)\n                   if f_local < self.fitness[i]:\n                        self.pop[i] = x_local\n                        self.fitness[i] = f_local\n                        eval_count+=5\n                        if eval_count > self.budget:\n                            break\n                else:\n                   f = self.func(self.pop[i])\n                   eval_count += 1\n                   self.fitness[i] = f\n\n                   if f < self.personal_best_fitness[i]:\n                       self.personal_best_fitness[i] = f\n                       self.personal_best_positions[i] = self.pop[i].copy()\n                   \n                   if f < self.best_fitness:\n                       self.best_fitness = f\n                       self.best_position = self.pop[i].copy()\n            # Stagnation check and restart\n            if self.best_fitness == self.last_best_fitness:\n                stagnation_counter += 1\n                if stagnation_counter > 50:  # If no improvement for 50 iterations, restart\n                    self.restart()\n                    stagnation_counter = 0\n            else:\n                stagnation_counter = 0\n\n            self.last_best_fitness = self.best_fitness\n        return self.best_fitness, self.best_position\n```", "operator": "random_new", "theta_sampled": 0.041586039077465206, "generation": 4}, "task_prompt": ""}
{"id": "40586cfb-baf9-485b-89e8-b27514847632", "fitness": 0.4086919912230699, "name": "AdaptiveCauchyDE_Shrink", "description": "Adaptive Cauchy Differential Evolution with dynamically adjusted mutation factor and shrinking search space.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE_Shrink:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1, shrink_factor=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.shrink_factor = shrink_factor\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9)) #Prevent division by zero\n            \n            # Dynamically adjust F\n            F = 0.5 + 0.5 * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb\n            self.ub = self.shrink_factor * self.ub\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveCauchyDE_Shrink scored 0.409 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698", "414dd85c-358d-4c93-8769-042881397968"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Cauchy Differential Evolution with dynamically adjusted mutation factor and shrinking search space.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE_Shrink:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1, shrink_factor=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.shrink_factor = shrink_factor\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i, F):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9)) #Prevent division by zero\n            \n            # Dynamically adjust F\n            F = 0.5 + 0.5 * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i, F)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Shrink the search space\n            self.lb = self.shrink_factor * self.lb\n            self.ub = self.shrink_factor * self.ub\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.006063574815042401, "generation": 5, "aucs": [0.166197112512242, 0.21059205808527082, 0.38443330927307073, 0.6011245373513379, 0.30393317141575915, 0.48667997527745743, 0.31715400650145775, 0.35549999843501146, 0.34621930127248146, 0.2158973407143432, 0.4006233636318167, 0.9984133811124276, 0.2689757244331824, 0.3349892751351309, 0.7425338356154533, 0.5135144576194705, 0.3194513355739418, 0.5246767771382732, 0.19291736237796553, 0.4900135009853037]}, "task_prompt": ""}
{"id": "1b47c6fa-f9eb-4abe-bc86-775b62348b66", "fitness": "-inf", "name": "StochasticRankingCMAES", "description": "A population-based algorithm that combines elements of Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with Stochastic Ranking to handle constraints and explores promising regions efficiently.", "code": "import numpy as np\n\nclass StochasticRankingCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma  # Overall step size\n        self.cs = cs        # Step size damping\n        self.mu = int(self.pop_size * mu_ratio)  # Number of parents\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None      # Mean of the population\n        self.C = None      # Covariance matrix\n        self.pc = None     # Evolution path for C\n        self.ps = None     # Evolution path for sigma\n        self.eigeneval_counter = 0\n        self.lb = None\n        self.ub = None\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        f_opt = np.inf\n        x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            \n            # Clip to bounds\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            if used_budget > self.budget:\n                f = f[:self.pop_size-(used_budget-self.budget)]\n                x = x[:self.pop_size-(used_budget-self.budget)]\n                self.pop_size = len(f)\n\n            # Stochastic ranking based on f\n            idx = np.argsort(f) # Sort by function values\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[0]\n            \n            # Selection and Recombination\n            x_mu = x[:self.mu]\n            z_mu = (x_mu - self.m) / self.sigma\n\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Update evolution paths\n            c_s = (self.cs * (self.mu / self.dim + (1 - self.mu/self.dim)*3))**0.5\n            self.ps = (1 - self.cs) * self.ps + c_s * zmean\n            self.pc = (1 - self.cs) * self.pc + (self.cs * (self.mu / self.dim + (1 - self.mu/self.dim)*3))**0.5 * (self.m - self.m + self.sigma * zmean)\n\n            # Update covariance matrix\n            self.C = (1 - self.cs) * self.C + self.cs * self.pc[:,None] @ self.pc[None, :]\n\n            # Update sigma\n            self.sigma *= np.exp((self.cs/0.4) * (np.linalg.norm(self.ps)/ (self.dim**0.5) - 1))\n\n\n\n        return f_opt, x_opt", "configspace": "", "generation": 5, "feedback": "In the code, line 154, in _raise_linalgerror_svd_nonconvergence, the following error occurred:\nLinAlgError: SVD did not converge", "error": "In the code, line 154, in _raise_linalgerror_svd_nonconvergence, the following error occurred:\nLinAlgError: SVD did not converge", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with Stochastic Ranking to handle constraints and explores promising regions efficiently.\n\n# Code:\n```python\nimport numpy as np\n\nclass StochasticRankingCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma  # Overall step size\n        self.cs = cs        # Step size damping\n        self.mu = int(self.pop_size * mu_ratio)  # Number of parents\n        self.weights = np.log(self.pop_size + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None      # Mean of the population\n        self.C = None      # Covariance matrix\n        self.pc = None     # Evolution path for C\n        self.ps = None     # Evolution path for sigma\n        self.eigeneval_counter = 0\n        self.lb = None\n        self.ub = None\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.m = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        f_opt = np.inf\n        x_opt = None\n        used_budget = 0\n\n        while used_budget < self.budget:\n            # Generate lambda offsprings\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            \n            # Clip to bounds\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = np.array([func(xi) for xi in x])\n            used_budget += self.pop_size\n            if used_budget > self.budget:\n                f = f[:self.pop_size-(used_budget-self.budget)]\n                x = x[:self.pop_size-(used_budget-self.budget)]\n                self.pop_size = len(f)\n\n            # Stochastic ranking based on f\n            idx = np.argsort(f) # Sort by function values\n            x = x[idx]\n            f = f[idx]\n\n\n            if f[0] < f_opt:\n                f_opt = f[0]\n                x_opt = x[0]\n            \n            # Selection and Recombination\n            x_mu = x[:self.mu]\n            z_mu = (x_mu - self.m) / self.sigma\n\n            self.m = np.sum(self.weights[:, None] * x_mu, axis=0)\n            zmean = np.sum(self.weights[:, None] * z_mu, axis=0)\n            \n            # Update evolution paths\n            c_s = (self.cs * (self.mu / self.dim + (1 - self.mu/self.dim)*3))**0.5\n            self.ps = (1 - self.cs) * self.ps + c_s * zmean\n            self.pc = (1 - self.cs) * self.pc + (self.cs * (self.mu / self.dim + (1 - self.mu/self.dim)*3))**0.5 * (self.m - self.m + self.sigma * zmean)\n\n            # Update covariance matrix\n            self.C = (1 - self.cs) * self.C + self.cs * self.pc[:,None] @ self.pc[None, :]\n\n            # Update sigma\n            self.sigma *= np.exp((self.cs/0.4) * (np.linalg.norm(self.ps)/ (self.dim**0.5) - 1))\n\n\n\n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.03341480485415792, "generation": 5}, "task_prompt": ""}
{"id": "e7367b1a-09f1-44fa-bb29-d1e56870a65e", "fitness": "-inf", "name": "CauchyParticleSwarmDE", "description": "Population-based algorithm that combines aspects of particle swarm optimization and differential evolution, using a Cauchy mutation operator and local search for exploitation.", "code": "import numpy as np\n\nclass CauchyParticleSwarmDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, F=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, x):\n        scale = 0.1 * (func.bounds.ub - func.bounds.lb)  # Scale Cauchy distribution\n        return x + scale * np.random.standard_cauchy(size=self.dim)\n\n    def local_search(self, x, func):\n        # Simple hill climbing around x\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        x_new = x.copy()\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n\n            #Clip Values\n            x_plus[i] = min(max(x_plus[i], func.bounds.lb), func.bounds.ub)\n            x_minus[i] = min(max(x_minus[i], func.bounds.lb), func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.eval_count += 2\n\n            if f_plus < func(x_new):\n              x_new = x_plus\n            elif f_minus < func(x_new):\n              x_new = x_minus\n              \n        if func(x_new) < func(x):\n          self.eval_count += 1\n          return x_new\n        else:\n          return x\n              \n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Particle Swarm Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = 0.5 * self.velocities[i] + cognitive_component + social_component  #inertia weight of 0.5\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutation = x1 + self.F * (x2 - x3)\n                mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = mutation[j]\n                \n                # Cauchy Mutation\n                trial_vector = self.cauchy_mutation(trial_vector)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                \n                #Local Search\n                trial_vector = self.local_search(trial_vector, func)\n                \n\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n                            \n                if self.eval_count >= self.budget:\n                  break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "In the code, line 34, in cauchy_mutation, the following error occurred:\nNameError: name 'func' is not defined\nOn line: scale = 0.1 * (func.bounds.ub - func.bounds.lb)  # Scale Cauchy distribution", "error": "In the code, line 34, in cauchy_mutation, the following error occurred:\nNameError: name 'func' is not defined\nOn line: scale = 0.1 * (func.bounds.ub - func.bounds.lb)  # Scale Cauchy distribution", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines aspects of particle swarm optimization and differential evolution, using a Cauchy mutation operator and local search for exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyParticleSwarmDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, F=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.cr = cr\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def cauchy_mutation(self, x):\n        scale = 0.1 * (func.bounds.ub - func.bounds.lb)  # Scale Cauchy distribution\n        return x + scale * np.random.standard_cauchy(size=self.dim)\n\n    def local_search(self, x, func):\n        # Simple hill climbing around x\n        step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n        x_new = x.copy()\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n\n            #Clip Values\n            x_plus[i] = min(max(x_plus[i], func.bounds.lb), func.bounds.ub)\n            x_minus[i] = min(max(x_minus[i], func.bounds.lb), func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.eval_count += 2\n\n            if f_plus < func(x_new):\n              x_new = x_plus\n            elif f_minus < func(x_new):\n              x_new = x_minus\n              \n        if func(x_new) < func(x):\n          self.eval_count += 1\n          return x_new\n        else:\n          return x\n              \n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Particle Swarm Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = 0.5 * self.velocities[i] + cognitive_component + social_component  #inertia weight of 0.5\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutation = x1 + self.F * (x2 - x3)\n                mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = mutation[j]\n                \n                # Cauchy Mutation\n                trial_vector = self.cauchy_mutation(trial_vector)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                \n                #Local Search\n                trial_vector = self.local_search(trial_vector, func)\n                \n\n                f_trial = func(trial_vector)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial_vector\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = trial_vector.copy()\n                            \n                if self.eval_count >= self.budget:\n                  break\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.011373208273387484, "generation": 5}, "task_prompt": ""}
{"id": "b396f992-38a3-4172-ba1d-be18d5395e3f", "fitness": 0.25971008187919287, "name": "GaussianAnnealing", "description": "Population-based algorithm using Gaussian mutation and simulated annealing acceptance criterion.", "code": "import numpy as np\n\nclass GaussianAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=20, temp_init=1.0, temp_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.temp_init = temp_init\n        self.temp_decay = temp_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        temp = self.temp_init\n        eval_count = self.pop_size # initial pop evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Generate mutant using Gaussian mutation\n                mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) #gaussian mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                f_mutant = func(mutant)\n                eval_count += 1\n\n                if f_mutant < self.f_opt:\n                    self.f_opt = f_mutant\n                    self.x_opt = mutant.copy()\n\n                # Simulated annealing acceptance criterion\n                delta = f_mutant - fitness[i]\n                if delta < 0 or np.random.rand() < np.exp(-delta / temp):\n                    population[i] = mutant.copy()\n                    fitness[i] = f_mutant\n                    \n            temp *= self.temp_decay # cool the temperature\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm GaussianAnnealing scored 0.260 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using Gaussian mutation and simulated annealing acceptance criterion.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=20, temp_init=1.0, temp_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.temp_init = temp_init\n        self.temp_decay = temp_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        temp = self.temp_init\n        eval_count = self.pop_size # initial pop evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Generate mutant using Gaussian mutation\n                mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) #gaussian mutation\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n                \n                f_mutant = func(mutant)\n                eval_count += 1\n\n                if f_mutant < self.f_opt:\n                    self.f_opt = f_mutant\n                    self.x_opt = mutant.copy()\n\n                # Simulated annealing acceptance criterion\n                delta = f_mutant - fitness[i]\n                if delta < 0 or np.random.rand() < np.exp(-delta / temp):\n                    population[i] = mutant.copy()\n                    fitness[i] = f_mutant\n                    \n            temp *= self.temp_decay # cool the temperature\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.04245948154727683, "generation": 5, "aucs": [0.11000255633376488, 0.1993072159435325, 0.26786174943051255, 0.1818620448641689, 0.24794248846356293, 0.25149796803246804, 0.23983978571278697, 0.2652544287706138, 0.20423180358164006, 0.17244978767092667, 0.2600340266628194, 0.3579504626310642, 0.2771629175937905, 0.17856069109880268, 0.5353621301361443, 0.2765661014552737, 0.2621125152967032, 0.30274071590318186, 0.17113859453321478, 0.43232365346888557]}, "task_prompt": ""}
{"id": "68de9165-658c-43e9-abe6-9e216288bc18", "fitness": 0.12420491080952274, "name": "GaussianAnnealing", "description": "A hybrid algorithm that combines a Gaussian-based mutation with Simulated Annealing to escape local optima.", "code": "import numpy as np\n\nclass GaussianAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.gaussian_scale = gaussian_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize at a random location\n        f = func(x)\n\n        temp = self.initial_temp\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a Gaussian-mutated candidate\n            x_new = x + np.random.normal(0, self.gaussian_scale, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n\n            # Simulated Annealing acceptance criterion\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Cool down the temperature\n            temp *= self.cooling_rate\n            self.gaussian_scale *= self.cooling_rate # Reducing the scale over time\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm GaussianAnnealing scored 0.124 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid algorithm that combines a Gaussian-based mutation with Simulated Annealing to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, gaussian_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.gaussian_scale = gaussian_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)  # Initialize at a random location\n        f = func(x)\n\n        temp = self.initial_temp\n        eval_count = 1\n\n        while eval_count < self.budget:\n            # Generate a Gaussian-mutated candidate\n            x_new = x + np.random.normal(0, self.gaussian_scale, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            eval_count += 1\n\n            delta_f = f_new - f\n\n            # Simulated Annealing acceptance criterion\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Cool down the temperature\n            temp *= self.cooling_rate\n            self.gaussian_scale *= self.cooling_rate # Reducing the scale over time\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.008189938107324286, "generation": 5, "aucs": [9.999999999998899e-05, 0.1554590404773195, 0.19376514174784698, 0.14014250317309473, 0.07354674733511568, 0.11438477239042277, 0.18977911059242858, 0.13052541186277444, 0.1458299182226872, 0.13934552666297517, 0.12472394024700839, 0.16174854310506237, 9.999999999998899e-05, 0.09719413892237061, 0.11835404812485628, 0.14938918048446104, 0.17754402555621096, 0.140522580743334, 0.12450480913645001, 0.10713877740603606]}, "task_prompt": ""}
{"id": "c71d8fac-61c0-4bf4-9492-3cc48bf31510", "fitness": 0.38193012825758677, "name": "AdaptiveDECauchyRestart", "description": "Adaptive Differential Evolution with Cauchy mutation and periodic restarts based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_period=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.restart_period = restart_period\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.no_improvement_count = 0\n        self.best_fitness_history = []\n        self.stagnation_threshold = 1e-6\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        mutation = a + self.F * (b - c) + self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return np.clip(mutation, self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.no_improvement_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                trial = self.crossover(mutant, self.pop[i])\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.no_improvement_count = 0  # Reset counter if improved\n                    else:\n                        self.no_improvement_count += 1\n\n                else:\n                     self.no_improvement_count += 1\n\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            if self.no_improvement_count > self.restart_period:\n                self.restart_population(func)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDECauchyRestart scored 0.382 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and periodic restarts based on stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECauchyRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_period=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.restart_period = restart_period\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.no_improvement_count = 0\n        self.best_fitness_history = []\n        self.stagnation_threshold = 1e-6\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        mutation = a + self.F * (b - c) + self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return np.clip(mutation, self.lb, self.ub)\n\n    def crossover(self, mutant, target):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.no_improvement_count = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                trial = self.crossover(mutant, self.pop[i])\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.no_improvement_count = 0  # Reset counter if improved\n                    else:\n                        self.no_improvement_count += 1\n\n                else:\n                     self.no_improvement_count += 1\n\n\n                if self.eval_count >= self.budget:\n                    break\n            \n            if self.no_improvement_count > self.restart_period:\n                self.restart_population(func)\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0040352022312283055, "generation": 5, "aucs": [0.16076131107223024, 0.2760768014965027, 0.33381194419645743, 0.4824839812716075, 0.28564069235620937, 0.3876009590392657, 0.2960061129386683, 0.33085028702859864, 0.2972247397319093, 0.2133581877375047, 0.4188574896632308, 0.9950365424332861, 0.2775877051215895, 0.2960468580467164, 0.7019111077691296, 0.39982727428099085, 0.31590059268301807, 0.49900561723478254, 0.1816716013650269, 0.48894275968501155]}, "task_prompt": ""}
{"id": "6f1e19c1-00ce-41f8-b1f2-36ad5b46e3e9", "fitness": 0.5140060723188127, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation and a dynamically adjusted population size, aiming for a balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initial population size based on dimensionality\n        pop_size = max(int(self.dim * self.pop_size_factor), 10)\n        pop = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        eval_count = pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = pop[np.argmin(fitness)]\n        \n        CR = 0.7\n        F = 0.5\n\n        while eval_count < self.budget:\n            # Dynamically adjust population size\n            if eval_count > self.budget * 0.75:\n                pop_size = max(int(self.dim * self.pop_size_factor // 2), 5)  #Reduce pop size in late stage\n                \n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution Mutation with Cauchy Perturbation\n                idx = [r for r in range(pop_size) if r != i]\n                a, b, c = np.random.choice(idx, 3, replace=False)\n\n                mutant = pop[a] + F * (pop[b] - pop[c]) + 0.01 * np.random.standard_cauchy(size=self.dim)  #Cauchy Perturbation\n                mutant = np.clip(mutant, self.lb, self.ub)  # Bound Handling\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial = np.clip(trial, self.lb, self.ub)  #Bound Handling\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.514 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["414dd85c-358d-4c93-8769-042881397968"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and a dynamically adjusted population size, aiming for a balance between exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initial population size based on dimensionality\n        pop_size = max(int(self.dim * self.pop_size_factor), 10)\n        pop = np.random.uniform(self.lb, self.ub, size=(pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        eval_count = pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = pop[np.argmin(fitness)]\n        \n        CR = 0.7\n        F = 0.5\n\n        while eval_count < self.budget:\n            # Dynamically adjust population size\n            if eval_count > self.budget * 0.75:\n                pop_size = max(int(self.dim * self.pop_size_factor // 2), 5)  #Reduce pop size in late stage\n                \n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution Mutation with Cauchy Perturbation\n                idx = [r for r in range(pop_size) if r != i]\n                a, b, c = np.random.choice(idx, 3, replace=False)\n\n                mutant = pop[a] + F * (pop[b] - pop[c]) + 0.01 * np.random.standard_cauchy(size=self.dim)  #Cauchy Perturbation\n                mutant = np.clip(mutant, self.lb, self.ub)  # Bound Handling\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial = np.clip(trial, self.lb, self.ub)  #Bound Handling\n\n                f_trial = func(trial)\n                eval_count += 1\n                \n                if f_trial < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.008569206919792228, "generation": 5, "aucs": [0.20384173140863104, 0.35822770755300914, 0.4757566885830331, 0.8198905585234105, 0.4699947002286128, 0.5312590540581903, 0.36692585135097666, 0.4293385131911759, 0.4593090933276158, 0.3920953742299548, 0.7831097279649151, 0.9887614287644244, 0.3095562779591965, 0.4574865540975023, 0.817819025075735, 0.5576631191906272, 0.4120461654695199, 0.6657824913229096, 0.2739577033816539, 0.5072996806951595]}, "task_prompt": ""}
{"id": "a6956d6c-a35e-4370-b946-b8f5b36e1c20", "fitness": 0.5990942688251777, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation, simplified for efficiency and robustness, using a population-wide learning rate and vectorized operations where possible.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def cauchy_mutation(self, pop, scale):\n        mutation = scale * np.random.standard_cauchy(size=(self.pop_size, self.dim))\n        return pop + mutation\n\n    def differential_evolution_crossover(self, pop):\n        idx = np.random.randint(0, self.pop_size, size=(self.pop_size, 3))\n        a, b, c = idx[:, 0], idx[:, 1], idx[:, 2]\n        \n        # Ensure that a, b, and c are different from each other and from the current index\n        for i in range(self.pop_size):\n            while a[i] == i:\n                a[i] = np.random.randint(0, self.pop_size)\n            while b[i] == i or b[i] == a[i]:\n                b[i] = np.random.randint(0, self.pop_size)\n            while c[i] == i or c[i] == a[i] or c[i] == b[i]:\n                c[i] = np.random.randint(0, self.pop_size)\n\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        \n        cross_points = np.random.rand(self.pop_size, self.dim) < self.CR\n        trial = np.where(cross_points, mutant, self.pop)\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            mutated_pop = self.cauchy_mutation(self.pop, scale)\n            mutated_pop = self.bound_handling(mutated_pop)\n            \n            trial_pop = self.differential_evolution_crossover(self.pop)\n            trial_pop = self.bound_handling(trial_pop)\n            \n            fitness_trial = np.array([func(x) for x in trial_pop])\n            self.eval_count += self.pop_size\n\n            improvement = fitness_trial < self.fitness\n            self.pop[improvement] = trial_pop[improvement]\n            self.fitness[improvement] = fitness_trial[improvement]\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n                \n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.599 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation, simplified for efficiency and robustness, using a population-wide learning rate and vectorized operations where possible.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.pop[best_index]\n\n    def cauchy_mutation(self, pop, scale):\n        mutation = scale * np.random.standard_cauchy(size=(self.pop_size, self.dim))\n        return pop + mutation\n\n    def differential_evolution_crossover(self, pop):\n        idx = np.random.randint(0, self.pop_size, size=(self.pop_size, 3))\n        a, b, c = idx[:, 0], idx[:, 1], idx[:, 2]\n        \n        # Ensure that a, b, and c are different from each other and from the current index\n        for i in range(self.pop_size):\n            while a[i] == i:\n                a[i] = np.random.randint(0, self.pop_size)\n            while b[i] == i or b[i] == a[i]:\n                b[i] = np.random.randint(0, self.pop_size)\n            while c[i] == i or c[i] == a[i] or c[i] == b[i]:\n                c[i] = np.random.randint(0, self.pop_size)\n\n        mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c])\n        \n        cross_points = np.random.rand(self.pop_size, self.dim) < self.CR\n        trial = np.where(cross_points, mutant, self.pop)\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            mutated_pop = self.cauchy_mutation(self.pop, scale)\n            mutated_pop = self.bound_handling(mutated_pop)\n            \n            trial_pop = self.differential_evolution_crossover(self.pop)\n            trial_pop = self.bound_handling(trial_pop)\n            \n            fitness_trial = np.array([func(x) for x in trial_pop])\n            self.eval_count += self.pop_size\n\n            improvement = fitness_trial < self.fitness\n            self.pop[improvement] = trial_pop[improvement]\n            self.fitness[improvement] = fitness_trial[improvement]\n\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.pop[best_index]\n                \n            if self.eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.004778877877720444, "generation": 5, "aucs": [0.2003515093017214, 0.3173376429775545, 0.5571957305158808, 0.773701457932335, 0.6419188897126559, 0.7209783975607933, 0.5651908723214264, 0.5578651446741815, 0.6591383128715644, 0.5857849952354663, 0.7901823950677771, 0.9975028856065971, 0.32147670631490055, 0.6193902280426629, 0.8753751944475965, 0.7367135235560208, 0.5066713178114595, 0.7846270465873172, 0.2505429368955896, 0.519940189070052]}, "task_prompt": ""}
{"id": "db15d475-5be8-43fa-842b-c9a315217cb2", "fitness": 0.6203659055181019, "name": "JADE_with_Random_Jump", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on diversification through random jumping.", "code": "import numpy as np\n\nclass JADE_with_Random_Jump:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm JADE_with_Random_Jump scored 0.620 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a focus on diversification through random jumping.\n# Code: \n```python\nimport numpy as np\n\nclass JADE_with_Random_Jump:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.017931617843962945, "generation": 6, "aucs": [0.2015116900133076, 0.3973485732035791, 0.6902681252712313, 0.8483873703390812, 0.7381493658426417, 0.8029261517561164, 0.5337543313125018, 0.641110438436764, 0.7634639080260762, 0.22905633245299295, 0.8340554934473188, 0.9989885525020766, 0.29754991394052077, 0.6405666649209534, 0.8752199155676966, 0.7963713268150476, 0.5143096103811704, 0.8587683093701439, 0.22316855587809037, 0.5223434808847285]}, "task_prompt": ""}
{"id": "8f93ddec-0e49-422a-8217-47d1e8324845", "fitness": "-inf", "name": "HybridDEPSO", "description": "A population-based algorithm that combines aspects of Differential Evolution and Particle Swarm Optimization, adaptively adjusting parameters based on performance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.8, pso_w=0.7, pso_c1=1.5, pso_c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.g_best_pos = None\n        self.g_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.best_pos = self.population.copy()\n        self.best_fitness = self.fitness.copy()\n        self.g_best_pos = self.population[np.argmin(self.fitness)].copy()\n        self.g_best_fitness = np.min(self.fitness)\n    \n    def de_mutation(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x_r1, x_r2, x_r3 = self.population[idxs]\n        return x_r1 + self.de_f * (x_r2 - x_r3)\n\n    def pso_velocity_update(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.pso_c1 * r1 * (self.best_pos[i] - self.population[i])\n        social_component = self.pso_c2 * r2 * (self.g_best_pos - self.population[i])\n        return self.pso_w * self.velocities[i] + cognitive_component + social_component\n\n\n    def __call__(self, func):\n        self.initialize(func)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Apply Differential Evolution\n                mutant = self.de_mutation(func, i)\n                \n                # Apply Crossover\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                trial = np.where(cross_points, mutant, self.population[i])\n                trial = np.clip(trial, lb, ub)\n                \n                # Evaluate Trial Vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                # Greedy Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update personal best\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = trial.copy()\n\n                        #Update global best\n                        if f_trial < self.g_best_fitness:\n                            self.g_best_fitness = f_trial\n                            self.g_best_pos = trial.copy()\n                else:\n                    #PSO Velocity update if DE failed\n                    new_velocity = self.pso_velocity_update(i)\n                    self.velocities[i] = new_velocity\n                    new_position = self.population[i] + new_velocity\n                    new_position = np.clip(new_position, lb, ub)\n                    f_new = func(new_position)\n                    self.eval_count += 1\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_position\n                        self.fitness[i] = f_new\n                        # Update personal best\n                        if f_new < self.best_fitness[i]:\n                            self.best_fitness[i] = f_new\n                            self.best_pos[i] = new_position.copy()\n\n                            #Update global best\n                            if f_new < self.g_best_fitness:\n                                self.g_best_fitness = f_new\n                                self.g_best_pos = new_position.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n                    \n\n        return self.g_best_fitness, self.g_best_pos", "configspace": "", "generation": 6, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of Differential Evolution and Particle Swarm Optimization, adaptively adjusting parameters based on performance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.8, pso_w=0.7, pso_c1=1.5, pso_c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.g_best_pos = None\n        self.g_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.best_pos = self.population.copy()\n        self.best_fitness = self.fitness.copy()\n        self.g_best_pos = self.population[np.argmin(self.fitness)].copy()\n        self.g_best_fitness = np.min(self.fitness)\n    \n    def de_mutation(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n        \n        x_r1, x_r2, x_r3 = self.population[idxs]\n        return x_r1 + self.de_f * (x_r2 - x_r3)\n\n    def pso_velocity_update(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.pso_c1 * r1 * (self.best_pos[i] - self.population[i])\n        social_component = self.pso_c2 * r2 * (self.g_best_pos - self.population[i])\n        return self.pso_w * self.velocities[i] + cognitive_component + social_component\n\n\n    def __call__(self, func):\n        self.initialize(func)\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Apply Differential Evolution\n                mutant = self.de_mutation(func, i)\n                \n                # Apply Crossover\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                trial = np.where(cross_points, mutant, self.population[i])\n                trial = np.clip(trial, lb, ub)\n                \n                # Evaluate Trial Vector\n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                # Greedy Selection\n                if f_trial < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    # Update personal best\n                    if f_trial < self.best_fitness[i]:\n                        self.best_fitness[i] = f_trial\n                        self.best_pos[i] = trial.copy()\n\n                        #Update global best\n                        if f_trial < self.g_best_fitness:\n                            self.g_best_fitness = f_trial\n                            self.g_best_pos = trial.copy()\n                else:\n                    #PSO Velocity update if DE failed\n                    new_velocity = self.pso_velocity_update(i)\n                    self.velocities[i] = new_velocity\n                    new_position = self.population[i] + new_velocity\n                    new_position = np.clip(new_position, lb, ub)\n                    f_new = func(new_position)\n                    self.eval_count += 1\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_position\n                        self.fitness[i] = f_new\n                        # Update personal best\n                        if f_new < self.best_fitness[i]:\n                            self.best_fitness[i] = f_new\n                            self.best_pos[i] = new_position.copy()\n\n                            #Update global best\n                            if f_new < self.g_best_fitness:\n                                self.g_best_fitness = f_new\n                                self.g_best_pos = new_position.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n                    \n\n        return self.g_best_fitness, self.g_best_pos\n```", "operator": "random_new", "theta_sampled": 0.03885585832803639, "generation": 6}, "task_prompt": ""}
{"id": "2bd9b024-5370-46d1-a3f2-beafd4c20175", "fitness": "-inf", "name": "CMAES_Restart", "description": "Covariance Matrix Adaptation Evolution Strategy with a restart mechanism based on stagnation detection and adaptive step size control using success history adaptation.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(dim))\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n        self.mean = np.zeros(self.dim)\n        self.sigma = 0.3\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 \n\n    def update_decomposition(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(self.D)\n        self.invsqrtC = self.B @ np.diag(1/self.D) @ self.B.T\n\n    def restart(self):\n         self.mean = np.zeros(self.dim)\n         self.sigma = 0.3\n         self.pc = np.zeros(self.dim)\n         self.ps = np.zeros(self.dim)\n         self.C = np.eye(self.dim)\n         self.B = np.eye(self.dim)\n         self.D = np.ones(self.dim)\n         self.invsqrtC = np.eye(self.dim)\n         self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n        while self.func_evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * z))\n            x = x.T\n\n            # Evaluate population, handling bounds\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                f[i] = func(x[i])\n                self.func_evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                if self.func_evals >= self.budget:\n                    break\n            if self.func_evals >= self.budget:\n                    break\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            zmean = np.sum(z[:, :self.mu] * self.weights, axis=1)\n            y = xmean - self.mean\n            s = (self.sigma * self.B @ (self.D * zmean))\n\n            # Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs * (2-self.cs) * self.mueff) * (self.B @ zmean)\n            hsig = np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.func_evals/self.popsize))/np.sqrt(self.dim+1) < 1.4 + 2/(self.dim+1)\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * y / self.sigma\n\n            # Update covariance matrix\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (self.B @ (self.D[:, np.newaxis] * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D[:, np.newaxis] * z[:, :self.mu]).T @ self.B.T)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim)-1))\n\n            # Update mean\n            self.mean = xmean\n\n            self.update_decomposition()\n\n            # Stagnation detection and restart\n            if np.linalg.norm(y) < 1e-8 * self.sigma:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation:\n                self.restart()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "In the code, line 94, in __call__, the following error occurred:\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 1)\nOn line: self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (self.B @ (self.D[:, np.newaxis] * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D[:, np.newaxis] * z[:, :self.mu]).T @ self.B.T)", "error": "In the code, line 94, in __call__, the following error occurred:\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 1)\nOn line: self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (self.B @ (self.D[:, np.newaxis] * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D[:, np.newaxis] * z[:, :self.mu]).T @ self.B.T)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with a restart mechanism based on stagnation detection and adaptive step size control using success history adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, popsize=None, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(dim))\n        self.mu = int(self.popsize * mu_ratio)\n        self.weights = np.log(self.popsize + 1/2) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n\n        self.mean = np.zeros(self.dim)\n        self.sigma = 0.3\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.invsqrtC = np.eye(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n        self.stagnation_counter = 0\n        self.max_stagnation = 100 \n\n    def update_decomposition(self):\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        self.D, self.B = np.linalg.eigh(self.C)\n        self.D = np.sqrt(self.D)\n        self.invsqrtC = self.B @ np.diag(1/self.D) @ self.B.T\n\n    def restart(self):\n         self.mean = np.zeros(self.dim)\n         self.sigma = 0.3\n         self.pc = np.zeros(self.dim)\n         self.ps = np.zeros(self.dim)\n         self.C = np.eye(self.dim)\n         self.B = np.eye(self.dim)\n         self.D = np.ones(self.dim)\n         self.invsqrtC = np.eye(self.dim)\n         self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n        while self.func_evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            x = self.mean[:, np.newaxis] + self.sigma * (self.B @ (self.D[:, np.newaxis] * z))\n            x = x.T\n\n            # Evaluate population, handling bounds\n            f = np.zeros(self.popsize)\n            for i in range(self.popsize):\n                x[i] = np.clip(x[i], func.bounds.lb, func.bounds.ub)\n                f[i] = func(x[i])\n                self.func_evals += 1\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                if self.func_evals >= self.budget:\n                    break\n            if self.func_evals >= self.budget:\n                    break\n\n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[idx]\n            z = z[:, idx]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            zmean = np.sum(z[:, :self.mu] * self.weights, axis=1)\n            y = xmean - self.mean\n            s = (self.sigma * self.B @ (self.D * zmean))\n\n            # Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs * (2-self.cs) * self.mueff) * (self.B @ zmean)\n            hsig = np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*self.func_evals/self.popsize))/np.sqrt(self.dim+1) < 1.4 + 2/(self.dim+1)\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * y / self.sigma\n\n            # Update covariance matrix\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.cmu * (self.B @ (self.D[:, np.newaxis] * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D[:, np.newaxis] * z[:, :self.mu]).T @ self.B.T)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim)-1))\n\n            # Update mean\n            self.mean = xmean\n\n            self.update_decomposition()\n\n            # Stagnation detection and restart\n            if np.linalg.norm(y) < 1e-8 * self.sigma:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation:\n                self.restart()\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.025128706594373516, "generation": 6}, "task_prompt": ""}
{"id": "cb3cacd6-0938-4089-8433-c657cd679770", "fitness": 0.0, "name": "AdaptiveCauchyDE", "description": "Adaptive Differential Evolution with Cauchy mutation and periodic population rejuvenation.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_interval = restart_interval\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            if self.eval_count % self.restart_interval == 0:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCauchyDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and periodic population rejuvenation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1, restart_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.restart_interval = restart_interval\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x):\n        mutation = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n    \n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i])\n                mutated = self.bound_handling(mutated)\n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            if self.eval_count % self.restart_interval == 0:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.005182155472028561, "generation": 6, "aucs": [0]}, "task_prompt": ""}
{"id": "37cbc014-8b5e-4296-bd31-7bd543e1d0fa", "fitness": 0.4289331949086074, "name": "AdaptiveCauchyDE", "description": "A simplified Adaptive Cauchy Differential Evolution, using a fixed Cauchy scale and a simplified adaptation strategy.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_solution = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, population, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        return population[a] + self.F * (population[b] - population[c])\n\n    def crossover(self, individual, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, individual)\n\n    def bound_handling(self, vector):\n        return np.clip(vector, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                mutant = self.bound_handling(mutant)\n                \n                cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = mutant + cauchy_noise\n                mutant = self.bound_handling(mutant)\n                \n                trial = self.crossover(self.pop[i], mutant)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_solution = trial\n\n                if self.eval_count >= self.budget:\n                    break\n                    \n            #Adapt F and CR every generation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.CR = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCauchyDE scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified Adaptive Cauchy Differential Evolution, using a fixed Cauchy scale and a simplified adaptation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_solution = self.pop[np.argmin(self.fitness)]\n\n    def mutate(self, population, i):\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        return population[a] + self.F * (population[b] - population[c])\n\n    def crossover(self, individual, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, individual)\n\n    def bound_handling(self, vector):\n        return np.clip(vector, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutant = self.mutate(self.pop, i)\n                mutant = self.bound_handling(mutant)\n                \n                cauchy_noise = self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = mutant + cauchy_noise\n                mutant = self.bound_handling(mutant)\n                \n                trial = self.crossover(self.pop[i], mutant)\n                trial = self.bound_handling(trial)\n\n                f_trial = func(trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_solution = trial\n\n                if self.eval_count >= self.budget:\n                    break\n                    \n            #Adapt F and CR every generation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.CR = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.best_fitness, self.best_solution\n```", "operator": "simplify", "theta_sampled": 0.004977111777842632, "generation": 6, "aucs": [0.18295486562514784, 0.31562739773526927, 0.411155329141622, 0.6713229961041921, 0.37308175948013245, 0.43108808553601685, 0.31731048890004543, 0.3496797409252518, 0.33774450173276915, 0.2576869978375679, 0.5551780897411853, 0.9971071948610043, 0.28145631984463804, 0.3462030450207073, 0.7284974590800044, 0.4566073454312126, 0.34167927257269415, 0.5148256395418107, 0.20959696145835371, 0.4998604076025228]}, "task_prompt": ""}
{"id": "ce03646c-6aad-49fa-8a8a-8f122fc1a37e", "fitness": 0.5437303709483612, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation and periodic restarts, dynamically adjusting mutation strength and crossover rate.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.7 # Crossover rate\n        self.restart_period = 50 # Number of iterations before checking restart condition\n        self.restart_threshold = 0.01\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        generation = 0\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive Mutation scale\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if eval_count >= self.budget:\n                    break\n            \n            generation += 1\n\n            if generation % self.restart_period == 0:\n                if np.std(self.fitness) < self.restart_threshold:\n                    self.restart_population(func)\n                    eval_count += self.pop_size\n                # Adaptive F and CR (simple update)\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.544 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and periodic restarts, dynamically adjusting mutation strength and crossover rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.7 # Crossover rate\n        self.restart_period = 50 # Number of iterations before checking restart condition\n        self.restart_threshold = 0.01\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n    \n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n        generation = 0\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive Mutation scale\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n\n                trial = self.differential_evolution(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if eval_count >= self.budget:\n                    break\n            \n            generation += 1\n\n            if generation % self.restart_period == 0:\n                if np.std(self.fitness) < self.restart_threshold:\n                    self.restart_population(func)\n                    eval_count += self.pop_size\n                # Adaptive F and CR (simple update)\n                self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(0.7, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0051951759314018174, "generation": 6, "aucs": [0.22144307139165276, 0.3699015073142181, 0.4447269931680349, 0.735392287480694, 0.6330443480864016, 0.4966024710603092, 0.5816549822506232, 0.3889245300301434, 0.6254724951227294, 0.46881488668166016, 0.7538819137250559, 0.9964719545881853, 0.43555300088058224, 0.6306861738320503, 0.7678837423896403, 0.5684017743200227, 0.45714192843616996, 0.5845981206661819, 0.21632038252422758, 0.4976908550186372]}, "task_prompt": ""}
{"id": "21b25381-c1f8-4198-b0c7-055419d1c6b0", "fitness": "-inf", "name": "DecayingCMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with a simple decay schedule for the step size and population size reduction over time.", "code": "import numpy as np\n\nclass DecayingCMAES:\n    def __init__(self, budget=10000, dim=10, mu_fraction=0.25, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu_fraction = mu_fraction\n        self.initial_sigma = initial_sigma  # Initial step size\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize CMA-ES parameters\n        lambda_ = int(4 + np.floor(3 * np.log(self.dim)))  # Population size\n        mu = int(lambda_ * self.mu_fraction)            # Number of parents\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights = weights / np.sum(weights)\n        mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        # Adaptation parameters\n        cs = (mueff + 2) / (self.dim + mueff + 5)\n        damps = 1 + 2 * max(0, np.sqrt((mueff - 1) / (self.dim + 1)) - 1) + cs\n        cc = (4 + mueff / self.dim) / (self.dim + 4 + 2 * mueff / self.dim)\n        c1 = 2 / ((self.dim + 1.3)**2 + mueff)\n        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((self.dim + 2)**2 + mueff))\n        \n        # Initialize distribution parameters\n        mean = self.rng.uniform(lb, ub, self.dim)  # Initialize mean within bounds\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)\n        \n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate and evaluate lambda offspring\n            z = self.rng.normal(0, 1, (self.dim, lambda_))\n            C_sqrt = np.linalg.cholesky(C)\n            x = mean[:, np.newaxis] + sigma * C_sqrt @ z\n            \n            # Clip to the bounds\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(x[:, i]) if eval_count + i < self.budget else np.inf for i in range(lambda_)])\n            eval_count += lambda_\n            \n            # Update optimal solution\n            if np.min(f) < f_opt:\n                f_opt = np.min(f)\n                x_opt = x[:, np.argmin(f)].copy()\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            z = z[:, idx]\n            \n            # Update distribution parameters\n            mean = np.sum(weights * x[:, :mu], axis=1)\n            \n            ps = (1 - cs) * ps + np.sqrt(cs * (2 - cs) * mueff) * (C_sqrt @ z[:, :mu] @ weights)\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - cs)**(2 * (eval_count / lambda_))) / 1.4 > 2 + 4 / (self.dim + 1)\n            \n            pc = (1 - cc) * pc + hsig * np.sqrt(cc * (2 - cc) * mueff) * (z[:, :mu] @ weights)\n            \n            C = (1 - c1 - cmu) * C + c1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) + cmu * (z[:, :mu] @ np.diag(weights) @ z[:, :mu].T)\n            \n            # Ensure that C remains positive definite\n            try:\n                np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n            \n            # Update sigma (step size) with decay\n            sigma *= np.exp((cs / damps) * (np.linalg.norm(ps) / np.sqrt(self.dim) - 1))\n            \n            # Reduce population size over time (linear decay)\n            lambda_decay_rate = 0.0001  # Adjust this value to control the decay speed\n            lambda_ = max(int(4 + np.floor(3 * np.log(self.dim)) * (1 - lambda_decay_rate * (eval_count / self.budget))), 4)\n            mu = int(lambda_ * self.mu_fraction)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = weights / np.sum(weights)\n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        return f_opt, x_opt", "configspace": "", "generation": 6, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with a simple decay schedule for the step size and population size reduction over time.\n# Code: \n```python\nimport numpy as np\n\nclass DecayingCMAES:\n    def __init__(self, budget=10000, dim=10, mu_fraction=0.25, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.mu_fraction = mu_fraction\n        self.initial_sigma = initial_sigma  # Initial step size\n        self.rng = np.random.default_rng()\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize CMA-ES parameters\n        lambda_ = int(4 + np.floor(3 * np.log(self.dim)))  # Population size\n        mu = int(lambda_ * self.mu_fraction)            # Number of parents\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights = weights / np.sum(weights)\n        mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        # Adaptation parameters\n        cs = (mueff + 2) / (self.dim + mueff + 5)\n        damps = 1 + 2 * max(0, np.sqrt((mueff - 1) / (self.dim + 1)) - 1) + cs\n        cc = (4 + mueff / self.dim) / (self.dim + 4 + 2 * mueff / self.dim)\n        c1 = 2 / ((self.dim + 1.3)**2 + mueff)\n        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((self.dim + 2)**2 + mueff))\n        \n        # Initialize distribution parameters\n        mean = self.rng.uniform(lb, ub, self.dim)  # Initialize mean within bounds\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)\n        \n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate and evaluate lambda offspring\n            z = self.rng.normal(0, 1, (self.dim, lambda_))\n            C_sqrt = np.linalg.cholesky(C)\n            x = mean[:, np.newaxis] + sigma * C_sqrt @ z\n            \n            # Clip to the bounds\n            x = np.clip(x, lb, ub)\n            \n            f = np.array([func(x[:, i]) if eval_count + i < self.budget else np.inf for i in range(lambda_)])\n            eval_count += lambda_\n            \n            # Update optimal solution\n            if np.min(f) < f_opt:\n                f_opt = np.min(f)\n                x_opt = x[:, np.argmin(f)].copy()\n            \n            # Sort by fitness\n            idx = np.argsort(f)\n            x = x[:, idx]\n            z = z[:, idx]\n            \n            # Update distribution parameters\n            mean = np.sum(weights * x[:, :mu], axis=1)\n            \n            ps = (1 - cs) * ps + np.sqrt(cs * (2 - cs) * mueff) * (C_sqrt @ z[:, :mu] @ weights)\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - cs)**(2 * (eval_count / lambda_))) / 1.4 > 2 + 4 / (self.dim + 1)\n            \n            pc = (1 - cc) * pc + hsig * np.sqrt(cc * (2 - cc) * mueff) * (z[:, :mu] @ weights)\n            \n            C = (1 - c1 - cmu) * C + c1 * (pc[:, np.newaxis] @ pc[np.newaxis, :]) + cmu * (z[:, :mu] @ np.diag(weights) @ z[:, :mu].T)\n            \n            # Ensure that C remains positive definite\n            try:\n                np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n            \n            # Update sigma (step size) with decay\n            sigma *= np.exp((cs / damps) * (np.linalg.norm(ps) / np.sqrt(self.dim) - 1))\n            \n            # Reduce population size over time (linear decay)\n            lambda_decay_rate = 0.0001  # Adjust this value to control the decay speed\n            lambda_ = max(int(4 + np.floor(3 * np.log(self.dim)) * (1 - lambda_decay_rate * (eval_count / self.budget))), 4)\n            mu = int(lambda_ * self.mu_fraction)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = weights / np.sum(weights)\n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n\n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.023025983710917266, "generation": 6}, "task_prompt": ""}
{"id": "e2799337-42c5-416d-b767-9303d3148253", "fitness": 0.0, "name": "OrthogonalCauchyOptimizer", "description": "Population-based algorithm with adaptive parameter control using a combination of orthogonal learning and Cauchy mutation for exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.lb = -5.0\n        self.ub = 5.0\n        self.alpha = 0.1  # Scaling factor for Cauchy mutation\n        self.cr = 0.7  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Orthogonal Learning\n                orthogonal_matrix = np.random.randn(self.orthogonal_components, self.dim)\n                orthogonal_matrix = orthogonal_matrix / np.linalg.norm(orthogonal_matrix, axis=1, keepdims=True) # Normalize Rows\n                orthogonal_points = population[i] + np.random.uniform(-1, 1, size=(self.orthogonal_components, 1)) * orthogonal_matrix\n                orthogonal_points = np.clip(orthogonal_points, self.lb, self.ub)\n                \n                orthogonal_fitnesses = np.array([func(x) for x in orthogonal_points])\n                self.budget -= self.orthogonal_components\n\n                if self.budget <= 0:\n                  break #Stop if budget runs out in orthogonal learning\n\n                best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                orthogonal_best_point = orthogonal_points[best_orthogonal_index]\n\n                # Cauchy Mutation\n                cauchy_mutation = self.alpha * np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + cauchy_mutation\n\n                # Crossover\n                jrand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == jrand:\n                        trial_vector[j] = orthogonal_best_point[j] # From orthogonal learning\n                    else:\n                        trial_vector[j] = mutated_individual[j]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub) # Clip to boundaries\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break #Stop if budget runs out during eval\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                # Update global best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm OrthogonalCauchyOptimizer scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive parameter control using a combination of orthogonal learning and Cauchy mutation for exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.lb = -5.0\n        self.ub = 5.0\n        self.alpha = 0.1  # Scaling factor for Cauchy mutation\n        self.cr = 0.7  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Orthogonal Learning\n                orthogonal_matrix = np.random.randn(self.orthogonal_components, self.dim)\n                orthogonal_matrix = orthogonal_matrix / np.linalg.norm(orthogonal_matrix, axis=1, keepdims=True) # Normalize Rows\n                orthogonal_points = population[i] + np.random.uniform(-1, 1, size=(self.orthogonal_components, 1)) * orthogonal_matrix\n                orthogonal_points = np.clip(orthogonal_points, self.lb, self.ub)\n                \n                orthogonal_fitnesses = np.array([func(x) for x in orthogonal_points])\n                self.budget -= self.orthogonal_components\n\n                if self.budget <= 0:\n                  break #Stop if budget runs out in orthogonal learning\n\n                best_orthogonal_index = np.argmin(orthogonal_fitnesses)\n                orthogonal_best_point = orthogonal_points[best_orthogonal_index]\n\n                # Cauchy Mutation\n                cauchy_mutation = self.alpha * np.random.standard_cauchy(size=self.dim)\n                mutated_individual = population[i] + cauchy_mutation\n\n                # Crossover\n                jrand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() <= self.cr or j == jrand:\n                        trial_vector[j] = orthogonal_best_point[j] # From orthogonal learning\n                    else:\n                        trial_vector[j] = mutated_individual[j]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub) # Clip to boundaries\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break #Stop if budget runs out during eval\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                # Update global best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.02393325126595605, "generation": 6, "aucs": [0]}, "task_prompt": ""}
{"id": "62614c2a-a233-40b4-81f2-720e86db321b", "fitness": "-inf", "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm that uses a combination of different mutation strategies and a self-adaptive parameter control mechanism to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.pop = None\n        self.fitness = None\n        self.mutation_strategies = [\"rand1\", \"best1\", \"current_to_rand1\"]\n        self.mutation_probs = np.array([0.33, 0.33, 0.34]) # Equal probabilities initially\n        self.success_F = []\n        self.success_CR = []\n        self.success_count = 0 # counter for successful mutations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n\n    def select_mutation_strategy(self):\n        return np.random.choice(self.mutation_strategies, p=self.mutation_probs)\n\n    def mutate(self, strategy, pop, i):\n        if strategy == \"rand1\":\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + self.F * (x2 - x3)\n        elif strategy == \"best1\":\n            best = pop[np.argmin(self.fitness)]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            while i in idxs:\n                 idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = pop[idxs]\n            v = best + self.F * (x1 - x2)\n        elif strategy == \"current_to_rand1\":\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = pop[i] + self.F * (x1 - pop[i]) + self.F * (x2 - x3)\n\n        v = np.clip(v, -5.0, 5.0)\n        return v\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def update_mutation_probs(self):\n         # Update mutation probabilities based on success rates\n        if self.success_count > 0: # Avoid division by zero\n            success_rates = np.array([len([x for x in self.success_CR if x == strat]) for strat in self.mutation_strategies]) / self.success_count\n            self.mutation_probs = success_rates / np.sum(success_rates)\n        else: # If no success, then remain the same.\n            pass\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.success_count = 0\n        fevals = 0\n        self.initialize_population(func)\n        fevals += self.pop_size\n\n        while fevals < self.budget:\n            new_pop = np.zeros_like(self.pop)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                strategy = self.select_mutation_strategy()\n                mutant = self.mutate(strategy, self.pop, i)\n                trial = self.crossover(self.pop[i], mutant)\n                f = func(trial)\n                fevals += 1\n\n                if f < self.fitness[i]:\n                    new_pop[i] = trial\n                    new_fitness[i] = f\n                    self.success_F.append(strategy) # Track what mutation strategy leads to success\n                    self.success_CR.append(strategy)\n                    self.success_count += 1 # Track successful changes\n                else:\n                    new_pop[i] = self.pop[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n\n                if fevals >= self.budget:\n                    break\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n            self.update_mutation_probs()\n            # Adjust F and CR adaptively (example, can be improved)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that uses a combination of different mutation strategies and a self-adaptive parameter control mechanism to balance exploration and exploitation.\n\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial scaling factor\n        self.CR = CR  # Initial crossover rate\n        self.pop = None\n        self.fitness = None\n        self.mutation_strategies = [\"rand1\", \"best1\", \"current_to_rand1\"]\n        self.mutation_probs = np.array([0.33, 0.33, 0.34]) # Equal probabilities initially\n        self.success_F = []\n        self.success_CR = []\n        self.success_count = 0 # counter for successful mutations\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n\n    def select_mutation_strategy(self):\n        return np.random.choice(self.mutation_strategies, p=self.mutation_probs)\n\n    def mutate(self, strategy, pop, i):\n        if strategy == \"rand1\":\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = x1 + self.F * (x2 - x3)\n        elif strategy == \"best1\":\n            best = pop[np.argmin(self.fitness)]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            while i in idxs:\n                 idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = pop[idxs]\n            v = best + self.F * (x1 - x2)\n        elif strategy == \"current_to_rand1\":\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            while i in idxs:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = pop[idxs]\n            v = pop[i] + self.F * (x1 - pop[i]) + self.F * (x2 - x3)\n\n        v = np.clip(v, -5.0, 5.0)\n        return v\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def update_mutation_probs(self):\n         # Update mutation probabilities based on success rates\n        if self.success_count > 0: # Avoid division by zero\n            success_rates = np.array([len([x for x in self.success_CR if x == strat]) for strat in self.mutation_strategies]) / self.success_count\n            self.mutation_probs = success_rates / np.sum(success_rates)\n        else: # If no success, then remain the same.\n            pass\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.success_count = 0\n        fevals = 0\n        self.initialize_population(func)\n        fevals += self.pop_size\n\n        while fevals < self.budget:\n            new_pop = np.zeros_like(self.pop)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                strategy = self.select_mutation_strategy()\n                mutant = self.mutate(strategy, self.pop, i)\n                trial = self.crossover(self.pop[i], mutant)\n                f = func(trial)\n                fevals += 1\n\n                if f < self.fitness[i]:\n                    new_pop[i] = trial\n                    new_fitness[i] = f\n                    self.success_F.append(strategy) # Track what mutation strategy leads to success\n                    self.success_CR.append(strategy)\n                    self.success_count += 1 # Track successful changes\n                else:\n                    new_pop[i] = self.pop[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial\n\n                if fevals >= self.budget:\n                    break\n\n            self.pop = new_pop\n            self.fitness = new_fitness\n            self.update_mutation_probs()\n            # Adjust F and CR adaptively (example, can be improved)\n            self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 1.0)\n            self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.01725994080850824, "generation": 7}, "task_prompt": ""}
{"id": "1f63996a-e481-4d75-8db4-75750838ce4e", "fitness": "-inf", "name": "SelfAdaptiveDE", "description": "A self-adaptive Differential Evolution algorithm with a novel mutation strategy incorporating both current-to-best and current-to-rand components, adaptively weighted based on success rate.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.5, f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Initial crossover rate\n        self.f = f    # Initial scaling factor\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n\n        self.cr_memory = []\n        self.f_memory = []\n        self.success_history = []\n        self.memory_size = 10  # Size of the memory for adaptation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n\n    def mutate(self, i):\n        # Adaptive weighting based on success rate\n        if len(self.success_history) > 0:\n             success_rate = np.mean(self.success_history[-self.memory_size:])\n        else:\n            success_rate = 0.5  # Default value if no history\n\n        # Current-to-best component\n        r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n        while r1 == i or r2 == i:\n            r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n        v_best = self.pop[i] + self.f * (self.pop[self.best_idx] - self.pop[i]) + self.f * (self.pop[r1] - self.pop[r2])\n        \n        # Current-to-rand component\n        r3, r4, r5 = np.random.choice(self.pop_size, 3, replace=False)\n        while r3 == i or r4 == i or r5 == i:\n            r3, r4, r5 = np.random.choice(self.pop_size, 3, replace=False)\n        v_rand = self.pop[i] + self.f * (self.pop[r3] - self.pop[i]) + self.f * (self.pop[r4] - self.pop[r5])\n\n\n        # Adaptive combination of the two mutation strategies\n        mutation_vector = success_rate * v_best + (1 - success_rate) * v_rand\n\n        return mutation_vector\n\n    def crossover(self, i, mutant_vector):\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                trial_vector[j] = mutant_vector[j]\n        return trial_vector\n\n    def selection(self, func, i, trial_vector):\n        f_trial = func(trial_vector)\n        if f_trial < self.fitness[i]:\n            self.success_history.append(1)\n            self.pop[i] = trial_vector\n            self.fitness[i] = f_trial\n            if f_trial < self.fitness[self.best_idx]:\n                self.best_idx = i\n        else:\n            self.success_history.append(0)\n\n    def adapt_parameters(self):\n       \n        # Adaptation of F (Scaling Factor):\n        if len(self.success_history) > 5 and np.mean(self.success_history[-5:]) < 0.2: #if too few successes\n            self.f = min(self.f * 1.1, 1.0) #Increase F\n\n        elif len(self.success_history) > 5 and np.mean(self.success_history[-5:]) > 0.8: #if too many successes\n            self.f = max(self.f * 0.9, 0.1) #Decrease F\n\n        # Adaptation of CR (Crossover Rate):\n        if len(self.success_history) > 5 and np.mean(self.success_history[-5:]) < 0.2: #if too few successes\n            self.cr = min(self.cr + 0.1, 1.0) #Increase CR\n\n        elif len(self.success_history) > 5 and np.mean(self.success_history[-5:]) > 0.8: #if too many successes\n            self.cr = max(self.cr - 0.1, 0.0) #Decrease CR\n\n        self.cr = np.clip(self.cr, 0.05, 0.95) #CR bounds\n        self.f  = np.clip(self.f, 0.1, 1.0) #F bounds\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        fevals = 0\n\n        self.initialize_population(func)\n        fevals += self.pop_size\n\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(i, mutant_vector)\n\n                # Clip the trial vector to the boundaries\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                self.selection(func, i, trial_vector)\n                fevals += 1\n\n                if self.fitness[self.best_idx] < self.f_opt:\n                    self.f_opt = self.fitness[self.best_idx]\n                    self.x_opt = self.pop[self.best_idx]\n            \n            self.adapt_parameters() # Adapt parameters after each generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-adaptive Differential Evolution algorithm with a novel mutation strategy incorporating both current-to-best and current-to-rand components, adaptively weighted based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr=0.5, f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Initial crossover rate\n        self.f = f    # Initial scaling factor\n        self.pop = None\n        self.fitness = None\n        self.best_idx = None\n\n        self.cr_memory = []\n        self.f_memory = []\n        self.success_history = []\n        self.memory_size = 10  # Size of the memory for adaptation\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_idx = np.argmin(self.fitness)\n\n    def mutate(self, i):\n        # Adaptive weighting based on success rate\n        if len(self.success_history) > 0:\n             success_rate = np.mean(self.success_history[-self.memory_size:])\n        else:\n            success_rate = 0.5  # Default value if no history\n\n        # Current-to-best component\n        r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n        while r1 == i or r2 == i:\n            r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n        v_best = self.pop[i] + self.f * (self.pop[self.best_idx] - self.pop[i]) + self.f * (self.pop[r1] - self.pop[r2])\n        \n        # Current-to-rand component\n        r3, r4, r5 = np.random.choice(self.pop_size, 3, replace=False)\n        while r3 == i or r4 == i or r5 == i:\n            r3, r4, r5 = np.random.choice(self.pop_size, 3, replace=False)\n        v_rand = self.pop[i] + self.f * (self.pop[r3] - self.pop[i]) + self.f * (self.pop[r4] - self.pop[r5])\n\n\n        # Adaptive combination of the two mutation strategies\n        mutation_vector = success_rate * v_best + (1 - success_rate) * v_rand\n\n        return mutation_vector\n\n    def crossover(self, i, mutant_vector):\n        trial_vector = np.copy(self.pop[i])\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.cr or j == j_rand:\n                trial_vector[j] = mutant_vector[j]\n        return trial_vector\n\n    def selection(self, func, i, trial_vector):\n        f_trial = func(trial_vector)\n        if f_trial < self.fitness[i]:\n            self.success_history.append(1)\n            self.pop[i] = trial_vector\n            self.fitness[i] = f_trial\n            if f_trial < self.fitness[self.best_idx]:\n                self.best_idx = i\n        else:\n            self.success_history.append(0)\n\n    def adapt_parameters(self):\n       \n        # Adaptation of F (Scaling Factor):\n        if len(self.success_history) > 5 and np.mean(self.success_history[-5:]) < 0.2: #if too few successes\n            self.f = min(self.f * 1.1, 1.0) #Increase F\n\n        elif len(self.success_history) > 5 and np.mean(self.success_history[-5:]) > 0.8: #if too many successes\n            self.f = max(self.f * 0.9, 0.1) #Decrease F\n\n        # Adaptation of CR (Crossover Rate):\n        if len(self.success_history) > 5 and np.mean(self.success_history[-5:]) < 0.2: #if too few successes\n            self.cr = min(self.cr + 0.1, 1.0) #Increase CR\n\n        elif len(self.success_history) > 5 and np.mean(self.success_history[-5:]) > 0.8: #if too many successes\n            self.cr = max(self.cr - 0.1, 0.0) #Decrease CR\n\n        self.cr = np.clip(self.cr, 0.05, 0.95) #CR bounds\n        self.f  = np.clip(self.f, 0.1, 1.0) #F bounds\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        fevals = 0\n\n        self.initialize_population(func)\n        fevals += self.pop_size\n\n        self.f_opt = self.fitness[self.best_idx]\n        self.x_opt = self.pop[self.best_idx]\n\n        while fevals < self.budget:\n            for i in range(self.pop_size):\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(i, mutant_vector)\n\n                # Clip the trial vector to the boundaries\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                self.selection(func, i, trial_vector)\n                fevals += 1\n\n                if self.fitness[self.best_idx] < self.f_opt:\n                    self.f_opt = self.fitness[self.best_idx]\n                    self.x_opt = self.pop[self.best_idx]\n            \n            self.adapt_parameters() # Adapt parameters after each generation\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.008340578970951657, "generation": 7}, "task_prompt": ""}
{"id": "e6c601b1-48fe-4db6-a352-8bf08cc1ef45", "fitness": 0.5399423147849758, "name": "VelocityEnhancedDE", "description": "Population-based algorithm with velocity-based exploration and adaptive learning rate inspired by Particle Swarm Optimization, combined with differential evolution mutation.", "code": "import numpy as np\n\nclass VelocityEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, c1=1.2, c2=0.8, F=0.7, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F      # Mutation factor\n        self.cr = cr    # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_x = None\n        self.global_best_f = np.inf\n        self.func_evals = 0\n        self.learning_rate = 0.1\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.global_best_x = self.pop[np.argmin(self.fitness)]\n        self.global_best_f = np.min(self.fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.pop[i] - self.pop[i])  # Individual best is the current position in this implementation\n                social_component = self.c2 * r2 * (self.global_best_x - self.pop[i])\n                self.velocities[i] = 0.9 * self.velocities[i] + cognitive_component + social_component\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c]) + self.velocities[i] * self.learning_rate\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n\n                    if f < self.global_best_f:\n                        self.global_best_f = f\n                        self.global_best_x = trial.copy()\n\n\n                # Adaptive Learning Rate (optional)\n                self.learning_rate = np.exp(-self.func_evals / self.budget) * 0.1 # Decay learning rate\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return self.global_best_f, self.global_best_x", "configspace": "", "generation": 7, "feedback": "The algorithm VelocityEnhancedDE scored 0.540 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with velocity-based exploration and adaptive learning rate inspired by Particle Swarm Optimization, combined with differential evolution mutation.\n# Code: \n```python\nimport numpy as np\n\nclass VelocityEnhancedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, c1=1.2, c2=0.8, F=0.7, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F      # Mutation factor\n        self.cr = cr    # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.global_best_x = None\n        self.global_best_f = np.inf\n        self.func_evals = 0\n        self.learning_rate = 0.1\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.func_evals += self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.global_best_x = self.pop[np.argmin(self.fitness)]\n        self.global_best_f = np.min(self.fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.func_evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.pop[i] - self.pop[i])  # Individual best is the current position in this implementation\n                social_component = self.c2 * r2 * (self.global_best_x - self.pop[i])\n                self.velocities[i] = 0.9 * self.velocities[i] + cognitive_component + social_component\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = self.pop[a] + self.F * (self.pop[b] - self.pop[c]) + self.velocities[i] * self.learning_rate\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.pop[i])\n\n                # Clip to bounds\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                f = func(trial)\n                self.func_evals += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = trial\n\n                    if f < self.global_best_f:\n                        self.global_best_f = f\n                        self.global_best_x = trial.copy()\n\n\n                # Adaptive Learning Rate (optional)\n                self.learning_rate = np.exp(-self.func_evals / self.budget) * 0.1 # Decay learning rate\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return self.global_best_f, self.global_best_x\n```", "operator": "random_new", "theta_sampled": -0.0008597663584883632, "generation": 7, "aucs": [0.18535329335229755, 0.3602488606765676, 0.5382636016834546, 0.7928614550227102, 0.570240042458221, 0.6581497139954766, 0.38245248274115884, 0.4574177729583021, 0.5505827935297296, 0.5017846925143803, 0.7717825574807986, 0.9949711564565656, 0.2923020727370832, 0.5101829967092361, 0.7187452755663459, 0.6282907561980753, 0.4448789652970704, 0.7364874703740989, 0.19543344887642644, 0.5084168870715176]}, "task_prompt": ""}
{"id": "d2948d93-d3d4-414e-bf0a-02305be1bc19", "fitness": 0.5966426183501133, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation and population-wide best influence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutation(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        # Incorporate the population best into the mutation\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.cauchy_scale * np.random.standard_cauchy(size=self.dim) * (self.x_opt - pop[i]) \n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutation(self.pop, i)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.crossover(self.pop, i, mutated)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.597 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and population-wide best influence.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def mutation(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        \n        # Incorporate the population best into the mutation\n        mutant = pop[a] + self.F * (pop[b] - pop[c]) + self.cauchy_scale * np.random.standard_cauchy(size=self.dim) * (self.x_opt - pop[i]) \n        return mutant\n\n    def crossover(self, pop, i, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.mutation(self.pop, i)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.crossover(self.pop, i, mutated)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": -0.0003028656709686571, "generation": 7, "aucs": [0.21801826497932353, 0.2316778155223721, 0.6070984785988087, 0.8524298892788023, 0.7060556683587658, 0.7517369407394339, 0.4842331929580955, 0.5612928505143595, 0.7065465032420031, 0.5542353588181312, 0.7526994045105558, 1.0, 0.26355618142284964, 0.5893640282326233, 0.8456084286720824, 0.7484774999204022, 0.5192540922459339, 0.8157430502606138, 0.22182437147486778, 0.503000347252243]}, "task_prompt": ""}
{"id": "c1a629b7-2870-44a1-80b0-51fde20cba82", "fitness": 0.2523054848083645, "name": "AdaptiveStepSizeEvolution", "description": "A population-based algorithm with adaptive step size control based on the success rate of recent steps and an aging mechanism to promote exploration.", "code": "import numpy as np\n\nclass AdaptiveStepSizeEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_step_size=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.step_sizes = np.ones(self.pop_size) * self.initial_step_size\n        self.success_rates = np.zeros(self.pop_size)\n        self.success_history = [[] for _ in range(self.pop_size)]\n        self.population = None\n        self.fitness = None\n        self.ages = None # track the age of each particle\n        self.age_threshold = budget // (pop_size * 2) # Threshold for promoting exploration\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.ages = np.zeros(self.pop_size)\n\n\n    def update_step_size(self, idx, success):\n        self.success_history[idx].append(success)\n        if len(self.success_history[idx]) > self.success_rate_memory:\n            self.success_history[idx].pop(0)\n        \n        self.success_rates[idx] = np.mean(self.success_history[idx]) if self.success_history[idx] else 0.0\n        \n        if self.success_rates[idx] > 0.7:\n            self.step_sizes[idx] *= 1.2  # Increase step size\n        elif self.success_rates[idx] < 0.3:\n            self.step_sizes[idx] *= 0.8  # Decrease step size\n\n        self.step_sizes[idx] = np.clip(self.step_sizes[idx], 1e-6, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Mutation: add adaptive noise\n                mutation = np.random.normal(0, self.step_sizes[i], self.dim)\n                new_x = self.population[i] + mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                new_f = func(new_x)\n                eval_count += 1\n                \n\n                if new_f < self.fitness[i]:\n                    self.fitness[i] = new_f\n                    self.population[i] = new_x\n                    self.update_step_size(i, 1)\n                    self.ages[i] = 0 # reset the age, particle made progress\n                    \n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                else:\n                    self.update_step_size(i, 0)\n                    self.ages[i] += 1\n\n                    # Aging mechanism: if a particle hasn't improved for a while, move it randomly\n                    if self.ages[i] > self.age_threshold:\n                        self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                        self.fitness[i] = func(self.population[i])\n                        eval_count += 1\n                        self.ages[i] = 0\n                        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveStepSizeEvolution scored 0.252 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive step size control based on the success rate of recent steps and an aging mechanism to promote exploration.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveStepSizeEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_step_size=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.step_sizes = np.ones(self.pop_size) * self.initial_step_size\n        self.success_rates = np.zeros(self.pop_size)\n        self.success_history = [[] for _ in range(self.pop_size)]\n        self.population = None\n        self.fitness = None\n        self.ages = None # track the age of each particle\n        self.age_threshold = budget // (pop_size * 2) # Threshold for promoting exploration\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.ages = np.zeros(self.pop_size)\n\n\n    def update_step_size(self, idx, success):\n        self.success_history[idx].append(success)\n        if len(self.success_history[idx]) > self.success_rate_memory:\n            self.success_history[idx].pop(0)\n        \n        self.success_rates[idx] = np.mean(self.success_history[idx]) if self.success_history[idx] else 0.0\n        \n        if self.success_rates[idx] > 0.7:\n            self.step_sizes[idx] *= 1.2  # Increase step size\n        elif self.success_rates[idx] < 0.3:\n            self.step_sizes[idx] *= 0.8  # Decrease step size\n\n        self.step_sizes[idx] = np.clip(self.step_sizes[idx], 1e-6, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Mutation: add adaptive noise\n                mutation = np.random.normal(0, self.step_sizes[i], self.dim)\n                new_x = self.population[i] + mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                new_f = func(new_x)\n                eval_count += 1\n                \n\n                if new_f < self.fitness[i]:\n                    self.fitness[i] = new_f\n                    self.population[i] = new_x\n                    self.update_step_size(i, 1)\n                    self.ages[i] = 0 # reset the age, particle made progress\n                    \n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                else:\n                    self.update_step_size(i, 0)\n                    self.ages[i] += 1\n\n                    # Aging mechanism: if a particle hasn't improved for a while, move it randomly\n                    if self.ages[i] > self.age_threshold:\n                        self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                        self.fitness[i] = func(self.population[i])\n                        eval_count += 1\n                        self.ages[i] = 0\n                        \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.011546611946786156, "generation": 7, "aucs": [0.14313244489767785, 0.20133276915723042, 0.32032039378847943, 0.20950730776189652, 0.2172247113289142, 0.22772202264197416, 0.21840292223289148, 0.2199675618402427, 0.16095126662557846, 0.14036580280183553, 0.18867473919309685, 0.21737680255164538, 0.2728849565454686, 0.21338930755922203, 0.543624938329069, 0.34995598279477913, 0.23210966308664815, 0.3587366525131218, 0.16153703071620296, 0.4488924198013158]}, "task_prompt": ""}
{"id": "165ecd4d-16c1-48ca-83f6-d1a3814d25da", "fitness": 0.32421472529956713, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Cauchy mutation and stochastic ranking for constraint handling.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy() # Ensure it's a copy\n\n    def cauchy_mutation(self, x, scale):\n        return x + scale * np.random.standard_cauchy(size=self.dim)\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        mutant = a + self.F * (b - c)\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, pop[i])\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.differential_evolution_crossover(self.pop, i)\n                mutated = self.bound_handling(mutated)\n\n                # Adaptive Cauchy Mutation: Smaller scale if close to bounds.\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(mutated, scale)\n                mutated = self.bound_handling(mutated)\n\n                trial_fitness = func(mutated)\n                eval_count += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.pop[i] = mutated\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = mutated.copy() # Ensure it's a copy\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.324 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Cauchy mutation and stochastic ranking for constraint handling.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy() # Ensure it's a copy\n\n    def cauchy_mutation(self, x, scale):\n        return x + scale * np.random.standard_cauchy(size=self.dim)\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = pop[idx[0]], pop[idx[1]], pop[idx[2]]\n        mutant = a + self.F * (b - c)\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, pop[i])\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                mutated = self.differential_evolution_crossover(self.pop, i)\n                mutated = self.bound_handling(mutated)\n\n                # Adaptive Cauchy Mutation: Smaller scale if close to bounds.\n                scale = 0.1 * (self.ub - self.lb)\n                mutated = self.cauchy_mutation(mutated, scale)\n                mutated = self.bound_handling(mutated)\n\n                trial_fitness = func(mutated)\n                eval_count += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.pop[i] = mutated\n                    self.fitness[i] = trial_fitness\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = mutated.copy() # Ensure it's a copy\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.005105508271561607, "generation": 7, "aucs": [0.13309464528210047, 0.21794870846852754, 0.3014124629049799, 0.3197575195703817, 0.24774306309381566, 0.30073458368804096, 0.26563924670278216, 0.24957315621319387, 0.2371950773355973, 0.17973436879345606, 0.28519306730801697, 0.9910664067230985, 0.2862277393348678, 0.24508734606805227, 0.6531872644892894, 0.32588562572713065, 0.2689253740639479, 0.3417003207354613, 0.16344063572840895, 0.4707478937601921]}, "task_prompt": ""}
{"id": "fc2c30e7-668d-4f6e-824d-e5c31a9f2f5a", "fitness": 0.6220104083371694, "name": "JADE_with_Random_Jump_Adaptive_F", "description": "JADE with Random Jump and Adaptive F, dynamically adjusting the mutation factor based on population diversity.", "code": "import numpy as np\n\nclass JADE_with_Random_Jump_Adaptive_F:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F_initial=0.5, jump_prob=0.05, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.jump_prob = jump_prob\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F: Adjust based on population diversity\n            diversity = np.std(population)\n            if diversity < self.diversity_threshold:\n                self.F = self.F_initial * 1.5  # Increase F to explore more\n            else:\n                self.F = self.F_initial  # Reset F\n\n            self.F = np.clip(self.F, 0.1, 1.0)  # Clip F to a reasonable range\n\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm JADE_with_Random_Jump_Adaptive_F scored 0.622 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db15d475-5be8-43fa-842b-c9a315217cb2", "a877a5f2-6afb-4699-83cd-3ed93bf2c19a"], "operator": "crossover", "metadata": {"llm_response": "# Description: JADE with Random Jump and Adaptive F, dynamically adjusting the mutation factor based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass JADE_with_Random_Jump_Adaptive_F:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F_initial=0.5, jump_prob=0.05, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.jump_prob = jump_prob\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F: Adjust based on population diversity\n            diversity = np.std(population)\n            if diversity < self.diversity_threshold:\n                self.F = self.F_initial * 1.5  # Increase F to explore more\n            else:\n                self.F = self.F_initial  # Reset F\n\n            self.F = np.clip(self.F, 0.1, 1.0)  # Clip F to a reasonable range\n\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.003771187592408724, "generation": 7, "aucs": [0.19321853897814822, 0.4325468133424062, 0.7059632747280775, 0.8724121041868637, 0.7260999674636867, 0.8055177461687817, 0.4868457471697697, 0.6323611617945896, 0.7339017282177225, 0.6182077397139858, 0.8528402770932781, 0.9949781259066762, 0.3427665898289157, 0.5955925981785951, 0.9169451663398461, 0.33174521574261917, 0.5487276296770547, 0.8491616457520751, 0.2972586540330471, 0.503117442427248]}, "task_prompt": ""}
{"id": "662e7e86-dd62-4013-8f5b-de7eb805c3f6", "fitness": 0.0, "name": "SelfAdaptiveDE_with_LocalSearch", "description": "A self-adaptive Differential Evolution algorithm that adjusts its parameters (mutation factor and crossover rate) based on the success of previous generations, and incorporates a local search based on a Gaussian perturbation around the best solution found so far.", "code": "import numpy as np\n\nclass SelfAdaptiveDE_with_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial crossover rate\n        self.local_search_prob = local_search_prob # Probability of applying local search\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_pop = np.copy(pop)\n\n            # Self-adaptive parameter updates\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n\n                mutant = pop[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        mutant[j] = pop[i, j]\n                \n                # Evaluate trial vector and update\n                f_mutant = func(mutant)\n                self.budget -= 1\n\n                if f_mutant < fitness[i]:\n                    new_pop[i] = mutant\n                    fitness[i] = f_mutant\n\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n                        \n\n            #Update Population\n            pop = new_pop\n\n            # Adjust F and CR\n            if successful_F:\n                self.F = np.mean(successful_F)\n            else:\n                self.F = np.random.uniform(0.1, 0.9)  # Reset if no success\n\n            if successful_CR:\n                self.CR = np.mean(successful_CR)\n            else:\n                self.CR = np.random.rand()  # Reset if no success\n\n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                std_dev = 0.1 * (func.bounds.ub - func.bounds.lb)\n                x_local = np.clip(self.x_opt + np.random.normal(0, std_dev, size=self.dim), func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm SelfAdaptiveDE_with_LocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-adaptive Differential Evolution algorithm that adjusts its parameters (mutation factor and crossover rate) based on the success of previous generations, and incorporates a local search based on a Gaussian perturbation around the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE_with_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial crossover rate\n        self.local_search_prob = local_search_prob # Probability of applying local search\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_pop = np.copy(pop)\n\n            # Self-adaptive parameter updates\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n\n                mutant = pop[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        mutant[j] = pop[i, j]\n                \n                # Evaluate trial vector and update\n                f_mutant = func(mutant)\n                self.budget -= 1\n\n                if f_mutant < fitness[i]:\n                    new_pop[i] = mutant\n                    fitness[i] = f_mutant\n\n                    successful_F.append(self.F)\n                    successful_CR.append(self.CR)\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n                        \n\n            #Update Population\n            pop = new_pop\n\n            # Adjust F and CR\n            if successful_F:\n                self.F = np.mean(successful_F)\n            else:\n                self.F = np.random.uniform(0.1, 0.9)  # Reset if no success\n\n            if successful_CR:\n                self.CR = np.mean(successful_CR)\n            else:\n                self.CR = np.random.rand()  # Reset if no success\n\n            # Local Search\n            if np.random.rand() < self.local_search_prob:\n                std_dev = 0.1 * (func.bounds.ub - func.bounds.lb)\n                x_local = np.clip(self.x_opt + np.random.normal(0, std_dev, size=self.dim), func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0036777678607271833, "generation": 7, "aucs": [0]}, "task_prompt": ""}
{"id": "a50e3603-9e3d-4968-98f4-c1ab8e8346e9", "fitness": "-inf", "name": "AdaptiveCauchyDE_with_Restarts", "description": "Adaptive Cauchy DE with random restarts based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE_with_Restarts:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.last_improvement = self.eval_count\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n        self.last_improvement = self.eval_count\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement = self.eval_count\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            # Stagnation check and restart\n            if self.eval_count - self.last_improvement > self.stagnation_threshold:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698", "fc2c30e7-668d-4f6e-824d-e5c31a9f2f5a"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Cauchy DE with random restarts based on stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE_with_Restarts:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.last_improvement = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.last_improvement = self.eval_count\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b, c = np.random.choice(idx, 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def restart_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.pop[best_index]\n        self.last_improvement = self.eval_count\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-10 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.last_improvement = self.eval_count\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            # Stagnation check and restart\n            if self.eval_count - self.last_improvement > self.stagnation_threshold:\n                self.restart_population(func)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0012856907361043601, "generation": 8}, "task_prompt": ""}
{"id": "b8a2b04d-77bc-4382-95b1-ff2b652be8a2", "fitness": 0.5462905817814139, "name": "FitnessScaledPSO", "description": "Population-based algorithm with fitness-dependent mutation scaling and a velocity update mechanism inspired by particle swarm optimization.", "code": "import numpy as np\n\nclass FitnessScaledPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n    \n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Mutation scaling based on fitness rank\n            fitness_ranks = np.argsort(self.fitness)\n            mutation_scales = np.linspace(0.1, 1.0, self.pop_size)  # Scale from 0.1 to 1 based on rank\n            mutation_scales = mutation_scales[fitness_ranks]\n\n            for i in range(self.pop_size):\n                # Update velocity\n                inertia_term = self.inertia * self.velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                new_position = self.population[i] + self.velocities[i]\n\n                # Handle boundary constraints\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                eval_count += 1\n                \n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                self.population[i] = new_position\n                self.fitness[i] = new_fitness\n                \n                self.update_global_best()\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm FitnessScaledPSO scored 0.546 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with fitness-dependent mutation scaling and a velocity update mechanism inspired by particle swarm optimization.\n# Code: \n```python\nimport numpy as np\n\nclass FitnessScaledPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n    \n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = self.fitness[best_index]\n            self.global_best_position = self.population[best_index].copy()\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Mutation scaling based on fitness rank\n            fitness_ranks = np.argsort(self.fitness)\n            mutation_scales = np.linspace(0.1, 1.0, self.pop_size)  # Scale from 0.1 to 1 based on rank\n            mutation_scales = mutation_scales[fitness_ranks]\n\n            for i in range(self.pop_size):\n                # Update velocity\n                inertia_term = self.inertia * self.velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                new_position = self.population[i] + self.velocities[i]\n\n                # Handle boundary constraints\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                eval_count += 1\n                \n                if new_fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness\n                    self.personal_best_positions[i] = new_position.copy()\n\n                self.population[i] = new_position\n                self.fitness[i] = new_fitness\n                \n                self.update_global_best()\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.01862638269339267, "generation": 8, "aucs": [0.20624853715931968, 0.33072842856200124, 0.7000773418811328, 0.9250827421388927, 0.7614792858427476, 0.7778544804954692, 0.31649046665657776, 0.6921357258519871, 0.7354790406717377, 0.23264893971025435, 0.8443392492887019, 0.9997608157672025, 0.24972529335542448, 0.287911526247592, 0.7367152298734875, 0.381295941264551, 0.6204112998015844, 0.3782723951448219, 0.2656388111353941, 0.4835160847793951]}, "task_prompt": ""}
{"id": "7e534557-4517-4fc8-b7b0-eb13b12b6f51", "fitness": 0.7504827810897953, "name": "DE_CMAES", "description": "Population-based algorithm with a combination of differential evolution and covariance matrix adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma # Learning rate for CMA-ES update\n        self.de_rate = de_rate # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm DE_CMAES scored 0.750 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a combination of differential evolution and covariance matrix adaptation for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma # Learning rate for CMA-ES update\n        self.de_rate = de_rate # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0064008540400818555, "generation": 8, "aucs": [0.41310313718115277, 0.7966401452525241, 0.8667741738938918, 0.9350775979386723, 0.8809123923687556, 0.8967013234132303, 0.6893099172042543, 0.8718598071835315, 0.9058964733379548, 0.23560431670869042, 0.9340943386834294, 0.9976735086892327, 0.730335980870303, 0.8459420650633727, 0.5860989849049208, 0.9079708716860919, 0.7516525708392017, 0.9439984382615619, 0.29384529535435944, 0.5261642829607744]}, "task_prompt": ""}
{"id": "01c0ee18-c41e-4134-a2a7-9921c6ce1803", "fitness": "-inf", "name": "PSO_NM", "description": "Implementation of a novel metaheuristic optimization algorithm combining aspects of Particle Swarm Optimization (PSO) with a local search inspired by Nelder-Mead, adaptively adjusting the local search frequency based on swarm performance.", "code": "import numpy as np\n\nclass PSO_NM:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=1.5, c2=1.5, w=0.7, nm_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.nm_freq = nm_freq # Frequency of Nelder-Mead local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        \n        # Initialize global best\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        \n        eval_count = self.swarm_size # Initial evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - swarm[i]) + \\\n                                self.c2 * r2 * (global_best_position - swarm[i])\n                \n                # Update position\n                new_swarm_pos = swarm[i] + velocities[i]\n                new_swarm_pos = np.clip(new_swarm_pos, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_swarm_pos)\n                eval_count += 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_swarm_pos.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_swarm_pos.copy()\n\n                swarm[i] = new_swarm_pos\n                \n                # Apply Nelder-Mead local search with adaptive frequency\n                if np.random.rand() < self.nm_freq and eval_count < self.budget:\n                    nm_result = self._nelder_mead(func, swarm[i].copy(), eval_count, func.bounds.lb, func.bounds.ub, self.budget)\n                    nm_fitness, nm_position, eval_count_increment = nm_result\n\n                    eval_count += eval_count_increment\n                    if nm_fitness < personal_best_fitnesses[i]:\n                        personal_best_fitnesses[i] = nm_fitness\n                        personal_best_positions[i] = nm_position.copy()\n                        swarm[i] = nm_position.copy()\n\n                        if nm_fitness < global_best_fitness:\n                            global_best_fitness = nm_fitness\n                            global_best_position = nm_position.copy()\n                \n                if eval_count >= self.budget:\n                    break\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n                            \n        return self.f_opt, self.x_opt\n\n\n    def _nelder_mead(self, func, x0, eval_count_start, lb, ub, budget, step=0.1, alpha=1, gamma=2, rho=-0.5, sigma=0.5):\n        \"\"\"\n        Implementation of the Nelder-Mead simplex algorithm for local search.\n\n        Args:\n            func: The objective function to minimize.\n            x0: Initial guess.\n            step: Initial simplex side length.\n            alpha: Reflection coefficient.\n            gamma: Expansion coefficient.\n            rho: Contraction coefficient.\n            sigma: Shrink coefficient.\n\n        Returns:\n            The best solution found.\n        \"\"\"\n        n = len(x0)\n        simplex = np.zeros((n + 1, n))\n        simplex[0] = x0\n        eval_count = 0\n\n        for i in range(1, n + 1):\n            simplex[i] = x0.copy()\n            simplex[i][i - 1] = x0[i - 1] + step\n            simplex[i] = np.clip(simplex[i], lb, ub)\n\n        evals = np.array([func(x) for x in simplex])\n        eval_count += n\n        \n        while eval_count_start + eval_count < budget:\n\n            # 1. Order\n            order = np.argsort(evals)\n            simplex = simplex[order]\n            evals = evals[order]\n\n            best = simplex[0]\n            worst = simplex[-1]\n            second_worst = simplex[-2]\n            \n            # 2. Centroid\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # 3. Reflection\n            reflected = centroid + alpha * (centroid - worst)\n            reflected = np.clip(reflected, lb, ub)\n            f_reflected = func(reflected)\n            eval_count += 1\n\n            if evals[0] <= f_reflected < evals[-2]:\n                simplex[-1] = reflected\n                evals[-1] = f_reflected\n                continue\n\n            # 4. Expansion\n            if f_reflected < evals[0]:\n                expanded = centroid + gamma * (reflected - centroid)\n                expanded = np.clip(expanded, lb, ub)\n                f_expanded = func(expanded)\n                eval_count += 1\n\n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded\n                    evals[-1] = f_expanded\n                    continue\n                else:\n                    simplex[-1] = reflected\n                    evals[-1] = f_reflected\n                    continue\n            # 5. Contraction\n            else:\n                contracted = centroid + rho * (worst - centroid)\n                contracted = np.clip(contracted, lb, ub)\n                f_contracted = func(contracted)\n                eval_count += 1\n\n                if f_contracted < evals[-1]:\n                    simplex[-1] = contracted\n                    evals[-1] = f_contracted\n                    continue\n\n            # 6. Shrink\n            for i in range(1, len(simplex)):\n                simplex[i] = best + sigma * (simplex[i] - best)\n                simplex[i] = np.clip(simplex[i], lb, ub)\n                evals[i] = func(simplex[i])\n                eval_count += 1\n        \n        best_index = np.argmin(evals)\n        return evals[best_index], simplex[best_index], eval_count", "configspace": "", "generation": 8, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Implementation of a novel metaheuristic optimization algorithm combining aspects of Particle Swarm Optimization (PSO) with a local search inspired by Nelder-Mead, adaptively adjusting the local search frequency based on swarm performance.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_NM:\n    def __init__(self, budget=10000, dim=10, swarm_size=50, c1=1.5, c2=1.5, w=0.7, nm_freq=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.nm_freq = nm_freq # Frequency of Nelder-Mead local search\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        \n        # Initialize global best\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        \n        eval_count = self.swarm_size # Initial evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - swarm[i]) + \\\n                                self.c2 * r2 * (global_best_position - swarm[i])\n                \n                # Update position\n                new_swarm_pos = swarm[i] + velocities[i]\n                new_swarm_pos = np.clip(new_swarm_pos, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_swarm_pos)\n                eval_count += 1\n                \n                # Update personal best\n                if new_fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = new_fitness\n                    personal_best_positions[i] = new_swarm_pos.copy()\n                    \n                    # Update global best\n                    if new_fitness < global_best_fitness:\n                        global_best_fitness = new_fitness\n                        global_best_position = new_swarm_pos.copy()\n\n                swarm[i] = new_swarm_pos\n                \n                # Apply Nelder-Mead local search with adaptive frequency\n                if np.random.rand() < self.nm_freq and eval_count < self.budget:\n                    nm_result = self._nelder_mead(func, swarm[i].copy(), eval_count, func.bounds.lb, func.bounds.ub, self.budget)\n                    nm_fitness, nm_position, eval_count_increment = nm_result\n\n                    eval_count += eval_count_increment\n                    if nm_fitness < personal_best_fitnesses[i]:\n                        personal_best_fitnesses[i] = nm_fitness\n                        personal_best_positions[i] = nm_position.copy()\n                        swarm[i] = nm_position.copy()\n\n                        if nm_fitness < global_best_fitness:\n                            global_best_fitness = nm_fitness\n                            global_best_position = nm_position.copy()\n                \n                if eval_count >= self.budget:\n                    break\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n                            \n        return self.f_opt, self.x_opt\n\n\n    def _nelder_mead(self, func, x0, eval_count_start, lb, ub, budget, step=0.1, alpha=1, gamma=2, rho=-0.5, sigma=0.5):\n        \"\"\"\n        Implementation of the Nelder-Mead simplex algorithm for local search.\n\n        Args:\n            func: The objective function to minimize.\n            x0: Initial guess.\n            step: Initial simplex side length.\n            alpha: Reflection coefficient.\n            gamma: Expansion coefficient.\n            rho: Contraction coefficient.\n            sigma: Shrink coefficient.\n\n        Returns:\n            The best solution found.\n        \"\"\"\n        n = len(x0)\n        simplex = np.zeros((n + 1, n))\n        simplex[0] = x0\n        eval_count = 0\n\n        for i in range(1, n + 1):\n            simplex[i] = x0.copy()\n            simplex[i][i - 1] = x0[i - 1] + step\n            simplex[i] = np.clip(simplex[i], lb, ub)\n\n        evals = np.array([func(x) for x in simplex])\n        eval_count += n\n        \n        while eval_count_start + eval_count < budget:\n\n            # 1. Order\n            order = np.argsort(evals)\n            simplex = simplex[order]\n            evals = evals[order]\n\n            best = simplex[0]\n            worst = simplex[-1]\n            second_worst = simplex[-2]\n            \n            # 2. Centroid\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # 3. Reflection\n            reflected = centroid + alpha * (centroid - worst)\n            reflected = np.clip(reflected, lb, ub)\n            f_reflected = func(reflected)\n            eval_count += 1\n\n            if evals[0] <= f_reflected < evals[-2]:\n                simplex[-1] = reflected\n                evals[-1] = f_reflected\n                continue\n\n            # 4. Expansion\n            if f_reflected < evals[0]:\n                expanded = centroid + gamma * (reflected - centroid)\n                expanded = np.clip(expanded, lb, ub)\n                f_expanded = func(expanded)\n                eval_count += 1\n\n                if f_expanded < f_reflected:\n                    simplex[-1] = expanded\n                    evals[-1] = f_expanded\n                    continue\n                else:\n                    simplex[-1] = reflected\n                    evals[-1] = f_reflected\n                    continue\n            # 5. Contraction\n            else:\n                contracted = centroid + rho * (worst - centroid)\n                contracted = np.clip(contracted, lb, ub)\n                f_contracted = func(contracted)\n                eval_count += 1\n\n                if f_contracted < evals[-1]:\n                    simplex[-1] = contracted\n                    evals[-1] = f_contracted\n                    continue\n\n            # 6. Shrink\n            for i in range(1, len(simplex)):\n                simplex[i] = best + sigma * (simplex[i] - best)\n                simplex[i] = np.clip(simplex[i], lb, ub)\n                evals[i] = func(simplex[i])\n                eval_count += 1\n        \n        best_index = np.argmin(evals)\n        return evals[best_index], simplex[best_index], eval_count\n```", "operator": "random_new", "theta_sampled": 0.00704469917468304, "generation": 8}, "task_prompt": ""}
{"id": "669783b4-16a9-4c6f-b112-96492ad4d7eb", "fitness": "-inf", "name": "HybridCMAESLocalSearch", "description": "A hybrid algorithm combining a simplified CMA-ES with a local search based on gradient estimation, focusing on exploration early on and exploitation later.", "code": "import numpy as np\n\nclass HybridCMAESLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.local_search_iterations = local_search_iterations\n        self.mean = np.zeros(dim)\n        self.sigma = initial_sigma\n        self.C = np.eye(dim) # Covariance matrix (initialized to identity)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.eval_count < self.budget:\n            # Simplified CMA-ES sampling\n            z = np.random.normal(0, 1, self.dim)\n            x = self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z) # Sample from multivariate normal\n            x = np.clip(x, func.bounds.lb, func.bounds.ub) # clip to bounds\n\n\n            f = func(x)\n            self.eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n\n            # Update mean and covariance\n            if self.eval_count < self.budget * 0.5: # Exploration phase\n                self.mean = self.mean + (x - self.mean) / (self.eval_count + 1)\n                self.C = 0.9 * self.C + 0.1 * np.outer(x - self.mean, x - self.mean) / (self.sigma**2) #Simplified rank-1 update\n                self.sigma *= 1.0 + 0.1 * (f - self.f_opt)\n            else: # Exploitation phase (Local Search)\n                x_local = self.local_search(func, x.copy())\n                f_local = func(x_local)\n                self.eval_count += 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n                \n                self.mean = self.mean + (x_local - self.mean) / (self.eval_count + 1)\n                self.C = 0.9 * self.C + 0.1 * np.outer(x_local - self.mean, x_local - self.mean) / (self.sigma**2)\n\n                self.sigma *= 1.0 + 0.01 * (f_local - self.f_opt)\n\n\n            self.sigma = np.clip(self.sigma, 1e-6, 1.0) # Avoid sigma becoming zero or too large\n            self.C = np.diag(np.diag(self.C)) # Make diagonal to avoid covariance explosion\n                \n\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x):\n        \"\"\"Performs a simple local search by estimating gradients.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            gradient = np.zeros(self.dim)\n            delta = 1e-3  # Step size for gradient estimation\n\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n\n                x_plus[i] += delta\n                x_minus[i] -= delta\n\n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n\n                self.eval_count += 2\n\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n                \n\n            # Move against the gradient\n            x_new = x - 0.1 * gradient  # Adjust step size here\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new.copy()\n            else:\n                break\n\n\n        return best_x", "configspace": "", "generation": 8, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid algorithm combining a simplified CMA-ES with a local search based on gradient estimation, focusing on exploration early on and exploitation later.\n# Code:\n```python\nimport numpy as np\n\nclass HybridCMAESLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.local_search_iterations = local_search_iterations\n        self.mean = np.zeros(dim)\n        self.sigma = initial_sigma\n        self.C = np.eye(dim) # Covariance matrix (initialized to identity)\n        self.eval_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.eval_count < self.budget:\n            # Simplified CMA-ES sampling\n            z = np.random.normal(0, 1, self.dim)\n            x = self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z) # Sample from multivariate normal\n            x = np.clip(x, func.bounds.lb, func.bounds.ub) # clip to bounds\n\n\n            f = func(x)\n            self.eval_count += 1\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x.copy()\n\n            # Update mean and covariance\n            if self.eval_count < self.budget * 0.5: # Exploration phase\n                self.mean = self.mean + (x - self.mean) / (self.eval_count + 1)\n                self.C = 0.9 * self.C + 0.1 * np.outer(x - self.mean, x - self.mean) / (self.sigma**2) #Simplified rank-1 update\n                self.sigma *= 1.0 + 0.1 * (f - self.f_opt)\n            else: # Exploitation phase (Local Search)\n                x_local = self.local_search(func, x.copy())\n                f_local = func(x_local)\n                self.eval_count += 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n                \n                self.mean = self.mean + (x_local - self.mean) / (self.eval_count + 1)\n                self.C = 0.9 * self.C + 0.1 * np.outer(x_local - self.mean, x_local - self.mean) / (self.sigma**2)\n\n                self.sigma *= 1.0 + 0.01 * (f_local - self.f_opt)\n\n\n            self.sigma = np.clip(self.sigma, 1e-6, 1.0) # Avoid sigma becoming zero or too large\n            self.C = np.diag(np.diag(self.C)) # Make diagonal to avoid covariance explosion\n                \n\n\n            if self.eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x):\n        \"\"\"Performs a simple local search by estimating gradients.\"\"\"\n        best_x = x.copy()\n        best_f = func(x)\n        self.eval_count += 1\n\n        for _ in range(self.local_search_iterations):\n            gradient = np.zeros(self.dim)\n            delta = 1e-3  # Step size for gradient estimation\n\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n\n                x_plus[i] += delta\n                x_minus[i] -= delta\n\n                x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n                x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n\n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n\n                self.eval_count += 2\n\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n                \n\n            # Move against the gradient\n            x_new = x - 0.1 * gradient  # Adjust step size here\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            self.eval_count += 1\n\n            if f_new < best_f:\n                best_f = f_new\n                best_x = x_new.copy()\n            else:\n                break\n\n\n        return best_x\n```", "operator": "random_new", "theta_sampled": 0.05133052663061431, "generation": 8}, "task_prompt": ""}
{"id": "ed0a01c6-0c6a-4e21-a976-f2186f9966eb", "fitness": 0.5755499335682152, "name": "AdaptiveCauchyDE", "description": "Population-based optimization using a Cauchy mutation with a self-adaptive mutation factor and simplified crossover.", "code": "import numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b = np.random.choice(idx, 2, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[i])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement, simplified\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-5 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveCauchyDE scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5688b583-bc74-4cb5-8ebc-3e2ec55b5698"], "operator": "simplify", "metadata": {"llm_response": "# Description: Population-based optimization using a Cauchy mutation with a self-adaptive mutation factor and simplified crossover.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, initial_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def cauchy_mutation(self, x, scale):\n        mutation = scale * np.random.standard_cauchy(size=self.dim)\n        return x + mutation\n\n    def differential_evolution_crossover(self, pop, i):\n        idx = [r for r in range(self.pop_size) if r != i]\n        a, b = np.random.choice(idx, 2, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[i])\n        \n        cross_points = np.random.rand(self.dim) < self.CR\n        trial = np.where(cross_points, mutant, pop[i])\n        return trial\n\n    def bound_handling(self, x):\n        return np.clip(x, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Adaptive scale based on fitness improvement, simplified\n            scale = self.initial_scale * (self.ub - self.lb) * np.exp(-5 * (self.f_opt - np.min(self.fitness)) / abs(self.f_opt + 1e-9))\n\n            for i in range(self.pop_size):\n                mutated = self.cauchy_mutation(self.pop[i], scale)\n                mutated = self.bound_handling(mutated)\n                \n                trial = self.differential_evolution_crossover(self.pop, i)\n                trial = self.bound_handling(trial)\n                \n                f_trial = func(trial)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": -0.001653550059024286, "generation": 8, "aucs": [0.21856398411204114, 0.4030596377041056, 0.5403386179930689, 0.7965307601461997, 0.6383448103489375, 0.7196019944643768, 0.38032437069557845, 0.5533067859667197, 0.6332248184358967, 0.45288619571358446, 0.7846747633362902, 0.9905474683322635, 0.3189022085975919, 0.5579759226346506, 0.8794610983412794, 0.715759044258099, 0.4418826118567344, 0.7714325360019993, 0.20839079670055138, 0.5057902457243364]}, "task_prompt": ""}
{"id": "9fd4bf33-3bd7-4a38-a357-a4a35e00d4ab", "fitness": 0.6733822749951103, "name": "AdaptiveDE", "description": "A simplified JADE with adaptive F and CR, focusing on exploitation around the best solution and occasional random jumps for exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            #Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.673 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc2c30e7-668d-4f6e-824d-e5c31a9f2f5a"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified JADE with adaptive F and CR, focusing on exploitation around the best solution and occasional random jumps for exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            #Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0020246348041237654, "generation": 8, "aucs": [0.23166124476294425, 0.49497641255169633, 0.7426193623611224, 0.9154321880897941, 0.7660127646002612, 0.8436352160831457, 0.5214418809832201, 0.7003145117698467, 0.8033538206510746, 0.5858194530288163, 0.8802638585480804, 0.9888454622920022, 0.34835130463434205, 0.6985646063077284, 0.9162638912987098, 0.8336071972692125, 0.5875602057508842, 0.8740889468602641, 0.22309052690913223, 0.5117426451499274]}, "task_prompt": ""}
{"id": "3db651a9-4d1c-46e8-9419-9bf1b2a36a04", "fitness": 0.46195529240055844, "name": "EnhancedJADE", "description": "Simplified JADE with adaptive F and random jumps, focusing on balancing exploration and exploitation with a reduced parameter set and a simpler adaptive F strategy.", "code": "import numpy as np\n\nclass EnhancedJADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F_initial=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F_initial\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F: Reduce or increase based on success\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    successful_mutations += 1\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n            \n            # Adaptive F update rule\n            if successful_mutations > self.pop_size / 4:  # More than 25% successful\n                self.F *= 0.9  # Reduce F to exploit\n            else:\n                self.F *= 1.1  # Increase F to explore\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedJADE scored 0.462 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["fc2c30e7-668d-4f6e-824d-e5c31a9f2f5a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified JADE with adaptive F and random jumps, focusing on balancing exploration and exploitation with a reduced parameter set and a simpler adaptive F strategy.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedJADE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, CR=0.5, F_initial=0.5, jump_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR\n        self.F = F_initial\n        self.jump_prob = jump_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F: Reduce or increase based on success\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation\n                if np.random.rand() < self.jump_prob:\n                    # Random Jump\n                    mutant = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # DE mutation with current-to-best\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                    \n                    # Clip to bounds\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    successful_mutations += 1\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n            \n            # Adaptive F update rule\n            if successful_mutations > self.pop_size / 4:  # More than 25% successful\n                self.F *= 0.9  # Reduce F to exploit\n            else:\n                self.F *= 1.1  # Increase F to explore\n\n            self.F = np.clip(self.F, 0.1, 1.0)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.010489342491868496, "generation": 8, "aucs": [0.1640915904910225, 0.2765520185382888, 0.4759537522425239, 0.7094475922564114, 0.4810573136109465, 0.6133550973080139, 0.3647603664816329, 0.4203208082718224, 0.48554047395785804, 0.3821038764301852, 0.4206090093277074, 0.994308721621874, 0.28005095292936777, 0.2986130251973228, 0.7237407002869769, 0.3560477844164306, 0.3706376878938157, 0.7008403652498332, 0.22247758113087446, 0.4985971303682617]}, "task_prompt": ""}
{"id": "bd4e8f10-ec09-4157-9715-a91b6de0a9b4", "fitness": "-inf", "name": "EnhancedAdaptiveDE", "description": "An enhanced Differential Evolution with adaptive parameters and a repair mechanism to keep solutions within bounds, combined with a periodic restart strategy to escape local optima.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5, restart_interval=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.restart_interval = restart_interval\n        self.generation = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation - DE/rand/1 with repair\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[r1] + self.F * (population[r2] - population[r3])\n                \n                # Repair: clip and reflection\n                for j in range(self.dim):\n                    if mutant[j] < self.lb:\n                        mutant[j] = 2 * self.lb - mutant[j]\n                        if mutant[j] > self.ub:\n                            mutant[j] = self.lb + np.random.rand() * (self.ub - self.lb)\n\n                    elif mutant[j] > self.ub:\n                        mutant[j] = 2 * self.ub - mutant[j]\n                        if mutant[j] < self.lb:\n                            mutant[j] = self.lb + np.random.rand() * (self.ub - self.lb)\n                \n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n            # Restart strategy\n            if self.generation % self.restart_interval == 0:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                if self.budget <= 0:\n                    break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "In the code, line 44, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if mutant[j] < self.lb:", "error": "In the code, line 44, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if mutant[j] < self.lb:", "parent_ids": ["9fd4bf33-3bd7-4a38-a357-a4a35e00d4ab"], "operator": "simplify", "metadata": {"llm_response": "# Description: An enhanced Differential Evolution with adaptive parameters and a repair mechanism to keep solutions within bounds, combined with a periodic restart strategy to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5, restart_interval=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.restart_interval = restart_interval\n        self.generation = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            self.generation += 1\n            \n            # Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation - DE/rand/1 with repair\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[r1] + self.F * (population[r2] - population[r3])\n                \n                # Repair: clip and reflection\n                for j in range(self.dim):\n                    if mutant[j] < self.lb:\n                        mutant[j] = 2 * self.lb - mutant[j]\n                        if mutant[j] > self.ub:\n                            mutant[j] = self.lb + np.random.rand() * (self.ub - self.lb)\n\n                    elif mutant[j] > self.ub:\n                        mutant[j] = 2 * self.ub - mutant[j]\n                        if mutant[j] < self.lb:\n                            mutant[j] = self.lb + np.random.rand() * (self.ub - self.lb)\n                \n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n            # Restart strategy\n            if self.generation % self.restart_interval == 0:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                if self.budget <= 0:\n                    break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.010572774443912823, "generation": 9}, "task_prompt": ""}
{"id": "2954b2f1-9896-409a-81e7-0cbaa2002d7e", "fitness": 0.6919922366421944, "name": "AdaptivePopulationDE", "description": "An adaptive differential evolution algorithm that uses a population-wide learning approach to update the scaling factor and crossover rate based on the success of individuals.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        memory_F = []\n        memory_CR = []\n        success_F = []\n        success_CR = []\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Adaptive F and CR\n                if len(memory_F) > 0:\n                    F = np.random.choice(memory_F)\n                else:\n                    F = self.F  #default value\n                if len(memory_CR) > 0:\n                    CR = np.random.choice(memory_CR)\n                else:\n                    CR = self.CR #default value\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    memory_F.append(F)\n                    memory_CR.append(CR)\n                    \n                    if len(memory_F) > 100:\n                        memory_F.pop(0)\n                        memory_CR.pop(0)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptivePopulationDE scored 0.692 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that uses a population-wide learning approach to update the scaling factor and crossover rate based on the success of individuals.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        memory_F = []\n        memory_CR = []\n        success_F = []\n        success_CR = []\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Adaptive F and CR\n                if len(memory_F) > 0:\n                    F = np.random.choice(memory_F)\n                else:\n                    F = self.F  #default value\n                if len(memory_CR) > 0:\n                    CR = np.random.choice(memory_CR)\n                else:\n                    CR = self.CR #default value\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    success_F.append(F)\n                    success_CR.append(CR)\n                    memory_F.append(F)\n                    memory_CR.append(CR)\n                    \n                    if len(memory_F) > 100:\n                        memory_F.pop(0)\n                        memory_CR.pop(0)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.048329813317901996, "generation": 9, "aucs": [0.29851277146428734, 0.6474669077840858, 0.6915303476151671, 0.8549274092147916, 0.7415032684404268, 0.7948934200818519, 0.6359537278213299, 0.6603558051737559, 0.72465681388173, 0.644045709573713, 0.8446575216182146, 0.9922422321546798, 0.6330258280252088, 0.7303039010812039, 0.9152893115732096, 0.7780253380574379, 0.6539422373686266, 0.8298051533258057, 0.25870859776294886, 0.5099984308254135]}, "task_prompt": ""}
{"id": "d7099f42-0222-42f1-8bea-89517702215f", "fitness": 0.206457802199863, "name": "SelfOrganizingScoutBeetle", "description": "A self-organizing scout beetle algorithm that iteratively updates position based on best neighbor and global best, with a shrinking search radius to promote convergence.", "code": "import numpy as np\n\nclass SelfOrganizingScoutBeetle:\n    def __init__(self, budget=10000, dim=10, step_size=0.5, reduction_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.reduction_factor = reduction_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize a population of scout beetles\n        population_size = 10\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        eval_count = population_size # Account for initial evaluations\n\n        while eval_count < self.budget:\n            for i in range(population_size):\n                # Find the best neighbor (excluding itself)\n                neighbors = np.concatenate((population[:i], population[i+1:]), axis=0)\n                neighbor_fitness = np.concatenate((fitness[:i], fitness[i+1:]))\n                best_neighbor_index = np.argmin(neighbor_fitness)\n                best_neighbor = neighbors[best_neighbor_index]\n\n                # Find the global best beetle\n                global_best_index = np.argmin(fitness)\n                global_best = population[global_best_index]\n\n                # Update the beetle's position based on the best neighbor and global best\n                direction_neighbor = best_neighbor - population[i]\n                direction_global = global_best - population[i]\n                \n                # Combination strategy, adding some noise to it\n                new_position = population[i] + self.step_size * (0.5 * direction_neighbor + 0.5 * direction_global) + np.random.normal(0, 0.01, self.dim)\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                eval_count += 1\n\n                # Update the beetle's position and fitness if it's better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                # Update the global best if necessary\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_position\n\n                if eval_count >= self.budget:\n                    break\n\n            # Reduce the step size to promote convergence\n            self.step_size *= self.reduction_factor\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm SelfOrganizingScoutBeetle scored 0.206 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-organizing scout beetle algorithm that iteratively updates position based on best neighbor and global best, with a shrinking search radius to promote convergence.\n# Code: \n```python\nimport numpy as np\n\nclass SelfOrganizingScoutBeetle:\n    def __init__(self, budget=10000, dim=10, step_size=0.5, reduction_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.reduction_factor = reduction_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize a population of scout beetles\n        population_size = 10\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        eval_count = population_size # Account for initial evaluations\n\n        while eval_count < self.budget:\n            for i in range(population_size):\n                # Find the best neighbor (excluding itself)\n                neighbors = np.concatenate((population[:i], population[i+1:]), axis=0)\n                neighbor_fitness = np.concatenate((fitness[:i], fitness[i+1:]))\n                best_neighbor_index = np.argmin(neighbor_fitness)\n                best_neighbor = neighbors[best_neighbor_index]\n\n                # Find the global best beetle\n                global_best_index = np.argmin(fitness)\n                global_best = population[global_best_index]\n\n                # Update the beetle's position based on the best neighbor and global best\n                direction_neighbor = best_neighbor - population[i]\n                direction_global = global_best - population[i]\n                \n                # Combination strategy, adding some noise to it\n                new_position = population[i] + self.step_size * (0.5 * direction_neighbor + 0.5 * direction_global) + np.random.normal(0, 0.01, self.dim)\n                \n                # Clip to bounds\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new position\n                new_fitness = func(new_position)\n                eval_count += 1\n\n                # Update the beetle's position and fitness if it's better\n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n\n                # Update the global best if necessary\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_position\n\n                if eval_count >= self.budget:\n                    break\n\n            # Reduce the step size to promote convergence\n            self.step_size *= self.reduction_factor\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.07679421244821957, "generation": 9, "aucs": [0.0414577402762667, 0.15651630991653842, 0.25463662910935025, 0.16483426542677682, 0.13451118046813748, 0.1811698494264572, 0.19827360068056943, 0.1805448739643183, 0.17257741188820985, 0.16264447544505112, 0.18390387261441155, 0.25055868216630806, 0.2737677546995235, 0.19895172538104133, 0.24705681055603634, 0.3462202586799754, 0.19965023251784864, 0.16846857932391335, 0.15838087044990512, 0.4550309210066207]}, "task_prompt": ""}
{"id": "f5b25e82-d0d3-431c-88a5-2ec1e3363f4b", "fitness": "-inf", "name": "OrthogonalLearningDE", "description": "Population-based algorithm using orthogonal learning to select promising individuals and update population members based on their location and performance.", "code": "import numpy as np\n\nclass OrthogonalLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index].copy()\n\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx]\n\n        # Create an orthogonal array with L9(3^4) design\n        OA = np.array([\n            [-1, -1, -1, -1],\n            [-1,  0,  0,  1],\n            [-1,  1,  1, -1],\n            [ 0, -1,  0, -1],\n            [ 0,  0,  1,  1],\n            [ 0,  1, -1,  1],\n            [ 1, -1,  1,  1],\n            [ 1,  0, -1, -1],\n            [ 1,  1,  0, -1]\n        ])\n\n        level_map = {-1: x1, 0: 0.5 * (x1 + x2), 1: x2}\n\n        candidates = np.zeros((9, self.dim))\n        for i in range(9):\n            for j in range(self.dim):\n                candidates[i,j] = level_map[OA[i % 9, j % 4]][j % self.dim] if self.dim > 0 else level_map[OA[i % 9, j % 4]] # prevent error in 1D optimization\n\n        fitnesses = np.array([func(x) for x in candidates])\n        self.eval_count += 9\n        best_index = np.argmin(fitnesses)\n        \n        if fitnesses[best_index] < self.f_opt:\n            self.f_opt = fitnesses[best_index]\n            self.x_opt = candidates[best_index].copy()\n\n        return candidates[best_index]\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == np.random.randint(self.dim):\n                        x_trial[j] = x_mutated[j]\n                    else:\n                        x_trial[j] = self.population[i][j]\n                \n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n\n                if self.eval_count + 9 <= self.budget:\n                    learned_vector = self.orthogonal_learning(func)\n                    f_learned = func(learned_vector)\n                    self.eval_count += 1\n                    \n                    if f_learned < self.f_opt:\n                        self.f_opt = f_learned\n                        self.x_opt = learned_vector.copy()\n                else:\n                    break\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using orthogonal learning to select promising individuals and update population members based on their location and performance.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index].copy()\n\n\n    def orthogonal_learning(self, func):\n        # Select two random individuals\n        idx = np.random.choice(self.pop_size, 2, replace=False)\n        x1, x2 = self.population[idx]\n\n        # Create an orthogonal array with L9(3^4) design\n        OA = np.array([\n            [-1, -1, -1, -1],\n            [-1,  0,  0,  1],\n            [-1,  1,  1, -1],\n            [ 0, -1,  0, -1],\n            [ 0,  0,  1,  1],\n            [ 0,  1, -1,  1],\n            [ 1, -1,  1,  1],\n            [ 1,  0, -1, -1],\n            [ 1,  1,  0, -1]\n        ])\n\n        level_map = {-1: x1, 0: 0.5 * (x1 + x2), 1: x2}\n\n        candidates = np.zeros((9, self.dim))\n        for i in range(9):\n            for j in range(self.dim):\n                candidates[i,j] = level_map[OA[i % 9, j % 4]][j % self.dim] if self.dim > 0 else level_map[OA[i % 9, j % 4]] # prevent error in 1D optimization\n\n        fitnesses = np.array([func(x) for x in candidates])\n        self.eval_count += 9\n        best_index = np.argmin(fitnesses)\n        \n        if fitnesses[best_index] < self.f_opt:\n            self.f_opt = fitnesses[best_index]\n            self.x_opt = candidates[best_index].copy()\n\n        return candidates[best_index]\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r1 - x_r2)\n\n                # Crossover\n                x_trial = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == np.random.randint(self.dim):\n                        x_trial[j] = x_mutated[j]\n                    else:\n                        x_trial[j] = self.population[i][j]\n                \n                x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n\n                if self.eval_count + 9 <= self.budget:\n                    learned_vector = self.orthogonal_learning(func)\n                    f_learned = func(learned_vector)\n                    self.eval_count += 1\n                    \n                    if f_learned < self.f_opt:\n                        self.f_opt = f_learned\n                        self.x_opt = learned_vector.copy()\n                else:\n                    break\n                \n                if self.eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03824479749269477, "generation": 9}, "task_prompt": ""}
{"id": "ea8bc65b-6af1-47d8-9006-c0bca0f00566", "fitness": 0.6523498788777017, "name": "OrthogonalCMAES", "description": "Population-based algorithm with adaptive exploration-exploitation balance using a simplified covariance matrix adaptation and orthogonal learning.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_sigma\n        self.pc = np.zeros(self.dim)\n        self.mean = None\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n        self.rng = np.random.default_rng()\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = self.rng.uniform(self.bounds_lb, self.bounds_ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Generate population\n            z = self.rng.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z\n            \n            # Boundary handling (clamping)\n            x = np.clip(x, self.bounds_lb, self.bounds_ub)\n\n            f = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            \n            # Cumulation\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.mean - mean_old) / self.sigma\n\n            # Step size control\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / np.sqrt(self.dim) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 10)  # Keep sigma within reasonable bounds\n\n\n            # Orthogonal Learning (Simplified) - Randomly choose 2 dimensions and perform orthogonal transformation\n            if self.dim > 1:\n                d1, d2 = self.rng.choice(self.dim, 2, replace=False)\n                \n                # Simple rotation matrix\n                theta = self.rng.uniform(0, 2*np.pi)\n                R = np.eye(2)\n                R[0,0] = np.cos(theta)\n                R[0,1] = -np.sin(theta)\n                R[1,0] = np.sin(theta)\n                R[1,1] = np.cos(theta)\n\n                # Apply rotation to the top mu individuals in z-space\n                for i in range(self.mu):\n                  v = z_sorted[i, [d1, d2]]\n                  z_sorted[i, [d1, d2]] = R @ v \n                \n                # Update mean using the rotated z-vectors\n                self.mean = np.sum(self.weights[:, None] * (self.mean + self.sigma * z_sorted[:self.mu]), axis=0)\n\n            # Break if budget is exceeded within population generation\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm OrthogonalCMAES scored 0.652 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive exploration-exploitation balance using a simplified covariance matrix adaptation and orthogonal learning.\n# Code:\n```python\nimport numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_sigma\n        self.pc = np.zeros(self.dim)\n        self.mean = None\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n        self.rng = np.random.default_rng()\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = self.rng.uniform(self.bounds_lb, self.bounds_ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Generate population\n            z = self.rng.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z\n            \n            # Boundary handling (clamping)\n            x = np.clip(x, self.bounds_lb, self.bounds_ub)\n\n            f = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n            \n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[np.argmin(f)]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            \n            # Cumulation\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.mean - mean_old) / self.sigma\n\n            # Step size control\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / np.sqrt(self.dim) - 1))\n            self.sigma = np.clip(self.sigma, 1e-10, 10)  # Keep sigma within reasonable bounds\n\n\n            # Orthogonal Learning (Simplified) - Randomly choose 2 dimensions and perform orthogonal transformation\n            if self.dim > 1:\n                d1, d2 = self.rng.choice(self.dim, 2, replace=False)\n                \n                # Simple rotation matrix\n                theta = self.rng.uniform(0, 2*np.pi)\n                R = np.eye(2)\n                R[0,0] = np.cos(theta)\n                R[0,1] = -np.sin(theta)\n                R[1,0] = np.sin(theta)\n                R[1,1] = np.cos(theta)\n\n                # Apply rotation to the top mu individuals in z-space\n                for i in range(self.mu):\n                  v = z_sorted[i, [d1, d2]]\n                  z_sorted[i, [d1, d2]] = R @ v \n                \n                # Update mean using the rotated z-vectors\n                self.mean = np.sum(self.weights[:, None] * (self.mean + self.sigma * z_sorted[:self.mu]), axis=0)\n\n            # Break if budget is exceeded within population generation\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03656722864721931, "generation": 9, "aucs": [0.20929800900599593, 0.8539296953467417, 0.9250578640486995, 0.960750859591959, 0.9266782947094773, 0.9375054106411126, 0.2801422384974942, 0.9159853986977716, 0.8968703758379041, 0.16976805987020194, 0.9574761178055922, 0.9973559005431525, 0.22491787584512168, 0.5357092413402912, 0.8623206497680735, 0.3549864290960124, 0.41266294892624567, 0.9595555238121672, 0.17878169355489848, 0.4872449906151225]}, "task_prompt": ""}
{"id": "03aaeeef-ba3f-4544-b9b3-33659b9e01b2", "fitness": 0.618713780729879, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with ensemble of mutation strategies and self-adaptive parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.mutation_strategies = [\"rand1\", \"current_to_best\", \"rand2\"]  # Ensemble of mutation strategies\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            # Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation Strategy Selection\n                mutation_strategy = np.random.choice(self.mutation_strategies)\n\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant = population[r1] + self.F * (population[r2] - population[r3])\n                elif mutation_strategy == \"current_to_best\":\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                elif mutation_strategy == \"rand2\":\n                     r1, r2, r3, r4, r5 = np.random.choice(self.pop_size, 5, replace=False)\n                     mutant = population[r1] + self.F * (population[r2] - population[r3]) + self.F * (population[r4] - population[r5])\n                \n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDE scored 0.619 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9fd4bf33-3bd7-4a38-a357-a4a35e00d4ab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with ensemble of mutation strategies and self-adaptive parameters.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, CR_initial=0.5, F_initial=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.CR = CR_initial\n        self.F = F_initial\n        self.F_initial = F_initial\n        self.mutation_strategies = [\"rand1\", \"current_to_best\", \"rand2\"]  # Ensemble of mutation strategies\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            # Adaptive CR and F\n            self.CR = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n            self.F = np.clip(np.random.normal(self.F_initial, 0.1), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # Mutation Strategy Selection\n                mutation_strategy = np.random.choice(self.mutation_strategies)\n\n                # Mutation\n                if mutation_strategy == \"rand1\":\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant = population[r1] + self.F * (population[r2] - population[r3])\n                elif mutation_strategy == \"current_to_best\":\n                    r1, r2 = np.random.choice(self.pop_size, 2, replace=False)\n                    mutant = population[i] + self.F * (self.x_opt - population[i]) + self.F * (population[r1] - population[r2])\n                elif mutation_strategy == \"rand2\":\n                     r1, r2, r3, r4, r5 = np.random.choice(self.pop_size, 5, replace=False)\n                     mutant = population[r1] + self.F * (population[r2] - population[r3]) + self.F * (population[r4] - population[r5])\n                \n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.04433553203787219, "generation": 9, "aucs": [0.20911808636487217, 0.38049465619910516, 0.6551227344338583, 0.866612530300124, 0.7021976399415916, 0.7883113818575059, 0.49324864859365636, 0.5795254740472486, 0.7282217509591965, 0.5695681964088442, 0.7843056501858584, 0.9906408835562633, 0.2766716186218404, 0.6465689805947135, 0.8765675300623129, 0.7939081047639414, 0.48719004983183345, 0.8168540038411111, 0.208096656244236, 0.5210510377894667]}, "task_prompt": ""}
{"id": "a7d420f6-ba41-410a-9ee7-3202128d42b9", "fitness": 0.4849988198886185, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on current-to-pbest mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, p_best=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.p_best = p_best\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            #Adaptive F\n            F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # p-best selection\n                p_best_count = max(1, int(self.pop_size * self.p_best))\n                indices = np.argsort(fitness)[:p_best_count]\n                p_best_index = np.random.choice(indices)\n                p_best_vector = population[p_best_index]\n                \n                # Mutation: current-to-pbest\n                r1 = np.random.choice(self.pop_size)\n                while r1 == i:\n                    r1 = np.random.choice(self.pop_size)\n                \n                mutant = population[i] + F * (p_best_vector - population[i]) + F * (population[r1] - population[i])\n                \n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < 0.9 # Fixed CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDE scored 0.485 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9fd4bf33-3bd7-4a38-a357-a4a35e00d4ab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and a focus on current-to-pbest mutation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, p_best=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.p_best = p_best\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        # Optimization loop\n        while self.budget > 0:\n            \n            #Adaptive F\n            F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0)\n\n            for i in range(self.pop_size):\n                # p-best selection\n                p_best_count = max(1, int(self.pop_size * self.p_best))\n                indices = np.argsort(fitness)[:p_best_count]\n                p_best_index = np.random.choice(indices)\n                p_best_vector = population[p_best_index]\n                \n                # Mutation: current-to-pbest\n                r1 = np.random.choice(self.pop_size)\n                while r1 == i:\n                    r1 = np.random.choice(self.pop_size)\n                \n                mutant = population[i] + F * (p_best_vector - population[i]) + F * (population[r1] - population[i])\n                \n                # Clip to bounds\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < 0.9 # Fixed CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Evaluation\n                f = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial_vector\n                    \n                    # Update best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.031203155796538772, "generation": 9, "aucs": [0.26295216176533476, 0.49788269877562086, 0.3993279350656481, 0.1662643948183582, 0.3233382357981476, 0.4969924684367174, 0.3395282342282102, 0.43819004079561696, 0.29237231060009494, 0.22008095914365022, 0.9095433143161715, 0.9923481912796644, 0.2703754683346561, 0.39793511454232255, 0.9323593899506462, 0.7556514896310431, 0.4128271194328451, 0.9163606405162431, 0.2089891907323681, 0.4666570396090096]}, "task_prompt": ""}
{"id": "716abbbd-a6ce-4107-a072-3f43c747f6c3", "fitness": "-inf", "name": "AdaptiveDE_CMA", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation (CMA) using a dynamically adjusted DE rate based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, F=0.5, CR=0.7, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_sigma = initial_sigma\n\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(dim)\n        self.de_rate = 0.5  # Initial DE rate\n        self.de_rate_history = []\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the population based on the mean distance to centroid.\"\"\"\n        distances = np.linalg.norm(self.population - self.mean, axis=1)\n        return np.mean(distances)\n\n    def update_de_rate(self):\n        \"\"\"Dynamically adjusts the DE rate based on population diversity.\"\"\"\n        diversity = self.calculate_diversity()\n        # Adjust DE rate based on diversity.  If diversity is low, reduce DE rate, else increase or keep same.\n        # Experiment with different adjustment strategies. A simple linear adjustment is used below.\n        if len(self.de_rate_history) > 5:\n            if diversity < np.mean(self.de_rate_history[-5:]):\n                self.de_rate = max(0.1, self.de_rate - 0.1)  # Reduce DE rate if diversity is low.\n            else:\n                self.de_rate = min(0.9, self.de_rate + 0.05)\n                \n\n        self.de_rate_history.append(diversity)\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            self.update_de_rate()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = np.mean(self.population, axis=0)\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation (CMA) using a dynamically adjusted DE rate based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, F=0.5, CR=0.7, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_sigma = initial_sigma\n\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(dim)\n        self.de_rate = 0.5  # Initial DE rate\n        self.de_rate_history = []\n\n    def calculate_diversity(self):\n        \"\"\"Calculates the diversity of the population based on the mean distance to centroid.\"\"\"\n        distances = np.linalg.norm(self.population - self.mean, axis=1)\n        return np.mean(distances)\n\n    def update_de_rate(self):\n        \"\"\"Dynamically adjusts the DE rate based on population diversity.\"\"\"\n        diversity = self.calculate_diversity()\n        # Adjust DE rate based on diversity.  If diversity is low, reduce DE rate, else increase or keep same.\n        # Experiment with different adjustment strategies. A simple linear adjustment is used below.\n        if len(self.de_rate_history) > 5:\n            if diversity < np.mean(self.de_rate_history[-5:]):\n                self.de_rate = max(0.1, self.de_rate - 0.1)  # Reduce DE rate if diversity is low.\n            else:\n                self.de_rate = min(0.9, self.de_rate + 0.05)\n                \n\n        self.de_rate_history.append(diversity)\n        \n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            self.update_de_rate()\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = np.mean(self.population, axis=0)\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.012438497852951903, "generation": 9}, "task_prompt": ""}
{"id": "089274d8-1c5f-48e1-84b3-c6bcc510e8c6", "fitness": "-inf", "name": "HypersphereDE", "description": "A population-based algorithm that combines aspects of differential evolution with a shrinking hypersphere around the best solution found so far.", "code": "import numpy as np\n\nclass HypersphereDE:\n    def __init__(self, budget=10000, dim=10, population_size=50, sphere_reduction_factor=0.99, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.sphere_reduction_factor = sphere_reduction_factor\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        sphere_radius = (ub - lb) / 2.0 # Initial radius of hypersphere\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                if self.budget <= 0:\n                    break\n                \n                # Choose three random distinct individuals\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n\n                # Mutation\n                mutant = a + self.de_mutation_factor * (b - c)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.de_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Hypersphere constraint: keep within hypersphere around best solution\n                trial = np.clip(trial, lb, ub)\n                \n                distance_to_best = np.linalg.norm(trial - self.x_opt)\n                if distance_to_best > sphere_radius:\n                    # Project back onto the hypersphere surface\n                    direction = (trial - self.x_opt) / distance_to_best\n                    trial = self.x_opt + sphere_radius * direction\n                    trial = np.clip(trial, lb, ub)\n                \n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        \n            # Reduce the hypersphere radius\n            sphere_radius *= self.sphere_reduction_factor\n            sphere_radius = max(sphere_radius, 1e-6 * (ub - lb)) # Avoid radius becoming zero\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "In the code, line 51, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if distance_to_best > sphere_radius:", "error": "In the code, line 51, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if distance_to_best > sphere_radius:", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a shrinking hypersphere around the best solution found so far.\n\n# Code:\n```python\nimport numpy as np\n\nclass HypersphereDE:\n    def __init__(self, budget=10000, dim=10, population_size=50, sphere_reduction_factor=0.99, de_mutation_factor=0.5, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.sphere_reduction_factor = sphere_reduction_factor\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        sphere_radius = (ub - lb) / 2.0 # Initial radius of hypersphere\n\n        while self.budget > 0:\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                if self.budget <= 0:\n                    break\n                \n                # Choose three random distinct individuals\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n\n                # Mutation\n                mutant = a + self.de_mutation_factor * (b - c)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.de_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Hypersphere constraint: keep within hypersphere around best solution\n                trial = np.clip(trial, lb, ub)\n                \n                distance_to_best = np.linalg.norm(trial - self.x_opt)\n                if distance_to_best > sphere_radius:\n                    # Project back onto the hypersphere surface\n                    direction = (trial - self.x_opt) / distance_to_best\n                    trial = self.x_opt + sphere_radius * direction\n                    trial = np.clip(trial, lb, ub)\n                \n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        \n            # Reduce the hypersphere radius\n            sphere_radius *= self.sphere_reduction_factor\n            sphere_radius = max(sphere_radius, 1e-6 * (ub - lb)) # Avoid radius becoming zero\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.035931422834220184, "generation": 10}, "task_prompt": ""}
{"id": "d4ac299e-e23e-4fbb-83ca-d4936fbe8015", "fitness": 0.31114658913210447, "name": "VelocityDE", "description": "A population-based algorithm that combines aspects of differential evolution with a simple velocity update, allowing for exploration and exploitation. The population is dynamically adjusted based on performance.", "code": "import numpy as np\n\nclass VelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.5, cr=0.7, velocity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Dynamic population size based on dimensionality\n        self.f = f\n        self.cr = cr\n        self.velocity_weight = velocity_weight\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def adjust_population_size(self):\n        # Dynamically adjust population size based on performance.\n        # If the population is converging too quickly (low diversity), increase it.\n        # If the population is stagnant, decrease it to focus the search.\n        diversity = np.std(self.population)\n        if diversity < 0.01:  # Example threshold, tune as needed\n            self.pop_size = int(self.pop_size * 1.1)  # Increase pop size\n        elif diversity > 1:  # Example threshold, tune as needed\n            self.pop_size = max(int(self.pop_size * 0.9), 4) # Decrease pop size, ensure minimum size\n        self.pop_size = min(self.pop_size, 2 * self.dim) # limit population size\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.adjust_population_size()\n\n            for i in range(self.pop_size):\n                # Differential Evolution part\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[idxs]\n                \n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.cr\n                trial = np.where(cross_mask, mutant, self.population[i])\n                \n                # Velocity update\n                velocity = self.velocity_weight * (self.x_opt - self.population[i])  # Towards best solution\n                trial = trial + velocity\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                f = func(trial)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm VelocityDE scored 0.311 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution with a simple velocity update, allowing for exploration and exploitation. The population is dynamically adjusted based on performance.\n# Code: \n```python\nimport numpy as np\n\nclass VelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, f=0.5, cr=0.7, velocity_weight=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Dynamic population size based on dimensionality\n        self.f = f\n        self.cr = cr\n        self.velocity_weight = velocity_weight\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def adjust_population_size(self):\n        # Dynamically adjust population size based on performance.\n        # If the population is converging too quickly (low diversity), increase it.\n        # If the population is stagnant, decrease it to focus the search.\n        diversity = np.std(self.population)\n        if diversity < 0.01:  # Example threshold, tune as needed\n            self.pop_size = int(self.pop_size * 1.1)  # Increase pop size\n        elif diversity > 1:  # Example threshold, tune as needed\n            self.pop_size = max(int(self.pop_size * 0.9), 4) # Decrease pop size, ensure minimum size\n        self.pop_size = min(self.pop_size, 2 * self.dim) # limit population size\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.adjust_population_size()\n\n            for i in range(self.pop_size):\n                # Differential Evolution part\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[idxs]\n                \n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.cr\n                trial = np.where(cross_mask, mutant, self.population[i])\n                \n                # Velocity update\n                velocity = self.velocity_weight * (self.x_opt - self.population[i])  # Towards best solution\n                trial = trial + velocity\n                trial = np.clip(trial, self.lb, self.ub)\n                \n                f = func(trial)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.eval_count >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.022095922757595914, "generation": 10, "aucs": [0.17476897706791839, 0.1924402652222621, 0.34094811610161546, 0.23767227650211342, 0.19973105595312557, 0.22049591707719662, 0.292219955733243, 0.2065115754878657, 0.3285949691065918, 0.1875399506022275, 0.20338826071979588, 0.9938986467965927, 0.27199895793043793, 0.27296656582271916, 0.5653425641091523, 0.2741271452826496, 0.22376978753128574, 0.34311086854224115, 0.21272640614440497, 0.4806795209086503]}, "task_prompt": ""}
{"id": "a015be72-0ea9-4b71-ae1e-1acef44f8134", "fitness": "-inf", "name": "AdaptiveDE_CMAES", "description": "Integrates adaptive F and CR parameters from AdaptivePopulationDE into DE_CMAES to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma # Learning rate for CMA-ES update\n        self.de_rate = de_rate # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.memory_F = []\n        self.memory_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                if len(self.memory_F) > 0:\n                    F = np.random.choice(self.memory_F)\n                else:\n                    F = self.F  #default value\n                if len(self.memory_CR) > 0:\n                    CR = np.random.choice(self.memory_CR)\n                else:\n                    CR = self.CR #default value\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Update memory of F and CR\n                    self.memory_F.append(F)\n                    self.memory_CR.append(CR)\n\n                    if len(self.memory_F) > 100:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n                        \n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51", "2954b2f1-9896-409a-81e7-0cbaa2002d7e"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates adaptive F and CR parameters from AdaptivePopulationDE into DE_CMAES to enhance exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma # Learning rate for CMA-ES update\n        self.de_rate = de_rate # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.memory_F = []\n        self.memory_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                if len(self.memory_F) > 0:\n                    F = np.random.choice(self.memory_F)\n                else:\n                    F = self.F  #default value\n                if len(self.memory_CR) > 0:\n                    CR = np.random.choice(self.memory_CR)\n                else:\n                    CR = self.CR #default value\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Update memory of F and CR\n                    self.memory_F.append(F)\n                    self.memory_CR.append(CR)\n\n                    if len(self.memory_F) > 100:\n                        self.memory_F.pop(0)\n                        self.memory_CR.pop(0)\n                        \n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": -0.002209864479813187, "generation": 10}, "task_prompt": ""}
{"id": "d2197210-50e0-46cd-96ad-ccf4f3c0ccf7", "fitness": 0.7189793662425804, "name": "SelfAdaptiveDE", "description": "Self-adaptive differential evolution with a dynamic population size and archive to maintain diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F_mu=0.5, CR_mu=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F_mu = F_mu\n        self.CR_mu = CR_mu\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.sf_list = []\n        self.scr_list = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F_mu, 0.1)\n                CR = np.random.normal(self.CR_mu, 0.1)\n                F = np.clip(F, 0.0, 1.0)\n                CR = np.clip(CR, 0.0, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0:\n                    idxs.append(np.random.randint(len(self.archive))) # add archive index\n                    candidates = np.concatenate((population[idxs[:self.pop_size-1]], np.array([self.archive[idxs[-1]]])))\n                else:\n                     candidates = population[np.random.choice(idxs, self.pop_size-1, replace=False)]\n                a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    self.sf_list.append(F)\n                    self.scr_list.append(CR)\n\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n            \n            if len(self.sf_list) > 0:\n                self.F_mu = np.mean(self.sf_list)\n                self.CR_mu = np.mean(self.scr_list)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm SelfAdaptiveDE scored 0.719 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2954b2f1-9896-409a-81e7-0cbaa2002d7e"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive differential evolution with a dynamic population size and archive to maintain diversity.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_size=10, F_mu=0.5, CR_mu=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F_mu = F_mu\n        self.CR_mu = CR_mu\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.sf_list = []\n        self.scr_list = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F_mu, 0.1)\n                CR = np.random.normal(self.CR_mu, 0.1)\n                F = np.clip(F, 0.0, 1.0)\n                CR = np.clip(CR, 0.0, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0:\n                    idxs.append(np.random.randint(len(self.archive))) # add archive index\n                    candidates = np.concatenate((population[idxs[:self.pop_size-1]], np.array([self.archive[idxs[-1]]])))\n                else:\n                     candidates = population[np.random.choice(idxs, self.pop_size-1, replace=False)]\n                a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    self.sf_list.append(F)\n                    self.scr_list.append(CR)\n\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n            \n            if len(self.sf_list) > 0:\n                self.F_mu = np.mean(self.sf_list)\n                self.CR_mu = np.mean(self.scr_list)\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.029706229706340702, "generation": 10, "aucs": [0.36132810670205473, 0.6690419964241701, 0.6672296922556875, 0.8679115374623907, 0.769549598150041, 0.7903928949046974, 0.6501158911294476, 0.7026334551905747, 0.7187327106861805, 0.7341182403261767, 0.8605672268318889, 0.9882326855737709, 0.7058994292726497, 0.7291685186666761, 0.9048445868151084, 0.7844022325260442, 0.6884092012726244, 0.8249240716157402, 0.2992918543751124, 0.6627933946705702]}, "task_prompt": ""}
{"id": "df51c34c-9046-4fb2-8d28-1bfa9771cb7e", "fitness": "-inf", "name": "AdaptiveDE_CMAES", "description": "Adaptively switches between DE and CMA-ES based on their recent success rates, simplifying parameter updates.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate_init=0.5, F=0.5, CR=0.7, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate_init\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_threshold = success_threshold\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.de_success_rate = 0.0\n        self.cma_success_rate = 0.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        de_successes = 0\n        cma_successes = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                total_iterations += 1\n\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    de_active = True\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    de_active = False\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    if de_active:\n                        de_successes += 1\n                    else:\n                        cma_successes += 1\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if de_active:\n                        pass # No CMA-ES update when DE succeeds\n                    else:\n                        diff = trial_vector - self.mean\n                        self.mean = (1 - self.lr_cma) * self.mean + self.lr_cma * trial_vector\n                        self.C = (1 - self.lr_cma) * self.C + self.lr_cma * (np.outer(diff / self.sigma, diff / self.sigma) - self.C)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n            \n            # Adaptive DE Rate Adjustment\n            if total_iterations > 0:\n                self.de_success_rate = de_successes / total_iterations\n                self.cma_success_rate = cma_successes / total_iterations\n\n                if self.de_success_rate > self.success_threshold:\n                    self.de_rate = min(1.0, self.de_rate + 0.1)\n                else:\n                    self.de_rate = max(0.0, self.de_rate - 0.1)\n                \n                de_successes = 0\n                cma_successes = 0\n                total_iterations = 0\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptively switches between DE and CMA-ES based on their recent success rates, simplifying parameter updates.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate_init=0.5, F=0.5, CR=0.7, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate_init\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_threshold = success_threshold\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.de_success_rate = 0.0\n        self.cma_success_rate = 0.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        de_successes = 0\n        cma_successes = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                total_iterations += 1\n\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    de_active = True\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    de_active = False\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    if de_active:\n                        de_successes += 1\n                    else:\n                        cma_successes += 1\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if de_active:\n                        pass # No CMA-ES update when DE succeeds\n                    else:\n                        diff = trial_vector - self.mean\n                        self.mean = (1 - self.lr_cma) * self.mean + self.lr_cma * trial_vector\n                        self.C = (1 - self.lr_cma) * self.C + self.lr_cma * (np.outer(diff / self.sigma, diff / self.sigma) - self.C)\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n            \n            # Adaptive DE Rate Adjustment\n            if total_iterations > 0:\n                self.de_success_rate = de_successes / total_iterations\n                self.cma_success_rate = cma_successes / total_iterations\n\n                if self.de_success_rate > self.success_threshold:\n                    self.de_rate = min(1.0, self.de_rate + 0.1)\n                else:\n                    self.de_rate = max(0.0, self.de_rate - 0.1)\n                \n                de_successes = 0\n                cma_successes = 0\n                total_iterations = 0\n                    \n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.013201271294120392, "generation": 10}, "task_prompt": ""}
{"id": "30e65db1-8df5-4e70-afc9-09b343e44104", "fitness": 0.7317798890975065, "name": "SelfAdaptiveDE", "description": "Self-adaptive Differential Evolution with archive and restart mechanism.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n        self.restart_trigger = 0.1 * budget # Trigger restart if no improvement for this many evaluations\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation parameters\n                F = np.random.normal(self.F, 0.1)\n                CR = np.random.normal(self.CR, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n                                \n                # Use archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                   arc_idx = np.random.randint(len(self.archive))\n                   mutant = a + F * (self.archive[arc_idx] - b)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n\n                if eval_count - self.last_improvement > self.restart_trigger:\n                  # Restart if no improvement\n                  population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                  fitness = np.array([func(x) for x in population])\n                  eval_count += self.pop_size # Adjust eval count\n                  best_index = np.argmin(fitness)\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n                  self.last_improvement = eval_count\n\n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm SelfAdaptiveDE scored 0.732 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2954b2f1-9896-409a-81e7-0cbaa2002d7e"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive Differential Evolution with archive and restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n        self.restart_trigger = 0.1 * budget # Trigger restart if no improvement for this many evaluations\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation parameters\n                F = np.random.normal(self.F, 0.1)\n                CR = np.random.normal(self.CR, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n                                \n                # Use archive\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                   arc_idx = np.random.randint(len(self.archive))\n                   mutant = a + F * (self.archive[arc_idx] - b)\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n\n                if eval_count - self.last_improvement > self.restart_trigger:\n                  # Restart if no improvement\n                  population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                  fitness = np.array([func(x) for x in population])\n                  eval_count += self.pop_size # Adjust eval count\n                  best_index = np.argmin(fitness)\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n                  self.last_improvement = eval_count\n\n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.007727478216799732, "generation": 10, "aucs": [0.3765441243712264, 0.7016609675705696, 0.7168094192294419, 0.887467653893464, 0.7803306100426383, 0.8241969749225942, 0.7033696856109238, 0.718556351012528, 0.7608658194587379, 0.7527807872047754, 0.8716455424632548, 0.9973144848513636, 0.7319044859067902, 0.75464290787325, 0.9186715070081594, 0.8148478097135029, 0.7050435990107036, 0.8613146657536488, 0.23631467970455367, 0.5213157063480008]}, "task_prompt": ""}
{"id": "04a095f7-57e1-47b5-b302-dfde93638a28", "fitness": "-inf", "name": "PSODE", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) with differential evolution (DE), using a dynamically adjusted inertia weight and crossover probability to balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0, cr_init=0.1, cr_final=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_final = cr_final\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def _initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim)) #Initialize velocities reasonably\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def __call__(self, func):\n        self._initialize(func)\n        eval_count = self.pop_size #Account for initial evaluation\n        \n        while eval_count < self.budget:\n            #Dynamic parameter adjustment\n            w = self.w_init - (self.w_init - self.w_final) * (eval_count / self.budget)\n            cr = self.cr_init + (self.cr_final - self.cr_init) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.particles[i])\n\n                #DE/mutation\n                donor_vector = self.particles[i].copy()\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.particles[idxs]\n\n                donor_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > cr and j != j_rand:\n                        donor_vector[j] = self.particles[i][j]\n                \n                # Clip to bounds\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                donor_vector = np.clip(donor_vector, lb, ub)\n\n\n                f = func(donor_vector)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n                if f < self.fitness[i]:\n                    self.particles[i] = donor_vector\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = donor_vector\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = donor_vector.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 10, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) with differential evolution (DE), using a dynamically adjusted inertia weight and crossover probability to balance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass PSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0, cr_init=0.1, cr_final=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_final = cr_final\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n    def _initialize(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim)) #Initialize velocities reasonably\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def __call__(self, func):\n        self._initialize(func)\n        eval_count = self.pop_size #Account for initial evaluation\n        \n        while eval_count < self.budget:\n            #Dynamic parameter adjustment\n            w = self.w_init - (self.w_init - self.w_final) * (eval_count / self.budget)\n            cr = self.cr_init + (self.cr_final - self.cr_init) * (eval_count / self.budget)\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.particles[i])\n\n                #DE/mutation\n                donor_vector = self.particles[i].copy()\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.particles[idxs]\n\n                donor_vector = x_r1 + 0.5 * (x_r2 - x_r3)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > cr and j != j_rand:\n                        donor_vector[j] = self.particles[i][j]\n                \n                # Clip to bounds\n                lb = func.bounds.lb\n                ub = func.bounds.ub\n                donor_vector = np.clip(donor_vector, lb, ub)\n\n\n                f = func(donor_vector)\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n                if f < self.fitness[i]:\n                    self.particles[i] = donor_vector\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = donor_vector\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = donor_vector.copy()\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.051537513359011564, "generation": 10}, "task_prompt": ""}
{"id": "592ed623-9351-4e13-95ab-de0731e3a247", "fitness": "-inf", "name": "AdaptiveDE_NelderMead", "description": "A hybrid algorithm that combines the exploration capabilities of Differential Evolution (DE) with the local search proficiency of Nelder-Mead Simplex, adaptively switching between them based on stagnation detection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NelderMead:\n    def __init__(self, budget=10000, dim=10, F=0.5, CR=0.7, popsize=20, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.popsize = popsize\n        self.stagnation_threshold = stagnation_threshold\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.use_de = True\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n\n    def de_step(self, func):\n        for i in range(self.popsize):\n            # Mutation\n            idxs = [idx for idx in range(self.popsize) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            crossover = np.random.rand(self.dim) < self.CR\n            trial = np.where(crossover, mutant, self.population[i])\n\n            # Selection\n            f = func(trial)\n            self.eval_count += 1\n            if f < self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = f\n\n    def nelder_mead_step(self, func, x_opt):\n        bounds = func.bounds\n        res = minimize(func, x_opt, method='Nelder-Mead', bounds=[(bounds.lb[i], bounds.ub[i]) for i in range(self.dim)], options={'maxfev': min(self.budget - self.eval_count, 500)}) # limit f evaluations\n        self.eval_count += res.nfev\n        if res.fun < np.min(self.fitness):\n            best_idx = np.argmin(self.fitness)\n            self.fitness[best_idx] = res.fun\n            self.population[best_idx] = res.x\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.use_de = True\n        \n\n        self.initialize_population(func)\n        best_fitness_history = []\n        \n        while self.eval_count < self.budget:\n            if self.use_de:\n                self.de_step(func)\n            else:\n                best_idx = np.argmin(self.fitness)\n                self.nelder_mead_step(func, self.population[best_idx])\n            \n            best_fitness = np.min(self.fitness)\n            if best_fitness < self.f_opt:\n                self.f_opt = best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            best_fitness_history.append(best_fitness)\n            \n            # Adaptive Switching\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.use_de = not self.use_de\n                self.stagnation_counter = 0 # reset stagnation counter\n                # Optionally perturb the population upon switching *to* DE\n                if self.use_de:\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "", "error": "Validation failed: Forbidden import: 'scipy.optimize' is not available in the evaluation environment", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A hybrid algorithm that combines the exploration capabilities of Differential Evolution (DE) with the local search proficiency of Nelder-Mead Simplex, adaptively switching between them based on stagnation detection.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDE_NelderMead:\n    def __init__(self, budget=10000, dim=10, F=0.5, CR=0.7, popsize=20, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.F = F\n        self.CR = CR\n        self.popsize = popsize\n        self.stagnation_threshold = stagnation_threshold\n        self.population = None\n        self.fitness = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.use_de = True\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.popsize\n\n    def de_step(self, func):\n        for i in range(self.popsize):\n            # Mutation\n            idxs = [idx for idx in range(self.popsize) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            crossover = np.random.rand(self.dim) < self.CR\n            trial = np.where(crossover, mutant, self.population[i])\n\n            # Selection\n            f = func(trial)\n            self.eval_count += 1\n            if f < self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = f\n\n    def nelder_mead_step(self, func, x_opt):\n        bounds = func.bounds\n        res = minimize(func, x_opt, method='Nelder-Mead', bounds=[(bounds.lb[i], bounds.ub[i]) for i in range(self.dim)], options={'maxfev': min(self.budget - self.eval_count, 500)}) # limit f evaluations\n        self.eval_count += res.nfev\n        if res.fun < np.min(self.fitness):\n            best_idx = np.argmin(self.fitness)\n            self.fitness[best_idx] = res.fun\n            self.population[best_idx] = res.x\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.stagnation_counter = 0\n        self.use_de = True\n        \n\n        self.initialize_population(func)\n        best_fitness_history = []\n        \n        while self.eval_count < self.budget:\n            if self.use_de:\n                self.de_step(func)\n            else:\n                best_idx = np.argmin(self.fitness)\n                self.nelder_mead_step(func, self.population[best_idx])\n            \n            best_fitness = np.min(self.fitness)\n            if best_fitness < self.f_opt:\n                self.f_opt = best_fitness\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            best_fitness_history.append(best_fitness)\n            \n            # Adaptive Switching\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.use_de = not self.use_de\n                self.stagnation_counter = 0 # reset stagnation counter\n                # Optionally perturb the population upon switching *to* DE\n                if self.use_de:\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.popsize, self.dim))\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "091ae6ba-7391-42c3-a1e4-e1c50d7a6e05", "fitness": 0.6046492212199167, "name": "SelfAdaptiveDE", "description": "Self-Adaptive Differential Evolution with simplified parameter adaptation and archive handling for improved exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_rate=0.1, F_mu=0.5, CR_mu=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = int(pop_size * archive_rate)  # Archive size as a fraction of pop_size\n        self.F_mu = F_mu\n        self.CR_mu = CR_mu\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.sf_list = []\n        self.scr_list = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation (simplified)\n                F = np.clip(np.random.normal(self.F_mu, 0.1), 0.0, 1.0)\n                CR = np.clip(np.random.normal(self.CR_mu, 0.1), 0.0, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    self.sf_list.append(F)\n                    self.scr_list.append(CR)\n\n                    # Archive update (simplified - probabilistic replacement)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    elif np.random.rand() < 0.1:  # 10% chance of replacing a random archive member\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Update adaptation parameters (if enough successful updates)\n            if len(self.sf_list) > 10:\n                self.F_mu = np.mean(self.sf_list)\n                self.CR_mu = np.mean(self.scr_list)\n                self.sf_list = []  # Reset lists after update\n                self.scr_list = []\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm SelfAdaptiveDE scored 0.605 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["d2197210-50e0-46cd-96ad-ccf4f3c0ccf7"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-Adaptive Differential Evolution with simplified parameter adaptation and archive handling for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, archive_rate=0.1, F_mu=0.5, CR_mu=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = int(pop_size * archive_rate)  # Archive size as a fraction of pop_size\n        self.F_mu = F_mu\n        self.CR_mu = CR_mu\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.sf_list = []\n        self.scr_list = []\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation (simplified)\n                F = np.clip(np.random.normal(self.F_mu, 0.1), 0.0, 1.0)\n                CR = np.clip(np.random.normal(self.CR_mu, 0.1), 0.0, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    self.sf_list.append(F)\n                    self.scr_list.append(CR)\n\n                    # Archive update (simplified - probabilistic replacement)\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    elif np.random.rand() < 0.1:  # 10% chance of replacing a random archive member\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Update adaptation parameters (if enough successful updates)\n            if len(self.sf_list) > 10:\n                self.F_mu = np.mean(self.sf_list)\n                self.CR_mu = np.mean(self.scr_list)\n                self.sf_list = []  # Reset lists after update\n                self.scr_list = []\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.01890579664652018, "generation": 11, "aucs": [0.3368195710180558, 0.38425531113047495, 0.4575298089058476, 0.8771031277873671, 0.5094358519563353, 0.7617712946205235, 0.41847478687619166, 0.47535886290755025, 0.64373161392586, 0.4626435308953464, 0.8611509978325602, 0.9981036843373561, 0.6063848147212944, 0.4618107724454822, 0.7923780845903337, 0.7972220048956129, 0.5725879058052772, 0.8612637693805296, 0.2867077850938361, 0.5282508452725005]}, "task_prompt": ""}
{"id": "92e9d80a-95ec-43f6-b853-91671b7d2575", "fitness": 0.3935080301435659, "name": "AdaptiveLocalSearchDE", "description": "A population-based algorithm with adaptive mutation and crossover, inspired by differential evolution, but with a local search component that is triggered probabilistically based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveLocalSearchDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, crossover_rate=0.7, mutation_factor=0.5, local_search_rate=0.1, local_search_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = mutation_factor\n        self.local_search_rate = local_search_rate\n        self.local_search_step = local_search_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                # Local Search (triggered probabilistically)\n                if np.random.rand() < self.local_search_rate:\n                    # Perform a small random step in each dimension\n                    x_trial_local = x_trial + np.random.uniform(-self.local_search_step, self.local_search_step, size=self.dim)\n                    x_trial_local = np.clip(x_trial_local, func.bounds.lb, func.bounds.ub)\n                else:\n                    x_trial_local = x_trial\n\n\n                # Selection\n                f_trial = func(x_trial_local)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial_local\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial_local\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveLocalSearchDE scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive mutation and crossover, inspired by differential evolution, but with a local search component that is triggered probabilistically based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveLocalSearchDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, crossover_rate=0.7, mutation_factor=0.5, local_search_rate=0.1, local_search_step=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.crossover_rate = crossover_rate\n        self.mutation_factor = mutation_factor\n        self.local_search_rate = local_search_rate\n        self.local_search_step = local_search_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                # Local Search (triggered probabilistically)\n                if np.random.rand() < self.local_search_rate:\n                    # Perform a small random step in each dimension\n                    x_trial_local = x_trial + np.random.uniform(-self.local_search_step, self.local_search_step, size=self.dim)\n                    x_trial_local = np.clip(x_trial_local, func.bounds.lb, func.bounds.ub)\n                else:\n                    x_trial_local = x_trial\n\n\n                # Selection\n                f_trial = func(x_trial_local)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial_local\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial_local\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.007749720545345335, "generation": 11, "aucs": [0.14718448911780002, 0.25737880664568846, 0.3890798139309406, 0.4557796988518287, 0.3024903418118263, 0.43375520115919886, 0.30088159049045293, 0.3267588533650896, 0.29516032294309025, 0.1946997484712677, 0.5163411607980396, 0.9761612643626969, 0.31473859428698947, 0.29909866692328513, 0.7213711997718402, 0.4334218593322108, 0.3260033546322596, 0.498080540731476, 0.1997603698344712, 0.48201472541086554]}, "task_prompt": ""}
{"id": "de30531c-1aa9-4468-b9ab-99e350568bd7", "fitness": 0.629790887127913, "name": "AdaptiveDE", "description": "Self-adaptive Differential Evolution with simplified parameter adaptation and a dynamic archive, focusing on faster convergence and efficient exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.F = 0.5\n        self.CR = 0.9\n        self.best_fitness = np.inf\n        self.best_solution = None\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.best_fitness = fitness[best_index]\n        self.best_solution = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                self.F = np.clip(np.random.normal(self.F, 0.05), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + self.F * (b - c)\n\n                # Archive usage\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = a + self.F * (self.archive[arc_idx] - b)\n\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update (dynamic size)\n                    if len(self.archive) < min(self.archive_size, eval_count // (self.pop_size * 2)): # Dynamic archive size\n\n                        self.archive.append(population[i].copy())\n                    elif len(self.archive) > 0: #Only replace if there is something in archive\n                        idx_to_replace = np.random.randint(len(self.archive))\n                        self.archive[idx_to_replace] = population[i].copy()\n\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = trial_vector\n\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDE scored 0.630 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["30e65db1-8df5-4e70-afc9-09b343e44104"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive Differential Evolution with simplified parameter adaptation and a dynamic archive, focusing on faster convergence and efficient exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n        self.F = 0.5\n        self.CR = 0.9\n        self.best_fitness = np.inf\n        self.best_solution = None\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.best_fitness = fitness[best_index]\n        self.best_solution = population[best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive F and CR\n                self.F = np.clip(np.random.normal(self.F, 0.05), 0.1, 1.0)\n                self.CR = np.clip(np.random.normal(self.CR, 0.05), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + self.F * (b - c)\n\n                # Archive usage\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = a + self.F * (self.archive[arc_idx] - b)\n\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update (dynamic size)\n                    if len(self.archive) < min(self.archive_size, eval_count // (self.pop_size * 2)): # Dynamic archive size\n\n                        self.archive.append(population[i].copy())\n                    elif len(self.archive) > 0: #Only replace if there is something in archive\n                        idx_to_replace = np.random.randint(len(self.archive))\n                        self.archive[idx_to_replace] = population[i].copy()\n\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_solution = trial_vector\n\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.best_fitness, self.best_solution\n```", "operator": "simplify", "theta_sampled": 0.016871479641880023, "generation": 11, "aucs": [0.2659777311671986, 0.6562877222492329, 0.6505548520458153, 0.837593325559972, 0.665702608961006, 0.7736158146681272, 0.4638350630715612, 0.563179605619764, 0.6570291513816431, 0.616620917560903, 0.8117986688659868, 0.9941058673656589, 0.3924387560820807, 0.602316912715485, 0.8698856805692025, 0.7647575433897378, 0.45861503132114445, 0.8250551627963126, 0.21394054247154026, 0.5125067846958864]}, "task_prompt": ""}
{"id": "1b51e0d0-ab6e-4cf9-9277-5a089dc119dd", "fitness": 0.0, "name": "SelfAdaptiveDE", "description": "Self-Adaptive Differential Evolution with simplified parameter adaptation and focused archive utilization.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial value of F\n        self.CR = 0.9 # Initial value of CR\n        self.restart_trigger = 0.2 * budget\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation (simplified)\n                F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n\n                # Archive utilization (focused on best archive member)\n                if len(self.archive) > 0:\n                    best_archive_idx = np.argmin([func(x) for x in self.archive])  # Find best archive member\n                    mutant = a + F * (self.archive[best_archive_idx] - b)  # Use best archive member\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        #Replace worst archive element\n                        worst_archive_idx = np.argmax([func(x) for x in self.archive])\n                        self.archive[worst_archive_idx] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n                        self.F = 0.5 * self.F + 0.5 * F  # Adjust F towards successful values\n                        self.CR = 0.5 * self.CR + 0.5 * CR # Adjust CR towards successful values\n\n                # Restart strategy\n                if eval_count - self.last_improvement > self.restart_trigger:\n                    population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    eval_count += self.pop_size\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.last_improvement = eval_count\n\n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm SelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["30e65db1-8df5-4e70-afc9-09b343e44104"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-Adaptive Differential Evolution with simplified parameter adaptation and focused archive utilization.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.archive = []\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial value of F\n        self.CR = 0.9 # Initial value of CR\n        self.restart_trigger = 0.2 * budget\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation (simplified)\n                F = np.clip(np.random.normal(self.F, 0.1), 0.1, 1.0)\n                CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n\n                # Archive utilization (focused on best archive member)\n                if len(self.archive) > 0:\n                    best_archive_idx = np.argmin([func(x) for x in self.archive])  # Find best archive member\n                    mutant = a + F * (self.archive[best_archive_idx] - b)  # Use best archive member\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        #Replace worst archive element\n                        worst_archive_idx = np.argmax([func(x) for x in self.archive])\n                        self.archive[worst_archive_idx] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n                        self.F = 0.5 * self.F + 0.5 * F  # Adjust F towards successful values\n                        self.CR = 0.5 * self.CR + 0.5 * CR # Adjust CR towards successful values\n\n                # Restart strategy\n                if eval_count - self.last_improvement > self.restart_trigger:\n                    population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    eval_count += self.pop_size\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.last_improvement = eval_count\n\n                if eval_count >= self.budget:\n                    break\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.025737224348306012, "generation": 11, "aucs": [0]}, "task_prompt": ""}
{"id": "f4c7a2a8-3ea3-4cfc-9d76-c690d648d824", "fitness": 0.23722078309518807, "name": "AdaptivePopulationDE", "description": "An adaptive Differential Evolution algorithm with a population size that adapts based on the success rate of generating better solutions.", "code": "import numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_rate = 0.05  # Initial success rate, used to adapt population size\n        self.pop_size_min = 10  # Minimum population size\n        self.pop_size_max = 200  # Maximum population size\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            \n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n            \n            # Adapt Population Size\n            if self.pop_size < self.pop_size_max:\n                current_success_rate = successful_mutations / self.pop_size\n                if current_success_rate > self.success_rate:\n                    self.pop_size = min(self.pop_size + 1, self.pop_size_max)\n                    self.population = np.vstack((self.population, np.random.uniform(self.lb, self.ub, size=(1, self.dim))))\n                    self.fitness = np.append(self.fitness, func(self.population[-1]))\n                    self.evals += 1\n                    \n                elif current_success_rate < self.success_rate and self.pop_size > self.pop_size_min:\n                   self.pop_size = max(self.pop_size - 1, self.pop_size_min)\n                   self.population = self.population[:-1]\n                   self.fitness = self.fitness[:-1]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptivePopulationDE scored 0.237 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution algorithm with a population size that adapts based on the success rate of generating better solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_rate = 0.05  # Initial success rate, used to adapt population size\n        self.pop_size_min = 10  # Minimum population size\n        self.pop_size_max = 200  # Maximum population size\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            \n            successful_mutations = 0\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    successful_mutations += 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n            \n            # Adapt Population Size\n            if self.pop_size < self.pop_size_max:\n                current_success_rate = successful_mutations / self.pop_size\n                if current_success_rate > self.success_rate:\n                    self.pop_size = min(self.pop_size + 1, self.pop_size_max)\n                    self.population = np.vstack((self.population, np.random.uniform(self.lb, self.ub, size=(1, self.dim))))\n                    self.fitness = np.append(self.fitness, func(self.population[-1]))\n                    self.evals += 1\n                    \n                elif current_success_rate < self.success_rate and self.pop_size > self.pop_size_min:\n                   self.pop_size = max(self.pop_size - 1, self.pop_size_min)\n                   self.population = self.population[:-1]\n                   self.fitness = self.fitness[:-1]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.02451457851257335, "generation": 11, "aucs": [0.1469816041493648, 0.209194884854897, 0.3406768076027371, 0.3197024682025238, 0.2601486490110172, 0.2959241108815944, 0.27471054254781524, 0.28764798060674324, 0]}, "task_prompt": ""}
{"id": "4b5090ee-966d-49d9-93b7-be7d71244e00", "fitness": 0.5838069441280607, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "An adaptive differential evolution algorithm that adjusts its mutation and crossover rates based on the success of previous generations. It also incorporates a local search operator to refine promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                if f < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adaptive F and CR based on success\n            successful_indices = np.where(fitness < new_fitness)[0]\n            if len(successful_indices) > 0:\n                delta_f = fitness[successful_indices] - new_fitness[successful_indices]\n                self.F = np.mean(delta_f / np.abs(fitness[successful_indices]))\n                self.CR = np.mean(np.random.rand(len(successful_indices)))  # Example: adjusting based on uniform distribution\n\n            # Local Search - refine the best solution so far\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                \n                # Perturb the current best solution\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                local_f = func(local_x)\n                self.budget -= 1  # Update budget\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDifferentialEvolutionLocalSearch scored 0.584 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that adjusts its mutation and crossover rates based on the success of previous generations. It also incorporates a local search operator to refine promising solutions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                    break\n\n                if f < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adaptive F and CR based on success\n            successful_indices = np.where(fitness < new_fitness)[0]\n            if len(successful_indices) > 0:\n                delta_f = fitness[successful_indices] - new_fitness[successful_indices]\n                self.F = np.mean(delta_f / np.abs(fitness[successful_indices]))\n                self.CR = np.mean(np.random.rand(len(successful_indices)))  # Example: adjusting based on uniform distribution\n\n            # Local Search - refine the best solution so far\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                \n                # Perturb the current best solution\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                local_x = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n\n                local_f = func(local_x)\n                self.budget -= 1  # Update budget\n\n                if local_f < self.f_opt:\n                    self.f_opt = local_f\n                    self.x_opt = local_x\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.010371355175125628, "generation": 11, "aucs": [0.22426036872683242, 0.31806997413246996, 0.577228984139649, 0.811024825702623, 0.6311480695756283, 0.6975793192390698, 0.5081280441495666, 0.5194845898291327, 0.6295576670495837, 0.4849036309478495, 0.7842537154567326, 0.993035258302938, 0.32273309687960317, 0.5847350431897304, 0.8785468749404971, 0.693177680345231, 0.4638252627949916, 0.7764867571737467, 0.24999907268547827, 0.5279606472998606]}, "task_prompt": ""}
{"id": "d59877a6-0a76-4ac1-974b-90a061a10f5b", "fitness": 0.5815307668445475, "name": "HybridDECMAS", "description": "Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES), prioritizing CMA-ES updates based on successful DE trials to enhance exploration around promising regions. Simplified CMA-ES update.", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n                    \n                    if f_trial < self.fitness[i]:\n                        diff = trial_vector - self.population[i]\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n\n                        # Update CMA-ES parameters based on DE success\n                        self.mean = (1 - self.lr_cma) * self.mean + self.lr_cma * trial_vector  # Adjusted mean update\n                        self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff, diff) / (np.linalg.norm(diff)**2 + 1e-8)  # Simplified covariance update\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                else:\n                    # CMA-ES exploration around the current mean\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDECMAS scored 0.582 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES), prioritizing CMA-ES updates based on successful DE trials to enhance exploration around promising regions. Simplified CMA-ES update.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n                    \n                    if f_trial < self.fitness[i]:\n                        diff = trial_vector - self.population[i]\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n\n                        # Update CMA-ES parameters based on DE success\n                        self.mean = (1 - self.lr_cma) * self.mean + self.lr_cma * trial_vector  # Adjusted mean update\n                        self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff, diff) / (np.linalg.norm(diff)**2 + 1e-8)  # Simplified covariance update\n\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                else:\n                    # CMA-ES exploration around the current mean\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.027464478717297215, "generation": 11, "aucs": [0.13590284363138705, 0.28697947506419175, 0.7856305756205293, 0.19857712851566278, 0.18601184761101297, 0.8880885693945625, 0.3656449167474498, 0.7566327336529302, 0.822907218080638, 0.21269600200643302, 0.8576715150194874, 0.9929521211753343, 0.6192209849938679, 0.5163064394256376, 0.9352375036825259, 0.8230096680946712, 0.6811173716134867, 0.9004213339711566, 0.15392672773501181, 0.511680360854974]}, "task_prompt": ""}
{"id": "d284f991-2984-470e-8cbc-ddbcbd908d18", "fitness": "-inf", "name": "SelfAdaptiveDE", "description": "Self-adaptive differential evolution with simplified parameter adaptation and a diversity-enhancing archive.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = 0.5\n        self.CR = 0.9\n        self.restart_trigger = 0.1 * budget\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F, 0.1)\n                CR = np.random.normal(self.CR, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n\n                # Use archive to enhance diversity\n                if len(self.archive) > 0 and np.random.rand() < 0.2: # Increased archive usage\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = a + F * (self.archive[arc_idx] - b) # archive difference\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update with replacement strategy\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n\n                    # Parameter adaptation based on success\n                    self.F = 0.9 * self.F + 0.1 * F\n                    self.CR = 0.9 * self.CR + 0.1 * CR\n\n\n                if eval_count - self.last_improvement > self.restart_trigger:\n                    # Restart with best individual preserved\n                    best_individual = population[np.argmin(fitness)].copy()\n                    population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                    population[0] = best_individual # Keep best individual\n                    fitness = np.array([func(x) for x in population])\n                    eval_count += self.pop_size -1 # Adjust eval count\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.last_improvement = eval_count\n\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["30e65db1-8df5-4e70-afc9-09b343e44104"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive differential evolution with simplified parameter adaptation and a diversity-enhancing archive.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n        self.F = 0.5\n        self.CR = 0.9\n        self.restart_trigger = 0.1 * budget\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        self.last_improvement = eval_count\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F, 0.1)\n                CR = np.random.normal(self.CR, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + F * (b - c)\n\n                # Use archive to enhance diversity\n                if len(self.archive) > 0 and np.random.rand() < 0.2: # Increased archive usage\n                    arc_idx = np.random.randint(len(self.archive))\n                    mutant = a + F * (self.archive[arc_idx] - b) # archive difference\n\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_mask, mutant, population[i])\n\n                # Evaluation\n                f = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f < fitness[i]:\n                    # Archive update with replacement strategy\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = population[i].copy()\n\n                    fitness[i] = f\n                    population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                        self.last_improvement = eval_count\n\n                    # Parameter adaptation based on success\n                    self.F = 0.9 * self.F + 0.1 * F\n                    self.CR = 0.9 * self.CR + 0.1 * CR\n\n\n                if eval_count - self.last_improvement > self.restart_trigger:\n                    # Restart with best individual preserved\n                    best_individual = population[np.argmin(fitness)].copy()\n                    population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n                    population[0] = best_individual # Keep best individual\n                    fitness = np.array([func(x) for x in population])\n                    eval_count += self.pop_size -1 # Adjust eval count\n                    best_index = np.argmin(fitness)\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.last_improvement = eval_count\n\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.01284276270307148, "generation": 11}, "task_prompt": ""}
{"id": "6ded7073-c9f4-414b-837e-709291dda6d2", "fitness": 0.3481078214351235, "name": "AdaptiveLandscapeWalker", "description": "A population-based algorithm with adaptive step size and direction based on fitness landscape information.", "code": "import numpy as np\n\nclass AdaptiveLandscapeWalker:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx]\n\n    def adapt_step_size(self):\n        # Simple adaptation based on success rate\n        success_rate = np.sum(self.fitness[1:] < self.fitness[:-1]) / (self.pop_size - 1)\n        if success_rate > 0.3:\n            self.step_size *= 1.1\n        elif success_rate < 0.2:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 0.001, 1.0) # Bounds for step size\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Select parents based on fitness (e.g., tournament selection)\n            indices = np.arange(self.pop_size)\n            np.random.shuffle(indices)\n            parents = indices[:self.pop_size // 2] # Select top half as parents.\n            \n            for i in range(self.pop_size):\n                # Sample direction randomly with step size.\n                direction = np.random.normal(0, 1, self.dim)\n                direction /= np.linalg.norm(direction)\n                \n                # Create offspring\n                new_x = self.population[parents[i % len(parents)]] + self.step_size * direction\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Ensure within bounds\n                \n                new_f = func(new_x)\n                self.eval_count += 1\n                \n                if new_f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                        \n                if self.eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveLandscapeWalker scored 0.348 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive step size and direction based on fitness landscape information.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveLandscapeWalker:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.population[best_idx]\n\n    def adapt_step_size(self):\n        # Simple adaptation based on success rate\n        success_rate = np.sum(self.fitness[1:] < self.fitness[:-1]) / (self.pop_size - 1)\n        if success_rate > 0.3:\n            self.step_size *= 1.1\n        elif success_rate < 0.2:\n            self.step_size *= 0.9\n        self.step_size = np.clip(self.step_size, 0.001, 1.0) # Bounds for step size\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            # Select parents based on fitness (e.g., tournament selection)\n            indices = np.arange(self.pop_size)\n            np.random.shuffle(indices)\n            parents = indices[:self.pop_size // 2] # Select top half as parents.\n            \n            for i in range(self.pop_size):\n                # Sample direction randomly with step size.\n                direction = np.random.normal(0, 1, self.dim)\n                direction /= np.linalg.norm(direction)\n                \n                # Create offspring\n                new_x = self.population[parents[i % len(parents)]] + self.step_size * direction\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Ensure within bounds\n                \n                new_f = func(new_x)\n                self.eval_count += 1\n                \n                if new_f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                        \n                if self.eval_count >= self.budget:\n                    break\n\n            self.adapt_step_size()\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.021894004306253646, "generation": 12, "aucs": [0.16362206643139066, 0.21084800310474916, 0.352061893984875, 0.3541723875929432, 0.2649004474645271, 0.31473057736796584, 0.285735332657178, 0.2942551916849775, 0.27581831917031663, 0.15273215533418028, 0.3504914616980369, 0.980787844962128, 0.252190764589574, 0.27868049949420215, 0.725791112299234, 0.35371493860755365, 0.30023032853390386, 0.3871209699494891, 0.16566604494744552, 0.4986060888277978]}, "task_prompt": ""}
{"id": "e634f981-cfd5-4a4b-b9c6-6cf12c9ad15f", "fitness": 0.4909896637678573, "name": "AdaptiveDE_CMAES", "description": "Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES), adaptively switching between them based on a success rate of DE updates, and using a simplified CMA-ES update.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate_init=0.5, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma  # Learning rate for CMA-ES update\n        self.de_rate = de_rate_init  # Initial probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.success_rate = 0.0  # Track success rate of DE\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        success_count = 0\n        total_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        success_count += 1\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n\n                    total_count += 1\n\n                else:\n                    # CMA-ES: Simplified version\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    \n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        self.mean = trial_vector # Move the mean towards the best solution\n\n                if self.budget <= 0:\n                    break\n            \n            # Update DE rate based on success\n            if total_count > 0:\n                self.success_rate = success_count / total_count\n                self.de_rate = 0.1 + 0.8 * self.success_rate # Adjust DE rate. Ensure it is never 0.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDE_CMAES scored 0.491 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES), adaptively switching between them based on a success rate of DE updates, and using a simplified CMA-ES update.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate_init=0.5, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma  # Learning rate for CMA-ES update\n        self.de_rate = de_rate_init  # Initial probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.success_rate = 0.0  # Track success rate of DE\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        success_count = 0\n        total_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.fitness[i]:\n                        success_count += 1\n                        self.fitness[i] = f_trial\n                        self.population[i] = trial_vector\n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n\n                    total_count += 1\n\n                else:\n                    # CMA-ES: Simplified version\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    \n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n                        self.mean = trial_vector # Move the mean towards the best solution\n\n                if self.budget <= 0:\n                    break\n            \n            # Update DE rate based on success\n            if total_count > 0:\n                self.success_rate = success_count / total_count\n                self.de_rate = 0.1 + 0.8 * self.success_rate # Adjust DE rate. Ensure it is never 0.\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.024093299741876597, "generation": 12, "aucs": [0.13216052656379274, 0.35088873512220975, 0.6053227938717296, 0.7183641832064689, 0.3859287543198455, 0.7529181174857982, 0.31607595985267056, 0.4174743152623184, 0.25729055252335575, 0.2000295598489884, 0.722776017490075, 0.9636017434985941, 0.3609714110506276, 0.3063933152395395, 0.8612874459918115, 0.6333313732368423, 0.352931327381648, 0.8022668391876371, 0.196412373784411, 0.48336793043878223]}, "task_prompt": ""}
{"id": "385890ab-b7ff-4479-84ca-68fbc512c80f", "fitness": "-inf", "name": "CauchyAdaptation", "description": "Population-based algorithm with a Cauchy mutation operator and adaptive population size based on success rate.", "code": "import numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.archive_size = 10  # Size of the archive for storing successful solutions\n        self.archive = []\n        self.archive_fitness = []\n        self.success_rate_threshold = 0.1 #threshold for population size adaptation\n        self.success_history = []\n        self.success_history_length = 10 # number of iterations to remember success rate\n\n    def sample_cauchy(self, loc, scale, size):\n          return loc + scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history = []\n\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Sort population by fitness\n        sorted_indices = np.argsort(fitness)\n        population = population[sorted_indices]\n        fitness = fitness[sorted_indices]\n\n        self.f_opt = fitness[0]\n        self.x_opt = population[0]\n        step_size = self.initial_step_size\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                mutated_individual = self.sample_cauchy(population[i], step_size, self.dim)\n\n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the mutated individual\n                new_fitness_i = func(mutated_individual)\n                self.budget -= 1\n                if new_fitness_i < self.f_opt:\n                    self.f_opt = new_fitness_i\n                    self.x_opt = mutated_individual\n\n                new_population[i] = mutated_individual\n                new_fitness[i] = new_fitness_i\n\n            # Selection: Replace parents with better offspring\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(new_population[i])\n                        self.archive_fitness.append(new_fitness[i])\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if new_fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = new_population[i]\n                            self.archive_fitness[max_archive_index] = new_fitness[i]\n\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            self.f_opt = min(self.f_opt, fitness[0])\n            self.x_opt = population[0]\n\n            # Adapt step size (simple adaptation)\n            if np.mean(new_fitness < fitness) > 0.2:\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Adapt population size based on success rate\n            success_rate = np.mean(new_fitness < fitness)\n            self.success_history.append(success_rate)\n            if len(self.success_history) > self.success_history_length:\n                  self.success_history.pop(0)\n            \n            avg_success_rate = np.mean(self.success_history) if self.success_history else 0\n\n            if avg_success_rate > self.success_rate_threshold and self.pop_size < 2 * self.dim :\n                self.pop_size = min(2*self.dim, int(self.pop_size * 1.1))\n                population = np.vstack((population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(population), self.dim))))\n                new_fitness = np.array([func(x) for x in population[self.pop_size - len(population):]])\n                self.budget -= len(new_fitness)\n                fitness = np.concatenate((fitness, new_fitness))\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices]\n                fitness = fitness[sorted_indices]\n            elif avg_success_rate < self.success_rate_threshold / 2 and self.pop_size > 4:\n                 self.pop_size = max(4, int(self.pop_size * 0.9))\n                 population = population[:self.pop_size]\n                 fitness = fitness[:self.pop_size]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "In the code, line 109, in __call__, the following error occurred:\nIndexError: index 6 is out of bounds for axis 0 with size 6\nOn line: population = population[sorted_indices]", "error": "In the code, line 109, in __call__, the following error occurred:\nIndexError: index 6 is out of bounds for axis 0 with size 6\nOn line: population = population[sorted_indices]", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a Cauchy mutation operator and adaptive population size based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.archive_size = 10  # Size of the archive for storing successful solutions\n        self.archive = []\n        self.archive_fitness = []\n        self.success_rate_threshold = 0.1 #threshold for population size adaptation\n        self.success_history = []\n        self.success_history_length = 10 # number of iterations to remember success rate\n\n    def sample_cauchy(self, loc, scale, size):\n          return loc + scale * np.random.standard_cauchy(size=size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.archive_fitness = []\n        self.success_history = []\n\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Sort population by fitness\n        sorted_indices = np.argsort(fitness)\n        population = population[sorted_indices]\n        fitness = fitness[sorted_indices]\n\n        self.f_opt = fitness[0]\n        self.x_opt = population[0]\n        step_size = self.initial_step_size\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                mutated_individual = self.sample_cauchy(population[i], step_size, self.dim)\n\n                # Clip to bounds\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the mutated individual\n                new_fitness_i = func(mutated_individual)\n                self.budget -= 1\n                if new_fitness_i < self.f_opt:\n                    self.f_opt = new_fitness_i\n                    self.x_opt = mutated_individual\n\n                new_population[i] = mutated_individual\n                new_fitness[i] = new_fitness_i\n\n            # Selection: Replace parents with better offspring\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_population[i]\n                    fitness[i] = new_fitness[i]\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(new_population[i])\n                        self.archive_fitness.append(new_fitness[i])\n                    else:\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if new_fitness[i] < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = new_population[i]\n                            self.archive_fitness[max_archive_index] = new_fitness[i]\n\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            self.f_opt = min(self.f_opt, fitness[0])\n            self.x_opt = population[0]\n\n            # Adapt step size (simple adaptation)\n            if np.mean(new_fitness < fitness) > 0.2:\n                step_size *= 1.1\n            else:\n                step_size *= 0.9\n\n            # Adapt population size based on success rate\n            success_rate = np.mean(new_fitness < fitness)\n            self.success_history.append(success_rate)\n            if len(self.success_history) > self.success_history_length:\n                  self.success_history.pop(0)\n            \n            avg_success_rate = np.mean(self.success_history) if self.success_history else 0\n\n            if avg_success_rate > self.success_rate_threshold and self.pop_size < 2 * self.dim :\n                self.pop_size = min(2*self.dim, int(self.pop_size * 1.1))\n                population = np.vstack((population, np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(population), self.dim))))\n                new_fitness = np.array([func(x) for x in population[self.pop_size - len(population):]])\n                self.budget -= len(new_fitness)\n                fitness = np.concatenate((fitness, new_fitness))\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices]\n                fitness = fitness[sorted_indices]\n            elif avg_success_rate < self.success_rate_threshold / 2 and self.pop_size > 4:\n                 self.pop_size = max(4, int(self.pop_size * 0.9))\n                 population = population[:self.pop_size]\n                 fitness = fitness[:self.pop_size]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.012721924355177744, "generation": 12}, "task_prompt": ""}
{"id": "a885dfe5-0072-46e4-827a-d6e1115e06eb", "fitness": "-inf", "name": "HybridDE", "description": "A simplified hybrid DE/CMA-ES using a fixed covariance matrix, adaptive population size and simplified update rules.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is None else 4 + int(3 * np.log(dim))\n        self.de_rate = de_rate\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim) # Fixed covariance matrix\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES-like mutation with fixed covariance\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    #Simplified mean adaptation\n                    self.mean = 0.9*self.mean + 0.1*trial_vector # Moving average\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "In the code, line 654, in numpy.random._common.cont, the following error occurred:\nTypeError: 'NoneType' object cannot be interpreted as an integer", "error": "In the code, line 654, in numpy.random._common.cont, the following error occurred:\nTypeError: 'NoneType' object cannot be interpreted as an integer", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified hybrid DE/CMA-ES using a fixed covariance matrix, adaptive population size and simplified update rules.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_rate=0.7, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is None else 4 + int(3 * np.log(dim))\n        self.de_rate = de_rate\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim) # Fixed covariance matrix\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES-like mutation with fixed covariance\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    #Simplified mean adaptation\n                    self.mean = 0.9*self.mean + 0.1*trial_vector # Moving average\n\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.006258375659981622, "generation": 12}, "task_prompt": ""}
{"id": "c6568aa1-0be4-42e2-813d-4463249b27f0", "fitness": "-inf", "name": "AdaptiveRestartDE", "description": "An adaptive Differential Evolution (DE) algorithm with a self-adjusting mutation strategy and a restart mechanism to avoid stagnation.", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Adaptive population size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.restart_trigger = restart_trigger # Percentage of budget used before restart check\n        self.archive = [] # Archive for storing promising solutions\n        self.archive_size = 10\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n\n        self.best_fitness_history = [self.f_opt]\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation factor\n                F = self.F * np.random.uniform(0.5, 1.5)\n                F = np.clip(F, 0.1, 1.0)\n                \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.pop[idxs]\n                x_mutated = self.pop[i] + F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n                \n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                        \n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(x_trial)\n                    else:\n                        #Replace a random element in the archive\n                        replace_index = np.random.randint(self.archive_size)\n                        self.archive[replace_index] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Restart mechanism\n            if self.eval_count > self.restart_trigger * self.budget:\n                if len(self.best_fitness_history) > 50: # Only check if enough history exists\n                    recent_history = self.best_fitness_history[-50:]\n                    if np.std(recent_history) < 1e-6:  # Check for stagnation\n                        # Restart from a combination of best solution and archive\n                        \n                        if len(self.archive) > 0:\n                            restart_points = [self.x_opt] + self.archive\n                        else:\n                            restart_points = [self.x_opt] #Only restart from best\n\n                        num_restart_points = len(restart_points)\n                        \n                        new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                        for i in range(self.pop_size):\n                            idx = np.random.randint(num_restart_points)\n                            new_pop[i] = restart_points[idx] + 0.1 * np.random.normal(0, 1, self.dim)\n                            new_pop[i] = np.clip(new_pop[i], self.lb, self.ub)\n\n                        self.pop = new_pop\n                        self.fitness = np.array([func(x) for x in self.pop])\n                        self.eval_count += self.pop_size\n\n                        if np.min(self.fitness) < self.f_opt:\n                            self.f_opt = np.min(self.fitness)\n                            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n                        self.best_fitness_history.append(self.f_opt)\n                        self.restart_trigger += 0.1 # Increase trigger for next restart\n                        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution (DE) algorithm with a self-adjusting mutation strategy and a restart mechanism to avoid stagnation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim  # Adaptive population size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.restart_trigger = restart_trigger # Percentage of budget used before restart check\n        self.archive = [] # Archive for storing promising solutions\n        self.archive_size = 10\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n\n        self.best_fitness_history = [self.f_opt]\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Adaptive mutation factor\n                F = self.F * np.random.uniform(0.5, 1.5)\n                F = np.clip(F, 0.1, 1.0)\n                \n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.pop[idxs]\n                x_mutated = self.pop[i] + F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, self.lb, self.ub)\n                \n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                        \n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(x_trial)\n                    else:\n                        #Replace a random element in the archive\n                        replace_index = np.random.randint(self.archive_size)\n                        self.archive[replace_index] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        \n            self.best_fitness_history.append(self.f_opt)\n            \n            # Restart mechanism\n            if self.eval_count > self.restart_trigger * self.budget:\n                if len(self.best_fitness_history) > 50: # Only check if enough history exists\n                    recent_history = self.best_fitness_history[-50:]\n                    if np.std(recent_history) < 1e-6:  # Check for stagnation\n                        # Restart from a combination of best solution and archive\n                        \n                        if len(self.archive) > 0:\n                            restart_points = [self.x_opt] + self.archive\n                        else:\n                            restart_points = [self.x_opt] #Only restart from best\n\n                        num_restart_points = len(restart_points)\n                        \n                        new_pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                        for i in range(self.pop_size):\n                            idx = np.random.randint(num_restart_points)\n                            new_pop[i] = restart_points[idx] + 0.1 * np.random.normal(0, 1, self.dim)\n                            new_pop[i] = np.clip(new_pop[i], self.lb, self.ub)\n\n                        self.pop = new_pop\n                        self.fitness = np.array([func(x) for x in self.pop])\n                        self.eval_count += self.pop_size\n\n                        if np.min(self.fitness) < self.f_opt:\n                            self.f_opt = np.min(self.fitness)\n                            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n                        self.best_fitness_history.append(self.f_opt)\n                        self.restart_trigger += 0.1 # Increase trigger for next restart\n                        \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.007037031721598518, "generation": 12}, "task_prompt": ""}
{"id": "83fb9a0c-32bc-411c-ba94-c157bd9f33e5", "fitness": 0.6451750359422996, "name": "AdaptiveDE_CMA", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation, dynamically adjusting mutation strength and crossover rate based on success.", "code": "import numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        trial_vector[j] = self.population[i, j]\n                        \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and CR\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                # Adaptive F and CR update\n                if len(self.success_F) > 0:\n                    self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                    self.CR = np.clip(np.mean(self.success_CR), 0.1, 0.9)\n\n                    self.success_F = [] #Clear lists\n                    self.success_CR = []\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDE_CMA scored 0.645 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation, dynamically adjusting mutation strength and crossover rate based on success.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                trial_vector = self.population[i] + self.F * (x_r2 - x_r3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        trial_vector[j] = self.population[i, j]\n                        \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Store successful F and CR\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                # Adaptive F and CR update\n                if len(self.success_F) > 0:\n                    self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                    self.CR = np.clip(np.mean(self.success_CR), 0.1, 0.9)\n\n                    self.success_F = [] #Clear lists\n                    self.success_CR = []\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.015952141960681974, "generation": 12, "aucs": [0.12394436260640962, 0.6298912083421008, 0.8523476343225049, 0.909994450902619, 0.40689088824265673, 0.9021771877481176, 0.330862652311552, 0.8339950007598396, 0.8503686560201644, 0.19831501827281495, 0.9214050499683458, 0.9963174737015201, 0.3755889217230992, 0.5304219798004364, 0.964028336454062, 0.8972220284942605, 0.5456000494316282, 0.941668975095103, 0.20461286542307267, 0.48784797922568446]}, "task_prompt": ""}
{"id": "319f5d81-ce81-4bc7-bcf6-b85f4ebdcfb3", "fitness": "-inf", "name": "AdaptiveDECMAES", "description": "Combines DE/CMA-ES with a self-adaptive F parameter and archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDECMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma  # Learning rate for CMA-ES update\n        self.de_rate = de_rate  # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    mutant = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Use archive\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:\n                       arc_idx = np.random.randint(len(self.archive))\n                       mutant = self.population[i] + F * (self.archive[arc_idx] - x_r2) # Modified to use x_r2, not x_b\n                                            \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(self.population[i]) # Ensure trial_vector is initialized\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            trial_vector[j] = mutant[j] # Apply mutation\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.population[i].copy()\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51", "30e65db1-8df5-4e70-afc9-09b343e44104"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE/CMA-ES with a self-adaptive F parameter and archive for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDECMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F=0.5, CR=0.7, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma  # Learning rate for CMA-ES update\n        self.de_rate = de_rate  # Probability of applying DE\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.archive = []\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive F\n                F = np.random.normal(self.F, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                \n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    mutant = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Use archive\n                    if len(self.archive) > 0 and np.random.rand() < 0.1:\n                       arc_idx = np.random.randint(len(self.archive))\n                       mutant = self.population[i] + F * (self.archive[arc_idx] - x_r2) # Modified to use x_r2, not x_b\n                                            \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    trial_vector = np.copy(self.population[i]) # Ensure trial_vector is initialized\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            trial_vector[j] = mutant[j] # Apply mutation\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Archive update\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(self.archive_size)\n                        self.archive[idx_to_replace] = self.population[i].copy()\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector  # Update mean to the new better vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0029838622205338875, "generation": 12}, "task_prompt": ""}
{"id": "2aabae24-19ae-4504-8022-f890e17b54e0", "fitness": 0.7503512850101066, "name": "AdaptiveDE_CMAES", "description": "Combines DE/CMA-ES with a self-adaptive F parameter for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F_mu=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate\n        self.F_mu = F_mu  # Mean value for F, adaptively updated\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.sf_list = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution with adaptive F\n                    F = np.random.normal(self.F_mu, 0.1)\n                    F = np.clip(F, 0.0, 1.0)\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Bookkeeping for adaptation\n                    if np.random.rand() < 0.1: #probability to add F. Adding all the time is costly.\n                        self.sf_list.append(F)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n            # Update F_mu based on successful F values\n            if len(self.sf_list) > 0:\n                self.F_mu = np.mean(self.sf_list)\n                self.sf_list = []  # Reset for next generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDE_CMAES scored 0.750 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7e534557-4517-4fc8-b7b0-eb13b12b6f51", "d2197210-50e0-46cd-96ad-ccf4f3c0ccf7"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE/CMA-ES with a self-adaptive F parameter for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lr_cma=0.1, de_rate=0.7, F_mu=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lr_cma = lr_cma\n        self.de_rate = de_rate\n        self.F_mu = F_mu  # Mean value for F, adaptively updated\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n\n        self.mean = np.random.uniform(self.lb, self.ub, size=dim)\n        self.sigma = 0.5\n        self.C = np.eye(dim)\n        self.sf_list = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.de_rate:\n                    # Differential Evolution with adaptive F\n                    F = np.random.normal(self.F_mu, 0.1)\n                    F = np.clip(F, 0.0, 1.0)\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[idxs]\n\n                    trial_vector = self.population[i] + F * (x_r2 - x_r3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.CR and j != j_rand:\n                            trial_vector[j] = self.population[i, j]\n                            \n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                else:\n                    # CMA-ES\n                    z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                    trial_vector = self.mean + self.sigma * z\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    # Bookkeeping for adaptation\n                    if np.random.rand() < 0.1: #probability to add F. Adding all the time is costly.\n                        self.sf_list.append(F)\n\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    # Update CMA-ES parameters\n                    diff = trial_vector - self.mean\n                    self.mean = trial_vector\n                    self.C = (1 - self.lr_cma) * self.C + self.lr_cma * np.outer(diff / self.sigma, diff / self.sigma)\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n\n            # Update F_mu based on successful F values\n            if len(self.sf_list) > 0:\n                self.F_mu = np.mean(self.sf_list)\n                self.sf_list = []  # Reset for next generation\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0011336831067206773, "generation": 12, "aucs": [0.4470574962901964, 0.7849261690959679, 0.6960008102279149, 0.9363561786302903, 0.8616393397178493, 0.8937006538648588, 0.708537839846932, 0.8442932496906846, 0.8913171636805013, 0.444063463545169, 0.9299388132186065, 0.9980564757777312, 0.4853641775853994, 0.8372287033165435, 0.9524559967779586, 0.8931416592961361, 0.7688072464550313, 0.9255617387114192, 0.20310755929303115, 0.5054709651799096]}, "task_prompt": ""}
