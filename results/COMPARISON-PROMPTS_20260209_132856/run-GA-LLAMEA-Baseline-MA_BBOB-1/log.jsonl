{"id": "41e8102d-b5ad-48d6-8ec1-5f807c284871", "fitness": 0.0, "name": "OrthogonalDE", "description": "A population-based algorithm that combines exploration using orthogonal sampling with exploitation using a differential evolution-like mutation and selection process, coupled with a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, restart_trigger=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.restart_trigger = restart_trigger # Threshold for function value improvement before restarting\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        last_f_opt = np.inf\n        while self.budget > 0:\n            # Orthogonal Sampling for Exploration\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution for Exploitation\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Restart mechanism\n            if last_f_opt - self.f_opt < self.restart_trigger:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.population[best_index]\n            \n            last_f_opt = self.f_opt\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OrthogonalDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines exploration using orthogonal sampling with exploitation using a differential evolution-like mutation and selection process, coupled with a restart mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, restart_trigger=0.001):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.restart_trigger = restart_trigger # Threshold for function value improvement before restarting\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        last_f_opt = np.inf\n        while self.budget > 0:\n            # Orthogonal Sampling for Exploration\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution for Exploitation\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Restart mechanism\n            if last_f_opt - self.f_opt < self.restart_trigger:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(self.fitness)\n                if self.fitness[best_index] < self.f_opt:\n                    self.f_opt = self.fitness[best_index]\n                    self.x_opt = self.population[best_index]\n            \n            last_f_opt = self.f_opt\n            \n\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0]}, "task_prompt": ""}
{"id": "e222266c-9d76-4f26-af8a-79a035d96e5f", "fitness": "-inf", "name": "AdaptiveDifferentialEvolutionCMA", "description": "Adaptive Differential Evolution with Covariance Matrix Adaptation, dynamically adjusting mutation and crossover rates based on success and using CMA to learn the covariance structure of successful steps.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Increased population size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_step_size = initial_step_size\n        self.C = np.eye(dim) * (self.initial_step_size**2)  # Covariance matrix initialization\n        self.learning_rate_mu = 0.1 # Learning rate for the mean\n        self.learning_rate_C = 0.1   # Learning rate for the covariance matrix\n        self.damps = 1.0  # Dampening factor for covariance matrix update\n        self.mu = None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.mu = np.copy(population[np.argmin(fitness)])  # initial mu\n\n        mutation_factor = 0.5  # Initial mutation factor\n        crossover_rate = 0.7  # Initial crossover rate\n\n        successful_steps = []\n        fitness_history = []\n\n        while self.budget > 0:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Apply CMA-ES based mutation\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                mutant = population[i] + mutation_factor * z\n                \n                # Ensure bounds\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    successful_steps.append(trial_vector - population[i])\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            #Adaptive parameter control\n            fitness_history.append(np.min(fitness))\n            if len(fitness_history) > 5:\n                if fitness_history[-1] > np.mean(fitness_history[-5:]): # if not improving much\n                    mutation_factor = min(1.0, mutation_factor * 1.1)  # Increase mutation\n                    crossover_rate = max(0.1, crossover_rate * 0.9) # Decrease crossover\n                else:\n                    mutation_factor = max(0.1, mutation_factor * 0.9)  # Decrease mutation\n                    crossover_rate = min(0.9, crossover_rate * 1.1) # increase crossover\n\n            # Covariance Matrix Adaptation\n            if len(successful_steps) > 0:\n                successful_steps = np.array(successful_steps)\n                # Update mean\n                self.mu = (1 - self.learning_rate_mu) * self.mu + self.learning_rate_mu * population[np.argmin(fitness)]  # move mean towards best individual\n\n                # Update covariance matrix\n                delta_C = np.zeros_like(self.C)\n\n                for step in successful_steps:\n                    delta_C += np.outer(step, step)\n\n                delta_C /= len(successful_steps)\n\n                self.C = (1 - self.learning_rate_C) * self.C + self.learning_rate_C * delta_C # update covariance matrix\n                \n                # Damp the covariance matrix\n                eigenvalues = np.linalg.eigvalsh(self.C)\n                min_eigenvalue = np.min(eigenvalues)\n                if min_eigenvalue <= 0:\n                    self.C += np.eye(self.dim) * (abs(min_eigenvalue) + 1e-8)  # Prevent non-positive definite matrix\n                \n                successful_steps = []\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Covariance Matrix Adaptation, dynamically adjusting mutation and crossover rates based on success and using CMA to learn the covariance structure of successful steps.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Increased population size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_step_size = initial_step_size\n        self.C = np.eye(dim) * (self.initial_step_size**2)  # Covariance matrix initialization\n        self.learning_rate_mu = 0.1 # Learning rate for the mean\n        self.learning_rate_C = 0.1   # Learning rate for the covariance matrix\n        self.damps = 1.0  # Dampening factor for covariance matrix update\n        self.mu = None\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        self.mu = np.copy(population[np.argmin(fitness)])  # initial mu\n\n        mutation_factor = 0.5  # Initial mutation factor\n        crossover_rate = 0.7  # Initial crossover rate\n\n        successful_steps = []\n        fitness_history = []\n\n        while self.budget > 0:\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n\n                # Apply CMA-ES based mutation\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                mutant = population[i] + mutation_factor * z\n                \n                # Ensure bounds\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    successful_steps.append(trial_vector - population[i])\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n            #Adaptive parameter control\n            fitness_history.append(np.min(fitness))\n            if len(fitness_history) > 5:\n                if fitness_history[-1] > np.mean(fitness_history[-5:]): # if not improving much\n                    mutation_factor = min(1.0, mutation_factor * 1.1)  # Increase mutation\n                    crossover_rate = max(0.1, crossover_rate * 0.9) # Decrease crossover\n                else:\n                    mutation_factor = max(0.1, mutation_factor * 0.9)  # Decrease mutation\n                    crossover_rate = min(0.9, crossover_rate * 1.1) # increase crossover\n\n            # Covariance Matrix Adaptation\n            if len(successful_steps) > 0:\n                successful_steps = np.array(successful_steps)\n                # Update mean\n                self.mu = (1 - self.learning_rate_mu) * self.mu + self.learning_rate_mu * population[np.argmin(fitness)]  # move mean towards best individual\n\n                # Update covariance matrix\n                delta_C = np.zeros_like(self.C)\n\n                for step in successful_steps:\n                    delta_C += np.outer(step, step)\n\n                delta_C /= len(successful_steps)\n\n                self.C = (1 - self.learning_rate_C) * self.C + self.learning_rate_C * delta_C # update covariance matrix\n                \n                # Damp the covariance matrix\n                eigenvalues = np.linalg.eigvalsh(self.C)\n                min_eigenvalue = np.min(eigenvalues)\n                if min_eigenvalue <= 0:\n                    self.C += np.eye(self.dim) * (abs(min_eigenvalue) + 1e-8)  # Prevent non-positive definite matrix\n                \n                successful_steps = []\n                \n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "33d1abee-2262-446b-a10e-0516ec2ad648", "fitness": 0.0, "name": "AdaptiveCoordinateDescent", "description": "Adaptive Coordinate Descent with shrinking search space and momentum.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n            \n        return best_f, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveCoordinateDescent scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Coordinate Descent with shrinking search space and momentum.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n            \n        return best_f, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0]}, "task_prompt": ""}
{"id": "db595387-3861-4520-be29-004ff9807db5", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success of previous generations, incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Restart mechanism\n        if np.random.rand() < self.restart_prob:\n            # Replace a portion of the population with random individuals\n            num_to_replace = int(0.2 * self.pop_size)\n            replace_indices = np.random.choice(self.pop_size, num_to_replace, replace=False)\n            self.pop[replace_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n            self.fitness[replace_indices] = np.array([func(x) for x in self.pop[replace_indices]])\n            self.eval_count += num_to_replace\n            \n            #Update best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm that dynamically adjusts its parameters based on the success of previous generations, incorporating a restart mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Restart mechanism\n        if np.random.rand() < self.restart_prob:\n            # Replace a portion of the population with random individuals\n            num_to_replace = int(0.2 * self.pop_size)\n            replace_indices = np.random.choice(self.pop_size, num_to_replace, replace=False)\n            self.pop[replace_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n            self.fitness[replace_indices] = np.array([func(x) for x in self.pop[replace_indices]])\n            self.eval_count += num_to_replace\n            \n            #Update best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "generation": 0, "operator": "init", "aucs": [0]}, "task_prompt": ""}
{"id": "d146b416-8868-4731-ba14-af5925191c17", "fitness": 0.0, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with self-adaptive parameter control using a success history and a simplified restart mechanism.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_size = success_history_size\n        self.success_F = np.ones(self.success_history_size) * F\n        self.success_Cr = np.ones(self.success_history_size) * Cr\n        self.success_idx = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update success history\n                self.success_F[self.success_idx] = self.F\n                self.success_Cr[self.success_idx] = self.Cr\n                self.success_idx = (self.success_idx + 1) % self.success_history_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive parameter control: Adjust F and Cr based on success history\n        self.F = np.median(self.success_F)\n        self.Cr = np.median(self.success_Cr)\n\n        # Restart mechanism: Simplified - restart only the worst individual\n        if np.random.rand() < self.restart_prob:\n            worst_index = np.argmax(self.fitness)\n            self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            self.fitness[worst_index] = func(self.pop[worst_index])\n            self.eval_count += 1\n            if self.fitness[worst_index] < self.f_opt:\n                self.f_opt = self.fitness[worst_index]\n                self.x_opt = self.pop[worst_index]\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db595387-3861-4520-be29-004ff9807db5"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with self-adaptive parameter control using a success history and a simplified restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_history_size = success_history_size\n        self.success_F = np.ones(self.success_history_size) * F\n        self.success_Cr = np.ones(self.success_history_size) * Cr\n        self.success_idx = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update success history\n                self.success_F[self.success_idx] = self.F\n                self.success_Cr[self.success_idx] = self.Cr\n                self.success_idx = (self.success_idx + 1) % self.success_history_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive parameter control: Adjust F and Cr based on success history\n        self.F = np.median(self.success_F)\n        self.Cr = np.median(self.success_Cr)\n\n        # Restart mechanism: Simplified - restart only the worst individual\n        if np.random.rand() < self.restart_prob:\n            worst_index = np.argmax(self.fitness)\n            self.pop[worst_index] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            self.fitness[worst_index] = func(self.pop[worst_index])\n            self.eval_count += 1\n            if self.fitness[worst_index] < self.f_opt:\n                self.f_opt = self.fitness[worst_index]\n                self.x_opt = self.pop[worst_index]\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0011460664762998306, "generation": 1, "aucs": [0]}, "task_prompt": ""}
{"id": "6eb40160-cd95-4756-bd7d-661d6d69b962", "fitness": "-inf", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with self-adaptive parameters and orthogonal design to sample promising regions.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05, ortho_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.ortho_trials = ortho_trials # Number of orthogonal design trials\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Orthogonal Design Exploration around the best solution\n        best_idx = np.argmin(self.fitness)\n        x_best = self.pop[best_idx]\n        \n        #Generate orthogonal design\n        for _ in range(self.ortho_trials):\n            # Generate a random direction vector\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n        \n            # Generate random step size\n            step_size = np.random.uniform(0.01, 0.1)  # Exploration range\n        \n            x_ortho = x_best + step_size * direction\n            x_ortho = np.clip(x_ortho, func.bounds.lb, func.bounds.ub)\n        \n            f_ortho = func(x_ortho)\n            self.eval_count += 1\n        \n            if f_ortho < self.f_opt:\n                self.f_opt = f_ortho\n                self.x_opt = x_ortho\n                \n        # Restart mechanism\n        if np.random.rand() < self.restart_prob:\n            # Replace a portion of the population with random individuals\n            num_to_replace = int(0.2 * self.pop_size)\n            replace_indices = np.random.choice(self.pop_size, num_to_replace, replace=False)\n            self.pop[replace_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n            self.fitness[replace_indices] = np.array([func(x) for x in self.pop[replace_indices]])\n            self.eval_count += num_to_replace\n            \n            #Update best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["db595387-3861-4520-be29-004ff9807db5"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with self-adaptive parameters and orthogonal design to sample promising regions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_prob=0.05, ortho_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_prob = restart_prob\n        self.ortho_trials = ortho_trials # Number of orthogonal design trials\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Orthogonal Design Exploration around the best solution\n        best_idx = np.argmin(self.fitness)\n        x_best = self.pop[best_idx]\n        \n        #Generate orthogonal design\n        for _ in range(self.ortho_trials):\n            # Generate a random direction vector\n            direction = np.random.randn(self.dim)\n            direction /= np.linalg.norm(direction)  # Normalize\n        \n            # Generate random step size\n            step_size = np.random.uniform(0.01, 0.1)  # Exploration range\n        \n            x_ortho = x_best + step_size * direction\n            x_ortho = np.clip(x_ortho, func.bounds.lb, func.bounds.ub)\n        \n            f_ortho = func(x_ortho)\n            self.eval_count += 1\n        \n            if f_ortho < self.f_opt:\n                self.f_opt = f_ortho\n                self.x_opt = x_ortho\n                \n        # Restart mechanism\n        if np.random.rand() < self.restart_prob:\n            # Replace a portion of the population with random individuals\n            num_to_replace = int(0.2 * self.pop_size)\n            replace_indices = np.random.choice(self.pop_size, num_to_replace, replace=False)\n            self.pop[replace_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_replace, self.dim))\n            self.fitness[replace_indices] = np.array([func(x) for x in self.pop[replace_indices]])\n            self.eval_count += num_to_replace\n            \n            #Update best\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.3204705639774113, "generation": 1}, "task_prompt": ""}
{"id": "71a5e8c2-46aa-404c-8564-ec0198290945", "fitness": "-inf", "name": "HybridPSO", "description": "Population-based algorithm that combines particle swarm optimization with a mutation operator inspired by differential evolution to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                # Clip velocities to prevent explosion\n                velocities[i] = np.clip(velocities[i], self.lb - population[i], self.ub - population[i]) # changed from original limits\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n\n                # Apply mutation (Differential Evolution inspired)\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutated_vector = x1 + 0.5 * (x2 - x3)  # Added a scaling factor for the difference vector\n                    \n                    # Ensure the mutated vector is within bounds\n                    mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n                    \n                    # Replace the current particle with the mutated vector\n                    population[i] = mutated_vector\n\n                # Clip positions to stay within bounds\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            num_evals = len(new_fitness)\n            self.budget -= num_evals\n\n            # Update personal best positions and fitness\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            current_best_index = np.argmin(new_fitness)\n            if new_fitness[current_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_best_index]\n                global_best_position = population[current_best_index].copy()\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines particle swarm optimization with a mutation operator inspired by differential evolution to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.mutation_rate = mutation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n\n        # Evaluate initial population\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        global_best_fitness = fitness[global_best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                # Clip velocities to prevent explosion\n                velocities[i] = np.clip(velocities[i], self.lb - population[i], self.ub - population[i]) # changed from original limits\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n\n                # Apply mutation (Differential Evolution inspired)\n                if np.random.rand() < self.mutation_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutated_vector = x1 + 0.5 * (x2 - x3)  # Added a scaling factor for the difference vector\n                    \n                    # Ensure the mutated vector is within bounds\n                    mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n                    \n                    # Replace the current particle with the mutated vector\n                    population[i] = mutated_vector\n\n                # Clip positions to stay within bounds\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in population])\n            num_evals = len(new_fitness)\n            self.budget -= num_evals\n\n            # Update personal best positions and fitness\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best position and fitness\n            current_best_index = np.argmin(new_fitness)\n            if new_fitness[current_best_index] < global_best_fitness:\n                global_best_fitness = new_fitness[current_best_index]\n                global_best_position = population[current_best_index].copy()\n\n        return global_best_fitness, global_best_position\n```", "operator": "random_new", "theta_sampled": 0.044350218304711225, "generation": 1}, "task_prompt": ""}
{"id": "03bf9b25-c4a4-4790-9855-c6b1338b5e1b", "fitness": "-inf", "name": "AdaptiveCoordinateDescent", "description": "Adaptive Coordinate Descent with dynamic step size control and momentum, focusing on efficient step size adaptation and exploration/exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n        self.success_rate = np.zeros(dim) # Track success rate for each dimension\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                original_f = best_f\n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i] * (1 + self.momentum_factor*self.momentum[i]) # Include momentum\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i] * (1 + self.momentum_factor*self.momentum[i]) # Include momentum\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        self.success_rate[i] += 1\n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        self.success_rate[i] += 1\n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                    self.success_rate[i] += 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                    self.success_rate[i] += 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.8  # Reduce step size more aggressively\n                    self.momentum[i] = 0 # Reset Momentum\n                    \n\n                if best_f >= original_f:\n                    self.success_rate[i] *= 0.5\n\n            # Adapt step sizes globally based on success rate\n            for i in range(self.dim):\n                if self.success_rate[i] > 0.2: # Dynamic Threshold\n                    self.step_sizes[i] *= 1.1  # Increase step size if successful\n                else:\n                    self.step_sizes[i] *= 0.9\n                self.success_rate[i] *= 0.9 # Decay success rate\n\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        return best_f, self.x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["33d1abee-2262-446b-a10e-0516ec2ad648"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Coordinate Descent with dynamic step size control and momentum, focusing on efficient step size adaptation and exploration/exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n        self.success_rate = np.zeros(dim) # Track success rate for each dimension\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                original_f = best_f\n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i] * (1 + self.momentum_factor*self.momentum[i]) # Include momentum\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i] * (1 + self.momentum_factor*self.momentum[i]) # Include momentum\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        self.success_rate[i] += 1\n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        self.success_rate[i] += 1\n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                    self.success_rate[i] += 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                    self.success_rate[i] += 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.8  # Reduce step size more aggressively\n                    self.momentum[i] = 0 # Reset Momentum\n                    \n\n                if best_f >= original_f:\n                    self.success_rate[i] *= 0.5\n\n            # Adapt step sizes globally based on success rate\n            for i in range(self.dim):\n                if self.success_rate[i] > 0.2: # Dynamic Threshold\n                    self.step_sizes[i] *= 1.1  # Increase step size if successful\n                else:\n                    self.step_sizes[i] *= 0.9\n                self.success_rate[i] *= 0.9 # Decay success rate\n\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        return best_f, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.06775370662592924, "generation": 1}, "task_prompt": ""}
{"id": "7f754dfc-cc0c-46e9-af03-af3c1d41ad77", "fitness": "-inf", "name": "LevyCMAES", "description": "Population-based search with covariance matrix adaptation and a mutation inspired by the Lvy flight distribution for enhanced exploration.", "code": "import numpy as np\n\nclass LevyCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)  # Covariance matrix\n        \n        # Parameters for CMA-ES\n        c_sigma = (np.sqrt(self.popsize) / np.sqrt(self.dim))\n        d_sigma = 1 + 2 * np.max([0, np.sqrt((self.mu / self.dim - 1))]) + c_sigma\n        c_c = 4 / (self.dim + 4)\n        c_mu = 2 / (self.dim + np.sqrt(2))\n        mu = self.popsize // 2\n\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n        \n        eigen_decomposition = np.linalg.eigh(C)\n        B = eigen_decomposition[1]  # Rotation matrix\n        D = np.sqrt(eigen_decomposition[0])  # Eigenvalues (standard deviations)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)  # Gaussian random numbers\n            \n            # Levy flight inspired mutation\n            u = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            v = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            step_size = np.power(np.divide(u, np.power(np.abs(v), 1/2)), 1) #alpha = 1\n\n            x = mean[:, np.newaxis] + sigma * B @ (D[:, np.newaxis] * (z + 0.01 * step_size))\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            eval_count += self.popsize\n            if eval_count > self.budget:\n                f = f[:self.popsize - (eval_count - self.budget)]\n                x = x[:, :self.popsize - (eval_count - self.budget)]\n                \n            for i in range(len(f)):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[:, i]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:mu]]\n            z_mu = z[:, idx[:mu]]\n\n            mean_old = mean.copy()\n            mean = np.mean(x_mu, axis=1)\n\n            # Update Evolution Path\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma)) * B @ z_mu.mean(axis=1)\n            sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            sigma = np.clip(sigma, 1e-10, 1)\n            \n            p_c = (1 - c_c) * p_c + np.sqrt(c_c * (2 - c_c)) * (mean - mean_old) / sigma\n            \n            # Update Covariance Matrix\n            C = (1 - c_mu) * C + c_mu * (mean - mean_old)[:, np.newaxis] @ (mean - mean_old)[np.newaxis, :] / sigma**2\n            \n            C = np.triu(C) + np.triu(C, 1).T\n\n            eigen_decomposition = np.linalg.eigh(C)\n            B = eigen_decomposition[1]  # Rotation matrix\n            D = np.sqrt(eigen_decomposition[0])  # Eigenvalues (standard deviations)\n            \n            if eval_count >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "In the code, line 20, in __call__, the following error occurred:\nAttributeError: 'LevyCMAES' object has no attribute 'mu'\nOn line: d_sigma = 1 + 2 * np.max([0, np.sqrt((self.mu / self.dim - 1))]) + c_sigma", "error": "In the code, line 20, in __call__, the following error occurred:\nAttributeError: 'LevyCMAES' object has no attribute 'mu'\nOn line: d_sigma = 1 + 2 * np.max([0, np.sqrt((self.mu / self.dim - 1))]) + c_sigma", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with covariance matrix adaptation and a mutation inspired by the Lvy flight distribution for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass LevyCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma0=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma0 = sigma0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)  # Covariance matrix\n        \n        # Parameters for CMA-ES\n        c_sigma = (np.sqrt(self.popsize) / np.sqrt(self.dim))\n        d_sigma = 1 + 2 * np.max([0, np.sqrt((self.mu / self.dim - 1))]) + c_sigma\n        c_c = 4 / (self.dim + 4)\n        c_mu = 2 / (self.dim + np.sqrt(2))\n        mu = self.popsize // 2\n\n        p_sigma = np.zeros(self.dim)\n        p_c = np.zeros(self.dim)\n        \n        eigen_decomposition = np.linalg.eigh(C)\n        B = eigen_decomposition[1]  # Rotation matrix\n        D = np.sqrt(eigen_decomposition[0])  # Eigenvalues (standard deviations)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)  # Gaussian random numbers\n            \n            # Levy flight inspired mutation\n            u = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            v = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            step_size = np.power(np.divide(u, np.power(np.abs(v), 1/2)), 1) #alpha = 1\n\n            x = mean[:, np.newaxis] + sigma * B @ (D[:, np.newaxis] * (z + 0.01 * step_size))\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            eval_count += self.popsize\n            if eval_count > self.budget:\n                f = f[:self.popsize - (eval_count - self.budget)]\n                x = x[:, :self.popsize - (eval_count - self.budget)]\n                \n            for i in range(len(f)):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[:, i]\n\n            # Selection and Recombination\n            idx = np.argsort(f)\n            x_mu = x[:, idx[:mu]]\n            z_mu = z[:, idx[:mu]]\n\n            mean_old = mean.copy()\n            mean = np.mean(x_mu, axis=1)\n\n            # Update Evolution Path\n            p_sigma = (1 - c_sigma) * p_sigma + np.sqrt(c_sigma * (2 - c_sigma)) * B @ z_mu.mean(axis=1)\n            sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(p_sigma) / np.sqrt(self.dim) - 1))\n            sigma = np.clip(sigma, 1e-10, 1)\n            \n            p_c = (1 - c_c) * p_c + np.sqrt(c_c * (2 - c_c)) * (mean - mean_old) / sigma\n            \n            # Update Covariance Matrix\n            C = (1 - c_mu) * C + c_mu * (mean - mean_old)[:, np.newaxis] @ (mean - mean_old)[np.newaxis, :] / sigma**2\n            \n            C = np.triu(C) + np.triu(C, 1).T\n\n            eigen_decomposition = np.linalg.eigh(C)\n            B = eigen_decomposition[1]  # Rotation matrix\n            D = np.sqrt(eigen_decomposition[0])  # Eigenvalues (standard deviations)\n            \n            if eval_count >= self.budget:\n                break\n                \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.11011158551797007, "generation": 1}, "task_prompt": ""}
{"id": "efd051e7-51bc-4719-afe9-a038d1ba6d2e", "fitness": "-inf", "name": "AdaptiveDE_CMAES", "description": "Adaptive Differential Evolution with orthogonal array based initialization and local search using CMA-ES.", "code": "import numpy as np\nfrom scipy.stats import norm\nimport cma\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_mutation_factor=0.5, de_crossover_rate=0.7, cmaes_sigma=0.1, local_search_frequency=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Adaptive population size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.cmaes_sigma = cmaes_sigma\n        self.local_search_frequency = local_search_frequency\n\n        self.archive = [] # archive poor solutions to escape local optima\n        self.archive_fitness = []\n\n\n    def orthogonal_array_initialization(self, func, num_points=None):\n      #Simplified orthogonal array initialization, sampling uniformly\n      num_points = num_points if num_points is not None else self.pop_size\n      initial_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_points, self.dim))\n      return initial_population\n    \n    def apply_bounds(self, x, lb, ub):\n        \"\"\"Apply bounds to a single vector.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population using orthogonal array sampling\n        self.population = self.orthogonal_array_initialization(func)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= len(self.fitness)\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = self.apply_bounds(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                x_trial = self.apply_bounds(x_trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < new_fitness[i]:\n                    new_fitness[i] = f_trial\n                    new_population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    # Archive the parent\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                    if len(self.archive) > 10 * self.dim: #Keep archive size reasonable\n                        self.archive.pop(0)\n                        self.archive_fitness.pop(0)\n                        \n                if self.budget <= 0:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Local search with CMA-ES (applied probabilistically)\n            if np.random.rand() < self.local_search_frequency and self.budget > self.dim + 2:\n                best_index = np.argmin(self.fitness)\n                x_local_search = self.population[best_index].copy()\n                \n                try:\n                    es = cma.purecma.CMAES(x_local_search, self.cmaes_sigma,\n                                            {'bounds': [func.bounds.lb, func.bounds.ub],\n                                             'verbose': -9})  # Disable CMA-ES output\n                    \n                    while es.ask_tell.evaluations < self.dim + 2 and self.budget > 0: # small budget for local search\n                        solutions = []\n                        for _ in range(es.ask_tell.dim): #Exploit CMA-ES's internal population without exceeding budget.\n                          if self.budget > 0:\n                            x = es.ask()\n                            solutions.append(x)\n                            self.budget -= 1\n                          else:\n                            break\n                        \n                        if len(solutions) > 0:\n                          fitness_values = [func(x) for x in solutions]\n                          es.tell(solutions, fitness_values)\n\n                    x_best_local = es.best.x\n                    f_best_local = func(x_best_local)\n\n                    if f_best_local < self.f_opt:\n                        self.f_opt = f_best_local\n                        self.x_opt = x_best_local\n                except Exception as e:\n                    pass # CMA-ES can be unstable; gracefully handle potential errors\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Validation failed: Forbidden import: 'cma' is not available in the evaluation environment", "parent_ids": ["41e8102d-b5ad-48d6-8ec1-5f807c284871"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal array based initialization and local search using CMA-ES.\n# Code: \n```python\nimport numpy as np\nfrom scipy.stats import norm\nimport cma\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, de_mutation_factor=0.5, de_crossover_rate=0.7, cmaes_sigma=0.1, local_search_frequency=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Adaptive population size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.cmaes_sigma = cmaes_sigma\n        self.local_search_frequency = local_search_frequency\n\n        self.archive = [] # archive poor solutions to escape local optima\n        self.archive_fitness = []\n\n\n    def orthogonal_array_initialization(self, func, num_points=None):\n      #Simplified orthogonal array initialization, sampling uniformly\n      num_points = num_points if num_points is not None else self.pop_size\n      initial_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_points, self.dim))\n      return initial_population\n    \n    def apply_bounds(self, x, lb, ub):\n        \"\"\"Apply bounds to a single vector.\"\"\"\n        return np.clip(x, lb, ub)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population using orthogonal array sampling\n        self.population = self.orthogonal_array_initialization(func)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= len(self.fitness)\n        \n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = self.apply_bounds(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                x_trial = self.apply_bounds(x_trial, func.bounds.lb, func.bounds.ub)\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < new_fitness[i]:\n                    new_fitness[i] = f_trial\n                    new_population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    # Archive the parent\n                    self.archive.append(self.population[i].copy())\n                    self.archive_fitness.append(self.fitness[i])\n                    if len(self.archive) > 10 * self.dim: #Keep archive size reasonable\n                        self.archive.pop(0)\n                        self.archive_fitness.pop(0)\n                        \n                if self.budget <= 0:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Local search with CMA-ES (applied probabilistically)\n            if np.random.rand() < self.local_search_frequency and self.budget > self.dim + 2:\n                best_index = np.argmin(self.fitness)\n                x_local_search = self.population[best_index].copy()\n                \n                try:\n                    es = cma.purecma.CMAES(x_local_search, self.cmaes_sigma,\n                                            {'bounds': [func.bounds.lb, func.bounds.ub],\n                                             'verbose': -9})  # Disable CMA-ES output\n                    \n                    while es.ask_tell.evaluations < self.dim + 2 and self.budget > 0: # small budget for local search\n                        solutions = []\n                        for _ in range(es.ask_tell.dim): #Exploit CMA-ES's internal population without exceeding budget.\n                          if self.budget > 0:\n                            x = es.ask()\n                            solutions.append(x)\n                            self.budget -= 1\n                          else:\n                            break\n                        \n                        if len(solutions) > 0:\n                          fitness_values = [func(x) for x in solutions]\n                          es.tell(solutions, fitness_values)\n\n                    x_best_local = es.best.x\n                    f_best_local = func(x_best_local)\n\n                    if f_best_local < self.f_opt:\n                        self.f_opt = f_best_local\n                        self.x_opt = x_best_local\n                except Exception as e:\n                    pass # CMA-ES can be unstable; gracefully handle potential errors\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "67b6c884-aae0-4108-8cc5-b772ba7cb7cf", "fitness": "-inf", "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "An adaptive population-based algorithm that combines elements of differential evolution with a self-adaptive mutation strategy and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Adaptive F and CR\n        adaptive_F = np.full(self.pop_size, self.F)\n        adaptive_CR = np.full(self.pop_size, self.CR)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive parameter tuning\n                if np.random.rand() < 0.1:  # Probability to change F and CR\n                    adaptive_F[i] = np.random.uniform(0.1, 0.9)\n                    adaptive_CR[i] = np.random.uniform(0.1, 0.9)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + adaptive_F[i] * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < adaptive_CR[i] or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                # Local Search (refinement)\n                for _ in range(self.local_search_iterations):\n                    if self.budget <=0:\n                      break\n                    \n                    # Select a random dimension for local search\n                    ls_dim = np.random.randint(0, self.dim)\n                    \n                    # Small perturbation around the current value\n                    perturbation = np.random.uniform(-0.1, 0.1) * (func.bounds.ub[ls_dim] - func.bounds.lb[ls_dim])  #Scale perturbation to bound range\n                    \n                    # Create a perturbed trial vector\n                    ls_trial = np.copy(trial)\n                    ls_trial[ls_dim] += perturbation\n                    ls_trial = np.clip(ls_trial, func.bounds.lb, func.bounds.ub) # Clip to bounds\n                    \n                    # Evaluate the perturbed trial vector\n                    ls_fitness = func(ls_trial)\n                    self.budget -= 1\n                    \n                    # Update trial if improvement found\n                    if ls_fitness < fitness[i]:\n                      trial = ls_trial\n                      fitness[i] = ls_fitness\n\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                  break\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n              self.f_opt = fitness[best_index]\n              self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines elements of differential evolution with a self-adaptive mutation strategy and local search refinement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        # Adaptive F and CR\n        adaptive_F = np.full(self.pop_size, self.F)\n        adaptive_CR = np.full(self.pop_size, self.CR)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive parameter tuning\n                if np.random.rand() < 0.1:  # Probability to change F and CR\n                    adaptive_F[i] = np.random.uniform(0.1, 0.9)\n                    adaptive_CR[i] = np.random.uniform(0.1, 0.9)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + adaptive_F[i] * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < adaptive_CR[i] or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                # Local Search (refinement)\n                for _ in range(self.local_search_iterations):\n                    if self.budget <=0:\n                      break\n                    \n                    # Select a random dimension for local search\n                    ls_dim = np.random.randint(0, self.dim)\n                    \n                    # Small perturbation around the current value\n                    perturbation = np.random.uniform(-0.1, 0.1) * (func.bounds.ub[ls_dim] - func.bounds.lb[ls_dim])  #Scale perturbation to bound range\n                    \n                    # Create a perturbed trial vector\n                    ls_trial = np.copy(trial)\n                    ls_trial[ls_dim] += perturbation\n                    ls_trial = np.clip(ls_trial, func.bounds.lb, func.bounds.ub) # Clip to bounds\n                    \n                    # Evaluate the perturbed trial vector\n                    ls_fitness = func(ls_trial)\n                    self.budget -= 1\n                    \n                    # Update trial if improvement found\n                    if ls_fitness < fitness[i]:\n                      trial = ls_trial\n                      fitness[i] = ls_fitness\n\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1 # Update budget\n                if self.budget <= 0:\n                  break\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n              self.f_opt = fitness[best_index]\n              self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.15862472554846713, "generation": 1}, "task_prompt": ""}
{"id": "af92c806-cf02-4018-8998-6f6535ee0fbc", "fitness": "-inf", "name": "RestartAdaptiveCoordinateDescent", "description": "Adaptive Coordinate Descent with periodic population-based restarts to escape local optima.", "code": "import numpy as np\n\nclass RestartAdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9, restart_interval=1000, pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n        self.restart_interval = restart_interval\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        iteration = 0\n        while self.budget > 0:\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                if self.budget <=0:\n                    break\n                f_plus = func(x_plus)\n                self.budget -= 1\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                if self.budget <=0:\n                    break\n\n                f_minus = func(x_minus)\n                self.budget -= 1\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n\n            iteration += 1\n            if iteration % self.restart_interval == 0:\n                # Population-based restart\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < best_f:\n                    best_f = fitness[best_index]\n                    self.x_opt = population[best_index]\n                \n                lower_bounds = np.full(self.dim, func.bounds.lb)\n                upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        return best_f, self.x_opt", "configspace": "", "generation": 1, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["33d1abee-2262-446b-a10e-0516ec2ad648", "41e8102d-b5ad-48d6-8ec1-5f807c284871"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Coordinate Descent with periodic population-based restarts to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass RestartAdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9, restart_interval=1000, pop_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.momentum = np.zeros(dim)\n        self.restart_interval = restart_interval\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initialize x_opt randomly\n        \n        best_f = func(self.x_opt)\n        self.budget -=1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        iteration = 0\n        while self.budget > 0:\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                if self.budget <=0:\n                    break\n                f_plus = func(x_plus)\n                self.budget -= 1\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                if self.budget <=0:\n                    break\n\n                f_minus = func(x_minus)\n                self.budget -= 1\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] + 1 \n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] + 1\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                    self.momentum[i] = self.momentum_factor * self.momentum[i] - 1\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n\n            iteration += 1\n            if iteration % self.restart_interval == 0:\n                # Population-based restart\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < best_f:\n                    best_f = fitness[best_index]\n                    self.x_opt = population[best_index]\n                \n                lower_bounds = np.full(self.dim, func.bounds.lb)\n                upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        return best_f, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.09448838391328403, "generation": 1}, "task_prompt": ""}
{"id": "e69e0266-dcaf-4e9a-a36f-530f3b3b1b09", "fitness": 0.20621663664961465, "name": "SimplifiedAdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and a more efficient restart strategy based on population diversity.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_threshold = restart_threshold #Population diversity threshold for restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Self-adaptive parameter control\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def should_restart(self):\n        # Calculate population diversity based on the standard deviation of the fitness values\n        diversity = np.std(self.fitness)\n        # Restart if the diversity is below the threshold\n        return diversity < self.restart_threshold\n\n    def restart_population(self, func):\n        # Replace the entire population with new random individuals\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.should_restart():\n                self.restart_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.206 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db595387-3861-4520-be29-004ff9807db5"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with self-adaptive parameters and a more efficient restart strategy based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, restart_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.restart_threshold = restart_threshold #Population diversity threshold for restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Self-adaptive parameter control\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def should_restart(self):\n        # Calculate population diversity based on the standard deviation of the fitness values\n        diversity = np.std(self.fitness)\n        # Restart if the diversity is below the threshold\n        return diversity < self.restart_threshold\n\n    def restart_population(self, func):\n        # Replace the entire population with new random individuals\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.should_restart():\n                self.restart_population(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.06583157893529391, "generation": 2, "aucs": [0.2888222407602954, 0.32982766918854856, 0]}, "task_prompt": ""}
{"id": "4b866f50-7b62-46ff-b962-b38a6029ab88", "fitness": 0.6316362746293791, "name": "AdaptiveOrthoDE", "description": "Combines Orthogonal Sampling and Differential Evolution with adaptive step size for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveOrthoDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        while self.budget > 0:\n            # Orthogonal Sampling with Adaptive Step Size\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n                \n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt step sizes\n            if self.f_opt < np.min(self.fitness):\n                self.step_sizes *= 1.1\n            else:\n                self.step_sizes *= 0.9\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveOrthoDE scored 0.632 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["41e8102d-b5ad-48d6-8ec1-5f807c284871", "33d1abee-2262-446b-a10e-0516ec2ad648"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Orthogonal Sampling and Differential Evolution with adaptive step size for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveOrthoDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        while self.budget > 0:\n            # Orthogonal Sampling with Adaptive Step Size\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n                \n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt step sizes\n            if self.f_opt < np.min(self.fitness):\n                self.step_sizes *= 1.1\n            else:\n                self.step_sizes *= 0.9\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.10914315769090198, "generation": 2, "aucs": [0.24585755736344272, 0.5061067188354315, 0.5941651293974597, 0.840470364677007, 0.6916981324683553, 0.7349106669691756, 0.5679334635429807, 0.6014239095212215, 0.6883420460620011, 0.6502756286455313, 0.8032945246544357, 0.9981446111598676, 0.36861712053846296, 0.6389320782252159, 0.9021944681614168, 0.742866483317346, 0.49187097345012676, 0.8123035671055508, 0.225907172465327, 0.5274108760272282]}, "task_prompt": ""}
{"id": "c4bc2150-dca4-4e8e-8cba-a5ab1935e5aa", "fitness": "-inf", "name": "AdaptiveOrthogonalDE", "description": "Combines Orthogonal Sampling and Differential Evolution with adaptive step size control for local search around the best solution.", "code": "import numpy as np\n\nclass AdaptiveOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        while self.budget > 0:\n            # Orthogonal Sampling around best solution\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n                \n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt step sizes for orthogonal sampling\n            if self.f_opt < self.fitness[np.argmin(self.fitness)]:\n               self.step_sizes *= 1.05  # Increase step size if improvement\n            else:\n                self.step_sizes *= 0.95 # Decrease step size if no improvement\n\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink the search space around current optimum\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": ["41e8102d-b5ad-48d6-8ec1-5f807c284871", "33d1abee-2262-446b-a10e-0516ec2ad648"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Orthogonal Sampling and Differential Evolution with adaptive step size control for local search around the best solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveOrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, orthogonal_components=5, de_mutation_factor=0.5, de_crossover_rate=0.7, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        while self.budget > 0:\n            # Orthogonal Sampling around best solution\n            for i in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n                \n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt step sizes for orthogonal sampling\n            if self.f_opt < self.fitness[np.argmin(self.fitness)]:\n               self.step_sizes *= 1.05  # Increase step size if improvement\n            else:\n                self.step_sizes *= 0.95 # Decrease step size if no improvement\n\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink the search space around current optimum\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.5797406721246828, "generation": 2}, "task_prompt": ""}
{"id": "c77c7ad6-009a-4dfe-a6d8-248297e34758", "fitness": 0.0, "name": "AdaptiveCoordinateDescentRestart", "description": "Adaptively adjusts coordinate descent step sizes with a probabilistic restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescentRestart:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.restart_prob = restart_prob\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        \n        best_f = func(self.x_opt)\n        self.budget -= 1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n            \n            # Restart mechanism: restart the solution with a probability\n            if np.random.rand() < self.restart_prob:\n                self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                best_f = func(self.x_opt)\n            \n        return best_f, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveCoordinateDescentRestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["33d1abee-2262-446b-a10e-0516ec2ad648", "d146b416-8868-4731-ba14-af5925191c17"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively adjusts coordinate descent step sizes with a probabilistic restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCoordinateDescentRestart:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.restart_prob = restart_prob\n        self.step_sizes = np.full(dim, initial_step_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        \n        best_f = func(self.x_opt)\n        self.budget -= 1\n        \n        lower_bounds = np.full(self.dim, func.bounds.lb)\n        upper_bounds = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                # Explore around the current best solution along each dimension\n                \n                # Positive direction\n                x_plus = self.x_opt.copy()\n                x_plus[i] += self.step_sizes[i]\n                x_plus[i] = np.clip(x_plus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_plus = func(x_plus)\n                \n                # Negative direction\n                x_minus = self.x_opt.copy()\n                x_minus[i] -= self.step_sizes[i]\n                x_minus[i] = np.clip(x_minus[i], lower_bounds[i], upper_bounds[i])\n                \n                f_minus = func(x_minus)\n                \n                # Choose the best direction\n                if f_plus < best_f and f_minus < best_f:\n                    if f_plus < f_minus:\n                        self.x_opt = x_plus\n                        best_f = f_plus\n                        \n                    else:\n                        self.x_opt = x_minus\n                        best_f = f_minus\n                        \n                elif f_plus < best_f:\n                    self.x_opt = x_plus\n                    best_f = f_plus\n                elif f_minus < best_f:\n                    self.x_opt = x_minus\n                    best_f = f_minus\n                else:\n                    # No improvement, reduce step size for this dimension\n                    self.step_sizes[i] *= 0.9  # Reduce step size\n\n            # Adapt step sizes globally\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n            \n            # Shrink search space\n            lower_bounds = np.maximum(lower_bounds, self.x_opt - self.initial_step_size)\n            upper_bounds = np.minimum(upper_bounds, self.x_opt + self.initial_step_size)\n            \n            # Restart mechanism: restart the solution with a probability\n            if np.random.rand() < self.restart_prob:\n                self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                best_f = func(self.x_opt)\n            \n        return best_f, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.5942823420845409, "generation": 2, "aucs": [0]}, "task_prompt": ""}
{"id": "7f70d562-db6f-440b-9f4c-a3593785cfe1", "fitness": 0.7480848577472168, "name": "AdaptiveDifferentialEvolution", "description": "Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced complexity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db595387-3861-4520-be29-004ff9807db5"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with self-adaptive parameters and reduced complexity.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.10175160717522702, "generation": 2, "aucs": [0.40133858079482065, 0.7246550576369424, 0.7569170845794524, 0.8864980430296902, 0.7696207807283275, 0.8363938290206983, 0.7454215142004784, 0.7215664983629987, 0.7579950295320259, 0.6996956078071925, 0.9021776544162182, 0.9950605054068608, 0.7021602128155426, 0.8026038481469526, 0.9396363543724615, 0.8110566944970296, 0.70554594613599, 0.8623291267527989, 0.4098921371867822, 0.5311326495210735]}, "task_prompt": ""}
{"id": "a7fea6ea-185e-4916-90cd-64f9093937aa", "fitness": "-inf", "name": "AdaptiveCoordinateDescent", "description": "Adaptive Coordinate Descent with dynamic step size and direction adaptation based on success rate.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.success_counts = np.zeros(dim)\n        self.trial_counts = np.zeros(dim)\n        self.success_rate_threshold = success_rate_threshold\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        f_best = func(x)\n        self.budget -= 1\n\n        lb = np.full(self.dim, func.bounds.lb)\n        ub = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                self.trial_counts[i] += 1\n                step = self.step_sizes[i]\n                \n                # Randomly choose direction (+1 or -1)\n                direction = np.random.choice([-1, 1])\n                x_new = x.copy()\n                x_new[i] += direction * step\n                x_new[i] = np.clip(x_new[i], lb[i], ub[i])\n                \n                f_new = func(x_new)\n                \n                if f_new < f_best:\n                    f_best = f_new\n                    x = x_new\n                    self.success_counts[i] += 1\n                else:\n                    # If no improvement, try the opposite direction with smaller step\n                    direction = -direction\n                    x_new = x.copy()\n                    x_new[i] += direction * step * 0.5\n                    x_new[i] = np.clip(x_new[i], lb[i], ub[i])\n                    f_new = func(x_new)\n\n                    if f_new < f_best:\n                        f_best = f_new\n                        x = x_new\n                        self.success_counts[i] += 1\n\n\n\n                # Adjust step size based on success rate\n                success_rate = self.success_counts[i] / self.trial_counts[i]\n                if success_rate > self.success_rate_threshold:\n                    self.step_sizes[i] *= 1.1  # Increase step size\n                else:\n                    self.step_sizes[i] *= 0.9  # Decrease step size\n\n                self.step_sizes[i] = np.clip(self.step_sizes[i], 1e-6, func.bounds.ub - func.bounds.lb)\n            \n        return f_best, x", "configspace": "", "generation": 2, "feedback": "In the code, line 60, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: self.step_sizes[i] = np.clip(self.step_sizes[i], 1e-6, func.bounds.ub - func.bounds.lb)", "error": "In the code, line 60, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: self.step_sizes[i] = np.clip(self.step_sizes[i], 1e-6, func.bounds.ub - func.bounds.lb)", "parent_ids": ["33d1abee-2262-446b-a10e-0516ec2ad648"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Coordinate Descent with dynamic step size and direction adaptation based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_rate_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.success_counts = np.zeros(dim)\n        self.trial_counts = np.zeros(dim)\n        self.success_rate_threshold = success_rate_threshold\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        f_best = func(x)\n        self.budget -= 1\n\n        lb = np.full(self.dim, func.bounds.lb)\n        ub = np.full(self.dim, func.bounds.ub)\n\n        for _ in range(self.budget):\n            for i in range(self.dim):\n                self.trial_counts[i] += 1\n                step = self.step_sizes[i]\n                \n                # Randomly choose direction (+1 or -1)\n                direction = np.random.choice([-1, 1])\n                x_new = x.copy()\n                x_new[i] += direction * step\n                x_new[i] = np.clip(x_new[i], lb[i], ub[i])\n                \n                f_new = func(x_new)\n                \n                if f_new < f_best:\n                    f_best = f_new\n                    x = x_new\n                    self.success_counts[i] += 1\n                else:\n                    # If no improvement, try the opposite direction with smaller step\n                    direction = -direction\n                    x_new = x.copy()\n                    x_new[i] += direction * step * 0.5\n                    x_new[i] = np.clip(x_new[i], lb[i], ub[i])\n                    f_new = func(x_new)\n\n                    if f_new < f_best:\n                        f_best = f_new\n                        x = x_new\n                        self.success_counts[i] += 1\n\n\n\n                # Adjust step size based on success rate\n                success_rate = self.success_counts[i] / self.trial_counts[i]\n                if success_rate > self.success_rate_threshold:\n                    self.step_sizes[i] *= 1.1  # Increase step size\n                else:\n                    self.step_sizes[i] *= 0.9  # Decrease step size\n\n                self.step_sizes[i] = np.clip(self.step_sizes[i], 1e-6, func.bounds.ub - func.bounds.lb)\n            \n        return f_best, x\n```", "operator": "simplify", "theta_sampled": 0.42509852871000475, "generation": 2}, "task_prompt": ""}
{"id": "cbbd6a19-2530-4ed8-af2b-5163259a6d57", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionOrthogonal", "description": "Adaptive Differential Evolution with orthogonal sampling for enhanced exploration around the best solution.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, orthogonal_components=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.orthogonal_components = orthogonal_components #Number of orthogonal samples per generation\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Orthogonal Sampling around best solution\n        for _ in range(self.orthogonal_components):\n            x_orthogonal = self.x_opt + np.random.normal(0, 0.1, size=self.dim)\n            x_orthogonal = np.clip(x_orthogonal, func.bounds.lb, func.bounds.ub)\n            f_orthogonal = func(x_orthogonal)\n            self.eval_count += 1\n\n            if f_orthogonal < self.f_opt:\n                self.f_opt = f_orthogonal\n                self.x_opt = x_orthogonal\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDifferentialEvolutionOrthogonal scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["db595387-3861-4520-be29-004ff9807db5", "41e8102d-b5ad-48d6-8ec1-5f807c284871"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with orthogonal sampling for enhanced exploration around the best solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionOrthogonal:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9, orthogonal_components=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial differential weight\n        self.Cr = Cr  # Initial crossover probability\n        self.orthogonal_components = orthogonal_components #Number of orthogonal samples per generation\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n        \n        # Adaptive parameter control: Adjust F and Cr based on success\n        success_indices = np.where(self.fitness < np.mean(self.fitness))[0]\n        if len(success_indices) > 0:\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        # Orthogonal Sampling around best solution\n        for _ in range(self.orthogonal_components):\n            x_orthogonal = self.x_opt + np.random.normal(0, 0.1, size=self.dim)\n            x_orthogonal = np.clip(x_orthogonal, func.bounds.lb, func.bounds.ub)\n            f_orthogonal = func(x_orthogonal)\n            self.eval_count += 1\n\n            if f_orthogonal < self.f_opt:\n                self.f_opt = f_orthogonal\n                self.x_opt = x_orthogonal\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.26791872517735094, "generation": 2, "aucs": [0]}, "task_prompt": ""}
{"id": "a45360ea-0a59-469a-ac46-3891c971dc4a", "fitness": 0.4378560469953974, "name": "OrthogonalDE", "description": "Combines orthogonal sampling for diversification with a simplified differential evolution for exploitation, using a dynamically adjusted mutation factor based on population diversity.", "code": "import numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=3, de_crossover_rate=0.7, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_crossover_rate = de_crossover_rate\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            # Orthogonal Sampling\n            for _ in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Dynamic Mutation Factor based on population diversity\n            diversity = np.std(self.population)\n            de_mutation_factor = 0.5 + 0.5 * (diversity > self.diversity_threshold)\n\n            # Simplified Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm OrthogonalDE scored 0.438 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["41e8102d-b5ad-48d6-8ec1-5f807c284871"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines orthogonal sampling for diversification with a simplified differential evolution for exploitation, using a dynamically adjusted mutation factor based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=3, de_crossover_rate=0.7, diversity_threshold=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_crossover_rate = de_crossover_rate\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            # Orthogonal Sampling\n            for _ in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Dynamic Mutation Factor based on population diversity\n            diversity = np.std(self.population)\n            de_mutation_factor = 0.5 + 0.5 * (diversity > self.diversity_threshold)\n\n            # Simplified Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.21468126807946458, "generation": 2, "aucs": [0.1688224239245879, 0.2095401134197178, 0.4090877027014087, 0.6516961115420847, 0.407726927926754, 0.5269701750004272, 0.3294079420580982, 0.38136116115772845, 0.40535505553734175, 0.27415696295679093, 0.5030405969249849, 0.9973873915300557, 0.2963025250051474, 0.3378046657165984, 0.7416085546513969, 0.5259744895553053, 0.32570938826802287, 0.5791665390343701, 0.1912319745775679, 0.4947702384195585]}, "task_prompt": ""}
{"id": "9b74d66b-0db9-480a-8b9a-ff76002d1892", "fitness": 0.7488189140831716, "name": "SimplifiedAdaptiveDE", "description": "Simplified Adaptive Differential Evolution with improved parameter adaptation and reduced population size.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.749 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with improved parameter adaptation and reduced population size.\n# Code: \n```python\nimport numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.3664933961170226, "generation": 3, "aucs": [0.24968153337802157, 0.7797185826654033, 0.8198433658272064, 0.899046749149608, 0.8799647897140273, 0.9096858968942876, 0.8460799859038668, 0.8177912596448319, 0.8874048326375794, 0.8631752775144355, 0.9220623098693204, 0.9904164631943264, 0.27718606906508014, 0.8575108738601246, 0.9358359398406719, 0.8899168171169676, 0.4234734786875691, 0.9078335172419453, 0.30354352254615, 0.5162070169120081]}, "task_prompt": ""}
{"id": "3cbf4312-8235-4969-9be4-32f27a965f6e", "fitness": 0.4733493473999397, "name": "AdaptiveOrthoDE", "description": "Combines orthogonal sampling with a simplified differential evolution strategy, adaptively adjusting the mutation factor based on the best solution found so far.", "code": "import numpy as np\n\nclass AdaptiveOrthoDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=3, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            # Orthogonal Sampling around the best solution\n            for _ in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-0.1, 0.1, size=self.dim)  # Sample around the best\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub) # Clip to bounds\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Adaptive Mutation Factor based on the best fitness\n            de_mutation_factor = 0.5 + 0.5 * np.exp(-abs(self.f_opt)) # Mutation factor based on f_opt\n\n            # Simplified Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveOrthoDE scored 0.473 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["a45360ea-0a59-469a-ac46-3891c971dc4a"], "operator": "simplify", "metadata": {"llm_response": "# Description: Combines orthogonal sampling with a simplified differential evolution strategy, adaptively adjusting the mutation factor based on the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveOrthoDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=3, de_crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.de_crossover_rate = de_crossover_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n\n        while self.budget > 0:\n            # Orthogonal Sampling around the best solution\n            for _ in range(self.orthogonal_components):\n                if self.budget <= 0:\n                    break\n                orthogonal_sample = self.x_opt + np.random.uniform(-0.1, 0.1, size=self.dim)  # Sample around the best\n                orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub) # Clip to bounds\n                f = func(orthogonal_sample)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = orthogonal_sample\n\n            # Adaptive Mutation Factor based on the best fitness\n            de_mutation_factor = 0.5 + 0.5 * np.exp(-abs(self.f_opt)) # Mutation factor based on f_opt\n\n            # Simplified Differential Evolution\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + de_mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                x_trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.de_crossover_rate:\n                        x_trial[j] = x_mutated[j]\n\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.47118197266130524, "generation": 3, "aucs": [0.20535367945023986, 0.26008589294192774, 0.42713893325651986, 0.7896415554866614, 0.39640812888048405, 0.5345187317783187, 0.3143889631388177, 0.4114901152407713, 0.42861835863082676, 0.36291321442968305, 0.5981283279448624, 0.991957275398398, 0.288278710150635, 0.37583397150692277, 0.8048729473888152, 0.559010816980991, 0.3539041940038615, 0.6394414933889987, 0.21163474968553597, 0.5133668883155247]}, "task_prompt": ""}
{"id": "0679ad74-f69d-40fd-add2-0d66c3355a3f", "fitness": 0.744294948819248, "name": "AdaptiveDE", "description": "An adaptive Differential Evolution strategy that dynamically adjusts F and Cr based on population diversity and individual success.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_solution = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.best_fitness:\n                    self.best_fitness = f_trial\n                    self.best_solution = x_trial\n\n        # Adaptive F and Cr (simplified)\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.9 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.best_fitness, self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDE scored 0.744 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "simplify", "metadata": {"llm_response": "# Description: An adaptive Differential Evolution strategy that dynamically adjusts F and Cr based on population diversity and individual success.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_solution = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.best_fitness = np.min(self.fitness)\n        self.best_solution = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.best_fitness:\n                    self.best_fitness = f_trial\n                    self.best_solution = x_trial\n\n        # Adaptive F and Cr (simplified)\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.9 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.best_fitness, self.best_solution\n```", "operator": "simplify", "theta_sampled": 0.33333393069452016, "generation": 3, "aucs": [0.3522129593594231, 0.7644487424051559, 0.7152084062237296, 0.8931754359310359, 0.7923307414068672, 0.8398712037946019, 0.7264290323610669, 0.7094581051728359, 0.7812705640891651, 0.7319109312494246, 0.872254978635194, 0.9991032720909079, 0.689798614356776, 0.7892056831334681, 0.9213576090383356, 0.841636026090731, 0.7311818418985434, 0.875441912598198, 0.3308456953919696, 0.5287572211575308]}, "task_prompt": ""}
{"id": "6705faa0-b1f5-4410-b472-5127f5cdbcab", "fitness": 0.7758793057495172, "name": "SimplifiedAdaptiveDE", "description": "Simplified Adaptive Differential Evolution with a reduced population size and less aggressive adaptation of F and Cr.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        self.Cr = 0.9 * (1 + 0.05 * np.random.randn())\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.776 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with a reduced population size and less aggressive adaptation of F and Cr.\n# Code: \n```python\nimport numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        self.Cr = 0.9 * (1 + 0.05 * np.random.randn())\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.11730739331398926, "generation": 3, "aucs": [0.6065331076042353, 0.46164200984466874, 0.8635867643973312, 0.947594815657894, 0.9025175330253726, 0.9164715743635541, 0.8380279884531365, 0.8677813278433727, 0.8907172280240071, 0.8765377787042079, 0.9485204111624665, 0.996464179481864, 0.3596803411308026, 0.9046743184561217, 0.7081045220998565, 0.9140768979142666, 0.712128653128291, 0.9265018546000107, 0.35736437975191004, 0.518660429346972]}, "task_prompt": ""}
{"id": "ef189d4f-e142-42b4-bdd5-e2d6950540b8", "fitness": 0.7279501482235802, "name": "AdaptiveOrthoDE_Plus", "description": "Integrates adaptive step size orthogonal sampling around the current best solution within the Adaptive Differential Evolution framework.", "code": "import numpy as np\n\nclass AdaptiveOrthoDE_Plus(object):\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=5, initial_step_size=1.0, de_mutation_factor=0.5, de_crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Orthogonal Sampling around the best solution\n        for _ in range(self.orthogonal_components):\n            if self.eval_count >= self.budget:\n                break\n            orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n            orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n\n            f_orthogonal = func(orthogonal_sample)\n            self.eval_count += 1\n\n            if f_orthogonal < self.f_opt:\n                self.f_opt = f_orthogonal\n                self.x_opt = orthogonal_sample\n                # Increase step size if improvement is found\n                self.step_sizes *= 1.1\n            else:\n                # Decrease step size if no improvement\n                self.step_sizes *= 0.9\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        # Differential Evolution\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveOrthoDE_Plus scored 0.728 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1", "4b866f50-7b62-46ff-b962-b38a6029ab88"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates adaptive step size orthogonal sampling around the current best solution within the Adaptive Differential Evolution framework.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveOrthoDE_Plus(object):\n    def __init__(self, budget=10000, dim=10, pop_size=40, orthogonal_components=5, initial_step_size=1.0, de_mutation_factor=0.5, de_crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.orthogonal_components = orthogonal_components\n        self.initial_step_size = initial_step_size\n        self.step_sizes = np.full(dim, initial_step_size)\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Orthogonal Sampling around the best solution\n        for _ in range(self.orthogonal_components):\n            if self.eval_count >= self.budget:\n                break\n            orthogonal_sample = self.x_opt + np.random.uniform(-self.step_sizes, self.step_sizes, size=self.dim)\n            orthogonal_sample = np.clip(orthogonal_sample, func.bounds.lb, func.bounds.ub)\n\n            f_orthogonal = func(orthogonal_sample)\n            self.eval_count += 1\n\n            if f_orthogonal < self.f_opt:\n                self.f_opt = f_orthogonal\n                self.x_opt = orthogonal_sample\n                # Increase step size if improvement is found\n                self.step_sizes *= 1.1\n            else:\n                # Decrease step size if no improvement\n                self.step_sizes *= 0.9\n            self.step_sizes = np.clip(self.step_sizes, 1e-6, self.initial_step_size)\n\n        # Differential Evolution\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.de_mutation_factor * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.de_crossover_rate:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.5397127788534352, "generation": 3, "aucs": [0.34943737931890095, 0.6843802597826227, 0.7394521194964485, 0.9316676646776361, 0.775847201351463, 0.7978142315235451, 0.7014257111246884, 0.6611565768276815, 0.7713262328542791, 0.6803361406902567, 0.8857497646110262, 0.998516687937789, 0.6916219429125672, 0.7764676281969445, 0.9316649678467845, 0.8188579891411603, 0.6506707178186588, 0.8729018821850677, 0.31930173554693175, 0.5204061306271521]}, "task_prompt": ""}
{"id": "d0d5cdf5-25db-433c-9869-c0dcc64d0a72", "fitness": 0.7280615893811258, "name": "AdaptiveDEwithOrthoSearch", "description": "Combines Adaptive Differential Evolution with Orthogonal Local Search to refine the best solution.", "code": "import numpy as np\n\nclass AdaptiveDEwithOrthoSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, ortho_trials=5, ortho_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.ortho_trials = ortho_trials\n        self.ortho_step_size = ortho_step_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def orthogonal_search(self, func):\n        for _ in range(self.ortho_trials):\n            if self.eval_count >= self.budget:\n                break\n            x_trial = self.x_opt + np.random.uniform(-self.ortho_step_size, self.ortho_step_size, size=self.dim)\n            x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n            f_trial = func(x_trial)\n            self.eval_count += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = x_trial\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.orthogonal_search(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveDEwithOrthoSearch scored 0.728 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1", "4b866f50-7b62-46ff-b962-b38a6029ab88"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive Differential Evolution with Orthogonal Local Search to refine the best solution.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEwithOrthoSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=40, ortho_trials=5, ortho_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.ortho_trials = ortho_trials\n        self.ortho_step_size = ortho_step_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def orthogonal_search(self, func):\n        for _ in range(self.ortho_trials):\n            if self.eval_count >= self.budget:\n                break\n            x_trial = self.x_opt + np.random.uniform(-self.ortho_step_size, self.ortho_step_size, size=self.dim)\n            x_trial = np.clip(x_trial, func.bounds.lb, func.bounds.ub)\n            f_trial = func(x_trial)\n            self.eval_count += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = x_trial\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr\n        self.F = 0.5 * (1 + np.random.normal(0, 0.1))\n        self.Cr = 0.9 * (1 + np.random.normal(0, 0.1))\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            self.orthogonal_search(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.13144651219098338, "generation": 3, "aucs": [0.3928122038899743, 0.7085678186905009, 0.7218709596916528, 0.8872516838019433, 0.7723280579416825, 0.8062778204052333, 0.6695915163518666, 0.7074418979830471, 0.7521027529308186, 0.7558761517871067, 0.8732986760075282, 0.9904728775416541, 0.6746478437078085, 0.7550430274502917, 0.9263985611663416, 0.7918451482432309, 0.6919468100169615, 0.8727284261296239, 0.3102901107372843, 0.5004394431479625]}, "task_prompt": ""}
{"id": "cfa8c3a1-df2f-4d46-9fce-18fc5310fa8c", "fitness": 0.7165928671807024, "name": "RankingDE", "description": "Self-adaptive Differential Evolution with ranking-based mutation and velocity clamping.", "code": "import numpy as np\n\nclass RankingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.velocity_clamping = 0.5  # Clamp velocity to prevent excessive jumps\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Rank the population based on fitness\n        ranked_indices = np.argsort(self.fitness)\n        ranked_pop = self.pop[ranked_indices]\n\n        for i in range(self.pop_size):\n            # Ranking-based Mutation: Use the best individual more often\n            best_idx = ranked_indices[0]  # Index of the best individual in original pop\n            idxs = np.random.choice(self.pop_size, 2, replace=False) # sample two other indices\n            x_r1, x_r2 = ranked_pop[idxs] # get individuals based on ranked population\n\n            # Mutation: More aggressive mutation with clamping\n            mutated_vector = self.pop[i] + self.F * (ranked_pop[0] - self.pop[i]) + self.F * (x_r1 - x_r2)  # Mutate towards the best and difference vector\n            velocity = mutated_vector - self.pop[i]\n            velocity = np.clip(velocity, -self.velocity_clamping * (func.bounds.ub - func.bounds.lb), self.velocity_clamping * (func.bounds.ub - func.bounds.lb))\n            x_mutated = self.pop[i] + velocity\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_mask = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_mask] = x_mutated[crossover_mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr (Simplified adaptation)\n        self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm RankingDE scored 0.717 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive Differential Evolution with ranking-based mutation and velocity clamping.\n# Code: \n```python\nimport numpy as np\n\nclass RankingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.velocity_clamping = 0.5  # Clamp velocity to prevent excessive jumps\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Rank the population based on fitness\n        ranked_indices = np.argsort(self.fitness)\n        ranked_pop = self.pop[ranked_indices]\n\n        for i in range(self.pop_size):\n            # Ranking-based Mutation: Use the best individual more often\n            best_idx = ranked_indices[0]  # Index of the best individual in original pop\n            idxs = np.random.choice(self.pop_size, 2, replace=False) # sample two other indices\n            x_r1, x_r2 = ranked_pop[idxs] # get individuals based on ranked population\n\n            # Mutation: More aggressive mutation with clamping\n            mutated_vector = self.pop[i] + self.F * (ranked_pop[0] - self.pop[i]) + self.F * (x_r1 - x_r2)  # Mutate towards the best and difference vector\n            velocity = mutated_vector - self.pop[i]\n            velocity = np.clip(velocity, -self.velocity_clamping * (func.bounds.ub - func.bounds.lb), self.velocity_clamping * (func.bounds.ub - func.bounds.lb))\n            x_mutated = self.pop[i] + velocity\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_mask = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_mask] = x_mutated[crossover_mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr (Simplified adaptation)\n        self.F = np.clip(np.random.normal(0.5, 0.1), 0.1, 0.9)\n        self.Cr = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.17211095924014286, "generation": 3, "aucs": [0.3994491265546385, 0.8338175477910261, 0.8358311423934355, 0.9242313605540537, 0.8425956813441615, 0.8710025360328323, 0.7329224579585005, 0.8030691867394109, 0.8511050951090764, 0.3894112502681889, 0.9215503184435603, 0.9963640709809296, 0.3726863379792631, 0.8376515288834318, 0.8194007882371499, 0.3329534085421899, 0.7821254620433565, 0.9126307481263805, 0.3715757902185757, 0.5014835054138846]}, "task_prompt": ""}
{"id": "5d1c514d-6a57-488a-ad4c-d5bc6424a269", "fitness": "-inf", "name": "CauchyMutationDifferentialEvolution", "description": "Population-based algorithm with Cauchy mutation and a selection strategy based on fitness rank and diversity.", "code": "import numpy as np\n\nclass CauchyMutationDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5*dim  # Adaptive population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def cauchy_mutation(self, x):\n        return x + self.mutation_factor * np.random.standard_cauchy(size=self.dim)\n\n    def diversity_metric(self, population):\n        \"\"\"Calculates the average Euclidean distance between individuals.\"\"\"\n        distances = []\n        for i in range(len(population)):\n            for j in range(i + 1, len(population)):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        return np.mean(distances) if distances else 0\n\n    def __call__(self, func):\n        if self.population is None:\n            self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                donor_vector = self.cauchy_mutation(self.population[i])\n\n                # Crossover\n                trial_vector = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial_vector[j] = donor_vector[j]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection based on fitness and diversity\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n            \n            # Adaptive population size (simplified)\n            if self.budget > 0:\n                diversity = self.diversity_metric(self.population)\n                if diversity < 0.1 * (self.ub - self.lb): #if diversity is low, increase pop size\n                    self.pop_size = min(2*self.pop_size, 10*self.dim)\n                    new_individuals = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.population), self.dim))\n                    new_fitnesses = np.array([func(x) for x in new_individuals])\n\n                    self.budget -= len(new_fitnesses)\n\n                    self.population = np.concatenate((self.population, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitnesses))\n                    if np.min(new_fitnesses) < self.f_opt:\n                        self.f_opt = np.min(new_fitnesses)\n                        self.x_opt = new_individuals[np.argmin(new_fitnesses)]\n\n                elif diversity > 0.5 * (self.ub - self.lb) and self.pop_size > 5*self.dim: # decrease population size if diversity is high.\n                    self.pop_size = max(self.pop_size // 2, 5*self.dim)\n                    indices_to_keep = np.argsort(self.fitness)[:self.pop_size]\n                    self.population = self.population[indices_to_keep]\n                    self.fitness = self.fitness[indices_to_keep]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "In the code, line 70, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if diversity < 0.1 * (self.ub - self.lb): #if diversity is low, increase pop size", "error": "In the code, line 70, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: if diversity < 0.1 * (self.ub - self.lb): #if diversity is low, increase pop size", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with Cauchy mutation and a selection strategy based on fitness rank and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyMutationDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5*dim  # Adaptive population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n    \n    def cauchy_mutation(self, x):\n        return x + self.mutation_factor * np.random.standard_cauchy(size=self.dim)\n\n    def diversity_metric(self, population):\n        \"\"\"Calculates the average Euclidean distance between individuals.\"\"\"\n        distances = []\n        for i in range(len(population)):\n            for j in range(i + 1, len(population)):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        return np.mean(distances) if distances else 0\n\n    def __call__(self, func):\n        if self.population is None:\n            self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                donor_vector = self.cauchy_mutation(self.population[i])\n\n                # Crossover\n                trial_vector = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        trial_vector[j] = donor_vector[j]\n\n                # Boundary handling\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection based on fitness and diversity\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n            \n            # Adaptive population size (simplified)\n            if self.budget > 0:\n                diversity = self.diversity_metric(self.population)\n                if diversity < 0.1 * (self.ub - self.lb): #if diversity is low, increase pop size\n                    self.pop_size = min(2*self.pop_size, 10*self.dim)\n                    new_individuals = np.random.uniform(self.lb, self.ub, size=(self.pop_size - len(self.population), self.dim))\n                    new_fitnesses = np.array([func(x) for x in new_individuals])\n\n                    self.budget -= len(new_fitnesses)\n\n                    self.population = np.concatenate((self.population, new_individuals))\n                    self.fitness = np.concatenate((self.fitness, new_fitnesses))\n                    if np.min(new_fitnesses) < self.f_opt:\n                        self.f_opt = np.min(new_fitnesses)\n                        self.x_opt = new_individuals[np.argmin(new_fitnesses)]\n\n                elif diversity > 0.5 * (self.ub - self.lb) and self.pop_size > 5*self.dim: # decrease population size if diversity is high.\n                    self.pop_size = max(self.pop_size // 2, 5*self.dim)\n                    indices_to_keep = np.argsort(self.fitness)[:self.pop_size]\n                    self.population = self.population[indices_to_keep]\n                    self.fitness = self.fitness[indices_to_keep]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.17802366635187825, "generation": 3}, "task_prompt": ""}
{"id": "dd3fa9e6-d02a-46a8-bd49-5daea706565e", "fitness": 0.5585708343687448, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with improved parameter adaptation using a memory of successful parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_memory = np.full(memory_size, 0.5)\n        self.Cr_memory = np.full(memory_size, 0.7)\n        self.memory_idx = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Adaptation based on success\n                self.F_memory[self.memory_idx] = self.F\n                self.Cr_memory[self.memory_idx] = self.Cr\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr using memory - weighted average\n        weights = np.arange(1, self.memory_size + 1)\n        weights = weights / np.sum(weights)  # Normalize weights\n\n        self.F = np.clip(np.average(self.F_memory, weights=weights) + 0.1 * np.random.randn(), 0.1, 0.9)\n        self.Cr = np.clip(np.average(self.Cr_memory, weights=weights) + 0.1 * np.random.randn(), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.559 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b74d66b-0db9-480a-8b9a-ff76002d1892"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with improved parameter adaptation using a memory of successful parameters.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, memory_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.memory_size = memory_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_memory = np.full(memory_size, 0.5)\n        self.Cr_memory = np.full(memory_size, 0.7)\n        self.memory_idx = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Adaptation based on success\n                self.F_memory[self.memory_idx] = self.F\n                self.Cr_memory[self.memory_idx] = self.Cr\n                self.memory_idx = (self.memory_idx + 1) % self.memory_size\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr using memory - weighted average\n        weights = np.arange(1, self.memory_size + 1)\n        weights = weights / np.sum(weights)  # Normalize weights\n\n        self.F = np.clip(np.average(self.F_memory, weights=weights) + 0.1 * np.random.randn(), 0.1, 0.9)\n        self.Cr = np.clip(np.average(self.Cr_memory, weights=weights) + 0.1 * np.random.randn(), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.2215250581944042, "generation": 4, "aucs": [0.25026617105830795, 0.3849614662355145, 0.4474103304855843, 0.5958952914311836, 0.6697107730464025, 0.9222058270506546, 0.5612873074812763, 0.36914405375408, 0.30894718471080274, 0.22099951957715513, 0.8749246143576056, 0.9936525846415896, 0.5220613765389428, 0.733742903028339, 0.9085755743224628, 0.8455855170038995, 0.4240098707986425, 0.37867795577104135, 0.2462898286817835, 0.5130685373996282]}, "task_prompt": ""}
{"id": "52bc49f8-cb0d-4a17-96a0-7b849ccbcfcc", "fitness": 0.704404052815564, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with improved parameter adaptation and exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.F_memory = [0.5] * 10\n        self.Cr_memory = [0.9] * 10\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim) # Ensure at least one element is different\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                delta_fitness = self.fitness[i] - f_trial\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    \n                #Adaptation: Update memory based on success\n                self.F_memory[self.memory_index] = self.F\n                self.Cr_memory[self.memory_index] = self.Cr\n                self.memory_index = (self.memory_index + 1) % len(self.F_memory)\n            \n            #Adaptation: Sample from memory\n            self.F = np.random.choice(self.F_memory)\n            self.Cr = np.random.choice(self.Cr_memory)\n            \n            #Ensure F and Cr remain within bounds\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                    \n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with improved parameter adaptation and exploration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.F_memory = [0.5] * 10\n        self.Cr_memory = [0.9] * 10\n        self.memory_index = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)].copy()\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim) # Ensure at least one element is different\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                delta_fitness = self.fitness[i] - f_trial\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n                    \n                #Adaptation: Update memory based on success\n                self.F_memory[self.memory_index] = self.F\n                self.Cr_memory[self.memory_index] = self.Cr\n                self.memory_index = (self.memory_index + 1) % len(self.F_memory)\n            \n            #Adaptation: Sample from memory\n            self.F = np.random.choice(self.F_memory)\n            self.Cr = np.random.choice(self.Cr_memory)\n            \n            #Ensure F and Cr remain within bounds\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n                    \n        return self.f_opt, self.x_opt\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.008705417447784441, "generation": 4, "aucs": [0.2394199260636637, 0.8887579260154334, 0.6931701117090623, 0.19807652413697607, 0.865140559300009, 0.9110765420319992, 0.8480448021937995, 0.8441901345460016, 0.8707365025566202, 0.8678192089271995, 0.9340062521953805, 0.9992579910464553, 0.2727046124495509, 0.8851953870435028, 0.8928354162529798, 0.9106927808197809, 0.6271974437811336, 0.5677649214850544, 0.2570632505348045, 0.5149307632218734]}, "task_prompt": ""}
{"id": "94c3dfc0-912a-4418-83b9-b416270f14f7", "fitness": 0.48282274742335646, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter control and population restart for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Fraction of budget to trigger restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.initial_F = 0.5\n        self.initial_Cr = 0.9\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, self.dim)] = True\n            x_trial[crossover_points] = x_mutated[crossover_points]\n            \n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified Adaptation of F and Cr, with a bias towards initial values\n        self.F = 0.8 * self.F + 0.2 * self.initial_F + 0.01 * np.random.randn()\n        self.Cr = 0.8 * self.Cr + 0.2 * self.initial_Cr + 0.01 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def should_restart(self):\n         return (self.eval_count / self.budget) > self.restart_trigger\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.evolve(func)\n            \n            if self.should_restart():\n                # Introduce diversity by re-initializing the population\n                self.initialize_population(func)\n                self.F = self.initial_F  # Reset F\n                self.Cr = self.initial_Cr  # Reset CR\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.483 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter control and population restart for enhanced exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger  # Fraction of budget to trigger restart\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.initial_F = 0.5\n        self.initial_Cr = 0.9\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, self.dim)] = True\n            x_trial[crossover_points] = x_mutated[crossover_points]\n            \n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified Adaptation of F and Cr, with a bias towards initial values\n        self.F = 0.8 * self.F + 0.2 * self.initial_F + 0.01 * np.random.randn()\n        self.Cr = 0.8 * self.Cr + 0.2 * self.initial_Cr + 0.01 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def should_restart(self):\n         return (self.eval_count / self.budget) > self.restart_trigger\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.evolve(func)\n            \n            if self.should_restart():\n                # Introduce diversity by re-initializing the population\n                self.initialize_population(func)\n                self.F = self.initial_F  # Reset F\n                self.Cr = self.initial_Cr  # Reset CR\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.08204435821847914, "generation": 4, "aucs": [0.11650595159792099, 0.25243896691802037, 0.4539593094663482, 0.9522319797869513, 0.48124251781113214, 0.5190173595150286, 0.3300160598031322, 0.45521938143072915, 0.39632582045467046, 0.39309881467737906, 0.5278051564724926, 0.9907003561186174, 0.31323154301139167, 0.3454962414752967, 0.8492175829548498, 0.5921002165481908, 0.3820438010950492, 0.6280447408563045, 0.18306498328383491, 0.49469416518978815]}, "task_prompt": ""}
{"id": "9e49b3f4-ca60-4db9-b901-d3da95964fac", "fitness": 0.7167297596212729, "name": "ImprovedAdaptiveDE", "description": "Simplified Adaptive DE with improved F/Cr adaptation based on population diversity.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on population diversity\n        if np.std(self.fitness) > 1e-6:  # Check if the population has diversity\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))  # Use Algorithm 2's adaptation\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.05)) # Slightly reduced Cr adaptation\n        else:\n            self.F = 0.5  # Reset to default if population is converging\n            self.Cr = 0.9\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm ImprovedAdaptiveDE scored 0.717 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "crossover", "metadata": {"llm_response": "# Description: Simplified Adaptive DE with improved F/Cr adaptation based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on population diversity\n        if np.std(self.fitness) > 1e-6:  # Check if the population has diversity\n            self.F = 0.5 * (1 + np.random.normal(0, 0.1))  # Use Algorithm 2's adaptation\n            self.Cr = 0.9 * (1 + np.random.normal(0, 0.05)) # Slightly reduced Cr adaptation\n        else:\n            self.F = 0.5  # Reset to default if population is converging\n            self.Cr = 0.9\n\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.059307562888978906, "generation": 4, "aucs": [0.4755353025082564, 0.39276035075993765, 0.8583031280125272, 0.9191268647768802, 0.8181902055465263, 0.7732278683435498, 0.85965948129808, 0.6026461077973962, 0.8677804237543141, 0.8775726844082387, 0.5313783507391835, 0.9997619102054928, 0.29099116407148995, 0.8998655344218007, 0.7832641362677505, 0.9116768995055355, 0.8110138441381385, 0.937901114632157, 0.20916122469243215, 0.5147785965457732]}, "task_prompt": ""}
{"id": "f925d824-577f-46e2-b10e-f21ba2d88743", "fitness": 0.7676733690003336, "name": "SelfAdaptiveDE", "description": "Self-adaptive differential evolution with reduced memory footprint and simplified parameter adaptation.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.Cr = 0.7 + 0.2 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SelfAdaptiveDE scored 0.768 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b74d66b-0db9-480a-8b9a-ff76002d1892"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive differential evolution with reduced memory footprint and simplified parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.Cr = 0.7 + 0.2 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.07047652489168454, "generation": 4, "aucs": [0.45449411672245266, 0.32395606137436705, 0.7595096244867947, 0.9390355057979637, 0.8741814064372224, 0.8545187029679323, 0.7985891982447124, 0.8264154269624931, 0.8649384835126869, 0.8455867795671757, 0.8999949232009401, 0.9959271457286798, 0.3439150260484063, 0.8489908114619817, 0.8997721200016873, 0.8251592153520746, 0.8142558261711903, 0.9089668937818073, 0.7478952605491466, 0.5273648516369572]}, "task_prompt": ""}
{"id": "fdf90637-b0ef-423f-b71c-1b98aa83ba28", "fitness": 0.711970536824649, "name": "AdaptiveDE", "description": "Simplified Adaptive Differential Evolution with self-adaptive population size and simplified parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_factor = pop_factor  # Population size factor relative to dimension\n        self.pop_size = max(10, int(self.pop_factor * self.dim))  # Adaptive population size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.9 + 0.1 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE scored 0.712 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with self-adaptive population size and simplified parameter adaptation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_factor = pop_factor  # Population size factor relative to dimension\n        self.pop_size = max(10, int(self.pop_factor * self.dim))  # Adaptive population size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr or j == j_rand:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.9 + 0.1 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.08178815479617942, "generation": 4, "aucs": [0.38575825504354355, 0.7922646894350709, 0.6952775102295878, 0.9223198934468246, 0.8771440827800687, 0.8903379572719797, 0.4999479364356747, 0.6444856771083036, 0.8612025817888345, 0.18672673495788628, 0.8927630008788514, 0.9983057339192388, 0.5537029714634891, 0.8439220664289728, 0.8403211748393448, 0.893339427588943, 0.7148126361232225, 0.9065469991966773, 0.32614296711836255, 0.5140884404381018]}, "task_prompt": ""}
{"id": "97ab5ead-b15f-4c23-85a5-b1593ea551e7", "fitness": "-inf", "name": "PSO_CMAES", "description": "A population-based algorithm that combines elements of particle swarm optimization with covariance matrix adaptation evolution strategy (CMA-ES) to balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia=0.7, c1=1.4, c2=1.4, cs=0.3, damps=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.cs = cs\n        self.damps = damps  # Damping for step-size adaptation\n        self.mean = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.D = None # Eigenvalues of C, initialized later\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim)) * 0.1 # Smaller initial velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.global_best_index].copy()\n        self.global_best_fitness = self.fitness[self.global_best_index]\n        \n        # CMA-ES Initialization\n        self.mean = self.global_best_position.copy() # initialize CMA-ES mean with current best\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.sigma = 0.1 # overall standard deviation\n        self.pc = np.zeros(self.dim)  # evolution path for C\n        self.ps = np.zeros(self.dim)  # evolution path for sigma\n        self.D = np.ones(self.dim) # Initialize eigenvalues for efficiency\n        self.eigen_decomposition_necessary = True\n\n    def update_cmaes(self, func):\n        c_sigma = self.cs\n        d_sigma = 1 + self.damps * c_sigma\n        mu = self.population_size // 4 # usually lambda / 4\n        weights = np.log(mu+0.5) - np.log(np.arange(1, mu+1)) # weights for recombination\n        weights = weights / np.sum(weights)\n        mueff = np.sum(weights)**2 / np.sum(weights**2)\n        c1 = 2 / ((self.dim+1.3)**2 + mueff)\n        cmu = min(1-c1, 2 * (mueff-2+1/mueff) / ((self.dim+2)**2 + mueff))\n\n        # Sample new population - using cholesky decomposition of C\n        if self.eigen_decomposition_necessary:\n            self.D, self.B = np.linalg.eigh(self.C) # Eigen decomposition\n            self.eigen_decomposition_necessary = False\n\n        z = np.random.normal(0, 1, size=(self.population_size, self.dim))\n        x = self.mean + self.sigma * self.B @ (self.D**0.5 * z).T  # Apply cholesky decomposition by hand\n        x = x.T\n        \n        # Clip the population to the bounds\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n        fitness = np.array([func(xi) for xi in x])\n\n        # Update evolution paths\n        y = (x - self.mean) / self.sigma\n        self.ps = (1-c_sigma) * self.ps + np.sqrt(c_sigma * (2-c_sigma) * mueff) * self.B @ np.mean(z[:mu], axis=0) # Use mean of top mu individuals\n        hsig = np.linalg.norm(self.ps)/np.sqrt(1-(1-c_sigma)**2) / np.sqrt(self.dim) < 1.4 + 2/(self.dim+1)\n        self.pc = (1-c1) * self.pc + hsig * np.sqrt(c1 * (2-c1) * mueff) * np.mean(y[:mu], axis=0) # Use mean of top mu individuals\n\n\n        # Update covariance matrix\n        delta = x[:mu] - self.mean\n        self.C = (1-c1-cmu) * self.C + c1 * (self.pc[:, None] @ self.pc[None, :]) + cmu * np.sum(weights[:, None, None] * (delta[:, :, None] @ delta[:, None, :]), axis=0)\n        \n        self.sigma *= np.exp((c_sigma/d_sigma) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1)) # Adapt step size\n\n        # Update mean\n        sorted_indices = np.argsort(fitness)\n        self.mean = np.sum(weights[:, None] * x[sorted_indices[:mu]], axis=0) # Weighted recombination of top mu individuals\n\n\n        # Enforce symmetry and ensure that C is positive definite\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim)\n\n        # Update global best\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index]\n            self.global_best_position = x[best_index].copy()\n\n        return x, fitness # returning x, fitness for possible PSO integration\n\n\n    def __call__(self, func):\n        self.initialize(func)\n        eval_count = self.population_size # Account for initial evaluations\n        \n        while eval_count < self.budget:\n            remaining_evals = self.budget - eval_count\n            \n            # CMA-ES component - generates a new population and updates its parameters\n            new_population, new_fitness = self.update_cmaes(func)\n            eval_count += self.population_size # new evaluations for CMA-ES population\n            \n            #PSO component - perturb CMA-ES population with PSO-like movements\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                     self.c1 * r1 * (self.personal_best_positions[i] - new_population[i]) +\n                                     self.c2 * r2 * (self.global_best_position - new_population[i]))\n\n                # Update position - use cmaes generated positions as current positions\n                new_population[i] = new_population[i] + self.velocities[i]\n                \n                # Clip the population to the bounds\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the new position only if needed\n                # This check ensures we don't exceed the budget when PSO updates the population\n                if eval_count < self.budget:\n                  new_fitness[i] = func(new_population[i])\n                  eval_count += 1\n                else:\n                    break\n\n            # Update personal best\n            for i in range(self.population_size):\n                if new_fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness[i]\n                    self.personal_best_positions[i] = new_population[i].copy()\n\n            # Update global best\n            if np.min(new_fitness) < self.global_best_fitness:\n                best_index = np.argmin(new_fitness)\n                self.global_best_fitness = new_fitness[best_index]\n                self.global_best_position = new_population[best_index].copy()\n            \n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 4, "feedback": "In the code, line 57, in update_cmaes, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,20) \nOn line: x = self.mean + self.sigma * self.B @ (self.D**0.5 * z).T  # Apply cholesky decomposition by hand", "error": "In the code, line 57, in update_cmaes, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,20) \nOn line: x = self.mean + self.sigma * self.B @ (self.D**0.5 * z).T  # Apply cholesky decomposition by hand", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization with covariance matrix adaptation evolution strategy (CMA-ES) to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, population_size=20, inertia=0.7, c1=1.4, c2=1.4, cs=0.3, damps=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.cs = cs\n        self.damps = damps  # Damping for step-size adaptation\n        self.mean = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.D = None # Eigenvalues of C, initialized later\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.population_size, self.dim)) * 0.1 # Smaller initial velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.global_best_index].copy()\n        self.global_best_fitness = self.fitness[self.global_best_index]\n        \n        # CMA-ES Initialization\n        self.mean = self.global_best_position.copy() # initialize CMA-ES mean with current best\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.sigma = 0.1 # overall standard deviation\n        self.pc = np.zeros(self.dim)  # evolution path for C\n        self.ps = np.zeros(self.dim)  # evolution path for sigma\n        self.D = np.ones(self.dim) # Initialize eigenvalues for efficiency\n        self.eigen_decomposition_necessary = True\n\n    def update_cmaes(self, func):\n        c_sigma = self.cs\n        d_sigma = 1 + self.damps * c_sigma\n        mu = self.population_size // 4 # usually lambda / 4\n        weights = np.log(mu+0.5) - np.log(np.arange(1, mu+1)) # weights for recombination\n        weights = weights / np.sum(weights)\n        mueff = np.sum(weights)**2 / np.sum(weights**2)\n        c1 = 2 / ((self.dim+1.3)**2 + mueff)\n        cmu = min(1-c1, 2 * (mueff-2+1/mueff) / ((self.dim+2)**2 + mueff))\n\n        # Sample new population - using cholesky decomposition of C\n        if self.eigen_decomposition_necessary:\n            self.D, self.B = np.linalg.eigh(self.C) # Eigen decomposition\n            self.eigen_decomposition_necessary = False\n\n        z = np.random.normal(0, 1, size=(self.population_size, self.dim))\n        x = self.mean + self.sigma * self.B @ (self.D**0.5 * z).T  # Apply cholesky decomposition by hand\n        x = x.T\n        \n        # Clip the population to the bounds\n        x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n        fitness = np.array([func(xi) for xi in x])\n\n        # Update evolution paths\n        y = (x - self.mean) / self.sigma\n        self.ps = (1-c_sigma) * self.ps + np.sqrt(c_sigma * (2-c_sigma) * mueff) * self.B @ np.mean(z[:mu], axis=0) # Use mean of top mu individuals\n        hsig = np.linalg.norm(self.ps)/np.sqrt(1-(1-c_sigma)**2) / np.sqrt(self.dim) < 1.4 + 2/(self.dim+1)\n        self.pc = (1-c1) * self.pc + hsig * np.sqrt(c1 * (2-c1) * mueff) * np.mean(y[:mu], axis=0) # Use mean of top mu individuals\n\n\n        # Update covariance matrix\n        delta = x[:mu] - self.mean\n        self.C = (1-c1-cmu) * self.C + c1 * (self.pc[:, None] @ self.pc[None, :]) + cmu * np.sum(weights[:, None, None] * (delta[:, :, None] @ delta[:, None, :]), axis=0)\n        \n        self.sigma *= np.exp((c_sigma/d_sigma) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1)) # Adapt step size\n\n        # Update mean\n        sorted_indices = np.argsort(fitness)\n        self.mean = np.sum(weights[:, None] * x[sorted_indices[:mu]], axis=0) # Weighted recombination of top mu individuals\n\n\n        # Enforce symmetry and ensure that C is positive definite\n        self.C = np.triu(self.C) + np.triu(self.C, 1).T\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = self.C + 1e-8 * np.eye(self.dim)\n\n        # Update global best\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.global_best_fitness:\n            self.global_best_fitness = fitness[best_index]\n            self.global_best_position = x[best_index].copy()\n\n        return x, fitness # returning x, fitness for possible PSO integration\n\n\n    def __call__(self, func):\n        self.initialize(func)\n        eval_count = self.population_size # Account for initial evaluations\n        \n        while eval_count < self.budget:\n            remaining_evals = self.budget - eval_count\n            \n            # CMA-ES component - generates a new population and updates its parameters\n            new_population, new_fitness = self.update_cmaes(func)\n            eval_count += self.population_size # new evaluations for CMA-ES population\n            \n            #PSO component - perturb CMA-ES population with PSO-like movements\n            for i in range(self.population_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.inertia * self.velocities[i] +\n                                     self.c1 * r1 * (self.personal_best_positions[i] - new_population[i]) +\n                                     self.c2 * r2 * (self.global_best_position - new_population[i]))\n\n                # Update position - use cmaes generated positions as current positions\n                new_population[i] = new_population[i] + self.velocities[i]\n                \n                # Clip the population to the bounds\n                new_population[i] = np.clip(new_population[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate the new position only if needed\n                # This check ensures we don't exceed the budget when PSO updates the population\n                if eval_count < self.budget:\n                  new_fitness[i] = func(new_population[i])\n                  eval_count += 1\n                else:\n                    break\n\n            # Update personal best\n            for i in range(self.population_size):\n                if new_fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = new_fitness[i]\n                    self.personal_best_positions[i] = new_population[i].copy()\n\n            # Update global best\n            if np.min(new_fitness) < self.global_best_fitness:\n                best_index = np.argmin(new_fitness)\n                self.global_best_fitness = new_fitness[best_index]\n                self.global_best_position = new_population[best_index].copy()\n            \n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.2258590173302415, "generation": 4}, "task_prompt": ""}
{"id": "fabbf244-36e4-4d5d-bcc2-0a003d27f51a", "fitness": 0.5837234983172619, "name": "EnhancedAdaptiveDE", "description": "Adaptive Differential Evolution with population-wide learning for F and Cr.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_history = []\n        self.Cr_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    \n                self.F_history.append(self.F)\n                self.Cr_history.append(self.Cr)\n\n        # Adapt F and Cr - population wide adaptation inspired by successful parameter settings\n        if self.F_history:\n            self.F = np.mean(self.F_history[-min(len(self.F_history), self.pop_size):]) + 0.1 * np.random.randn()\n            self.Cr = np.mean(self.Cr_history[-min(len(self.Cr_history), self.pop_size):]) + 0.05 * np.random.randn() #keep Cr high\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.3, 1.0) #Lower bound higher to promote crossover\n        else:\n            # If no successful updates, keep the initial values\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.05 * np.random.randn() # keep Cr high\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.3, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.584 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b74d66b-0db9-480a-8b9a-ff76002d1892", "7f70d562-db6f-440b-9f4c-a3593785cfe1"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with population-wide learning for F and Cr.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_history = []\n        self.Cr_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    \n                self.F_history.append(self.F)\n                self.Cr_history.append(self.Cr)\n\n        # Adapt F and Cr - population wide adaptation inspired by successful parameter settings\n        if self.F_history:\n            self.F = np.mean(self.F_history[-min(len(self.F_history), self.pop_size):]) + 0.1 * np.random.randn()\n            self.Cr = np.mean(self.Cr_history[-min(len(self.Cr_history), self.pop_size):]) + 0.05 * np.random.randn() #keep Cr high\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.3, 1.0) #Lower bound higher to promote crossover\n        else:\n            # If no successful updates, keep the initial values\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.05 * np.random.randn() # keep Cr high\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.3, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0019150091751177004, "generation": 4, "aucs": [0.31552240157937117, 0.3822542147971081, 0.4807222339704553, 0.3004063815306314, 0.33405489172307046, 0.8196832567332127, 0.6753773700960968, 0.3488493528698323, 0.2874679494927439, 0.8792688802023217, 0.8639745737989883, 0.9994139215080424, 0.4216345727156958, 0.8957441903862525, 0.8149340136458373, 0.8596640329034952, 0.40570708353194496, 0.7070163030312812, 0.3493960035422994, 0.5333783382865576]}, "task_prompt": ""}
{"id": "331e48ff-9776-4b53-8f25-b73df61a149e", "fitness": 0.5682537328228873, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and jittering to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            # Add jitter to improve exploration\n            jitter = np.random.normal(0, 0.01, self.dim) # small gaussian noise\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3) + jitter\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Adaptive F and Cr - simplified adaptation\n            self.F = np.clip(self.F + 0.01 * np.random.randn(), 0.1, 0.9) # slower changes, simplified bounds\n            self.Cr = np.clip(self.Cr + 0.01 * np.random.randn(), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.568 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and jittering to enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            \n            # Add jitter to improve exploration\n            jitter = np.random.normal(0, 0.01, self.dim) # small gaussian noise\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3) + jitter\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Adaptive F and Cr - simplified adaptation\n            self.F = np.clip(self.F + 0.01 * np.random.randn(), 0.1, 0.9) # slower changes, simplified bounds\n            self.Cr = np.clip(self.Cr + 0.01 * np.random.randn(), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.1013947077999272, "generation": 5, "aucs": [0.27552403761564115, 0.602539437560183, 0.5307836708321296, 0.9127639210135022, 0.25069039790033476, 0.5830420058307078, 0.5245263977190755, 0.48844803277276416, 0.6014078848800716, 0.5359020633033635, 0.8656625850899692, 0.9979945120073318, 0.2909117664056665, 0.5886123536835923, 0.9409730991054087, 0.5555004678050066, 0.44225648204230095, 0.5520174927578052, 0.30558226018991175, 0.5199357879429791]}, "task_prompt": ""}
{"id": "f8cdc4b6-064d-44cd-bbdf-dbcf0213a943", "fitness": 0.0, "name": "SimplifiedAdaptiveDE", "description": "Simplified Adaptive Differential Evolution with smaller population size and exploration-exploitation balance via dynamic parameter adjustment.", "code": "import numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):  # Reduced population size\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.F_history = []\n        self.Cr_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - using history and dynamic adjustment\n        if len(self.F_history) > 10:\n            self.F = 0.5 * (1 + 0.1 * np.random.randn()) # Basic randomness with mean 0.5\n            self.Cr = 0.9 * (1 + 0.05 * np.random.randn()) # basic randomness around 0.9\n        else:\n            self.F = 0.5 # Exploration in beginning\n            self.Cr = 0.9\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        self.F_history.append(self.F)\n        self.Cr_history.append(self.Cr)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm SimplifiedAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive Differential Evolution with smaller population size and exploration-exploitation balance via dynamic parameter adjustment.\n# Code: \n```python\nimport numpy as np\n\nclass SimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):  # Reduced population size\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.F_history = []\n        self.Cr_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - using history and dynamic adjustment\n        if len(self.F_history) > 10:\n            self.F = 0.5 * (1 + 0.1 * np.random.randn()) # Basic randomness with mean 0.5\n            self.Cr = 0.9 * (1 + 0.05 * np.random.randn()) # basic randomness around 0.9\n        else:\n            self.F = 0.5 # Exploration in beginning\n            self.Cr = 0.9\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        self.F_history.append(self.F)\n        self.Cr_history.append(self.Cr)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.10818582879956867, "generation": 5, "aucs": [0]}, "task_prompt": ""}
{"id": "9979e537-c842-474b-8da6-50cf2cc10cf6", "fitness": 0.6867253135872591, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines elements of particle swarm optimization (PSO) and differential evolution (DE), adaptively adjusting parameters based on population performance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.velocities = np.zeros_like(self.pop)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pop[i] - self.pop[i]) + \\\n                                     self.c2 * r2 * (self.best_pos - self.pop[i])\n                \n                new_pos = np.clip(self.pop[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # DE Update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                \n                mutation = x1 + self.f * (x2 - x3)\n                mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        mutation[j] = self.pop[i,j]\n\n                # Evaluate and Update\n                new_fitness = func(mutation)\n                eval_count += 1\n                \n                if new_fitness < self.fitness[i]:\n                    self.pop[i] = mutation\n                    self.fitness[i] = new_fitness\n                    \n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_pos = mutation.copy()\n\n                if eval_count >= self.budget:\n                    break  # Stop if budget is exceeded\n            \n        return self.best_fitness, self.best_pos", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE scored 0.687 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of particle swarm optimization (PSO) and differential evolution (DE), adaptively adjusting parameters based on population performance.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n        self.velocities = np.zeros_like(self.pop)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.pop[i] - self.pop[i]) + \\\n                                     self.c2 * r2 * (self.best_pos - self.pop[i])\n                \n                new_pos = np.clip(self.pop[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # DE Update\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                \n                mutation = x1 + self.f * (x2 - x3)\n                mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        mutation[j] = self.pop[i,j]\n\n                # Evaluate and Update\n                new_fitness = func(mutation)\n                eval_count += 1\n                \n                if new_fitness < self.fitness[i]:\n                    self.pop[i] = mutation\n                    self.fitness[i] = new_fitness\n                    \n                    if new_fitness < self.best_fitness:\n                        self.best_fitness = new_fitness\n                        self.best_pos = mutation.copy()\n\n                if eval_count >= self.budget:\n                    break  # Stop if budget is exceeded\n            \n        return self.best_fitness, self.best_pos\n```", "operator": "random_new", "theta_sampled": 0.26457289138396406, "generation": 5, "aucs": [0.2045045114183609, 0.47491907093736907, 0.7461987260504745, 0.8966173041752481, 0.7611794067932702, 0.809865530494668, 0.6669031009074833, 0.68670979244474, 0.7580381014132043, 0.7686937086826346, 0.8255537526495049, 0.9935546195214677, 0.42833815427416433, 0.699643034124478, 0.9276685623000727, 0.8227446363121693, 0.6097675819049289, 0.8568526625666636, 0.2801846119674184, 0.5165694028068611]}, "task_prompt": ""}
{"id": "e0dff2e6-70b0-45b1-b442-e4bec34c4d62", "fitness": "-inf", "name": "PSO_DE", "description": "A population-based algorithm that combines aspects of Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameter control based on population diversity.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.5, CR_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init  # Cognitive coefficient\n        self.c2_init = c2_init  # Social coefficient\n        self.F_init = F_init  # Mutation factor\n        self.CR_init = CR_init  # Crossover rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_parameters(self):\n          # Adaptive parameter control based on population diversity\n        diversity = np.std(self.population)\n\n        # Adjust parameters based on diversity (example: high diversity -> explore, low diversity -> exploit)\n        self.w = self.w_init * (1 - diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.c1 = self.c1_init + (1 - self.c1_init) * (diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.c2 = self.c2_init + (1 - self.c2_init) * (diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n\n        self.F = self.F_init * (1 + diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.CR = self.CR_init * (1 - diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            self.update_parameters()\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.population[i])\n\n                # DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3) # Mutation\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        v[j] = self.population[i, j] # Crossover\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                f_trial = func(v)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.population[i] = v\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = v.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = v.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 5, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameter control based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.5, CR_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init  # Cognitive coefficient\n        self.c2_init = c2_init  # Social coefficient\n        self.F_init = F_init  # Mutation factor\n        self.CR_init = CR_init  # Crossover rate\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_parameters(self):\n          # Adaptive parameter control based on population diversity\n        diversity = np.std(self.population)\n\n        # Adjust parameters based on diversity (example: high diversity -> explore, low diversity -> exploit)\n        self.w = self.w_init * (1 - diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.c1 = self.c1_init + (1 - self.c1_init) * (diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.c2 = self.c2_init + (1 - self.c2_init) * (diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n\n        self.F = self.F_init * (1 + diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n        self.CR = self.CR_init * (1 - diversity / (np.abs(self.population.max() - self.population.min()) + 1e-8))\n\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            self.update_parameters()\n\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = self.w * self.velocities[i] + \\\n                                     self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) + \\\n                                     self.c2 * r2 * (self.global_best_position - self.population[i])\n\n                # DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3) # Mutation\n\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.CR and j != j_rand:\n                        v[j] = self.population[i, j] # Crossover\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                f_trial = func(v)\n                self.eval_count += 1\n                \n                if f_trial < self.fitness[i]:\n                    self.population[i] = v\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = v.copy()\n\n                        if f_trial < self.global_best_fitness:\n                            self.global_best_fitness = f_trial\n                            self.global_best_position = v.copy()\n\n                if self.eval_count >= self.budget:\n                    break\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.1725843148895509, "generation": 5}, "task_prompt": ""}
{"id": "df6277f9-1d2a-4386-b9a5-14266ddd5211", "fitness": 0.6952354680837464, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with a dynamically adjusted population size based on the problem dimensionality and budget, coupled with self-adaptation of F and Cr parameters.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_multiplier * np.log(dim) * dim) #Dynamically adjust pop size\n        self.pop_size = min(self.pop_size, budget // 2) # Limit pop size to half the budget.\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (Self-Adaptive)\n            self.F = 0.5 + 0.3 * np.random.normal() # Gaussian distribution\n            self.Cr = 0.7 + 0.2 * np.random.normal()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.695 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a dynamically adjusted population size based on the problem dimensionality and budget, coupled with self-adaptation of F and Cr parameters.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(pop_multiplier * np.log(dim) * dim) #Dynamically adjust pop size\n        self.pop_size = min(self.pop_size, budget // 2) # Limit pop size to half the budget.\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (Self-Adaptive)\n            self.F = 0.5 + 0.3 * np.random.normal() # Gaussian distribution\n            self.Cr = 0.7 + 0.2 * np.random.normal()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.03706096548296961, "generation": 5, "aucs": [0.2688403887374561, 0.560213081541529, 0.6862317000620279, 0.8719674420771811, 0.738598554042903, 0.8095578825259717, 0.7179023105455347, 0.6412369929030062, 0.7703933154948266, 0.6926053138141957, 0.8700265944843331, 0.9982923550074483, 0.48804353136136003, 0.7309724548243657, 0.8841591238292827, 0.7863478539059967, 0.6031857735229937, 0.8697216405118955, 0.2198704731114186, 0.6965425793712012]}, "task_prompt": ""}
{"id": "1f0a4118-cce3-4390-a324-52fad1329c87", "fitness": 0.6422250807943878, "name": "PSO_DE", "description": "Population-based algorithm that combines particle swarm optimization with a differential evolution mutation operator to balance exploration and exploitation.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.cr = cr # Crossover rate for DE\n        self.f = f   # Scaling factor for DE\n        self.population = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.gbest_position = None\n        self.gbest_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_position = self.population[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size \n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = x1 + self.f * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Particle Swarm Update\n                velocity = (self.w * (self.population[i] - self.population[i])  #Zero velocity to start with (we can use the DE part instead of the PSO part if we want to)\n                            + self.c1 * np.random.rand() * (self.pbest_positions[i] - self.population[i])\n                            + self.c2 * np.random.rand() * (self.gbest_position - self.population[i]))\n                \n                new_position = u + velocity\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n                new_fitness = func(new_position)\n                eval_count += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.pbest_fitness[i]:\n                        self.pbest_positions[i] = new_position\n                        self.pbest_fitness[i] = new_fitness\n\n                        if new_fitness < self.gbest_fitness:\n                            self.gbest_position = new_position\n                            self.gbest_fitness = new_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.gbest_fitness, self.gbest_position", "configspace": "", "generation": 5, "feedback": "The algorithm PSO_DE scored 0.642 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines particle swarm optimization with a differential evolution mutation operator to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.cr = cr # Crossover rate for DE\n        self.f = f   # Scaling factor for DE\n        self.population = None\n        self.fitness = None\n        self.pbest_positions = None\n        self.pbest_fitness = None\n        self.gbest_position = None\n        self.gbest_fitness = np.inf\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.pbest_positions = self.population.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_position = self.population[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size \n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = x1 + self.f * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        u[j] = v[j]\n\n                # Particle Swarm Update\n                velocity = (self.w * (self.population[i] - self.population[i])  #Zero velocity to start with (we can use the DE part instead of the PSO part if we want to)\n                            + self.c1 * np.random.rand() * (self.pbest_positions[i] - self.population[i])\n                            + self.c2 * np.random.rand() * (self.gbest_position - self.population[i]))\n                \n                new_position = u + velocity\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n\n                new_fitness = func(new_position)\n                eval_count += 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n\n                    if new_fitness < self.pbest_fitness[i]:\n                        self.pbest_positions[i] = new_position\n                        self.pbest_fitness[i] = new_fitness\n\n                        if new_fitness < self.gbest_fitness:\n                            self.gbest_position = new_position\n                            self.gbest_fitness = new_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.gbest_fitness, self.gbest_position\n```", "operator": "random_new", "theta_sampled": 0.04449969178811036, "generation": 5, "aucs": [0.21535386118920097, 0.4522247539238661, 0.6418070422592204, 0.8773789561120906, 0.6363645588548923, 0.7750176964615184, 0.5954060652272561, 0.6215372230671818, 0.70338386634613, 0.6587493622090284, 0.8255167229876782, 0.9998353217483905, 0.32812064931396867, 0.6967727728221893, 0.9154837344661971, 0.7740655839955294, 0.5177147112549778, 0.8339882846896398, 0.24797027927426418, 0.527810169684534]}, "task_prompt": ""}
{"id": "f9d0de6c-0c5f-41ed-854d-57d1c3c9af3e", "fitness": 0.7261094409067586, "name": "AdaptiveDE", "description": "An Adaptive Differential Evolution with per-individual parameter adaptation and simplified adaptation rules.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = np.full(pop_size, 0.5)  # Individual F values\n        self.Cr = np.full(pop_size, 0.9)  # Individual Cr values\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i]\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Parameter Adaptation (individual-based)\n            self.F[i] = 0.5 * (1 + 0.1 * np.random.randn())\n            self.Cr[i] = 0.9 * (1 + 0.05 * np.random.randn())\n            self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n            self.Cr[i] = np.clip(self.Cr[i], 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDE scored 0.726 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "crossover", "metadata": {"llm_response": "# Description: An Adaptive Differential Evolution with per-individual parameter adaptation and simplified adaptation rules.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = np.full(pop_size, 0.5)  # Individual F values\n        self.Cr = np.full(pop_size, 0.9)  # Individual Cr values\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i]\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Parameter Adaptation (individual-based)\n            self.F[i] = 0.5 * (1 + 0.1 * np.random.randn())\n            self.Cr[i] = 0.9 * (1 + 0.05 * np.random.randn())\n            self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n            self.Cr[i] = np.clip(self.Cr[i], 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.11169197078576916, "generation": 5, "aucs": [0.2837224657817594, 0.8611751098712145, 0.713262733112902, 0.9555822076451721, 0.6259754546831164, 0.7894964097453776, 0.8557200405803992, 0.8754067884772818, 0.8825383394458949, 0.25831588871018407, 0.9425720935109171, 0.9905253440727795, 0.5495993813968676, 0.8858012445657473, 0.5968102696366675, 0.9133593601029687, 0.8612259463916714, 0.37988339865273146, 0.7796551126084404, 0.5215612291430788]}, "task_prompt": ""}
{"id": "7feaa8e4-3ffb-4759-8ee8-bc35a9063d78", "fitness": 0.0, "name": "EnhancedSelfAdaptiveDE", "description": "Simplified Self-Adaptive Differential Evolution with population diversity enhancement and reduced parameter tuning.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        F = 0.5 * np.ones(self.pop_size)  # Individual F values\n        Cr = 0.7 * np.ones(self.pop_size) # Individual Cr values\n\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter Adaptation (individual-based)\n                F_i = F[i] + 0.1 * np.random.randn()\n                Cr_i = Cr[i] + 0.05 * np.random.randn()\n                F_i = np.clip(F_i, 0.1, 0.9)\n                Cr_i = np.clip(Cr_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < Cr_i\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n                    F[i] = F_i #update F value\n                    Cr[i] = Cr_i #update Cr value\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    #Diversity Enhancement: if no improvement, perturb the individual slightly\n                    pop[i] = np.clip(pop[i] + 0.01 * np.random.randn(self.dim), func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i]) #re-evaluate fitness\n                    self.eval_count +=1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Self-Adaptive Differential Evolution with population diversity enhancement and reduced parameter tuning.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        F = 0.5 * np.ones(self.pop_size)  # Individual F values\n        Cr = 0.7 * np.ones(self.pop_size) # Individual Cr values\n\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Parameter Adaptation (individual-based)\n                F_i = F[i] + 0.1 * np.random.randn()\n                Cr_i = Cr[i] + 0.05 * np.random.randn()\n                F_i = np.clip(F_i, 0.1, 0.9)\n                Cr_i = np.clip(Cr_i, 0.1, 1.0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + F_i * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < Cr_i\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n                    F[i] = F_i #update F value\n                    Cr[i] = Cr_i #update Cr value\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                else:\n                    #Diversity Enhancement: if no improvement, perturb the individual slightly\n                    pop[i] = np.clip(pop[i] + 0.01 * np.random.randn(self.dim), func.bounds.lb, func.bounds.ub)\n                    fitness[i] = func(pop[i]) #re-evaluate fitness\n                    self.eval_count +=1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.03806110494933809, "generation": 5, "aucs": [0]}, "task_prompt": ""}
{"id": "30b94bb5-a729-4428-bc24-9870f6c3270a", "fitness": 0.0, "name": "AdaptiveDE", "description": "Simplified Adaptive DE with increased population diversity and reduced parameter adaptation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, self.dim)] = True\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength, only adapt probabilistically\n        if np.random.rand() < 0.1:\n             self.F = 0.5 * (1 + 0.05 * np.random.randn())\n             self.F = np.clip(self.F, 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = 0.7 * (1 + 0.025 * np.random.randn())\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Adaptive DE with increased population diversity and reduced parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=30):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(crossover_points):\n                crossover_points[np.random.randint(0, self.dim)] = True\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength, only adapt probabilistically\n        if np.random.rand() < 0.1:\n             self.F = 0.5 * (1 + 0.05 * np.random.randn())\n             self.F = np.clip(self.F, 0.1, 0.9)\n        if np.random.rand() < 0.1:\n            self.Cr = 0.7 * (1 + 0.025 * np.random.randn())\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.04164116424999815, "generation": 6, "aucs": [0]}, "task_prompt": ""}
{"id": "7bc316fe-f8c9-4342-9940-653f25ff74b4", "fitness": "-inf", "name": "AdaptiveCMAES", "description": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) with dynamic population size adjustment based on success rate and simplified update rules.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_ratio = mu_ratio\n        self.pop_size = int(4 + 3 * np.log(self.dim))  # Initial population size\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n        success_rate_history = []\n\n        while eval_count < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            x = mean + sigma * z\n            f = np.array([func(xi) if eval_count + i < self.budget else np.inf for i, xi in enumerate(x)])\n            eval_count += self.pop_size\n            \n            if np.any(np.isinf(f)): # handle exceeding the budget\n                f = f[f != np.inf]\n                x = x[:len(f)]\n                self.pop_size = len(f)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                if self.mu <= 0:\n                    break # cannot proceed\n\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n                self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            f_sorted = f[idx]\n\n            if f_sorted[0] < f_opt:\n                f_opt = f_sorted[0]\n                x_opt = x_sorted[0]\n\n            mean_diff = np.sum(self.weights[:, None] * (x_sorted[:self.mu] - mean), axis=0)\n            mean = mean + mean_diff\n\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * mean_diff / sigma\n            \n            success_rate = np.linalg.norm(ps) / self.chiN\n            success_rate_history.append(success_rate)\n            \n            C = (1-self.cs) * C + self.cs * np.outer(ps,ps)\n            \n            sigma = sigma * np.exp((self.cs/self.damps)*(success_rate-1))\n            \n            # Dynamic population size adjustment\n            if len(success_rate_history) > 10:\n                recent_success_rate = np.mean(success_rate_history[-10:])\n                if recent_success_rate > 1.1:\n                    self.pop_size = min(self.pop_size * 1.1, self.budget)  # Increase population size\n                    self.mu = int(self.pop_size * self.mu_ratio)\n                elif recent_success_rate < 0.9:\n                    self.pop_size = max(int(self.pop_size * 0.9), 2)  # Decrease population size\n                    self.mu = int(self.pop_size * self.mu_ratio)\n\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n                self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        return f_opt, x_opt", "configspace": "", "generation": 6, "feedback": "In the code, line 4233, in numpy.random.mtrand.RandomState.multivariate_normal, the following error occurred:\nTypeError: 'float' object is unsliceable", "error": "In the code, line 4233, in numpy.random.mtrand.RandomState.multivariate_normal, the following error occurred:\nTypeError: 'float' object is unsliceable", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive covariance matrix adaptation evolution strategy (CMA-ES) with dynamic population size adjustment based on success rate and simplified update rules.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_ratio=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_ratio = mu_ratio\n        self.pop_size = int(4 + 3 * np.log(self.dim))  # Initial population size\n        self.mu = int(self.pop_size * self.mu_ratio)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        f_opt = np.inf\n        x_opt = None\n        eval_count = 0\n        success_rate_history = []\n\n        while eval_count < self.budget:\n            z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            x = mean + sigma * z\n            f = np.array([func(xi) if eval_count + i < self.budget else np.inf for i, xi in enumerate(x)])\n            eval_count += self.pop_size\n            \n            if np.any(np.isinf(f)): # handle exceeding the budget\n                f = f[f != np.inf]\n                x = x[:len(f)]\n                self.pop_size = len(f)\n                self.mu = int(self.pop_size * self.mu_ratio)\n                if self.mu <= 0:\n                    break # cannot proceed\n\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n                self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n\n            idx = np.argsort(f)\n            x_sorted = x[idx]\n            f_sorted = f[idx]\n\n            if f_sorted[0] < f_opt:\n                f_opt = f_sorted[0]\n                x_opt = x_sorted[0]\n\n            mean_diff = np.sum(self.weights[:, None] * (x_sorted[:self.mu] - mean), axis=0)\n            mean = mean + mean_diff\n\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * mean_diff / sigma\n            \n            success_rate = np.linalg.norm(ps) / self.chiN\n            success_rate_history.append(success_rate)\n            \n            C = (1-self.cs) * C + self.cs * np.outer(ps,ps)\n            \n            sigma = sigma * np.exp((self.cs/self.damps)*(success_rate-1))\n            \n            # Dynamic population size adjustment\n            if len(success_rate_history) > 10:\n                recent_success_rate = np.mean(success_rate_history[-10:])\n                if recent_success_rate > 1.1:\n                    self.pop_size = min(self.pop_size * 1.1, self.budget)  # Increase population size\n                    self.mu = int(self.pop_size * self.mu_ratio)\n                elif recent_success_rate < 0.9:\n                    self.pop_size = max(int(self.pop_size * 0.9), 2)  # Decrease population size\n                    self.mu = int(self.pop_size * self.mu_ratio)\n\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1)/(self.dim + 1)) - 1) + self.cs\n                self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        return f_opt, x_opt\n```", "operator": "random_new", "theta_sampled": 0.14877763180546258, "generation": 6}, "task_prompt": ""}
{"id": "8ec04375-0eb5-4a26-995f-5a5a46b5fd1b", "fitness": 0.0, "name": "AdaptiveDEArchive", "description": "Adaptive Differential Evolution with a population archive and a simplified adaptation scheme for F and Cr.", "code": "import numpy as np\n\nclass AdaptiveDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = None\n        self.archive_fitness = None\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        # Initialize archive\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        self.archive_fitness = np.array([func(x) for x in self.archive])\n        self.eval_count += self.archive_size\n\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation - use archive as one of the parents\n            if np.random.rand() < 0.1:  # 10% chance to use archive\n                idx_archive = np.random.choice(self.archive_size)\n                x_r1 = self.archive[idx_archive]\n            else:\n                idxs = np.random.choice(self.pop_size, 1, replace=False)\n                x_r1 = self.pop[idxs[0]]\n\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = self.pop[i] + self.F * (x_r1 - x_r2) + self.F*(self.pop[i]-x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update population\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                # Update archive\n                if f_trial < np.max(self.archive_fitness):\n                    worst_idx = np.argmax(self.archive_fitness)\n                    self.archive[worst_idx] = x_trial\n                    self.archive_fitness[worst_idx] = f_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveDEArchive scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b74d66b-0db9-480a-8b9a-ff76002d1892"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with a population archive and a simplified adaptation scheme for F and Cr.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEArchive:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.archive = None\n        self.archive_fitness = None\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n        # Initialize archive\n        self.archive = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.archive_size, self.dim))\n        self.archive_fitness = np.array([func(x) for x in self.archive])\n        self.eval_count += self.archive_size\n\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation - use archive as one of the parents\n            if np.random.rand() < 0.1:  # 10% chance to use archive\n                idx_archive = np.random.choice(self.archive_size)\n                x_r1 = self.archive[idx_archive]\n            else:\n                idxs = np.random.choice(self.pop_size, 1, replace=False)\n                x_r1 = self.pop[idxs[0]]\n\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x_r2, x_r3 = self.pop[idxs]\n\n            x_mutated = self.pop[i] + self.F * (x_r1 - x_r2) + self.F*(self.pop[i]-x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Update population\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n                # Update archive\n                if f_trial < np.max(self.archive_fitness):\n                    worst_idx = np.argmax(self.archive_fitness)\n                    self.archive[worst_idx] = x_trial\n                    self.archive_fitness[worst_idx] = f_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0024485063774555022, "generation": 6, "aucs": [0]}, "task_prompt": ""}
{"id": "29a651ca-87aa-438c-926c-a9a9ab6d57fe", "fitness": 0.0, "name": "ImprovedSimplifiedAdaptiveDE", "description": "A simplified Differential Evolution with adaptive parameters and periodic population rejuvenation to escape local optima.", "code": "import numpy as np\n\nclass ImprovedSimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, refresh_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = F\n        self.Cr = Cr\n        self.refresh_interval = refresh_interval  # Added population refresh interval\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def refresh_population(self, func):\n        # Replace a portion of the population with new random solutions\n        num_refresh = self.pop_size // 4  # Refresh 25% of the population\n        idxs_to_refresh = np.random.choice(self.pop_size, num_refresh, replace=False)\n        self.pop[idxs_to_refresh] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_refresh, self.dim))\n        self.fitness[idxs_to_refresh] = np.array([func(x) for x in self.pop[idxs_to_refresh]])\n        self.eval_count += num_refresh\n        \n        # Update optimal solution if necessary\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count % self.refresh_interval == 0 and self.eval_count < self.budget:\n                self.refresh_population(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm ImprovedSimplifiedAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["9b74d66b-0db9-480a-8b9a-ff76002d1892"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified Differential Evolution with adaptive parameters and periodic population rejuvenation to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedSimplifiedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, refresh_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = F\n        self.Cr = Cr\n        self.refresh_interval = refresh_interval  # Added population refresh interval\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = 0.7 + 0.2 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def refresh_population(self, func):\n        # Replace a portion of the population with new random solutions\n        num_refresh = self.pop_size // 4  # Refresh 25% of the population\n        idxs_to_refresh = np.random.choice(self.pop_size, num_refresh, replace=False)\n        self.pop[idxs_to_refresh] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_refresh, self.dim))\n        self.fitness[idxs_to_refresh] = np.array([func(x) for x in self.pop[idxs_to_refresh]])\n        self.eval_count += num_refresh\n        \n        # Update optimal solution if necessary\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n            if self.eval_count % self.refresh_interval == 0 and self.eval_count < self.budget:\n                self.refresh_population(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.09132228949251554, "generation": 6, "aucs": [0]}, "task_prompt": ""}
{"id": "64d8df1b-f91d-4c42-ac38-d3067877fc4d", "fitness": "-inf", "name": "AdaptiveRadiusSearch", "description": "An adaptive sampling algorithm that focuses sampling near the best solutions found so far, adjusting the sampling radius based on function value improvement.", "code": "import numpy as np\n\nclass AdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_radius = initial_radius\n        self.radius = initial_radius\n        self.shrink_factor = 0.9\n        self.expand_factor = 1.1\n        self.min_radius = 1e-3\n        self.success_history = []\n        self.success_threshold = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub) # Initialize at a random point\n        self.f_opt = func(self.x_opt)\n        self.budget -= 1\n        \n        for i in range(self.budget):\n            # Sample around the current best solution\n            x_new = self.x_opt + np.random.uniform(-self.radius, self.radius, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # Keep within bounds\n            \n            f_new = func(x_new)\n            \n\n            if f_new < self.f_opt:\n                # Improvement: Update best solution and shrink the radius\n                self.f_opt = f_new\n                self.x_opt = x_new\n                self.radius = max(self.radius * self.shrink_factor, self.min_radius) # Shrink radius\n                self.success_history.append(1)\n\n            else:\n                # No improvement: Expand the radius\n                self.radius = self.radius * self.expand_factor # Expand radius\n                self.success_history.append(0)\n            \n            if len(self.success_history) > 100:\n                self.success_history = self.success_history[-100:] # Keep a window\n            \n            # Adaptive adjustment of radius\n            success_rate = np.mean(self.success_history)\n            \n            if success_rate > self.success_threshold:\n                self.radius *= self.shrink_factor\n            elif success_rate < (1 - self.success_threshold):\n                self.radius *= self.expand_factor\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "In the code, line 1179, in numpy.random.mtrand.RandomState.uniform, the following error occurred:\nOverflowError: Range exceeds valid bounds", "error": "In the code, line 1179, in numpy.random.mtrand.RandomState.uniform, the following error occurred:\nOverflowError: Range exceeds valid bounds", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive sampling algorithm that focuses sampling near the best solutions found so far, adjusting the sampling radius based on function value improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_radius = initial_radius\n        self.radius = initial_radius\n        self.shrink_factor = 0.9\n        self.expand_factor = 1.1\n        self.min_radius = 1e-3\n        self.success_history = []\n        self.success_threshold = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(func.bounds.lb, func.bounds.ub) # Initialize at a random point\n        self.f_opt = func(self.x_opt)\n        self.budget -= 1\n        \n        for i in range(self.budget):\n            # Sample around the current best solution\n            x_new = self.x_opt + np.random.uniform(-self.radius, self.radius, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # Keep within bounds\n            \n            f_new = func(x_new)\n            \n\n            if f_new < self.f_opt:\n                # Improvement: Update best solution and shrink the radius\n                self.f_opt = f_new\n                self.x_opt = x_new\n                self.radius = max(self.radius * self.shrink_factor, self.min_radius) # Shrink radius\n                self.success_history.append(1)\n\n            else:\n                # No improvement: Expand the radius\n                self.radius = self.radius * self.expand_factor # Expand radius\n                self.success_history.append(0)\n            \n            if len(self.success_history) > 100:\n                self.success_history = self.success_history[-100:] # Keep a window\n            \n            # Adaptive adjustment of radius\n            success_rate = np.mean(self.success_history)\n            \n            if success_rate > self.success_threshold:\n                self.radius *= self.shrink_factor\n            elif success_rate < (1 - self.success_threshold):\n                self.radius *= self.expand_factor\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.20774122697796496, "generation": 6}, "task_prompt": ""}
{"id": "0a78a8fc-74cd-454e-be68-4d87d2ff4a95", "fitness": 0.7640327335389611, "name": "ImprovedAdaptiveDE", "description": "Simplified Adaptive DE with stochastic crossover and reduced adaptation strength.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover - using stochastic crossover from Algorithm 2\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength, same as Algorithm 1\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        self.Cr = 0.9 * (1 + 0.05 * np.random.randn())\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm ImprovedAdaptiveDE scored 0.764 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "9b74d66b-0db9-480a-8b9a-ff76002d1892"], "operator": "crossover", "metadata": {"llm_response": "# Description: Simplified Adaptive DE with stochastic crossover and reduced adaptation strength.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover - using stochastic crossover from Algorithm 2\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength, same as Algorithm 1\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        self.Cr = 0.9 * (1 + 0.05 * np.random.randn())\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.09936384703903685, "generation": 6, "aucs": [0.25658236708117066, 0.21744112850084318, 0.7912933358801999, 0.9564586516385966, 0.8962563823773935, 0.905618368930035, 0.8485109097503132, 0.7588113450882986, 0.9059412360003056, 0.8560875062513601, 0.9437487108586121, 0.9990375387882918, 0.30233513860568806, 0.8886524371309438, 0.9198361122656527, 0.9116354199716332, 0.8580358348081736, 0.9388639504842216, 0.5869259237368138, 0.5385823726306711]}, "task_prompt": ""}
{"id": "b5d8de1c-5879-4679-9004-611e2445706a", "fitness": "-inf", "name": "HybridPSO_DE", "description": "A population-based algorithm combining features of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init # Cognitive coefficient\n        self.c2_init = c2_init # Social coefficient\n        self.F_init = F_init  # DE mutation factor\n        self.CR_init = CR_init # DE crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Adaptive parameter settings\n        w = self.w_init\n        c1 = self.c1_init\n        c2 = self.c2_init\n        F = self.F_init\n        CR = self.CR_init\n        \n        def calculate_diversity(pop):\n            centroid = np.mean(pop, axis=0)\n            distances = np.linalg.norm(pop - centroid, axis=1)\n            diversity = np.mean(distances)\n            return diversity\n\n\n        while self.budget > 0:\n            diversity = calculate_diversity(population)\n\n            # Parameter adaptation based on diversity\n            w = self.w_init * (1 - diversity / (self.ub - self.lb))\n            c1 = self.c1_init + diversity / (self.ub - self.lb)\n            c2 = self.c2_init - diversity / (self.ub - self.lb)\n            F = self.F_init + diversity / (self.ub - self.lb)\n            CR = self.CR_init - diversity / (self.ub - self.lb)\n            c1 = np.clip(c1, 0.5, 3.5)\n            c2 = np.clip(c2, 0.5, 3.5)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                # PSO update\n                velocities[i] = w * velocities[i] + \\\n                                c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                population[i] = population[i] + velocities[i]\n\n                # DE update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[r1] + F * (population[r2] - population[r3])\n                \n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                # Clip to bounds\n                population[i] = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(population[i])\n                self.budget -= 1\n\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position", "configspace": "", "generation": 6, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm combining features of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_init=0.9, c1_init=2.0, c2_init=2.0, F_init=0.8, CR_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Inertia weight\n        self.c1_init = c1_init # Cognitive coefficient\n        self.c2_init = c2_init # Social coefficient\n        self.F_init = F_init  # DE mutation factor\n        self.CR_init = CR_init # DE crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Adaptive parameter settings\n        w = self.w_init\n        c1 = self.c1_init\n        c2 = self.c2_init\n        F = self.F_init\n        CR = self.CR_init\n        \n        def calculate_diversity(pop):\n            centroid = np.mean(pop, axis=0)\n            distances = np.linalg.norm(pop - centroid, axis=1)\n            diversity = np.mean(distances)\n            return diversity\n\n\n        while self.budget > 0:\n            diversity = calculate_diversity(population)\n\n            # Parameter adaptation based on diversity\n            w = self.w_init * (1 - diversity / (self.ub - self.lb))\n            c1 = self.c1_init + diversity / (self.ub - self.lb)\n            c2 = self.c2_init - diversity / (self.ub - self.lb)\n            F = self.F_init + diversity / (self.ub - self.lb)\n            CR = self.CR_init - diversity / (self.ub - self.lb)\n            c1 = np.clip(c1, 0.5, 3.5)\n            c2 = np.clip(c2, 0.5, 3.5)\n            F = np.clip(F, 0.1, 1.0)\n            CR = np.clip(CR, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                # PSO update\n                velocities[i] = w * velocities[i] + \\\n                                c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n\n                population[i] = population[i] + velocities[i]\n\n                # DE update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                mutant = population[r1] + F * (population[r2] - population[r3])\n                \n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial_vector[j] = mutant[j]\n\n                # Clip to bounds\n                population[i] = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(population[i])\n                self.budget -= 1\n\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return global_best_fitness, global_best_position\n```", "operator": "random_new", "theta_sampled": 0.051802952926173, "generation": 6}, "task_prompt": ""}
{"id": "609abcf3-60fd-43a8-b0c8-3da88ce3c780", "fitness": 0.23213099207998558, "name": "AdaptiveShrinkingEvolution", "description": "Population-based algorithm with a shrinking search space and adaptive mutation based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveShrinkingEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor  # Adjusts the rate of search space shrinking\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within the current search space\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        mutation_scale = 0.1 * (self.ub - self.lb) # Adaptive Mutation Scaling\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Adaptively scaled Gaussian mutation. Scale decreases with budget exhaustion.\n                mutation = mutation_scale * np.random.normal(0, 1, size=self.dim)\n                mutated_x = population[i] + mutation\n                mutated_x = np.clip(mutated_x, self.lb, self.ub) # Clipping\n\n                f_mutated = func(mutated_x)\n                self.budget -= 1\n\n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_x\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_x\n\n            # Shrink Search Space based on current best\n            self.lb = np.maximum(self.lb, self.x_opt - self.shrink_factor * (self.ub - self.lb) / 2)\n            self.ub = np.minimum(self.ub, self.x_opt + self.shrink_factor * (self.ub - self.lb) / 2)\n\n            # Limit the shrinking to avoid extremely small search spaces\n            width = self.ub - self.lb\n            if np.any(width < 1e-6):\n                break\n            \n            #Update mutation scale\n            mutation_scale = 0.1 * (self.ub - self.lb)\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveShrinkingEvolution scored 0.232 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a shrinking search space and adaptive mutation based on fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveShrinkingEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor  # Adjusts the rate of search space shrinking\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population within the current search space\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        mutation_scale = 0.1 * (self.ub - self.lb) # Adaptive Mutation Scaling\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Adaptively scaled Gaussian mutation. Scale decreases with budget exhaustion.\n                mutation = mutation_scale * np.random.normal(0, 1, size=self.dim)\n                mutated_x = population[i] + mutation\n                mutated_x = np.clip(mutated_x, self.lb, self.ub) # Clipping\n\n                f_mutated = func(mutated_x)\n                self.budget -= 1\n\n                if f_mutated < fitness[i]:\n                    fitness[i] = f_mutated\n                    population[i] = mutated_x\n\n                    if f_mutated < self.f_opt:\n                        self.f_opt = f_mutated\n                        self.x_opt = mutated_x\n\n            # Shrink Search Space based on current best\n            self.lb = np.maximum(self.lb, self.x_opt - self.shrink_factor * (self.ub - self.lb) / 2)\n            self.ub = np.minimum(self.ub, self.x_opt + self.shrink_factor * (self.ub - self.lb) / 2)\n\n            # Limit the shrinking to avoid extremely small search spaces\n            width = self.ub - self.lb\n            if np.any(width < 1e-6):\n                break\n            \n            #Update mutation scale\n            mutation_scale = 0.1 * (self.ub - self.lb)\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.20734111834640584, "generation": 6, "aucs": [0.11997026386868181, 0.19432551810462606, 0.2626985622101141, 0.1473888525293945, 0.18469597100377033, 0.2201724021664868, 0.24561782008831212, 0.2149546981191527, 0.19942404050334073, 0.17270041594731234, 0.28670559480053304, 0.28933736166676227, 0.2363141408246101, 0.1971072163983868, 0.13423346223417099, 0.33507386137851836, 0.2795227281213656, 0.2483329455001314, 0.21603728732789385, 0.4580066988061482]}, "task_prompt": ""}
{"id": "fe798a7f-c55e-44e7-93ef-43e56627fa73", "fitness": 0.08230826416921738, "name": "DynDE_LS", "description": "A population-based algorithm with dynamic mutation strength and a local search component, focusing on exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynDE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, ls_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR\n        self.ls_iters = ls_iters # number of local search iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0  # Track function evaluations\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals += self.pop_size\n\n        # Local search helper function\n        def local_search(x, f, iters):\n            x_curr = x.copy()\n            f_curr = f\n            for _ in range(iters):\n                x_new = x_curr + np.random.normal(0, 0.1, size=self.dim)  # Small random perturbation\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) #Respect boundaries\n                f_new = func(x_new)\n                self.evals += 1\n                if f_new < f_curr:\n                    f_curr = f_new\n                    x_curr = x_new\n            return x_curr, f_curr\n\n\n        while self.evals < self.budget:\n            # Adaptive F\n            F = self.F * np.random.uniform(0.5, 1.5)\n            F = np.clip(F, 0.1, 1.0)  # Clip to reasonable range\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  break\n\n                # Differential Evolution mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mut = population[i] + F * (x_r2 - x_r3)\n                x_mut = np.clip(x_mut, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                x_trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mut[j]\n\n                # Evaluate trial vector\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = x_trial\n                    fitness[i] = f_trial\n\n                    #Local search around improved solutions\n                    population[i], fitness[i] = local_search(population[i], fitness[i], self.ls_iters)\n\n\n\n                # Update optimal solution\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm DynDE_LS scored 0.082 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with dynamic mutation strength and a local search component, focusing on exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass DynDE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, ls_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR\n        self.ls_iters = ls_iters # number of local search iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0  # Track function evaluations\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals += self.pop_size\n\n        # Local search helper function\n        def local_search(x, f, iters):\n            x_curr = x.copy()\n            f_curr = f\n            for _ in range(iters):\n                x_new = x_curr + np.random.normal(0, 0.1, size=self.dim)  # Small random perturbation\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) #Respect boundaries\n                f_new = func(x_new)\n                self.evals += 1\n                if f_new < f_curr:\n                    f_curr = f_new\n                    x_curr = x_new\n            return x_curr, f_curr\n\n\n        while self.evals < self.budget:\n            # Adaptive F\n            F = self.F * np.random.uniform(0.5, 1.5)\n            F = np.clip(F, 0.1, 1.0)  # Clip to reasonable range\n\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                  break\n\n                # Differential Evolution mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mut = population[i] + F * (x_r2 - x_r3)\n                x_mut = np.clip(x_mut, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Crossover\n                x_trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mut[j]\n\n                # Evaluate trial vector\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    population[i] = x_trial\n                    fitness[i] = f_trial\n\n                    #Local search around improved solutions\n                    population[i], fitness[i] = local_search(population[i], fitness[i], self.ls_iters)\n\n\n\n                # Update optimal solution\n                if fitness[i] < self.f_opt:\n                    self.f_opt = fitness[i]\n                    self.x_opt = population[i]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.08482268745565699, "generation": 7, "aucs": [0.16461652833843476, 0]}, "task_prompt": ""}
{"id": "ef34aa8d-512b-42e2-a725-50904b7e455b", "fitness": 0.7484281069327546, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and population diversity maintenance.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            cross_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            x_trial[cross_points] = x_mutated[cross_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive F and Cr - simplified adaptation with inertia\n        success_indices = self.fitness < np.mean(self.fitness)\n        if np.any(success_indices):\n             self.F = 0.5 * self.F + 0.5 * np.random.uniform(0.3, 0.9)\n             self.Cr = 0.5 * self.Cr + 0.5 * np.random.uniform(0.2, 1.0)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and population diversity maintenance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            cross_points = np.random.rand(self.dim) < self.Cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            x_trial[cross_points] = x_mutated[cross_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive F and Cr - simplified adaptation with inertia\n        success_indices = self.fitness < np.mean(self.fitness)\n        if np.any(success_indices):\n             self.F = 0.5 * self.F + 0.5 * np.random.uniform(0.3, 0.9)\n             self.Cr = 0.5 * self.Cr + 0.5 * np.random.uniform(0.2, 1.0)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.07706077204521407, "generation": 7, "aucs": [0.372427853347282, 0.48004754264064176, 0.8056211431779045, 0.8892860404052246, 0.8426446960601442, 0.8833534316065059, 0.7740023428724161, 0.7705443842293929, 0.8307032062520342, 0.755244140050801, 0.8770443693917044, 0.9811941319472348, 0.4361780745235261, 0.8206145171235965, 0.9349495190303352, 0.8722130387684266, 0.7211707306549634, 0.8966070828517017, 0.4873347364387035, 0.5373811572825555]}, "task_prompt": ""}
{"id": "74fb5b16-035b-490f-9135-fdbf8fc1c9da", "fitness": "-inf", "name": "StochasticRankingLocalSearch", "description": "A population-based algorithm with stochastic ranking and local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass StochasticRankingLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, p_crossover=0.9, p_mutation=0.1, ls_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.p_crossover = p_crossover\n        self.p_mutation = p_mutation\n        self.ls_iterations = ls_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.eval_count = 0\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.eval_count < self.budget:\n            # Selection & Crossover\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                # Binary tournament selection with stochastic ranking\n                p1_idx = np.random.randint(self.pop_size)\n                p2_idx = np.random.randint(self.pop_size)\n\n                if np.random.rand() < 0.45 or self.fitness[p1_idx] < self.fitness[p2_idx]: #Stochastic Ranking\n                    parent1 = self.population[p1_idx]\n                    parent1_fitness = self.fitness[p1_idx]\n                else:\n                    parent1 = self.population[p2_idx]\n                    parent1_fitness = self.fitness[p2_idx]\n\n                p1_idx = np.random.randint(self.pop_size)\n                p2_idx = np.random.randint(self.pop_size)\n                if np.random.rand() < 0.45 or self.fitness[p1_idx] < self.fitness[p2_idx]: #Stochastic Ranking\n                    parent2 = self.population[p1_idx]\n                    parent2_fitness = self.fitness[p1_idx]\n                else:\n                    parent2 = self.population[p2_idx]\n                    parent2_fitness = self.fitness[p2_idx]\n\n                # Crossover\n                if np.random.rand() < self.p_crossover:\n                    crossover_point = np.random.randint(1, self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1.copy()\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.p_mutation:\n                        child[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n\n                # Local Search\n                best_child = child.copy()\n                best_child_fitness = np.inf\n                for _ in range(self.ls_iterations):\n                    neighbor = child + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    neighbor_fitness = func(neighbor)\n                    self.eval_count += 1\n\n                    if neighbor_fitness < best_child_fitness:\n                        best_child = neighbor\n                        best_child_fitness = neighbor_fitness\n                    \n                    if self.eval_count >= self.budget:\n                        break\n                \n                if best_child_fitness < np.inf:\n                  new_population.append(best_child)\n                  new_fitness.append(best_child_fitness)\n\n                  if best_child_fitness < self.f_opt:\n                      self.f_opt = best_child_fitness\n                      self.x_opt = best_child\n            \n            if len(new_population) == 0:\n                break; #Terminate if no new samples were added\n\n\n            self.population[:len(new_population)] = np.array(new_population)\n            self.fitness[:len(new_fitness)] = np.array(new_fitness)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with stochastic ranking and local search to balance exploration and exploitation.\n\n# Code: \n```python\nimport numpy as np\n\nclass StochasticRankingLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, p_crossover=0.9, p_mutation=0.1, ls_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.p_crossover = p_crossover\n        self.p_mutation = p_mutation\n        self.ls_iterations = ls_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.eval_count = 0\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.eval_count < self.budget:\n            # Selection & Crossover\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                # Binary tournament selection with stochastic ranking\n                p1_idx = np.random.randint(self.pop_size)\n                p2_idx = np.random.randint(self.pop_size)\n\n                if np.random.rand() < 0.45 or self.fitness[p1_idx] < self.fitness[p2_idx]: #Stochastic Ranking\n                    parent1 = self.population[p1_idx]\n                    parent1_fitness = self.fitness[p1_idx]\n                else:\n                    parent1 = self.population[p2_idx]\n                    parent1_fitness = self.fitness[p2_idx]\n\n                p1_idx = np.random.randint(self.pop_size)\n                p2_idx = np.random.randint(self.pop_size)\n                if np.random.rand() < 0.45 or self.fitness[p1_idx] < self.fitness[p2_idx]: #Stochastic Ranking\n                    parent2 = self.population[p1_idx]\n                    parent2_fitness = self.fitness[p1_idx]\n                else:\n                    parent2 = self.population[p2_idx]\n                    parent2_fitness = self.fitness[p2_idx]\n\n                # Crossover\n                if np.random.rand() < self.p_crossover:\n                    crossover_point = np.random.randint(1, self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1.copy()\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.p_mutation:\n                        child[j] = np.random.uniform(func.bounds.lb[j], func.bounds.ub[j])\n\n                # Local Search\n                best_child = child.copy()\n                best_child_fitness = np.inf\n                for _ in range(self.ls_iterations):\n                    neighbor = child + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    neighbor_fitness = func(neighbor)\n                    self.eval_count += 1\n\n                    if neighbor_fitness < best_child_fitness:\n                        best_child = neighbor\n                        best_child_fitness = neighbor_fitness\n                    \n                    if self.eval_count >= self.budget:\n                        break\n                \n                if best_child_fitness < np.inf:\n                  new_population.append(best_child)\n                  new_fitness.append(best_child_fitness)\n\n                  if best_child_fitness < self.f_opt:\n                      self.f_opt = best_child_fitness\n                      self.x_opt = best_child\n            \n            if len(new_population) == 0:\n                break; #Terminate if no new samples were added\n\n\n            self.population[:len(new_population)] = np.array(new_population)\n            self.fitness[:len(new_fitness)] = np.array(new_fitness)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.16007994487432997, "generation": 7}, "task_prompt": ""}
{"id": "0b5bd41e-792f-4d61-904f-34a2caf4b9e1", "fitness": 0.7575725728974663, "name": "AdaptiveDEPerDimensionCr", "description": "Self-adaptive DE with per-dimension adaptation of crossover probability.", "code": "import numpy as np\n\nclass AdaptiveDEPerDimensionCr:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = np.full(dim, Cr)  # Per-dimension Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = 0.7 + 0.2 * np.random.randn(self.dim) # Adapt per dimension\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDEPerDimensionCr scored 0.758 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743", "0a78a8fc-74cd-454e-be68-4d87d2ff4a95"], "operator": "crossover", "metadata": {"llm_response": "# Description: Self-adaptive DE with per-dimension adaptation of crossover probability.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEPerDimensionCr:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = np.full(dim, Cr)  # Per-dimension Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = 0.7 + 0.2 * np.random.randn(self.dim) # Adapt per dimension\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.056344547028350116, "generation": 7, "aucs": [0.34687531763757673, 0.7898273802665547, 0.7424623756044444, 0.9322574189620235, 0.32090523700131524, 0.8946906128562324, 0.8155752533547089, 0.6615529545051798, 0.8905557723148027, 0.786173061396306, 0.9241005620735496, 0.9953300042396952, 0.35194387716367614, 0.8869705427144297, 0.9307533697077414, 0.9243108675164987, 0.6866609042251944, 0.9235453088730015, 0.8123844838313524, 0.5345761537050427]}, "task_prompt": ""}
{"id": "99c3e4f6-e02d-4324-9b28-430b148f31fd", "fitness": 0.20342571732062983, "name": "AdaptiveMutationEvolutionStrategy", "description": "A population-based algorithm that adaptively adjusts mutation strength based on the success rate of individuals, promoting exploration in promising regions and exploitation around elite solutions.", "code": "import numpy as np\n\nclass AdaptiveMutationEvolutionStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        sigmas = np.full((self.pop_size, self.dim), self.initial_sigma)  # Individual step sizes\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # reduce budget by initial population evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        archive_size = int(self.pop_size / 2)\n        archive_population = np.zeros((archive_size, self.dim))\n        archive_fitness = np.full(archive_size, np.inf)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Mutation and Recombination (Self-adaptation of step sizes)\n            offspring = population + sigmas * np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Selection and Update\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    population[i] = offspring[i]\n                    fitness[i] = offspring_fitness[i]\n\n                    # Adaptive Mutation Control: Adjust sigma based on success\n                    success_ratio = np.mean(offspring_fitness[i] < fitness[i])\n                    if success_ratio > 0.2: #exploration\n                        sigmas[i] = sigmas[i] * np.exp(0.1) #increase sigma\n                    else: #exploitation\n                        sigmas[i] = sigmas[i] * np.exp(-0.1)  # decrease sigma if not successful\n                        \n                    sigmas[i] = np.clip(sigmas[i], self.initial_sigma / 10, 1.0) # Prevent sigma from becoming too small or too large.\n                    \n            # Archive maintenance for exploitation\n            for i in range(self.pop_size):\n                if fitness[i] < np.max(archive_fitness):\n                    worst_archive_index = np.argmax(archive_fitness)\n                    archive_fitness[worst_archive_index] = fitness[i]\n                    archive_population[worst_archive_index] = population[i]\n\n            # Global Best Update\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveMutationEvolutionStrategy scored 0.203 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adaptively adjusts mutation strength based on the success rate of individuals, promoting exploration in promising regions and exploitation around elite solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveMutationEvolutionStrategy:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_sigma = initial_sigma\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        sigmas = np.full((self.pop_size, self.dim), self.initial_sigma)  # Individual step sizes\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size # reduce budget by initial population evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        archive_size = int(self.pop_size / 2)\n        archive_population = np.zeros((archive_size, self.dim))\n        archive_fitness = np.full(archive_size, np.inf)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Mutation and Recombination (Self-adaptation of step sizes)\n            offspring = population + sigmas * np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Selection and Update\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    population[i] = offspring[i]\n                    fitness[i] = offspring_fitness[i]\n\n                    # Adaptive Mutation Control: Adjust sigma based on success\n                    success_ratio = np.mean(offspring_fitness[i] < fitness[i])\n                    if success_ratio > 0.2: #exploration\n                        sigmas[i] = sigmas[i] * np.exp(0.1) #increase sigma\n                    else: #exploitation\n                        sigmas[i] = sigmas[i] * np.exp(-0.1)  # decrease sigma if not successful\n                        \n                    sigmas[i] = np.clip(sigmas[i], self.initial_sigma / 10, 1.0) # Prevent sigma from becoming too small or too large.\n                    \n            # Archive maintenance for exploitation\n            for i in range(self.pop_size):\n                if fitness[i] < np.max(archive_fitness):\n                    worst_archive_index = np.argmax(archive_fitness)\n                    archive_fitness[worst_archive_index] = fitness[i]\n                    archive_population[worst_archive_index] = population[i]\n\n            # Global Best Update\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.31182494390925936, "generation": 7, "aucs": [0.12551877640034637, 0.15086673473604517, 0.2381376275232462, 0.1632614207214772, 0.10593334063657, 0.13066813770355168, 0.20745057620774532, 0.13121256839019135, 0.17043903329102938, 0.165819509572821, 0.18513073381585643, 0.19060406640016303, 0.24653894255199127, 0.15770597506463835, 0.39906998150960005, 0.2627884352707732, 0.21301349698452599, 0.22622244756359, 0.16860753851025778, 0.42952500355817724]}, "task_prompt": ""}
{"id": "8797b8cd-47c0-49ba-8990-63b726aaf90d", "fitness": 0.41393191486194425, "name": "AdaptiveDE", "description": "Simplified Differential Evolution with population resizing and adaptive parameters based on success history.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.7, resize_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive pop size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.resize_factor = resize_factor\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (using success history)\n            if self.success_F:\n                self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_Cr), 0.1, 1.0)\n                self.success_F = []\n                self.success_Cr = []\n            else:\n                # If no success, revert to defaults with small random perturbation\n                self.F = np.clip(0.5 + 0.1 * np.random.randn(), 0.1, 0.9)\n                self.Cr = np.clip(0.7 + 0.1 * np.random.randn(), 0.1, 1.0)\n\n            # Population Resizing\n            if self.eval_count > self.budget * 0.5:  # Start resizing later in the search\n                if np.random.rand() < self.resize_factor:\n                    new_pop_size = int(4 + 3 * np.log(self.dim))\n                    if new_pop_size != self.pop_size:\n                        self.pop_size = new_pop_size\n                        new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                        new_fitness = np.array([func(x) for x in new_pop])\n                        self.eval_count += self.pop_size\n                        pop = new_pop\n                        fitness = new_fitness\n\n                        best_index = np.argmin(fitness)\n                        if fitness[best_index] < self.f_opt:\n                            self.f_opt = fitness[best_index]\n                            self.x_opt = pop[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDE scored 0.414 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Differential Evolution with population resizing and adaptive parameters based on success history.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, Cr=0.7, resize_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + 3 * np.log(dim))  # Adaptive pop size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_F = []\n        self.success_Cr = []\n        self.resize_factor = resize_factor\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_Cr.append(self.Cr)\n\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (using success history)\n            if self.success_F:\n                self.F = np.clip(np.mean(self.success_F), 0.1, 0.9)\n                self.Cr = np.clip(np.mean(self.success_Cr), 0.1, 1.0)\n                self.success_F = []\n                self.success_Cr = []\n            else:\n                # If no success, revert to defaults with small random perturbation\n                self.F = np.clip(0.5 + 0.1 * np.random.randn(), 0.1, 0.9)\n                self.Cr = np.clip(0.7 + 0.1 * np.random.randn(), 0.1, 1.0)\n\n            # Population Resizing\n            if self.eval_count > self.budget * 0.5:  # Start resizing later in the search\n                if np.random.rand() < self.resize_factor:\n                    new_pop_size = int(4 + 3 * np.log(self.dim))\n                    if new_pop_size != self.pop_size:\n                        self.pop_size = new_pop_size\n                        new_pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                        new_fitness = np.array([func(x) for x in new_pop])\n                        self.eval_count += self.pop_size\n                        pop = new_pop\n                        fitness = new_fitness\n\n                        best_index = np.argmin(fitness)\n                        if fitness[best_index] < self.f_opt:\n                            self.f_opt = fitness[best_index]\n                            self.x_opt = pop[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0176650535711956, "generation": 7, "aucs": [0.18766319879492876, 0.36479589454681705, 0.36754555757164986, 0.42263700275937277, 0.4423354914889783, 0.31509669482774694, 0.3587373329112372, 0.2249065233086608, 0.5162939594446934, 0.20242890210275077, 0.27384862875434224, 0.9993153303756929, 0.23533740109955736, 0.41542043150174235, 0.7564402276528681, 0.6056818022266879, 0.5476519393239114, 0.36010391299390554, 0.19625922092651849, 0.48613884462682366]}, "task_prompt": ""}
{"id": "c7dc26bf-222c-4df6-b784-4ecedb1af127", "fitness": 0.4610064891218232, "name": "EnsembleAdaptiveDE", "description": "Adaptive Differential Evolution with ensemble of mutation strategies and simplified parameter adaptation.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation Strategy Ensemble\n                mutation_strategy = np.random.choice([1, 2, 3]) # Ensemble of three strategies\n\n                if mutation_strategy == 1:  # DE/rand/1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = pop[idxs]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                elif mutation_strategy == 2:  # DE/current-to-rand/1\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = pop[idxs]\n                    x_mutated = pop[i] + self.F * (x_r1 - pop[i]) + self.F * (x_r2 - pop[i])\n                else:  #DE/best/1\n                    x_best = pop[np.argmin(fitness)]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = pop[idxs]\n\n                    x_mutated = x_best + self.F * (x_r1 - x_r2)\n                \n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Simplified Parameter Adaptation (linear decrease)\n            self.F = 0.5 # Fixed F\n            self.Cr = 0.9 - (0.8 * self.eval_count / self.budget) #Linearly decrease Cr\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm EnsembleAdaptiveDE scored 0.461 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with ensemble of mutation strategies and simplified parameter adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation Strategy Ensemble\n                mutation_strategy = np.random.choice([1, 2, 3]) # Ensemble of three strategies\n\n                if mutation_strategy == 1:  # DE/rand/1\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = pop[idxs]\n                    x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                elif mutation_strategy == 2:  # DE/current-to-rand/1\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = pop[idxs]\n                    x_mutated = pop[i] + self.F * (x_r1 - pop[i]) + self.F * (x_r2 - pop[i])\n                else:  #DE/best/1\n                    x_best = pop[np.argmin(fitness)]\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x_r1, x_r2 = pop[idxs]\n\n                    x_mutated = x_best + self.F * (x_r1 - x_r2)\n                \n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Simplified Parameter Adaptation (linear decrease)\n            self.F = 0.5 # Fixed F\n            self.Cr = 0.9 - (0.8 * self.eval_count / self.budget) #Linearly decrease Cr\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.019898831797444186, "generation": 7, "aucs": [0.15254911620020628, 0.23131947245552642, 0.7037836142474854, 0.5237985721631828, 0.24876344693961017, 0.4595885838046492, 0.28807980078859796, 0.424782694655371, 0.27170408594345885, 0.22752301228941707, 0.9792781888594927, 0.997021754703258, 0.29487410082048215, 0.3737821066281838, 0.6721886327103628, 0.3736999570113687, 0.32789311766214024, 0.9696359421067001, 0.19064275419326338, 0.5092208282537091]}, "task_prompt": ""}
{"id": "e67b27f2-e11e-4fd9-8f6c-f7df81d17b62", "fitness": 0.4417743498167553, "name": "HybridDE_LocalSearch", "description": "A population-based algorithm that uses a combination of differential evolution operators and a local search to improve exploitation around promising regions, with dynamically adjusted parameters for exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.7, cr=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update global best\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Mutation\n                v = population[i] + self.f * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.random.rand(self.dim) < self.cr\n                trial_vector = np.where(u, v, population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                    # Local Search around improved solution\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n                        local_point = population[i] + perturbation\n                        local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                        f_local = func(local_point)\n                        self.budget -= 1\n\n                        if f_local < fitness[i]:\n                            fitness[i] = f_local\n                            population[i] = local_point\n                        else:\n                            break   #Stop local search if no improvement\n\n\n                    # Update global best\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive Parameter Adjustment (simple version)\n            if generation % 10 == 0: # adjust every 10 generations\n                self.f = np.random.uniform(0.5, 0.9)\n                self.cr = np.random.uniform(0.7, 1.0)\n            \n            generation += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDE_LocalSearch scored 0.442 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of differential evolution operators and a local search to improve exploitation around promising regions, with dynamically adjusted parameters for exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, f=0.7, cr=0.9, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Mutation factor\n        self.cr = cr  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update global best\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Mutation\n                v = population[i] + self.f * (x_r1 - x_r2)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.random.rand(self.dim) < self.cr\n                trial_vector = np.where(u, v, population[i])\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector\n\n                    # Local Search around improved solution\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.1, size=self.dim) # Small perturbation\n                        local_point = population[i] + perturbation\n                        local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                        f_local = func(local_point)\n                        self.budget -= 1\n\n                        if f_local < fitness[i]:\n                            fitness[i] = f_local\n                            population[i] = local_point\n                        else:\n                            break   #Stop local search if no improvement\n\n\n                    # Update global best\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n                \n                if self.budget <= 0:\n                    break\n\n            # Adaptive Parameter Adjustment (simple version)\n            if generation % 10 == 0: # adjust every 10 generations\n                self.f = np.random.uniform(0.5, 0.9)\n                self.cr = np.random.uniform(0.7, 1.0)\n            \n            generation += 1\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.09342345453420674, "generation": 7, "aucs": [0.23489963848908324, 0.4716548410912704, 0.5442195435271218, 0.8182827085145634, 0.5815893672784931, 0]}, "task_prompt": ""}
{"id": "7eab9171-9cd4-450a-9313-56457870a2c8", "fitness": 0.659807980434738, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and focus on exploitation through reduced exploration range.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Simplified Adaptation\n            if np.random.rand() < 0.1: # Reduced Adaptation Frequency\n                self.F = np.clip(self.F + 0.01 * np.random.randn(), 0.1, 0.9)  #Smaller step\n                self.Cr = np.clip(self.Cr + 0.01 * np.random.randn(), 0.1, 1.0)  #Smaller step\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and focus on exploitation through reduced exploration range.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Simplified Adaptation\n            if np.random.rand() < 0.1: # Reduced Adaptation Frequency\n                self.F = np.clip(self.F + 0.01 * np.random.randn(), 0.1, 0.9)  #Smaller step\n                self.Cr = np.clip(self.Cr + 0.01 * np.random.randn(), 0.1, 1.0)  #Smaller step\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.04102815079114691, "generation": 8, "aucs": [0.2275188654149577, 0.8017360620407746, 0.8726095806248475, 0.9224095515212931, 0.41264788133695596, 0.912000965210849, 0.805009014784013, 0.8206328811868884, 0.9143445263536418, 0.22949252540819443, 0.9338162173302911, 0.9938440224659534, 0.40571779857228807, 0.8914565438124006, 0.6719335695920524, 0.33398990716050536, 0.29831262903438527, 0.9338834309013085, 0.30990692830966593, 0.5048967076334929]}, "task_prompt": ""}
{"id": "9dafe96e-89af-4a07-a0cd-e0d8932983ed", "fitness": 0.1587835406259958, "name": "SimplifiedCMAES", "description": "An algorithm that uses a covariance matrix adaptation evolution strategy (CMA-ES) inspired approach with simplified parameter adaptation and population size control to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(self.dim / 2 + 1)  # Number of parents\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim)) # Population size\n        else:\n            self.popsize = popsize\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.m = np.zeros(self.dim)  # Mean\n        self.sigma = 0.2  # Step size\n        self.c_sigma = 0.4 # Learning rate for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma # Damping for sigma\n        self.c_cov = 2 / (self.dim**2) # Learning rate for covariance matrix\n        self.p_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        self.lb = -5\n        self.ub = 5\n        self.archive_x = []\n        self.archive_f = []\n    \n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        x = self.m + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        x = np.clip(x, self.lb, self.ub)\n        return x\n    \n    def update(self, x, f):\n        # Selection and Recombination\n        idx = np.argsort(f)[:self.mu]\n        x_best = x[idx]\n        z = (x_best - self.m) / self.sigma\n        self.m = np.mean(x_best, axis=0)\n\n        # Update Evolution Path for Sigma\n        self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.mean(z, axis=0)\n\n        # Update Step Size\n        self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n    \n        # Update Covariance Matrix\n        delta = x_best - self.m\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.mean([np.outer(delta[i], delta[i]) for i in range(self.mu)], axis=0) / (self.sigma**2)\n\n        # Ensure PSD\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        while evals < self.budget:\n            x = self.sample()\n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            for i in range(self.popsize):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    \n            self.update(x, f)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm SimplifiedCMAES scored 0.159 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that uses a covariance matrix adaptation evolution strategy (CMA-ES) inspired approach with simplified parameter adaptation and population size control to balance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None):\n        self.budget = budget\n        self.dim = dim\n        self.mu = int(self.dim / 2 + 1)  # Number of parents\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim)) # Population size\n        else:\n            self.popsize = popsize\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.m = np.zeros(self.dim)  # Mean\n        self.sigma = 0.2  # Step size\n        self.c_sigma = 0.4 # Learning rate for sigma\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma # Damping for sigma\n        self.c_cov = 2 / (self.dim**2) # Learning rate for covariance matrix\n        self.p_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        self.lb = -5\n        self.ub = 5\n        self.archive_x = []\n        self.archive_f = []\n    \n    def sample(self):\n        z = np.random.normal(0, 1, size=(self.popsize, self.dim))\n        x = self.m + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n        x = np.clip(x, self.lb, self.ub)\n        return x\n    \n    def update(self, x, f):\n        # Selection and Recombination\n        idx = np.argsort(f)[:self.mu]\n        x_best = x[idx]\n        z = (x_best - self.m) / self.sigma\n        self.m = np.mean(x_best, axis=0)\n\n        # Update Evolution Path for Sigma\n        self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.mean(z, axis=0)\n\n        # Update Step Size\n        self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma) / np.sqrt(self.dim) - 1))\n    \n        # Update Covariance Matrix\n        delta = x_best - self.m\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * np.mean([np.outer(delta[i], delta[i]) for i in range(self.mu)], axis=0) / (self.sigma**2)\n\n        # Ensure PSD\n        try:\n            np.linalg.cholesky(self.C)\n        except np.linalg.LinAlgError:\n            self.C = np.eye(self.dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        while evals < self.budget:\n            x = self.sample()\n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n            \n            for i in range(self.popsize):\n                if f[i] < self.f_opt:\n                    self.f_opt = f[i]\n                    self.x_opt = x[i]\n                    \n            self.update(x, f)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.08291810949364439, "generation": 8, "aucs": [0.04919013829059771, 0.17474452720303468, 0.2904869884814252, 0.10327627698818465, 0.115415897104025, 0.1580352032860134, 0.17084277175022822, 0.16397779444114835, 0.14779823933090253, 0.15429510056064633, 0.1560410280570642, 0.20650239781856583, 0.25883558630711945, 0.11029306337795264, 0.11429935879835307, 0.22799149148722297, 0.13371355824732578, 0.14809925474401953, 0.13845948214167603, 0.15337265410441137]}, "task_prompt": ""}
{"id": "11e1690a-c4d3-458b-b4d1-57fd0ffb8b14", "fitness": 0.6787596587632942, "name": "SimplifiedSelfAdaptiveDE", "description": "Simplified Self-Adaptive Differential Evolution with per-vector crossover and reduced parameter adaptation frequency for efficiency.", "code": "import numpy as np\n\nclass SimplifiedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, adapt_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.adapt_freq = adapt_freq  # Frequency of adapting F and Cr\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (per-vector)\n                x_trial = pop[i].copy()\n                Cr_vector = np.random.rand(self.dim)\n                mask = Cr_vector < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified, less frequent)\n            generation += 1\n            if generation % self.adapt_freq == 0:\n                self.F = 0.5 + 0.3 * np.random.randn()\n                self.Cr = 0.7 + 0.2 * np.random.randn()\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm SimplifiedSelfAdaptiveDE scored 0.679 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Self-Adaptive Differential Evolution with per-vector crossover and reduced parameter adaptation frequency for efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass SimplifiedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.7, adapt_freq=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.adapt_freq = adapt_freq  # Frequency of adapting F and Cr\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover (per-vector)\n                x_trial = pop[i].copy()\n                Cr_vector = np.random.rand(self.dim)\n                mask = Cr_vector < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified, less frequent)\n            generation += 1\n            if generation % self.adapt_freq == 0:\n                self.F = 0.5 + 0.3 * np.random.randn()\n                self.Cr = 0.7 + 0.2 * np.random.randn()\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.015654141302240767, "generation": 8, "aucs": [0.4644705852037865, 0.7453790399774565, 0.5034315688388542, 0.9075500399734833, 0.8743019258220636, 0.875453451809402, 0.813847070088776, 0.4251696038904852, 0.8484213961764111, 0.45814202865319553, 0.919143570407091, 0.9913878133696336, 0.40739773141570046, 0.740168180928221, 0.7773105226919477, 0.8419738845426525, 0.799891015749045, 0.41437290692687057, 0.2352430060299362, 0.5321378327708707]}, "task_prompt": ""}
{"id": "1f995828-c357-43db-9198-1ae15aaa352c", "fitness": "-inf", "name": "AdaptivePopulationSearch", "description": "A population-based algorithm with adaptive scaling factors and a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Default pop size\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = 100  # Number of iterations without improvement before restart\n        self.scale_adaptation_rate = 0.9  # Rate at which the scale shrinks if stalled\n        self.restart_probability = 0.1 # Probability of randomly restarting part of the population\n        self.min_scale = 0.0001 # Minimal scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        self.scale = self.initial_scale * (self.ub - self.lb) #Adaptation parameter\n\n        self.stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            # Select parents (e.g., tournament selection)\n            indices = np.random.choice(self.pop_size, size=(self.pop_size, 3), replace=False)\n            winners = np.argmin(self.fitness[indices], axis=1)\n            parents = self.population[indices[np.arange(self.pop_size), winners]]\n\n            # Create offspring\n            offspring = parents + self.scale * np.random.normal(size=(self.pop_size, self.dim))\n\n            # Ensure offspring are within bounds\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            # Evaluate offspring\n            fitness_offspring = np.array([func(x) for x in offspring])\n            self.eval_count += self.pop_size\n\n            # Replace parents with better offspring\n            improved = fitness_offspring < self.fitness\n            self.population[improved] = offspring[improved]\n            self.fitness[improved] = fitness_offspring[improved]\n\n            # Update optimal solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.scale *= self.scale_adaptation_rate\n                if self.scale < self.min_scale:\n                    self.scale = self.initial_scale * (self.ub - self.lb)\n\n                #Option to Restart:\n                if np.random.rand() < self.restart_probability:\n                    num_to_restart = int(self.pop_size * 0.2) #Restart a percentage\n                    indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n                    self.population[indices_to_restart] = np.random.uniform(self.lb, self.ub, size=(num_to_restart, self.dim))\n                    self.fitness[indices_to_restart] = np.array([func(x) for x in self.population[indices_to_restart]])\n                    self.eval_count += num_to_restart\n                    \n                self.stagnation_counter = 0  # Reset stagnation counter\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "error": "In the code, line 1025, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: Cannot take a larger sample than population when 'replace=False'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive scaling factors and a restart mechanism based on stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 5 * dim  # Default pop size\n        self.initial_scale = initial_scale\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_threshold = 100  # Number of iterations without improvement before restart\n        self.scale_adaptation_rate = 0.9  # Rate at which the scale shrinks if stalled\n        self.restart_probability = 0.1 # Probability of randomly restarting part of the population\n        self.min_scale = 0.0001 # Minimal scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        \n        self.scale = self.initial_scale * (self.ub - self.lb) #Adaptation parameter\n\n        self.stagnation_counter = 0\n\n        while self.eval_count < self.budget:\n            # Select parents (e.g., tournament selection)\n            indices = np.random.choice(self.pop_size, size=(self.pop_size, 3), replace=False)\n            winners = np.argmin(self.fitness[indices], axis=1)\n            parents = self.population[indices[np.arange(self.pop_size), winners]]\n\n            # Create offspring\n            offspring = parents + self.scale * np.random.normal(size=(self.pop_size, self.dim))\n\n            # Ensure offspring are within bounds\n            offspring = np.clip(offspring, self.lb, self.ub)\n\n            # Evaluate offspring\n            fitness_offspring = np.array([func(x) for x in offspring])\n            self.eval_count += self.pop_size\n\n            # Replace parents with better offspring\n            improved = fitness_offspring < self.fitness\n            self.population[improved] = offspring[improved]\n            self.fitness[improved] = fitness_offspring[improved]\n\n            # Update optimal solution\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.scale *= self.scale_adaptation_rate\n                if self.scale < self.min_scale:\n                    self.scale = self.initial_scale * (self.ub - self.lb)\n\n                #Option to Restart:\n                if np.random.rand() < self.restart_probability:\n                    num_to_restart = int(self.pop_size * 0.2) #Restart a percentage\n                    indices_to_restart = np.random.choice(self.pop_size, size=num_to_restart, replace=False)\n                    self.population[indices_to_restart] = np.random.uniform(self.lb, self.ub, size=(num_to_restart, self.dim))\n                    self.fitness[indices_to_restart] = np.array([func(x) for x in self.population[indices_to_restart]])\n                    self.eval_count += num_to_restart\n                    \n                self.stagnation_counter = 0  # Reset stagnation counter\n                \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.33205926707378386, "generation": 8}, "task_prompt": ""}
{"id": "aea7f83c-03c3-44aa-a6d0-a6b20a5e3998", "fitness": 0.7483839360891184, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on population diversity.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation: select three distinct individuals\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Mutation\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive F and Cr - simplified and clipped\n        success_indices = self.fitness < np.mean(self.fitness)\n        if np.any(success_indices):\n            self.F = np.clip(np.mean(np.random.normal(0.5, 0.1, size=np.sum(success_indices))), 0.1, 0.9)\n            self.Cr = np.clip(np.mean(np.random.normal(0.9, 0.05, size=np.sum(success_indices))), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDE scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and a focus on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation: select three distinct individuals\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n\n            # Mutation\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adaptive F and Cr - simplified and clipped\n        success_indices = self.fitness < np.mean(self.fitness)\n        if np.any(success_indices):\n            self.F = np.clip(np.mean(np.random.normal(0.5, 0.1, size=np.sum(success_indices))), 0.1, 0.9)\n            self.Cr = np.clip(np.mean(np.random.normal(0.9, 0.05, size=np.sum(success_indices))), 0.1, 1.0)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.032365713908503346, "generation": 8, "aucs": [0.6170462192956684, 0.3311308816866495, 0.8971900840894184, 0.9537675538589424, 0.9089513827134943, 0.9223691157660997, 0.5933556105779338, 0.8741337025731805, 0.8547172935992633, 0.8644258545687389, 0.9339543797857208, 0.9999145140737968, 0.45640989304153, 0.8798451240642692, 0.8323463532512115, 0.9094191841319119, 0.44823099512112474, 0.9398254706053057, 0.2314344915813603, 0.5192106173967443]}, "task_prompt": ""}
{"id": "62439fce-b01e-4748-a4ef-45d2e8a37b70", "fitness": 0.7499208232499253, "name": "AdaptiveDESuccessHistory", "description": "Adaptively adjusts F and Cr based on the success of recent trials, focusing on population diversity and convergence.", "code": "import numpy as np\n\nclass AdaptiveDESuccessHistory:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_history = []\n        self.Cr_history = []\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_history.append((self.F, self.Cr, self.fitness[i] - f_trial))\n                if len(self.success_history) > self.archive_size:\n                    self.success_history.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on success history\n        if self.success_history:\n            F_vals, Cr_vals, imp = zip(*self.success_history)\n            imp = np.array(imp)\n            sum_imp = np.sum(imp)\n            if sum_imp > 0: # Avoid division by zero\n                F_avg = np.sum(np.array(F_vals) * imp) / sum_imp\n                Cr_avg = np.sum(np.array(Cr_vals) * imp) / sum_imp\n            else:\n                F_avg = np.mean(F_vals)\n                Cr_avg = np.mean(Cr_vals)\n\n            self.F = 0.9 * self.F + 0.1 * F_avg\n            self.Cr = 0.9 * self.Cr + 0.1 * Cr_avg\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        else:\n            # If no successes, add some randomness\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.Cr = 0.7 + 0.2 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDESuccessHistory scored 0.750 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively adjusts F and Cr based on the success of recent trials, focusing on population diversity and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDESuccessHistory:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n        self.F_history = []\n        self.Cr_history = []\n        self.success_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_history.append((self.F, self.Cr, self.fitness[i] - f_trial))\n                if len(self.success_history) > self.archive_size:\n                    self.success_history.pop(0)\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on success history\n        if self.success_history:\n            F_vals, Cr_vals, imp = zip(*self.success_history)\n            imp = np.array(imp)\n            sum_imp = np.sum(imp)\n            if sum_imp > 0: # Avoid division by zero\n                F_avg = np.sum(np.array(F_vals) * imp) / sum_imp\n                Cr_avg = np.sum(np.array(Cr_vals) * imp) / sum_imp\n            else:\n                F_avg = np.mean(F_vals)\n                Cr_avg = np.mean(Cr_vals)\n\n            self.F = 0.9 * self.F + 0.1 * F_avg\n            self.Cr = 0.9 * self.Cr + 0.1 * Cr_avg\n\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        else:\n            # If no successes, add some randomness\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.Cr = 0.7 + 0.2 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.021052793483477668, "generation": 8, "aucs": [0.3207767137410993, 0.22631580664876794, 0.8627493319229366, 0.9259384110200557, 0.8589996160139038, 0.9083663939249812, 0.8154331563388642, 0.8305058784863546, 0.8720266127106255, 0.8580724235559553, 0.9056210411024688, 0.9956350478047625, 0.3919506662379548, 0.8227370477777058, 0.9413155394181607, 0.9074903372116375, 0.7899846336770018, 0.8990315288989043, 0.33029169130005964, 0.5351745872063058]}, "task_prompt": ""}
{"id": "a1e1c94a-90f8-443c-aff8-9582d0b721f7", "fitness": "-inf", "name": "AdaptiveDifferentialEvolutionWithLocalSearch", "description": "Population-based algorithm with adaptive mutation and crossover, combined with a local search component using Nelder-Mead simplex method.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDifferentialEvolutionWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_factor=0.5, crossover_rate=0.7, local_search_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_interval = local_search_interval\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                x_mutated = population[i] + self.mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == np.random.randint(self.dim):\n                        x_trial[j] = x_mutated[j]\n                    else:\n                        x_trial[j] = population[i][j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search\n            if generation % self.local_search_interval == 0:\n                best_index = np.argmin(fitness)\n                \n                # Local search around the current best individual\n                res = minimize(func, population[best_index], method='Nelder-Mead',\n                               bounds=list(zip([func.bounds.lb]*self.dim, [func.bounds.ub]*self.dim)),\n                               options={'maxfev': min(self.budget // 2, 500)})  # Limit function evaluations for local search\n                \n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                \n                self.budget -= res.nfev\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Validation failed: Forbidden import: 'scipy.optimize' is not available in the evaluation environment", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive mutation and crossover, combined with a local search component using Nelder-Mead simplex method.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveDifferentialEvolutionWithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_factor=0.5, crossover_rate=0.7, local_search_interval=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_interval = local_search_interval\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[indices]\n                x_mutated = population[i] + self.mutation_factor * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.zeros(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == np.random.randint(self.dim):\n                        x_trial[j] = x_mutated[j]\n                    else:\n                        x_trial[j] = population[i][j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Local Search\n            if generation % self.local_search_interval == 0:\n                best_index = np.argmin(fitness)\n                \n                # Local search around the current best individual\n                res = minimize(func, population[best_index], method='Nelder-Mead',\n                               bounds=list(zip([func.bounds.lb]*self.dim, [func.bounds.ub]*self.dim)),\n                               options={'maxfev': min(self.budget // 2, 500)})  # Limit function evaluations for local search\n                \n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                \n                self.budget -= res.nfev\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "c7c82582-d439-42df-b36e-0760b3e5da8f", "fitness": 0.0, "name": "RankBasedDifferentialEvolutionLocalSearch", "description": "Population-based algorithm using a combination of differential evolution with a crossover strategy based on the rank of the individuals, and a local search based on a decaying step size.", "code": "import numpy as np\n\nclass RankBasedDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            # Rank-based crossover\n            ranked_indices = np.argsort(fitness)\n            for i in range(self.pop_size):\n                # Select parent indices based on rank\n                p1, p2, p3 = np.random.choice(self.pop_size, 3, replace=False) # Ensure different parents\n                \n                # Differential evolution mutation and crossover\n                F = 0.5 + 0.5 * np.random.rand() # Adaptive F\n                CR = (ranked_indices[i] / self.pop_size) # Rank based CR\n\n                v = population[p1] + F * (population[p2] - population[p3])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                u = np.array([v[j] if np.random.rand() < CR or j == j_rand else population[i, j] for j in range(self.dim)])\n                \n                f_u = func(u)\n                eval_count += 1\n\n                if f_u < fitness[i]:\n                    fitness[i] = f_u\n                    population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u.copy()\n\n                if eval_count >= self.budget:\n                    break\n\n            # Local search around the best solution with decaying step size\n            step_size = 0.1 * (1 - eval_count / self.budget)  # Decaying step size\n            for _ in range(self.local_search_iterations):\n                perturbation = np.random.uniform(-step_size, step_size, size=self.dim)\n                x_local = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                eval_count += 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n\n                if eval_count >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm RankBasedDifferentialEvolutionLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of differential evolution with a crossover strategy based on the rank of the individuals, and a local search based on a decaying step size.\n# Code: \n```python\nimport numpy as np\n\nclass RankBasedDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while eval_count < self.budget:\n            # Rank-based crossover\n            ranked_indices = np.argsort(fitness)\n            for i in range(self.pop_size):\n                # Select parent indices based on rank\n                p1, p2, p3 = np.random.choice(self.pop_size, 3, replace=False) # Ensure different parents\n                \n                # Differential evolution mutation and crossover\n                F = 0.5 + 0.5 * np.random.rand() # Adaptive F\n                CR = (ranked_indices[i] / self.pop_size) # Rank based CR\n\n                v = population[p1] + F * (population[p2] - population[p3])\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                u = np.array([v[j] if np.random.rand() < CR or j == j_rand else population[i, j] for j in range(self.dim)])\n                \n                f_u = func(u)\n                eval_count += 1\n\n                if f_u < fitness[i]:\n                    fitness[i] = f_u\n                    population[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u.copy()\n\n                if eval_count >= self.budget:\n                    break\n\n            # Local search around the best solution with decaying step size\n            step_size = 0.1 * (1 - eval_count / self.budget)  # Decaying step size\n            for _ in range(self.local_search_iterations):\n                perturbation = np.random.uniform(-step_size, step_size, size=self.dim)\n                x_local = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                eval_count += 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local.copy()\n\n                if eval_count >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.1892867020939952, "generation": 8, "aucs": [0]}, "task_prompt": ""}
{"id": "d64030dc-5fb3-4ef6-b309-ac4b89ce81a1", "fitness": 0.0, "name": "ExploitativeDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and focus on exploitation by reducing population diversity.", "code": "import numpy as np\n\nclass ExploitativeDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            if np.random.rand() < self.Cr:\n                x_trial = x_mutated\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength\n        self.F = 0.5 + 0.05 * np.random.randn()\n        self.Cr = 0.7 + 0.025 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm ExploitativeDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and focus on exploitation by reducing population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass ExploitativeDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.7\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            if np.random.rand() < self.Cr:\n                x_trial = x_mutated\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - reduced adaptation strength\n        self.F = 0.5 + 0.05 * np.random.randn()\n        self.Cr = 0.7 + 0.025 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.014637555972453153, "generation": 9, "aucs": [0]}, "task_prompt": ""}
{"id": "979fcbf0-d522-490d-9452-d7bc4e1c7cdd", "fitness": 0.7048816523245746, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and a focus on exploration using a larger population size.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.1 * np.random.randn()\n        self.Cr = 0.9 + 0.05 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDE scored 0.705 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and a focus on exploration using a larger population size.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr - simplified adaptation\n        self.F = 0.5 + 0.1 * np.random.randn()\n        self.Cr = 0.9 + 0.05 * np.random.randn()\n        self.F = np.clip(self.F, 0.1, 0.9)\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.028587478997144682, "generation": 9, "aucs": [0.3098682614297248, 0.6348173256917442, 0.6738433486665358, 0.8642175548463276, 0.7733733299608503, 0.799494418853776, 0.6804796229507313, 0.6801257765376196, 0.7262774915379862, 0.7278060435383118, 0.8607832730603894, 0.9972123521827734, 0.6208511756160547, 0.741557840982306, 0.9134907338118109, 0.7758677484664762, 0.5639989834963137, 0.8332173293830103, 0.32203175667999107, 0.5983186787987569]}, "task_prompt": ""}
{"id": "a131dbfe-7261-4ac0-8ab5-8479ecd7ddb7", "fitness": 0.0, "name": "AdaptiveDE", "description": "A simplified Differential Evolution with adaptive F and Cr parameters and a focus on exploration by occasionally re-initializing individuals.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Occasional Re-initialization\n            elif np.random.rand() < 0.01:  # 1% chance of re-initialization\n                self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n\n        # Adaptive F and Cr\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = np.random.rand()\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.clip(self.Cr, 0.0, 1.0)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: A simplified Differential Evolution with adaptive F and Cr parameters and a focus on exploration by occasionally re-initializing individuals.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr  # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            for j in range(self.dim):\n                if np.random.rand() < self.Cr:\n                    x_trial[j] = x_mutated[j]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n            # Occasional Re-initialization\n            elif np.random.rand() < 0.01:  # 1% chance of re-initialization\n                self.pop[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.fitness[i] = func(self.pop[i])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.pop[i]\n\n        # Adaptive F and Cr\n        self.F = 0.5 + 0.3 * np.random.randn()\n        self.Cr = np.random.rand()\n        self.F = np.clip(self.F, 0.1, 1.0)\n        self.Cr = np.clip(self.Cr, 0.0, 1.0)\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.009832242206572837, "generation": 9, "aucs": [0]}, "task_prompt": ""}
{"id": "63a1c241-5f63-4d48-a10a-a35b5f42aa35", "fitness": "-inf", "name": "AdaptiveDifferentialEvolution", "description": "A population-based algorithm with adaptive mutation and crossover rates based on the success history of previous parameter choices. It utilizes a pool of mutation strategies and updates crossover rate adaptively.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_pool_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_pool_size = mutation_pool_size\n        self.mutation_strategies = [\n            lambda x, b, c, F: x + F * (b - c),  # DE/rand/1\n            lambda x, best, b, c, F: x + F * (best - x) + F * (b - c),  # DE/current-to-best/1\n            lambda x, best, b, c, d, e, F: x + F * (best - x) + F * (b - c) + F * (d-e), # DE/current-to-best/2\n        ]\n        self.memory_cr = np.zeros(self.mutation_pool_size)\n        self.memory_F = np.full(self.mutation_pool_size, 0.5)\n        self.success_cr = []\n        self.success_F = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                strategy_index = np.random.randint(self.mutation_pool_size)\n                cr = np.random.normal(self.memory_cr[strategy_index], 0.1)\n                cr = np.clip(cr, 0, 1)\n                F = np.random.normal(self.memory_F[strategy_index], 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n\n                x = self.population[i]\n                best = self.population[np.argmin(self.fitness)]\n                a, b, c, d, e = self.population[indices[0]], self.population[indices[1]], self.population[indices[2]], self.population[indices[3]], self.population[indices[4]]\n\n                \n                mutant = self.mutation_strategies[strategy_index](x, best, b, c, d, e, F) if strategy_index == 2 else self.mutation_strategies[strategy_index](x, best, b, c, F) if strategy_index == 1 else self.mutation_strategies[strategy_index](x, b, c, F)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.array([mutant[j] if np.random.rand() < cr or j == j_rand else x[j] for j in range(self.dim)])\n\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.success_cr.append(cr)\n                    self.success_F.append(F)\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n            if self.success_cr:\n                weights = np.array([f - self.f_opt for f in self.fitness if f < self.f_opt])\n                weights = np.abs(weights)\n                if np.sum(weights) > 0:\n                    weights /= np.sum(weights)\n                else:\n                    weights = np.ones(len(weights)) / len(weights)\n\n                self.memory_cr[strategy_index] = np.average(self.success_cr, weights=weights)\n                self.memory_F[strategy_index] = np.average(self.success_F, weights=weights)\n\n                self.success_cr = []\n                self.success_F = []\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "In the code, line 419, in _weights_are_valid, the following error occurred:\nTypeError: Axis must be specified when shapes of a and weights differ.", "error": "In the code, line 419, in _weights_are_valid, the following error occurred:\nTypeError: Axis must be specified when shapes of a and weights differ.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive mutation and crossover rates based on the success history of previous parameter choices. It utilizes a pool of mutation strategies and updates crossover rate adaptively.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_pool_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_pool_size = mutation_pool_size\n        self.mutation_strategies = [\n            lambda x, b, c, F: x + F * (b - c),  # DE/rand/1\n            lambda x, best, b, c, F: x + F * (best - x) + F * (b - c),  # DE/current-to-best/1\n            lambda x, best, b, c, d, e, F: x + F * (best - x) + F * (b - c) + F * (d-e), # DE/current-to-best/2\n        ]\n        self.memory_cr = np.zeros(self.mutation_pool_size)\n        self.memory_F = np.full(self.mutation_pool_size, 0.5)\n        self.success_cr = []\n        self.success_F = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                strategy_index = np.random.randint(self.mutation_pool_size)\n                cr = np.random.normal(self.memory_cr[strategy_index], 0.1)\n                cr = np.clip(cr, 0, 1)\n                F = np.random.normal(self.memory_F[strategy_index], 0.1)\n                F = np.clip(F, 0.1, 1.0)\n\n                indices = np.random.choice(self.pop_size, 5, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 5, replace=False)\n\n                x = self.population[i]\n                best = self.population[np.argmin(self.fitness)]\n                a, b, c, d, e = self.population[indices[0]], self.population[indices[1]], self.population[indices[2]], self.population[indices[3]], self.population[indices[4]]\n\n                \n                mutant = self.mutation_strategies[strategy_index](x, best, b, c, d, e, F) if strategy_index == 2 else self.mutation_strategies[strategy_index](x, best, b, c, F) if strategy_index == 1 else self.mutation_strategies[strategy_index](x, b, c, F)\n                \n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.array([mutant[j] if np.random.rand() < cr or j == j_rand else x[j] for j in range(self.dim)])\n\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.success_cr.append(cr)\n                    self.success_F.append(F)\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n            if self.success_cr:\n                weights = np.array([f - self.f_opt for f in self.fitness if f < self.f_opt])\n                weights = np.abs(weights)\n                if np.sum(weights) > 0:\n                    weights /= np.sum(weights)\n                else:\n                    weights = np.ones(len(weights)) / len(weights)\n\n                self.memory_cr[strategy_index] = np.average(self.success_cr, weights=weights)\n                self.memory_F[strategy_index] = np.average(self.success_F, weights=weights)\n\n                self.success_cr = []\n                self.success_F = []\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.1825052360892757, "generation": 9}, "task_prompt": ""}
{"id": "8cc3750e-ed4c-4387-972c-e73f15cf5b19", "fitness": 0.40433416166519287, "name": "AdaptiveRestartDE", "description": "A population-based algorithm with a restart mechanism that uses a combination of global and local search strategies, adaptively adjusting the search behavior based on performance.", "code": "import numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_memory = [0.5] * 10\n        self.CR_memory = [0.7] * 10\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        while self.eval_count < self.budget:\n            # Adaptive parameter control (using memory)\n            F = np.random.choice(self.F_memory)\n            CR = np.random.choice(self.CR_memory)\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                x_mutated = self.population[i] + F * (x_r1 - x_r2)\n\n                # Clipping\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    # Update memory with successful parameters\n                    self.F_memory[self.memory_index] = F\n                    self.CR_memory[self.memory_index] = CR\n                    self.memory_index = (self.memory_index + 1) % len(self.F_memory)\n\n                # Update best solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n            # Restart mechanism: Check for stagnation\n            if self.eval_count > self.budget * self.restart_trigger:\n                if np.std(self.fitness) < 1e-6:\n                    # Restart the population\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.pop_size\n                    # Reset mutation and crossover rates\n                    self.F = 0.5\n                    self.CR = 0.7\n                    self.F_memory = [0.5] * 10\n                    self.CR_memory = [0.7] * 10\n                    self.memory_index = 0\n                    \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveRestartDE scored 0.404 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with a restart mechanism that uses a combination of global and local search strategies, adaptively adjusting the search behavior based on performance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveRestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.restart_trigger = restart_trigger\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7 # Initial crossover rate\n        self.F_memory = [0.5] * 10\n        self.CR_memory = [0.7] * 10\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n\n        while self.eval_count < self.budget:\n            # Adaptive parameter control (using memory)\n            F = np.random.choice(self.F_memory)\n            CR = np.random.choice(self.CR_memory)\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                x_mutated = self.population[i] + F * (x_r1 - x_r2)\n\n                # Clipping\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    # Update memory with successful parameters\n                    self.F_memory[self.memory_index] = F\n                    self.CR_memory[self.memory_index] = CR\n                    self.memory_index = (self.memory_index + 1) % len(self.F_memory)\n\n                # Update best solution\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial.copy()\n\n            # Restart mechanism: Check for stagnation\n            if self.eval_count > self.budget * self.restart_trigger:\n                if np.std(self.fitness) < 1e-6:\n                    # Restart the population\n                    self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    self.fitness = np.array([func(x) for x in self.population])\n                    self.eval_count += self.pop_size\n                    # Reset mutation and crossover rates\n                    self.F = 0.5\n                    self.CR = 0.7\n                    self.F_memory = [0.5] * 10\n                    self.CR_memory = [0.7] * 10\n                    self.memory_index = 0\n                    \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03672150124107227, "generation": 9, "aucs": [0.15362515523123854, 0.25081923304052933, 0.3969740581248862, 0.48366943880201774, 0.30032139786468504, 0.43262872300564736, 0.3035517782954664, 0.3506325410775428, 0.3189657115636678, 0.20328624029977782, 0.5470930848762285, 0.9898158727631549, 0.3158863951609826, 0.3003375052970849, 0.7740507270089219, 0.4315586347769177, 0.32718143330900706, 0.5276734400337877, 0.186481521497322, 0.49213034127499]}, "task_prompt": ""}
{"id": "18e4dc5e-6c26-4235-9614-ab64279010ee", "fitness": "-inf", "name": "GaussianMixtureModelOptimization", "description": "Population-based algorithm using a Gaussian Mixture Model to sample new candidate solutions, adapting the GMM based on the best solutions found so far.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureModelOptimization:\n    def __init__(self, budget=10000, dim=10, n_components=5, top_fraction=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.top_fraction = top_fraction\n        self.population_size = min(100, budget // 10) #Dynamically adapt population size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Select top solutions for GMM training\n            n_top = int(self.top_fraction * self.population_size)\n            top_indices = np.argsort(fitness)[:n_top]\n            top_solutions = population[top_indices]\n\n            # Train GMM\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=10, random_state=42, init_params='kmeans++')\n            try:\n                gmm.fit(top_solutions)\n            except ValueError as e:\n                # Handle the case where the GMM cannot be fit (e.g., due to insufficient data)\n                # Generate samples randomly within the bounds\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.population_size\n            else:\n                # Sample new solutions from GMM\n                new_population = gmm.sample(self.population_size)[0]\n                # Clip the new population to be within the bounds\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.population_size\n\n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n\n            # Update optimal solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Validation failed: Forbidden import: 'sklearn' is not available in the evaluation environment", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a Gaussian Mixture Model to sample new candidate solutions, adapting the GMM based on the best solutions found so far.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureModelOptimization:\n    def __init__(self, budget=10000, dim=10, n_components=5, top_fraction=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.top_fraction = top_fraction\n        self.population_size = min(100, budget // 10) #Dynamically adapt population size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.population_size\n\n        if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Select top solutions for GMM training\n            n_top = int(self.top_fraction * self.population_size)\n            top_indices = np.argsort(fitness)[:n_top]\n            top_solutions = population[top_indices]\n\n            # Train GMM\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=10, random_state=42, init_params='kmeans++')\n            try:\n                gmm.fit(top_solutions)\n            except ValueError as e:\n                # Handle the case where the GMM cannot be fit (e.g., due to insufficient data)\n                # Generate samples randomly within the bounds\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.population_size\n            else:\n                # Sample new solutions from GMM\n                new_population = gmm.sample(self.population_size)[0]\n                # Clip the new population to be within the bounds\n                new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= self.population_size\n\n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n\n            # Update optimal solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n        \n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "60be53f4-8bc6-455f-9c4e-290db5a42807", "fitness": "-inf", "name": "RestartCMAES", "description": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and increasing population size after each restart to escape local optima.", "code": "import numpy as np\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Increase population size with each restart\n            pop_size = 4 + int(3 * np.log(self.dim)) + restart * 2\n\n            # Initialize CMA-ES parameters\n            mean = np.random.uniform(self.lb, self.ub, self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n            pc = np.zeros(self.dim)  # Evolution path for C\n            ps = np.zeros(self.dim)  # Evolution path for sigma\n            chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n            # Learning rate parameters\n            c_sigma = (pop_size + 2) / (self.dim + pop_size + 5)\n            c_c = (4 + (self.dim / 3)) / (self.dim + 4 + (self.dim*1.5))\n            c_1 = 2 / ((self.dim + 1.3)**2 + pop_size)\n            c_mu = min(1 - c_1, 2 * (pop_size - 2 + 1)/( (self.dim + 2)**2 + pop_size))\n            d_sigma = 1 + 2 * max(0, np.sqrt((c_1 + c_mu - 1))) + c_sigma\n\n            mu = pop_size // 2  # Number of parents\n\n            while evals_used < self.budget:\n                # Generate and evaluate population\n                z = np.random.multivariate_normal(np.zeros(self.dim), C, pop_size)\n                x = mean + sigma * z\n                f = np.zeros(pop_size)\n\n                # Clip solutions to bounds\n                for i in range(pop_size):\n                    x[i] = np.clip(x[i], self.lb, self.ub)\n                    f[i] = func(x[i])\n                    evals_used += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n\n                    if evals_used >= self.budget:\n                        break\n                if evals_used >= self.budget:\n                    break\n\n\n                # Selection and recombination\n                idx = np.argsort(f)\n                x_mu = x[idx[:mu]]\n                z_mu = z[idx[:mu]]\n                mean_old = mean.copy()\n                mean = np.mean(x_mu, axis=0)\n\n                # Update evolution paths\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * np.linalg.solve(np.linalg.cholesky(C).T, (mean - mean_old) / sigma)\n                hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * (evals_used / pop_size))) / chiN < 1.4 + 2 / (self.dim + 1))\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c)) * (mean - mean_old) / sigma\n\n                # Update covariance matrix\n                C = (1 + c_1 * (1 - hsig**2) * c_c * (2 - c_c) - c_1 - c_mu) * C + c_1 * np.outer(pc, pc)\n                C += c_mu * np.sum([np.outer(z_mu[i], z_mu[i]) for i in range(mu)], axis=0)\n\n                # Update step size\n                sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps) / chiN - 1))\n                sigma = np.clip(sigma, 1e-10, 10)\n                C = np.triu(C) + np.triu(C, 1).T  # Ensure symmetry\n                \n                try:\n                    np.linalg.cholesky(C) # Check if C is positive definite.\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim)  # Reset C if it's not positive definite.\n                \n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with restarts and increasing population size after each restart to escape local optima.\n\n# Code:\n```python\nimport numpy as np\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.restarts = restarts\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals_used = 0\n\n        for restart in range(self.restarts):\n            # Increase population size with each restart\n            pop_size = 4 + int(3 * np.log(self.dim)) + restart * 2\n\n            # Initialize CMA-ES parameters\n            mean = np.random.uniform(self.lb, self.ub, self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n            pc = np.zeros(self.dim)  # Evolution path for C\n            ps = np.zeros(self.dim)  # Evolution path for sigma\n            chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n            # Learning rate parameters\n            c_sigma = (pop_size + 2) / (self.dim + pop_size + 5)\n            c_c = (4 + (self.dim / 3)) / (self.dim + 4 + (self.dim*1.5))\n            c_1 = 2 / ((self.dim + 1.3)**2 + pop_size)\n            c_mu = min(1 - c_1, 2 * (pop_size - 2 + 1)/( (self.dim + 2)**2 + pop_size))\n            d_sigma = 1 + 2 * max(0, np.sqrt((c_1 + c_mu - 1))) + c_sigma\n\n            mu = pop_size // 2  # Number of parents\n\n            while evals_used < self.budget:\n                # Generate and evaluate population\n                z = np.random.multivariate_normal(np.zeros(self.dim), C, pop_size)\n                x = mean + sigma * z\n                f = np.zeros(pop_size)\n\n                # Clip solutions to bounds\n                for i in range(pop_size):\n                    x[i] = np.clip(x[i], self.lb, self.ub)\n                    f[i] = func(x[i])\n                    evals_used += 1\n                    if f[i] < self.f_opt:\n                        self.f_opt = f[i]\n                        self.x_opt = x[i]\n\n                    if evals_used >= self.budget:\n                        break\n                if evals_used >= self.budget:\n                    break\n\n\n                # Selection and recombination\n                idx = np.argsort(f)\n                x_mu = x[idx[:mu]]\n                z_mu = z[idx[:mu]]\n                mean_old = mean.copy()\n                mean = np.mean(x_mu, axis=0)\n\n                # Update evolution paths\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * np.linalg.solve(np.linalg.cholesky(C).T, (mean - mean_old) / sigma)\n                hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * (evals_used / pop_size))) / chiN < 1.4 + 2 / (self.dim + 1))\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c)) * (mean - mean_old) / sigma\n\n                # Update covariance matrix\n                C = (1 + c_1 * (1 - hsig**2) * c_c * (2 - c_c) - c_1 - c_mu) * C + c_1 * np.outer(pc, pc)\n                C += c_mu * np.sum([np.outer(z_mu[i], z_mu[i]) for i in range(mu)], axis=0)\n\n                # Update step size\n                sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps) / chiN - 1))\n                sigma = np.clip(sigma, 1e-10, 10)\n                C = np.triu(C) + np.triu(C, 1).T  # Ensure symmetry\n                \n                try:\n                    np.linalg.cholesky(C) # Check if C is positive definite.\n                except np.linalg.LinAlgError:\n                    C = np.eye(self.dim)  # Reset C if it's not positive definite.\n                \n                \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.4272594772981436, "generation": 9}, "task_prompt": ""}
{"id": "474a6c8b-f699-432e-8384-e3862808d30c", "fitness": 0.18014294546597218, "name": "RestartDE", "description": "Simplified Differential Evolution with reduced parameter adaptation and periodic population restart.", "code": "import numpy as np\n\nclass RestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, restart_trigger=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.restart_trigger = restart_trigger\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            if np.random.rand() < self.Cr:\n                x_trial = x_mutated\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified adaptation and restart mechanism\n        if np.random.rand() < self.restart_trigger or np.std(self.fitness) < 1e-8:\n             self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n             self.fitness = np.array([func(x) for x in self.pop])\n             self.eval_count += self.pop_size\n             \n             \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n   \n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm RestartDE scored 0.180 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified Differential Evolution with reduced parameter adaptation and periodic population restart.\n# Code: \n```python\nimport numpy as np\n\nclass RestartDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, restart_trigger=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.restart_trigger = restart_trigger\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            if np.random.rand() < self.Cr:\n                x_trial = x_mutated\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified adaptation and restart mechanism\n        if np.random.rand() < self.restart_trigger or np.std(self.fitness) < 1e-8:\n             self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n             self.fitness = np.array([func(x) for x in self.pop])\n             self.eval_count += self.pop_size\n             \n             \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n   \n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.007405252053956218, "generation": 9, "aucs": [0.12864014301826032, 0.20154314077725954, 0.3011970674098601, 0.26933437612448097, 0]}, "task_prompt": ""}
{"id": "9903463e-8b9c-4bdb-9259-4c0709993147", "fitness": 0.7616202196264216, "name": "AdaptiveDE", "description": "Self-adaptive Differential Evolution with a simplified parameter adaptation scheme and adaptive population sizing.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_factor = pop_factor\n        self.pop_size = min(int(self.pop_factor * self.dim), self.budget // 2)  # Adaptive pop size\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        if self.pop_size < 4:\n          self.pop_size = 4\n    \n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDE scored 0.762 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive Differential Evolution with a simplified parameter adaptation scheme and adaptive population sizing.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_factor=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_factor = pop_factor\n        self.pop_size = min(int(self.pop_factor * self.dim), self.budget // 2)  # Adaptive pop size\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        if self.pop_size < 4:\n          self.pop_size = 4\n    \n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.004764743691551951, "generation": 10, "aucs": [0.36280674422411374, 0.7006353831559644, 0.7897327724852904, 0.9288051884484707, 0.8204168311541479, 0.86488123268276, 0.8040144864352612, 0.7710792185487787, 0.8398991944891975, 0.8134918192775418, 0.9160709771540151, 0.9967394185245425, 0.5319301015089575, 0.7877562371220073, 0.9371224054098526, 0.8726522762679837, 0.7398495704432924, 0.9124298166558065, 0.32742161951194393, 0.5146690990285059]}, "task_prompt": ""}
{"id": "cb490eb8-d191-4963-88d9-e3d2756a7987", "fitness": 0.0, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with simplified parameter adaptation and population size reduction for faster convergence.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(5 + np.ceil(np.log(dim)))\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified Adaptation of F and Cr\n        if np.random.rand() < 0.1:\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.random.rand()\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with simplified parameter adaptation and population size reduction for faster convergence.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(5 + np.ceil(np.log(dim)))\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            crossover_points = np.random.rand(self.dim) < self.Cr\n            x_trial[crossover_points] = x_mutated[crossover_points]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Simplified Adaptation of F and Cr\n        if np.random.rand() < 0.1:\n            self.F = 0.5 + 0.3 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.random.rand()\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.003272498619980156, "generation": 10, "aucs": [0]}, "task_prompt": ""}
{"id": "755ad601-1670-4526-96f4-9c312e42a44e", "fitness": "-inf", "name": "PSO_DE", "description": "A population-based algorithm that combines elements of Particle Swarm Optimization (PSO) and Differential Evolution (DE), adaptively adjusting parameters based on population diversity and success rate.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.5, f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f    # Mutation factor\n        self.pop = None\n        self.fitness = None\n        self.pbest = None\n        self.pbest_fitness = None\n        self.gbest = None\n        self.gbest_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.pbest = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Diversity check\n            diversity = np.std(self.pop)\n            \n            # Adaptive parameter adjustment based on diversity\n            if diversity < 0.1:  # If population is too similar\n                self.cr = min(1.0, self.cr + 0.1) # Increase crossover rate\n                self.f = min(1.0, self.f + 0.1)   # Increase mutation factor\n                self.w = max(0.4, self.w -0.05) #decrease inertia\n            else:\n                self.cr = max(0.1, self.cr - 0.05) #decrease crossover rate\n                self.f = max(0.1, self.f - 0.05)   #decrease mutation factor\n                self.w = min(0.9, self.w + 0.025)\n                \n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.f * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = self.w * (self.pop[i] - self.pbest[i]) + self.c1 * np.random.rand(self.dim) * (self.pbest[i] - self.pop[i]) + self.c2 * np.random.rand(self.dim) * (self.gbest - self.pop[i])\n                velocity = np.clip(velocity, -1, 1)  # Limit velocity to avoid excessive jumps.\n                trial = self.pop[i] + velocity\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial[j] = self.pop[i][j]\n\n                f = func(trial)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.pbest_fitness[i]:\n                        self.pbest[i] = trial\n                        self.pbest_fitness[i] = f\n\n                        if f < self.gbest_fitness:\n                            self.gbest = trial.copy()\n                            self.gbest_fitness = f\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.gbest_fitness, self.gbest", "configspace": "", "generation": 10, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of Particle Swarm Optimization (PSO) and Differential Evolution (DE), adaptively adjusting parameters based on population diversity and success rate.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.5, f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.f = f    # Mutation factor\n        self.pop = None\n        self.fitness = None\n        self.pbest = None\n        self.pbest_fitness = None\n        self.gbest = None\n        self.gbest_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.pbest = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_fitness = np.min(self.fitness)\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Diversity check\n            diversity = np.std(self.pop)\n            \n            # Adaptive parameter adjustment based on diversity\n            if diversity < 0.1:  # If population is too similar\n                self.cr = min(1.0, self.cr + 0.1) # Increase crossover rate\n                self.f = min(1.0, self.f + 0.1)   # Increase mutation factor\n                self.w = max(0.4, self.w -0.05) #decrease inertia\n            else:\n                self.cr = max(0.1, self.cr - 0.05) #decrease crossover rate\n                self.f = max(0.1, self.f - 0.05)   #decrease mutation factor\n                self.w = min(0.9, self.w + 0.025)\n                \n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.f * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = self.w * (self.pop[i] - self.pbest[i]) + self.c1 * np.random.rand(self.dim) * (self.pbest[i] - self.pop[i]) + self.c2 * np.random.rand(self.dim) * (self.gbest - self.pop[i])\n                velocity = np.clip(velocity, -1, 1)  # Limit velocity to avoid excessive jumps.\n                trial = self.pop[i] + velocity\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial[j] = self.pop[i][j]\n\n                f = func(trial)\n                self.eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.pop[i] = trial\n                    self.fitness[i] = f\n\n                    if f < self.pbest_fitness[i]:\n                        self.pbest[i] = trial\n                        self.pbest_fitness[i] = f\n\n                        if f < self.gbest_fitness:\n                            self.gbest = trial.copy()\n                            self.gbest_fitness = f\n\n                if self.eval_count >= self.budget:\n                    break\n\n        return self.gbest_fitness, self.gbest\n```", "operator": "random_new", "theta_sampled": 0.04623059416978114, "generation": 10}, "task_prompt": ""}
{"id": "aa57dc36-bdc5-462e-80cc-7df49adb2ea3", "fitness": 0.3050750002117783, "name": "HybridDEPSO", "description": "Population-based algorithm that combines the strengths of Differential Evolution and Particle Swarm Optimization, using a velocity update rule inspired by PSO with DE-inspired mutation and crossover for exploration.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, F=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.F = F  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                v_donor = x1 + self.F * (x2 - x3)\n                v_donor = np.clip(v_donor, func.bounds.lb, func.bounds.ub)\n                \n                trial_vector = pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = v_donor[j]\n\n                # PSO Velocity Update and Position Update\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                \n                trial_vector = pop[i] + velocities[i]\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub) # Clip after applying PSO\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < pbest_fitness[i]:\n                    pbest_fitness[i] = f_trial\n                    pbest_pop[i] = trial_vector.copy()\n\n                    if f_trial < gbest_fitness:\n                        gbest_fitness = f_trial\n                        gbest_x = trial_vector.copy()\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial_vector.copy()\n\n\n        return gbest_fitness, gbest_x", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSO scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines the strengths of Differential Evolution and Particle Swarm Optimization, using a velocity update rule inspired by PSO with DE-inspired mutation and crossover for exploration.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.7, F=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.cr = cr  # Crossover rate\n        self.F = F  # Mutation factor\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                v_donor = x1 + self.F * (x2 - x3)\n                v_donor = np.clip(v_donor, func.bounds.lb, func.bounds.ub)\n                \n                trial_vector = pop[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = v_donor[j]\n\n                # PSO Velocity Update and Position Update\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                \n                trial_vector = pop[i] + velocities[i]\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub) # Clip after applying PSO\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < pbest_fitness[i]:\n                    pbest_fitness[i] = f_trial\n                    pbest_pop[i] = trial_vector.copy()\n\n                    if f_trial < gbest_fitness:\n                        gbest_fitness = f_trial\n                        gbest_x = trial_vector.copy()\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial_vector.copy()\n\n\n        return gbest_fitness, gbest_x\n```", "operator": "random_new", "theta_sampled": 0.053897528817835175, "generation": 10, "aucs": [0.14378002750165253, 0.1999513143368451, 0.4165820410382163, 0.2244872731724431, 0.2563405522673542, 0.19040359442234023, 0.2266722418977083, 0.22023496049077507, 0.2012157509150052, 0.21846394840725092, 0.1883149334169696, 0.9980270130196071, 0.2213018032941081, 0.23883013766351446, 0.6506947488999187, 0.3554880724481635, 0.30164731677631396, 0.20579234773587596, 0.17879867456039777, 0.4644732519711068]}, "task_prompt": ""}
{"id": "6a88e0b1-7846-4362-9f45-5b989299a485", "fitness": 0.7014202281120298, "name": "AdaptiveDESuccessCr", "description": "Adaptive Differential Evolution with per-vector crossover probability update based on success.", "code": "import numpy as np\n\nclass AdaptiveDESuccessCr:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = np.full(pop_size, 0.9) # Per-individual Cr\n        self.success_Cr = []\n        self.memory_size = 10\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i] # Use per-individual Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_Cr.append(self.Cr[i])\n                if len(self.success_Cr) > self.memory_size:\n                    self.success_Cr.pop(0) # FIFO queue\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n        # Adapt F and Cr - based on successful Cr values\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        if self.success_Cr:\n          self.Cr = np.full(self.pop_size, np.mean(self.success_Cr))\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDESuccessCr scored 0.701 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "0a78a8fc-74cd-454e-be68-4d87d2ff4a95"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with per-vector crossover probability update based on success.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDESuccessCr:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = np.full(pop_size, 0.9) # Per-individual Cr\n        self.success_Cr = []\n        self.memory_size = 10\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i] # Use per-individual Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.success_Cr.append(self.Cr[i])\n                if len(self.success_Cr) > self.memory_size:\n                    self.success_Cr.pop(0) # FIFO queue\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n            \n        # Adapt F and Cr - based on successful Cr values\n        self.F = 0.5 * (1 + 0.1 * np.random.randn())\n        if self.success_Cr:\n          self.Cr = np.full(self.pop_size, np.mean(self.success_Cr))\n        self.Cr = np.clip(self.Cr, 0.1, 1.0)\n        self.F = np.clip(self.F, 0.1, 0.9)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.11556001182679151, "generation": 10, "aucs": [0.5275672111031265, 0.3795341021109365, 0.5224267606248605, 0.8978406682158409, 0.8817332238364521, 0.8720737854059624, 0.8739566160133766, 0.8601753290337548, 0.23019372168173058, 0.8515875418962174, 0.9523002648751638, 0.9918142609807409, 0.4401412957604087, 0.42205658487533493, 0.7126078273984744, 0.9351528053420818, 0.7133485713295502, 0.5893468291541377, 0.8532777990058209, 0.5212693635966239]}, "task_prompt": ""}
{"id": "3383e5d2-f57b-45f1-a909-e4dabb02676c", "fitness": 0.7654455179935536, "name": "AdaptiveDE", "description": "Self-adaptive Differential Evolution with simplified parameter adaptation and a focus on exploration in early stages.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial F\n        self.Cr = 0.7 # Initial Cr\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Exploration-focused parameter adaptation (higher F and Cr initially)\n        F = 0.7\n        Cr = 0.9\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Linear decrease of exploration parameters\n            F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n            Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDE scored 0.765 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Self-adaptive Differential Evolution with simplified parameter adaptation and a focus on exploration in early stages.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5  # Initial F\n        self.Cr = 0.7 # Initial Cr\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Exploration-focused parameter adaptation (higher F and Cr initially)\n        F = 0.7\n        Cr = 0.9\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Linear decrease of exploration parameters\n            F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n            Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.006394302400317487, "generation": 10, "aucs": [0.29113513540003944, 0.7546532292823682, 0.8096742726389488, 0.9316337395103865, 0.8479155169505654, 0.892716865030522, 0.7884106802398001, 0.7951643419387026, 0.8618590058642225, 0.8326473945204206, 0.9019651975063332, 0.9975018753057442, 0.48600804820655663, 0.8336749803023917, 0.947619599999935, 0.8733389548224338, 0.81038690680036, 0.9010472526203663, 0.24465893043068665, 0.5068984325002892]}, "task_prompt": ""}
{"id": "1e4310b6-75a8-4fc3-ba6a-56901031cb09", "fitness": 0.7266397919780838, "name": "AdaptiveDEWithFitnessImprovement", "description": "Simplified Adaptive DE with per-iteration adaptation of F and Cr based on population fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDEWithFitnessImprovement:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        old_best_fitness = self.f_opt\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on fitness improvement\n        fitness_improvement = old_best_fitness - self.f_opt\n        if fitness_improvement > 0:\n            # If there was improvement, increase F and Cr slightly\n            self.F = np.clip(self.F * (1 + 0.1 * np.random.rand()), 0.1, 0.9)\n            self.Cr = np.clip(self.Cr * (1 + 0.05 * np.random.rand()), 0.1, 1.0)\n        else:\n            # If no improvement, decrease F and Cr slightly\n            self.F = np.clip(self.F * (1 - 0.05 * np.random.rand()), 0.1, 0.9)\n            self.Cr = np.clip(self.Cr * (1 - 0.025 * np.random.rand()), 0.1, 1.0)\n            \n        self.best_fitness_history.append(self.f_opt)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveDEWithFitnessImprovement scored 0.727 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "crossover", "metadata": {"llm_response": "# Description: Simplified Adaptive DE with per-iteration adaptation of F and Cr based on population fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEWithFitnessImprovement:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n        self.best_fitness_history = []\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        self.best_fitness_history.append(self.f_opt)\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        old_best_fitness = self.f_opt\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        # Adapt F and Cr based on fitness improvement\n        fitness_improvement = old_best_fitness - self.f_opt\n        if fitness_improvement > 0:\n            # If there was improvement, increase F and Cr slightly\n            self.F = np.clip(self.F * (1 + 0.1 * np.random.rand()), 0.1, 0.9)\n            self.Cr = np.clip(self.Cr * (1 + 0.05 * np.random.rand()), 0.1, 1.0)\n        else:\n            # If no improvement, decrease F and Cr slightly\n            self.F = np.clip(self.F * (1 - 0.05 * np.random.rand()), 0.1, 0.9)\n            self.Cr = np.clip(self.Cr * (1 - 0.025 * np.random.rand()), 0.1, 1.0)\n            \n        self.best_fitness_history.append(self.f_opt)\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.043717498401577244, "generation": 10, "aucs": [0.30003836860680355, 0.6593972406799253, 0.808258039001234, 0.9035101027701613, 0.32371041187680905, 0.8879127183563797, 0.8107842578804746, 0.7971795139401863, 0.8764421744873577, 0.8481198136777821, 0.9213954889563696, 0.9926064337935101, 0.30379576303341105, 0.8346719689358537, 0.9541840093136305, 0.8832348701087654, 0.7685389213266447, 0.9125557804918143, 0.2282968579572835, 0.5181631043672776]}, "task_prompt": ""}
{"id": "22163acf-0443-4a64-9df8-2deed1955e54", "fitness": 0.0, "name": "HybridDE", "description": "Population-based algorithm with a focus on exploration and exploitation, using a combination of differential evolution and a simple local search strategy to refine solutions.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.7, ls_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_trials = ls_trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            # Local Search - Applied to the current best individual\n            if self.x_opt is not None:\n                x_ls = self.x_opt.copy()\n                f_ls_best = self.f_opt\n                \n                for _ in range(self.ls_trials):\n                    delta = np.random.uniform(-0.1, 0.1, size=self.dim) # Small perturbation\n                    x_ls_trial = x_ls + delta\n                    x_ls_trial = np.clip(x_ls_trial, func.bounds.lb, func.bounds.ub)\n                    \n                    f_ls_trial = func(x_ls_trial)\n                    self.eval_count += 1\n\n                    if f_ls_trial < f_ls_best:\n                        f_ls_best = f_ls_trial\n                        x_ls = x_ls_trial.copy()\n                        \n                        self.f_opt = f_ls_best\n                        self.x_opt = x_ls.copy()\n                    \n                    if self.eval_count >= self.budget:\n                        break\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a focus on exploration and exploitation, using a combination of differential evolution and a simple local search strategy to refine solutions.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.7, ls_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.ls_trials = ls_trials\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                \n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial.copy()\n                \n                if self.eval_count >= self.budget:\n                    break\n            \n            # Local Search - Applied to the current best individual\n            if self.x_opt is not None:\n                x_ls = self.x_opt.copy()\n                f_ls_best = self.f_opt\n                \n                for _ in range(self.ls_trials):\n                    delta = np.random.uniform(-0.1, 0.1, size=self.dim) # Small perturbation\n                    x_ls_trial = x_ls + delta\n                    x_ls_trial = np.clip(x_ls_trial, func.bounds.lb, func.bounds.ub)\n                    \n                    f_ls_trial = func(x_ls_trial)\n                    self.eval_count += 1\n\n                    if f_ls_trial < f_ls_best:\n                        f_ls_best = f_ls_trial\n                        x_ls = x_ls_trial.copy()\n                        \n                        self.f_opt = f_ls_best\n                        self.x_opt = x_ls.copy()\n                    \n                    if self.eval_count >= self.budget:\n                        break\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.28213059268870005, "generation": 10, "aucs": [0]}, "task_prompt": ""}
{"id": "c673c2c4-3af2-4ca5-8904-7218d71b802f", "fitness": 0.38244812406354867, "name": "AdaptiveStepSizeOptimization", "description": "A population-based algorithm with adaptive step size control based on the success rate of improving solutions.", "code": "import numpy as np\n\nclass AdaptiveStepSizeOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate = 0.0  # Initialize success rate\n        self.success_memory = [] # Store success rate for adaptation\n        self.success_memory_size = 10 # Keep track of the last N success rates\n        self.min_step_size = 1e-8 # Avoid premature convergence\n        self.lb = -5.0 # Lower bound\n        self.ub = 5.0 # Upper bound\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            successful_moves = 0\n            \n            for i in range(self.pop_size):\n                # Generate a candidate solution by adding a random step\n                step = np.random.normal(0, self.step_size, size=self.dim)\n                candidate = population[i] + step\n\n                # Clip the candidate to stay within bounds\n                candidate = np.clip(candidate, self.lb, self.ub)\n\n                # Evaluate the candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                if f_candidate < fitness[i]:\n                    new_population[i] = candidate\n                    fitness[i] = f_candidate\n                    successful_moves += 1\n\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n\n                if self.budget <= 0:\n                    break\n                    \n            population = new_population\n            \n            # Update success rate\n            self.success_rate = successful_moves / self.pop_size\n\n            # Store success rate in memory\n            self.success_memory.append(self.success_rate)\n            if len(self.success_memory) > self.success_memory_size:\n                self.success_memory.pop(0)\n\n            # Adapt step size based on success rate\n            avg_success_rate = np.mean(self.success_memory) if self.success_memory else self.success_rate  # Handle empty memory\n            if avg_success_rate > 0.4:\n                self.step_size *= 1.1  # Increase step size if success rate is high\n            elif avg_success_rate < 0.1:\n                self.step_size *= 0.9  # Decrease step size if success rate is low\n                \n            self.step_size = max(self.step_size, self.min_step_size) # Ensure step size doesn't vanish\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveStepSizeOptimization scored 0.382 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive step size control based on the success rate of improving solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveStepSizeOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate = 0.0  # Initialize success rate\n        self.success_memory = [] # Store success rate for adaptation\n        self.success_memory_size = 10 # Keep track of the last N success rates\n        self.min_step_size = 1e-8 # Avoid premature convergence\n        self.lb = -5.0 # Lower bound\n        self.ub = 5.0 # Upper bound\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            successful_moves = 0\n            \n            for i in range(self.pop_size):\n                # Generate a candidate solution by adding a random step\n                step = np.random.normal(0, self.step_size, size=self.dim)\n                candidate = population[i] + step\n\n                # Clip the candidate to stay within bounds\n                candidate = np.clip(candidate, self.lb, self.ub)\n\n                # Evaluate the candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                \n                if f_candidate < fitness[i]:\n                    new_population[i] = candidate\n                    fitness[i] = f_candidate\n                    successful_moves += 1\n\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n\n                if self.budget <= 0:\n                    break\n                    \n            population = new_population\n            \n            # Update success rate\n            self.success_rate = successful_moves / self.pop_size\n\n            # Store success rate in memory\n            self.success_memory.append(self.success_rate)\n            if len(self.success_memory) > self.success_memory_size:\n                self.success_memory.pop(0)\n\n            # Adapt step size based on success rate\n            avg_success_rate = np.mean(self.success_memory) if self.success_memory else self.success_rate  # Handle empty memory\n            if avg_success_rate > 0.4:\n                self.step_size *= 1.1  # Increase step size if success rate is high\n            elif avg_success_rate < 0.1:\n                self.step_size *= 0.9  # Decrease step size if success rate is low\n                \n            self.step_size = max(self.step_size, self.min_step_size) # Ensure step size doesn't vanish\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.12895189167681795, "generation": 11, "aucs": [0.15275678478103327, 0.215228998197588, 0.5114550499195454, 0.613848370914869, 0.5729637399675722, 0.18078385103451622, 0.2768054645643414, 0.4385554989831384, 0.5122270029080622, 0.1446579701274573, 0.4187406877331067, 0.23010658576669762, 0.2971378152329065, 0.3197836356338811, 0.854056691219421, 0.37386651666814363, 0.3323669088600626, 0.6466442621097457, 0.14837597334860853, 0.40860067330027794]}, "task_prompt": ""}
{"id": "db590e69-226a-4dae-9f78-9ab4677ed73d", "fitness": "-inf", "name": "CMAES", "description": "Covariance Matrix Adaptation Evolution Strategy with population size adaptation and orthogonal sampling.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_mu=None, c_cov_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else min(1, self.mueff / self.dim**2)\n        self.c_cov_one = c_cov_one if c_cov_one is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_cov_mu = min(1-self.c_cov_one, self.c_cov_mu)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.path_c = np.zeros(self.dim)\n        self.path_sigma = np.zeros(self.dim) # Changed from dim to dim for consistency\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n        covariance = np.eye(self.dim)\n        C = covariance\n\n        invsqrt_C = np.linalg.inv(np.linalg.cholesky(C)) # Changed calculation\n\n        evals = 0\n\n        while evals < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            x = mean + sigma * (invsqrt_C @ z).T\n            \n            # Clip the solutions to the bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            B = invsqrt_C.T # rotation matrix\n            z = (x[:self.mu] - mean_old) / sigma\n            self.path_sigma = (1-self.cs) * self.path_sigma + np.sqrt(self.cs*(2-self.cs)*self.mueff) * (invsqrt_C @ B.T @ (z).T).mean(axis=1)\n\n            # Update covariance matrix\n            C = (1-self.c_cov_one-self.c_cov_mu) * C + self.c_cov_one * (self.path_sigma[:, None] @ self.path_sigma[None, :]) + self.c_cov_mu * np.sum(self.weights[:,None,None] * (z.T[:,:,None] @ z.T[:,None,:]), axis=0)\n            \n            # Repair covariance matrix if necessary\n            if np.any(np.isnan(C)):\n                C = np.eye(self.dim)\n\n            try:\n                invsqrt_C = np.linalg.inv(np.linalg.cholesky(C))\n            except np.linalg.LinAlgError:\n                C = C + 1e-6 * np.eye(self.dim)\n                invsqrt_C = np.linalg.inv(np.linalg.cholesky(C)) # Added try-except block\n\n            # Update step size\n            sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.path_sigma)/np.sqrt(self.dim) - 1))\n\n            # Adaptive Population Size\n            if evals > self.budget * 0.8 and self.popsize > 5:  # Reduce population size if near budget limit\n                self.popsize = max(5, self.popsize // 2)\n                self.mu = self.popsize // 2\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "In the code, line 67, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (3,1,1) (2,3,3) \nOn line: C = (1-self.c_cov_one-self.c_cov_mu) * C + self.c_cov_one * (self.path_sigma[:, None] @ self.path_sigma[None, :]) + self.c_cov_mu * np.sum(self.weights[:,None,None] * (z.T[:,:,None] @ z.T[:,None,:]), axis=0)", "error": "In the code, line 67, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (3,1,1) (2,3,3) \nOn line: C = (1-self.c_cov_one-self.c_cov_mu) * C + self.c_cov_one * (self.path_sigma[:, None] @ self.path_sigma[None, :]) + self.c_cov_mu * np.sum(self.weights[:,None,None] * (z.T[:,:,None] @ z.T[:,None,:]), axis=0)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with population size adaptation and orthogonal sampling.\n# Code:\n```python\nimport numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.3, damps=None, c_cov_mu=None, c_cov_one=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.c_cov_mu = c_cov_mu if c_cov_mu is not None else min(1, self.mueff / self.dim**2)\n        self.c_cov_one = c_cov_one if c_cov_one is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.c_cov_mu = min(1-self.c_cov_one, self.c_cov_mu)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.path_c = np.zeros(self.dim)\n        self.path_sigma = np.zeros(self.dim) # Changed from dim to dim for consistency\n\n    def __call__(self, func):\n        # Initialization\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = 0.1 * (func.bounds.ub - func.bounds.lb)\n        covariance = np.eye(self.dim)\n        C = covariance\n\n        invsqrt_C = np.linalg.inv(np.linalg.cholesky(C)) # Changed calculation\n\n        evals = 0\n\n        while evals < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            x = mean + sigma * (invsqrt_C @ z).T\n            \n            # Clip the solutions to the bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            f = np.array([func(xi) for xi in x])\n            evals += self.popsize\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            B = invsqrt_C.T # rotation matrix\n            z = (x[:self.mu] - mean_old) / sigma\n            self.path_sigma = (1-self.cs) * self.path_sigma + np.sqrt(self.cs*(2-self.cs)*self.mueff) * (invsqrt_C @ B.T @ (z).T).mean(axis=1)\n\n            # Update covariance matrix\n            C = (1-self.c_cov_one-self.c_cov_mu) * C + self.c_cov_one * (self.path_sigma[:, None] @ self.path_sigma[None, :]) + self.c_cov_mu * np.sum(self.weights[:,None,None] * (z.T[:,:,None] @ z.T[:,None,:]), axis=0)\n            \n            # Repair covariance matrix if necessary\n            if np.any(np.isnan(C)):\n                C = np.eye(self.dim)\n\n            try:\n                invsqrt_C = np.linalg.inv(np.linalg.cholesky(C))\n            except np.linalg.LinAlgError:\n                C = C + 1e-6 * np.eye(self.dim)\n                invsqrt_C = np.linalg.inv(np.linalg.cholesky(C)) # Added try-except block\n\n            # Update step size\n            sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.path_sigma)/np.sqrt(self.dim) - 1))\n\n            # Adaptive Population Size\n            if evals > self.budget * 0.8 and self.popsize > 5:  # Reduce population size if near budget limit\n                self.popsize = max(5, self.popsize // 2)\n                self.mu = self.popsize // 2\n                self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n                self.weights = self.weights / np.sum(self.weights)\n                self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03268174045371844, "generation": 11}, "task_prompt": ""}
{"id": "296385b4-5de1-4d68-bd79-cb31bf07834f", "fitness": 0.0, "name": "ProbabilisticAdaptiveDE", "description": "Adaptive Differential Evolution with probabilistic parameter adaptation and population reduction.", "code": "import numpy as np\n\nclass ProbabilisticAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.7, reduce_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.reduce_freq = reduce_freq\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Parameter Adaptation (probabilistic)\n            if np.random.rand() < 0.1:  # 10% chance to adapt F\n                self.F = 0.5 + 0.3 * np.random.randn()\n                self.F = np.clip(self.F, 0.1, 0.9)\n            if np.random.rand() < 0.1:  # 10% chance to adapt Cr\n                self.Cr = 0.7 + 0.2 * np.random.randn()\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            \n            # Population Reduction (every reduce_freq generations)\n            generation += 1\n            if generation * self.pop_size > self.reduce_freq and self.pop_size > 10:\n                generation = 0\n                num_to_reduce = max(1, int(self.pop_size * 0.1))  # Reduce by 10%, at least 1\n                \n                # Remove the worst individuals\n                worst_indices = np.argsort(fitness)[-num_to_reduce:]\n                pop = np.delete(pop, worst_indices, axis=0)\n                fitness = np.delete(fitness, worst_indices)\n                self.pop_size = pop.shape[0] # update pop size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = pop[best_index]\n        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm ProbabilisticAdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with probabilistic parameter adaptation and population reduction.\n# Code: \n```python\nimport numpy as np\n\nclass ProbabilisticAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, Cr=0.7, reduce_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.reduce_freq = reduce_freq\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        generation = 0\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Parameter Adaptation (probabilistic)\n            if np.random.rand() < 0.1:  # 10% chance to adapt F\n                self.F = 0.5 + 0.3 * np.random.randn()\n                self.F = np.clip(self.F, 0.1, 0.9)\n            if np.random.rand() < 0.1:  # 10% chance to adapt Cr\n                self.Cr = 0.7 + 0.2 * np.random.randn()\n                self.Cr = np.clip(self.Cr, 0.1, 1.0)\n            \n            # Population Reduction (every reduce_freq generations)\n            generation += 1\n            if generation * self.pop_size > self.reduce_freq and self.pop_size > 10:\n                generation = 0\n                num_to_reduce = max(1, int(self.pop_size * 0.1))  # Reduce by 10%, at least 1\n                \n                # Remove the worst individuals\n                worst_indices = np.argsort(fitness)[-num_to_reduce:]\n                pop = np.delete(pop, worst_indices, axis=0)\n                fitness = np.delete(fitness, worst_indices)\n                self.pop_size = pop.shape[0] # update pop size\n\n                best_index = np.argmin(fitness)\n                self.f_opt = fitness[best_index]\n                self.x_opt = pop[best_index]\n        \n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": -0.010262054215053546, "generation": 11, "aucs": [0]}, "task_prompt": ""}
{"id": "e569f2b0-2b9f-48d8-ad09-7063284bd716", "fitness": 0.330155879820182, "name": "HybridVelocityDE", "description": "Population-based algorithm that uses a combination of velocity updates inspired by PSO and differential evolution mutation to explore the search space.", "code": "import numpy as np\n\nclass HybridVelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.4, c2=1.4, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1 # Cognitive coefficient for PSO\n        self.c2 = c2 # Social coefficient for PSO\n        self.f = f   # Mutation factor for DE\n        self.cr = cr  # Crossover rate for DE\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pbest_pop[np.argmin(self.pbest_fitness)].copy()\n        self.gbest_f = np.min(self.pbest_fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO inspired velocity update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = (self.w * self.velocities[i] +\n                            self.c1 * r1 * (self.pbest_pop[i] - self.pop[i]) +\n                            self.c2 * r2 * (self.gbest_x - self.pop[i]))\n                \n                # Ensure velocity components respect bounds\n                velocity = np.clip(velocity, -1, 1)\n                \n                # DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        v[j] = self.pop[i, j]\n\n                # Move particle\n                new_x = self.pop[i] + velocity\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_f = func(new_x)\n                eval_count += 1\n                \n                if new_f < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = new_f\n                        self.pbest_pop[i] = new_x.copy()\n\n                        if new_f < self.gbest_f:\n                            self.gbest_f = new_f\n                            self.gbest_x = new_x.copy()\n\n                if eval_count >= self.budget:\n                    break\n        \n        return self.gbest_f, self.gbest_x", "configspace": "", "generation": 11, "feedback": "The algorithm HybridVelocityDE scored 0.330 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that uses a combination of velocity updates inspired by PSO and differential evolution mutation to explore the search space.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridVelocityDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.4, c2=1.4, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1 # Cognitive coefficient for PSO\n        self.c2 = c2 # Social coefficient for PSO\n        self.f = f   # Mutation factor for DE\n        self.cr = cr  # Crossover rate for DE\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pbest_pop[np.argmin(self.pbest_fitness)].copy()\n        self.gbest_f = np.min(self.pbest_fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO inspired velocity update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = (self.w * self.velocities[i] +\n                            self.c1 * r1 * (self.pbest_pop[i] - self.pop[i]) +\n                            self.c2 * r2 * (self.gbest_x - self.pop[i]))\n                \n                # Ensure velocity components respect bounds\n                velocity = np.clip(velocity, -1, 1)\n                \n                # DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                v = self.pop[i] + self.f * (x2 - x3)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        v[j] = self.pop[i, j]\n\n                # Move particle\n                new_x = self.pop[i] + velocity\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_f = func(new_x)\n                eval_count += 1\n                \n                if new_f < self.fitness[i]:\n                    self.pop[i] = new_x\n                    self.fitness[i] = new_f\n\n                    if new_f < self.pbest_fitness[i]:\n                        self.pbest_fitness[i] = new_f\n                        self.pbest_pop[i] = new_x.copy()\n\n                        if new_f < self.gbest_f:\n                            self.gbest_f = new_f\n                            self.gbest_x = new_x.copy()\n\n                if eval_count >= self.budget:\n                    break\n        \n        return self.gbest_f, self.gbest_x\n```", "operator": "random_new", "theta_sampled": 0.047489897324524105, "generation": 11, "aucs": [0.16142373977946978, 0.26022930329626837, 0.3467360328602659, 0.17615879418970692, 0.26989009383792495, 0.3172414705861303, 0.2299871702947479, 0.2852762384586205, 0.27025307922131425, 0.17232751305632843, 0.32040363631451874, 0.9991633172052362, 0.2674592130773594, 0.2669015626870739, 0.7107765588423892, 0.2755819149950838, 0.2631614738261905, 0.3498280170841622, 0.17209060977253288, 0.48822785701831717]}, "task_prompt": ""}
{"id": "e7aad7b2-76ed-4726-a3b9-48fa39a282ac", "fitness": 0.7385096623856815, "name": "PSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on fitness landscape exploration.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.9, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f  # Mutation factor for DE\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n    \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Initial population evaluation\n        \n        while eval_count < self.budget:\n            # Adaptive parameter adjustments based on landscape exploration\n            if np.std(self.fitness) < 1e-6:  # Stagnation detection\n                self.w = 0.9  # Increase exploration\n                self.cr = 0.1 # increase exploration\n            else:\n                self.w = 0.7\n                self.cr = 0.9\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (self.pop[i] - self.pop[i]) + self.c1 * np.random.rand(self.dim) * (self.best_pos - self.pop[i]) + self.c2 * np.random.rand(self.dim) * (self.pop[np.random.randint(self.pop_size)] - self.pop[i])\n                new_x_pso = self.pop[i] + v\n                new_x_pso = np.clip(new_x_pso, self.lb, self.ub)\n\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                j_rand = np.random.randint(self.dim)\n                new_x_de = self.pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = mutant[j]\n\n                # Combine PSO and DE\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                    \n                f = func(new_x)\n                eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = new_x\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_pos = new_x.copy()\n                \n                if eval_count >= self.budget:\n                    break\n        \n        return self.best_fitness, self.best_pos", "configspace": "", "generation": 11, "feedback": "The algorithm PSO_DE scored 0.739 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE) with adaptive parameter control based on fitness landscape exploration.\n# Code: \n```python\nimport numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, cr=0.9, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f  # Mutation factor for DE\n        self.pop = None\n        self.fitness = None\n        self.best_pos = None\n        self.best_fitness = np.inf\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.best_pos = self.pop[np.argmin(self.fitness)].copy()\n        self.best_fitness = np.min(self.fitness)\n    \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Initial population evaluation\n        \n        while eval_count < self.budget:\n            # Adaptive parameter adjustments based on landscape exploration\n            if np.std(self.fitness) < 1e-6:  # Stagnation detection\n                self.w = 0.9  # Increase exploration\n                self.cr = 0.1 # increase exploration\n            else:\n                self.w = 0.7\n                self.cr = 0.9\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (self.pop[i] - self.pop[i]) + self.c1 * np.random.rand(self.dim) * (self.best_pos - self.pop[i]) + self.c2 * np.random.rand(self.dim) * (self.pop[np.random.randint(self.pop_size)] - self.pop[i])\n                new_x_pso = self.pop[i] + v\n                new_x_pso = np.clip(new_x_pso, self.lb, self.ub)\n\n                # DE update\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n                \n                j_rand = np.random.randint(self.dim)\n                new_x_de = self.pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = mutant[j]\n\n                # Combine PSO and DE\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                    \n                f = func(new_x)\n                eval_count += 1\n                \n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.pop[i] = new_x\n                    if f < self.best_fitness:\n                        self.best_fitness = f\n                        self.best_pos = new_x.copy()\n                \n                if eval_count >= self.budget:\n                    break\n        \n        return self.best_fitness, self.best_pos\n```", "operator": "random_new", "theta_sampled": 0.12300504953239809, "generation": 11, "aucs": [0.25835587455216824, 0.7830020002849427, 0.8747292091769826, 0.9574964422399102, 0.9144885980554442, 0.9311509915051847, 0.3336110682168717, 0.834578346199661, 0.9089815586190413, 0.23046756529451362, 0.9443018509804798, 0.9976860261168067, 0.5012824644710978, 0.3095997061868392, 0.949193261849086, 0.931695597635535, 0.8318616117436838, 0.9468069199054159, 0.8242491036057895, 0.5066550510741757]}, "task_prompt": ""}
{"id": "bd5eeaca-6b81-4d9b-8ffb-0cde4f3a41cd", "fitness": 0.6563821790237343, "name": "GuidedSelfAdaptiveDE", "description": "Simplified self-adaptive differential evolution with population-wide best-guided mutation and adaptive parameters.", "code": "import numpy as np\n\nclass GuidedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation: Guided by population best\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = pop[idxs]\n                x_mutated = pop[i] + self.F * (self.x_opt - pop[i]) + self.F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm GuidedSelfAdaptiveDE scored 0.656 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "simplify", "metadata": {"llm_response": "# Description: Simplified self-adaptive differential evolution with population-wide best-guided mutation and adaptive parameters.\n# Code:\n```python\nimport numpy as np\n\nclass GuidedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.5\n        self.Cr = 0.7\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = pop[best_index]\n\n        # Evolution\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation: Guided by population best\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x_r1, x_r2 = pop[idxs]\n                x_mutated = pop[i] + self.F * (self.x_opt - pop[i]) + self.F * (x_r1 - x_r2)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = pop[i].copy()\n                mask = np.random.rand(self.dim) < self.Cr\n                x_trial[mask] = x_mutated[mask]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Parameter Adaptation (simplified)\n            self.F = 0.5 + 0.1 * np.random.randn()\n            self.Cr = 0.7 + 0.1 * np.random.randn()\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.Cr = np.clip(self.Cr, 0.1, 1.0)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "simplify", "theta_sampled": 0.0023884914178689933, "generation": 11, "aucs": [0.44538861795472806, 0.2341603980454937, 0.7238937398840963, 0.9622384163068027, 0.258391712214848, 0.9449631675671337, 0.34203938614645113, 0.8974025832313075, 0.9205506616300531, 0.4615267310121972, 0.9518205652515829, 0.9995729868674462, 0.3707041260997538, 0.8766233096645787, 0.97243205981139, 0.6584298791221848, 0.8545330693072611, 0.4435563858040955, 0.3016435936560675, 0.5077721908972159]}, "task_prompt": ""}
{"id": "8d65b7b3-8fe1-4f7b-a8f5-4208754db794", "fitness": "-inf", "name": "CMAES_OBL", "description": "Covariance Matrix Adaptation Evolution Strategy with a population-based mutation strategy based on opposition-based learning.", "code": "import numpy as np\n\nclass CMAES_OBL:\n    def __init__(self, budget=10000, dim=10, popsize=None, mu=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0  # Overall standard deviation\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else self.popsize // 2  # Number of parents\n        self.mu = int(self.mu)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))  # Weights for recombination\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Strategy parameter setting: Adaptation\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        while self.func_evals < self.budget:\n            # Generate and evaluate lambda offspring\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean + self.sigma0 * y\n            \n            # Opposition-based learning mutation:\n            x_opp = 2 * np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) - x\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            x_opp = np.clip(x_opp, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x.T])\n            f_opp = np.array([func(xi) for xi in x_opp.T])\n\n            self.func_evals += 2 * self.popsize\n\n            if self.func_evals > self.budget:\n                remaining_evals = self.budget - (self.func_evals - 2 * self.popsize)\n                x_valid = x[:, :remaining_evals // 2]\n                x_opp_valid = x_opp[:, :remaining_evals // 2]\n                f = f[:remaining_evals//2]\n                f_opp = f_opp[:remaining_evals//2]\n                \n                x = np.concatenate((x_valid, x_opp_valid), axis=1)\n                f = np.concatenate((f, f_opp), axis=0)\n                \n                self.func_evals = self.budget\n            else:\n                x = np.concatenate((x, x_opp), axis=1)\n                f = np.concatenate((f, f_opp), axis=0)\n\n\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            y_w = xmean - self.mean\n            yw = y_w / self.sigma0\n            \n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * yw * np.random.normal()  # Added noise\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.func_evals / self.popsize)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * yw\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.cc * (2-self.cc) * self.C) + self.cmu * np.sum(self.weights * np.array([np.outer(x[:,i] - self.mean, x[:,i] - self.mean) for i in range(self.mu)]), axis=0)\n\n            self.sigma0 *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean = xmean\n            \n            # Repair covariance matrix\n            if np.any(np.diag(self.C) <= 0):\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma0 = self.sigma0 / 2\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "In the code, line 36, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = self.mean + self.sigma0 * y", "error": "In the code, line 36, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = self.mean + self.sigma0 * y", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with a population-based mutation strategy based on opposition-based learning.\n# Code: \n```python\nimport numpy as np\n\nclass CMAES_OBL:\n    def __init__(self, budget=10000, dim=10, popsize=None, mu=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0  # Overall standard deviation\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = mu if mu is not None else self.popsize // 2  # Number of parents\n        self.mu = int(self.mu)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))  # Weights for recombination\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Strategy parameter setting: Adaptation\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        while self.func_evals < self.budget:\n            # Generate and evaluate lambda offspring\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean + self.sigma0 * y\n            \n            # Opposition-based learning mutation:\n            x_opp = 2 * np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) - x\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            x_opp = np.clip(x_opp, func.bounds.lb, func.bounds.ub)\n\n            f = np.array([func(xi) for xi in x.T])\n            f_opp = np.array([func(xi) for xi in x_opp.T])\n\n            self.func_evals += 2 * self.popsize\n\n            if self.func_evals > self.budget:\n                remaining_evals = self.budget - (self.func_evals - 2 * self.popsize)\n                x_valid = x[:, :remaining_evals // 2]\n                x_opp_valid = x_opp[:, :remaining_evals // 2]\n                f = f[:remaining_evals//2]\n                f_opp = f_opp[:remaining_evals//2]\n                \n                x = np.concatenate((x_valid, x_opp_valid), axis=1)\n                f = np.concatenate((f, f_opp), axis=0)\n                \n                self.func_evals = self.budget\n            else:\n                x = np.concatenate((x, x_opp), axis=1)\n                f = np.concatenate((f, f_opp), axis=0)\n\n\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            y_w = xmean - self.mean\n            yw = y_w / self.sigma0\n            \n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * yw * np.random.normal()  # Added noise\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.func_evals / self.popsize)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * yw\n            \n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.cc * (2-self.cc) * self.C) + self.cmu * np.sum(self.weights * np.array([np.outer(x[:,i] - self.mean, x[:,i] - self.mean) for i in range(self.mu)]), axis=0)\n\n            self.sigma0 *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.mean = xmean\n            \n            # Repair covariance matrix\n            if np.any(np.diag(self.C) <= 0):\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.sigma0 = self.sigma0 / 2\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.15808086295036933, "generation": 11}, "task_prompt": ""}
{"id": "3de83135-5c17-4f40-9b7c-a061590e4003", "fitness": 0.7763645935121757, "name": "ImprovedAdaptiveDE", "description": "Adaptive Differential Evolution with linearly decreasing exploration favoring exploitation later in the search.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from AdaptiveDE)\n        F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm ImprovedAdaptiveDE scored 0.776 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["6705faa0-b1f5-4410-b472-5127f5cdbcab", "3383e5d2-f57b-45f1-a909-e4dabb02676c"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with linearly decreasing exploration favoring exploitation later in the search.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from AdaptiveDE)\n        F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + F * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.009271095140635349, "generation": 11, "aucs": [0.38210922476250153, 0.8030073803828224, 0.7983570487639813, 0.9231858134277462, 0.8369823952191675, 0.887282671882631, 0.7676900931861775, 0.7800653771802664, 0.8509078443155411, 0.8312091588064741, 0.9248785443087778, 0.9996657357834277, 0.629501889790837, 0.8411851745848624, 0.9486009892995001, 0.8678014271160996, 0.7695504389179065, 0.9101459551104398, 0.25164784147649166, 0.5235168659278581]}, "task_prompt": ""}
{"id": "2c41a60f-e99d-4638-9a82-0d4246aefd0a", "fitness": 0.7543209049114782, "name": "EnhancedAdaptiveDE", "description": "Combines linear parameter adaptation with individual-based parameter tuning for improved DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = np.full(pop_size, 0.5)\n        self.Cr = np.full(pop_size, 0.9)\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from AdaptiveDE), applied globally\n        global_F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        global_Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i]\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Adaptation of F and Cr (inspired by SelfAdaptiveDE)\n                if f_trial < self.fitness[i]:\n                    self.F[i] = global_F + 0.1 * np.random.randn()\n                    self.Cr[i] = global_Cr + 0.05 * np.random.randn()\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Clip F and Cr\n            self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n            self.Cr[i] = np.clip(self.Cr[i], 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveDE scored 0.754 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3de83135-5c17-4f40-9b7c-a061590e4003", "f925d824-577f-46e2-b10e-f21ba2d88743"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines linear parameter adaptation with individual-based parameter tuning for improved DE.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = np.full(pop_size, 0.5)\n        self.Cr = np.full(pop_size, 0.9)\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from AdaptiveDE), applied globally\n        global_F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        global_Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + self.F[i] * (x_r2 - x_r3)\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < self.Cr[i]\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                # Adaptation of F and Cr (inspired by SelfAdaptiveDE)\n                if f_trial < self.fitness[i]:\n                    self.F[i] = global_F + 0.1 * np.random.randn()\n                    self.Cr[i] = global_Cr + 0.05 * np.random.randn()\n\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n            # Clip F and Cr\n            self.F[i] = np.clip(self.F[i], 0.1, 0.9)\n            self.Cr[i] = np.clip(self.Cr[i], 0.1, 1.0)\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": -0.005332762403471225, "generation": 12, "aucs": [0.31374104316079277, 0.7274856231578338, 0.8040116037772319, 0.9286136450376041, 0.8328649899280895, 0.8872223642903728, 0.7509893812581515, 0.8119444813166938, 0.8355917493003837, 0.8384636884876848, 0.8923869931792827, 0.9965053150589669, 0.40096958060328525, 0.8268118928006045, 0.9370672849630808, 0.8720248911642685, 0.7079207213613486, 0.8885566000284572, 0.29989770971226726, 0.5333485396431639]}, "task_prompt": ""}
{"id": "e4743dba-20ef-4502-b7e4-187e76a2e582", "fitness": "-inf", "name": "HybridDEPSO", "description": "A population-based algorithm that combines features of differential evolution and particle swarm optimization, adaptively adjusting parameters based on population diversity and success rate.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.CR = CR  # Differential evolution crossover rate\n        self.w = w    # PSO inertia weight\n        self.c1 = c1  # PSO cognitive coefficient\n        self.c2 = c2  # PSO social coefficient\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.velocities = None\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.1  # Initialize velocities\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def de_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        v_mutation = x_r1 + self.F * (x_r2 - x_r3)\n        return v_mutation\n\n    def pso_velocity_update(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.c1 * r1 * (self.best_position - self.pop[i])\n        social_component = self.c2 * r2 * (self.pop[np.argmin(self.fitness)] - self.pop[i]) # Use best individual in current population for social component\n        self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Adaptive parameter control based on population diversity\n                diversity = np.std(self.pop)\n                adaptive_F = self.F * (1 + diversity)  # Example: Increase F with higher diversity\n                adaptive_CR = min(1.0, self.CR + diversity)  #Example: Reduce CR with lower diversity\n\n                # Apply DE mutation\n                v_mutation = self.de_mutation(i)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_i = np.array([np.random.rand() < adaptive_CR or j == j_rand for j in range(self.dim)])\n                trial_vector = np.where(u_i, v_mutation, self.pop[i])\n\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial_vector.copy()\n\n                    # Update global best\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_position = trial_vector.copy()\n                        \n                #PSO Component\n                self.pso_velocity_update(i)\n                self.pop[i] = np.clip(self.pop[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Re-evaluate after PSO update\n                f_updated = func(self.pop[i])\n                eval_count += 1\n                if f_updated < self.fitness[i]:\n                    self.fitness[i] = f_updated\n                    if f_updated < self.best_fitness:\n                        self.best_fitness = f_updated\n                        self.best_position = self.pop[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position", "configspace": "", "generation": 12, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines features of differential evolution and particle swarm optimization, adaptively adjusting parameters based on population diversity and success rate.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.CR = CR  # Differential evolution crossover rate\n        self.w = w    # PSO inertia weight\n        self.c1 = c1  # PSO cognitive coefficient\n        self.c2 = c2  # PSO social coefficient\n        self.pop = None\n        self.fitness = None\n        self.best_fitness = np.inf\n        self.best_position = None\n        self.velocities = None\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) * 0.1  # Initialize velocities\n\n        self.best_fitness = np.min(self.fitness)\n        self.best_position = self.pop[np.argmin(self.fitness)].copy()\n\n    def de_mutation(self, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        while i in idxs:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n\n        x_r1, x_r2, x_r3 = self.pop[idxs]\n        v_mutation = x_r1 + self.F * (x_r2 - x_r3)\n        return v_mutation\n\n    def pso_velocity_update(self, i):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        cognitive_component = self.c1 * r1 * (self.best_position - self.pop[i])\n        social_component = self.c2 * r2 * (self.pop[np.argmin(self.fitness)] - self.pop[i]) # Use best individual in current population for social component\n        self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluations\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                \n                # Adaptive parameter control based on population diversity\n                diversity = np.std(self.pop)\n                adaptive_F = self.F * (1 + diversity)  # Example: Increase F with higher diversity\n                adaptive_CR = min(1.0, self.CR + diversity)  #Example: Reduce CR with lower diversity\n\n                # Apply DE mutation\n                v_mutation = self.de_mutation(i)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u_i = np.array([np.random.rand() < adaptive_CR or j == j_rand for j in range(self.dim)])\n                trial_vector = np.where(u_i, v_mutation, self.pop[i])\n\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n                # Evaluate trial vector\n                f_trial = func(trial_vector)\n                eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = trial_vector.copy()\n\n                    # Update global best\n                    if f_trial < self.best_fitness:\n                        self.best_fitness = f_trial\n                        self.best_position = trial_vector.copy()\n                        \n                #PSO Component\n                self.pso_velocity_update(i)\n                self.pop[i] = np.clip(self.pop[i] + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Re-evaluate after PSO update\n                f_updated = func(self.pop[i])\n                eval_count += 1\n                if f_updated < self.fitness[i]:\n                    self.fitness[i] = f_updated\n                    if f_updated < self.best_fitness:\n                        self.best_fitness = f_updated\n                        self.best_position = self.pop[i].copy()\n\n                if eval_count >= self.budget:\n                    break\n\n\n        return self.best_fitness, self.best_position\n```", "operator": "random_new", "theta_sampled": 0.024919880031230315, "generation": 12}, "task_prompt": ""}
{"id": "0f277821-5a62-40c2-a503-862a1516cad9", "fitness": "-inf", "name": "HybridDECMAS", "description": "A population-based algorithm that blends features of differential evolution and covariance matrix adaptation evolution strategy (CMA-ES) to adaptively explore and exploit the search space.", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma0=0.5, cs=0.3, damps=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2  # Number of parents\n        self.sigma = sigma0\n        self.cs = cs\n        self.damps = damps #Damping for step size\n        self.C = np.eye(dim)  # Covariance matrix (initialized as identity)\n        self.pc = np.zeros(dim) #Evolution path for C\n        self.ps = np.zeros(dim) #Evolution path for sigma\n        self.eigeneval_tries = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        while evals < self.budget:\n            # 1. Selection and Recombination (Differential Evolution Style)\n            indices = np.arange(self.pop_size)\n            np.random.shuffle(indices)\n            \n            for i in range(self.pop_size):\n                a, b, c = indices[np.random.choice(self.pop_size, 3, replace=False)]\n                \n                #DE mutation\n                mutant = population[a] + 0.5 * (population[b] - population[c])\n                \n                #DE crossover\n                j_rand = np.random.randint(self.dim)\n                trial = population[i].copy()\n                for j in range(self.dim):\n                  if np.random.rand() < 0.7 or j == j_rand:\n                    trial[j] = mutant[j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n\n            # 2. Selection (CMA-ES style)\n            elite_indices = np.argsort(fitness)[:self.mu]\n            elite_population = population[elite_indices]\n            \n            # Compute the weighted mean of the elite individuals\n            weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            weights /= np.sum(weights)\n            mean = np.sum(elite_population * weights[:, None], axis=0)\n            \n            #3. Update evolution paths\n            y = (mean - np.mean(population, axis = 0))/self.sigma\n\n            self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs))*y\n            self.pc = (1-self.damps)*self.pc + np.sqrt(self.damps*(2-self.damps))*np.sqrt(weights[0])*y\n            \n            # 4. Adapt Covariance Matrix\n            delta = elite_population - np.tile(mean, (self.mu, 1))\n            rank_one = np.sum([w * np.outer(delta[i], delta[i]) for i, w in enumerate(weights)], axis=0)\n\n            self.C = (1 - self.damps) * self.C + self.damps/np.linalg.norm(self.ps)**2 * np.outer(self.ps, self.ps) + (1 - self.damps) * self.damps * rank_one\n\n\n            # 5. Adapt step size\n            cn = self.cs/np.linalg.norm(self.ps)\n            self.sigma *= np.exp(cn * (np.linalg.norm(self.ps)/ np.sqrt(self.dim) - 1))\n                    \n            # 6. Generate new population (CMA-ES sampling)\n            try:\n                L = np.linalg.cholesky(self.C)\n                new_population = np.array([mean + self.sigma * L @ np.random.randn(self.dim) for _ in range(self.pop_size)])\n            except np.linalg.LinAlgError:\n                self.eigeneval_tries += 1\n                # If the covariance matrix is not positive definite, reset it to identity\n                self.C = np.eye(self.dim)\n                L = np.eye(self.dim)\n                new_population = np.array([mean + self.sigma * L @ np.random.randn(self.dim) for _ in range(self.pop_size)])\n\n\n\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n            new_fitness = np.array([func(x) for x in new_population])\n            evals += self.pop_size\n\n            #Elitism\n            worst_index = np.argmax(fitness)\n            if np.min(new_fitness) < fitness[worst_index]:\n                best_new_index = np.argmin(new_fitness)\n                population[worst_index] = new_population[best_new_index]\n                fitness[worst_index] = new_fitness[best_new_index]\n\n            for i in range(self.pop_size):\n              if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n            \n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that blends features of differential evolution and covariance matrix adaptation evolution strategy (CMA-ES) to adaptively explore and exploit the search space.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma0=0.5, cs=0.3, damps=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2  # Number of parents\n        self.sigma = sigma0\n        self.cs = cs\n        self.damps = damps #Damping for step size\n        self.C = np.eye(dim)  # Covariance matrix (initialized as identity)\n        self.pc = np.zeros(dim) #Evolution path for C\n        self.ps = np.zeros(dim) #Evolution path for sigma\n        self.eigeneval_tries = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        while evals < self.budget:\n            # 1. Selection and Recombination (Differential Evolution Style)\n            indices = np.arange(self.pop_size)\n            np.random.shuffle(indices)\n            \n            for i in range(self.pop_size):\n                a, b, c = indices[np.random.choice(self.pop_size, 3, replace=False)]\n                \n                #DE mutation\n                mutant = population[a] + 0.5 * (population[b] - population[c])\n                \n                #DE crossover\n                j_rand = np.random.randint(self.dim)\n                trial = population[i].copy()\n                for j in range(self.dim):\n                  if np.random.rand() < 0.7 or j == j_rand:\n                    trial[j] = mutant[j]\n\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial.copy()\n                        \n\n            # 2. Selection (CMA-ES style)\n            elite_indices = np.argsort(fitness)[:self.mu]\n            elite_population = population[elite_indices]\n            \n            # Compute the weighted mean of the elite individuals\n            weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n            weights /= np.sum(weights)\n            mean = np.sum(elite_population * weights[:, None], axis=0)\n            \n            #3. Update evolution paths\n            y = (mean - np.mean(population, axis = 0))/self.sigma\n\n            self.ps = (1-self.cs)*self.ps + np.sqrt(self.cs*(2-self.cs))*y\n            self.pc = (1-self.damps)*self.pc + np.sqrt(self.damps*(2-self.damps))*np.sqrt(weights[0])*y\n            \n            # 4. Adapt Covariance Matrix\n            delta = elite_population - np.tile(mean, (self.mu, 1))\n            rank_one = np.sum([w * np.outer(delta[i], delta[i]) for i, w in enumerate(weights)], axis=0)\n\n            self.C = (1 - self.damps) * self.C + self.damps/np.linalg.norm(self.ps)**2 * np.outer(self.ps, self.ps) + (1 - self.damps) * self.damps * rank_one\n\n\n            # 5. Adapt step size\n            cn = self.cs/np.linalg.norm(self.ps)\n            self.sigma *= np.exp(cn * (np.linalg.norm(self.ps)/ np.sqrt(self.dim) - 1))\n                    \n            # 6. Generate new population (CMA-ES sampling)\n            try:\n                L = np.linalg.cholesky(self.C)\n                new_population = np.array([mean + self.sigma * L @ np.random.randn(self.dim) for _ in range(self.pop_size)])\n            except np.linalg.LinAlgError:\n                self.eigeneval_tries += 1\n                # If the covariance matrix is not positive definite, reset it to identity\n                self.C = np.eye(self.dim)\n                L = np.eye(self.dim)\n                new_population = np.array([mean + self.sigma * L @ np.random.randn(self.dim) for _ in range(self.pop_size)])\n\n\n\n            new_population = np.clip(new_population, func.bounds.lb, func.bounds.ub)\n            new_fitness = np.array([func(x) for x in new_population])\n            evals += self.pop_size\n\n            #Elitism\n            worst_index = np.argmax(fitness)\n            if np.min(new_fitness) < fitness[worst_index]:\n                best_new_index = np.argmin(new_fitness)\n                population[worst_index] = new_population[best_new_index]\n                fitness[worst_index] = new_fitness[best_new_index]\n\n            for i in range(self.pop_size):\n              if new_fitness[i] < fitness[i]:\n                population[i] = new_population[i]\n                fitness[i] = new_fitness[i]\n            \n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)].copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.06027895750667425, "generation": 12}, "task_prompt": ""}
{"id": "9ff6010c-48fc-4406-97b3-838092705d96", "fitness": "-inf", "name": "OrthogonalPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), with a focus on exploration using orthogonal design to sample diverse solutions.", "code": "import numpy as np\n\nclass OrthogonalPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, c1=1.49445, c2=1.49445, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.orthogonal_design = self.generate_orthogonal_design()\n\n    def generate_orthogonal_design(self, num_factors=None, levels=3):\n        \"\"\"Generates an orthogonal design using a simple approach.\n           For proper orthogonal designs, a dedicated library is recommended (e.g., pyDOE).\n           This implementation ensures basic diversity but may not satisfy all orthogonality properties.\n        \"\"\"\n        if num_factors is None:\n            num_factors = self.dim  # Use problem dimensionality as the number of factors\n\n        design = np.zeros((levels, num_factors))\n        for i in range(levels):\n            for j in range(num_factors):\n                design[i, j] = (i / (levels - 1))  # Normalize to [0, 1] range\n\n        return design\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(func.bounds.ub - func.bounds.lb) / 10, abs(func.bounds.ub - func.bounds.lb) / 10, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = (self.omega * self.velocities[i] +\n                            self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                            self.c2 * r2 * (self.global_best_position - self.population[i]))\n                \n                # Limit the velocity\n                v_max = abs(func.bounds.ub - func.bounds.lb) / 2\n                velocity = np.clip(velocity, -v_max, v_max)\n                \n                new_position = self.population[i] + velocity\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # DE mutation and crossover\n                donor_vector = self.population[i].copy()\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                mutant_vector = x_r1 + self.F * (x_r2 - x_r3)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        donor_vector[j] = mutant_vector[j]\n\n                donor_vector = np.clip(donor_vector, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal design-based exploration\n                level_index = np.random.randint(0, self.orthogonal_design.shape[0])\n                orthogonal_sample = self.orthogonal_design[level_index]\n                exploration_vector = func.bounds.lb + orthogonal_sample * (func.bounds.ub - func.bounds.lb)\n\n\n                # Combine PSO and DE results with Orthogonal Exploration\n                rand_choice = np.random.rand()\n                if rand_choice < 0.33:\n                    trial_vector = new_position\n                elif rand_choice < 0.66:\n                    trial_vector = donor_vector\n                else:\n                    trial_vector = exploration_vector\n\n\n                f = func(trial_vector)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = trial_vector.copy()\n\n                if eval_count >= self.budget:\n                  break\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 12, "feedback": "Evaluation timed out after 300 seconds.", "error": "Evaluation timed out after 300 seconds.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), with a focus on exploration using orthogonal design to sample diverse solutions.\n\n# Code:\n```python\nimport numpy as np\n\nclass OrthogonalPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, c1=1.49445, c2=1.49445, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.orthogonal_design = self.generate_orthogonal_design()\n\n    def generate_orthogonal_design(self, num_factors=None, levels=3):\n        \"\"\"Generates an orthogonal design using a simple approach.\n           For proper orthogonal designs, a dedicated library is recommended (e.g., pyDOE).\n           This implementation ensures basic diversity but may not satisfy all orthogonality properties.\n        \"\"\"\n        if num_factors is None:\n            num_factors = self.dim  # Use problem dimensionality as the number of factors\n\n        design = np.zeros((levels, num_factors))\n        for i in range(levels):\n            for j in range(num_factors):\n                design[i, j] = (i / (levels - 1))  # Normalize to [0, 1] range\n\n        return design\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-abs(func.bounds.ub - func.bounds.lb) / 10, abs(func.bounds.ub - func.bounds.lb) / 10, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # PSO update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity = (self.omega * self.velocities[i] +\n                            self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                            self.c2 * r2 * (self.global_best_position - self.population[i]))\n                \n                # Limit the velocity\n                v_max = abs(func.bounds.ub - func.bounds.lb) / 2\n                velocity = np.clip(velocity, -v_max, v_max)\n                \n                new_position = self.population[i] + velocity\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                \n                # DE mutation and crossover\n                donor_vector = self.population[i].copy()\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                mutant_vector = x_r1 + self.F * (x_r2 - x_r3)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        donor_vector[j] = mutant_vector[j]\n\n                donor_vector = np.clip(donor_vector, func.bounds.lb, func.bounds.ub)\n\n                # Orthogonal design-based exploration\n                level_index = np.random.randint(0, self.orthogonal_design.shape[0])\n                orthogonal_sample = self.orthogonal_design[level_index]\n                exploration_vector = func.bounds.lb + orthogonal_sample * (func.bounds.ub - func.bounds.lb)\n\n\n                # Combine PSO and DE results with Orthogonal Exploration\n                rand_choice = np.random.rand()\n                if rand_choice < 0.33:\n                    trial_vector = new_position\n                elif rand_choice < 0.66:\n                    trial_vector = donor_vector\n                else:\n                    trial_vector = exploration_vector\n\n\n                f = func(trial_vector)\n                eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial_vector\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = trial_vector.copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = trial_vector.copy()\n\n                if eval_count >= self.budget:\n                  break\n        return self.global_best_fitness, self.global_best_position\n```", "operator": "random_new", "theta_sampled": 0.10337792638794935, "generation": 12}, "task_prompt": ""}
{"id": "51164576-f334-46b2-acf7-bbcc4e9b4749", "fitness": 0.6732511557043471, "name": "AdaptiveDE_Scaling", "description": "Adaptive Differential Evolution with Population-Wide Mutation Scaling", "code": "import numpy as np\n\nclass AdaptiveDE_Scaling:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from ImprovedAdaptiveDE)\n        F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        # Calculate a scaling factor based on population diversity\n        pop_std = np.std(self.pop)\n        scale_factor = 1.0 + 0.1 * pop_std  # Scale F based on diversity\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + F * scale_factor * (x_r2 - x_r3)  # Apply scaling\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDE_Scaling scored 0.673 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3de83135-5c17-4f40-9b7c-a061590e4003", "6705faa0-b1f5-4410-b472-5127f5cdbcab"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Population-Wide Mutation Scaling\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_Scaling:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.F = 0.5\n        self.Cr = 0.9\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n        return self.f_opt, self.x_opt\n\n    def evolve(self, func):\n        # Linear decrease of exploration parameters (from ImprovedAdaptiveDE)\n        F = 0.2 + (0.7 - 0.2) * (1 - self.eval_count / self.budget)\n        Cr = 0.4 + (0.9 - 0.4) * (1 - self.eval_count / self.budget)\n\n        # Calculate a scaling factor based on population diversity\n        pop_std = np.std(self.pop)\n        scale_factor = 1.0 + 0.1 * pop_std  # Scale F based on diversity\n\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.pop[idxs]\n            x_mutated = x_r1 + F * scale_factor * (x_r2 - x_r3)  # Apply scaling\n            x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            x_trial = self.pop[i].copy()\n            mask = np.random.rand(self.dim) < Cr\n            x_trial[mask] = x_mutated[mask]\n\n            # Selection\n            f_trial = func(x_trial)\n            self.eval_count += 1\n\n            if f_trial < self.fitness[i]:\n                self.fitness[i] = f_trial\n                self.pop[i] = x_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n\n    def __call__(self, func):\n        self.f_opt, self.x_opt = self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.evolve(func)\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": -9.339635525708849e-05, "generation": 12, "aucs": [0.21550407202785726, 0.6756680799522612, 0.772393240773898, 0.881511537463546, 0.746001754319861, 0.8232730308946011, 0.6934270318081226, 0.7637556019934627, 0.7769448637960892, 0.2383326253598037, 0.8505658187748419, 0.9980604336202451, 0.4504629407982359, 0.7143097996768409, 0.7324640021410598, 0.8206940626691487, 0.707112622086497, 0.8720766009206271, 0.2127322712747265, 0.5197327237352194]}, "task_prompt": ""}
{"id": "e2dc4937-f6c9-47ac-9109-d8d6cd42692b", "fitness": "-inf", "name": "OrthogonalLearningDE", "description": "Population-based algorithm using orthogonal learning to generate diverse candidate solutions and a selection mechanism favoring both exploration and exploitation.", "code": "import numpy as np\n\nclass OrthogonalLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def orthogonal_design(self):\n        # A simple orthogonal design (L9 for 3 factors at 3 levels)\n        design = np.array([\n            [1, 1, 1],\n            [1, 2, 2],\n            [1, 3, 3],\n            [2, 1, 2],\n            [2, 2, 3],\n            [2, 3, 1],\n            [3, 1, 3],\n            [3, 2, 1],\n            [3, 3, 2]\n        ])\n        return design - 2 # Shift to -1, 0, 1\n\n    def generate_trial_vector(self, target_index, design):\n        trial_vector = self.population[target_index].copy()\n        \n        # Select three random parents\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[indices]\n\n        for i in range(self.dim):\n            level = np.random.randint(0, 3) # Choose a level from the orthogonal design\n            \n            if design[level, 0] == -1:\n                x1 = a[i]\n            elif design[level, 0] == 0:\n                x1 = self.population[target_index][i]\n            else:\n                x1 = b[i]\n\n            if design[level, 1] == -1:\n                x2 = c[i]\n            elif design[level, 1] == 0:\n                x2 = b[i]\n            else:\n                x2 = self.population[target_index][i]\n                \n            if design[level, 2] == -1:\n                x3 = self.lb\n            elif design[level, 2] == 0:\n                x3 = (self.lb + self.ub) / 2 # Use midpoint for the design\n            else:\n                x3 = self.ub\n\n\n            trial_vector[i] = x1 + self.F * (x2 - x3)\n\n\n            if np.random.rand() > self.CR:\n                trial_vector[i] = self.population[target_index][i] # Crossover\n\n        trial_vector = np.clip(trial_vector, self.lb, self.ub)\n        return trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        design = self.orthogonal_design()\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                trial_vector = self.generate_trial_vector(i, design)\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection: Favor better solutions but also maintain some diversity\n                if f_trial < self.fitness[i] or np.random.rand() < 0.05:  # 5% chance to replace even if worse\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "In the code, line 69, in generate_trial_vector, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: trial_vector[i] = x1 + self.F * (x2 - x3)", "error": "In the code, line 69, in generate_trial_vector, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: trial_vector[i] = x1 + self.F * (x2 - x3)", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using orthogonal learning to generate diverse candidate solutions and a selection mechanism favoring both exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalLearningDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def orthogonal_design(self):\n        # A simple orthogonal design (L9 for 3 factors at 3 levels)\n        design = np.array([\n            [1, 1, 1],\n            [1, 2, 2],\n            [1, 3, 3],\n            [2, 1, 2],\n            [2, 2, 3],\n            [2, 3, 1],\n            [3, 1, 3],\n            [3, 2, 1],\n            [3, 3, 2]\n        ])\n        return design - 2 # Shift to -1, 0, 1\n\n    def generate_trial_vector(self, target_index, design):\n        trial_vector = self.population[target_index].copy()\n        \n        # Select three random parents\n        indices = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[indices]\n\n        for i in range(self.dim):\n            level = np.random.randint(0, 3) # Choose a level from the orthogonal design\n            \n            if design[level, 0] == -1:\n                x1 = a[i]\n            elif design[level, 0] == 0:\n                x1 = self.population[target_index][i]\n            else:\n                x1 = b[i]\n\n            if design[level, 1] == -1:\n                x2 = c[i]\n            elif design[level, 1] == 0:\n                x2 = b[i]\n            else:\n                x2 = self.population[target_index][i]\n                \n            if design[level, 2] == -1:\n                x3 = self.lb\n            elif design[level, 2] == 0:\n                x3 = (self.lb + self.ub) / 2 # Use midpoint for the design\n            else:\n                x3 = self.ub\n\n\n            trial_vector[i] = x1 + self.F * (x2 - x3)\n\n\n            if np.random.rand() > self.CR:\n                trial_vector[i] = self.population[target_index][i] # Crossover\n\n        trial_vector = np.clip(trial_vector, self.lb, self.ub)\n        return trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        design = self.orthogonal_design()\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                trial_vector = self.generate_trial_vector(i, design)\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection: Favor better solutions but also maintain some diversity\n                if f_trial < self.fitness[i] or np.random.rand() < 0.05:  # 5% chance to replace even if worse\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.05469090702832366, "generation": 12}, "task_prompt": ""}
{"id": "1d1efcb7-42df-4671-bbb8-fc8410603d61", "fitness": "-inf", "name": "CMArES", "description": "Covariance Matrix Adaptation Evolution Strategy with restart mechanism triggered by stagnation detection.", "code": "import numpy as np\n\nclass CMArES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma=0.1, mu_factor=0.25, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.mu_factor = mu_factor\n        self.cs = cs\n        self.damps = damps\n        self.restarts = restarts\n\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = max(1, int(self.popsize * self.mu_factor)) \n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        self.ccovmu = min(1 - self.ccov1, self.ccovmu)\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.damps = self.damps + 2*max(0, (self.mueff - 1)/(self.dim + 1) - 1) + self.cs\n        self.damps = max(1, self.damps)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        \n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        B = None\n        D = None\n\n        used_budget = 0\n        stagnation_counter = 0\n        max_stagnation = 50  #Stagnation before restarts\n\n\n        for restart in range(self.restarts):\n            \n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # re-initialize\n\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            B = None\n            D = None\n            self.sigma = 0.1 #Reset sigma\n\n            stagnation_counter = 0\n            \n            while used_budget < self.budget:\n                \n                z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n                \n                if B is None or D is None:\n                    C = np.triu(C) + np.triu(C, 1).T\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(D)\n                \n                x = mean[:, np.newaxis] + self.sigma * (B @ (D[:, np.newaxis] * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                f = np.array([func(xi) for xi in x.T])\n                used_budget += self.popsize\n                \n                idx = np.argsort(f)\n                x = x[:, idx]\n                f = f[idx]\n                \n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[:, 0]\n                    stagnation_counter = 0 # Reset counter\n                else:\n                    stagnation_counter +=1\n\n                xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n                \n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ z[:, :self.mu] @ self.weights)\n                hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * (used_budget / self.popsize))) / self.chiN < 1.4 + 2/(self.dim + 1))\n                \n                pc = (1 - self.cc) * pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - mean) / self.sigma\n\n                artw = z[:, :self.mu] * self.weights[np.newaxis, :]\n\n                C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc) + self.ccovmu * (B @ artw @ artw.T @ B.T)\n\n                mean = xmean\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n                \n                C = np.triu(C) + np.triu(C, 1).T\n\n                if np.min(np.diag(C)) <= 0: # numerical stability.\n                    C = C + np.eye(self.dim)*1e-10 # Add a small ridge\n\n                B = None\n                D = None #Recompute B and D at next generation\n                \n                if stagnation_counter > max_stagnation:\n                    break #Early termination of this run and restart\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Covariance Matrix Adaptation Evolution Strategy with restart mechanism triggered by stagnation detection.\n# Code: \n```python\nimport numpy as np\n\nclass CMArES:\n    def __init__(self, budget=10000, dim=10, popsize=None, sigma=0.1, mu_factor=0.25, cs=0.3, damps=1.0, ccov1=None, ccovmu=None, restarts=5):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.mu_factor = mu_factor\n        self.cs = cs\n        self.damps = damps\n        self.restarts = restarts\n\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = max(1, int(self.popsize * self.mu_factor)) \n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff)\n        self.ccovmu = min(1 - self.ccov1, self.ccovmu)\n\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.damps = self.damps + 2*max(0, (self.mueff - 1)/(self.dim + 1) - 1) + self.cs\n        self.damps = max(1, self.damps)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # Initialize mean within bounds\n        \n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        B = None\n        D = None\n\n        used_budget = 0\n        stagnation_counter = 0\n        max_stagnation = 50  #Stagnation before restarts\n\n\n        for restart in range(self.restarts):\n            \n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) # re-initialize\n\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            B = None\n            D = None\n            self.sigma = 0.1 #Reset sigma\n\n            stagnation_counter = 0\n            \n            while used_budget < self.budget:\n                \n                z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n                \n                if B is None or D is None:\n                    C = np.triu(C) + np.triu(C, 1).T\n                    D, B = np.linalg.eigh(C)\n                    D = np.sqrt(D)\n                \n                x = mean[:, np.newaxis] + self.sigma * (B @ (D[:, np.newaxis] * z))\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                f = np.array([func(xi) for xi in x.T])\n                used_budget += self.popsize\n                \n                idx = np.argsort(f)\n                x = x[:, idx]\n                f = f[idx]\n                \n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[:, 0]\n                    stagnation_counter = 0 # Reset counter\n                else:\n                    stagnation_counter +=1\n\n                xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n                \n                ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (B @ z[:, :self.mu] @ self.weights)\n                hsig = (np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**(2 * (used_budget / self.popsize))) / self.chiN < 1.4 + 2/(self.dim + 1))\n                \n                pc = (1 - self.cc) * pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - mean) / self.sigma\n\n                artw = z[:, :self.mu] * self.weights[np.newaxis, :]\n\n                C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.cc * (2 - self.cc)) * C + self.ccov1 * np.outer(pc, pc) + self.ccovmu * (B @ artw @ artw.T @ B.T)\n\n                mean = xmean\n                self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n                \n                C = np.triu(C) + np.triu(C, 1).T\n\n                if np.min(np.diag(C)) <= 0: # numerical stability.\n                    C = C + np.eye(self.dim)*1e-10 # Add a small ridge\n\n                B = None\n                D = None #Recompute B and D at next generation\n                \n                if stagnation_counter > max_stagnation:\n                    break #Early termination of this run and restart\n            \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.13356596747791025, "generation": 12}, "task_prompt": ""}
{"id": "de1c2254-282a-4e24-aa0e-89a6de79362f", "fitness": "-inf", "name": "PSO_CMAES", "description": "This algorithm combines the strengths of Particle Swarm Optimization (PSO) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES). It uses PSO to explore the search space broadly, while CMA-ES provides local refinement and efficient adaptation of the search distribution.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.damps = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n        self.cs = None\n        self.cc = None\n        self.mucov = None\n        self.ccov = None\n        self.CMAES_INIT = False\n\n\n    def initialize_pso(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n\n    def update_pso(self, func):\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = self.w * self.velocities[i] + \\\n                                 self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                                 self.c2 * r2 * (self.global_best_position - self.particles[i])\n            self.particles[i] = self.particles[i] + self.velocities[i]\n\n            # Boundary handling (clip the particle if it goes out of bounds)\n            self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.particles[i])\n            self.eval_count += 1\n            if f < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = f\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.particles[i].copy()\n\n    def initialize_cmaes(self):\n        self.mean = self.global_best_position.copy()\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.damps = 1 + (2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)) + self.cs\n        self.mu = int(self.pop_size / 4)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights**2)**-1\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.mucov = self.mueff\n        self.ccov = (1 / self.mucov) * (2 / ((self.dim + np.sqrt(2))**2 + self.mueff)) * (cs <= 0.446) + (1 - (1 / self.mucov)) * min(1, (2 * self.mueff - 1) / ((self.dim + 2)**2 + self.mueff))\n        self.CMAES_INIT = True\n\n    def sample_cmaes(self):\n        z = np.random.randn(self.dim)\n        return self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n\n    def update_cmaes(self, func):\n      \n        positions = np.array([self.sample_cmaes() for _ in range(self.pop_size)])\n        for i in range(len(positions)):\n            positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n        fitnesses = np.array([func(x) for x in positions])\n        self.eval_count += self.pop_size\n        \n        idx = np.argsort(fitnesses)\n        positions = positions[idx]\n        fitnesses = fitnesses[idx]\n\n        xmean = np.sum(self.weights[:, None] * positions[:self.mu], axis=0)\n        \n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma * np.linalg.inv(np.linalg.cholesky(self.C))\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n\n        dC = self.ccov * (1 / self.mucov) * (self.pc[:, None] @ self.pc[None, :]) + self.ccov * (1 - (1 / self.mucov)) * (self.C * hsig**2)\n        for k in range(self.mu):\n            dC += self.weights[k] * ((positions[k] - self.mean)[:, None] @ (positions[k] - self.mean)[None, :]) / (self.sigma**2)\n\n        self.C = (1 - self.ccov) * self.C + dC\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.mean = xmean\n\n        if fitnesses[0] < self.global_best_fitness:\n            self.global_best_fitness = fitnesses[0]\n            self.global_best_position = positions[0].copy()\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.global_best_fitness = np.inf\n\n        # Initial PSO phase for exploration\n        self.initialize_pso(func)\n        pso_evals = int(self.budget * 0.3) # 30% of budget to PSO\n        while self.eval_count < pso_evals:\n            self.update_pso(func)\n        \n        # Transition to CMA-ES for exploitation around the best PSO solution\n        self.initialize_cmaes()\n\n        cmaes_evals = self.budget - self.eval_count\n        while self.eval_count < self.budget:\n           self.update_cmaes(func)\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "In the code, line 73, in initialize_cmaes, the following error occurred:\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\nOn line: self.damps = 1 + (2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)) + self.cs", "error": "In the code, line 73, in initialize_cmaes, the following error occurred:\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\nOn line: self.damps = 1 + (2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)) + self.cs", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: This algorithm combines the strengths of Particle Swarm Optimization (PSO) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES). It uses PSO to explore the search space broadly, while CMA-ES provides local refinement and efficient adaptation of the search distribution.\n\n# Code:\n```python\nimport numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=1.49, c2=1.49, w=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitnesses = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.damps = None\n        self.mu = None\n        self.weights = None\n        self.mueff = None\n        self.cs = None\n        self.cc = None\n        self.mucov = None\n        self.ccov = None\n        self.CMAES_INIT = False\n\n\n    def initialize_pso(self, func):\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitnesses = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n        self.global_best_position = self.personal_best_positions[np.argmin(self.personal_best_fitnesses)].copy()\n        self.global_best_fitness = np.min(self.personal_best_fitnesses)\n\n    def update_pso(self, func):\n        for i in range(self.pop_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            self.velocities[i] = self.w * self.velocities[i] + \\\n                                 self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \\\n                                 self.c2 * r2 * (self.global_best_position - self.particles[i])\n            self.particles[i] = self.particles[i] + self.velocities[i]\n\n            # Boundary handling (clip the particle if it goes out of bounds)\n            self.particles[i] = np.clip(self.particles[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.particles[i])\n            self.eval_count += 1\n            if f < self.personal_best_fitnesses[i]:\n                self.personal_best_fitnesses[i] = f\n                self.personal_best_positions[i] = self.particles[i].copy()\n\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.particles[i].copy()\n\n    def initialize_cmaes(self):\n        self.mean = self.global_best_position.copy()\n        self.sigma = 0.5\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n        self.damps = 1 + (2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1)) + self.cs\n        self.mu = int(self.pop_size / 4)\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights**2)**-1\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.mucov = self.mueff\n        self.ccov = (1 / self.mucov) * (2 / ((self.dim + np.sqrt(2))**2 + self.mueff)) * (cs <= 0.446) + (1 - (1 / self.mucov)) * min(1, (2 * self.mueff - 1) / ((self.dim + 2)**2 + self.mueff))\n        self.CMAES_INIT = True\n\n    def sample_cmaes(self):\n        z = np.random.randn(self.dim)\n        return self.mean + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n\n    def update_cmaes(self, func):\n      \n        positions = np.array([self.sample_cmaes() for _ in range(self.pop_size)])\n        for i in range(len(positions)):\n            positions[i] = np.clip(positions[i], func.bounds.lb, func.bounds.ub)\n        fitnesses = np.array([func(x) for x in positions])\n        self.eval_count += self.pop_size\n        \n        idx = np.argsort(fitnesses)\n        positions = positions[idx]\n        fitnesses = fitnesses[idx]\n\n        xmean = np.sum(self.weights[:, None] * positions[:self.mu], axis=0)\n        \n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean) / self.sigma * np.linalg.inv(np.linalg.cholesky(self.C))\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * (xmean - self.mean) / self.sigma\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.eval_count / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n\n        dC = self.ccov * (1 / self.mucov) * (self.pc[:, None] @ self.pc[None, :]) + self.ccov * (1 - (1 / self.mucov)) * (self.C * hsig**2)\n        for k in range(self.mu):\n            dC += self.weights[k] * ((positions[k] - self.mean)[:, None] @ (positions[k] - self.mean)[None, :]) / (self.sigma**2)\n\n        self.C = (1 - self.ccov) * self.C + dC\n\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.mean = xmean\n\n        if fitnesses[0] < self.global_best_fitness:\n            self.global_best_fitness = fitnesses[0]\n            self.global_best_position = positions[0].copy()\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.global_best_fitness = np.inf\n\n        # Initial PSO phase for exploration\n        self.initialize_pso(func)\n        pso_evals = int(self.budget * 0.3) # 30% of budget to PSO\n        while self.eval_count < pso_evals:\n            self.update_pso(func)\n        \n        # Transition to CMA-ES for exploitation around the best PSO solution\n        self.initialize_cmaes()\n\n        cmaes_evals = self.budget - self.eval_count\n        while self.eval_count < self.budget:\n           self.update_cmaes(func)\n\n        self.f_opt = self.global_best_fitness\n        self.x_opt = self.global_best_position\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.17949513256471794, "generation": 12}, "task_prompt": ""}
