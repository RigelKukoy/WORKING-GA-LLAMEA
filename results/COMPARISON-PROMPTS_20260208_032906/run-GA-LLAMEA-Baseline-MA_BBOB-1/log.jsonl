{"id": "43baa676-89e3-4977-a7ef-16b71bc5d2eb", "fitness": 0.0, "name": "AdaptiveMomentumSearch", "description": "A self-adjusting step size random search with momentum, that restarts when stagnating.", "code": "import numpy as np\n\nclass AdaptiveMomentumSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9, stagnation_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.stagnation_patience = stagnation_patience\n        self.velocity = np.zeros(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initial random position\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        best_f_history = []\n        stagnation_counter = 0\n\n        for i in range(self.budget):\n            # Momentum update\n            self.velocity = self.momentum_factor * self.velocity + (1 - self.momentum_factor) * np.random.normal(0, self.step_size, self.dim)\n\n            # New position\n            x_new = x + self.velocity\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # keep within bounds\n            \n            f_new = func(x_new)\n           \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                f = f_new\n                \n                # Reset stagnation counter\n                stagnation_counter = 0\n\n            else:\n                stagnation_counter += 1\n            \n            # Adaptive step size adjustment\n            if stagnation_counter > self.stagnation_patience:\n                self.step_size *= 0.8  # Reduce step size if stagnating\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub) # Restart\n                f = func(x)\n                stagnation_counter = 0\n                self.velocity = np.zeros(self.dim) # Reset velocity\n\n            if self.step_size < 1e-6: # Minimum step size\n                self.step_size = 1e-6\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveMomentumSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A self-adjusting step size random search with momentum, that restarts when stagnating.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveMomentumSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, momentum_factor=0.9, stagnation_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n        self.stagnation_patience = stagnation_patience\n        self.velocity = np.zeros(dim)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub)  # Initial random position\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        \n        best_f_history = []\n        stagnation_counter = 0\n\n        for i in range(self.budget):\n            # Momentum update\n            self.velocity = self.momentum_factor * self.velocity + (1 - self.momentum_factor) * np.random.normal(0, self.step_size, self.dim)\n\n            # New position\n            x_new = x + self.velocity\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # keep within bounds\n            \n            f_new = func(x_new)\n           \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                f = f_new\n                \n                # Reset stagnation counter\n                stagnation_counter = 0\n\n            else:\n                stagnation_counter += 1\n            \n            # Adaptive step size adjustment\n            if stagnation_counter > self.stagnation_patience:\n                self.step_size *= 0.8  # Reduce step size if stagnating\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub) # Restart\n                f = func(x)\n                stagnation_counter = 0\n                self.velocity = np.zeros(self.dim) # Reset velocity\n\n            if self.step_size < 1e-6: # Minimum step size\n                self.step_size = 1e-6\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "bc42aef7-1c5f-4816-af53-b9d32788534a", "fitness": 0.477608784654719, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines features of particle swarm optimization and differential evolution, using a dynamically adjusted exploration-exploitation balance based on function evaluation progress.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, c1=2.0, c2=2.0, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb) #scaled initial velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_particle(self, i, func, inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        self.velocities[i] = (inertia * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                              self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n        # Velocity clamping\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n        new_position = self.population[i] + self.velocities[i]\n        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)  # Boundary handling\n\n        new_fitness = func(new_position)\n        self.eval_count += 1\n\n        if new_fitness < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = new_fitness\n            self.personal_best_positions[i] = new_position.copy()\n\n            if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_position = new_position.copy()\n        \n        self.population[i] = new_position #update position\n    \n\n    def differential_evolution_step(self, i, func):\n         # Differential Evolution Mutation and Crossover\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n        # Crossover\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[i])\n\n        # Evaluation\n        f = func(trial)\n        self.eval_count += 1\n\n        # Selection\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            self.population[i] = trial\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = trial.copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial.copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Dynamic adjustment of exploration-exploitation balance\n            progress = self.eval_count / self.budget\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * progress  # Linearly decreasing inertia\n\n            for i in range(self.pop_size):\n                if np.random.rand() < (1 - progress): # Higher chance of PSO in early stage (exploration)\n                    self.update_particle(i, func, inertia)\n                else: # Higher chance of DE in later stage (exploitation)\n                    self.differential_evolution_step(i, func)\n\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.478 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines features of particle swarm optimization and differential evolution, using a dynamically adjusted exploration-exploitation balance based on function evaluation progress.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, c1=2.0, c2=2.0, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n        self.F = F\n        self.CR = CR\n\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb) #scaled initial velocities\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def update_particle(self, i, func, inertia):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n\n        self.velocities[i] = (inertia * self.velocities[i] +\n                              self.c1 * r1 * (self.personal_best_positions[i] - self.population[i]) +\n                              self.c2 * r2 * (self.global_best_position - self.population[i]))\n\n        # Velocity clamping\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n\n        new_position = self.population[i] + self.velocities[i]\n        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)  # Boundary handling\n\n        new_fitness = func(new_position)\n        self.eval_count += 1\n\n        if new_fitness < self.personal_best_fitness[i]:\n            self.personal_best_fitness[i] = new_fitness\n            self.personal_best_positions[i] = new_position.copy()\n\n            if new_fitness < self.global_best_fitness:\n                self.global_best_fitness = new_fitness\n                self.global_best_position = new_position.copy()\n        \n        self.population[i] = new_position #update position\n    \n\n    def differential_evolution_step(self, i, func):\n         # Differential Evolution Mutation and Crossover\n        idxs = [idx for idx in range(self.pop_size) if idx != i]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n        # Crossover\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n\n        trial = np.where(cross_points, mutant, self.population[i])\n\n        # Evaluation\n        f = func(trial)\n        self.eval_count += 1\n\n        # Selection\n        if f < self.fitness[i]:\n            self.fitness[i] = f\n            self.population[i] = trial\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = trial.copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial.copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            # Dynamic adjustment of exploration-exploitation balance\n            progress = self.eval_count / self.budget\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * progress  # Linearly decreasing inertia\n\n            for i in range(self.pop_size):\n                if np.random.rand() < (1 - progress): # Higher chance of PSO in early stage (exploration)\n                    self.update_particle(i, func, inertia)\n                else: # Higher chance of DE in later stage (exploitation)\n                    self.differential_evolution_step(i, func)\n\n\n        return self.global_best_fitness, self.global_best_position\n```", "aucs": [0.22428284131165133, 0.3409872177357478, 0.4604371445464386, 0.8043421746811545, 0.45560940667906846, 0.5376089447885932, 0.3292784826368975, 0.3987775127887129, 0.45404636003885357, 0.19006454976877962, 0.786776350091325, 0.9990320342137309, 0.31195969369690735, 0.4654132686961997, 0.7361930216378907, 0.5335770136883716, 0.38376898227229117, 0.3783184237104824, 0.2572763637989528, 0.5044259063123306], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "7a36599f-f8bb-4c51-9e48-fa37c19bc018", "fitness": 0.7021866708842264, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines particle swarm optimization with differential evolution for exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.702 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines particle swarm optimization with differential evolution for exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.22178354069393258, 0.41110675375852934, 0.8446559845767918, 0.8913211628356981, 0.8535531641088251, 0.8989302879845581, 0.8174924055663371, 0.6612477609286822, 0.828493967543305, 0.8474471833618388, 0.7846505253821167, 0.9959661004862125, 0.3167776620743088, 0.8323655381959845, 0.8833245081450459, 0.8718029796066696, 0.44621427344215037, 0.9378705042554097, 0.19577763037789642, 0.5029514843602356], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "7764b8d8-7601-43c5-83ca-41ac013cba16", "fitness": 0.6213301281783674, "name": "SelfAdaptiveDE", "description": "A differential evolution strategy with self-adaptive parameters and a local search component to refine promising solutions.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            if self.budget > 0:\n                # Self-adaptation of F and CR (optional, can be commented out if necessary for budget)\n                self.F = np.random.normal(0.5, 0.1)\n                self.CR = np.random.normal(0.7, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                # Local search around the best solution (optional)\n                for _ in range(self.local_search_iterations):\n                    if self.budget <= 0:\n                        break\n                    perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                    local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = local_point\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.621 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A differential evolution strategy with self-adaptive parameters and a local search component to refine promising solutions.\n# Code: \n```python\nimport numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            if self.budget > 0:\n                # Self-adaptation of F and CR (optional, can be commented out if necessary for budget)\n                self.F = np.random.normal(0.5, 0.1)\n                self.CR = np.random.normal(0.7, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                # Local search around the best solution (optional)\n                for _ in range(self.local_search_iterations):\n                    if self.budget <= 0:\n                        break\n                    perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                    local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = local_point\n\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23215162702460357, 0.5217941711681409, 0.5533748551481611, 0.8155086414199441, 0.6960587515334193, 0.7269427282620817, 0.5337994993626101, 0.5830696739166796, 0.6506488763519749, 0.5151961565415253, 0.8153377528903517, 0.9863208285257379, 0.36833956796597844, 0.6611753573992682, 0.8603600888673071, 0.7599579402993779, 0.5429224885372813, 0.8081988391237093, 0.2703141659887943, 0.5251305532404026], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "d0c8ed52-cbd0-4718-bbfe-bd2b2578ce8e", "fitness": 0.09613034196346887, "name": "AdaptiveHybridPSO_DE", "description": "Dynamically adjusts PSO and DE parameters based on population diversity and success rate, incorporating a local search strategy for exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.5, cr_end=0.9, f_init=0.5, f_end=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        success_rate_pso = 0.5  # Initial success rate for PSO\n        success_rate_de = 0.5  # Initial success rate for DE\n        n_pso = 0\n        n_de = 0\n        success_pso = 0\n        success_de = 0\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive parameter updates\n            w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / self.budget)  # Linear decrease\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (1 - self.budget / self.budget)  # Linear increase\n            f = self.f_init + (self.f_end - self.f_init) * (1 - self.budget / self.budget)  # Linear increase\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n                new_f_pso = func(new_x_pso)\n                self.budget -= 1\n                n_pso += 1\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n                \n                new_x_de = np.clip(new_x_de, lb, ub)\n                new_f_de = func(new_x_de)\n                self.budget -= 1\n                n_de += 1\n\n                # Select between PSO and DE\n                if success_rate_pso > success_rate_de:\n                    new_x = new_x_pso\n                    new_f = new_f_pso\n                    if new_f < pbest_fitness[i]:\n                        success_pso +=1\n                else:\n                    new_x = new_x_de\n                    new_f = new_f_de\n                    if new_f < pbest_fitness[i]:\n                        success_de += 1\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Perform a small random perturbation around the best solution\n                    scale = 0.01 * (ub - lb)  # Scale of the perturbation\n                    new_x_local = new_x + np.random.normal(0, scale, self.dim)\n                    new_x_local = np.clip(new_x_local, lb, ub)  # Clip to bounds\n                    new_f_local = func(new_x_local)\n                    self.budget -= 1\n\n                    if new_f_local < new_f:\n                        new_f = new_f_local\n                        new_x = new_x_local\n\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if n_pso > 0:\n                success_rate_pso = success_pso/n_pso\n            if n_de > 0:\n                success_rate_de = success_de/n_de\n\n            n_pso = 0\n            n_de = 0\n            success_pso = 0\n            success_de = 0\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.096 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO and DE parameters based on population diversity and success rate, incorporating a local search strategy for exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.5, cr_end=0.9, f_init=0.5, f_end=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.local_search_prob = local_search_prob # Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        success_rate_pso = 0.5  # Initial success rate for PSO\n        success_rate_de = 0.5  # Initial success rate for DE\n        n_pso = 0\n        n_de = 0\n        success_pso = 0\n        success_de = 0\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive parameter updates\n            w = self.w_init - (self.w_init - self.w_end) * (1 - self.budget / self.budget)  # Linear decrease\n            cr = self.cr_init + (self.cr_end - self.cr_init) * (1 - self.budget / self.budget)  # Linear increase\n            f = self.f_init + (self.f_end - self.f_init) * (1 - self.budget / self.budget)  # Linear increase\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n                new_f_pso = func(new_x_pso)\n                self.budget -= 1\n                n_pso += 1\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n                \n                new_x_de = np.clip(new_x_de, lb, ub)\n                new_f_de = func(new_x_de)\n                self.budget -= 1\n                n_de += 1\n\n                # Select between PSO and DE\n                if success_rate_pso > success_rate_de:\n                    new_x = new_x_pso\n                    new_f = new_f_pso\n                    if new_f < pbest_fitness[i]:\n                        success_pso +=1\n                else:\n                    new_x = new_x_de\n                    new_f = new_f_de\n                    if new_f < pbest_fitness[i]:\n                        success_de += 1\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    # Perform a small random perturbation around the best solution\n                    scale = 0.01 * (ub - lb)  # Scale of the perturbation\n                    new_x_local = new_x + np.random.normal(0, scale, self.dim)\n                    new_x_local = np.clip(new_x_local, lb, ub)  # Clip to bounds\n                    new_f_local = func(new_x_local)\n                    self.budget -= 1\n\n                    if new_f_local < new_f:\n                        new_f = new_f_local\n                        new_x = new_x_local\n\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if n_pso > 0:\n                success_rate_pso = success_pso/n_pso\n            if n_de > 0:\n                success_rate_de = success_de/n_de\n\n            n_pso = 0\n            n_de = 0\n            success_pso = 0\n            success_de = 0\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19226068392693774, 0], "operator": "mutation", "theta_sampled": 0.370331224354284, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "9f8802d4-ec65-46ba-adea-f1c084a2170c", "fitness": 0.0, "name": "AdaptiveKrillHerd", "description": "Population-based algorithm utilizing Krill Herd optimization principles with adaptive step size and local search refinement.", "code": "import numpy as np\n\nclass AdaptiveKrillHerd:\n    def __init__(self, budget=10000, dim=10, population_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n\n    def _calculate_fitness(self, func, population):\n        fitness = np.zeros(self.population_size)\n        for i in range(self.population_size):\n            fitness[i] = func(population[i])\n        return fitness\n\n    def _movement(self, population, fitness, best_position):\n        \"\"\"Simulates krill movement influenced by other krill, foraging, and random diffusion.\"\"\"\n        N = np.zeros((self.population_size, self.dim))  # Movement induced by other krill\n        F = np.zeros((self.population_size, self.dim))  # Foraging activity\n        D = np.zeros((self.population_size, self.dim))  # Physical diffusion\n\n        for i in range(self.population_size):\n            # Movement induced by other krill\n            for j in range(self.population_size):\n                if i != j:\n                    distance = np.linalg.norm(population[i] - population[j])\n                    influence = np.exp(-distance)\n                    N[i] += influence * (population[j] - population[i])\n\n            # Foraging activity (attraction to best position)\n            distance_to_best = np.linalg.norm(population[i] - best_position)\n            F[i] = 2 * np.random.rand() * (best_position - population[i]) * np.exp(-distance_to_best)\n\n            # Physical diffusion (random movement)\n            D[i] = self.step_size * np.random.uniform(-1, 1, self.dim)\n\n            # Combine movements\n            population[i] += N[i] + F[i] + D[i]\n            population[i] = np.clip(population[i], self.lb, self.ub)\n\n        return population\n\n    def _local_search(self, func, x, f_x):\n        \"\"\"Performs a local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = f_x\n        for _ in range(5): # Small local search budget\n            new_x = x + np.random.normal(0, self.step_size/5, self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        return best_x, best_f\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = self._calculate_fitness(func, population)\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        eval_count = self.population_size # Number of function evaluations already spent\n\n        while eval_count < self.budget:\n            population = self._movement(population, fitness, self.x_opt)\n            new_fitness = self._calculate_fitness(func, population)\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i], new_fitness[i] = self._local_search(func, population[i], new_fitness[i])\n                    eval_count += 5  # Account for local search calls, even though budget is already spent if over\n\n            fitness = new_fitness\n            best_index = np.argmin(fitness)\n\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            self.step_size *= 0.99  # Gradually reduce step size for fine-tuning\n            self.step_size = max(self.step_size, 0.0001) # prevent step_size from vanishing completely.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveKrillHerd scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm utilizing Krill Herd optimization principles with adaptive step size and local search refinement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveKrillHerd:\n    def __init__(self, budget=10000, dim=10, population_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.population_size, self.dim))\n\n    def _calculate_fitness(self, func, population):\n        fitness = np.zeros(self.population_size)\n        for i in range(self.population_size):\n            fitness[i] = func(population[i])\n        return fitness\n\n    def _movement(self, population, fitness, best_position):\n        \"\"\"Simulates krill movement influenced by other krill, foraging, and random diffusion.\"\"\"\n        N = np.zeros((self.population_size, self.dim))  # Movement induced by other krill\n        F = np.zeros((self.population_size, self.dim))  # Foraging activity\n        D = np.zeros((self.population_size, self.dim))  # Physical diffusion\n\n        for i in range(self.population_size):\n            # Movement induced by other krill\n            for j in range(self.population_size):\n                if i != j:\n                    distance = np.linalg.norm(population[i] - population[j])\n                    influence = np.exp(-distance)\n                    N[i] += influence * (population[j] - population[i])\n\n            # Foraging activity (attraction to best position)\n            distance_to_best = np.linalg.norm(population[i] - best_position)\n            F[i] = 2 * np.random.rand() * (best_position - population[i]) * np.exp(-distance_to_best)\n\n            # Physical diffusion (random movement)\n            D[i] = self.step_size * np.random.uniform(-1, 1, self.dim)\n\n            # Combine movements\n            population[i] += N[i] + F[i] + D[i]\n            population[i] = np.clip(population[i], self.lb, self.ub)\n\n        return population\n\n    def _local_search(self, func, x, f_x):\n        \"\"\"Performs a local search around a given solution.\"\"\"\n        best_x = x.copy()\n        best_f = f_x\n        for _ in range(5): # Small local search budget\n            new_x = x + np.random.normal(0, self.step_size/5, self.dim)\n            new_x = np.clip(new_x, self.lb, self.ub)\n            new_f = func(new_x)\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n        return best_x, best_f\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = self._calculate_fitness(func, population)\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        eval_count = self.population_size # Number of function evaluations already spent\n\n        while eval_count < self.budget:\n            population = self._movement(population, fitness, self.x_opt)\n            new_fitness = self._calculate_fitness(func, population)\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i], new_fitness[i] = self._local_search(func, population[i], new_fitness[i])\n                    eval_count += 5  # Account for local search calls, even though budget is already spent if over\n\n            fitness = new_fitness\n            best_index = np.argmin(fitness)\n\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            self.step_size *= 0.99  # Gradually reduce step size for fine-tuning\n            self.step_size = max(self.step_size, 0.0001) # prevent step_size from vanishing completely.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.2993712851687566, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "e220b1c8-273c-417b-803d-c87a9de03210", "fitness": 0.5486245008630779, "name": "GaussianCauchyOptimizer", "description": "Population-based algorithm with a combination of Gaussian mutation and Cauchy crossover to balance exploration and exploitation.", "code": "import numpy as np\n\nclass GaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Account for initial fitness evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Gaussian mutation with adaptive step size\n                mutation = np.random.normal(0, self.mutation_rate * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                mutated_individual = population[i] + mutation\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n\n                # Crossover: Cauchy crossover\n                if np.random.rand() < self.crossover_rate:\n                    cauchy_sample = np.random.standard_cauchy(size=self.dim)\n                    crossover_individual = self.x_opt + cauchy_sample * (population[i] - population[np.random.randint(self.pop_size)]) #Sample a location around the current best using cauchy dist.\n\n                    crossover_individual = np.clip(crossover_individual, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate crossover individual\n                    fitness_crossover = func(crossover_individual)\n                    self.budget -= 1\n                    if fitness_crossover < fitness[i]:\n                        population[i] = crossover_individual\n                        fitness[i] = fitness_crossover\n\n                else:\n                    # Evaluate mutated individual\n                    fitness_mutated = func(mutated_individual)\n                    self.budget -= 1\n\n                    if fitness_mutated < fitness[i]:\n                        population[i] = mutated_individual\n                        fitness[i] = fitness_mutated\n\n\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm GaussianCauchyOptimizer scored 0.549 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a combination of Gaussian mutation and Cauchy crossover to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianCauchyOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1, crossover_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Account for initial fitness evaluations\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Gaussian mutation with adaptive step size\n                mutation = np.random.normal(0, self.mutation_rate * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                mutated_individual = population[i] + mutation\n                mutated_individual = np.clip(mutated_individual, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n\n                # Crossover: Cauchy crossover\n                if np.random.rand() < self.crossover_rate:\n                    cauchy_sample = np.random.standard_cauchy(size=self.dim)\n                    crossover_individual = self.x_opt + cauchy_sample * (population[i] - population[np.random.randint(self.pop_size)]) #Sample a location around the current best using cauchy dist.\n\n                    crossover_individual = np.clip(crossover_individual, func.bounds.lb, func.bounds.ub)\n\n                    # Evaluate crossover individual\n                    fitness_crossover = func(crossover_individual)\n                    self.budget -= 1\n                    if fitness_crossover < fitness[i]:\n                        population[i] = crossover_individual\n                        fitness[i] = fitness_crossover\n\n                else:\n                    # Evaluate mutated individual\n                    fitness_mutated = func(mutated_individual)\n                    self.budget -= 1\n\n                    if fitness_mutated < fitness[i]:\n                        population[i] = mutated_individual\n                        fitness[i] = fitness_mutated\n\n\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17570795894309754, 0.2343541740224112, 0.7379134118436258, 0.35424977833733273, 0.2941038047952911, 0.8309955265724758, 0.323938638066847, 0.3745825294265843, 0.7532803112917054, 0.6922550790762259, 0.7077344915799502, 0.9950654412672408, 0.289492936577492, 0.6704216793697333, 0.8563581579490084, 0.8422868381698798, 0.3232173542863789, 0.8131352384132804, 0.20640186893655177, 0.4969947983364448], "operator": "random_new", "theta_sampled": 0.1024935281283595, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac", "fitness": 0.6528261987729025, "name": "HybridPSO_DESA", "description": "Combines PSO's global search with DE's mutation and crossover, along with self-adaptation and local search for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DESA scored 0.653 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "7764b8d8-7601-43c5-83ca-41ac013cba16"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines PSO's global search with DE's mutation and crossover, along with self-adaptation and local search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2243149462249886, 0.22852265640285385, 0.8680770754316743, 0.9458112759589448, 0.8082989313077296, 0.9215074845677312, 0.3374571990433165, 0.8520950816142175, 0.8893477370004872, 0.25286243258127883, 0.9219370271683689, 0.9964159654793027, 0.3782345886410947, 0.3991644262308772, 0.5871467778798344, 0.8947671478903036, 0.2672116487386498, 0.9378402526005489, 0.8387150251853283, 0.5067962955105179], "operator": "crossover", "theta_sampled": 0.26053622623819267, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "fd938d4e-7be9-44b1-a308-bad4c7dde3c6", "fitness": 0.0, "name": "AdaptiveEvolutionarySearch", "description": "An evolutionary strategy using a combination of Gaussian mutation and differential crossover with adaptive step size control based on success rate.", "code": "import numpy as np\n\nclass AdaptiveEvolutionarySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.tau = 1 / np.sqrt(2 * dim)  # Learning rate for step size adaptation\n        self.tau_prime = 1 / np.sqrt(2 * np.sqrt(dim))\n\n    def __call__(self, func):\n        # Initialize population and step sizes\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.ones((self.pop_size, self.dim)) * 0.1  # Initial step sizes\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        success_history = []\n\n        while self.budget > 0:\n            # Reproduction (mutation and crossover)\n            offspring = np.copy(population)\n            offspring_step_sizes = np.copy(step_sizes)\n\n            for i in range(self.pop_size):\n                # Step size adaptation\n                global_step_size_change = self.tau_prime * np.random.normal(0, 1)\n                for j in range(self.dim):\n                    offspring_step_sizes[i, j] = step_sizes[i, j] * np.exp(global_step_size_change + self.tau * np.random.normal(0, 1))\n                    offspring_step_sizes[i, j] = np.clip(offspring_step_sizes[i, j], 1e-10, 1.0) # Clipping the step size\n\n                # Mutation\n                mutation_vector = np.random.normal(0, offspring_step_sizes[i])\n                offspring[i] = population[i] + mutation_vector\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub) #Clipping\n\n                # Differential Crossover\n                donor_indices = np.random.choice(self.pop_size, 3, replace=False)\n                donor_indices = donor_indices[donor_indices != i]\n                F = 0.8 # Crossover rate\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                   if np.random.rand() < F or j == j_rand:\n                       offspring[i][j] = population[donor_indices[0]][j] + 0.5 * (population[donor_indices[1]][j] - population[donor_indices[2]][j])\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub) #Clipping\n\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Selection (replace parent if offspring is better)\n            success = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i]\n                    step_sizes[i] = offspring_step_sizes[i]\n                    success += 1\n\n            success_history.append(success / self.pop_size)\n            if len(success_history) > 10:\n                success_history.pop(0)\n                \n            # Adapt mutation rate based on success rate history. The success rate is averaged over the past 10 generations.\n            avg_success_rate = np.mean(success_history)\n            if avg_success_rate > 0.4:\n                self.mutation_rate *= 1.1\n            elif avg_success_rate < 0.1:\n                self.mutation_rate *= 0.9\n            self.mutation_rate = np.clip(self.mutation_rate, 0.01, 0.5)\n\n            # Update best solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: index 2 is out of bounds for axis 0 with size 2", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An evolutionary strategy using a combination of Gaussian mutation and differential crossover with adaptive step size control based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveEvolutionarySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.tau = 1 / np.sqrt(2 * dim)  # Learning rate for step size adaptation\n        self.tau_prime = 1 / np.sqrt(2 * np.sqrt(dim))\n\n    def __call__(self, func):\n        # Initialize population and step sizes\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        step_sizes = np.ones((self.pop_size, self.dim)) * 0.1  # Initial step sizes\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        success_history = []\n\n        while self.budget > 0:\n            # Reproduction (mutation and crossover)\n            offspring = np.copy(population)\n            offspring_step_sizes = np.copy(step_sizes)\n\n            for i in range(self.pop_size):\n                # Step size adaptation\n                global_step_size_change = self.tau_prime * np.random.normal(0, 1)\n                for j in range(self.dim):\n                    offspring_step_sizes[i, j] = step_sizes[i, j] * np.exp(global_step_size_change + self.tau * np.random.normal(0, 1))\n                    offspring_step_sizes[i, j] = np.clip(offspring_step_sizes[i, j], 1e-10, 1.0) # Clipping the step size\n\n                # Mutation\n                mutation_vector = np.random.normal(0, offspring_step_sizes[i])\n                offspring[i] = population[i] + mutation_vector\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub) #Clipping\n\n                # Differential Crossover\n                donor_indices = np.random.choice(self.pop_size, 3, replace=False)\n                donor_indices = donor_indices[donor_indices != i]\n                F = 0.8 # Crossover rate\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                   if np.random.rand() < F or j == j_rand:\n                       offspring[i][j] = population[donor_indices[0]][j] + 0.5 * (population[donor_indices[1]][j] - population[donor_indices[2]][j])\n                offspring[i] = np.clip(offspring[i], func.bounds.lb, func.bounds.ub) #Clipping\n\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            # Selection (replace parent if offspring is better)\n            success = 0\n            for i in range(self.pop_size):\n                if offspring_fitness[i] < fitness[i]:\n                    fitness[i] = offspring_fitness[i]\n                    population[i] = offspring[i]\n                    step_sizes[i] = offspring_step_sizes[i]\n                    success += 1\n\n            success_history.append(success / self.pop_size)\n            if len(success_history) > 10:\n                success_history.pop(0)\n                \n            # Adapt mutation rate based on success rate history. The success rate is averaged over the past 10 generations.\n            avg_success_rate = np.mean(success_history)\n            if avg_success_rate > 0.4:\n                self.mutation_rate *= 1.1\n            elif avg_success_rate < 0.1:\n                self.mutation_rate *= 0.9\n            self.mutation_rate = np.clip(self.mutation_rate, 0.01, 0.5)\n\n            # Update best solution\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.08478884247596044, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "b3f65d84-7bec-4322-bdfb-f0bfbb75223d", "fitness": 0.0, "name": "FixedCovarianceCMAES", "description": "An algorithm that uses a simplified covariance matrix adaptation evolution strategy (CMA-ES) with a fixed covariance matrix, focusing on adaptation of the step size and mean.", "code": "import numpy as np\n\nclass FixedCovarianceCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mean = None\n        self.sigma = initial_step_size\n        self.C = np.eye(dim)  # Fixed covariance matrix\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.c_sigma = (self.mu / self.dim)**0.5\n        self.d_sigma = 1 + 2 * max(0, (1 - self.c_sigma*(self.budget / self.dim)**0.5 + 1e-9))\n        \n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.pop_size)\n        x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        return x\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Initialize mean within bounds\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            f = np.array([func(x[:, i]) for i in range(self.pop_size)])\n            self.eval_count += self.pop_size\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n\n            # Update mean\n            self.mean = np.sum(x_sorted[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n            # Adapt step size\n            z = (x_sorted[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n            ps = np.sum(z * self.weights[np.newaxis, :], axis=1)\n            self.sigma = self.sigma * np.exp(self.c_sigma / self.d_sigma * (np.linalg.norm(ps) / (self.dim**0.5) - 1))\n\n            self.sigma = np.clip(self.sigma, 1e-10, 5)\n\n            if self.eval_count >= self.budget:\n                remaining_evals = self.budget - (self.eval_count - self.pop_size)\n                if remaining_evals > 0:\n                    x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, remaining_evals))\n                    f = np.array([func(x[:, i]) for i in range(remaining_evals)])\n                    self.eval_count += remaining_evals\n                    \n                    if np.min(f) < self.f_opt:\n                        self.f_opt = np.min(f)\n                        self.x_opt = x[:, np.argmin(f)]\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5, 8) and arg 1 with shape (5,).", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that uses a simplified covariance matrix adaptation evolution strategy (CMA-ES) with a fixed covariance matrix, focusing on adaptation of the step size and mean.\n# Code: \n```python\nimport numpy as np\n\nclass FixedCovarianceCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mean = None\n        self.sigma = initial_step_size\n        self.C = np.eye(dim)  # Fixed covariance matrix\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.c_sigma = (self.mu / self.dim)**0.5\n        self.d_sigma = 1 + 2 * max(0, (1 - self.c_sigma*(self.budget / self.dim)**0.5 + 1e-9))\n        \n\n    def sample_population(self):\n        z = np.random.randn(self.dim, self.pop_size)\n        x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n        return x\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Initialize mean within bounds\n\n        while self.eval_count < self.budget:\n            x = self.sample_population()\n            f = np.array([func(x[:, i]) for i in range(self.pop_size)])\n            self.eval_count += self.pop_size\n\n            if np.min(f) < self.f_opt:\n                self.f_opt = np.min(f)\n                self.x_opt = x[:, np.argmin(f)]\n\n            idx = np.argsort(f)\n            x_sorted = x[:, idx]\n\n            # Update mean\n            self.mean = np.sum(x_sorted[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n            # Adapt step size\n            z = (x_sorted[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n            ps = np.sum(z * self.weights[np.newaxis, :], axis=1)\n            self.sigma = self.sigma * np.exp(self.c_sigma / self.d_sigma * (np.linalg.norm(ps) / (self.dim**0.5) - 1))\n\n            self.sigma = np.clip(self.sigma, 1e-10, 5)\n\n            if self.eval_count >= self.budget:\n                remaining_evals = self.budget - (self.eval_count - self.pop_size)\n                if remaining_evals > 0:\n                    x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim, remaining_evals))\n                    f = np.array([func(x[:, i]) for i in range(remaining_evals)])\n                    self.eval_count += remaining_evals\n                    \n                    if np.min(f) < self.f_opt:\n                        self.f_opt = np.min(f)\n                        self.x_opt = x[:, np.argmin(f)]\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.0755116328112197, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "47484919-9f08-4c35-b70a-67fb6f937bb5", "fitness": 0.3459911276769179, "name": "AdaptiveRadiusSearch", "description": "Population-based algorithm with adaptive radius search, focusing on intensifying search in promising regions.", "code": "import numpy as np\n\nclass AdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, initial_radius=0.5, radius_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evaluations = self.population_size\n\n        # Find the best individual in the initial population\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        radius = self.initial_radius\n\n        while evaluations < self.budget:\n            \n            new_population = []\n            new_fitness = []\n\n            for i in range(self.population_size):\n                # Sample within a radius around the current individual\n                x = population[i]\n                new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                new_f = func(new_x)\n                evaluations += 1\n                \n                new_population.append(new_x)\n                new_fitness.append(new_f)\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n                \n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n\n            # Update population: keep the best from the current and new population\n            combined_population = np.concatenate((population, new_population), axis=0)\n            combined_fitness = np.concatenate((fitness, new_fitness), axis=0)\n            \n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n            \n            # Adapt radius\n            radius *= self.radius_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveRadiusSearch scored 0.346 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive radius search, focusing on intensifying search in promising regions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveRadiusSearch:\n    def __init__(self, budget=10000, dim=10, population_size=20, initial_radius=0.5, radius_decay=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evaluations = self.population_size\n\n        # Find the best individual in the initial population\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n        \n        radius = self.initial_radius\n\n        while evaluations < self.budget:\n            \n            new_population = []\n            new_fitness = []\n\n            for i in range(self.population_size):\n                # Sample within a radius around the current individual\n                x = population[i]\n                new_x = x + np.random.uniform(-radius, radius, size=self.dim)\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                new_f = func(new_x)\n                evaluations += 1\n                \n                new_population.append(new_x)\n                new_fitness.append(new_f)\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n                \n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n\n            # Update population: keep the best from the current and new population\n            combined_population = np.concatenate((population, new_population), axis=0)\n            combined_fitness = np.concatenate((fitness, new_fitness), axis=0)\n            \n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n            \n            # Adapt radius\n            radius *= self.radius_decay\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15326033797701843, 0.18101312789991797, 0.8281944949931714, 0.1872060999867965, 0.2163226114546476, 0.1982354335945975, 0.2238654620976388, 0.7720295203542072, 0.1888379861764634, 0.267038534458782, 0.20636862381095122, 0.9971367258982734, 0.2866227070491729, 0.19391262819841726, 0.5360931129971256, 0.3167888548508718, 0.27433823676939095, 0.23302750467336597, 0.24424645874246642, 0.41528409155508184], "operator": "random_new", "theta_sampled": 0.6252034851136808, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "5c648535-adb4-414b-bf4d-fb4c2d524bb8", "fitness": 0.0, "name": "GaussianProcessOptimization", "description": "Employs a Gaussian Process surrogate model to guide the search, balancing exploration and exploitation with an acquisition function based on Expected Improvement.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.bounds = None\n\n    def acquisition_function(self, x, gpr, y_max):\n        mu, sigma = gpr.predict(x.reshape(1, -1)), gpr.predict(x.reshape(1, -1), return_std=True)[1]\n        \n        if sigma == 0: # very low certainty: avoid zero division\n           return 0\n\n        Z = (mu - y_max) / sigma\n        return (mu - y_max) * norm.cdf(Z) + sigma * norm.pdf(Z)\n\n    def optimize_acquisition_function(self, gpr, y_max):\n        x_start = np.random.uniform(self.bounds.lb, self.bounds.ub, size=self.dim)\n        \n        bounds_list = [(self.bounds.lb[i], self.bounds.ub[i]) for i in range(self.dim)]\n\n        result = minimize(\n            lambda x: -self.acquisition_function(x, gpr, y_max),\n            x_start,\n            bounds=bounds_list,\n            method='L-BFGS-B'\n        )\n        return result.x\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.X = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        \n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\n        remaining_budget = self.budget - self.n_initial_samples\n        \n        for i in range(remaining_budget):\n            self.gpr.fit(self.X, self.y)\n            \n            x_next = self.optimize_acquisition_function(self.gpr, self.y.max())\n            \n            f_next = func(x_next)\n            \n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: name 'C' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Employs a Gaussian Process surrogate model to guide the search, balancing exploration and exploitation with an acquisition function based on Expected Improvement.\n# Code: \n```python\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.bounds = None\n\n    def acquisition_function(self, x, gpr, y_max):\n        mu, sigma = gpr.predict(x.reshape(1, -1)), gpr.predict(x.reshape(1, -1), return_std=True)[1]\n        \n        if sigma == 0: # very low certainty: avoid zero division\n           return 0\n\n        Z = (mu - y_max) / sigma\n        return (mu - y_max) * norm.cdf(Z) + sigma * norm.pdf(Z)\n\n    def optimize_acquisition_function(self, gpr, y_max):\n        x_start = np.random.uniform(self.bounds.lb, self.bounds.ub, size=self.dim)\n        \n        bounds_list = [(self.bounds.lb[i], self.bounds.ub[i]) for i in range(self.dim)]\n\n        result = minimize(\n            lambda x: -self.acquisition_function(x, gpr, y_max),\n            x_start,\n            bounds=bounds_list,\n            method='L-BFGS-B'\n        )\n        return result.x\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.X = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        \n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\n        remaining_budget = self.budget - self.n_initial_samples\n        \n        for i in range(remaining_budget):\n            self.gpr.fit(self.X, self.y)\n            \n            x_next = self.optimize_acquisition_function(self.gpr, self.y.max())\n            \n            f_next = func(x_next)\n            \n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.4788823126601054, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "1adfaba0-e350-4689-956a-12117f368eb5", "fitness": 0.5276209772359037, "name": "HybridPSO_DESANiche", "description": "Combines PSO and self-adaptive DE with a niching strategy based on fitness to maintain population diversity and enhance exploration.", "code": "import numpy as np\n\nclass HybridPSO_DESANiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, niche_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.niche_radius = niche_radius\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Niche formation: encourage diversity\n                # If the new solution is too close to an existing niche, perturb it\n                distance_to_gbest = np.linalg.norm(new_x - gbest_x)\n                if distance_to_gbest < self.niche_radius:\n                    perturbation = np.random.normal(0, 0.05, size=self.dim)\n                    new_x = np.clip(new_x + perturbation, lb, ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DESANiche scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines PSO and self-adaptive DE with a niching strategy based on fitness to maintain population diversity and enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DESANiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, niche_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.niche_radius = niche_radius\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Niche formation: encourage diversity\n                # If the new solution is too close to an existing niche, perturb it\n                distance_to_gbest = np.linalg.norm(new_x - gbest_x)\n                if distance_to_gbest < self.niche_radius:\n                    perturbation = np.random.normal(0, 0.05, size=self.dim)\n                    new_x = np.clip(new_x + perturbation, lb, ub)\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2744722911895552, 0.22688167416137361, 0.5071716986302474, 0.9334373100653908, 0.5003947534629345, 0.5820899850664258, 0.44690592284050645, 0.44118108988869986, 0.5086504547912558, 0.18356123075548658, 0.9016047143916813, 0.9985365083674472, 0.32410814928757636, 0.48113009631117054, 0.922472965565226, 0.60240431478511, 0.28825881006413556, 0.714447932123844, 0.21019743797448398, 0.5045122049955216], "operator": "crossover", "theta_sampled": 0.2671519906560938, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "49474d10-fb49-48d5-8b07-010ea8e2a1fa", "fitness": 0.3642411619130469, "name": "StochasticInterpolationDE", "description": "Population-based algorithm that evolves individuals by stochastically interpolating between the best solution and randomly selected solutions in the population, while also incorporating a mutation step inspired by differential evolution.", "code": "import numpy as np\n\nclass StochasticInterpolationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.cr = cr # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Stochastic Interpolation\n                best_solution = population[np.argmin(fitness)]\n                random_index = np.random.randint(self.pop_size)\n                x_rand = population[random_index]\n\n                # Interpolate towards the best solution\n                trial_vector = population[i] + np.random.rand() * (best_solution - population[i]) + \\\n                               self.F * (x_rand - population[i])\n\n\n                # Differential Evolution Mutation and Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                # Clip to bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector.copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm StochasticInterpolationDE scored 0.364 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that evolves individuals by stochastically interpolating between the best solution and randomly selected solutions in the population, while also incorporating a mutation step inspired by differential evolution.\n# Code: \n```python\nimport numpy as np\n\nclass StochasticInterpolationDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, cr=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution mutation factor\n        self.cr = cr # Crossover rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Stochastic Interpolation\n                best_solution = population[np.argmin(fitness)]\n                random_index = np.random.randint(self.pop_size)\n                x_rand = population[random_index]\n\n                # Interpolate towards the best solution\n                trial_vector = population[i] + np.random.rand() * (best_solution - population[i]) + \\\n                               self.F * (x_rand - population[i])\n\n\n                # Differential Evolution Mutation and Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                # Clip to bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial_vector.copy()\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13491114022890616, 0.2127991287907809, 0.3033003696280323, 0.9818292165280547, 0.25007445086281244, 0.3739766324387731, 0.2881104367772518, 0.20450644404630336, 0.22849263376974793, 0.19472958296067233, 0.2854713825434304, 0.9956860824493645, 0.2604079007759287, 0.353910308344192, 0.6421175999538427, 0.34205441409575665, 0.29913273316299016, 0.24334274385126387, 0.20039654529953144, 0.489573491753303], "operator": "random_new", "theta_sampled": -0.014937101567226744, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "a76ee84a-f3d4-47b6-be78-5a49968c9791", "fitness": 0.0, "name": "HybridPSODE_LS", "description": "Combines PSO, DE with self-adaptive parameters, and a local search strategy, leveraging neighborhood information for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ls_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ls_probability = ls_probability # Probability of performing local search on an individual\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n\n                # Local search on each individual with probability ls_probability\n                if np.random.rand() < self.ls_probability:\n                    new_x_ls = new_x.copy()\n                    new_f_ls = func(new_x_ls)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                        local_point = np.clip(new_x_ls + perturbation, lb, ub)\n                        f_local = func(local_point)\n                        self.budget -= 1\n\n                        if self.budget <= 0:\n                            break\n                        \n                        if f_local < new_f_ls:\n                            new_f_ls = f_local\n                            new_x_ls = local_point.copy()\n\n                    if new_f_ls < func(new_x): # Only replace if local search improves the point\n                        new_x = new_x_ls\n                        new_f = new_f_ls\n                    else:\n                        new_f = func(new_x) # Otherwise, re-evaluate the non-local search point to maintain consistency\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n\n                else:\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines PSO, DE with self-adaptive parameters, and a local search strategy, leveraging neighborhood information for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSODE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ls_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ls_probability = ls_probability # Probability of performing local search on an individual\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n\n                # Local search on each individual with probability ls_probability\n                if np.random.rand() < self.ls_probability:\n                    new_x_ls = new_x.copy()\n                    new_f_ls = func(new_x_ls)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    for _ in range(self.local_search_iterations):\n                        perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                        local_point = np.clip(new_x_ls + perturbation, lb, ub)\n                        f_local = func(local_point)\n                        self.budget -= 1\n\n                        if self.budget <= 0:\n                            break\n                        \n                        if f_local < new_f_ls:\n                            new_f_ls = f_local\n                            new_x_ls = local_point.copy()\n\n                    if new_f_ls < func(new_x): # Only replace if local search improves the point\n                        new_x = new_x_ls\n                        new_f = new_f_ls\n                    else:\n                        new_f = func(new_x) # Otherwise, re-evaluate the non-local search point to maintain consistency\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n\n                else:\n                    new_f = func(new_x)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.09918013103225796, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "15c562bb-937c-4fef-ad7d-1a4e07557a9e", "fitness": 0.44574101685364775, "name": "HybridPSODE_SA_LS_VC", "description": "A hybrid PSO-DE algorithm with self-adaptive parameters, local search around the global best, and velocity clamping to prevent premature convergence.", "code": "import numpy as np\n\nclass HybridPSODE_SA_LS_VC:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight for PSO\n        self.w_min = w_min\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.velocity_clamp = velocity_clamp\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.success_f = []\n        self.success_cr = []\n        self.memory_f = np.ones(10) * 0.5\n        self.memory_cr = np.ones(10) * 0.7\n        self.memory_index = 0\n        self.mu_f = 0.5\n        self.mu_cr = 0.7\n        self.epsilon = 1e-10\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        velocities = np.zeros_like(pop)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update inertia weight linearly\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / (self.budget + self.pop_size))\n\n            for i in range(self.pop_size):\n                # PSO update\n                velocities[i] = w * velocities[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                new_x_pso = pop[i] + velocities[i]\n                \n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    self.success_f.append(self.f)\n                    self.success_cr.append(self.cr)\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Self-adaptive F and CR using success history\n            if self.success_f:\n                self.mu_f = np.mean(self.success_f)\n                self.mu_cr = np.mean(self.success_cr)\n\n                self.memory_f[self.memory_index] = self.mu_f\n                self.memory_cr[self.memory_index] = self.mu_cr\n                self.memory_index = (self.memory_index + 1) % 10\n                \n                self.f = np.random.normal(self.mu_f, 0.1)\n                self.cr = np.random.normal(self.mu_cr, 0.1)\n                self.f = np.clip(self.f, 0.1, 1.0)\n                self.cr = np.clip(self.cr, 0.1, 1.0)\n                \n                self.success_f = []\n                self.success_cr = []\n            else:\n                self.f = np.random.choice(self.memory_f)\n                self.cr = np.random.choice(self.memory_cr)\n\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODE_SA_LS_VC scored 0.446 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with self-adaptive parameters, local search around the global best, and velocity clamping to prevent premature convergence.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSODE_SA_LS_VC:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight for PSO\n        self.w_min = w_min\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.velocity_clamp = velocity_clamp\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.success_f = []\n        self.success_cr = []\n        self.memory_f = np.ones(10) * 0.5\n        self.memory_cr = np.ones(10) * 0.7\n        self.memory_index = 0\n        self.mu_f = 0.5\n        self.mu_cr = 0.7\n        self.epsilon = 1e-10\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        velocities = np.zeros_like(pop)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Update inertia weight linearly\n            w = self.w_max - (self.w_max - self.w_min) * (1 - self.budget / (self.budget + self.pop_size))\n\n            for i in range(self.pop_size):\n                # PSO update\n                velocities[i] = w * velocities[i] + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                                self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n\n                new_x_pso = pop[i] + velocities[i]\n                \n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    self.success_f.append(self.f)\n                    self.success_cr.append(self.cr)\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Self-adaptive F and CR using success history\n            if self.success_f:\n                self.mu_f = np.mean(self.success_f)\n                self.mu_cr = np.mean(self.success_cr)\n\n                self.memory_f[self.memory_index] = self.mu_f\n                self.memory_cr[self.memory_index] = self.mu_cr\n                self.memory_index = (self.memory_index + 1) % 10\n                \n                self.f = np.random.normal(self.mu_f, 0.1)\n                self.cr = np.random.normal(self.mu_cr, 0.1)\n                self.f = np.clip(self.f, 0.1, 1.0)\n                self.cr = np.clip(self.cr, 0.1, 1.0)\n                \n                self.success_f = []\n                self.success_cr = []\n            else:\n                self.f = np.random.choice(self.memory_f)\n                self.cr = np.random.choice(self.memory_cr)\n\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18547799137107934, 0.341371918595756, 0.46588341293282043, 0.7539084017562121, 0.27720952749032635, 0.5038260096660494, 0.33739156019960215, 0.3303715759293504, 0.2725470701668097, 0.3815026434024138, 0.38523980976328154, 0.995491999069198, 0.3248946928367954, 0.44526372743306486, 0.7161542239813663, 0.5359432669119374, 0.34498824743378975, 0.6263285688405842, 0.19264150158283033, 0.49838418770968707], "operator": "crossover", "theta_sampled": 0.025654053918697323, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "c2351078-073e-4fd3-a99e-0378c8a87cc5", "fitness": 0.4375563340690675, "name": "CovarianceMatrixAdaptationDifferentialEvolution", "description": "A population-based algorithm that evolves a distribution of solutions using a covariance matrix adaptation strategy, combined with a differential evolution mutation to enhance exploration.", "code": "import numpy as np\n\nclass CovarianceMatrixAdaptationDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.sigma0 = sigma0\n        self.C = np.eye(dim)  # Covariance matrix\n        self.m = None  # Mean of the population\n        self.p_c = np.zeros(dim) # Evolution path for C\n        self.p_sigma = np.zeros(dim) # Evolution path for sigma\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1-self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        self.m = np.mean(population, axis=0)\n\n        while self.budget > 0:\n            # Generate offspring\n            offspring = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                # CMA-ES sampling\n                z = np.random.normal(0, 1, self.dim)\n                x = self.m + self.sigma0 * np.dot(np.linalg.cholesky(self.C), z)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_mutated = population[idxs[0]] + 0.5 * (population[idxs[1]] - population[idxs[2]])\n                \n                # Ensure x is within bounds\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between CMA-ES sample and DE mutated vector\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                  if np.random.rand() < 0.5 or j == j_rand:\n                    offspring[k, j] = x[j]\n                  else:\n                    offspring[k, j] = x_mutated[j]\n\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            if np.min(offspring_fitness) < self.f_opt:\n                self.f_opt = np.min(offspring_fitness)\n                self.x_opt = offspring[np.argmin(offspring_fitness)]\n\n            # Selection and update CMA parameters\n            idx_sort = np.argsort(offspring_fitness)\n            offspring_sorted = offspring[idx_sort]\n\n            weights = np.array([np.log(self.mu + 0.5) - np.log(i + 1) for i in range(self.mu)])\n            weights = weights / np.sum(weights)\n            \n            m_old = self.m\n            self.m = np.sum(weights[:,None] * offspring_sorted[:self.mu], axis=0)\n            \n            # Update evolution paths\n            B = np.linalg.cholesky(self.C) # Compute B such that B @ B.T = C\n            z_weighted = (self.m - m_old) / self.sigma0\n            z_weighted = np.linalg.solve(B.T,np.linalg.solve(B, z_weighted)) # equivalent to np.linalg.solve(C, z_weighted)\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_weighted\n\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim + 1)\n\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * z_weighted\n\n            # Update covariance matrix C\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.p_c, self.p_c)\n\n            for i in range(self.mu):\n              y = (offspring_sorted[i] - m_old) / self.sigma0\n              y = np.linalg.solve(B.T, np.linalg.solve(B, y))\n              self.C += self.c_mu * weights[i] * np.outer(y, y)\n\n            self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n            \n            population = offspring.copy() # the next population is the current offspring\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm CovarianceMatrixAdaptationDifferentialEvolution scored 0.438 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that evolves a distribution of solutions using a covariance matrix adaptation strategy, combined with a differential evolution mutation to enhance exploration.\n# Code: \n```python\nimport numpy as np\n\nclass CovarianceMatrixAdaptationDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mu=None, sigma0=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.sigma0 = sigma0\n        self.C = np.eye(dim)  # Covariance matrix\n        self.m = None  # Mean of the population\n        self.p_c = np.zeros(dim) # Evolution path for C\n        self.p_sigma = np.zeros(dim) # Evolution path for sigma\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.c_c = (4 + self.mu / self.dim) / (self.dim + 4 + 2 * self.mu / self.dim)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.chiN = dim**0.5 * (1 - (1/(4*dim)) + 1/(21*dim**2))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1-self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        self.m = np.mean(population, axis=0)\n\n        while self.budget > 0:\n            # Generate offspring\n            offspring = np.zeros((self.pop_size, self.dim))\n            for k in range(self.pop_size):\n                # CMA-ES sampling\n                z = np.random.normal(0, 1, self.dim)\n                x = self.m + self.sigma0 * np.dot(np.linalg.cholesky(self.C), z)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_mutated = population[idxs[0]] + 0.5 * (population[idxs[1]] - population[idxs[2]])\n                \n                # Ensure x is within bounds\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover between CMA-ES sample and DE mutated vector\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                  if np.random.rand() < 0.5 or j == j_rand:\n                    offspring[k, j] = x[j]\n                  else:\n                    offspring[k, j] = x_mutated[j]\n\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n            \n            if np.min(offspring_fitness) < self.f_opt:\n                self.f_opt = np.min(offspring_fitness)\n                self.x_opt = offspring[np.argmin(offspring_fitness)]\n\n            # Selection and update CMA parameters\n            idx_sort = np.argsort(offspring_fitness)\n            offspring_sorted = offspring[idx_sort]\n\n            weights = np.array([np.log(self.mu + 0.5) - np.log(i + 1) for i in range(self.mu)])\n            weights = weights / np.sum(weights)\n            \n            m_old = self.m\n            self.m = np.sum(weights[:,None] * offspring_sorted[:self.mu], axis=0)\n            \n            # Update evolution paths\n            B = np.linalg.cholesky(self.C) # Compute B such that B @ B.T = C\n            z_weighted = (self.m - m_old) / self.sigma0\n            z_weighted = np.linalg.solve(B.T,np.linalg.solve(B, z_weighted)) # equivalent to np.linalg.solve(C, z_weighted)\n            self.p_sigma = (1 - self.c_sigma) * self.p_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_weighted\n\n            hsig = np.linalg.norm(self.p_sigma) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim + 1)\n\n            self.p_c = (1 - self.c_c) * self.p_c + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * z_weighted\n\n            # Update covariance matrix C\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * np.outer(self.p_c, self.p_c)\n\n            for i in range(self.mu):\n              y = (offspring_sorted[i] - m_old) / self.sigma0\n              y = np.linalg.solve(B.T, np.linalg.solve(B, y))\n              self.C += self.c_mu * weights[i] * np.outer(y, y)\n\n            self.sigma0 *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.p_sigma)/self.chiN - 1))\n            \n            population = offspring.copy() # the next population is the current offspring\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14815984509933988, 0.17446119665092896, 0.32662435444326143, 0.21665530417347878, 0.3431468600316625, 0.9591872305772995, 0.2493552091643071, 0.695372893793273, 0.8407421166260575, 0.19400297417633328, 0.2055000067615118, 0.9961720388993182, 0.21147012793681652, 0.5594770126223515, 0.6742568463837908, 0.2993588991156063, 0.3208636427123812, 0.9602806815143736, 0.19973447642436504, 0.17630496427489484], "operator": "random_new", "theta_sampled": 0.11088295980559248, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "677378a3-abbb-499c-8207-f79535fe817f", "fitness": 0.0, "name": "HybridPSODE_OL_SA", "description": "A hybrid PSO-DE algorithm with self-adaptive parameters, orthogonal learning, and a local search strategy around the best solution.", "code": "import numpy as np\n\nclass HybridPSODE_OL_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ol_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ol_samples = ol_samples # Number of samples for orthogonal learning\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n\n                # Orthogonal Learning\n                ol_matrix = self.create_orthogonal_array(self.ol_samples, self.dim)\n                best_ol_f = np.inf\n                best_ol_x = None\n                for k in range(self.ol_samples):\n                    ol_point = new_x.copy()\n                    for j in range(self.dim):\n                         ol_point[j] = lb + (ub - lb) * ol_matrix[k,j]\n                    ol_point = np.clip(ol_point, lb, ub)\n                    ol_f = func(ol_point)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if ol_f < best_ol_f:\n                        best_ol_f = ol_f\n                        best_ol_x = ol_point.copy()\n                \n                if self.budget <=0:\n                    break\n\n                #Evaluate new_x\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n                \n                # Choose between original new_x and orthogonal learning point\n                if best_ol_x is not None and best_ol_f < new_f:\n                    new_x = best_ol_x\n                    new_f = best_ol_f\n\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n    \n    def create_orthogonal_array(self, samples, dim):\n        # Simple implementation using random sampling\n        return np.random.rand(samples, dim)", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with self-adaptive parameters, orthogonal learning, and a local search strategy around the best solution.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSODE_OL_SA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ol_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ol_samples = ol_samples # Number of samples for orthogonal learning\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n\n                # Orthogonal Learning\n                ol_matrix = self.create_orthogonal_array(self.ol_samples, self.dim)\n                best_ol_f = np.inf\n                best_ol_x = None\n                for k in range(self.ol_samples):\n                    ol_point = new_x.copy()\n                    for j in range(self.dim):\n                         ol_point[j] = lb + (ub - lb) * ol_matrix[k,j]\n                    ol_point = np.clip(ol_point, lb, ub)\n                    ol_f = func(ol_point)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    if ol_f < best_ol_f:\n                        best_ol_f = ol_f\n                        best_ol_x = ol_point.copy()\n                \n                if self.budget <=0:\n                    break\n\n                #Evaluate new_x\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n                \n                # Choose between original new_x and orthogonal learning point\n                if best_ol_x is not None and best_ol_f < new_f:\n                    new_x = best_ol_x\n                    new_f = best_ol_f\n\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n    \n    def create_orthogonal_array(self, samples, dim):\n        # Simple implementation using random sampling\n        return np.random.rand(samples, dim)\n```", "operator": "crossover", "theta_sampled": 0.41053958048855616, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "61eb8782-46a5-485d-819e-2c5c213b9da2", "fitness": 0.5728116389289479, "name": "EnhancedHybridPSO_DE", "description": "A hybrid PSO-DE algorithm with self-adaptive parameters and a local search, further enhanced with a selection mechanism for PSO/DE updates based on the fitness improvement.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, pso_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.pso_prob = pso_prob # Probability of choosing PSO update\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub) # Clip here, before evaluation\n                f_pso = func(new_x_pso) if self.budget > 0 else np.inf\n                if self.budget > 0:\n                    self.budget -= 1\n\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                new_x_de = np.clip(new_x_de, lb, ub) # Clip here, before evaluation\n                f_de = func(new_x_de) if self.budget > 0 else np.inf\n                if self.budget > 0:\n                    self.budget -= 1\n\n                # Selection mechanism: Choose the update with better fitness\n                if f_pso < f_de:\n                    new_x = new_x_pso\n                    new_f = f_pso\n                else:\n                    new_x = new_x_de\n                    new_f = f_de\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSO_DE scored 0.573 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with self-adaptive parameters and a local search, further enhanced with a selection mechanism for PSO/DE updates based on the fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, pso_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.pso_prob = pso_prob # Probability of choosing PSO update\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub) # Clip here, before evaluation\n                f_pso = func(new_x_pso) if self.budget > 0 else np.inf\n                if self.budget > 0:\n                    self.budget -= 1\n\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                new_x_de = np.clip(new_x_de, lb, ub) # Clip here, before evaluation\n                f_de = func(new_x_de) if self.budget > 0 else np.inf\n                if self.budget > 0:\n                    self.budget -= 1\n\n                # Selection mechanism: Choose the update with better fitness\n                if f_pso < f_de:\n                    new_x = new_x_pso\n                    new_f = f_pso\n                else:\n                    new_x = new_x_de\n                    new_f = f_de\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2287073196752869, 0.3730655860979186, 0.876067071882372, 0.18020646695711806, 0.2913401004449333, 0.9060123983084405, 0.3079348352331238, 0.7896739271359041, 0.8692401422325597, 0.20510312119694263, 0.8526282124403647, 0.9934562365981502, 0.28852350017162676, 0.33170840967824033, 0.9495811602307992, 0.9313569431330042, 0.44286431319729724, 0.9393404095157217, 0.2105037502408471, 0.4889188742083048], "operator": "crossover", "theta_sampled": 0.2954321235106025, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "1ae74229-4be9-4f7c-9abf-8f99554e9431", "fitness": 0.07269999513290049, "name": "EnhancedSelfAdaptiveDE", "description": "An enhanced Self-Adaptive Differential Evolution algorithm with a restart mechanism, orthogonal learning, and dynamic parameter control for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger # Percentage of budget used before restart consideration\n        self.initial_F = F\n        self.initial_CR = CR\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        archive = population.copy() # Archive for past solutions\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            old_f_opt = self.f_opt  # Store the previous best fitness for stagnation detection\n\n            for i in range(self.pop_size):\n                # Mutation with archive consideration\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = population[np.random.choice(idxs, 2, replace=False)]\n\n                #Select c from population or archive\n                if np.random.rand() < 0.5:\n                    c = population[np.random.choice(idxs, 1, replace=False)][0]\n                else:\n                    c = archive[np.random.choice(range(self.pop_size), 1, replace=False)][0]\n\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    archive[i] = trial #Update Archive\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1\n            \n\n            if self.budget > 0:\n                # Self-adaptation of F and CR with decaying learning rate\n                decay_rate = 0.95\n                self.F = 0.9 * self.F + 0.1 * np.random.normal(0.5, 0.1)\n                self.CR = 0.9 * self.CR + 0.1 * np.random.normal(0.7, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n                # Local search around the best solution (optional)\n                for _ in range(min(self.local_search_iterations, self.budget)):  # Ensure local search doesn't exceed the budget\n                    if self.budget <= 0:\n                        break\n                    perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                    local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = local_point\n                        self.stagnation_counter = 0  # Reset stagnation counter\n\n\n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold or (self.budget < (1-self.restart_trigger)*self.budget): #Restart if stagnant or approaching budget limit\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                archive = population.copy()\n                self.F = self.initial_F\n                self.CR = self.initial_CR\n                self.stagnation_counter = 0\n\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.073 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7764b8d8-7601-43c5-83ca-41ac013cba16"], "operator": "mutation", "metadata": {"llm_response": "# Description: An enhanced Self-Adaptive Differential Evolution algorithm with a restart mechanism, orthogonal learning, and dynamic parameter control for improved exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger # Percentage of budget used before restart consideration\n        self.initial_F = F\n        self.initial_CR = CR\n        self.stagnation_counter = 0\n        self.stagnation_threshold = 50\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        archive = population.copy() # Archive for past solutions\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            old_f_opt = self.f_opt  # Store the previous best fitness for stagnation detection\n\n            for i in range(self.pop_size):\n                # Mutation with archive consideration\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = population[np.random.choice(idxs, 2, replace=False)]\n\n                #Select c from population or archive\n                if np.random.rand() < 0.5:\n                    c = population[np.random.choice(idxs, 1, replace=False)][0]\n                else:\n                    c = archive[np.random.choice(range(self.pop_size), 1, replace=False)][0]\n\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    archive[i] = trial #Update Archive\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter +=1\n            \n\n            if self.budget > 0:\n                # Self-adaptation of F and CR with decaying learning rate\n                decay_rate = 0.95\n                self.F = 0.9 * self.F + 0.1 * np.random.normal(0.5, 0.1)\n                self.CR = 0.9 * self.CR + 0.1 * np.random.normal(0.7, 0.1)\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n\n                # Local search around the best solution (optional)\n                for _ in range(min(self.local_search_iterations, self.budget)):  # Ensure local search doesn't exceed the budget\n                    if self.budget <= 0:\n                        break\n                    perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                    local_point = np.clip(self.x_opt + perturbation, func.bounds.lb, func.bounds.ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < self.f_opt:\n                        self.f_opt = f_local\n                        self.x_opt = local_point\n                        self.stagnation_counter = 0  # Reset stagnation counter\n\n\n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_threshold or (self.budget < (1-self.restart_trigger)*self.budget): #Restart if stagnant or approaching budget limit\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                archive = population.copy()\n                self.F = self.initial_F\n                self.CR = self.initial_CR\n                self.stagnation_counter = 0\n\n\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14539999026580097, 0], "operator": "mutation", "theta_sampled": 0.2552464503842551, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "4b7e9bbb-5165-4edd-9662-d64ae7e26485", "fitness": 0.2551417338087118, "name": "AdaptiveStepCauchySearch", "description": "Population-based algorithm that dynamically adjusts step size based on the success rate of previous steps and uses a Cauchy mutation for exploration.", "code": "import numpy as np\n\nclass AdaptiveStepCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                z = np.random.standard_cauchy(size=self.dim)\n                mutation = self.step_size * z\n                new_x = population[i] + mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n\n                f = func(new_x)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    new_population[i] = new_x\n                    new_fitness[i] = f\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n                    self.success_history.append(1)  # Success\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                    self.success_history.append(0)  # Failure\n\n                if self.budget <= 0:\n                    break # Break out of inner loop if budget is exhausted\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adjust step size based on success rate\n            if len(self.success_history) > self.success_rate_memory:\n                self.success_history = self.success_history[-self.success_rate_memory:]\n            \n            success_rate = np.mean(self.success_history) if self.success_history else 0.5  #Default value\n\n            if success_rate > 0.6:\n                self.step_size *= 1.1  # Increase step size\n            elif success_rate < 0.4:\n                self.step_size *= 0.9  # Decrease step size\n\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)  # Keep step size within reasonable bounds\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveStepCauchySearch scored 0.255 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that dynamically adjusts step size based on the success rate of previous steps and uses a Cauchy mutation for exploration.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveStepCauchySearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=0.1, success_rate_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = initial_step_size\n        self.success_rate_memory = success_rate_memory\n        self.success_history = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Cauchy mutation\n                z = np.random.standard_cauchy(size=self.dim)\n                mutation = self.step_size * z\n                new_x = population[i] + mutation\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n\n                f = func(new_x)\n                self.budget -= 1\n                \n                if f < fitness[i]:\n                    new_population[i] = new_x\n                    new_fitness[i] = f\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n                    self.success_history.append(1)  # Success\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                    self.success_history.append(0)  # Failure\n\n                if self.budget <= 0:\n                    break # Break out of inner loop if budget is exhausted\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adjust step size based on success rate\n            if len(self.success_history) > self.success_rate_memory:\n                self.success_history = self.success_history[-self.success_rate_memory:]\n            \n            success_rate = np.mean(self.success_history) if self.success_history else 0.5  #Default value\n\n            if success_rate > 0.6:\n                self.step_size *= 1.1  # Increase step size\n            elif success_rate < 0.4:\n                self.step_size *= 0.9  # Decrease step size\n\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)  # Keep step size within reasonable bounds\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.08938738359343701, 0.22118086500327594, 0.3437007324379636, 0.1832395934251584, 0.18665414477849118, 0.22242960408475665, 0.2795104021693271, 0.23395978636525627, 0.16725681552389216, 0.16337947184243695, 0.22450115177700114, 0.20021617950432347, 0.27601413778937167, 0.1616750139025518, 0.6740468166452908, 0.306677048730713, 0.22186968584090905, 0.34105781148108794, 0.15341730130815867, 0.4526607299708333], "operator": "random_new", "theta_sampled": 0.261222414906329, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "99ace9ff-05b8-46ef-b1be-bff31400305c", "fitness": 0.31670616710083777, "name": "AdaptiveRangeSearch", "description": "A population-based algorithm that dynamically adjusts the search range based on the distribution of successful solutions, focusing on promising regions while maintaining exploration.", "code": "import numpy as np\n\nclass AdaptiveRangeSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_range=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_range = initial_range\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population within the bounds.\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update the best solution found so far.\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Adaptive range parameters.\n        current_range = np.full(self.dim, self.initial_range) # Range for each dimension\n        shrink_factor = 0.95  # Reduce range when stagnating\n        expand_factor = 1.1 # Expand range if needed\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Generate new candidate solutions based on the current population and range.\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Sample new solution within the adaptive range around a randomly selected individual.\n                ref_idx = np.random.randint(self.pop_size)\n                new_x = population[ref_idx] + np.random.uniform(-current_range, current_range, size=self.dim)\n\n                # Clip values to stay within the bounds.\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_population[i] = new_x\n                \n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Update the population. Replace the worst individuals with the better new ones.\n            for i in range(self.pop_size):\n                worst_index = np.argmax(fitness)  # Index of worst fitness in population\n                if new_fitness[i] < fitness[worst_index]:\n                    population[worst_index] = new_population[i]\n                    fitness[worst_index] = new_fitness[i]\n\n            # Update the best solution found so far.\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Dynamically adjust the search range.\n            # Calculate the standard deviation of the population along each dimension.\n            std_dev = np.std(population, axis=0)\n\n            # Adjust the range based on the standard deviation.\n            # If the standard deviation is small, shrink the range.\n            # If the standard deviation is large (close to initial), expand the range.\n            for d in range(self.dim):\n                if std_dev[d] < current_range[d] * 0.1:  # Consider a small threshold\n                    current_range[d] *= shrink_factor\n                elif std_dev[d] > self.initial_range * 0.8: # Reached Initial Range Almost\n                    current_range[d] *= expand_factor\n                current_range[d] = np.clip(current_range[d], 0.01, self.initial_range * 2.0) # Clip the range.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveRangeSearch scored 0.317 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that dynamically adjusts the search range based on the distribution of successful solutions, focusing on promising regions while maintaining exploration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveRangeSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_range=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_range = initial_range\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population within the bounds.\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Update the best solution found so far.\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        # Adaptive range parameters.\n        current_range = np.full(self.dim, self.initial_range) # Range for each dimension\n        shrink_factor = 0.95  # Reduce range when stagnating\n        expand_factor = 1.1 # Expand range if needed\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Generate new candidate solutions based on the current population and range.\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Sample new solution within the adaptive range around a randomly selected individual.\n                ref_idx = np.random.randint(self.pop_size)\n                new_x = population[ref_idx] + np.random.uniform(-current_range, current_range, size=self.dim)\n\n                # Clip values to stay within the bounds.\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                new_population[i] = new_x\n                \n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n            \n            # Update the population. Replace the worst individuals with the better new ones.\n            for i in range(self.pop_size):\n                worst_index = np.argmax(fitness)  # Index of worst fitness in population\n                if new_fitness[i] < fitness[worst_index]:\n                    population[worst_index] = new_population[i]\n                    fitness[worst_index] = new_fitness[i]\n\n            # Update the best solution found so far.\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Dynamically adjust the search range.\n            # Calculate the standard deviation of the population along each dimension.\n            std_dev = np.std(population, axis=0)\n\n            # Adjust the range based on the standard deviation.\n            # If the standard deviation is small, shrink the range.\n            # If the standard deviation is large (close to initial), expand the range.\n            for d in range(self.dim):\n                if std_dev[d] < current_range[d] * 0.1:  # Consider a small threshold\n                    current_range[d] *= shrink_factor\n                elif std_dev[d] > self.initial_range * 0.8: # Reached Initial Range Almost\n                    current_range[d] *= expand_factor\n                current_range[d] = np.clip(current_range[d], 0.01, self.initial_range * 2.0) # Clip the range.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13822756448161033, 0.19549454033257663, 0.2825840936432391, 0.2908633354485374, 0.23288008804963745, 0.27285528763940914, 0.26308266473827024, 0.250826849241898, 0.21573785689744818, 0.19055216406298936, 0.28264863275705066, 0.9988469177223472, 0.2797633881566125, 0.2427029457340356, 0.6560184397459483, 0.30532541147531933, 0.2673795209750296, 0.31630588932976356, 0.1708939471459855, 0.48113380443904785], "operator": "random_new", "theta_sampled": -0.13583597791217333, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "6fdb3734-b8e2-43fc-92e0-87e4c2aa6d3d", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "A covariance matrix adaptation evolution strategy (CMA-ES) variant that dynamically adjusts the population size based on the success rate of adaptation steps, aiming to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_factor=0.25, cs=0.08, damps=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_factor = mu_factor\n        self.cs = cs\n        self.damps = damps\n\n        self.mu = int(self.budget * mu_factor)  # Initial mu is proportional to the budget, but limited by population size\n        self.lambda_ = 4 + int(3 * np.log(self.dim))  # dynamic lambda based on dim\n        self.C = np.eye(self.dim)              # Covariance matrix\n        self.sigma = self.initial_sigma           # Step size\n        self.m = np.zeros(self.dim)            # Mean of the population\n        self.pc = np.zeros(self.dim)           # Evolution path for C\n        self.ps = np.zeros(self.dim)           # Evolution path for sigma\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2.3)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.lambda_)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.lambda_)])\n            evals += self.lambda_\n            if evals > self.budget:\n                evals = self.budget #Ensure the budget is not exceeded. f is only partially filled.\n                f = f[:self.budget- (evals-self.lambda_)]\n                self.lambda_ = len(f)\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            xmean = np.sum(x[:, :self.lambda_] * self.weights[:self.lambda_], axis=1)\n\n            # Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m)/self.sigma)\n            hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*(evals/self.lambda_)))/np.sqrt(self.dim) < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc*(2-self.cc)*self.mueff) * (xmean - self.m)/self.sigma\n\n            # Update covariance matrix\n            artmp = (x[:, :self.lambda_] - self.m[:, np.newaxis]) / self.sigma\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.cc*(2-self.cc) * self.C) + self.cmu * np.dot(artmp, np.dot(np.diag(self.weights[:self.lambda_]), artmp.T))\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n\n            # Update mean\n            self.m = xmean\n\n            # Dynamic population size adjustment\n            if evals > self.budget // 4:\n                if f[0] < self.f_opt:\n                    self.success_rate = 0.9  # Increased success rate\n                else:\n                    self.success_rate = 0.1  # Decreased success rate\n\n                if self.success_rate > 0.7 and self.lambda_ < 2 * self.dim:\n                    self.lambda_ = min(2*self.lambda_, self.budget - evals)\n                    self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                elif self.success_rate < 0.3 and self.lambda_ > 4:\n                    self.lambda_ = max(4, self.lambda_ // 2)\n                    self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A covariance matrix adaptation evolution strategy (CMA-ES) variant that dynamically adjusts the population size based on the success rate of adaptation steps, aiming to balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_factor=0.25, cs=0.08, damps=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_factor = mu_factor\n        self.cs = cs\n        self.damps = damps\n\n        self.mu = int(self.budget * mu_factor)  # Initial mu is proportional to the budget, but limited by population size\n        self.lambda_ = 4 + int(3 * np.log(self.dim))  # dynamic lambda based on dim\n        self.C = np.eye(self.dim)              # Covariance matrix\n        self.sigma = self.initial_sigma           # Step size\n        self.m = np.zeros(self.dim)            # Mean of the population\n        self.pc = np.zeros(self.dim)           # Evolution path for C\n        self.ps = np.zeros(self.dim)           # Evolution path for sigma\n        self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff-2+1/self.mueff) / ((self.dim+2.3)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1))-1) + self.cs\n        self.success_rate = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.lambda_)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.lambda_)])\n            evals += self.lambda_\n            if evals > self.budget:\n                evals = self.budget #Ensure the budget is not exceeded. f is only partially filled.\n                f = f[:self.budget- (evals-self.lambda_)]\n                self.lambda_ = len(f)\n\n            # Sort population\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n\n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0]\n\n            # Update mean\n            xmean = np.sum(x[:, :self.lambda_] * self.weights[:self.lambda_], axis=1)\n\n            # Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs*(2-self.cs)*self.mueff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m)/self.sigma)\n            hsig = (np.linalg.norm(self.ps)/np.sqrt(1-(1-self.cs)**(2*(evals/self.lambda_)))/np.sqrt(self.dim) < 1.4 + 2/(self.dim+1))\n\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc*(2-self.cc)*self.mueff) * (xmean - self.m)/self.sigma\n\n            # Update covariance matrix\n            artmp = (x[:, :self.lambda_] - self.m[:, np.newaxis]) / self.sigma\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.cc*(2-self.cc) * self.C) + self.cmu * np.dot(artmp, np.dot(np.diag(self.weights[:self.lambda_]), artmp.T))\n\n            # Update step size\n            self.sigma *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1))\n\n            # Update mean\n            self.m = xmean\n\n            # Dynamic population size adjustment\n            if evals > self.budget // 4:\n                if f[0] < self.f_opt:\n                    self.success_rate = 0.9  # Increased success rate\n                else:\n                    self.success_rate = 0.1  # Decreased success rate\n\n                if self.success_rate > 0.7 and self.lambda_ < 2 * self.dim:\n                    self.lambda_ = min(2*self.lambda_, self.budget - evals)\n                    self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                elif self.success_rate < 0.3 and self.lambda_ > 4:\n                    self.lambda_ = max(4, self.lambda_ // 2)\n                    self.weights = np.log(self.lambda_ + 1/2) - np.log(np.arange(1, self.lambda_ + 1))\n                    self.weights = self.weights / np.sum(self.weights)\n                    self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n                    \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.09995634405952278, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "d8d338aa-d6be-4318-90d0-b7d6da7ecb48", "fitness": 0.0, "name": "GPSurrogateCMAES", "description": "A novel optimization algorithm that combines a Gaussian Process surrogate model with a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for efficient global optimization.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom cmaes import CMA\n\nclass GPSurrogateCMAES:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=20, gp_noise_level=1e-3):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.gp_noise_level = gp_noise_level\n        self.X = None\n        self.y = None\n        self.gp = None\n        self.optimizer = None\n\n\n    def initialize(self, func):\n        # Generate initial samples\n        X_init = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n\n        self.X = X_init\n        self.y = y_init\n\n        # Initialize Gaussian Process\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, alpha=self.gp_noise_level)\n        self.gp.fit(self.X, self.y)\n\n        # Initialize CMA-ES\n        self.optimizer = CMA(mean=np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim), \n                              sigma=1.0, \n                              bounds=np.array([func.bounds.lb, func.bounds.ub]))\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return -mu[0] + 2 * sigma[0]  # Upper Confidence Bound (UCB)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        num_evals = 0\n\n        self.initialize(func)\n        num_evals += self.n_initial_samples\n\n        while num_evals < self.budget:\n            # Suggest a new point using CMA-ES on the acquisition function\n            solutions = []\n            for _ in range(self.optimizer.population_size):\n                x = self.optimizer.ask()\n                solutions.append((x, self.acquisition_function(x)))\n\n            solutions.sort(key=lambda s: s[1])\n            \n            best_x = solutions[0][0] #Get best x from the optimization of the acquisition function via CMA-ES\n\n            # Evaluate the actual function\n            f = func(best_x)\n            num_evals += 1\n\n            # Update the Gaussian Process with the new data\n            self.X = np.vstack([self.X, best_x])\n            self.y = np.append(self.y, f)\n            self.gp.fit(self.X, self.y)\n            \n            #Tell CMA-ES the new function value on the real function\n            self.optimizer.tell(best_x, f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = best_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: No module named 'cmaes'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A novel optimization algorithm that combines a Gaussian Process surrogate model with a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for efficient global optimization.\n# Code:\n```python\nimport numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom cmaes import CMA\n\nclass GPSurrogateCMAES:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=20, gp_noise_level=1e-3):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.gp_noise_level = gp_noise_level\n        self.X = None\n        self.y = None\n        self.gp = None\n        self.optimizer = None\n\n\n    def initialize(self, func):\n        # Generate initial samples\n        X_init = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n\n        self.X = X_init\n        self.y = y_init\n\n        # Initialize Gaussian Process\n        kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, alpha=self.gp_noise_level)\n        self.gp.fit(self.X, self.y)\n\n        # Initialize CMA-ES\n        self.optimizer = CMA(mean=np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim), \n                              sigma=1.0, \n                              bounds=np.array([func.bounds.lb, func.bounds.ub]))\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        return -mu[0] + 2 * sigma[0]  # Upper Confidence Bound (UCB)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        num_evals = 0\n\n        self.initialize(func)\n        num_evals += self.n_initial_samples\n\n        while num_evals < self.budget:\n            # Suggest a new point using CMA-ES on the acquisition function\n            solutions = []\n            for _ in range(self.optimizer.population_size):\n                x = self.optimizer.ask()\n                solutions.append((x, self.acquisition_function(x)))\n\n            solutions.sort(key=lambda s: s[1])\n            \n            best_x = solutions[0][0] #Get best x from the optimization of the acquisition function via CMA-ES\n\n            # Evaluate the actual function\n            f = func(best_x)\n            num_evals += 1\n\n            # Update the Gaussian Process with the new data\n            self.X = np.vstack([self.X, best_x])\n            self.y = np.append(self.y, f)\n            self.gp.fit(self.X, self.y)\n            \n            #Tell CMA-ES the new function value on the real function\n            self.optimizer.tell(best_x, f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = best_x\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.04579953389148951, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "ef49558f-6f89-4474-9150-1c8b250b8424", "fitness": 0.5371680594968762, "name": "EnhancedHybridPSO_DESA", "description": "Combines PSO and DE with self-adaptive parameters, a local search strategy, and velocity clamping for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.velocity_clamp = velocity_clamp # Clamp velocity to prevent premature convergence\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n            \n            for i in range(self.pop_size):\n                # PSO update with velocity clamping\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + self.c1 * r1 * (pbest_pop[i] - pop[i]) + \\\n                                 self.c2 * r2 * (gbest_x - pop[i])\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                new_x_pso = pop[i] + velocities[i]\n                new_x_pso = np.clip(new_x_pso, lb, ub)  # Clip to bounds\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                \n                # Evaluate\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_DESA scored 0.537 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines PSO and DE with self-adaptive parameters, a local search strategy, and velocity clamping for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, velocity_clamp=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.velocity_clamp = velocity_clamp # Clamp velocity to prevent premature convergence\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n            \n            for i in range(self.pop_size):\n                # PSO update with velocity clamping\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + self.c1 * r1 * (pbest_pop[i] - pop[i]) + \\\n                                 self.c2 * r2 * (gbest_x - pop[i])\n                \n                # Clamp velocities\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (ub - lb), self.velocity_clamp * (ub - lb))\n                \n                new_x_pso = pop[i] + velocities[i]\n                new_x_pso = np.clip(new_x_pso, lb, ub)  # Clip to bounds\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                \n                # Evaluate\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2239681624918589, 0.41721610040982027, 0.4999086973811566, 0.821923471446331, 0.4650974121605672, 0.6435103527295178, 0.3727982223814861, 0.46153415611833326, 0.5524979723525645, 0.4283539087108844, 0.7515124477299429, 0.99898016736243, 0.31109435455735224, 0.4566592720642889, 0.8667543534943049, 0.5870265153397829, 0.40514678295397055, 0.7498919173961163, 0.22414204416067318, 0.5053448786961403], "operator": "crossover", "theta_sampled": 0.3492677665054855, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "bdd9b6de-f32f-4748-ac78-02880ac406fb", "fitness": 0.6329012465052269, "name": "EnhancedHybridPSO_DESA", "description": "A hybrid PSO-DE algorithm with self-adaptive parameters, local search, and a diversity-enhancing mechanism to prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.diversity_threshold = diversity_threshold\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update with adaptive F and CR\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                # Adaptive F and CR\n                F_adaptive = np.random.normal(0.5, 0.1)\n                CR_adaptive = np.random.normal(0.7, 0.1)\n                F_adaptive = np.clip(F_adaptive, 0.1, 1.0)\n                CR_adaptive = np.clip(CR_adaptive, 0.1, 1.0)\n\n                v_de = pbest_pop[r1] + F_adaptive * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < CR_adaptive or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n            \n            # Diversity check and enhancement\n            if generation % 10 == 0:  # Check diversity every 10 generations\n                diversity = np.std(pop)\n                if diversity < self.diversity_threshold:\n                    # Introduce more randomness to the population\n                    for i in range(self.pop_size):\n                        pop[i] = np.random.uniform(lb, ub)\n                    fitness = np.array([func(x) for x in pop])\n                    self.budget -= self.pop_size\n                    if self.budget <= 0:\n                        break\n                    pbest_pop = pop.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest_index = np.argmin(pbest_fitness)\n                    gbest_x = pbest_pop[gbest_index].copy()\n                    gbest_f = pbest_fitness[gbest_index]\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_DESA scored 0.633 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with self-adaptive parameters, local search, and a diversity-enhancing mechanism to prevent premature convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSO_DESA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.diversity_threshold = diversity_threshold\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update with adaptive F and CR\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                # Adaptive F and CR\n                F_adaptive = np.random.normal(0.5, 0.1)\n                CR_adaptive = np.random.normal(0.7, 0.1)\n                F_adaptive = np.clip(F_adaptive, 0.1, 1.0)\n                CR_adaptive = np.clip(CR_adaptive, 0.1, 1.0)\n\n                v_de = pbest_pop[r1] + F_adaptive * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < CR_adaptive or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n            \n            # Diversity check and enhancement\n            if generation % 10 == 0:  # Check diversity every 10 generations\n                diversity = np.std(pop)\n                if diversity < self.diversity_threshold:\n                    # Introduce more randomness to the population\n                    for i in range(self.pop_size):\n                        pop[i] = np.random.uniform(lb, ub)\n                    fitness = np.array([func(x) for x in pop])\n                    self.budget -= self.pop_size\n                    if self.budget <= 0:\n                        break\n                    pbest_pop = pop.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest_index = np.argmin(pbest_fitness)\n                    gbest_x = pbest_pop[gbest_index].copy()\n                    gbest_f = pbest_fitness[gbest_index]\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.25582699030415457, 0.5118021380490339, 0.859674772027199, 0.9479116088166641, 0.8189105438392419, 0.9099281346112772, 0.3376112691734994, 0.6161555938538025, 0.33898840062287394, 0.2023231405181607, 0.9273272846610859, 0.9945680301441364, 0.35749362081514835, 0.3737005351483558, 0.9196144206500485, 0.8789502072183076, 0.6444481106261837, 0.9417859532066701, 0.3294105572452334, 0.4915936185734586], "operator": "crossover", "theta_sampled": 0.42501932992148506, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "16541f34-77c0-463e-8e6e-67407973a0d6", "fitness": 0.40518398571801295, "name": "AdaptiveMutationEvolution", "description": "Population-based algorithm that adaptively adjusts mutation strength based on population diversity and local landscape information using a combination of Cauchy and Gaussian mutations.", "code": "import numpy as np\n\nclass AdaptiveMutationEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.1\n        self.cauchy_prob = 0.5 # Probability of using Cauchy mutation\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average distance between individuals in the population.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def mutate(self, x, diversity, f):\n        \"\"\"Adaptive mutation using Gaussian and Cauchy distributions.\"\"\"\n        mutation_strength = self.mutation_rate * (self.ub - self.lb) * (1 + np.exp(-diversity)) # Scale with diversity\n        \n        if np.random.rand() < self.cauchy_prob:\n            # Cauchy mutation: Larger steps, good for exploration\n            mutation = mutation_strength * np.random.standard_cauchy(size=self.dim)\n        else:\n            # Gaussian mutation: Smaller steps, good for exploitation\n            mutation = mutation_strength * np.random.normal(size=self.dim)\n\n        mutated_x = x + mutation\n        mutated_x = np.clip(mutated_x, self.lb, self.ub) # Clip to bounds\n        return mutated_x\n\n    def crossover(self, x, best_x):\n        \"\"\"Simple crossover with the best individual.\"\"\"\n        cross_rate = 0.7\n        mask = np.random.rand(self.dim) < cross_rate\n        offspring = x.copy()\n        offspring[mask] = best_x[mask]\n        return offspring\n\n\n    def __call__(self, func):\n        population = self.initialize_population()\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Account for initial population evaluations\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity(population)\n            best_x = population[best_index]\n            new_population = []\n            new_fitness = []\n            \n            for i in range(self.pop_size):\n                # Mutation and Crossover\n                mutated_x = self.mutate(population[i], diversity, fitness[i])\n                offspring = self.crossover(mutated_x, best_x)\n\n                # Evaluate the offspring\n                f = func(offspring)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                new_population.append(offspring)\n                new_fitness.append(f)\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = offspring\n\n            if self.budget <= 0:\n                break\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n            \n            # Selection: Replace the worst individuals\n            worst_indices = np.argsort(fitness)[-len(new_fitness):] # indices of worst individuals\n            population[worst_indices] = new_population\n            fitness[worst_indices] = new_fitness\n            \n            best_index = np.argmin(fitness)\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveMutationEvolution scored 0.405 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that adaptively adjusts mutation strength based on population diversity and local landscape information using a combination of Cauchy and Gaussian mutations.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveMutationEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.1\n        self.cauchy_prob = 0.5 # Probability of using Cauchy mutation\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def calculate_diversity(self, population):\n        \"\"\"Calculates the average distance between individuals in the population.\"\"\"\n        centroid = np.mean(population, axis=0)\n        distances = np.linalg.norm(population - centroid, axis=1)\n        return np.mean(distances)\n\n    def mutate(self, x, diversity, f):\n        \"\"\"Adaptive mutation using Gaussian and Cauchy distributions.\"\"\"\n        mutation_strength = self.mutation_rate * (self.ub - self.lb) * (1 + np.exp(-diversity)) # Scale with diversity\n        \n        if np.random.rand() < self.cauchy_prob:\n            # Cauchy mutation: Larger steps, good for exploration\n            mutation = mutation_strength * np.random.standard_cauchy(size=self.dim)\n        else:\n            # Gaussian mutation: Smaller steps, good for exploitation\n            mutation = mutation_strength * np.random.normal(size=self.dim)\n\n        mutated_x = x + mutation\n        mutated_x = np.clip(mutated_x, self.lb, self.ub) # Clip to bounds\n        return mutated_x\n\n    def crossover(self, x, best_x):\n        \"\"\"Simple crossover with the best individual.\"\"\"\n        cross_rate = 0.7\n        mask = np.random.rand(self.dim) < cross_rate\n        offspring = x.copy()\n        offspring[mask] = best_x[mask]\n        return offspring\n\n\n    def __call__(self, func):\n        population = self.initialize_population()\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Account for initial population evaluations\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            diversity = self.calculate_diversity(population)\n            best_x = population[best_index]\n            new_population = []\n            new_fitness = []\n            \n            for i in range(self.pop_size):\n                # Mutation and Crossover\n                mutated_x = self.mutate(population[i], diversity, fitness[i])\n                offspring = self.crossover(mutated_x, best_x)\n\n                # Evaluate the offspring\n                f = func(offspring)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                new_population.append(offspring)\n                new_fitness.append(f)\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = offspring\n\n            if self.budget <= 0:\n                break\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n            \n            # Selection: Replace the worst individuals\n            worst_indices = np.argsort(fitness)[-len(new_fitness):] # indices of worst individuals\n            population[worst_indices] = new_population\n            fitness[worst_indices] = new_fitness\n            \n            best_index = np.argmin(fitness)\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19327110751426435, 0.19849545184117812, 0.43168190449783417, 0.555971185897681, 0.3026835560302278, 0.48955072330571814, 0.2937978096886439, 0.3731994596718933, 0.2514750500743954, 0.2216750279749734, 0.4628102477330396, 0.9981388022497116, 0.2365634954039565, 0.25792585653070277, 0.6995492032941026, 0.5672041623704875, 0.3602492705978477, 0.5047131441865764, 0.2196173327549258, 0.48510692274210043], "operator": "random_new", "theta_sampled": 0.043503451465569797, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "916a63e1-6293-4238-acbe-87bf6b0973a3", "fitness": 0.5952195958398558, "name": "AdaptivePSO_DE", "description": "An adaptive population-based algorithm that combines aspects of Particle Swarm Optimization (PSO) and Differential Evolution (DE), with a novel perturbation strategy to enhance exploration in promising regions.", "code": "import numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, pso_weight=0.7, de_cross_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross_rate = de_cross_rate\n        self.archive_size = int(self.pop_size * 0.5)  # Size of the archive\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        archive = [] # Archive to store promising solutions\n        archive_fitness = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive PSO component\n                inertia = self.pso_weight * (ub - lb) / (1 + (self.budget / 1000)) # Linearly decreasing inertia\n\n                velocity = inertia * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                           inertia * np.random.rand(self.dim) * (gbest_x - pop[i]) \n                \n                # Differential Evolution component, applied with probability\n                if np.random.rand() < 0.7:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = pop[idxs]\n\n                    # Perturbation using archive and best solution with probability 0.3\n                    if np.random.rand() < 0.3 and len(archive) > 0:\n                        arch_idx = np.random.randint(0, len(archive))\n                        mutant = pop[i] + 0.5 * (archive[arch_idx] - pop[i]) + 0.5*(gbest_x - pop[i])\n                    else:\n                        mutant = x_1 + 0.5 * (x_2 - x_3) # Simplified DE\n                   \n                    cross = np.random.rand(self.dim) < self.de_cross_rate\n                    trial = np.where(cross, mutant, pop[i])\n                    \n                    trial = np.clip(trial, lb, ub)\n\n                    f = func(trial)\n                    self.budget -= 1\n                    \n                    if f < fitness[i]:\n                        pop[i] = trial.copy()\n                        fitness[i] = f\n\n                        if f < pbest_fitness[i]:\n                            pbest_pop[i] = trial.copy()\n                            pbest_fitness[i] = f\n\n                            if f < gbest_fitness:\n                                gbest_x = trial.copy()\n                                gbest_fitness = f\n\n                else:\n                    # Small random perturbation\n                    scale = (ub - lb) / 100  # Keep perturbation relatively small.\n                    perturbation = np.random.uniform(-scale, scale, self.dim)\n                    new_x = np.clip(pop[i] + perturbation, lb, ub)\n\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < fitness[i]:\n                        pop[i] = new_x.copy()\n                        fitness[i] = f\n                        if f < pbest_fitness[i]:\n                            pbest_pop[i] = new_x.copy()\n                            pbest_fitness[i] = f\n                            if f < gbest_fitness:\n                                gbest_x = new_x.copy()\n                                gbest_fitness = f\n\n\n            # Archive maintenance - store diverse and promising solutions\n            for i in range(self.pop_size):\n                if fitness[i] < np.max(archive_fitness) if len(archive_fitness) > 0 else True:\n                    if len(archive) < self.archive_size:\n                        archive.append(pop[i].copy())\n                        archive_fitness.append(fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(archive_fitness)\n                        archive[worst_arch_idx] = pop[i].copy()\n                        archive_fitness[worst_arch_idx] = fitness[i]\n            \n        return gbest_fitness, gbest_x", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptivePSO_DE scored 0.595 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines aspects of Particle Swarm Optimization (PSO) and Differential Evolution (DE), with a novel perturbation strategy to enhance exploration in promising regions.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=40, pso_weight=0.7, de_cross_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross_rate = de_cross_rate\n        self.archive_size = int(self.pop_size * 0.5)  # Size of the archive\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n        gbest_index = np.argmin(fitness)\n        gbest_x = pop[gbest_index].copy()\n        gbest_fitness = fitness[gbest_index]\n        \n        archive = [] # Archive to store promising solutions\n        archive_fitness = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive PSO component\n                inertia = self.pso_weight * (ub - lb) / (1 + (self.budget / 1000)) # Linearly decreasing inertia\n\n                velocity = inertia * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                           inertia * np.random.rand(self.dim) * (gbest_x - pop[i]) \n                \n                # Differential Evolution component, applied with probability\n                if np.random.rand() < 0.7:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_1, x_2, x_3 = pop[idxs]\n\n                    # Perturbation using archive and best solution with probability 0.3\n                    if np.random.rand() < 0.3 and len(archive) > 0:\n                        arch_idx = np.random.randint(0, len(archive))\n                        mutant = pop[i] + 0.5 * (archive[arch_idx] - pop[i]) + 0.5*(gbest_x - pop[i])\n                    else:\n                        mutant = x_1 + 0.5 * (x_2 - x_3) # Simplified DE\n                   \n                    cross = np.random.rand(self.dim) < self.de_cross_rate\n                    trial = np.where(cross, mutant, pop[i])\n                    \n                    trial = np.clip(trial, lb, ub)\n\n                    f = func(trial)\n                    self.budget -= 1\n                    \n                    if f < fitness[i]:\n                        pop[i] = trial.copy()\n                        fitness[i] = f\n\n                        if f < pbest_fitness[i]:\n                            pbest_pop[i] = trial.copy()\n                            pbest_fitness[i] = f\n\n                            if f < gbest_fitness:\n                                gbest_x = trial.copy()\n                                gbest_fitness = f\n\n                else:\n                    # Small random perturbation\n                    scale = (ub - lb) / 100  # Keep perturbation relatively small.\n                    perturbation = np.random.uniform(-scale, scale, self.dim)\n                    new_x = np.clip(pop[i] + perturbation, lb, ub)\n\n                    f = func(new_x)\n                    self.budget -= 1\n                    if f < fitness[i]:\n                        pop[i] = new_x.copy()\n                        fitness[i] = f\n                        if f < pbest_fitness[i]:\n                            pbest_pop[i] = new_x.copy()\n                            pbest_fitness[i] = f\n                            if f < gbest_fitness:\n                                gbest_x = new_x.copy()\n                                gbest_fitness = f\n\n\n            # Archive maintenance - store diverse and promising solutions\n            for i in range(self.pop_size):\n                if fitness[i] < np.max(archive_fitness) if len(archive_fitness) > 0 else True:\n                    if len(archive) < self.archive_size:\n                        archive.append(pop[i].copy())\n                        archive_fitness.append(fitness[i])\n                    else:\n                        worst_arch_idx = np.argmax(archive_fitness)\n                        archive[worst_arch_idx] = pop[i].copy()\n                        archive_fitness[worst_arch_idx] = fitness[i]\n            \n        return gbest_fitness, gbest_x\n```", "aucs": [0.20581982737187277, 0.31177844513722464, 0.6189652675065264, 0.8708305372784336, 0.7280297402937519, 0.791684822993041, 0.5640901036919596, 0.5645081702426042, 0.6423314157616149, 0.18770552832286325, 0.8758236771193011, 0.9994860120957875, 0.2994247421537487, 0.5474309429679342, 0.8634926055198936, 0.8389035338159023, 0.4023737146502473, 0.8484658009191539, 0.24444707853880698, 0.4987999504164474], "operator": "random_new", "theta_sampled": 0.124328512288137, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "cd5029d0-fdfd-486c-a766-4b84d95d48da", "fitness": 0.2683084060002671, "name": "HybridPSO_DESA_Restart", "description": "A hybrid algorithm combining PSO, self-adaptive DE, and a restarting mechanism with an aging archive for diversity.", "code": "import numpy as np\n\nclass HybridPSO_DESA_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, \n                 local_search_iterations=5, restart_trigger=0.1, archive_size=100, aging_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger # Probability of restart\n        self.archive_size = archive_size\n        self.archive_x = []\n        self.archive_f = []\n        self.aging_rate = aging_rate\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.stagnation_counter = 0\n        self.max_stagnation = 100\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n        \n        best_f_history = [gbest_f] # Track best fitness to detect stagnation\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                        self.stagnation_counter = 0 # Reset counter if improvement\n                    \n                    \n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n                    self.stagnation_counter = 0 # Reset counter on local search improvement\n\n            # Archive management: Add gbest to archive\n            if len(self.archive_x) < self.archive_size:\n                self.archive_x.append(gbest_x.copy())\n                self.archive_f.append(gbest_f)\n            else:\n                # Replace worst element in archive\n                worst_index = np.argmax(self.archive_f)\n                if gbest_f < self.archive_f[worst_index]:\n                    self.archive_x[worst_index] = gbest_x.copy()\n                    self.archive_f[worst_index] = gbest_f\n            \n            # Aging mechanism: Increase archive diversity\n            for j in range(len(self.archive_f)):\n                self.archive_f[j] *= self.aging_rate\n\n            # Stagnation check and restart\n            self.stagnation_counter += 1\n            if self.stagnation_counter > self.max_stagnation or np.random.rand() < self.restart_trigger:\n                # Restart: Re-initialize population using archive\n                if len(self.archive_x) > 0:\n                    # Sample from archive with probability proportional to fitness\n                    probs = np.exp(-np.array(self.archive_f) / np.std(self.archive_f))\n                    probs /= np.sum(probs)\n\n                    indices = np.random.choice(len(self.archive_x), size=self.pop_size, replace=True, p=probs)\n                    pop = np.array([self.archive_x[i] for i in indices])\n                else:\n                    # If the archive is empty, just re-initialize randomly\n                    pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                \n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                if self.budget <= 0:\n                   break\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DESA_Restart scored 0.268 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining PSO, self-adaptive DE, and a restarting mechanism with an aging archive for diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSO_DESA_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, \n                 local_search_iterations=5, restart_trigger=0.1, archive_size=100, aging_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.restart_trigger = restart_trigger # Probability of restart\n        self.archive_size = archive_size\n        self.archive_x = []\n        self.archive_f = []\n        self.aging_rate = aging_rate\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.stagnation_counter = 0\n        self.max_stagnation = 100\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n        \n        best_f_history = [gbest_f] # Track best fitness to detect stagnation\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                        self.stagnation_counter = 0 # Reset counter if improvement\n                    \n                    \n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim) # Small perturbation\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n                    self.stagnation_counter = 0 # Reset counter on local search improvement\n\n            # Archive management: Add gbest to archive\n            if len(self.archive_x) < self.archive_size:\n                self.archive_x.append(gbest_x.copy())\n                self.archive_f.append(gbest_f)\n            else:\n                # Replace worst element in archive\n                worst_index = np.argmax(self.archive_f)\n                if gbest_f < self.archive_f[worst_index]:\n                    self.archive_x[worst_index] = gbest_x.copy()\n                    self.archive_f[worst_index] = gbest_f\n            \n            # Aging mechanism: Increase archive diversity\n            for j in range(len(self.archive_f)):\n                self.archive_f[j] *= self.aging_rate\n\n            # Stagnation check and restart\n            self.stagnation_counter += 1\n            if self.stagnation_counter > self.max_stagnation or np.random.rand() < self.restart_trigger:\n                # Restart: Re-initialize population using archive\n                if len(self.archive_x) > 0:\n                    # Sample from archive with probability proportional to fitness\n                    probs = np.exp(-np.array(self.archive_f) / np.std(self.archive_f))\n                    probs /= np.sum(probs)\n\n                    indices = np.random.choice(len(self.archive_x), size=self.pop_size, replace=True, p=probs)\n                    pop = np.array([self.archive_x[i] for i in indices])\n                else:\n                    # If the archive is empty, just re-initialize randomly\n                    pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                \n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                if self.budget <= 0:\n                   break\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16198929504725368, 0.1808050550869309, 0.7304392738668839, 0], "operator": "crossover", "theta_sampled": 0.07961207253771865, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "01317def-b817-4e78-89ce-b35b21842ca8", "fitness": 0.0, "name": "RankBasedDifferentialEvolution", "description": "A population-based algorithm with self-adaptation of mutation strength and crossover probability based on the rank of solutions in the population, incorporating a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass RankBasedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, restart_patience=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial crossover rate\n        self.restart_patience = restart_patience # Number of iterations before restart\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size # Initial evaluations\n\n        self.best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_index]\n        self.x_opt = self.population[self.best_index]\n        self.last_improvement = 0\n\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n\n                # Rank-based adaptation of F and CR\n                ranked_indices = np.argsort(self.fitness)\n                rank = np.where(ranked_indices == i)[0][0]\n                \n                # Adapt F and CR based on rank\n                F = self.F * (1 + 0.1 * (rank / self.pop_size - 0.5))\n                CR = self.CR * (1 + 0.1 * (0.5 - rank / self.pop_size))\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_1, x_2, x_3 = self.population[indices]\n                x_mutated = self.population[i] + F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.evals += 1\n                \n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.last_improvement = self.evals\n\n            # Restart mechanism based on stagnation\n            if self.evals - self.last_improvement > self.restart_patience:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_index]\n                self.x_opt = self.population[self.best_index]\n                self.last_improvement = self.evals\n                print(\"Restarting population\")\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm RankBasedDifferentialEvolution scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with self-adaptation of mutation strength and crossover probability based on the rank of solutions in the population, incorporating a restart mechanism based on stagnation detection.\n# Code:\n```python\nimport numpy as np\n\nclass RankBasedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, restart_patience=2000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial crossover rate\n        self.restart_patience = restart_patience # Number of iterations before restart\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size # Initial evaluations\n\n        self.best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[self.best_index]\n        self.x_opt = self.population[self.best_index]\n        self.last_improvement = 0\n\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                if self.evals >= self.budget:\n                    break\n\n                # Rank-based adaptation of F and CR\n                ranked_indices = np.argsort(self.fitness)\n                rank = np.where(ranked_indices == i)[0][0]\n                \n                # Adapt F and CR based on rank\n                F = self.F * (1 + 0.1 * (rank / self.pop_size - 0.5))\n                CR = self.CR * (1 + 0.1 * (0.5 - rank / self.pop_size))\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n\n                x_1, x_2, x_3 = self.population[indices]\n                x_mutated = self.population[i] + F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Evaluation\n                f_trial = func(x_trial)\n                self.evals += 1\n                \n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = x_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.last_improvement = self.evals\n\n            # Restart mechanism based on stagnation\n            if self.evals - self.last_improvement > self.restart_patience:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.best_index = np.argmin(self.fitness)\n                self.f_opt = self.fitness[self.best_index]\n                self.x_opt = self.population[self.best_index]\n                self.last_improvement = self.evals\n                print(\"Restarting population\")\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.045544439441039225, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "a993ef29-a80a-4ee7-b024-3a0cf40266b4", "fitness": 0.6612820756901162, "name": "AdaptiveHybridPSO_DE", "description": "Hybrid PSO-DE with adaptive parameter control and a velocity clamping mechanism to prevent premature convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.661 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid PSO-DE with adaptive parameter control and a velocity clamping mechanism to prevent premature convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.24565225660246137, 0.7475519041993464, 0.83856026202044, 0.9118676409027681, 0.8601091656559807, 0.9000335826353199, 0.7782537998820335, 0.7295300417228813, 0.3777007391130497, 0.21650851477437094, 0.8719974690360649, 0.9919616000125014, 0.34845228650795346, 0.5359720189744464, 0.9200862150365843, 0.8861192485351491, 0.37714661304803165, 0.911164327720502, 0.2621487858118108, 0.5148250416106304], "operator": "mutation", "theta_sampled": 0.013221701064092595, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "baf9f87e-6e6b-48d1-aa96-95641794d974", "fitness": 0.5507153292203696, "name": "AdaptiveHybridPSO_DE", "description": "Combines PSO and DE with self-adaptive parameters, a focused local search, and dynamic population diversity control for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.local_search_iterations = local_search_iterations\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.archive = [] # Archive for successful DE mutations\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n\n                # Adaptive DE update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                # Incorporate archive information\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # Use archive occasionally\n                    arch_idx = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[arch_idx])\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Combined update using adaptive probability\n                pso_prob = 0.5 # Start with equal probability, but it can be adjusted during the iterations\n                if np.random.rand() < pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Evaluate new solution\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal and global best\n                if new_f < pbest_fitness[i]:\n                    #If pbest is updated, add the solution to the archive\n                    self.archive.append(pbest_pop[i].copy())\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n            \n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n                    \n            # Diversity check and population reset\n            if self.population_diversity(pop) < self.diversity_threshold:\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim)) #reset population\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                if self.budget <=0:\n                  break\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population based on the mean pairwise distance.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(pop[i] - pop[j]))\n        \n        if len(distances) > 0:\n            return np.mean(distances)\n        else:\n            return 0", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.551 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines PSO and DE with self-adaptive parameters, a focused local search, and dynamic population diversity control for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.local_search_iterations = local_search_iterations\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.archive = [] # Archive for successful DE mutations\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n\n                # Adaptive DE update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                # Incorporate archive information\n                if len(self.archive) > 0 and np.random.rand() < 0.1:  # Use archive occasionally\n                    arch_idx = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[arch_idx])\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Combined update using adaptive probability\n                pso_prob = 0.5 # Start with equal probability, but it can be adjusted during the iterations\n                if np.random.rand() < pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Evaluate new solution\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal and global best\n                if new_f < pbest_fitness[i]:\n                    #If pbest is updated, add the solution to the archive\n                    self.archive.append(pbest_pop[i].copy())\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Self-adaptation of F and CR\n            self.f = np.random.normal(0.5, 0.1)\n            self.cr = np.random.normal(0.7, 0.1)\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n            \n            # Local search around the best solution\n            for _ in range(self.local_search_iterations):\n                if self.budget <= 0:\n                    break\n                perturbation = np.random.normal(0, 0.01, size=self.dim)\n                local_point = np.clip(gbest_x + perturbation, lb, ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < gbest_f:\n                    gbest_f = f_local\n                    gbest_x = local_point.copy()\n                    \n            # Diversity check and population reset\n            if self.population_diversity(pop) < self.diversity_threshold:\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim)) #reset population\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                if self.budget <=0:\n                  break\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n\n    def population_diversity(self, pop):\n        \"\"\"Calculates the diversity of the population based on the mean pairwise distance.\"\"\"\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(pop[i] - pop[j]))\n        \n        if len(distances) > 0:\n            return np.mean(distances)\n        else:\n            return 0\n```", "aucs": [0.1808186919299798, 0.4566328283176859, 0.5592452314897587, 0.9441608072021369, 0.547872864035332, 0.6789690038481672, 0.4536307237911974, 0.4840187952719991, 0.5788810196258114, 0.2533357769112684, 0.8955985911551863, 0.9969308362531579, 0.3567279708765173, 0.4876786110075967, 0.9369435158101185, 0], "operator": "crossover", "theta_sampled": 0.3830205014524122, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "06e9be93-1fb2-4ce8-b0ab-8027f298f3ec", "fitness": 0.6444726185004455, "name": "EnhancedHybridPSO_DESA_v2", "description": "Combines Hybrid PSO-DE with self-adaptive DE parameters and a more aggressive local search strategy around the global best, enhancing exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DESA_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ls_prob = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Initial Crossover rate for DE\n        self.f = f    # Initial Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ls_prob = ls_prob # probability of performing local search\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.archive = []  # Archive for storing discarded solutions for DE\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update with archive\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                # Select a solution from the archive with a probability\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    ra = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[ra])  # Use archive\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    # Add the discarded solution to the archive\n                    self.archive.append(pop[i].copy())\n                    if len(self.archive) > self.pop_size:\n                        self.archive.pop(0)  # Keep archive size limited\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR (using a better update rule)\n            self.f = 0.5 + 0.3 * np.random.randn()\n            self.cr = 0.7 + 0.2 * np.random.randn()\n\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            if np.random.rand() < self.ls_prob:\n                for _ in range(self.local_search_iterations):\n                    if self.budget <= 0:\n                        break\n                    # More aggressive perturbation\n                    perturbation = np.random.normal(0, 0.1, size=self.dim)\n                    local_point = np.clip(gbest_x + perturbation, lb, ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < gbest_f:\n                        gbest_f = f_local\n                        gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSO_DESA_v2 scored 0.644 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "4a3933da-4cb4-4f1c-a7cd-8f0a89323bac"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Hybrid PSO-DE with self-adaptive DE parameters and a more aggressive local search strategy around the global best, enhancing exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSO_DESA_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, local_search_iterations=5, ls_prob = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Initial Crossover rate for DE\n        self.f = f    # Initial Mutation factor for DE\n        self.local_search_iterations = local_search_iterations\n        self.ls_prob = ls_prob # probability of performing local search\n        self.F_adaptive = 0.5\n        self.CR_adaptive = 0.7\n        self.archive = []  # Archive for storing discarded solutions for DE\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update with archive\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                # Select a solution from the archive with a probability\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    ra = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[ra])  # Use archive\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    # Add the discarded solution to the archive\n                    self.archive.append(pop[i].copy())\n                    if len(self.archive) > self.pop_size:\n                        self.archive.pop(0)  # Keep archive size limited\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n            \n            # Self-adaptation of F and CR (using a better update rule)\n            self.f = 0.5 + 0.3 * np.random.randn()\n            self.cr = 0.7 + 0.2 * np.random.randn()\n\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search around the best solution\n            if np.random.rand() < self.ls_prob:\n                for _ in range(self.local_search_iterations):\n                    if self.budget <= 0:\n                        break\n                    # More aggressive perturbation\n                    perturbation = np.random.normal(0, 0.1, size=self.dim)\n                    local_point = np.clip(gbest_x + perturbation, lb, ub)\n                    f_local = func(local_point)\n                    self.budget -= 1\n\n                    if f_local < gbest_f:\n                        gbest_f = f_local\n                        gbest_x = local_point.copy()\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2482745432231923, 0.8151433743732361, 0.8701549158249386, 0.9452451084359854, 0.34253065043762276, 0.9098615700227973, 0.33164178959520185, 0.44902193572841875, 0.9009122944037562, 0.22789448872107554, 0.935275103489677, 0.9975992415844365, 0.35961427465249296, 0.8856857932621331, 0.9240486837265648, 0.8110598985970962, 0.32969438508056115, 0.918578625653055, 0.1839578849224549, 0.5032578082742127], "operator": "crossover", "theta_sampled": 0.012446170109520715, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "580f0144-7ac6-4fa9-a65e-efa25e1eb9d1", "fitness": 0.0, "name": "AdaptiveDE_Orthogonal_Restart", "description": "An adaptive differential evolution strategy with orthogonal learning and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveDE_Orthogonal_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9, orthogonal_trials=5, restart_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.orthogonal_trials = orthogonal_trials\n        self.restart_patience = restart_patience # Evaluations before restart if no improvement\n        self.best_f_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Find initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n        self.best_f_history.append(self.f_opt)\n\n        evals_since_last_improvement = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                # Adaptive F and CR\n                F = self.F * (1 + 0.1 * np.random.randn()) # adding some noise\n                F = np.clip(F, 0.1, 1.0)\n                CR = self.CR * (1 + 0.1 * np.random.randn())\n                CR = np.clip(CR, 0.1, 1.0)\n\n                v = x_r1 + F * (x_r2 - x_r3)\n                \n                u = np.copy(pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)  # Clip to bounds\n\n                # Orthogonal Learning\n                x_orth = self.orthogonal_learning(func, u, lb, ub)\n                f_orth = func(x_orth)\n                self.budget -= 1\n                \n                f_trial = func(u)\n                self.budget -= 1\n\n                # Selection\n                if min(f_trial, f_orth) < fitness[i]:\n                    if f_trial < f_orth:\n                        pop[i] = u\n                        fitness[i] = f_trial\n                    else:\n                        pop[i] = x_orth\n                        fitness[i] = f_orth\n\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n                        evals_since_last_improvement = 0\n                        self.best_f_history.append(self.f_opt)\n                else:\n                    evals_since_last_improvement += 1\n\n            # Restart Mechanism\n            if evals_since_last_improvement > self.restart_patience:\n                pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = pop[best_idx]\n                    self.best_f_history.append(self.f_opt)\n                evals_since_last_improvement = 0 # reset patience\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_learning(self, func, x, lb, ub):\n        # Generate orthogonal array (simplified)\n        levels = 2\n        factors = self.dim\n        oa = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) # hardcoded orthogonal array for levels=2, runs=4\n        \n        # Generate trial points\n        trials = np.zeros((len(oa), factors))\n        for i in range(len(oa)):\n            for j in range(factors):\n                if oa[i, j % levels] == 0:\n                    trials[i, j] = x[j] - 0.05 * (ub[j] - lb[j])  #perturbation\n                else:\n                    trials[i, j] = x[j] + 0.05 * (ub[j] - lb[j])\n\n        trials = np.clip(trials, lb, ub)\n\n        # Evaluate trial points\n        fitness = np.array([func(trials[i]) for i in range(len(oa))])\n        self.budget -= len(oa)\n\n        # Select the best point\n        best_idx = np.argmin(fitness)\n        return trials[best_idx]", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDE_Orthogonal_Restart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution strategy with orthogonal learning and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_Orthogonal_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9, orthogonal_trials=5, restart_patience=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.orthogonal_trials = orthogonal_trials\n        self.restart_patience = restart_patience # Evaluations before restart if no improvement\n        self.best_f_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        # Find initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n        self.best_f_history.append(self.f_opt)\n\n        evals_since_last_improvement = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                # Adaptive F and CR\n                F = self.F * (1 + 0.1 * np.random.randn()) # adding some noise\n                F = np.clip(F, 0.1, 1.0)\n                CR = self.CR * (1 + 0.1 * np.random.randn())\n                CR = np.clip(CR, 0.1, 1.0)\n\n                v = x_r1 + F * (x_r2 - x_r3)\n                \n                u = np.copy(pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        u[j] = v[j]\n\n                u = np.clip(u, lb, ub)  # Clip to bounds\n\n                # Orthogonal Learning\n                x_orth = self.orthogonal_learning(func, u, lb, ub)\n                f_orth = func(x_orth)\n                self.budget -= 1\n                \n                f_trial = func(u)\n                self.budget -= 1\n\n                # Selection\n                if min(f_trial, f_orth) < fitness[i]:\n                    if f_trial < f_orth:\n                        pop[i] = u\n                        fitness[i] = f_trial\n                    else:\n                        pop[i] = x_orth\n                        fitness[i] = f_orth\n\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n                        evals_since_last_improvement = 0\n                        self.best_f_history.append(self.f_opt)\n                else:\n                    evals_since_last_improvement += 1\n\n            # Restart Mechanism\n            if evals_since_last_improvement > self.restart_patience:\n                pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = pop[best_idx]\n                    self.best_f_history.append(self.f_opt)\n                evals_since_last_improvement = 0 # reset patience\n\n        return self.f_opt, self.x_opt\n\n    def orthogonal_learning(self, func, x, lb, ub):\n        # Generate orthogonal array (simplified)\n        levels = 2\n        factors = self.dim\n        oa = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) # hardcoded orthogonal array for levels=2, runs=4\n        \n        # Generate trial points\n        trials = np.zeros((len(oa), factors))\n        for i in range(len(oa)):\n            for j in range(factors):\n                if oa[i, j % levels] == 0:\n                    trials[i, j] = x[j] - 0.05 * (ub[j] - lb[j])  #perturbation\n                else:\n                    trials[i, j] = x[j] + 0.05 * (ub[j] - lb[j])\n\n        trials = np.clip(trials, lb, ub)\n\n        # Evaluate trial points\n        fitness = np.array([func(trials[i]) for i in range(len(oa))])\n        self.budget -= len(oa)\n\n        # Select the best point\n        best_idx = np.argmin(fitness)\n        return trials[best_idx]\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.09875693374826328, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "85b0dc87-83e8-4b89-b58a-7a15fb452c8f", "fitness": 0.4971538023265178, "name": "SHADEPSO", "description": "Hybridizes PSO and DE with a self-adaptive strategy for choosing between the two, and incorporates a local search to refine solutions.", "code": "import numpy as np\n\nclass SHADEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0, cr=0.5, f=0.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_final = w_final # Final inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_prob = local_search_prob #Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Memory for successful F and CR values (for SHADE adaptation)\n        memory_f = np.ones(self.pop_size) * self.f\n        memory_cr = np.ones(self.pop_size) * self.cr\n\n        archive = [] #Archive for storing inferior solutions\n\n        def local_search(x, f):\n          \"\"\"Performs local search around a solution.\"\"\"\n          step_size = 0.01 * (ub - lb)\n          new_x = x + np.random.uniform(-step_size, step_size, self.dim)\n          new_x = np.clip(new_x, lb, ub)\n          new_f = func(new_x)\n          if self.budget > 0:\n            self.budget -= 1\n            if new_f < f:\n              return new_x, new_f\n            else:\n              return x, f\n          else:\n            return x, f\n\n\n\n        # Optimization loop\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Update inertia weight (linear decreasing)\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget / self.pop_size + generation))\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                f_i = np.random.choice(memory_f)\n                cr_i = np.random.choice(memory_cr)\n\n\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                r1, r2 = np.random.choice(indices, 2, replace=False)\n\n                donor_vector = pbest_pop[r1] + f_i * (gbest_x - pbest_pop[r2])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        new_x_de[j] = donor_vector[j]\n\n                # Clip to bounds\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Evaluate both PSO and DE candidates\n                f_pso = func(new_x_pso)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                f_de = func(new_x_de)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n\n                # Select between PSO and DE based on which is better\n                if f_pso < f_de:\n                  new_x = new_x_pso\n                  new_f = f_pso\n                else:\n                  new_x = new_x_de\n                  new_f = f_de\n                  successful_cr.append(cr_i)\n                  successful_f.append(f_i)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                  new_x, new_f = local_search(new_x, new_f)\n                 \n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    if pbest_fitness[i] < gbest_f:\n                      archive.append(pbest_pop[i])\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if successful_cr:\n              memory_cr = np.concatenate([np.array(successful_cr), memory_cr[:self.pop_size - len(successful_cr)]])\n            if successful_f:\n              memory_f = np.concatenate([np.array(successful_f), memory_f[:self.pop_size - len(successful_f)]])\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm SHADEPSO scored 0.497 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybridizes PSO and DE with a self-adaptive strategy for choosing between the two, and incorporates a local search to refine solutions.\n# Code:\n```python\nimport numpy as np\n\nclass SHADEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0, cr=0.5, f=0.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_final = w_final # Final inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.local_search_prob = local_search_prob #Probability of performing local search\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Memory for successful F and CR values (for SHADE adaptation)\n        memory_f = np.ones(self.pop_size) * self.f\n        memory_cr = np.ones(self.pop_size) * self.cr\n\n        archive = [] #Archive for storing inferior solutions\n\n        def local_search(x, f):\n          \"\"\"Performs local search around a solution.\"\"\"\n          step_size = 0.01 * (ub - lb)\n          new_x = x + np.random.uniform(-step_size, step_size, self.dim)\n          new_x = np.clip(new_x, lb, ub)\n          new_f = func(new_x)\n          if self.budget > 0:\n            self.budget -= 1\n            if new_f < f:\n              return new_x, new_f\n            else:\n              return x, f\n          else:\n            return x, f\n\n\n\n        # Optimization loop\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Update inertia weight (linear decreasing)\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget / self.pop_size + generation))\n            successful_cr = []\n            successful_f = []\n\n            for i in range(self.pop_size):\n                # SHADE parameter adaptation\n                f_i = np.random.choice(memory_f)\n                cr_i = np.random.choice(memory_cr)\n\n\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                r1, r2 = np.random.choice(indices, 2, replace=False)\n\n                donor_vector = pbest_pop[r1] + f_i * (gbest_x - pbest_pop[r2])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr_i or j == j_rand:\n                        new_x_de[j] = donor_vector[j]\n\n                # Clip to bounds\n                new_x_pso = np.clip(new_x_pso, lb, ub)\n                new_x_de = np.clip(new_x_de, lb, ub)\n\n                # Evaluate both PSO and DE candidates\n                f_pso = func(new_x_pso)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                f_de = func(new_x_de)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n\n                # Select between PSO and DE based on which is better\n                if f_pso < f_de:\n                  new_x = new_x_pso\n                  new_f = f_pso\n                else:\n                  new_x = new_x_de\n                  new_f = f_de\n                  successful_cr.append(cr_i)\n                  successful_f.append(f_i)\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                  new_x, new_f = local_search(new_x, new_f)\n                 \n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    if pbest_fitness[i] < gbest_f:\n                      archive.append(pbest_pop[i])\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if successful_cr:\n              memory_cr = np.concatenate([np.array(successful_cr), memory_cr[:self.pop_size - len(successful_cr)]])\n            if successful_f:\n              memory_f = np.concatenate([np.array(successful_f), memory_f[:self.pop_size - len(successful_f)]])\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1899740118721256, 0.26480001020397725, 0.8303561726322737, 0.9453094228212171, 0.3379769829603645, 0.9116600157956667, 0], "operator": "mutation", "theta_sampled": 0.2841750679165073, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "3d9c220a-7a30-4b18-a764-670d49adee39", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with velocity clamping and mutation enhancements, dynamically adjusting PSO/DE balance and mutation strength based on performance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.v_max = v_max_ratio * (func.bounds.ub - func.bounds.lb) # Velocity clamping\n        self.pso_prob = 0.5 # Initial probability of using PSO\n        self.success_rate = 0.5 # Smoothed success rate of PSO\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        success_history = []\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -self.v_max, self.v_max)\n                new_x_pso = pop[i] + v\n\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                # Enhanced Mutation Strategy\n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3]) + 0.01 * np.random.randn(self.dim)  # add noise\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < self.pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    success = True\n                    success_history.append(1)\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    success = False\n                    success_history.append(0)\n                \n                pop[i] = new_x.copy()\n\n            # Adaptive PSO/DE probability\n            if len(success_history) > 20:\n                recent_success_rate = np.mean(success_history[-20:])\n                self.success_rate = 0.9 * self.success_rate + 0.1 * recent_success_rate  # Smooth success rate\n\n                # Adjust PSO probability based on success\n                self.pso_prob = np.clip(self.success_rate, 0.1, 0.9)  # Keep within reasonable bounds\n\n                # Adapt mutation factor\n                self.f = 0.5 + 0.5 * (1 - self.success_rate)\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with velocity clamping and mutation enhancements, dynamically adjusting PSO/DE balance and mutation strength based on performance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.v_max = v_max_ratio * (func.bounds.ub - func.bounds.lb) # Velocity clamping\n        self.pso_prob = 0.5 # Initial probability of using PSO\n        self.success_rate = 0.5 # Smoothed success rate of PSO\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        success_history = []\n\n        # Optimization loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -self.v_max, self.v_max)\n                new_x_pso = pop[i] + v\n\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                # Enhanced Mutation Strategy\n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3]) + 0.01 * np.random.randn(self.dim)  # add noise\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < self.pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    success = True\n                    success_history.append(1)\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    success = False\n                    success_history.append(0)\n                \n                pop[i] = new_x.copy()\n\n            # Adaptive PSO/DE probability\n            if len(success_history) > 20:\n                recent_success_rate = np.mean(success_history[-20:])\n                self.success_rate = 0.9 * self.success_rate + 0.1 * recent_success_rate  # Smooth success rate\n\n                # Adjust PSO probability based on success\n                self.pso_prob = np.clip(self.success_rate, 0.1, 0.9)  # Keep within reasonable bounds\n\n                # Adapt mutation factor\n                self.f = 0.5 + 0.5 * (1 - self.success_rate)\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.43234622228282626, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "2f46eaed-4741-4db0-b4f9-dbc2bbbc3faf", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Adaptive Hybrid PSO-DE with aging and local search, balancing exploration and exploitation by adjusting PSO/DE probabilities and incorporating a simple local search to refine solutions.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_prob=0.05, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.ls_prob = ls_prob # Probability of local search\n        self.age_limit = age_limit\n        self.ages = np.zeros(pop_size)\n\n    def local_search(self, x, func, lb, ub):\n        # Simple local search around x\n        delta = np.random.uniform(-0.1, 0.1, self.dim)  # Small perturbation\n        new_x = x + delta\n        new_x = np.clip(new_x, lb, ub)\n        new_f = func(new_x)\n        return new_x, new_f\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        pso_prob = 0.5 # Initial probability for PSO\n        de_prob = 0.5  # Initial probability for DE\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                \n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n                \n                #Local Search\n                if np.random.rand() < self.ls_prob:\n                     new_x, new_f_ls = self.local_search(new_x, func, lb, ub)\n                else:\n                  new_f_ls = np.inf # Initialize to prevent using it by mistake\n                  new_f_ls = func(new_x)\n\n                \n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n                    self.ages[i] = 0 # Reset age\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    self.ages[i] += 1\n                \n                # Aging mechanism: replace old particles\n                if self.ages[i] > self.age_limit:\n                    pop[i] = np.random.uniform(lb, ub, self.dim)\n                    fitness[i] = func(pop[i])\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n                    self.ages[i] = 0 # Reset age\n                    self.budget -= 1  # Account for the new function evaluation\n                    if fitness[i] < gbest_f:\n                        gbest_f = fitness[i]\n                        gbest_x = pop[i].copy()\n\n                pop[i] = new_x.copy()\n                # Adapt probabilities\n                if np.random.rand() < 0.1:  # Adjust every now and then\n                    if new_f < pbest_fitness[i]:\n                      pso_prob *= 1.05\n                      de_prob *= 0.95\n                    else:\n                      pso_prob *= 0.95\n                      de_prob *= 1.05\n\n                    pso_prob = np.clip(pso_prob, 0.1, 0.9)\n                    de_prob = np.clip(de_prob, 0.1, 0.9)\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with aging and local search, balancing exploration and exploitation by adjusting PSO/DE probabilities and incorporating a simple local search to refine solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_prob=0.05, age_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight for PSO\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.ls_prob = ls_prob # Probability of local search\n        self.age_limit = age_limit\n        self.ages = np.zeros(pop_size)\n\n    def local_search(self, x, func, lb, ub):\n        # Simple local search around x\n        delta = np.random.uniform(-0.1, 0.1, self.dim)  # Small perturbation\n        new_x = x + delta\n        new_x = np.clip(new_x, lb, ub)\n        new_f = func(new_x)\n        return new_x, new_f\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Optimization loop\n        pso_prob = 0.5 # Initial probability for PSO\n        de_prob = 0.5  # Initial probability for DE\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < pso_prob:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n                \n\n                # Clip to bounds\n                new_x = np.clip(new_x, lb, ub)\n                \n                #Local Search\n                if np.random.rand() < self.ls_prob:\n                     new_x, new_f_ls = self.local_search(new_x, func, lb, ub)\n                else:\n                  new_f_ls = np.inf # Initialize to prevent using it by mistake\n                  new_f_ls = func(new_x)\n\n                \n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n                    self.ages[i] = 0 # Reset age\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    self.ages[i] += 1\n                \n                # Aging mechanism: replace old particles\n                if self.ages[i] > self.age_limit:\n                    pop[i] = np.random.uniform(lb, ub, self.dim)\n                    fitness[i] = func(pop[i])\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i]\n                    self.ages[i] = 0 # Reset age\n                    self.budget -= 1  # Account for the new function evaluation\n                    if fitness[i] < gbest_f:\n                        gbest_f = fitness[i]\n                        gbest_x = pop[i].copy()\n\n                pop[i] = new_x.copy()\n                # Adapt probabilities\n                if np.random.rand() < 0.1:  # Adjust every now and then\n                    if new_f < pbest_fitness[i]:\n                      pso_prob *= 1.05\n                      de_prob *= 0.95\n                    else:\n                      pso_prob *= 0.95\n                      de_prob *= 1.05\n\n                    pso_prob = np.clip(pso_prob, 0.1, 0.9)\n                    de_prob = np.clip(de_prob, 0.1, 0.9)\n\n            if self.budget <= 0:\n                break\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.3309422263201868, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "b138b469-88fa-41d7-afbc-ae3ebf5726db", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMAES", "description": "An adaptive hybrid PSO-DE algorithm with a CMA-ES based local search to balance exploration and exploitation, featuring dynamic parameter adaptation and archive management.", "code": "import numpy as np\nimport cma\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_iterations=5, ls_prob=0.1, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.ls_iterations = ls_iterations\n        self.ls_prob = ls_prob\n        self.archive_size = archive_size\n        self.archive = []\n\n        self.f_adaptive = 0.5\n        self.cr_adaptive = 0.7\n        self.sigma = 0.1  # Initial step size for CMA-ES\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # DE update with archive\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    ra = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[ra])\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Adaptive choice between PSO and DE\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n                if new_f < pbest_fitness[i]:\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(pop[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = pop[i].copy()\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Adaptive F and CR using a simplified approach\n            self.f = 0.5 + 0.3 * np.random.randn()\n            self.cr = 0.7 + 0.2 * np.random.randn()\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search with CMA-ES\n            if np.random.rand() < self.ls_prob:\n                es = cma.purecma.PureCMAES(gbest_x, self.sigma, bounds=[lb, ub], incpopsize=2)\n                \n                for _ in range(self.ls_iterations):\n                    if self.budget <= 0:\n                        break\n                    solutions = []\n                    for _ in range(es.popsize):\n                        x = es.ask()\n                        f = func(x)\n                        solutions.append((x, f))\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n                    \n                    if self.budget <= 0:\n                        break\n\n                    es.tell([s[0] for s in solutions], [s[1] for s in solutions])\n                    es.disp()\n\n                    best_solution = min(solutions, key=lambda s: s[1])\n                    x_local, f_local = best_solution\n                    \n                    if f_local < gbest_f:\n                        gbest_f = f_local\n                        gbest_x = x_local.copy()\n                \n                self.sigma *= 0.9  # Reduce step size over time\n                self.sigma = max(self.sigma, 1e-4)\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: No module named 'cma'", "parent_ids": ["06e9be93-1fb2-4ce8-b0ab-8027f298f3ec"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with a CMA-ES based local search to balance exploration and exploitation, featuring dynamic parameter adaptation and archive management.\n# Code:\n```python\nimport numpy as np\nimport cma\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w=0.7, c1=1.5, c2=1.5, cr=0.7, f=0.8, ls_iterations=5, ls_prob=0.1, archive_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.cr = cr\n        self.f = f\n        self.ls_iterations = ls_iterations\n        self.ls_prob = ls_prob\n        self.archive_size = archive_size\n        self.archive = []\n\n        self.f_adaptive = 0.5\n        self.cr_adaptive = 0.7\n        self.sigma = 0.1  # Initial step size for CMA-ES\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # PSO update\n                v = self.w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n                new_x_pso = pop[i] + v\n\n                # DE update with archive\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                if len(self.archive) > 0 and np.random.rand() < 0.1:\n                    ra = np.random.randint(len(self.archive))\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - self.archive[ra])\n                else:\n                    v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Adaptive choice between PSO and DE\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n                if new_f < pbest_fitness[i]:\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(pop[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = pop[i].copy()\n\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Adaptive F and CR using a simplified approach\n            self.f = 0.5 + 0.3 * np.random.randn()\n            self.cr = 0.7 + 0.2 * np.random.randn()\n            self.f = np.clip(self.f, 0.1, 1.0)\n            self.cr = np.clip(self.cr, 0.1, 1.0)\n\n            # Local search with CMA-ES\n            if np.random.rand() < self.ls_prob:\n                es = cma.purecma.PureCMAES(gbest_x, self.sigma, bounds=[lb, ub], incpopsize=2)\n                \n                for _ in range(self.ls_iterations):\n                    if self.budget <= 0:\n                        break\n                    solutions = []\n                    for _ in range(es.popsize):\n                        x = es.ask()\n                        f = func(x)\n                        solutions.append((x, f))\n                        self.budget -= 1\n                        if self.budget <= 0:\n                            break\n                    \n                    if self.budget <= 0:\n                        break\n\n                    es.tell([s[0] for s in solutions], [s[1] for s in solutions])\n                    es.disp()\n\n                    best_solution = min(solutions, key=lambda s: s[1])\n                    x_local, f_local = best_solution\n                    \n                    if f_local < gbest_f:\n                        gbest_f = f_local\n                        gbest_x = x_local.copy()\n                \n                self.sigma *= 0.9  # Reduce step size over time\n                self.sigma = max(self.sigma, 1e-4)\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": -0.04108644286065912, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "cafcbd41-58b3-43c6-9080-4c4446900f24", "fitness": 0.43188247398558566, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "An adaptive hybrid PSO-DE algorithm with enhanced exploration and exploitation by dynamically adjusting parameters and incorporating a self-adaptive selection of PSO and DE updates based on their recent success.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, pso_de_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.v_max_ratio = v_max_ratio\n        self.pso_de_prob = pso_de_prob  # Initial probability for choosing PSO vs DE\n\n        self.pso_success_rate = 0.5  # Initialize PSO success rate\n        self.de_success_rate = 0.5   # Initialize DE success rate\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            pso_successes = 0\n            de_successes = 0\n\n            for i in range(self.pop_size):\n                # Adaptive PSO/DE selection\n                if np.random.rand() < self.pso_de_prob:\n                    # PSO update\n                    v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                        self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                    # Velocity clamping\n                    v = np.clip(v, -v_max, v_max)\n                    new_x = pop[i] + v\n                    method = \"PSO\"\n                else:\n                    # Differential Evolution update\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                    while r1 == i or r2 == i or r3 == i:\n                        r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                    v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    new_x = pop[i].copy()\n                    for j in range(self.dim):\n                        if np.random.rand() < cr or j == j_rand:\n                            new_x[j] = v_de[j]\n                    method = \"DE\"\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    if method == \"PSO\":\n                        pso_successes += 1\n                    else:\n                        de_successes += 1\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Update PSO/DE selection probability based on success rates\n            self.pso_success_rate = pso_successes / self.pop_size\n            self.de_success_rate = de_successes / self.pop_size\n            self.pso_de_prob = self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9)  # Avoid division by zero\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE scored 0.432 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "a993ef29-a80a-4ee7-b024-3a0cf40266b4"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with enhanced exploration and exploitation by dynamically adjusting parameters and incorporating a self-adaptive selection of PSO and DE updates based on their recent success.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, pso_de_prob=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.cr_init = cr_init\n        self.cr_end = cr_end\n        self.f_init = f_init\n        self.f_end = f_end\n        self.v_max_ratio = v_max_ratio\n        self.pso_de_prob = pso_de_prob  # Initial probability for choosing PSO vs DE\n\n        self.pso_success_rate = 0.5  # Initialize PSO success rate\n        self.de_success_rate = 0.5   # Initialize DE success rate\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            pso_successes = 0\n            de_successes = 0\n\n            for i in range(self.pop_size):\n                # Adaptive PSO/DE selection\n                if np.random.rand() < self.pso_de_prob:\n                    # PSO update\n                    v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                        self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                    # Velocity clamping\n                    v = np.clip(v, -v_max, v_max)\n                    new_x = pop[i] + v\n                    method = \"PSO\"\n                else:\n                    # Differential Evolution update\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                    while r1 == i or r2 == i or r3 == i:\n                        r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n\n                    v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    new_x = pop[i].copy()\n                    for j in range(self.dim):\n                        if np.random.rand() < cr or j == j_rand:\n                            new_x[j] = v_de[j]\n                    method = \"DE\"\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    if method == \"PSO\":\n                        pso_successes += 1\n                    else:\n                        de_successes += 1\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            # Update PSO/DE selection probability based on success rates\n            self.pso_success_rate = pso_successes / self.pop_size\n            self.de_success_rate = de_successes / self.pop_size\n            self.pso_de_prob = self.pso_success_rate / (self.pso_success_rate + self.de_success_rate + 1e-9)  # Avoid division by zero\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14546213571989974, 0.17771096181429225, 0.4533682451665585, 0.2465005156913408, 0.33881508557003204, 0.5393214948979401, 0.27909553975910295, 0.2738065425863567, 0.3474699361421947, 0.19562747861076668, 0.49246236151886935, 0.9990653176892578, 0.2903050584760878, 0.2425430747835332, 0.889122086100683, 0.8525336735736129, 0.3424776776398888, 0.7257929149033033, 0.2985632809600455, 0.507606098107948], "operator": "crossover", "theta_sampled": 0.2304696744904119, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "1024f211-c3fb-421a-bf61-49ead6a93152", "fitness": 0.6727478311111961, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with velocity clamping and dynamic probability switching between PSO and DE updates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, p_pso_init=0.5, p_pso_end=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.p_pso_init = p_pso_init # Initial probability of using PSO\n        self.p_pso_end = p_pso_end  # Final probability of using PSO\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            p_pso = self.p_pso_init - (self.p_pso_init - self.p_pso_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on dynamic probability\n                if np.random.rand() < p_pso:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE scored 0.673 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "a993ef29-a80a-4ee7-b024-3a0cf40266b4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with velocity clamping and dynamic probability switching between PSO and DE updates.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, p_pso_init=0.5, p_pso_end=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.p_pso_init = p_pso_init # Initial probability of using PSO\n        self.p_pso_end = p_pso_end  # Final probability of using PSO\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            p_pso = self.p_pso_init - (self.p_pso_init - self.p_pso_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on dynamic probability\n                if np.random.rand() < p_pso:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23167435715659745, 0.6443050068674961, 0.8149187273516862, 0.9244429731987358, 0.8071870165761108, 0.8801381025595632, 0.33983404022692076, 0.8130490187159154, 0.8756711065854134, 0.2276963831286154, 0.8625626747242712, 0.9928607291923308, 0.3331246840469422, 0.7852274397931438, 0.9294317124402389, 0.8835287067595254, 0.4107747258307348, 0.918478600425487, 0.2592934808016637, 0.5207571358425291], "operator": "crossover", "theta_sampled": 0.10458089805712839, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "7cd7c5e7-ac19-4a85-a310-1f34161d4eb9", "fitness": 0.0, "name": "RankCMAES", "description": "Evolutionary algorithm with covariance matrix adaptation (CMA-ES) inspired mutation and a selection scheme based on fitness ranking and crowding distance.", "code": "import numpy as np\n\nclass RankCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0  # Initial step size\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.D = None  # Diagonal of C\n        self.B = None  # Eigenvectors of C\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.mu = int(self.pop_size / 2) # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def initialize(self):\n        self.mean = np.random.uniform(low=-5.0, high=5.0, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n\n    def __call__(self, func):\n        self.initialize()\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            # 1. Generate samples\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.mean[:, np.newaxis] + self.sigma0 * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate samples\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n\n            # 3. Sort samples\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0].copy()\n\n            # 5. Update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = (xmean - self.mean) / self.sigma0\n\n            # 6. Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs * (2-self.cs) * self.mueff) * (self.B @ y)\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1-(1-self.cs)**(2*evals/self.pop_size))/self.chiN < 1 + 2/(self.dim+1)\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * y\n\n            # 7. Update covariance matrix\n            self.C = (1-self.c1-self.cmu) * self.C \\\n                       + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) \\\n                       + self.cmu * (self.B @ ((self.D**2 * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D**2 * z[:, :self.mu]).T) @ self.B.T)\n\n            # 8. Update step size\n            self.sigma0 *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # 9. Update mean\n            self.mean = xmean\n\n\n            # 10. Eigenvalue decomposition\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(self.D)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Evolutionary algorithm with covariance matrix adaptation (CMA-ES) inspired mutation and a selection scheme based on fitness ranking and crowding distance.\n# Code: \n```python\nimport numpy as np\n\nclass RankCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0  # Initial step size\n        self.mean = None\n        self.C = None  # Covariance matrix\n        self.D = None  # Diagonal of C\n        self.B = None  # Eigenvectors of C\n        self.pc = None # Evolution path for C\n        self.ps = None # Evolution path for sigma\n        self.mu = int(self.pop_size / 2) # Number of parents\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff))\n        self.damps = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def initialize(self):\n        self.mean = np.random.uniform(low=-5.0, high=5.0, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        self.B = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n\n    def __call__(self, func):\n        self.initialize()\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n\n        while evals < self.budget:\n            # 1. Generate samples\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.mean[:, np.newaxis] + self.sigma0 * (self.B @ (self.D[:, np.newaxis] * z))\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # 2. Evaluate samples\n            f = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n\n            # 3. Sort samples\n            idx = np.argsort(f)\n            x = x[:, idx]\n            f = f[idx]\n\n            # 4. Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[:, 0].copy()\n\n            # 5. Update mean\n            xmean = np.sum(x[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n            y = (xmean - self.mean) / self.sigma0\n\n            # 6. Update evolution paths\n            self.ps = (1-self.cs) * self.ps + np.sqrt(self.cs * (2-self.cs) * self.mueff) * (self.B @ y)\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1-(1-self.cs)**(2*evals/self.pop_size))/self.chiN < 1 + 2/(self.dim+1)\n            self.pc = (1-self.cc) * self.pc + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * y\n\n            # 7. Update covariance matrix\n            self.C = (1-self.c1-self.cmu) * self.C \\\n                       + self.c1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) \\\n                       + self.cmu * (self.B @ ((self.D**2 * z[:, :self.mu]) @ np.diag(self.weights) @ (self.D**2 * z[:, :self.mu]).T) @ self.B.T)\n\n            # 8. Update step size\n            self.sigma0 *= np.exp((self.cs/self.damps) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n            # 9. Update mean\n            self.mean = xmean\n\n\n            # 10. Eigenvalue decomposition\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.D, self.B = np.linalg.eigh(self.C)\n            self.D = np.sqrt(self.D)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.2551814601775339, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "1f0770e6-f651-4099-b7be-ddbfcc07b3a7", "fitness": 0.42833388950164675, "name": "AdaptiveHybridPSO_DE_v2", "description": "Adaptively combines PSO and DE with a self-adaptive probability switch based on the performance of each algorithm.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, pso_de_prob_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.pso_de_prob = pso_de_prob_init  # Initial probability of choosing PSO update\n\n        self.pso_success_rate = 0.0\n        self.de_success_rate = 0.0\n        self.success_memory = []\n        self.memory_size = 10  # Keep track of the last 10 updates.\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < self.pso_de_prob:\n                    new_x = new_x_pso\n                    method = \"PSO\"\n                else:\n                    new_x = new_x_de\n                    method = \"DE\"\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                        success = 1\n                    else:\n                        success = 0\n\n\n                    # Update success memory\n                    if method == \"PSO\":\n                        self.success_memory.append((1,0)) # PSO success, DE fail\n                    else:\n                        self.success_memory.append((0,1)) # DE success, PSO fail\n                    if len(self.success_memory) > self.memory_size:\n                        self.success_memory.pop(0)\n\n\n                    #Update probability\n                    pso_successes = sum([x[0] for x in self.success_memory])\n                    de_successes = sum([x[1] for x in self.success_memory])\n                    total_successes = pso_successes + de_successes\n\n                    if total_successes > 0:\n                        self.pso_success_rate = pso_successes / total_successes\n                        self.de_success_rate = de_successes / total_successes\n                        self.pso_de_prob = self.pso_success_rate #Probability of PSO should be related to its success rate\n\n\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_v2 scored 0.428 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "a993ef29-a80a-4ee7-b024-3a0cf40266b4"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with a self-adaptive probability switch based on the performance of each algorithm.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, pso_de_prob_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.pso_de_prob = pso_de_prob_init  # Initial probability of choosing PSO update\n\n        self.pso_success_rate = 0.0\n        self.de_success_rate = 0.0\n        self.success_memory = []\n        self.memory_size = 10  # Keep track of the last 10 updates.\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < self.pso_de_prob:\n                    new_x = new_x_pso\n                    method = \"PSO\"\n                else:\n                    new_x = new_x_de\n                    method = \"DE\"\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                        success = 1\n                    else:\n                        success = 0\n\n\n                    # Update success memory\n                    if method == \"PSO\":\n                        self.success_memory.append((1,0)) # PSO success, DE fail\n                    else:\n                        self.success_memory.append((0,1)) # DE success, PSO fail\n                    if len(self.success_memory) > self.memory_size:\n                        self.success_memory.pop(0)\n\n\n                    #Update probability\n                    pso_successes = sum([x[0] for x in self.success_memory])\n                    de_successes = sum([x[1] for x in self.success_memory])\n                    total_successes = pso_successes + de_successes\n\n                    if total_successes > 0:\n                        self.pso_success_rate = pso_successes / total_successes\n                        self.de_success_rate = de_successes / total_successes\n                        self.pso_de_prob = self.pso_success_rate #Probability of PSO should be related to its success rate\n\n\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17059308859342182, 0.2020509685548204, 0.503933357901136, 0.9709972188091744, 0.2812732991180972, 0.2657453414835734, 0.29663353731116926, 0.28985630933676554, 0.24381199113503793, 0.19417976607832488, 0.2359151156477607, 0.9981365724492729, 0.30074091637882017, 0.22919056962424578, 0.7673948515527806, 0.7325439900308094, 0.2894886293553305, 0.9421252438646914, 0.1966074001252628, 0.45545962268243934], "operator": "crossover", "theta_sampled": -0.09207564669436906, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "ad6819aa-e9ac-409e-9196-573305609e43", "fitness": 0.0, "name": "AdaptiveCoordinateDescentSA", "description": "Adaptive Coordinate Descent with Simulated Annealing, that exploits coordinate descent locally but escapes local optima with simulated annealing.", "code": "import numpy as np\nimport math\n\nclass AdaptiveCoordinateDescentSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, cd_steps = 5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.cd_steps = cd_steps\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n        evals = 0\n        while evals < self.budget:\n            # Coordinate Descent Step\n            for _ in range(self.cd_steps):\n                if evals >= self.budget:\n                    break\n                \n                for i in range(self.dim):\n                    #Perturb each dimension\n                    step_size = (func.bounds.ub - func.bounds.lb) / 100.0 # Adaptive step size\n                    x_new = x.copy()\n\n                    # Try positive perturbation\n                    x_new[i] = min(func.bounds.ub, x[i] + step_size)\n                    f_new = func(x_new)\n                    evals += 1\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n                        x = x_new.copy()\n                        f = f_new\n                        continue # Restart CD loop after improvement\n                        \n                    # Try negative perturbation if positive fails\n                    x_new[i] = max(func.bounds.lb, x[i] - step_size)\n                    f_new = func(x_new)\n                    evals += 1\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n                        x = x_new.copy()\n                        f = f_new\n                        continue # Restart CD loop after improvement\n            \n            #Simulated Annealing Step\n            if evals < self.budget:\n                x_new = x + np.random.normal(0, (func.bounds.ub - func.bounds.lb) / 10.0, size=self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                f_new = func(x_new)\n                evals += 1\n            \n                delta_e = f_new - f\n                if delta_e < 0:\n                    x = x_new.copy()\n                    f = f_new\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x.copy()\n                else:\n                    acceptance_prob = math.exp(-delta_e / temp)\n                    if np.random.rand() < acceptance_prob:\n                        x = x_new.copy()\n                        f = f_new\n            temp *= self.cooling_rate\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Coordinate Descent with Simulated Annealing, that exploits coordinate descent locally but escapes local optima with simulated annealing.\n# Code: \n```python\nimport numpy as np\nimport math\n\nclass AdaptiveCoordinateDescentSA:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.99, cd_steps = 5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.cd_steps = cd_steps\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n        evals = 0\n        while evals < self.budget:\n            # Coordinate Descent Step\n            for _ in range(self.cd_steps):\n                if evals >= self.budget:\n                    break\n                \n                for i in range(self.dim):\n                    #Perturb each dimension\n                    step_size = (func.bounds.ub - func.bounds.lb) / 100.0 # Adaptive step size\n                    x_new = x.copy()\n\n                    # Try positive perturbation\n                    x_new[i] = min(func.bounds.ub, x[i] + step_size)\n                    f_new = func(x_new)\n                    evals += 1\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n                        x = x_new.copy()\n                        f = f_new\n                        continue # Restart CD loop after improvement\n                        \n                    # Try negative perturbation if positive fails\n                    x_new[i] = max(func.bounds.lb, x[i] - step_size)\n                    f_new = func(x_new)\n                    evals += 1\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n                        x = x_new.copy()\n                        f = f_new\n                        continue # Restart CD loop after improvement\n            \n            #Simulated Annealing Step\n            if evals < self.budget:\n                x_new = x + np.random.normal(0, (func.bounds.ub - func.bounds.lb) / 10.0, size=self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                f_new = func(x_new)\n                evals += 1\n            \n                delta_e = f_new - f\n                if delta_e < 0:\n                    x = x_new.copy()\n                    f = f_new\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x.copy()\n                else:\n                    acceptance_prob = math.exp(-delta_e / temp)\n                    if np.random.rand() < acceptance_prob:\n                        x = x_new.copy()\n                        f = f_new\n            temp *= self.cooling_rate\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.25612824075679363, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "dd3b8fcf-b733-48a2-959c-0a9aa421da4a", "fitness": 0.653031307814499, "name": "AdaptiveHybridPSO_DE_v2", "description": "An adaptive hybrid PSO-DE algorithm with self-adaptive parameter control and a diversity maintenance mechanism.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init *= 0.95  # Reduce inertia to explore more\n                self.cr_init *= 0.9  # Reduce crossover rate\n                self.f_init *= 1.1  # Increase mutation factor to explore more\n                self.stagnation_counter = 0 #reset stagnation counter\n            \n            self.previous_gbest_f = gbest_f\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_v2 scored 0.653 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "a993ef29-a80a-4ee7-b024-3a0cf40266b4"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with self-adaptive parameter control and a diversity maintenance mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init *= 0.95  # Reduce inertia to explore more\n                self.cr_init *= 0.9  # Reduce crossover rate\n                self.f_init *= 1.1  # Increase mutation factor to explore more\n                self.stagnation_counter = 0 #reset stagnation counter\n            \n            self.previous_gbest_f = gbest_f\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23845958623774477, 0.32054968319474353, 0.841690168587148, 0.94394336591117, 0.6191657077854513, 0.8859976531924559, 0.36113713842619277, 0.4438863486785386, 0.8546098713381476, 0.8478813352566703, 0.8544367859161374, 0.9951477624536718, 0.36876678450076483, 0.5767929808431809, 0.9327424200051547, 0.8725247593841641, 0.33938418285987815, 0.9129407093042025, 0.3465343330356059, 0.5040345793789607], "operator": "crossover", "theta_sampled": 0.20149097041828254, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "066d8fe7-7878-4097-901b-b80291a8fc41", "fitness": 0.0, "name": "EnhancedAdaptiveHybridPSO_DELocal", "description": "A hybrid PSO-DE algorithm with adaptive parameter control and a novel local search mechanism using a dynamically adjusted neighborhood based on individual success.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DELocal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, p_pso_init=0.5, p_pso_end=0.2, local_search_prob=0.1, neighborhood_size_ratio=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.p_pso_init = p_pso_init # Initial probability of using PSO\n        self.p_pso_end = p_pso_end  # Final probability of using PSO\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.neighborhood_size_ratio = neighborhood_size_ratio  # Ratio of search space range for neighborhood size\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Calculate the initial neighborhood size\n        neighborhood_size = self.neighborhood_size_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        success_rate = np.zeros(self.pop_size)\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            p_pso = self.p_pso_init - (self.p_pso_init - self.p_pso_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on dynamic probability\n                if np.random.rand() < p_pso:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    # Adaptive neighborhood size\n                    current_neighborhood_size = neighborhood_size * (1 + success_rate[i])  # Adjust size based on individual success\n                    \n                    new_x_local = pop[i].copy()\n                    for j in range(self.dim):\n                        # Sample from a neighborhood of the current position\n                        new_x_local[j] = np.random.uniform(max(lb, pop[i][j] - current_neighborhood_size / 2), min(ub, pop[i][j] + current_neighborhood_size / 2))\n                    new_f_local = func(new_x_local)\n\n                    self.budget -=1\n                    if self.budget <= 0:\n                        break\n\n                    if new_f_local < new_f:\n                        new_f = new_f_local\n                        new_x = new_x_local\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    success_rate[i] += 0.1 # Increment success\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    success_rate[i] = max(0, success_rate[i] - 0.05) # Decrease success rate\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018", "1024f211-c3fb-421a-bf61-49ead6a93152"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with adaptive parameter control and a novel local search mechanism using a dynamically adjusted neighborhood based on individual success.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DELocal:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, p_pso_init=0.5, p_pso_end=0.2, local_search_prob=0.1, neighborhood_size_ratio=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.p_pso_init = p_pso_init # Initial probability of using PSO\n        self.p_pso_end = p_pso_end  # Final probability of using PSO\n        self.local_search_prob = local_search_prob # Probability of performing local search\n        self.neighborhood_size_ratio = neighborhood_size_ratio  # Ratio of search space range for neighborhood size\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Calculate the initial neighborhood size\n        neighborhood_size = self.neighborhood_size_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        success_rate = np.zeros(self.pop_size)\n        while self.budget > 0:\n            # Adaptive parameter update\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            p_pso = self.p_pso_init - (self.p_pso_init - self.p_pso_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on dynamic probability\n                if np.random.rand() < p_pso:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    # Adaptive neighborhood size\n                    current_neighborhood_size = neighborhood_size * (1 + success_rate[i])  # Adjust size based on individual success\n                    \n                    new_x_local = pop[i].copy()\n                    for j in range(self.dim):\n                        # Sample from a neighborhood of the current position\n                        new_x_local[j] = np.random.uniform(max(lb, pop[i][j] - current_neighborhood_size / 2), min(ub, pop[i][j] + current_neighborhood_size / 2))\n                    new_f_local = func(new_x_local)\n\n                    self.budget -=1\n                    if self.budget <= 0:\n                        break\n\n                    if new_f_local < new_f:\n                        new_f = new_f_local\n                        new_x = new_x_local\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    success_rate[i] += 0.1 # Increment success\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n                else:\n                    success_rate[i] = max(0, success_rate[i] - 0.05) # Decrease success rate\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.37458380418027715, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "a6f3a703-618a-4ce7-b678-b1d4b2645143", "fitness": 0.21255353086892717, "name": "SelfOrganizingScoutSwarm", "description": "A self-organizing scout swarm algorithm where scouts are attracted to promising regions and repelled from crowded areas to promote exploration and exploitation.", "code": "import numpy as np\n\nclass SelfOrganizingScoutSwarm:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, attraction_radius=0.5, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.attraction_radius = attraction_radius\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        scout_positions = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        scout_fitnesses = np.array([func(x) for x in scout_positions])\n        eval_count = self.num_scouts\n\n        while eval_count < self.budget:\n            for i in range(self.num_scouts):\n                # Attraction to best scout within radius\n                distances = np.linalg.norm(scout_positions - scout_positions[i], axis=1)\n                nearby_scouts = np.where(distances < self.attraction_radius)[0]\n                \n                if len(nearby_scouts) > 1: # Avoid selecting self if only scout in radius\n                    best_nearby_index = nearby_scouts[np.argmin(scout_fitnesses[nearby_scouts])]\n                    attraction_vector = (scout_positions[best_nearby_index] - scout_positions[i])\n                else:\n                    attraction_vector = np.zeros(self.dim) # No attraction if alone\n\n                # Repulsion from other scouts (simplified, constant factor)\n                repulsion_vector = np.zeros(self.dim)\n                for j in range(self.num_scouts):\n                    if i != j:\n                       repulsion_vector += (scout_positions[i] - scout_positions[j]) / (np.linalg.norm(scout_positions[i] - scout_positions[j]) + 1e-8) #avoid div by zero\n                repulsion_vector *= self.repulsion_factor\n\n                # Movement\n                movement_vector = attraction_vector + repulsion_vector + 0.01 * np.random.randn(self.dim) #random pert\n                new_position = scout_positions[i] + movement_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub) # Keep within bounds\n                \n                new_fitness = func(new_position)\n                eval_count += 1\n\n                if new_fitness < scout_fitnesses[i]:\n                    scout_positions[i] = new_position\n                    scout_fitnesses[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            best_index = np.argmin(scout_fitnesses)\n            if scout_fitnesses[best_index] < self.f_opt:\n                self.f_opt = scout_fitnesses[best_index]\n                self.x_opt = scout_positions[best_index]\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SelfOrganizingScoutSwarm scored 0.213 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A self-organizing scout swarm algorithm where scouts are attracted to promising regions and repelled from crowded areas to promote exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass SelfOrganizingScoutSwarm:\n    def __init__(self, budget=10000, dim=10, num_scouts=20, attraction_radius=0.5, repulsion_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_scouts = num_scouts\n        self.attraction_radius = attraction_radius\n        self.repulsion_factor = repulsion_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        scout_positions = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_scouts, self.dim))\n        scout_fitnesses = np.array([func(x) for x in scout_positions])\n        eval_count = self.num_scouts\n\n        while eval_count < self.budget:\n            for i in range(self.num_scouts):\n                # Attraction to best scout within radius\n                distances = np.linalg.norm(scout_positions - scout_positions[i], axis=1)\n                nearby_scouts = np.where(distances < self.attraction_radius)[0]\n                \n                if len(nearby_scouts) > 1: # Avoid selecting self if only scout in radius\n                    best_nearby_index = nearby_scouts[np.argmin(scout_fitnesses[nearby_scouts])]\n                    attraction_vector = (scout_positions[best_nearby_index] - scout_positions[i])\n                else:\n                    attraction_vector = np.zeros(self.dim) # No attraction if alone\n\n                # Repulsion from other scouts (simplified, constant factor)\n                repulsion_vector = np.zeros(self.dim)\n                for j in range(self.num_scouts):\n                    if i != j:\n                       repulsion_vector += (scout_positions[i] - scout_positions[j]) / (np.linalg.norm(scout_positions[i] - scout_positions[j]) + 1e-8) #avoid div by zero\n                repulsion_vector *= self.repulsion_factor\n\n                # Movement\n                movement_vector = attraction_vector + repulsion_vector + 0.01 * np.random.randn(self.dim) #random pert\n                new_position = scout_positions[i] + movement_vector\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub) # Keep within bounds\n                \n                new_fitness = func(new_position)\n                eval_count += 1\n\n                if new_fitness < scout_fitnesses[i]:\n                    scout_positions[i] = new_position\n                    scout_fitnesses[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n            \n            best_index = np.argmin(scout_fitnesses)\n            if scout_fitnesses[best_index] < self.f_opt:\n                self.f_opt = scout_fitnesses[best_index]\n                self.x_opt = scout_positions[best_index]\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0.04506635092284106, 0.10158950688358781, 0.2381278806218391, 0.18109465192461494, 0.1863880437553057, 0.18686059303236757, 0.1877037701107025, 0.14540652504172846, 0.14842893683268432, 0.12972262278716096, 0.14076014883728927, 0.9986187679539035, 0.08577979132503155, 0.1333473244449831, 0.15041508261203873, 0.26362391422505194, 0.18820024872528984, 0.16707694700605713, 0.12509190493412348, 0.44776760540194294], "operator": "random_new", "theta_sampled": 0.16387697449926264, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "81278083-4240-4f1a-abd0-9257ad09bc0d", "fitness": 0.0, "name": "LevyDE", "description": "A population-based algorithm employing a Levy flight-based exploration strategy coupled with a differential evolution-inspired exploitation mechanism, dynamically adapting parameters based on population diversity.", "code": "import numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, de_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_rate = de_rate\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Levy distributed steps.\n        \"\"\"\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        step = u / np.power(np.abs(v), (1.0 / self.levy_exponent))\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * np.power(2, (self.levy_exponent - 1) / 2)))**(1 / self.levy_exponent)\n        steps = sigma * step\n        return steps\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive Parameter Adjustment (based on population diversity)\n            diversity = np.std(population)\n            adaptive_levy_exponent = max(0.5, min(1.9, self.levy_exponent + (diversity - 0.5))) # Levy exponent adaptation\n            adaptive_de_rate = min(0.9, max(0.1, self.de_rate * (1 + diversity))) # Differential evolution rate adaptation\n\n\n            new_population = np.copy(population)\n            for i in range(self.pop_size):\n                # Levy Flight Exploration\n                levy_steps = self.levy_flight(self.dim)\n                levy_movement = levy_steps * (self.x_opt - population[i])\n                candidate = population[i] + levy_movement\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n\n                # Differential Evolution Exploitation\n                if np.random.rand() < adaptive_de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    diff_vector = x_r1 + 0.5 * (x_r2 - x_r3) #Mutation factor of 0.5\n                    diff_vector = np.clip(diff_vector, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < 0.7  # Crossover rate of 0.7\n                    candidate[crossover_mask] = diff_vector[crossover_mask]\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n\n                # Evaluate candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    new_population[i] = candidate\n\n                    # Update global best\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate.copy()\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population #Update population\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm employing a Levy flight-based exploration strategy coupled with a differential evolution-inspired exploitation mechanism, dynamically adapting parameters based on population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass LevyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5, de_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.de_rate = de_rate\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Levy distributed steps.\n        \"\"\"\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        step = u / np.power(np.abs(v), (1.0 / self.levy_exponent))\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * np.power(2, (self.levy_exponent - 1) / 2)))**(1 / self.levy_exponent)\n        steps = sigma * step\n        return steps\n\n    def __call__(self, func):\n        # Initialization\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        # Optimization loop\n        while self.budget > 0:\n            # Adaptive Parameter Adjustment (based on population diversity)\n            diversity = np.std(population)\n            adaptive_levy_exponent = max(0.5, min(1.9, self.levy_exponent + (diversity - 0.5))) # Levy exponent adaptation\n            adaptive_de_rate = min(0.9, max(0.1, self.de_rate * (1 + diversity))) # Differential evolution rate adaptation\n\n\n            new_population = np.copy(population)\n            for i in range(self.pop_size):\n                # Levy Flight Exploration\n                levy_steps = self.levy_flight(self.dim)\n                levy_movement = levy_steps * (self.x_opt - population[i])\n                candidate = population[i] + levy_movement\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n\n                # Differential Evolution Exploitation\n                if np.random.rand() < adaptive_de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    diff_vector = x_r1 + 0.5 * (x_r2 - x_r3) #Mutation factor of 0.5\n                    diff_vector = np.clip(diff_vector, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n\n                    # Crossover\n                    crossover_mask = np.random.rand(self.dim) < 0.7  # Crossover rate of 0.7\n                    candidate[crossover_mask] = diff_vector[crossover_mask]\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n\n                # Evaluate candidate\n                f_candidate = func(candidate)\n                self.budget -= 1\n                if f_candidate < fitness[i]:\n                    fitness[i] = f_candidate\n                    new_population[i] = candidate\n\n                    # Update global best\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate.copy()\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population #Update population\n\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": -0.023583602131650505, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "c1c29c2d-7647-4f49-96b8-f3406a4a9517", "fitness": 0.0, "name": "DE_CMAES", "description": "A population-based algorithm that combines elements of Differential Evolution and Covariance Matrix Adaptation Evolution Strategy, focusing on local search intensification within promising regions and diversity injection when convergence stagnates.", "code": "import numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.mu = self.population[np.argmin(self.fitness)]\n        self.sigma = 0.1 * (ub - lb) #Initial step size\n\n        self.stagnation_counter = 0\n\n        while self.budget > 0:\n            \n            # Differential Evolution part: mutation and crossover\n            mutated_population = self.population.copy()\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + 0.5 * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n                mutated_population[i] = mutant\n            \n            # Crossover (binomial)\n            trial_population = self.population.copy()\n            for i in range(self.pop_size):\n                for j in range(self.dim):\n                    if np.random.rand() < 0.9 or j == np.random.randint(0, self.dim):\n                        trial_population[i, j] = mutated_population[i, j]\n\n            # Selection\n            trial_fitness = np.array([func(x) for x in trial_population])\n            self.budget -= self.pop_size\n            \n            for i in range(self.pop_size):\n                if trial_fitness[i] < self.fitness[i]:\n                    self.population[i] = trial_population[i]\n                    self.fitness[i] = trial_fitness[i]\n\n            # Local search intensification around the best solution\n            best_index = np.argmin(self.fitness)\n            for _ in range(min(self.local_search_iterations, self.budget)):\n                x_local = self.population[best_index] + self.sigma * np.random.randn(self.dim)\n                x_local = np.clip(x_local, lb, ub)\n                f_local = func(x_local)\n                self.budget -= 1\n                if f_local < self.fitness[best_index]:\n                    self.population[best_index] = x_local\n                    self.fitness[best_index] = f_local\n\n            # Update best solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            # Stagnation check and diversity injection\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                self.sigma *= 1.2 #increase step size after diversity injection\n            else:\n                self.sigma *= 0.99 #decrease step size if not stagnated\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm DE_CMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines elements of Differential Evolution and Covariance Matrix Adaptation Evolution Strategy, focusing on local search intensification within promising regions and diversity injection when convergence stagnates.\n# Code:\n```python\nimport numpy as np\n\nclass DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations\n        self.stagnation_threshold = stagnation_threshold\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.mu = self.population[np.argmin(self.fitness)]\n        self.sigma = 0.1 * (ub - lb) #Initial step size\n\n        self.stagnation_counter = 0\n\n        while self.budget > 0:\n            \n            # Differential Evolution part: mutation and crossover\n            mutated_population = self.population.copy()\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + 0.5 * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n                mutated_population[i] = mutant\n            \n            # Crossover (binomial)\n            trial_population = self.population.copy()\n            for i in range(self.pop_size):\n                for j in range(self.dim):\n                    if np.random.rand() < 0.9 or j == np.random.randint(0, self.dim):\n                        trial_population[i, j] = mutated_population[i, j]\n\n            # Selection\n            trial_fitness = np.array([func(x) for x in trial_population])\n            self.budget -= self.pop_size\n            \n            for i in range(self.pop_size):\n                if trial_fitness[i] < self.fitness[i]:\n                    self.population[i] = trial_population[i]\n                    self.fitness[i] = trial_fitness[i]\n\n            # Local search intensification around the best solution\n            best_index = np.argmin(self.fitness)\n            for _ in range(min(self.local_search_iterations, self.budget)):\n                x_local = self.population[best_index] + self.sigma * np.random.randn(self.dim)\n                x_local = np.clip(x_local, lb, ub)\n                f_local = func(x_local)\n                self.budget -= 1\n                if f_local < self.fitness[best_index]:\n                    self.population[best_index] = x_local\n                    self.fitness[best_index] = f_local\n\n            # Update best solution\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            # Stagnation check and diversity injection\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                self.sigma *= 1.2 #increase step size after diversity injection\n            else:\n                self.sigma *= 0.99 #decrease step size if not stagnated\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.35780732313178376, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "f7c32d4f-92bf-4ba7-b741-64ab0d8172a4", "fitness": 0.7300201065490594, "name": "AdaptiveHybridPSO_DE_v3", "description": "Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd3b8fcf-b733-48a2-959c-0a9aa421da4a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23085331642320728, 0.5927806555141326, 0.8464343792370237, 0.9303321280482861, 0.8817467524829654, 0.8954632000461651, 0.35885983466005955, 0.6429511107786456, 0.8827452498907019, 0.8238452686286073, 0.8811148439426826, 0.9982121205507668, 0.3129647795251814, 0.759440132824202, 0.9245485561140223, 0.8996422290640026, 0.5525258400680322, 0.9023911975040474, 0.7840041454556073, 0.4995463902228474], "operator": "mutation", "theta_sampled": 0.18151281957997545, "reward": 0.027833435664832984, "generation": 6}, "task_prompt": ""}
{"id": "d39552a1-6c51-4832-91c6-cfacb3db4e33", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_v3", "description": "Adaptive Hybrid PSO_DE with velocity clamping and a restart mechanism for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=2.0, c2=2.0, cr=0.9, f=0.8, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight for PSO\n        self.w_min = w_min\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.v_max_ratio = v_max_ratio # Maximum velocity as a ratio of the search space\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Initialize velocities\n        v_max = self.v_max_ratio * (ub - lb)\n        v_min = -v_max\n        v = np.random.uniform(v_min, v_max, (self.pop_size, self.dim))\n\n\n        stagnation_counter = 0\n        max_stagnation = 50  # Number of iterations before restart\n\n        # Optimization loop\n        while self.budget > 0:\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / 10000) # linearly decreasing inertia weight\n            \n            prev_gbest_f = gbest_f # Store previous best fitness for stagnation check\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * v + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, v_min, v_max)\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            #Stagnation Check\n            if gbest_f >= prev_gbest_f:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            if stagnation_counter > max_stagnation:\n                # Restart: Re-initialize a fraction of the population around the best\n                num_restart = int(self.pop_size * 0.2)\n                indices_to_restart = np.random.choice(self.pop_size, num_restart, replace=False)\n                for i in indices_to_restart:\n                    pop[i] = np.random.uniform(lb, ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i].copy()\n                    \n                    if fitness[i] < gbest_f:\n                        gbest_f = fitness[i]\n                        gbest_x = pop[i].copy()\n                stagnation_counter = 0\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["7a36599f-f8bb-4c51-9e48-fa37c19bc018"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO_DE with velocity clamping and a restart mechanism for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_max=0.9, w_min=0.4, c1=2.0, c2=2.0, cr=0.9, f=0.8, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max  # Inertia weight for PSO\n        self.w_min = w_min\n        self.c1 = c1  # Cognitive coefficient for PSO\n        self.c2 = c2  # Social coefficient for PSO\n        self.cr = cr  # Crossover rate for DE\n        self.f = f    # Mutation factor for DE\n        self.v_max_ratio = v_max_ratio # Maximum velocity as a ratio of the search space\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Initialize velocities\n        v_max = self.v_max_ratio * (ub - lb)\n        v_min = -v_max\n        v = np.random.uniform(v_min, v_max, (self.pop_size, self.dim))\n\n\n        stagnation_counter = 0\n        max_stagnation = 50  # Number of iterations before restart\n\n        # Optimization loop\n        while self.budget > 0:\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / 10000) # linearly decreasing inertia weight\n            \n            prev_gbest_f = gbest_f # Store previous best fitness for stagnation check\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * v + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, v_min, v_max)\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + self.f * (pbest_pop[r2] - pbest_pop[r3])\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            #Stagnation Check\n            if gbest_f >= prev_gbest_f:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n            \n            if stagnation_counter > max_stagnation:\n                # Restart: Re-initialize a fraction of the population around the best\n                num_restart = int(self.pop_size * 0.2)\n                indices_to_restart = np.random.choice(self.pop_size, num_restart, replace=False)\n                for i in indices_to_restart:\n                    pop[i] = np.random.uniform(lb, ub)\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    pbest_pop[i] = pop[i].copy()\n                    pbest_fitness[i] = fitness[i].copy()\n                    \n                    if fitness[i] < gbest_f:\n                        gbest_f = fitness[i]\n                        gbest_x = pop[i].copy()\n                stagnation_counter = 0\n\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.004603363463784281, "reward": 0.0, "generation": 6}, "task_prompt": ""}
