{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "c9bd2903-3dd2-4919-bf9e-672ead43060b", "fitness": 0.7249750949180572, "name": "EnsembleAdaptiveDE", "description": "An enhanced adaptive differential evolution algorithm using a dynamically adjusted ensemble of mutation strategies and orthogonal learning to improve exploration and exploitation.", "code": "import numpy as np\n\nclass EnsembleAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, restart_patience=500, ensemble_size=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.restart_patience = restart_patience\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.ensemble_size = ensemble_size\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n\n        # Mutation strategy pool\n        self.mutation_strategies = [\n            self.mutation_DE_rand1,\n            self.mutation_DE_best1,\n            self.mutation_DE_current_to_best1\n        ]\n        self.strategy_weights = np.ones(self.ensemble_size) / self.ensemble_size  # Initially uniform weights\n        self.success_rates = np.zeros(self.ensemble_size)  # Track success rates of each strategy\n        self.strategy_counts = np.zeros(self.ensemble_size)\n\n    def mutation_DE_rand1(self, pop, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x_r1, x_r2, x_r3 = pop[idxs]\n        v = x_r1 + self.F * (x_r2 - x_r3)\n        return v\n    \n    def mutation_DE_best1(self, pop, best_idx, i):\n        idxs = np.random.choice(self.pop_size, 2, replace=False)\n        x_r1, x_r2 = pop[idxs]\n        v = pop[best_idx] + self.F * (x_r1 - x_r2)\n        return v\n\n    def mutation_DE_current_to_best1(self, pop, best_idx, i):\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x_r1, x_r2 = pop[idxs]\n         v = pop[i] + self.F * (pop[best_idx] - pop[i]) + self.F * (x_r1 - x_r2)\n         return v\n    \n\n    def orthogonal_learning(self, u, bounds):\n        # Simple orthogonal learning: generate a random orthogonal vector\n        rand_vec = np.random.rand(self.dim)\n        rand_vec /= np.linalg.norm(rand_vec)  # Normalize\n        step_size = np.random.uniform(-0.1, 0.1) #Adaptive step size\n        \n        u_new = u + step_size * rand_vec\n        u_new = np.clip(u_new, bounds.lb, bounds.ub)\n        return u_new\n\n    def __call__(self, func):\n        # Initialize population\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n\n        iteration = 0\n        no_improvement_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Ensemble of mutation strategies: select a strategy based on weights\n                strategy_idx = np.random.choice(self.ensemble_size, p=self.strategy_weights)\n                self.strategy_counts[strategy_idx] += 1\n                mutation_strategy = self.mutation_strategies[strategy_idx]\n                \n                if mutation_strategy == self.mutation_DE_rand1:\n                    v = mutation_strategy(pop, i)\n                else:\n                    v = mutation_strategy(pop, best_idx, i)\n\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                u = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n\n                # Apply orthogonal learning\n                if np.random.rand() < 0.1:\n                    u = self.orthogonal_learning(u, func.bounds)\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < fitness[i]:\n                    # Strategy was successful\n                    self.success_rates[strategy_idx] += 1\n                    \n                    fitness[i] = f_u\n                    pop[i] = u\n\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                        no_improvement_count = 0\n                    else:\n                        no_improvement_count += 1\n                else:\n                    no_improvement_count += 1\n                \n                #Update archive\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(pop[i].copy())\n                elif np.random.rand() < 0.1: #Small chance to replace\n                    idx_replace = np.random.randint(len(self.archive))\n                    self.archive[idx_replace] = pop[i].copy()\n\n            # Update strategy weights based on success rates\n            self.strategy_weights = self.success_rates / self.strategy_counts\n            self.strategy_weights /= np.sum(self.strategy_weights)\n            self.strategy_weights = np.nan_to_num(self.strategy_weights)  # Handle potential NaN values\n            if np.sum(self.strategy_weights) == 0:\n                self.strategy_weights = np.ones(self.ensemble_size) / self.ensemble_size\n\n            # Restart mechanism\n            if no_improvement_count > self.restart_patience:\n                pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size\n                \n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = pop[best_idx]\n                no_improvement_count = 0\n                self.archive = []\n                self.strategy_weights = np.ones(self.ensemble_size) / self.ensemble_size  # Reset weights\n                self.success_rates = np.zeros(self.ensemble_size)\n                self.strategy_counts = np.zeros(self.ensemble_size)\n\n            iteration += 1\n\n            best_idx = np.argmin(fitness)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm EnsembleAdaptiveDE scored 0.725 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["edbf797c-dcc3-460f-8549-de041651be38"], "operator": null, "metadata": {"aucs": [0.35666996998431644, 0.8142118607865952, 0.8419483402169583, 0.9380042026060744, 0.8938023787414371, 0.910832155889376, 0.37401825682289325, 0.8538426656706173, 0.8946062053331103, 0.4651589627885069, 0.9413197986904631, 0.9932531942430366, 0.8305240945799123, 0.3834651030253713, 0.924155842297414, 0.9022583378258384, 0.4128466666800522, 0.9314726259049101, 0.32915459543840353, 0.5079566408358585]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-0", "seed": 0}
{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "919af7fb-26b1-445f-8d6c-693055affe56", "fitness": 0.6539289359155027, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution strategy that adjusts its parameters based on the function evaluations and population diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n\n                # Clip mutant to bounds\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adaptive Parameter Control (Example: Adaptive F)\n            if generation % 10 == 0:\n                diversity = np.std(population)\n                if diversity < 0.1: # If population collapses, increase exploration\n                    self.F = min(self.F + 0.1, 1.0)\n                else:\n                    self.F = max(self.F - 0.05, 0.1)\n\n            # Early stopping\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.654 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.23789563447271433, 0.677186445664161, 0.518326014952897, 0.8779465910291683, 0.7705327530674014, 0.8045795323393496, 0.5363991947171631, 0.6285188660338139, 0.6165499139674624, 0.7227862058849357, 0.8591618422778027, 0.9922674665685023, 0.3691263491974939, 0.7884982983383618, 0.790198853179851, 0.7789200114898509, 0.5126354202144024, 0.8435648480660777, 0.22540294762591484, 0.5280815292227302]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-1", "seed": 1}
{"method_name": "LLaMEA-Prompt5", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "LLaMEA-Prompt5", "budget": 50, "kwargs": {"mutation_prompts": ["Refine the strategy of the selected solution to improve it.", "Generate a new algorithm that is different from the algorithms you have tried before.", "Refine and simplify the selected algorithm to improve it."], "n_parents": 4, "n_offspring": 8, "elitism": true}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "b74c2b0d-4c48-4477-a287-77e6ab627c01", "fitness": 0.7373788991217323, "name": "AdaptiveCulturalDifferentialEvolution", "description": "A simplified self-adaptive Cultural Differential Evolution with dynamic parameter control based on success history and belief space adaptation, focusing on efficiency and exploration.", "code": "import numpy as np\n\nclass AdaptiveCulturalDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, cr=0.7, f=0.8, belief_space_size=5, local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr  # Crossover rate\n        self.f = f    # Differential weight\n        self.belief_space_size = belief_space_size # Size of the belief space\n        self.local_search_prob = local_search_prob # Probability of local search\n\n        self.cr_history = []\n        self.f_history = []\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n        \n        # Initialize belief space\n        belief_space = population[np.argsort(fitness)[:self.belief_space_size]].copy()\n        belief_fitness = np.sort(fitness)[:self.belief_space_size].copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Adaptive Parameter Control (simplified)\n            if generation > 5 and self.cr_history and self.f_history:\n                self.cr = np.clip(np.mean(self.cr_history), 0.2, 0.9)\n                self.f = np.clip(np.mean(self.f_history), 0.2, 1.0)\n                self.cr_history = []\n                self.f_history = []\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = x_r1 + self.f * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, lb, ub)\n                \n                # Crossover\n                x_trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n                \n                # Cultural Learning (simplified influence)\n                belief_idx = np.random.randint(self.belief_space_size)\n                x_trial = 0.8 * x_trial + 0.2 * belief_space[belief_idx]  # Weighted average\n                x_trial = np.clip(x_trial, lb, ub)\n                \n                # Local Search (less frequent)\n                if np.random.rand() < self.local_search_prob:\n                    x_trial = x_trial + np.random.normal(0, 0.01 * (ub - lb), self.dim)\n                    x_trial = np.clip(x_trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(x_trial)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    # Update CR/F history\n                    self.cr_history.append(self.cr)\n                    self.f_history.append(self.f)\n                    \n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    # Simplified Belief Space Update\n                    if f_trial < belief_fitness[-1]:\n                        belief_fitness[-1] = f_trial\n                        belief_space[-1] = x_trial\n                        \n                        # Re-sort belief space\n                        sorted_indices = np.argsort(belief_fitness)\n                        belief_fitness = belief_fitness[sorted_indices]\n                        belief_space = belief_space[sorted_indices]\n\n                # Update overall best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n                    \n                if self.budget <= 0:\n                    break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveCulturalDifferentialEvolution scored 0.737 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["acecb8ce-e251-4aab-a92b-4a34ce1be12e"], "operator": null, "metadata": {"aucs": [0.3221755796665017, 0.6810726725133507, 0.7773666870207309, 0.9082693328095413, 0.8336458795754655, 0.8561324399410427, 0.7456807621628245, 0.7643018161937823, 0.82624127806947, 0.7786380625701927, 0.9032494589056242, 0.9959419880335441, 0.4411464043625075, 0.7872545926071123, 0.9357327806850363, 0.8604343179523692, 0.6867838759268489, 0.902470897555584, 0.20581351880542353, 0.5352256370776899]}, "task_prompt": "\nYou are a Python developer working on a new optimization algorithm.\nYour task is to develop a novel heuristic optimization algorithm for continuous optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the Many Affine BBOB test suite of noiseless functions. Your task is to write the optimization algorithm in Python code. \nEach of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nThe code should contain an `__init__(self, budget, dim)` function with optional additional arguments and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. \n"}, "log_dir": "run-LLaMEA-Prompt5-MA_BBOB-2", "seed": 2}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 4.68714330884082, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.11001371869196722, "pulls": 14}, "crossover": {"count": 2.513454928466129, "mean": 0.004486962373746042, "var": 1.908902157650892e-05, "std": 0.004369098485558424, "theta": 0.009186020466898651, "pulls": 15}, "random_new": {"count": 2.720850090580262, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.3065422171732377, "pulls": 17}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "ac79e3cd-91bb-4e55-8257-ef35d17b015c", "fitness": 0.6269818555820013, "name": "AdaptiveDEPlusPlus", "description": "Combines adaptive F and CR with success-history based adaptation, adaptive population sizing, and restarts for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDEPlusPlus:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=4, F_initial=0.5, CR_initial=0.9, stagnation_threshold=1000, archive_size=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size_factor (int): Factor to determine initial population size (pop_size = pop_size_factor * dim).\n            F_initial (float): Initial differential weight.\n            CR_initial (float): Initial crossover probability.\n            stagnation_threshold (int): Number of iterations without improvement to trigger a restart.\n            archive_size (int): Size of archive for storing successful F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_factor * dim  # Population size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.success_rate_threshold = 0.2  # Threshold for adjusting population size\n        self.pop_size_reduction_factor = 0.8 # Reduction factor if success rate is too low\n        self.pop_size_increase_factor = 1.2 # Increase factor if success rate is high\n        self.min_pop_size = 4 * dim # Minimal population size\n        self.max_pop_size = 10 * dim # Maximal population size\n\n        self.archive_F = []  # Archive for storing successful F values\n        self.archive_CR = []  # Archive for storing successful CR values\n        self.archive_size = archive_size\n\n        self.F_mean = 0.5 # Initialize F_mean\n        self.F_std = 0.3 # Initialize F_std\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n\n        # Main optimization loop\n        while self.eval_count < self.budget:\n            \n            # Store fitness values for success rate calculation\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Adaptive F: Uses a dynamically adjusted normal distribution\n                if self.stagnation_counter == 0: # If improved: Reduce F_std and F_mean\n                    self.F_mean = max(0.2, self.F_mean * 0.95) # Reduce mean\n                    self.F_std = max(0.1, self.F_std * 0.95) # Reduce std\n\n                else: # Else: Increase F_std and maybe also F_mean\n                    self.F_mean = min(0.8, self.F_mean * 1.05) # Increase mean\n                    self.F_std = min(0.5, self.F_std * 1.05) # Increase std\n\n                self.F = np.random.normal(self.F_mean, self.F_std)  # Mean 0.5, standard deviation 0.3\n                self.F = np.clip(self.F, 0.1, 1.0) # ensure F stays within bounds [0.1, 1]\n\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n\n                # Ensure the mutated vector stays within bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n\n                # Adaptive CR: Sample CR from archive of successful values\n                if self.archive_CR:\n                    CR_index = np.random.randint(len(self.archive_CR))\n                    current_CR = self.archive_CR[CR_index]\n                else:\n                    current_CR = self.CR # Use initial CR if archive is empty\n\n                for j in range(self.dim):\n                    if np.random.rand() < current_CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Store successful F and CR values in archive\n                    self.archive_F.append(self.F)\n                    self.archive_CR.append(current_CR)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0) # Keep archive size constant\n                    if len(self.archive_CR) > self.archive_size:\n                        self.archive_CR.pop(0) # Keep archive size constant\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive population size adjustment based on success rate\n            successful_individuals = np.sum(fitness < old_fitness)\n            success_rate = successful_individuals / self.pop_size\n\n            if success_rate < self.success_rate_threshold:\n                self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                self.pop_size = max(self.pop_size, self.min_pop_size)  # Ensure minimum population size\n            elif success_rate > (1 - self.success_rate_threshold): # High success_rate\n                self.pop_size = int(self.pop_size * self.pop_size_increase_factor)\n                self.pop_size = min(self.pop_size, self.max_pop_size) # Ensure maximal population size\n            \n            # Regenerate population (only the changed part!)\n            if self.pop_size != population.shape[0]:\n                if self.pop_size > population.shape[0]: # Increase population\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - population.shape[0], self.dim))\n                    population = np.vstack((population, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.eval_count += len(new_fitness)\n                    fitness = np.concatenate((fitness, new_fitness))\n\n                else: # Reduce Population\n                    # Remove the worst individuals (high fitness value)\n                    worst_indices = np.argsort(fitness)[self.pop_size:] # Indices of worst individuals\n                    population = np.delete(population, worst_indices, axis=0)\n                    fitness = np.delete(fitness, worst_indices)\n            \n            # Restart mechanism if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDEPlusPlus scored 0.627 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0197df04-ea20-47c5-bee1-99bf5f5b7c20", "87c78c15-dbc5-43ef-b285-5a2015525591"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive F and CR with success-history based adaptation, adaptive population sizing, and restarts for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEPlusPlus:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=4, F_initial=0.5, CR_initial=0.9, stagnation_threshold=1000, archive_size=100):\n        \"\"\"\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size_factor (int): Factor to determine initial population size (pop_size = pop_size_factor * dim).\n            F_initial (float): Initial differential weight.\n            CR_initial (float): Initial crossover probability.\n            stagnation_threshold (int): Number of iterations without improvement to trigger a restart.\n            archive_size (int): Size of archive for storing successful F and CR values.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_factor * dim  # Population size\n        self.F = F_initial\n        self.CR = CR_initial\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.success_rate_threshold = 0.2  # Threshold for adjusting population size\n        self.pop_size_reduction_factor = 0.8 # Reduction factor if success rate is too low\n        self.pop_size_increase_factor = 1.2 # Increase factor if success rate is high\n        self.min_pop_size = 4 * dim # Minimal population size\n        self.max_pop_size = 10 * dim # Maximal population size\n\n        self.archive_F = []  # Archive for storing successful F values\n        self.archive_CR = []  # Archive for storing successful CR values\n        self.archive_size = archive_size\n\n        self.F_mean = 0.5 # Initialize F_mean\n        self.F_std = 0.3 # Initialize F_std\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.eval_count += self.pop_size\n\n\n        # Update optimal solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n            self.stagnation_counter = 0  # Reset stagnation counter\n        else:\n            self.stagnation_counter +=1\n\n        # Main optimization loop\n        while self.eval_count < self.budget:\n            \n            # Store fitness values for success rate calculation\n            old_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n\n                # Adaptive F: Uses a dynamically adjusted normal distribution\n                if self.stagnation_counter == 0: # If improved: Reduce F_std and F_mean\n                    self.F_mean = max(0.2, self.F_mean * 0.95) # Reduce mean\n                    self.F_std = max(0.1, self.F_std * 0.95) # Reduce std\n\n                else: # Else: Increase F_std and maybe also F_mean\n                    self.F_mean = min(0.8, self.F_mean * 1.05) # Increase mean\n                    self.F_std = min(0.5, self.F_std * 1.05) # Increase std\n\n                self.F = np.random.normal(self.F_mean, self.F_std)  # Mean 0.5, standard deviation 0.3\n                self.F = np.clip(self.F, 0.1, 1.0) # ensure F stays within bounds [0.1, 1]\n\n                x_mutated = population[i] + self.F * (x_r2 - x_r3)\n\n                # Ensure the mutated vector stays within bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n\n                # Adaptive CR: Sample CR from archive of successful values\n                if self.archive_CR:\n                    CR_index = np.random.randint(len(self.archive_CR))\n                    current_CR = self.archive_CR[CR_index]\n                else:\n                    current_CR = self.CR # Use initial CR if archive is empty\n\n                for j in range(self.dim):\n                    if np.random.rand() < current_CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n\n                    # Store successful F and CR values in archive\n                    self.archive_F.append(self.F)\n                    self.archive_CR.append(current_CR)\n                    if len(self.archive_F) > self.archive_size:\n                        self.archive_F.pop(0) # Keep archive size constant\n                    if len(self.archive_CR) > self.archive_size:\n                        self.archive_CR.pop(0) # Keep archive size constant\n\n\n                    # Update optimal solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                        self.stagnation_counter = 0 # Reset stagnation counter\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive population size adjustment based on success rate\n            successful_individuals = np.sum(fitness < old_fitness)\n            success_rate = successful_individuals / self.pop_size\n\n            if success_rate < self.success_rate_threshold:\n                self.pop_size = int(self.pop_size * self.pop_size_reduction_factor)\n                self.pop_size = max(self.pop_size, self.min_pop_size)  # Ensure minimum population size\n            elif success_rate > (1 - self.success_rate_threshold): # High success_rate\n                self.pop_size = int(self.pop_size * self.pop_size_increase_factor)\n                self.pop_size = min(self.pop_size, self.max_pop_size) # Ensure maximal population size\n            \n            # Regenerate population (only the changed part!)\n            if self.pop_size != population.shape[0]:\n                if self.pop_size > population.shape[0]: # Increase population\n                    new_individuals = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - population.shape[0], self.dim))\n                    population = np.vstack((population, new_individuals))\n                    new_fitness = np.array([func(x) for x in new_individuals])\n                    self.eval_count += len(new_fitness)\n                    fitness = np.concatenate((fitness, new_fitness))\n\n                else: # Reduce Population\n                    # Remove the worst individuals (high fitness value)\n                    worst_indices = np.argsort(fitness)[self.pop_size:] # Indices of worst individuals\n                    population = np.delete(population, worst_indices, axis=0)\n                    fitness = np.delete(fitness, worst_indices)\n            \n            # Restart mechanism if stagnating\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.eval_count += self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                self.stagnation_counter = 0 # Reset stagnation counter\n            else:\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index]\n                    self.stagnation_counter = 0 # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23277036258767592, 0.6126088325673156, 0.5630807109851405, 0.8294060348203555, 0.6867554450984776, 0.7345487083688365, 0.42333049752747687, 0.5321080282421204, 0.6312565900608207, 0.595340869892606, 0.8474904783162919, 0.9873815945342467, 0.6000025869317342, 0.5499247673185581, 0.9139538422743939, 0.7259205984352535, 0.5199008091996937, 0.7898895795203329, 0.2627909958795137, 0.5011757790791791], "operator": "crossover", "theta_sampled": 0.003039785615766519, "reward": 0.017730161909644493, "generation": 5}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-0", "seed": 0}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 3.0574794695687624, "mean": 0.008192622071332643, "var": 5.262708452514248e-05, "std": 0.007254452737811618, "theta": 0.004603363463784281, "pulls": 9}, "crossover": {"count": 2.950310278879165, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.31538620144107715, "pulls": 16}, "random_new": {"count": 3.9136585794392857, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.30757895989575157, "pulls": 21}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "f7c32d4f-92bf-4ba7-b741-64ab0d8172a4", "fitness": 0.7300201065490594, "name": "AdaptiveHybridPSO_DE_v3", "description": "Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.730 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["dd3b8fcf-b733-48a2-959c-0a9aa421da4a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements an adaptive hybrid PSO-DE algorithm with dynamic parameter adjustments based on population diversity and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=50, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, cr_init=0.9, cr_end=0.1, f_init=0.8, f_end=0.2, v_max_ratio=0.2, stagnation_threshold=10, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_init = w_init  # Initial inertia weight for PSO\n        self.w_end = w_end    # Final inertia weight for PSO\n        self.c1 = c1          # Cognitive coefficient for PSO\n        self.c2 = c2          # Social coefficient for PSO\n        self.cr_init = cr_init  # Initial Crossover rate for DE\n        self.cr_end = cr_end    # Final Crossover rate for DE\n        self.f_init = f_init    # Initial Mutation factor for DE\n        self.f_end = f_end      # Final Mutation factor for DE\n        self.v_max_ratio = v_max_ratio  # Maximum velocity as a ratio of the search range\n        self.stagnation_threshold = stagnation_threshold # Number of iterations without improvement to trigger parameter adaptation\n        self.stagnation_counter = 0\n        self.previous_gbest_f = np.inf\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n    def __call__(self, func):\n        # Initialize population\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluation\n\n        # Initialize personal best positions and fitness\n        pbest_pop = pop.copy()\n        pbest_fitness = fitness.copy()\n\n        # Initialize global best position and fitness\n        gbest_index = np.argmin(pbest_fitness)\n        gbest_x = pbest_pop[gbest_index].copy()\n        gbest_f = pbest_fitness[gbest_index]\n\n        # Calculate the maximum velocity for each dimension based on search range\n        v_max = self.v_max_ratio * (ub - lb)\n\n        # Optimization loop\n        iter_num = 0\n        while self.budget > 0:\n            # Adaptive parameter update (linear decay)\n            w = self.w_init - (self.w_init - self.w_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            cr = self.cr_init - (self.cr_init - self.cr_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n            f = self.f_init - (self.f_init - self.f_end) * (iter_num / (self.budget / self.pop_size + iter_num))\n\n            # Stagnation detection and parameter adaptation\n            if gbest_f >= self.previous_gbest_f:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Adapt parameters to escape local optima\n                self.w_init = min(0.9, self.w_init * 1.05) # Ensure w_init does not exceed 0.9\n                self.cr_init = max(0.1, self.cr_init * 0.95)  # Ensure cr_init does not go below 0.1\n                self.f_init = min(0.9, self.f_init * 1.05)  # Ensure f_init does not exceed 0.9\n                self.stagnation_counter = 0 #reset stagnation counter\n                print(\"Stagnation detected, adapting parameters\")\n\n            self.previous_gbest_f = gbest_f\n\n            # Calculate population diversity\n            diversity = np.std(pop)\n            if diversity < self.diversity_threshold:\n                # Restart the population to increase exploration\n                print(\"Low diversity, restarting population\")\n                pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in pop])\n                self.budget -= self.pop_size  # Update budget after restart\n\n                pbest_pop = pop.copy()\n                pbest_fitness = fitness.copy()\n\n                gbest_index = np.argmin(pbest_fitness)\n                gbest_x = pbest_pop[gbest_index].copy()\n                gbest_f = pbest_fitness[gbest_index]\n\n            for i in range(self.pop_size):\n                # PSO update\n                v = w * (pop[i] - pbest_pop[i]) + self.c1 * np.random.rand(self.dim) * (pbest_pop[i] - pop[i]) + \\\n                    self.c2 * np.random.rand(self.dim) * (gbest_x - pop[i])\n\n                # Velocity clamping\n                v = np.clip(v, -v_max, v_max)  # Limit the velocity\n\n                new_x_pso = pop[i] + v\n\n                # Differential Evolution update\n                r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                while r1 == i or r2 == i or r3 == i:\n                    r1, r2, r3 = np.random.choice(self.pop_size, 3, replace=False)\n                \n                v_de = pbest_pop[r1] + f * (pbest_pop[r2] - pbest_pop[r3])\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                new_x_de = pop[i].copy()  # Start with the current position\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        new_x_de[j] = v_de[j]\n\n                # Combined update: Choose between PSO and DE based on probability\n                if np.random.rand() < 0.5:\n                    new_x = new_x_pso\n                else:\n                    new_x = new_x_de\n\n                # Clip to bounds and evaluate\n                new_x = np.clip(new_x, lb, ub)\n                new_f = func(new_x)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break  # Stop if budget is exhausted\n\n                # Update personal best\n                if new_f < pbest_fitness[i]:\n                    pbest_fitness[i] = new_f\n                    pbest_pop[i] = new_x.copy()\n\n                    # Update global best\n                    if new_f < gbest_f:\n                        gbest_f = new_f\n                        gbest_x = new_x.copy()\n\n                pop[i] = new_x.copy()\n\n            if self.budget <= 0:\n                break\n\n            iter_num += 1\n\n        self.f_opt = gbest_f\n        self.x_opt = gbest_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23085331642320728, 0.5927806555141326, 0.8464343792370237, 0.9303321280482861, 0.8817467524829654, 0.8954632000461651, 0.35885983466005955, 0.6429511107786456, 0.8827452498907019, 0.8238452686286073, 0.8811148439426826, 0.9982121205507668, 0.3129647795251814, 0.759440132824202, 0.9245485561140223, 0.8996422290640026, 0.5525258400680322, 0.9023911975040474, 0.7840041454556073, 0.4995463902228474], "operator": "mutation", "theta_sampled": 0.18151281957997545, "reward": 0.027833435664832984, "generation": 6}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-1", "seed": 1}
{"method_name": "GA-LLAMEA-Baseline", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "GA-LLAMEA-Baseline", "budget": 50, "n_parents": 4, "n_offspring": 8, "elitism": true, "discount": 0.9, "tau_max": 0.2, "method_type": "GA-LLAMEA", "bandit_state": {"mutation": {"count": 5.827537740198358, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": -0.13771895645673035, "pulls": 19}, "crossover": {"count": 1.148733724624329, "mean": 0.0072137050654049375, "var": 0.0007299560090055615, "std": 0.027017698070071802, "theta": -0.0069269557056053175, "pulls": 13}, "random_new": {"count": 2.9451768630645256, "mean": 0.0, "var": 0.04000000000000001, "std": 0.2, "theta": 0.15235368106951794, "pulls": 14}}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "162a8d63-dd69-484e-b20c-ca59a99035e3", "fitness": 0.7342799744009025, "name": "AdaptiveHybridPSO_DE", "description": "An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.734 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.37717489583923547, 0.7485584900826626, 0.7794829481157071, 0.8804095412024632, 0.8215762396500277, 0.8453933883368048, 0.5914048269786178, 0.7577094841970708, 0.8207214412116675, 0.8020313547327237, 0.8964030379046536, 0.9993926563741286, 0.44780283860518744, 0.7747087663335395, 0.9603433732144111, 0.8440558130931847, 0.694529420749078, 0.8984401085311924, 0.2103651453487846, 0.5350957175169124], "operator": "crossover", "theta_sampled": 0.02322416725178006, "reward": 0.17745804387555764, "generation": 2}, "task_prompt": ""}, "log_dir": "run-GA-LLAMEA-Baseline-MA_BBOB-2", "seed": 2}
{"method_name": "EoH", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "EoH", "budget": 50, "kwargs": {"pop_size": 4}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "6d0891c6-3601-47be-814a-bb3a56a6aff4", "fitness": 0.75694, "name": "SelfAdaptiveDifferentialEvolution", "description": "A self-adaptive Differential Evolution algorithm that adjusts both the crossover rate and the mutation factor based on the success rate of previous generations.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cr_memory = np.ones(self.pop_size) * self.cr_init\n        self.f_memory = np.ones(self.pop_size) * self.f_init\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        \n        evals = self.pop_size\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Adaptation of F and CR\n                self.cr = np.random.normal(self.cr_memory[i], 0.1)\n                self.cr = np.clip(self.cr, 0.0, 1.0)\n                self.f = np.random.normal(self.f_memory[i], 0.3)\n                self.f = np.clip(self.f, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.f * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                evals += 1\n\n                if f < self.fitness[i]:\n                    delta_fitness = self.fitness[i] - f\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                    \n                    # Update memory of F and CR based on success\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * self.cr\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * self.f\n                else:\n                    # Even if selection fails, slightly perturb the CR and F\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * np.random.rand()\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * np.random.rand()\n\n                if evals >= self.budget:\n                    break\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}, "log_dir": "run-EoH-MA_BBOB-0", "seed": 0}
{"method_name": "EoH", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "EoH", "budget": 50, "kwargs": {"pop_size": 4}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "1d7768c1-167c-436d-8458-1a61a92a4958", "fitness": 0.67292, "name": "AdaptiveDE", "description": "# Description: An adaptive Differential Evolution (DE) algorithm with a self-adjusting mutation factor and population size reduction.\n# Code:\n```", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_factor=0.5, crossover_rate=0.7, reduction_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.reduction_factor = reduction_factor\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)].copy()\n        self.budget -= self.pop_size\n\n    def evolve(self, func):\n        new_population = np.copy(self.population)\n        new_fitness = np.copy(self.fitness)\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n\n            # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n\n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector.copy()\n\n        self.population = new_population\n        self.fitness = new_fitness\n        \n        # Population size reduction (optional)\n        if self.budget > 0 and len(self.population) > 10 and np.random.rand() < 0.1:\n            indices = np.argsort(self.fitness)[::-1] #sort from worst to best\n            remove_count = int(len(self.population) * (1 - self.reduction_factor))\n            indices_to_keep = indices[:-remove_count] #indices of the best solutions\n            \n            self.population = self.population[indices_to_keep]\n            self.fitness = self.fitness[indices_to_keep]\n            self.pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            self.evolve(func)\n            # Adapt mutation factor\n            if np.random.rand() < 0.2:\n                self.mutation_factor = np.random.uniform(0.3, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}, "log_dir": "run-EoH-MA_BBOB-1", "seed": 1}
{"method_name": "EoH", "problem_name": "MA_BBOB", "llm_name": "gemini-2.0-flash", "method": {"method_name": "EoH", "budget": 50, "kwargs": {"pop_size": 4}}, "problem": {"name": "MA_BBOB", "dims": [5], "training_instances": "range(0, 20)", "test_instances": "range(20, 120)", "budget_factor": 2000}, "llm": {"model": "gemini-2.0-flash", "code_pattern": "```(?:python)?\\n(.*?)\\n```", "name_pattern": "class\\s*(\\w*)(?:\\(\\w*\\))?\\:", "desc_pattern": "#\\s*Description\\s*:\\s*(.*)", "cs_pattern": "space\\s*:\\s*\\n*```\\n*(?:python)?\\n(.*?)\\n```"}, "solution": {"id": "31efb890-9e0d-4377-9189-d4b47ce7936b", "fitness": 0.73603, "name": "AdaptiveDE", "description": "This algorithm uses a differential evolution strategy with adaptive mutation and crossover rates based on the success rate of previous generations, aiming for a self-adjusting balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.success_F = []\n        self.success_CR = []\n        self.memory_F = [F] * 10\n        self.memory_CR = [CR] * 10\n        self.memory_index = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        best_index = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_index]\n        self.x_opt = self.population[best_index]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Adaptive F and CR\n                F = self.memory_F[self.memory_index]\n                CR = self.memory_CR[self.memory_index]\n                \n                mutant = self.population[a] + F * (self.population[b] - self.population[c])\n                mutant = np.clip(mutant, lb, ub)\n                \n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.success_F.append(F)\n                    self.success_CR.append(CR)\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            # Update memory of F and CR\n            if self.success_F:\n                self.memory_F[self.memory_index] = np.mean(self.success_F)\n                self.memory_CR[self.memory_index] = np.mean(self.success_CR)\n                self.success_F = []\n                self.success_CR = []\n            \n            self.memory_index = (self.memory_index + 1) % 10\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}, "log_dir": "run-EoH-MA_BBOB-2", "seed": 2}

