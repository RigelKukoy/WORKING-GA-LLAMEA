{"id": "0e4e8dce-72ef-4e86-be29-d7c6e50d4587", "fitness": 0.38924678298782356, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "A population-based algorithm with adaptive exploration and exploitation using a combination of differential evolution and local search.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.5, crossover_rate=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.mutation_rate * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate:\n                    trial[j] = mutant[j]\n\n            # Evaluation\n            f = func(trial)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i]\n                    \n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n             if self.eval_count >= self.budget:\n                break\n             x = np.copy(self.population[i])\n             f = self.fitness[i]\n             \n             for _ in range(self.local_search_iterations):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Generate a small random perturbation\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                x_new = x + perturbation\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.eval_count += 1\n\n                if f_new < f:\n                    f = f_new\n                    x = x_new\n                    self.fitness[i] = f\n                    self.population[i] = x\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolutionLocalSearch scored 0.389 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive exploration and exploitation using a combination of differential evolution and local search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.5, crossover_rate=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.local_search_iterations = local_search_iterations\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.mutation_rate * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate:\n                    trial[j] = mutant[j]\n\n            # Evaluation\n            f = func(trial)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.population[i] = trial\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i]\n                    \n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n             if self.eval_count >= self.budget:\n                break\n             x = np.copy(self.population[i])\n             f = self.fitness[i]\n             \n             for _ in range(self.local_search_iterations):\n                if self.eval_count >= self.budget:\n                    break\n\n                # Generate a small random perturbation\n                perturbation = np.random.normal(0, 0.1, size=self.dim)\n                x_new = x + perturbation\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n                f_new = func(x_new)\n                self.eval_count += 1\n\n                if f_new < f:\n                    f = f_new\n                    x = x_new\n                    self.fitness[i] = f\n                    self.population[i] = x\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14221839605978892, 0.24099901752602382, 0.38701280855388964, 0.4987368750477682, 0.29045491468986284, 0.39082745388463214, 0.286065361724248, 0.3292351120733392, 0.30097332781739283, 0.19433964978923235, 0.4848265042216868, 0.9971994646968433, 0.3082544906633299, 0.27891057461909863, 0.732626708346059, 0.3957620315435981, 0.32333132016246713, 0.5141934004060833, 0.1803738266688535, 0.5085944212622736], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "b1378fc4-63d2-4b4f-a616-637534fafb35", "fitness": 0.5284246319779193, "name": "AdaptiveVelocityParticleSwarm", "description": "A population-based algorithm with velocity updates and adaptive exploration based on the fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate # probability of exploring random directions\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Smaller initial velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests and global best\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Adaptive exploration\n                if np.random.rand() < self.exploration_rate:\n                    # Explore a random direction\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                else:\n                    # Standard PSO velocity update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                    social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                    velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                    # Velocity Clamping\n                    velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                        global_best_position = population[i].copy()  # Update global best position\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveVelocityParticleSwarm scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm with velocity updates and adaptive exploration based on the fitness landscape.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveVelocityParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate # probability of exploring random directions\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1  # Smaller initial velocities\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal bests and global best\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                # Adaptive exploration\n                if np.random.rand() < self.exploration_rate:\n                    # Explore a random direction\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                else:\n                    # Standard PSO velocity update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                    social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                    velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                    # Velocity Clamping\n                    velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate new position\n                f = func(population[i])\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n                        global_best_position = population[i].copy()  # Update global best position\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt\n```", "aucs": [0.22113770182332937, 0.4452432765228316, 0.5098812446725114, 0.9256246734860786, 0.5270146508784823, 0.6076394646569458, 0.3392298754956291, 0.45652988001433725, 0.5537176854357344, 0.21361762971462328, 0.8268700008339593, 0.9989559467710148, 0.24448807714150822, 0.4008365552376505, 0.8004400961658107, 0.6456623188276678, 0.39354091323727247, 0.7283367098762497, 0.2206262825995675, 0.5090996561671832], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "b59b5fd5-7595-4ea8-8c98-3c2a44c09c80", "fitness": 0.3219761556788905, "name": "HybridOptimizer", "description": "A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a self-adaptive mutation strategy.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.4, c2=1.4, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), size=(self.pop_size, self.dim))\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_f = np.min(self.fitness)\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.gbest_f:\n            self.gbest_f = self.fitness[best_index]\n            self.gbest_x = self.pop[best_index].copy()\n\n    def update_personal_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_pop[i] = self.pop[i].copy()\n\n    def apply_pso(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        self.velocities = (self.inertia * self.velocities +\n                           self.c1 * r1 * (self.pbest_pop - self.pop) +\n                           self.c2 * r2 * (self.gbest_x - self.pop))\n        self.pop = self.pop + self.velocities\n        self.pop = np.clip(self.pop, lb, ub)\n        \n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.fitness = new_fitness\n\n    def apply_differential_evolution(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            \n            # Adaptive Mutation\n            mutation_factor = np.random.uniform(0, 1) * self.mutation_rate  # Smaller mutation more often.\n            \n            v = x1 + mutation_factor * (x2 - x3)\n            \n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.9 or j == j_rand:\n                    self.pop[i, j] = v[j]\n        \n        self.pop = np.clip(self.pop, lb, ub)\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.fitness = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            \n            if np.random.rand() < 0.5: #adaptive selection\n                self.apply_pso(func)\n            else:\n                self.apply_differential_evolution(func)\n            \n            self.update_personal_best()\n            self.update_global_best()\n\n        return self.gbest_f, self.gbest_x", "configspace": "", "generation": 0, "feedback": "The algorithm HybridOptimizer scored 0.322 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization and differential evolution with a self-adaptive mutation strategy.\n# Code:\n```python\nimport numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.4, c2=1.4, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.pop = None\n        self.fitness = None\n        self.velocities = None\n        self.pbest_pop = None\n        self.pbest_fitness = None\n        self.gbest_x = None\n        self.gbest_f = np.inf\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.pop = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), size=(self.pop_size, self.dim))\n        self.pbest_pop = self.pop.copy()\n        self.pbest_fitness = self.fitness.copy()\n        self.gbest_x = self.pop[np.argmin(self.fitness)].copy()\n        self.gbest_f = np.min(self.fitness)\n\n    def update_global_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.gbest_f:\n            self.gbest_f = self.fitness[best_index]\n            self.gbest_x = self.pop[best_index].copy()\n\n    def update_personal_best(self):\n        for i in range(self.pop_size):\n            if self.fitness[i] < self.pbest_fitness[i]:\n                self.pbest_fitness[i] = self.fitness[i]\n                self.pbest_pop[i] = self.pop[i].copy()\n\n    def apply_pso(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        self.velocities = (self.inertia * self.velocities +\n                           self.c1 * r1 * (self.pbest_pop - self.pop) +\n                           self.c2 * r2 * (self.gbest_x - self.pop))\n        self.pop = self.pop + self.velocities\n        self.pop = np.clip(self.pop, lb, ub)\n        \n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.fitness = new_fitness\n\n    def apply_differential_evolution(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.pop[idxs]\n            \n            # Adaptive Mutation\n            mutation_factor = np.random.uniform(0, 1) * self.mutation_rate  # Smaller mutation more often.\n            \n            v = x1 + mutation_factor * (x2 - x3)\n            \n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < 0.9 or j == j_rand:\n                    self.pop[i, j] = v[j]\n        \n        self.pop = np.clip(self.pop, lb, ub)\n        new_fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.fitness = new_fitness\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            \n            if np.random.rand() < 0.5: #adaptive selection\n                self.apply_pso(func)\n            else:\n                self.apply_differential_evolution(func)\n            \n            self.update_personal_best()\n            self.update_global_best()\n\n        return self.gbest_f, self.gbest_x\n```", "aucs": [0.13831631545285383, 0.18309556074328803, 0.2908517491655199, 0.39507703293399865, 0.23251647247758878, 0.32100538395259615, 0.25785791628403854, 0.27827737171074785, 0.2510666010826359, 0.2054787874275117, 0.21875472707643917, 0.9981919114030948, 0.2377635177808355, 0.24524959048264205, 0.6574962022047682, 0.3423469400905106, 0.2691651411676601, 0.2822937124242566, 0.1646717143059777, 0.47004646541084616], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "8f3ca0fd-e75c-486c-b26a-a1870c1181e1", "fitness": 0.4591262996035274, "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Archive and Budget-Aware Parameter Tuning.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.update_best()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation based on remaining budget\n                remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + adapted_F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < adapted_CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    # Update population and fitness\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.population[i].copy()\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    self.update_best()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n    \n    def update_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.459 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Archive and Budget-Aware Parameter Tuning.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.update_best()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation based on remaining budget\n                remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = x1 + adapted_F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < adapted_CR\n                trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n                # Selection\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    # Update population and fitness\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(self.population[i].copy())\n                    else:\n                        idx_to_replace = np.random.randint(0, self.archive_size)\n                        self.archive[idx_to_replace] = self.population[i].copy()\n                    self.population[i] = trial_vector\n                    self.fitness[i] = f_trial\n\n                    self.update_best()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n    \n    def update_best(self):\n        best_index = np.argmin(self.fitness)\n        if self.fitness[best_index] < self.f_opt:\n            self.f_opt = self.fitness[best_index]\n            self.x_opt = self.population[best_index]\n```", "aucs": [0.16628329406441078, 0.2835481185958787, 0.40059241069124996, 0.663333478430556, 0.4047124250854359, 0.5072707385926479, 0.3037948272766148, 0.38034904369883693, 0.3809993894752365, 0.3486297763606161, 0.6479417600603623, 0.9949473494685149, 0.32913636618349484, 0.3492569568777115, 0.8394776325073456, 0.5236069498784414, 0.35527519038539623, 0.6048948772774894, 0.21172847234045034, 0.4867469348198591], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "723b6023-2e90-40fe-9445-dfa39531d36b", "fitness": 0.49571079359098746, "name": "AdaptiveDifferentialEvolutionNeighborhoodSearch", "description": "Adaptive Differential Evolution with Neighborhood Search and Parameter Adaptation based on Success History.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.5, crossover_rate=0.7, neighborhood_size=0.1, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.neighborhood_size = neighborhood_size\n        self.adaptation_rate = adaptation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_mutation_rates = []\n        self.success_crossover_rates = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.mutation_rate * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate:\n                    trial[j] = mutant[j]\n\n            # Evaluation\n            f = func(trial)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.success_mutation_rates.append(self.mutation_rate)\n                self.success_crossover_rates.append(self.crossover_rate)\n                self.fitness[i] = f\n                self.population[i] = trial\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i]\n\n    def neighborhood_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            x = self.population[i]\n            f = self.fitness[i]\n\n            # Generate a random neighbor within a certain radius\n            neighbor = x + np.random.uniform(-self.neighborhood_size, self.neighborhood_size, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < f:\n                self.fitness[i] = f_neighbor\n                self.population[i] = neighbor\n                if f_neighbor < self.f_opt:\n                    self.f_opt = f_neighbor\n                    self.x_opt = neighbor\n    \n    def adapt_parameters(self):\n        if self.success_mutation_rates:\n            self.mutation_rate = (1 - self.adaptation_rate) * self.mutation_rate + self.adaptation_rate * np.mean(self.success_mutation_rates)\n            self.mutation_rate = np.clip(self.mutation_rate, 0.1, 1.0)\n            self.success_mutation_rates = []\n\n        if self.success_crossover_rates:\n            self.crossover_rate = (1 - self.adaptation_rate) * self.crossover_rate + self.adaptation_rate * np.mean(self.success_crossover_rates)\n            self.crossover_rate = np.clip(self.crossover_rate, 0.1, 1.0)\n            self.success_crossover_rates = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            self.neighborhood_search(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveDifferentialEvolutionNeighborhoodSearch scored 0.496 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["0e4e8dce-72ef-4e86-be29-d7c6e50d4587"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Neighborhood Search and Parameter Adaptation based on Success History.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionNeighborhoodSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.5, crossover_rate=0.7, neighborhood_size=0.1, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.neighborhood_size = neighborhood_size\n        self.adaptation_rate = adaptation_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.success_mutation_rates = []\n        self.success_crossover_rates = []\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.eval_count += 1\n            if self.fitness[i] < self.f_opt:\n                self.f_opt = self.fitness[i]\n                self.x_opt = self.population[i]\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n            \n            # Mutation\n            idxs = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = np.random.choice(idxs, 3, replace=False)\n            mutant = self.population[a] + self.mutation_rate * (self.population[b] - self.population[c])\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Crossover\n            trial = np.copy(self.population[i])\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate:\n                    trial[j] = mutant[j]\n\n            # Evaluation\n            f = func(trial)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.success_mutation_rates.append(self.mutation_rate)\n                self.success_crossover_rates.append(self.crossover_rate)\n                self.fitness[i] = f\n                self.population[i] = trial\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i]\n\n    def neighborhood_search(self, func):\n        for i in range(self.pop_size):\n            if self.eval_count >= self.budget:\n                break\n\n            x = self.population[i]\n            f = self.fitness[i]\n\n            # Generate a random neighbor within a certain radius\n            neighbor = x + np.random.uniform(-self.neighborhood_size, self.neighborhood_size, size=self.dim)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n\n            f_neighbor = func(neighbor)\n            self.eval_count += 1\n\n            if f_neighbor < f:\n                self.fitness[i] = f_neighbor\n                self.population[i] = neighbor\n                if f_neighbor < self.f_opt:\n                    self.f_opt = f_neighbor\n                    self.x_opt = neighbor\n    \n    def adapt_parameters(self):\n        if self.success_mutation_rates:\n            self.mutation_rate = (1 - self.adaptation_rate) * self.mutation_rate + self.adaptation_rate * np.mean(self.success_mutation_rates)\n            self.mutation_rate = np.clip(self.mutation_rate, 0.1, 1.0)\n            self.success_mutation_rates = []\n\n        if self.success_crossover_rates:\n            self.crossover_rate = (1 - self.adaptation_rate) * self.crossover_rate + self.adaptation_rate * np.mean(self.success_crossover_rates)\n            self.crossover_rate = np.clip(self.crossover_rate, 0.1, 1.0)\n            self.success_crossover_rates = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.initialize_population(func)\n        \n        while self.eval_count < self.budget:\n            self.differential_evolution(func)\n            self.neighborhood_search(func)\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19445119691428348, 0.33561963691717434, 0.44785284504534617, 0.7555812254148548, 0.5095254329772221, 0.5714336757589955, 0.3117760523117158, 0.4507013055548277, 0.5020092218006185, 0.2831983626633149, 0.6627591285209605, 0.9878840925534502, 0.32081885653276, 0.4209250272241768, 0.8015401385138039, 0.6049213477234939, 0.36355414764842964, 0.6937168510414267, 0.19482605032683264, 0.5011212763760637], "operator": "mutation", "theta_sampled": 0.4620727809537921, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "40884d7a-1726-433e-a294-2483f0b1009c", "fitness": 0.0, "name": "GeneticAnnealing", "description": "Population-based algorithm that combines aspects of Genetic Algorithms and Simulated Annealing, where individuals undergo crossover and mutation, with an acceptance probability inspired by the Metropolis criterion.", "code": "import numpy as np\n\nclass GeneticAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.8, temperature_decay=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.temperature_decay = temperature_decay\n        self.temperature = 1.0\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n            return child1, child2\n        else:\n            return parent1, parent2\n\n    def mutate(self, individual, func):\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                individual[i] += np.random.normal(0, 0.1)  # Add Gaussian noise\n                individual[i] = np.clip(individual[i], func.bounds.lb, func.bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            # Selection (Tournament Selection)\n            indices = np.random.choice(self.pop_size, size=2, replace=False)\n            parent1_idx, parent2_idx = indices[0], indices[1]\n            parent1 = population[parent1_idx]\n            parent2 = population[parent2_idx]\n            \n            # Crossover\n            child1, child2 = self.crossover(parent1, parent2)\n\n            # Mutation\n            child1 = self.mutate(child1, func)\n            child2 = self.mutate(child2, func)\n\n            # Evaluation\n            f_child1 = func(child1)\n            f_child2 = func(child2)\n            eval_count += 2\n\n            # Acceptance (Simulated Annealing)\n            for i, (child, f_child) in enumerate([(child1, f_child1), (child2, f_child2)]):\n                if f_child < np.max(fitness):\n                    max_fitness_idx = np.argmax(fitness)\n                    if np.random.rand() < np.exp(-(f_child - fitness[max_fitness_idx]) / self.temperature):\n                      \n                        population[max_fitness_idx] = child\n                        fitness[max_fitness_idx] = f_child\n\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n            \n            self.temperature *= self.temperature_decay\n            if eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm that combines aspects of Genetic Algorithms and Simulated Annealing, where individuals undergo crossover and mutation, with an acceptance probability inspired by the Metropolis criterion.\n# Code: \n```python\nimport numpy as np\n\nclass GeneticAnnealing:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.8, temperature_decay=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.temperature_decay = temperature_decay\n        self.temperature = 1.0\n\n    def initialize_population(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        return population, fitness\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n            return child1, child2\n        else:\n            return parent1, parent2\n\n    def mutate(self, individual, func):\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                individual[i] += np.random.normal(0, 0.1)  # Add Gaussian noise\n                individual[i] = np.clip(individual[i], func.bounds.lb, func.bounds.ub)\n        return individual\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        population, fitness = self.initialize_population(func)\n        eval_count += self.pop_size\n\n        while eval_count < self.budget:\n            # Selection (Tournament Selection)\n            indices = np.random.choice(self.pop_size, size=2, replace=False)\n            parent1_idx, parent2_idx = indices[0], indices[1]\n            parent1 = population[parent1_idx]\n            parent2 = population[parent2_idx]\n            \n            # Crossover\n            child1, child2 = self.crossover(parent1, parent2)\n\n            # Mutation\n            child1 = self.mutate(child1, func)\n            child2 = self.mutate(child2, func)\n\n            # Evaluation\n            f_child1 = func(child1)\n            f_child2 = func(child2)\n            eval_count += 2\n\n            # Acceptance (Simulated Annealing)\n            for i, (child, f_child) in enumerate([(child1, f_child1), (child2, f_child2)]):\n                if f_child < np.max(fitness):\n                    max_fitness_idx = np.argmax(fitness)\n                    if np.random.rand() < np.exp(-(f_child - fitness[max_fitness_idx]) / self.temperature):\n                      \n                        population[max_fitness_idx] = child\n                        fitness[max_fitness_idx] = f_child\n\n                if f_child < self.f_opt:\n                    self.f_opt = f_child\n                    self.x_opt = child\n            \n            self.temperature *= self.temperature_decay\n            if eval_count >= self.budget:\n                break\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.2581800198838095, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "5fa4b3d4-4bee-4179-bfdd-90c232b4253d", "fitness": 0.5193046009709739, "name": "HybridAdaptivePSO_DE", "description": "Combines adaptive velocity PSO with adaptive DE, using PSO for exploration and DE for exploitation, while dynamically adjusting parameters and switching between algorithms based on performance metrics.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9, pso_frequency=0.75):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_frequency = pso_frequency  # Probability of running PSO in an iteration\n        self.pso_success_rate = 0.5 # adaptive probability\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.pso_successes = 0\n        self.pso_trials = 0\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < adapted_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                pso_improved = self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.pso_trials > 10:\n                self.pso_success_rate = self.pso_successes / self.pso_trials\n                self.pso_trials = 0\n                self.pso_successes = 0\n                self.pso_frequency = min(1.0, self.pso_frequency * (1.0 + 0.1 * (self.pso_success_rate - 0.5)))\n                #self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.519 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1378fc4-63d2-4b4f-a616-637534fafb35", "8f3ca0fd-e75c-486c-b26a-a1870c1181e1"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive velocity PSO with adaptive DE, using PSO for exploration and DE for exploitation, while dynamically adjusting parameters and switching between algorithms based on performance metrics.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9, pso_frequency=0.75):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_frequency = pso_frequency  # Probability of running PSO in an iteration\n        self.pso_success_rate = 0.5 # adaptive probability\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.pso_successes = 0\n        self.pso_trials = 0\n\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < adapted_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                pso_improved = self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.pso_trials > 10:\n                self.pso_success_rate = self.pso_successes / self.pso_trials\n                self.pso_trials = 0\n                self.pso_successes = 0\n                self.pso_frequency = min(1.0, self.pso_frequency * (1.0 + 0.1 * (self.pso_success_rate - 0.5)))\n                #self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19198831539353167, 0.41968226237322004, 0.4908818801048993, 0.9138959867005483, 0.41699758967472833, 0.532929142361483, 0.32796946642120817, 0.43028063708639774, 0.5419930779144453, 0.20153888960765887, 0.8804580001590818, 0.9973731817592199, 0.2958502159469697, 0.47447461831335924, 0.8550024081583375, 0.5888571204635589, 0.4055675615404781, 0.7043558760097042, 0.21154787690559984, 0.504447912525047], "operator": "crossover", "theta_sampled": 0.19421288772055648, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "b1cb184a-8852-4c9f-8ade-ae52adf2661c", "fitness": 0.31089667497544876, "name": "CurvatureAdaptiveOptimizer", "description": "Population-based algorithm with adaptive step size control based on fitness landscape curvature estimation.", "code": "import numpy as np\n\nclass CurvatureAdaptiveOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, curvature_window=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.curvature_window = curvature_window  # How many past fitness values to consider for curvature estimation\n        self.x_history = []\n        self.f_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        indices = np.argsort(self.fitness)\n        self.population = self.population[indices]\n        self.fitness = self.fitness[indices]\n        \n        if self.fitness[0] < self.f_opt:\n            self.f_opt = self.fitness[0]\n            self.x_opt = self.population[0].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Create a noisy copy of the current individual\n                x_new = self.population[i] + self.step_size * np.random.normal(0, 1, size=self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                \n                f_new = func(x_new)\n                self.budget -= 1\n                \n                if f_new < self.fitness[i]:\n                    self.population[i] = x_new.copy()\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n\n            # Adaptive Step Size Control:\n            if len(self.f_history) >= self.curvature_window:\n                # Estimate curvature based on the recent fitness history.\n                recent_fitness = np.array(self.f_history[-self.curvature_window:])\n                curvature = np.var(recent_fitness) # Simplified curvature proxy\n                \n                # Adjust step size based on curvature. Higher curvature -> smaller step.\n                self.step_size = min(0.5, self.step_size * (1 - 0.5 * curvature)) # Reduce step size if curvature is high\n            else:\n                 self.step_size = min(0.5, self.step_size*1.05) # increase step size if not enough history to measure curvature\n\n\n            self.x_history.append(self.x_opt)\n            self.f_history.append(self.f_opt)\n\n            indices = np.argsort(self.fitness)\n            self.population = self.population[indices]\n            self.fitness = self.fitness[indices]\n                    \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm CurvatureAdaptiveOptimizer scored 0.311 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive step size control based on fitness landscape curvature estimation.\n# Code: \n```python\nimport numpy as np\n\nclass CurvatureAdaptiveOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, curvature_window=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.curvature_window = curvature_window  # How many past fitness values to consider for curvature estimation\n        self.x_history = []\n        self.f_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        indices = np.argsort(self.fitness)\n        self.population = self.population[indices]\n        self.fitness = self.fitness[indices]\n        \n        if self.fitness[0] < self.f_opt:\n            self.f_opt = self.fitness[0]\n            self.x_opt = self.population[0].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Create a noisy copy of the current individual\n                x_new = self.population[i] + self.step_size * np.random.normal(0, 1, size=self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n                \n                f_new = func(x_new)\n                self.budget -= 1\n                \n                if f_new < self.fitness[i]:\n                    self.population[i] = x_new.copy()\n                    self.fitness[i] = f_new\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new.copy()\n\n            # Adaptive Step Size Control:\n            if len(self.f_history) >= self.curvature_window:\n                # Estimate curvature based on the recent fitness history.\n                recent_fitness = np.array(self.f_history[-self.curvature_window:])\n                curvature = np.var(recent_fitness) # Simplified curvature proxy\n                \n                # Adjust step size based on curvature. Higher curvature -> smaller step.\n                self.step_size = min(0.5, self.step_size * (1 - 0.5 * curvature)) # Reduce step size if curvature is high\n            else:\n                 self.step_size = min(0.5, self.step_size*1.05) # increase step size if not enough history to measure curvature\n\n\n            self.x_history.append(self.x_opt)\n            self.f_history.append(self.f_opt)\n\n            indices = np.argsort(self.fitness)\n            self.population = self.population[indices]\n            self.fitness = self.fitness[indices]\n                    \n        return self.f_opt, self.x_opt\n```", "aucs": [0.10670377029183509, 0.08702920100075806, 0.3783844337096629, 0.43569359403827124, 0.1717244533969564, 0.17215294542578918, 0.26039778670008185, 0.14848107990929893, 0.17358288400373345, 0.15029749368265, 0.3765371465269457, 0.8450736371064437, 0.30437339137435804, 0.14253230776419146, 0.7449733990539344, 0.34473519273502584, 0.26014483018531287, 0.43846935500679785, 0.21608320443130902, 0.4605633931656177], "operator": "random_new", "theta_sampled": 0.1265849929146244, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "8922a96f-d9ad-4a5a-82b4-567075f7c6e7", "fitness": 0.5566596909400614, "name": "HybridAdaptivePSO_DE", "description": "Dynamically fuses Adaptive Velocity Particle Swarm with Adaptive Differential Evolution, adjusting algorithm weights based on performance feedback and remaining budget.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1, F=0.5, CR=0.9, pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = 10 # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Adaptive weighting\n                if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                    avg_pso_success = np.mean(self.pso_success_history)\n                    avg_de_success = np.mean(self.de_success_history)\n                    if avg_pso_success + avg_de_success > 0:\n                        self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                        self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                    else:\n                        self.pso_weight = 0.5\n                        self.de_weight = 0.5\n\n\n                # PSO update\n                if np.random.rand() < self.pso_weight:\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n                    \n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success +=1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                # DE update\n                else:\n                    remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                    adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                    adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_to_replace] = population[i].copy()\n                        self.de_success += 1\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the population\n            population = new_population\n            fitness = new_fitness\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.557 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1378fc4-63d2-4b4f-a616-637534fafb35", "8f3ca0fd-e75c-486c-b26a-a1870c1181e1"], "operator": "crossover", "metadata": {"llm_response": "# Description: Dynamically fuses Adaptive Velocity Particle Swarm with Adaptive Differential Evolution, adjusting algorithm weights based on performance feedback and remaining budget.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1, F=0.5, CR=0.9, pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = 10 # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Adaptive weighting\n                if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                    avg_pso_success = np.mean(self.pso_success_history)\n                    avg_de_success = np.mean(self.de_success_history)\n                    if avg_pso_success + avg_de_success > 0:\n                        self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                        self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                    else:\n                        self.pso_weight = 0.5\n                        self.de_weight = 0.5\n\n\n                # PSO update\n                if np.random.rand() < self.pso_weight:\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n                    \n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success +=1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                # DE update\n                else:\n                    remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                    adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                    adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_to_replace] = population[i].copy()\n                        self.de_success += 1\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the population\n            population = new_population\n            fitness = new_fitness\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19275078732318163, 0.40412047783726923, 0.4823980102245966, 0.8673763306030546, 0.4392374198176111, 0.5748773132645114, 0.4284070289835047, 0.463389318140637, 0.5115577956385762, 0.591899159601017, 0.8441661828608034, 0.9990055259463674, 0.3554578986890422, 0.5108200582561375, 0.9254973926677235, 0.6365049360710073, 0.44209224130211444, 0.6876808144276395, 0.2535242446908874, 0.5224308824555441], "operator": "crossover", "theta_sampled": 0.09087459095685169, "reward": 0.028235058962142068, "generation": 1}, "task_prompt": ""}
{"id": "2bc37f4b-33aa-41ba-b030-d8f0a5ac530e", "fitness": 0.0, "name": "CauchyAdaptation", "description": "A population-based algorithm that adaptively adjusts its exploration-exploitation balance using a Cauchy mutation operator and a shrinking search space.", "code": "import numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        step_size = self.initial_step_size * (ub - lb)\n        shrinkage_rate = 0.99 #Rate at which the search space shrinks\n\n        while self.budget > 0:\n            # Generate Cauchy mutations for each individual\n            mutations = np.random.standard_cauchy(size=(self.pop_size, self.dim)) * step_size\n\n            # Apply mutations to create offspring\n            offspring = population + mutations\n\n            # Clip offspring to stay within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size # Update budget\n\n            # Selection: Replace parents with better offspring\n            improved = offspring_fitness < fitness\n            population[improved] = offspring[improved]\n            fitness[improved] = offspring_fitness[improved]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            #Shrink the search space\n            lb = np.maximum(lb, self.x_opt - shrinkage_rate*(ub-lb)/2)\n            ub = np.minimum(ub, self.x_opt + shrinkage_rate*(ub-lb)/2)\n            \n            #Dynamically adjust the step size\n            step_size = step_size * shrinkage_rate\n            \n            if step_size < 1e-6:\n                step_size = self.initial_step_size * (ub - lb) #Reset step size\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that adaptively adjusts its exploration-exploitation balance using a Cauchy mutation operator and a shrinking search space.\n# Code: \n```python\nimport numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population within bounds\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size  # Update budget\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        step_size = self.initial_step_size * (ub - lb)\n        shrinkage_rate = 0.99 #Rate at which the search space shrinks\n\n        while self.budget > 0:\n            # Generate Cauchy mutations for each individual\n            mutations = np.random.standard_cauchy(size=(self.pop_size, self.dim)) * step_size\n\n            # Apply mutations to create offspring\n            offspring = population + mutations\n\n            # Clip offspring to stay within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Evaluate offspring fitness\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size # Update budget\n\n            # Selection: Replace parents with better offspring\n            improved = offspring_fitness < fitness\n            population[improved] = offspring[improved]\n            fitness[improved] = offspring_fitness[improved]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n            \n            #Shrink the search space\n            lb = np.maximum(lb, self.x_opt - shrinkage_rate*(ub-lb)/2)\n            ub = np.minimum(ub, self.x_opt + shrinkage_rate*(ub-lb)/2)\n            \n            #Dynamically adjust the step size\n            step_size = step_size * shrinkage_rate\n            \n            if step_size < 1e-6:\n                step_size = self.initial_step_size * (ub - lb) #Reset step size\n            \n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.15124872981007365, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "b65667a2-5249-46c7-b457-5a1ea682681e", "fitness": 0.3944655933748441, "name": "HybridAdaptivePSO_DE", "description": "A hybrid algorithm combining adaptive velocity particle swarm optimization with differential evolution mutation and crossover for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.9, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal bests and global best\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive exploration\n                if np.random.rand() < self.exploration_rate:\n                    # Explore a random direction\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                else:\n                    # Standard PSO velocity update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                    social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                    velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                    velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Apply DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Adaptive Parameter Control\n                remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                mutant = x1 + adapted_F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                crossover_mask = np.random.rand(self.dim) < adapted_CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluate new position\n                f = func(trial_vector)\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = trial_vector.copy()\n                    population[i] = trial_vector.copy() # Update population if trial is better\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.394 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1378fc4-63d2-4b4f-a616-637534fafb35", "8f3ca0fd-e75c-486c-b26a-a1870c1181e1"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining adaptive velocity particle swarm optimization with differential evolution mutation and crossover for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.9, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal bests and global best\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adaptive exploration\n                if np.random.rand() < self.exploration_rate:\n                    # Explore a random direction\n                    velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                else:\n                    # Standard PSO velocity update\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                    social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                    velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                    velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Apply DE mutation and crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Adaptive Parameter Control\n                remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                mutant = x1 + adapted_F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                crossover_mask = np.random.rand(self.dim) < adapted_CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluate new position\n                f = func(trial_vector)\n                self.budget -= 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = trial_vector.copy()\n                    population[i] = trial_vector.copy() # Update population if trial is better\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16980966385719254, 0.2699628417997385, 0.38587074718310554, 0.5032797564871407, 0.31517757106656497, 0.4031218040950151, 0.29854095417657245, 0.34323634213788756, 0.30250783494556, 0.26828909585757754, 0.4283798821405248, 0.9965766355573116, 0.29105826230668697, 0.30173402694637375, 0.7446230638150383, 0.3740062248204733, 0.32257032616891723, 0.4844381420880659, 0.19504418456119665, 0.49108450748593857], "operator": "crossover", "theta_sampled": 0.014900718167402028, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "2384ebfe-60a9-4e08-a226-ca277fdec67d", "fitness": 0.5568219305253449, "name": "HybridAdaptivePSO_DE", "description": "Adaptively combines Particle Swarm Optimization's exploration with Differential Evolution's exploitation, using a dynamic switch to balance the two strategies based on budget and performance.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.7, pso_exploration_rate=0.1, switch_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob # Probability of switching between PSO and DE\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"  # Start with PSO\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n\n\n            if self.budget <= 0:\n                break\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Adaptive Strategy Switching\n            if np.random.rand() < self.switch_prob:\n                self.current_strategy = \"DE\" if self.current_strategy == \"PSO\" else \"PSO\"\n\n            if self.current_strategy == \"PSO\":\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.557 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["b1378fc4-63d2-4b4f-a616-637534fafb35", "8f3ca0fd-e75c-486c-b26a-a1870c1181e1"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines Particle Swarm Optimization's exploration with Differential Evolution's exploitation, using a dynamic switch to balance the two strategies based on budget and performance.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.7, pso_exploration_rate=0.1, switch_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob # Probability of switching between PSO and DE\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"  # Start with PSO\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n\n\n            if self.budget <= 0:\n                break\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Adaptive Strategy Switching\n            if np.random.rand() < self.switch_prob:\n                self.current_strategy = \"DE\" if self.current_strategy == \"PSO\" else \"PSO\"\n\n            if self.current_strategy == \"PSO\":\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2120216853303285, 0.32429032117679657, 0.4734063751597719, 0.8985026650471434, 0.6152379212868246, 0.5289901101488198, 0.31769226812096063, 0.5067717861994991, 0.4261561748488192, 0.46633462162315187, 0.7758016485101549, 0.9963068754012122, 0.2975740867191178, 0.48664044316113486, 0.8574856363809941, 0.8060041678844574, 0.5610029735288682, 0.6838374579348226, 0.3853710808051155, 0.5170103112389056], "operator": "crossover", "theta_sampled": 0.005847968516992046, "reward": 0.028397298547425565, "generation": 1}, "task_prompt": ""}
{"id": "66536d53-6e28-4bce-b209-60a09a823d39", "fitness": 0.41795498715267837, "name": "HybridAdaptivePSO_DE", "description": "Integrates PSO and DE with dynamic parameter adaptation based on performance feedback and a simplified parameter adaptation strategy for DE.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.pso_frequency = 0.5  # Probability of running PSO in an iteration\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.pso_successes = 0\n        self.pso_trials = 0\n        self.de_successes = 0\n        self.de_trials = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        self.de_trials += 1\n        improved = False\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                self.de_successes += 1\n                improved = True\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n        return improved\n\n    def update_parameters(self):\n        if self.pso_trials > 10 and self.de_trials > 10:\n            pso_success_rate = self.pso_successes / self.pso_trials\n            de_success_rate = self.de_successes / self.de_trials\n\n            # Adjust PSO frequency based on relative success\n            self.pso_frequency = 0.5 + 0.3 * (pso_success_rate - de_success_rate)\n            self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)  # Keep frequency within bounds\n\n            # Reset counters\n            self.pso_trials = 0\n            self.pso_successes = 0\n            self.de_trials = 0\n            self.de_successes = 0\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n            self.update_parameters()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridAdaptivePSO_DE scored 0.418 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5fa4b3d4-4bee-4179-bfdd-90c232b4253d"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates PSO and DE with dynamic parameter adaptation based on performance feedback and a simplified parameter adaptation strategy for DE.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.pso_frequency = 0.5  # Probability of running PSO in an iteration\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.pso_successes = 0\n        self.pso_trials = 0\n        self.de_successes = 0\n        self.de_trials = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        self.de_trials += 1\n        improved = False\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                self.de_successes += 1\n                improved = True\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n        return improved\n\n    def update_parameters(self):\n        if self.pso_trials > 10 and self.de_trials > 10:\n            pso_success_rate = self.pso_successes / self.pso_trials\n            de_success_rate = self.de_successes / self.de_trials\n\n            # Adjust PSO frequency based on relative success\n            self.pso_frequency = 0.5 + 0.3 * (pso_success_rate - de_success_rate)\n            self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)  # Keep frequency within bounds\n\n            # Reset counters\n            self.pso_trials = 0\n            self.pso_successes = 0\n            self.de_trials = 0\n            self.de_successes = 0\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n            self.update_parameters()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10849456293467952, 0.34770865615933355, 0.45298022636789936, 0.2889348264622297, 0.4588460017336402, 0.5089413462676239, 0.32838923400900666, 0.3942344296779602, 0.37765458985504263, 0.21013825996985336, 0.8879945364977762, 0.9983225655712149, 0.30420636342075225, 0.25615036293576754, 0.661838816311572, 0.34895112158436037, 0.36890681333139386, 0.34498036384324227, 0.21215782555817309, 0.49926884056204557], "operator": "mutation", "theta_sampled": 0.11693063481990405, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "0ed8bf31-2d46-4013-a788-cedbc6126450", "fitness": 0.0, "name": "AdaptiveHybridPSO_DERestart", "description": "Integrates PSO and DE with adaptive parameter control and a restart mechanism triggered by stagnation to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9, pso_frequency=0.75, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_frequency = pso_frequency  # Probability of running PSO in an iteration\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.pso_success_rate = 0.5\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pso_successes = 0\n        self.pso_trials = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < adapted_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) > self.stagnation_threshold:\n            if np.abs(self.best_fitness_history[-1] - np.mean(self.best_fitness_history[-self.stagnation_threshold:])) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter > self.stagnation_threshold // 2:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n\n        if self.personal_best_fitness[global_best_index] < self.f_opt:\n            self.f_opt = self.personal_best_fitness[global_best_index].copy()\n            self.x_opt = self.global_best_position.copy()\n\n        self.best_fitness_history.clear()\n        self.best_fitness_history.append(self.f_opt)\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                pso_improved = self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.pso_trials > 10:\n                self.pso_success_rate = self.pso_successes / self.pso_trials\n                self.pso_trials = 0\n                self.pso_successes = 0\n                self.pso_frequency = min(1.0, self.pso_frequency * (1.0 + 0.1 * (self.pso_success_rate - 0.5)))\n                #self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            if self.check_stagnation():\n                self.restart(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DERestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["5fa4b3d4-4bee-4179-bfdd-90c232b4253d"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates PSO and DE with adaptive parameter control and a restart mechanism triggered by stagnation to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_F=0.5, de_CR=0.9, pso_frequency=0.75, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_F = de_F\n        self.de_CR = de_CR\n        self.archive_size = int(self.pop_size * 0.2)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_frequency = pso_frequency  # Probability of running PSO in an iteration\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.pso_success_rate = 0.5\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pso_successes = 0\n        self.pso_trials = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n        self.budget -= self.pop_size\n\n    def pso_step(self, func):\n        self.pso_trials += 1\n        improved = False\n        for i in range(self.pop_size):\n            if np.random.rand() < self.exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.pso_successes += 1\n                improved = True\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            if self.budget <= 0:\n                break\n        return improved\n\n    def de_step(self, func):\n        for i in range(self.pop_size):\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < adapted_CR\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n            if f_trial < self.fitness[i]:\n                if len(self.archive) < self.archive_size:\n                    self.archive.append(self.population[i].copy())\n                else:\n                    idx_to_replace = np.random.randint(0, self.archive_size)\n                    self.archive[idx_to_replace] = self.population[i].copy()\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n\n            if self.budget <= 0:\n                break\n\n    def check_stagnation(self):\n        if len(self.best_fitness_history) > self.stagnation_threshold:\n            if np.abs(self.best_fitness_history[-1] - np.mean(self.best_fitness_history[-self.stagnation_threshold:])) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n        \n        if self.stagnation_counter > self.stagnation_threshold // 2:\n            return True\n        return False\n\n    def restart(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n\n        if self.personal_best_fitness[global_best_index] < self.f_opt:\n            self.f_opt = self.personal_best_fitness[global_best_index].copy()\n            self.x_opt = self.global_best_position.copy()\n\n        self.best_fitness_history.clear()\n        self.best_fitness_history.append(self.f_opt)\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        self.initialize(func)\n\n        while self.budget > 0:\n            if np.random.rand() < self.pso_frequency:\n                pso_improved = self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.pso_trials > 10:\n                self.pso_success_rate = self.pso_successes / self.pso_trials\n                self.pso_trials = 0\n                self.pso_successes = 0\n                self.pso_frequency = min(1.0, self.pso_frequency * (1.0 + 0.1 * (self.pso_success_rate - 0.5)))\n                #self.pso_frequency = np.clip(self.pso_frequency, 0.1, 0.9)\n            \n            self.best_fitness_history.append(self.f_opt)\n\n            if self.check_stagnation():\n                self.restart(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.04169776400424521, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "6f8154de-a636-46fe-817e-4dd8b4dae61f", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that dynamically adjusts its parameters based on the function evaluations, using a restart strategy with increasing population size.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_factor = mu_factor\n        self.restart_factor = 2  # Factor to increase population size on restart\n        self.min_popsize = 4\n        self.cs = 0.3  # Learning rate for step-size control\n        self.ccum = 0.4 # Learning rate for mean\n        self.cov_learning_rate = 0.5\n        self.damps = 1 + self.cs # Damping for step-size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        popsize = self.min_popsize\n\n        while evals < self.budget:\n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n\n            mu = int(popsize * self.mu_factor)\n            weights = np.log(popsize + 1) - np.log(np.arange(1, popsize + 1))\n            weights = weights / np.sum(weights)\n\n            success_history = []\n            success_threshold = 0.2\n\n            while evals < self.budget:\n                # Generate and evaluate offspring\n                z = np.random.randn(self.dim, popsize)\n                x = mean[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                f = np.array([func(x[:, i]) for i in range(popsize)])\n                evals += popsize\n\n                # Sort by fitness\n                idx = np.argsort(f)\n                x = x[:, idx]\n                f = f[idx]\n\n                # Update optimal solution\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[:, 0]\n\n                # Update mean\n                mean_diff = x[:, :mu] - mean[:, np.newaxis]\n                mean = mean + self.ccum * np.sum(weights[:mu] * mean_diff, axis=1)\n\n\n                # Update step-size (sigma)\n                sigma = sigma * np.exp((self.cs / self.damps) * (np.mean(np.linalg.norm(z[:, :mu], axis=0)) - np.sqrt(self.dim)))\n\n                # Update covariance matrix\n                z_weighted = z[:, :mu] * weights[:mu]\n                C = (1 - self.cov_learning_rate) * C + self.cov_learning_rate * np.dot(z_weighted, z_weighted.T)\n\n                # Check termination condition (e.g., stagnation)\n                if np.std(f) < 1e-6:\n                    break\n\n                success_history.append(f[0] < np.median(f))\n                if len(success_history) > 10:\n                    success_rate = np.mean(success_history[-10:])\n                    if success_rate < success_threshold:\n                        break\n\n\n            # Restart with increased population size\n            popsize = int(popsize * self.restart_factor)\n            if popsize > self.budget/2:\n               popsize = self.min_popsize # prevent increasing popsize to large numbers.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (2,4) (2,) (2,) ", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that dynamically adjusts its parameters based on the function evaluations, using a restart strategy with increasing population size.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, mu_factor=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mu_factor = mu_factor\n        self.restart_factor = 2  # Factor to increase population size on restart\n        self.min_popsize = 4\n        self.cs = 0.3  # Learning rate for step-size control\n        self.ccum = 0.4 # Learning rate for mean\n        self.cov_learning_rate = 0.5\n        self.damps = 1 + self.cs # Damping for step-size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        popsize = self.min_popsize\n\n        while evals < self.budget:\n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.initial_sigma\n            C = np.eye(self.dim)  # Covariance matrix\n\n            mu = int(popsize * self.mu_factor)\n            weights = np.log(popsize + 1) - np.log(np.arange(1, popsize + 1))\n            weights = weights / np.sum(weights)\n\n            success_history = []\n            success_threshold = 0.2\n\n            while evals < self.budget:\n                # Generate and evaluate offspring\n                z = np.random.randn(self.dim, popsize)\n                x = mean[:, np.newaxis] + sigma * np.dot(np.linalg.cholesky(C), z)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                f = np.array([func(x[:, i]) for i in range(popsize)])\n                evals += popsize\n\n                # Sort by fitness\n                idx = np.argsort(f)\n                x = x[:, idx]\n                f = f[idx]\n\n                # Update optimal solution\n                if f[0] < self.f_opt:\n                    self.f_opt = f[0]\n                    self.x_opt = x[:, 0]\n\n                # Update mean\n                mean_diff = x[:, :mu] - mean[:, np.newaxis]\n                mean = mean + self.ccum * np.sum(weights[:mu] * mean_diff, axis=1)\n\n\n                # Update step-size (sigma)\n                sigma = sigma * np.exp((self.cs / self.damps) * (np.mean(np.linalg.norm(z[:, :mu], axis=0)) - np.sqrt(self.dim)))\n\n                # Update covariance matrix\n                z_weighted = z[:, :mu] * weights[:mu]\n                C = (1 - self.cov_learning_rate) * C + self.cov_learning_rate * np.dot(z_weighted, z_weighted.T)\n\n                # Check termination condition (e.g., stagnation)\n                if np.std(f) < 1e-6:\n                    break\n\n                success_history.append(f[0] < np.median(f))\n                if len(success_history) > 10:\n                    success_rate = np.mean(success_history[-10:])\n                    if success_rate < success_threshold:\n                        break\n\n\n            # Restart with increased population size\n            popsize = int(popsize * self.restart_factor)\n            if popsize > self.budget/2:\n               popsize = self.min_popsize # prevent increasing popsize to large numbers.\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.03041995118650624, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "18151642-c8f0-4e17-8eb2-e2b31f0b6852", "fitness": 0.5756813361355502, "name": "AdaptiveHybridPSO_DE", "description": "Dynamically adapts PSO and DE based on their recent success and adjusts DE parameters based on remaining budget.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight=0.5, de_weight=0.5, success_memory=10, archive_size_factor=0.2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: Dynamically adapts PSO and DE based on their recent success and adjusts DE parameters based on remaining budget.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight=0.5, de_weight=0.5, success_memory=10, archive_size_factor=0.2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19229638107777502, 0.4196842147292503, 0.5573696707634439, 0.8197926666990877, 0.6706876787287678, 0.5995286129589098, 0.39521412594016214, 0.4287459074821912, 0.6209166784186286, 0.489834344796102, 0.7922356601076797, 0.9943121157015149, 0.47022995563092596, 0.5419850358878484, 0.9181171869970842, 0.699818490985887, 0.4451038120520091, 0.7252253998595268, 0.22778012054391117, 0.5047486633502964], "operator": "crossover", "theta_sampled": 0.011017855914036843, "reward": 0.01885940561020527, "generation": 2}, "task_prompt": ""}
{"id": "828f3959-a255-4d9d-b24c-159690107628", "fitness": 0.27499240521538826, "name": "GradientEnhancedPopulationSearch", "description": "A population-based algorithm that dynamically adjusts step size and search direction based on gradient estimation and population diversity.", "code": "import numpy as np\n\nclass GradientEnhancedPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, grad_estim_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.grad_estim_samples = grad_estim_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Gradient estimation for each individual\n            gradients = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                grad_est = np.zeros(self.dim)\n                for _ in range(self.grad_estim_samples):\n                    delta = np.random.normal(0, self.step_size, self.dim)\n                    x_neighbor = np.clip(population[i] + delta, self.lb, self.ub)\n                    if self.budget > 0:\n                      f_neighbor = func(x_neighbor)\n                      self.budget -= 1\n                      grad_est += (f_neighbor - fitness[i]) * delta\n                gradients[i] = grad_est / self.grad_estim_samples\n\n            # Update population based on gradient and population diversity\n            for i in range(self.pop_size):\n                # Direction based on gradient and towards the best individual\n                direction = -gradients[i] + (self.x_opt - population[i]) * 0.5  # Attraction to the best\n                direction /= (np.linalg.norm(direction) + 1e-8) # Normalize\n\n                # Adaptive step size based on population diversity\n                diversity = np.std(population, axis=0).mean() # Mean standard deviation across dimensions\n                adaptive_step_size = self.step_size * (1 + diversity)\n\n                # Update individual\n                new_x = population[i] + adaptive_step_size * direction\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Evaluate new individual\n                if self.budget > 0:\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    # Update population and best solution if improved\n                    if new_f < fitness[i]:\n                        population[i] = new_x\n                        fitness[i] = new_f\n\n                        if new_f < self.f_opt:\n                            self.f_opt = new_f\n                            self.x_opt = new_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm GradientEnhancedPopulationSearch scored 0.275 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that dynamically adjusts step size and search direction based on gradient estimation and population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass GradientEnhancedPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, grad_estim_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.grad_estim_samples = grad_estim_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Gradient estimation for each individual\n            gradients = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                grad_est = np.zeros(self.dim)\n                for _ in range(self.grad_estim_samples):\n                    delta = np.random.normal(0, self.step_size, self.dim)\n                    x_neighbor = np.clip(population[i] + delta, self.lb, self.ub)\n                    if self.budget > 0:\n                      f_neighbor = func(x_neighbor)\n                      self.budget -= 1\n                      grad_est += (f_neighbor - fitness[i]) * delta\n                gradients[i] = grad_est / self.grad_estim_samples\n\n            # Update population based on gradient and population diversity\n            for i in range(self.pop_size):\n                # Direction based on gradient and towards the best individual\n                direction = -gradients[i] + (self.x_opt - population[i]) * 0.5  # Attraction to the best\n                direction /= (np.linalg.norm(direction) + 1e-8) # Normalize\n\n                # Adaptive step size based on population diversity\n                diversity = np.std(population, axis=0).mean() # Mean standard deviation across dimensions\n                adaptive_step_size = self.step_size * (1 + diversity)\n\n                # Update individual\n                new_x = population[i] + adaptive_step_size * direction\n                new_x = np.clip(new_x, self.lb, self.ub)\n\n                # Evaluate new individual\n                if self.budget > 0:\n                    new_f = func(new_x)\n                    self.budget -= 1\n\n                    # Update population and best solution if improved\n                    if new_f < fitness[i]:\n                        population[i] = new_x\n                        fitness[i] = new_f\n\n                        if new_f < self.f_opt:\n                            self.f_opt = new_f\n                            self.x_opt = new_x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.0809890787704558, 0.1602491027969699, 0.37862761327667127, 0.17113893469224783, 0.17815993326391422, 0.17335253891241242, 0.2264398669246317, 0.14137556666679463, 0.18617200878806406, 0.14354995766419998, 0.3689657958161898, 0.9867086698524514, 0.32374947985739977, 0.15605338613950825, 0.5224320715979278, 0.2550723546848219, 0.22239153174969684, 0.2661012673174675, 0.12988536171948728, 0.428433583816452], "operator": "random_new", "theta_sampled": 0.2171390961529646, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "162a8d63-dd69-484e-b20c-ca59a99035e3", "fitness": 0.7342799744009025, "name": "AdaptiveHybridPSO_DE", "description": "An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSO_DE scored 0.734 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: An adaptive hybrid PSO-DE algorithm with success-based parameter adaptation, archive utilization, and dynamic strategy selection based on performance feedback.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.37717489583923547, 0.7485584900826626, 0.7794829481157071, 0.8804095412024632, 0.8215762396500277, 0.8453933883368048, 0.5914048269786178, 0.7577094841970708, 0.8207214412116675, 0.8020313547327237, 0.8964030379046536, 0.9993926563741286, 0.44780283860518744, 0.7747087663335395, 0.9603433732144111, 0.8440558130931847, 0.694529420749078, 0.8984401085311924, 0.2103651453487846, 0.5350957175169124], "operator": "crossover", "theta_sampled": 0.02322416725178006, "reward": 0.17745804387555764, "generation": 2}, "task_prompt": ""}
{"id": "c2a7edac-24af-4331-9b96-f0b50d5085ea", "fitness": 0.48448575301173175, "name": "AdaptiveHybridPSODE", "description": "Adaptive hybrid PSO-DE algorithm with a success-history-based adaptation of PSO and DE weights, dynamically adjusted DE parameters, and a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1, F=0.5, CR=0.9, pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10, restart_prob=0.01):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total number of function evaluations allowed.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Probability of exploration in PSO.\n            F (float): Mutation factor for DE.\n            CR (float): Crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            archive_size_factor (float): Factor to determine the size of the archive for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            restart_prob (float): Probability of restarting the population to escape local optima.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best fitness value found and the corresponding solution.\n        \"\"\"\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Adaptive weighting\n                if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                    avg_pso_success = np.mean(self.pso_success_history)\n                    avg_de_success = np.mean(self.de_success_history)\n                    if avg_pso_success + avg_de_success > 0:\n                        self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                        self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                    else:\n                        self.pso_weight = 0.5\n                        self.de_weight = 0.5\n\n\n                # PSO update\n                if np.random.rand() < self.pso_weight:\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n                    \n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success +=1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                # DE update\n                else:\n                    remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                    adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                    adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_to_replace] = population[i].copy()\n                        self.de_success += 1\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the population\n            population = new_population\n            fitness = new_fitness\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size # Account for new function evaluations\n                velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_index = np.argmin(fitness)\n                global_best_position = population[best_index].copy()\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = global_best_position.copy()\n\n\n            iteration += 1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveHybridPSODE scored 0.484 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive hybrid PSO-DE algorithm with a success-history-based adaptation of PSO and DE weights, dynamically adjusted DE parameters, and a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1, F=0.5, CR=0.9, pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10, restart_prob=0.01):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total number of function evaluations allowed.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Probability of exploration in PSO.\n            F (float): Mutation factor for DE.\n            CR (float): Crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            archive_size_factor (float): Factor to determine the size of the archive for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            restart_prob (float): Probability of restarting the population to escape local optima.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_F = 0.1\n        self.max_F = 0.9\n        self.min_CR = 0.1\n        self.max_CR = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best fitness value found and the corresponding solution.\n        \"\"\"\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n            \n            for i in range(self.pop_size):\n                # Adaptive weighting\n                if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                    avg_pso_success = np.mean(self.pso_success_history)\n                    avg_de_success = np.mean(self.de_success_history)\n                    if avg_pso_success + avg_de_success > 0:\n                        self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                        self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                    else:\n                        self.pso_weight = 0.5\n                        self.de_weight = 0.5\n\n\n                # PSO update\n                if np.random.rand() < self.pso_weight:\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n                    \n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success +=1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                # DE update\n                else:\n                    remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n                    adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n                    adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio # Linearly scale CR\n\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, self.archive_size)\n                            self.archive[idx_to_replace] = population[i].copy()\n                        self.de_success += 1\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the population\n            population = new_population\n            fitness = new_fitness\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size # Account for new function evaluations\n                velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_index = np.argmin(fitness)\n                global_best_position = population[best_index].copy()\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = global_best_position.copy()\n\n\n            iteration += 1\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1903387154886037, 0.2853110374098563, 0.34925945339285114, 0.8916217569311055, 0.3414633123296227, 0.5516091410987845, 0.3177217857385993, 0.36103953110979614, 0.6387659443283822, 0.20094234728344396, 0.85052681630375, 0.9959036468202069, 0.3911704881064375, 0.35069761153656953, 0.9212354846785468, 0.43843722207083446, 0.3480885376001104, 0.5681788286466513, 0.2061190192399558, 0.49128438012052555], "operator": "crossover", "theta_sampled": 0.07489116481298118, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "ed532357-4777-4c15-9e7c-90b0c6dbca9b", "fitness": 0.5752455514350298, "name": "HybridAdaptivePSO_DE_v2", "description": "Combines adaptive PSO and DE with success-based weighting and dynamic parameter adaptation for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridAdaptivePSO_DE_v2 scored 0.575 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d", "8922a96f-d9ad-4a5a-82b4-567075f7c6e7"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive PSO and DE with success-based weighting and dynamic parameter adaptation for efficient exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19560032290958096, 0.42491479082453976, 0.4191280031153608, 0.4486436340935819, 0.5556844712966746, 0.7242276733961474, 0.4343514953794658, 0.56101436525081, 0.6355296247162946, 0.4225851453701842, 0.9365950265711585, 0.9974727865912643, 0.4383992869689106, 0.602523270911878, 0.8826921193506603, 0.7166507508358316, 0.4390564982902535, 0.829132659061035, 0.3123425758960684, 0.5283665278708948], "operator": "crossover", "theta_sampled": 0.06791695956751048, "reward": 0.018423620909684857, "generation": 2}, "task_prompt": ""}
{"id": "2aa1e1a6-61f6-44ca-b937-392c2767aeb6", "fitness": 0.4206140865460722, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Adaptively combines PSO and DE with success-history based weighting and parameter adaptation based on remaining budget for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, local_search_prob=0.05):\n        \"\"\"\n        Initializes the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            local_search_prob (float): Probability of performing local search on the best particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.local_search_prob = local_search_prob\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            # Parameter adaptation for DE\n            remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Local search around the best solution\n            if np.random.rand() < self.local_search_prob:\n                # Perform a small perturbation on the best solution\n                perturbation = np.random.uniform(-0.01, 0.01, size=self.dim) * (func.bounds.ub - func.bounds.lb)\n                local_point = self.x_opt + perturbation\n                local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = local_point.copy()\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE scored 0.421 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3", "18151642-c8f0-4e17-8eb2-e2b31f0b6852"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with success-history based weighting and parameter adaptation based on remaining budget for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, local_search_prob=0.05):\n        \"\"\"\n        Initializes the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            local_search_prob (float): Probability of performing local search on the best particle.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.local_search_prob = local_search_prob\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            # Parameter adaptation for DE\n            remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Local search around the best solution\n            if np.random.rand() < self.local_search_prob:\n                # Perform a small perturbation on the best solution\n                perturbation = np.random.uniform(-0.01, 0.01, size=self.dim) * (func.bounds.ub - func.bounds.lb)\n                local_point = self.x_opt + perturbation\n                local_point = np.clip(local_point, func.bounds.lb, func.bounds.ub)\n                f_local = func(local_point)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = local_point.copy()\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20493524385255435, 0.5102821341483688, 0.6184878781358469, 0.6591824561364111, 0.5307968070032518, 0], "operator": "crossover", "theta_sampled": 0.06854402178216523, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "822f81f7-833d-443f-a30f-ae4f3606c06b", "fitness": 0.22346216644285694, "name": "BudgetAwareCMAES", "description": "Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step size adaptation and restarts.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.mu = dim // 2  # Number of parents\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n        self.initial_step_size = initial_step_size\n        self.mean = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.eigeneval = 0\n        self.lambd = self.popsize\n\n        self.mu_eff = None\n        self.weights = None\n        self.mueff = None\n\n        self.init_cma_parameters()\n\n    def init_cma_parameters(self):\n        self.weights = np.log(self.lambd + 1/2) - np.log(np.arange(1, self.lambd + 1))\n        self.weights[self.weights < 0] = 0\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_step_size\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.mean = np.zeros(self.dim)\n\n\n    def sample_solutions(self):\n        z = np.random.randn(self.dim, self.lambd)\n        return self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n\n    def update_distribution(self, solutions, fitness_values):\n        # Sort solutions based on fitness\n        indices = np.argsort(fitness_values)\n        solutions = solutions[:, indices]\n\n        # Update mean\n        self.mean = np.dot(solutions[:, :self.mu], self.weights[:self.mu])\n\n        # Update evolution path for covariance matrix\n        z = (solutions[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.old_mean) / self.sigma)\n        \n        # Update evolution path for step size\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget_used/self.lambd))) / self.chiN < 1.4 + 2/(self.dim + 1)\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mu_eff) * (self.mean - self.old_mean) / self.sigma\n        \n        # Update covariance matrix\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.ccovmu_cum) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.dot(z[:, :self.mu] * self.weights[:self.mu], z[:, :self.mu].T)\n\n        # Update step size\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.budget_used = 0\n\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.ccovmu = min(1-self.ccov1, 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        self.ccovmu_cum = self.ccov1 * (2/(self.mu_eff)) + (self.ccovmu * (2/self.mu_eff))\n\n        self.init_cma_parameters()\n\n\n        restart_counter = 0\n        while self.budget_used < self.budget:\n            self.old_mean = self.mean.copy()\n            solutions = self.sample_solutions()\n            \n            # Clip the solutions within the defined bounds\n            solutions = np.clip(solutions, func.bounds.lb[:, np.newaxis], func.bounds.ub[:, np.newaxis])\n            \n            fitness_values = np.zeros(self.lambd)\n            for i in range(self.lambd):\n                if self.budget_used < self.budget:\n                    fitness_values[i] = func(solutions[:, i])\n                    self.budget_used += 1\n                else:\n                    fitness_values[i] = np.inf\n\n                if fitness_values[i] < self.f_opt:\n                    self.f_opt = fitness_values[i]\n                    self.x_opt = solutions[:, i]\n\n            self.update_distribution(solutions, fitness_values)\n            \n            # Budget-aware step size adaptation: Reduce step size if stagnation is detected\n            if restart_counter > 5 and (np.std(fitness_values) < 1e-9):\n                self.sigma *= 0.8\n                restart_counter = 0\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n            \n            # Restart strategy if step size becomes too small\n            if self.sigma < 1e-10:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                restart_counter = 0\n\n            restart_counter += 1\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm BudgetAwareCMAES scored 0.223 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Implements a Covariance Matrix Adaptation Evolution Strategy (CMA-ES) with a budget-aware step size adaptation and restarts.\n# Code: \n```python\nimport numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.mu = dim // 2  # Number of parents\n        if popsize is None:\n            self.popsize = 4 + int(3 * np.log(self.dim))\n        else:\n            self.popsize = popsize\n        self.initial_step_size = initial_step_size\n        self.mean = None\n        self.C = None\n        self.sigma = None\n        self.pc = None\n        self.ps = None\n        self.eigeneval = 0\n        self.lambd = self.popsize\n\n        self.mu_eff = None\n        self.weights = None\n        self.mueff = None\n\n        self.init_cma_parameters()\n\n    def init_cma_parameters(self):\n        self.weights = np.log(self.lambd + 1/2) - np.log(np.arange(1, self.lambd + 1))\n        self.weights[self.weights < 0] = 0\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.C = np.eye(self.dim)\n        self.sigma = self.initial_step_size\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.mean = np.zeros(self.dim)\n\n\n    def sample_solutions(self):\n        z = np.random.randn(self.dim, self.lambd)\n        return self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n\n    def update_distribution(self, solutions, fitness_values):\n        # Sort solutions based on fitness\n        indices = np.argsort(fitness_values)\n        solutions = solutions[:, indices]\n\n        # Update mean\n        self.mean = np.dot(solutions[:, :self.mu], self.weights[:self.mu])\n\n        # Update evolution path for covariance matrix\n        z = (solutions[:, :self.mu] - self.mean[:, np.newaxis]) / self.sigma\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.mean - self.old_mean) / self.sigma)\n        \n        # Update evolution path for step size\n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget_used/self.lambd))) / self.chiN < 1.4 + 2/(self.dim + 1)\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mu_eff) * (self.mean - self.old_mean) / self.sigma\n        \n        # Update covariance matrix\n        self.C = (1 - self.ccov1 - self.ccovmu + self.ccov1 * self.ccovmu_cum) * self.C + self.ccov1 * np.outer(self.pc, self.pc) \\\n                 + self.ccovmu * np.dot(z[:, :self.mu] * self.weights[:self.mu], z[:, :self.mu].T)\n\n        # Update step size\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.budget_used = 0\n\n        self.ccov1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.ccovmu = min(1-self.ccov1, 2 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2)**2 + self.mu_eff))\n        self.ccovmu_cum = self.ccov1 * (2/(self.mu_eff)) + (self.ccovmu * (2/self.mu_eff))\n\n        self.init_cma_parameters()\n\n\n        restart_counter = 0\n        while self.budget_used < self.budget:\n            self.old_mean = self.mean.copy()\n            solutions = self.sample_solutions()\n            \n            # Clip the solutions within the defined bounds\n            solutions = np.clip(solutions, func.bounds.lb[:, np.newaxis], func.bounds.ub[:, np.newaxis])\n            \n            fitness_values = np.zeros(self.lambd)\n            for i in range(self.lambd):\n                if self.budget_used < self.budget:\n                    fitness_values[i] = func(solutions[:, i])\n                    self.budget_used += 1\n                else:\n                    fitness_values[i] = np.inf\n\n                if fitness_values[i] < self.f_opt:\n                    self.f_opt = fitness_values[i]\n                    self.x_opt = solutions[:, i]\n\n            self.update_distribution(solutions, fitness_values)\n            \n            # Budget-aware step size adaptation: Reduce step size if stagnation is detected\n            if restart_counter > 5 and (np.std(fitness_values) < 1e-9):\n                self.sigma *= 0.8\n                restart_counter = 0\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n            \n            # Restart strategy if step size becomes too small\n            if self.sigma < 1e-10:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = self.initial_step_size\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                restart_counter = 0\n\n            restart_counter += 1\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07269047526901395, 0.1500505257494309, 0.2928328735107155, 0.1341394527461276, 0.12969981589893198, 0.16697960393226863, 0.18721162640710998, 0.17019859058190945, 0.20365648430727457, 0.1339651808871497, 0.16310770072678826, 0.7820530563222305, 0.25176027446206195, 0.15768128754019195, 0.4313638858785428, 0.22967404133266034, 0.17249807353597812, 0.16991535869238106, 0.1293731654048852, 0.3403918556714851], "operator": "random_new", "theta_sampled": 0.07356598334827008, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "85b53b8f-1c5c-4206-8474-8f6262d185ae", "fitness": 0.48755782497614514, "name": "AdaptiveHybridPSO_DE_Enhanced", "description": "Adaptive Hybrid PSO-DE with enhanced DE mutation strategy, archive-based learning and dynamic parameter control for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Rate to adapt F based on success.\n            CR_adapt_rate (float): Rate to adapt CR based on success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.F_history = []\n        self.CR_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with archive and adaptive F/CR\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = population[idxs]\n\n                    # Choose a random vector from archive or population\n                    if len(self.archive) > 0 and np.random.rand() < 0.5:\n                        x3 = self.archive[np.random.randint(0, len(self.archive))]\n                    else:\n                        x3_idx = np.random.choice(self.pop_size, 1, replace=False)[0]\n                        x3 = population[x3_idx]\n\n                    mutant = population[i] + self.F * (x1 - x2) + self.F * (population[i] - x3)  # Enhanced mutation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n\n                        # Adaptive F/CR update\n                        self.F = max(0.1, min(1.0, self.F * (1 + self.F_adapt_rate * np.random.normal(0, 1))))\n                        self.CR = max(0.1, min(1.0, self.CR * (1 + self.CR_adapt_rate * np.random.normal(0, 1))))\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n                        # If DE fails, decrease F and CR slightly\n                        self.F = max(0.1, min(1.0, self.F * (1 - self.F_adapt_rate * np.random.normal(0, 1))))\n                        self.CR = max(0.1, min(1.0, self.CR * (1 - self.CR_adapt_rate * np.random.normal(0, 1))))\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.F_history.append(self.F)\n            self.CR_history.append(self.CR)\n\n\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n                self.F_history.pop(0)\n                self.CR_history.pop(0)\n\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE_Enhanced scored 0.488 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with enhanced DE mutation strategy, archive-based learning and dynamic parameter control for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Rate to adapt F based on success.\n            CR_adapt_rate (float): Rate to adapt CR based on success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.F_history = []\n        self.CR_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with archive and adaptive F/CR\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = population[idxs]\n\n                    # Choose a random vector from archive or population\n                    if len(self.archive) > 0 and np.random.rand() < 0.5:\n                        x3 = self.archive[np.random.randint(0, len(self.archive))]\n                    else:\n                        x3_idx = np.random.choice(self.pop_size, 1, replace=False)[0]\n                        x3 = population[x3_idx]\n\n                    mutant = population[i] + self.F * (x1 - x2) + self.F * (population[i] - x3)  # Enhanced mutation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n\n                        # Adaptive F/CR update\n                        self.F = max(0.1, min(1.0, self.F * (1 + self.F_adapt_rate * np.random.normal(0, 1))))\n                        self.CR = max(0.1, min(1.0, self.CR * (1 + self.CR_adapt_rate * np.random.normal(0, 1))))\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n                        # If DE fails, decrease F and CR slightly\n                        self.F = max(0.1, min(1.0, self.F * (1 - self.F_adapt_rate * np.random.normal(0, 1))))\n                        self.CR = max(0.1, min(1.0, self.CR * (1 - self.CR_adapt_rate * np.random.normal(0, 1))))\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.F_history.append(self.F)\n            self.CR_history.append(self.CR)\n\n\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n                self.F_history.pop(0)\n                self.CR_history.pop(0)\n\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.22525317009168344, 0.38631963113196977, 0.4909702244221711, 0.8491377355058863, 0.3817838745865697, 0.5675969462160924, 0.2978517858022657, 0.4211279583992721, 0.4395177048227381, 0.24674430081553733, 0.4960960182171428, 0.9994900938754613, 0.27338169349328356, 0.45585960357253374, 0.8442849000301804, 0.5713438562540073, 0.37932127390143766, 0.7305626210439391, 0.19299515473195028, 0.5015179526087805], "operator": "mutation", "theta_sampled": 0.46509557020248704, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "1fc58b0b-254f-4a40-95fb-736b67483f25", "fitness": 0.0, "name": "AdaptiveDE_CMAES", "description": "A population-based algorithm that combines aspects of differential evolution and covariance matrix adaptation evolution strategy (CMA-ES), adaptively adjusting its parameters based on the success rate of candidate solutions.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim)) # CMA-ES inspired pop size\n        self.CR = 0.5  # Crossover rate\n        self.F = 0.7   # Mutation factor\n        self.mu = self.pop_size // 2 # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.c_m = 1 / np.sqrt(dim)\n        self.c_sigma = (np.sqrt(dim) / 2) * (budget / (dim * self.pop_size)) # Adaptation rate for step size\n        self.d_sigma = 1 + 2 * np.max(self.weights)**2 # Damping factor\n        \n        self.sigma = 0.1  # Step size\n        self.C = np.eye(dim) # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for covariance matrix\n        self.ps = np.zeros(dim) # Evolution path for step size\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim) # Learning rate for rank-one update\n        self.c_mu = min(1 - self.c_c, (2*(self.mu-1))/(dim+2)**2 + (self.c_c * (1 - self.c_c) * ((2*self.mu-1)/(self.mu)))) # Learning rate for rank-mu update\n        self.c_1 = self.c_c # Learning rate for rank-one update\n        \n        self.success_history = []\n        self.success_rate_threshold = 0.3\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # 1. Variation (DE + CMA-ES components)\n            offspring = self.generate_offspring(func)\n\n            # 2. Selection\n            self.selection(offspring, func)\n            \n            # 3. Adaptation\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n\n    def generate_offspring(self, func):\n        offspring = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Differential Evolution part\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            mutation = x_r1 + self.F * (x_r2 - x_r3)\n            \n            # Apply bounds\n            mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n            \n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    offspring[i, j] = mutation[j]\n                else:\n                    offspring[i, j] = self.population[i, j]\n                    \n        # CMA-ES Part (add noise based on covariance matrix)\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size = self.pop_size) # Draw random samples from multivariate normal\n        offspring = offspring + self.sigma * z\n        \n        offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n                    \n        return offspring\n\n    def selection(self, offspring, func):\n        offspring_fitness = np.array([func(x) for x in offspring])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if offspring_fitness[i] < self.fitness[i]:\n                self.population[i] = offspring[i]\n                self.fitness[i] = offspring_fitness[i]\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n                \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def adapt_parameters(self):\n        # Adapt CR and F based on success rate (simplified)\n        if len(self.success_history) > 10 * self.pop_size:\n            success_rate = np.mean(self.success_history[-10 * self.pop_size:])\n            \n            if success_rate > self.success_rate_threshold:\n               self.F = max(0.1, self.F * 0.95) # Reduce F if success rate is too high\n               self.CR = min(0.9, self.CR * 1.05)\n            else:\n               self.F = min(0.9, self.F * 1.05) # Increase F if success rate is too low\n               self.CR = max(0.1, self.CR * 0.95)\n            \n        #CMA-ES Adaptation (simplified - based on https://github.com/CyberAgentAILab/cmaes)\n        xmean = np.sum(self.weights.reshape(-1,1) * self.population[np.argsort(self.fitness)[:self.mu]], axis=0) # Weighted mean of the parents\n\n        z = (xmean - np.mean(self.population, axis=0)) / self.sigma # Normalize\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z # Update evolution path\n        self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1)) # Update step size\n\n        self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * z * np.sqrt(self.sigma) # Update evolution path\n\n        # Update covariance matrix\n        delta = (self.population[np.argsort(self.fitness)[:self.mu]] - np.mean(self.population, axis=0)) / self.sigma\n        self.C = (1 - self.c_1 - self.c_mu) * self.C \\\n                 + self.c_1 * np.outer(self.pc, self.pc) \\\n                 + self.c_mu * np.sum(self.weights.reshape(-1, 1, 1) * (delta[:, :, None] @ delta[:, None, :]), axis=0)", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: SVD did not converge", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution and covariance matrix adaptation evolution strategy (CMA-ES), adaptively adjusting its parameters based on the success rate of candidate solutions.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim)) # CMA-ES inspired pop size\n        self.CR = 0.5  # Crossover rate\n        self.F = 0.7   # Mutation factor\n        self.mu = self.pop_size // 2 # Number of parents\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n\n        self.c_m = 1 / np.sqrt(dim)\n        self.c_sigma = (np.sqrt(dim) / 2) * (budget / (dim * self.pop_size)) # Adaptation rate for step size\n        self.d_sigma = 1 + 2 * np.max(self.weights)**2 # Damping factor\n        \n        self.sigma = 0.1  # Step size\n        self.C = np.eye(dim) # Covariance matrix\n        self.pc = np.zeros(dim) # Evolution path for covariance matrix\n        self.ps = np.zeros(dim) # Evolution path for step size\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim) # Learning rate for rank-one update\n        self.c_mu = min(1 - self.c_c, (2*(self.mu-1))/(dim+2)**2 + (self.c_c * (1 - self.c_c) * ((2*self.mu-1)/(self.mu)))) # Learning rate for rank-mu update\n        self.c_1 = self.c_c # Learning rate for rank-one update\n        \n        self.success_history = []\n        self.success_rate_threshold = 0.3\n\n    def __call__(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.budget > 0:\n            # 1. Variation (DE + CMA-ES components)\n            offspring = self.generate_offspring(func)\n\n            # 2. Selection\n            self.selection(offspring, func)\n            \n            # 3. Adaptation\n            self.adapt_parameters()\n\n        return self.f_opt, self.x_opt\n\n    def generate_offspring(self, func):\n        offspring = np.zeros_like(self.population)\n        for i in range(self.pop_size):\n            # Differential Evolution part\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n            \n            mutation = x_r1 + self.F * (x_r2 - x_r3)\n            \n            # Apply bounds\n            mutation = np.clip(mutation, func.bounds.lb, func.bounds.ub)\n            \n            # Crossover\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.CR or j == j_rand:\n                    offspring[i, j] = mutation[j]\n                else:\n                    offspring[i, j] = self.population[i, j]\n                    \n        # CMA-ES Part (add noise based on covariance matrix)\n        z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size = self.pop_size) # Draw random samples from multivariate normal\n        offspring = offspring + self.sigma * z\n        \n        offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n                    \n        return offspring\n\n    def selection(self, offspring, func):\n        offspring_fitness = np.array([func(x) for x in offspring])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if offspring_fitness[i] < self.fitness[i]:\n                self.population[i] = offspring[i]\n                self.fitness[i] = offspring_fitness[i]\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n                \n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def adapt_parameters(self):\n        # Adapt CR and F based on success rate (simplified)\n        if len(self.success_history) > 10 * self.pop_size:\n            success_rate = np.mean(self.success_history[-10 * self.pop_size:])\n            \n            if success_rate > self.success_rate_threshold:\n               self.F = max(0.1, self.F * 0.95) # Reduce F if success rate is too high\n               self.CR = min(0.9, self.CR * 1.05)\n            else:\n               self.F = min(0.9, self.F * 1.05) # Increase F if success rate is too low\n               self.CR = max(0.1, self.CR * 0.95)\n            \n        #CMA-ES Adaptation (simplified - based on https://github.com/CyberAgentAILab/cmaes)\n        xmean = np.sum(self.weights.reshape(-1,1) * self.population[np.argsort(self.fitness)[:self.mu]], axis=0) # Weighted mean of the parents\n\n        z = (xmean - np.mean(self.population, axis=0)) / self.sigma # Normalize\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z # Update evolution path\n        self.sigma = self.sigma * np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps)/np.sqrt(self.dim) - 1)) # Update step size\n\n        self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * z * np.sqrt(self.sigma) # Update evolution path\n\n        # Update covariance matrix\n        delta = (self.population[np.argsort(self.fitness)[:self.mu]] - np.mean(self.population, axis=0)) / self.sigma\n        self.C = (1 - self.c_1 - self.c_mu) * self.C \\\n                 + self.c_1 * np.outer(self.pc, self.pc) \\\n                 + self.c_mu * np.sum(self.weights.reshape(-1, 1, 1) * (delta[:, :, None] @ delta[:, None, :]), axis=0)\n\n```", "operator": "random_new", "theta_sampled": 0.21866581624536086, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "afed005a-409e-4d6e-9e17-587abdba6f9d", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Dynamically adjusts PSO/DE parameters based on their recent performance and introduces a local search component for exploitation, switching strategies based on performance metrics.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=30, \n                 inertia_start=0.9, inertia_end=0.4, \n                 cognitive_coeff_start=1.5, cognitive_coeff_end=2.0,\n                 social_coeff_start=1.5, social_coeff_end=0.5,\n                 de_mutation_factor_start=0.5, de_mutation_factor_end=0.9,\n                 de_crossover_rate_start=0.7, de_crossover_rate_end=0.3,\n                 pso_exploration_rate=0.1, switch_prob=0.05, ls_rate=0.05, ls_radius=0.1): #Added ls_rate\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff_start = cognitive_coeff_start\n        self.cognitive_coeff_end = cognitive_coeff_end\n        self.social_coeff_start = social_coeff_start\n        self.social_coeff_end = social_coeff_end\n        self.de_mutation_factor_start = de_mutation_factor_start\n        self.de_mutation_factor_end = de_mutation_factor_end\n        self.de_crossover_rate_start = de_crossover_rate_start\n        self.de_crossover_rate_end = de_crossover_rate_end\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob # Probability of switching between PSO and DE\n        self.ls_rate = ls_rate\n        self.ls_radius = ls_radius # Radius for local search\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"  # Start with PSO\n\n        # Performance tracking for adaptive parameter control\n        self.pso_success_rate = 0.0\n        self.de_success_rate = 0.0\n        self.pso_success_count = 0\n        self.de_success_count = 0\n        self.strategy_switch_interval = 10  # Check success rate every this many iterations\n        self.iteration_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def update_parameters(self):\n         # Linear annealing for PSO parameters\n        progress = 1 - (self.budget / self.initial_budget) # Progress from 0 to 1\n        self.inertia = self.inertia_start + progress * (self.inertia_end - self.inertia_start)\n        self.cognitive_coeff = self.cognitive_coeff_start + progress * (self.cognitive_coeff_end - self.cognitive_coeff_start)\n        self.social_coeff = self.social_coeff_start + progress * (self.social_coeff_end - self.social_coeff_start)\n\n        # Linear annealing for DE parameters\n        self.de_mutation_factor = self.de_mutation_factor_start + progress * (self.de_mutation_factor_end - self.de_mutation_factor_start)\n        self.de_crossover_rate = self.de_crossover_rate_start + progress * (self.de_crossover_rate_end - self.de_crossover_rate_start)\n\n    def pso_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n                    success_count += 1 # Track success\n            if self.budget <= 0:\n                break\n        return success_count\n\n\n    def de_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n                success_count += 1 # Track success\n\n            if self.budget <= 0:\n                break\n        return success_count\n\n    def local_search(self, func):\n        if np.random.rand() < self.ls_rate:\n            # Apply local search around the global best\n            x_ls = self.global_best_position + np.random.uniform(-self.ls_radius, self.ls_radius, size=self.dim)\n            x_ls = np.clip(x_ls, func.bounds.lb, func.bounds.ub)\n            f_ls = func(x_ls)\n            self.budget -= 1\n\n            if f_ls < self.f_opt:\n                self.f_opt = f_ls\n                self.x_opt = x_ls\n                self.global_best_position = x_ls.copy()\n                return True\n        return False # No Improvement\n\n    def __call__(self, func):\n        self.initial_budget = self.budget #Store initial budget\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.update_parameters() # Update inertia and other parameters\n            self.iteration_count += 1\n\n            # Strategy Selection based on Success Rate\n            if self.iteration_count % self.strategy_switch_interval == 0:\n                if self.pso_success_count + self.de_success_count > 0: # avoid division by zero\n                    self.pso_success_rate = self.pso_success_count / (self.pso_success_count + self.de_success_count)\n                    self.de_success_rate = self.de_success_count / (self.pso_success_count + self.de_success_count)\n                else:\n                    self.pso_success_rate = 0.5 # Default values\n                    self.de_success_rate = 0.5\n\n                self.pso_success_count = 0  # Reset counts\n                self.de_success_count = 0\n\n\n                if self.pso_success_rate > self.de_success_rate:\n                    self.current_strategy = \"PSO\"\n                else:\n                    self.current_strategy = \"DE\"\n\n            if self.current_strategy == \"PSO\":\n                self.pso_success_count += self.pso_step(func)\n            else:\n                self.de_success_count += self.de_step(func)\n\n            if self.local_search(func): #Perform Local Search\n               pass #Optional -  can track the success rate of local search\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO/DE parameters based on their recent performance and introduces a local search component for exploitation, switching strategies based on performance metrics.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=30, \n                 inertia_start=0.9, inertia_end=0.4, \n                 cognitive_coeff_start=1.5, cognitive_coeff_end=2.0,\n                 social_coeff_start=1.5, social_coeff_end=0.5,\n                 de_mutation_factor_start=0.5, de_mutation_factor_end=0.9,\n                 de_crossover_rate_start=0.7, de_crossover_rate_end=0.3,\n                 pso_exploration_rate=0.1, switch_prob=0.05, ls_rate=0.05, ls_radius=0.1): #Added ls_rate\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff_start = cognitive_coeff_start\n        self.cognitive_coeff_end = cognitive_coeff_end\n        self.social_coeff_start = social_coeff_start\n        self.social_coeff_end = social_coeff_end\n        self.de_mutation_factor_start = de_mutation_factor_start\n        self.de_mutation_factor_end = de_mutation_factor_end\n        self.de_crossover_rate_start = de_crossover_rate_start\n        self.de_crossover_rate_end = de_crossover_rate_end\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob # Probability of switching between PSO and DE\n        self.ls_rate = ls_rate\n        self.ls_radius = ls_radius # Radius for local search\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"  # Start with PSO\n\n        # Performance tracking for adaptive parameter control\n        self.pso_success_rate = 0.0\n        self.de_success_rate = 0.0\n        self.pso_success_count = 0\n        self.de_success_count = 0\n        self.strategy_switch_interval = 10  # Check success rate every this many iterations\n        self.iteration_count = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def update_parameters(self):\n         # Linear annealing for PSO parameters\n        progress = 1 - (self.budget / self.initial_budget) # Progress from 0 to 1\n        self.inertia = self.inertia_start + progress * (self.inertia_end - self.inertia_start)\n        self.cognitive_coeff = self.cognitive_coeff_start + progress * (self.cognitive_coeff_end - self.cognitive_coeff_start)\n        self.social_coeff = self.social_coeff_start + progress * (self.social_coeff_end - self.social_coeff_start)\n\n        # Linear annealing for DE parameters\n        self.de_mutation_factor = self.de_mutation_factor_start + progress * (self.de_mutation_factor_end - self.de_mutation_factor_start)\n        self.de_crossover_rate = self.de_crossover_rate_start + progress * (self.de_crossover_rate_end - self.de_crossover_rate_start)\n\n    def pso_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n                    success_count += 1 # Track success\n            if self.budget <= 0:\n                break\n        return success_count\n\n\n    def de_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n                success_count += 1 # Track success\n\n            if self.budget <= 0:\n                break\n        return success_count\n\n    def local_search(self, func):\n        if np.random.rand() < self.ls_rate:\n            # Apply local search around the global best\n            x_ls = self.global_best_position + np.random.uniform(-self.ls_radius, self.ls_radius, size=self.dim)\n            x_ls = np.clip(x_ls, func.bounds.lb, func.bounds.ub)\n            f_ls = func(x_ls)\n            self.budget -= 1\n\n            if f_ls < self.f_opt:\n                self.f_opt = f_ls\n                self.x_opt = x_ls\n                self.global_best_position = x_ls.copy()\n                return True\n        return False # No Improvement\n\n    def __call__(self, func):\n        self.initial_budget = self.budget #Store initial budget\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.update_parameters() # Update inertia and other parameters\n            self.iteration_count += 1\n\n            # Strategy Selection based on Success Rate\n            if self.iteration_count % self.strategy_switch_interval == 0:\n                if self.pso_success_count + self.de_success_count > 0: # avoid division by zero\n                    self.pso_success_rate = self.pso_success_count / (self.pso_success_count + self.de_success_count)\n                    self.de_success_rate = self.de_success_count / (self.pso_success_count + self.de_success_count)\n                else:\n                    self.pso_success_rate = 0.5 # Default values\n                    self.de_success_rate = 0.5\n\n                self.pso_success_count = 0  # Reset counts\n                self.de_success_count = 0\n\n\n                if self.pso_success_rate > self.de_success_rate:\n                    self.current_strategy = \"PSO\"\n                else:\n                    self.current_strategy = \"DE\"\n\n            if self.current_strategy == \"PSO\":\n                self.pso_success_count += self.pso_step(func)\n            else:\n                self.de_success_count += self.de_step(func)\n\n            if self.local_search(func): #Perform Local Search\n               pass #Optional -  can track the success rate of local search\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.03832693616396369, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "a340f207-467e-454f-af18-cc8b10b6aafc", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_LS", "description": "Dynamically adjusts PSO and DE parameters based on their recent performance, incorporating a local search component for exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.7, pso_exploration_rate=0.1, switch_prob=0.05, local_search_prob=0.05, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"\n\n        self.pso_success_rate = 0.5\n        self.de_success_rate = 0.5\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.success_history_length = 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (1 - self.budget / self.budget)\n\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n            self.fitness[i] = f\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            \n            if f < old_fitness:\n                success_count += 1\n\n\n            if self.budget <= 0:\n                break\n        \n        self.pso_success_history.append(success_count / self.pop_size)\n        if len(self.pso_success_history) > self.success_history_length:\n            self.pso_success_history.pop(0)\n        self.pso_success_rate = np.mean(self.pso_success_history)\n\n\n    def de_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n                success_count += 1\n\n\n            if self.budget <= 0:\n                break\n        \n        self.de_success_history.append(success_count / self.pop_size)\n        if len(self.de_success_history) > self.success_history_length:\n            self.de_success_history.pop(0)\n        self.de_success_rate = np.mean(self.de_success_history)\n\n\n    def local_search(self, func):\n         for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_prob:\n                # Generate a random perturbation within the defined radius\n                perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                new_position = self.population[i] + perturbation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n                        self.global_best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Adaptive Strategy Switching\n            if np.random.rand() < self.switch_prob:\n                if self.pso_success_rate > self.de_success_rate:\n                    self.current_strategy = \"PSO\"\n                else:\n                    self.current_strategy = \"DE\"\n\n\n            if self.current_strategy == \"PSO\":\n                self.pso_step(func)\n                self.de_mutation_factor = np.clip(self.de_mutation_factor + 0.01, 0.1, 0.9)\n\n            else:\n                self.de_step(func)\n                self.de_mutation_factor = np.clip(self.de_mutation_factor - 0.01, 0.1, 0.9)\n                \n            self.local_search(func)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveHybridPSO_DE_LS scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["2384ebfe-60a9-4e08-a226-ca277fdec67d"], "operator": "mutation", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO and DE parameters based on their recent performance, incorporating a local search component for exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LS:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia_start=0.9, inertia_end=0.4, cognitive_coeff=1.5, social_coeff=1.5, de_mutation_factor=0.5, de_crossover_rate=0.7, pso_exploration_rate=0.1, switch_prob=0.05, local_search_prob=0.05, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_exploration_rate = pso_exploration_rate\n        self.switch_prob = switch_prob\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.current_strategy = \"PSO\"\n\n        self.pso_success_rate = 0.5\n        self.de_success_rate = 0.5\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.success_history_length = 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            inertia = self.inertia_start - (self.inertia_start - self.inertia_end) * (1 - self.budget / self.budget)\n\n            if np.random.rand() < self.pso_exploration_rate:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n            else:\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n            f = func(self.population[i])\n            self.budget -= 1\n            self.fitness[i] = f\n\n            if f < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n            \n            if f < old_fitness:\n                success_count += 1\n\n\n            if self.budget <= 0:\n                break\n        \n        self.pso_success_history.append(success_count / self.pop_size)\n        if len(self.pso_success_history) > self.success_history_length:\n            self.pso_success_history.pop(0)\n        self.pso_success_rate = np.mean(self.pso_success_history)\n\n\n    def de_step(self, func):\n        success_count = 0\n        for i in range(self.pop_size):\n            old_fitness = self.fitness[i]\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + self.de_mutation_factor * (x2 - x3)\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n            trial_vector = np.where(crossover_mask, mutant, self.population[i])\n\n            f_trial = func(trial_vector)\n            self.budget -= 1\n\n            if f_trial < self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = f_trial\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = trial_vector\n                    self.global_best_position = trial_vector.copy()\n                success_count += 1\n\n\n            if self.budget <= 0:\n                break\n        \n        self.de_success_history.append(success_count / self.pop_size)\n        if len(self.de_success_history) > self.success_history_length:\n            self.de_success_history.pop(0)\n        self.de_success_rate = np.mean(self.de_success_history)\n\n\n    def local_search(self, func):\n         for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_prob:\n                # Generate a random perturbation within the defined radius\n                perturbation = np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                new_position = self.population[i] + perturbation\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                if new_fitness < self.fitness[i]:\n                    self.population[i] = new_position\n                    self.fitness[i] = new_fitness\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n                        self.global_best_position = new_position.copy()\n\n                if self.budget <= 0:\n                    break\n\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Adaptive Strategy Switching\n            if np.random.rand() < self.switch_prob:\n                if self.pso_success_rate > self.de_success_rate:\n                    self.current_strategy = \"PSO\"\n                else:\n                    self.current_strategy = \"DE\"\n\n\n            if self.current_strategy == \"PSO\":\n                self.pso_step(func)\n                self.de_mutation_factor = np.clip(self.de_mutation_factor + 0.01, 0.1, 0.9)\n\n            else:\n                self.de_step(func)\n                self.de_mutation_factor = np.clip(self.de_mutation_factor - 0.01, 0.1, 0.9)\n                \n            self.local_search(func)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.24230340392857005, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "3341a75b-d820-42d2-b4c6-e554640732c1", "fitness": 0.3175733514752872, "name": "OrthogonalCMAES", "description": "Population-based algorithm with a simplified covariance matrix adaptation strategy using orthogonal sampling to generate new search points around the best solution found so far.", "code": "import numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2  # Number of parents/selected points\n        self.c_m = 1  # Step size adaptation learning rate\n        self.sigma = 0.5  # Overall standard deviation\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize mean\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        # Simplified covariance matrix adaptation (only diagonal elements adapted)\n        diag_sigma = np.ones(self.dim) # Initialize diagonal std devs\n\n\n        evals = 0\n        while evals < self.budget:\n            # Generate orthogonal sample matrix\n            Z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            Q, R = np.linalg.qr(Z) # QR decomposition for orthogonal matrix\n\n            X = np.zeros((self.pop_size, self.dim))\n            F = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Generate sample point\n                x = mean + self.sigma * diag_sigma * Q[i]\n                \n                # Clip to bounds\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate\n                f = func(x)\n                \n                X[i] = x\n                F[i] = f\n                evals += 1\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Sort by fitness\n            idx = np.argsort(F)\n            X = X[idx]\n            F = F[idx]\n\n            # Update mean\n            mean = np.mean(X[:self.mu], axis=0)\n\n            # Update step size\n            d_sigma = np.mean((X[:self.mu] - mean) / (self.sigma * diag_sigma), axis=0)\n            diag_sigma = diag_sigma * np.exp(self.c_m / self.dim * d_sigma) # Element-wise multiplication\n\n\n\n            # Check budget again to exit loop if necessary\n            if evals >= self.budget:\n                break\n        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm OrthogonalCMAES scored 0.318 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a simplified covariance matrix adaptation strategy using orthogonal sampling to generate new search points around the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass OrthogonalCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2  # Number of parents/selected points\n        self.c_m = 1  # Step size adaptation learning rate\n        self.sigma = 0.5  # Overall standard deviation\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize mean\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        # Simplified covariance matrix adaptation (only diagonal elements adapted)\n        diag_sigma = np.ones(self.dim) # Initialize diagonal std devs\n\n\n        evals = 0\n        while evals < self.budget:\n            # Generate orthogonal sample matrix\n            Z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            Q, R = np.linalg.qr(Z) # QR decomposition for orthogonal matrix\n\n            X = np.zeros((self.pop_size, self.dim))\n            F = np.zeros(self.pop_size)\n\n            for i in range(self.pop_size):\n                # Generate sample point\n                x = mean + self.sigma * diag_sigma * Q[i]\n                \n                # Clip to bounds\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate\n                f = func(x)\n                \n                X[i] = x\n                F[i] = f\n                evals += 1\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Sort by fitness\n            idx = np.argsort(F)\n            X = X[idx]\n            F = F[idx]\n\n            # Update mean\n            mean = np.mean(X[:self.mu], axis=0)\n\n            # Update step size\n            d_sigma = np.mean((X[:self.mu] - mean) / (self.sigma * diag_sigma), axis=0)\n            diag_sigma = diag_sigma * np.exp(self.c_m / self.dim * d_sigma) # Element-wise multiplication\n\n\n\n            # Check budget again to exit loop if necessary\n            if evals >= self.budget:\n                break\n        \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.08503970998582389, 0.18115506639685508, 0.40125234135911236, 0.47051082007711664, 0.27713025721652473, 0.16454609024066214, 0.27556686246175455, 0.31851150233734393, 0.16816734832073632, 0.1847546808789774, 0.3913172427731064, 0.9607586345092626, 0.28498748251754236, 0.32428919324363903, 0.6629463693345761, 0.22586347047289645, 0.31195956333470565, 0.16888472720336323, 0.13716614895496537, 0.3566595178867793], "operator": "random_new", "theta_sampled": 0.38362059386477554, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "818de98b-afc8-4fb4-839f-721f28963dc8", "fitness": 0.35101977406107526, "name": "ShrinkingHypersphereSearch", "description": "Population-based search with a shrinking hypersphere, focusing on local exploration around the best solution found so far.", "code": "import numpy as np\n\nclass ShrinkingHypersphereSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population randomly\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        eval_count = self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        radius = self.initial_radius\n        \n        while eval_count < self.budget:\n            # Generate new samples within a shrinking hypersphere around the best solution\n            new_samples = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Generate a random vector within the hypersphere\n                while True:\n                    u = np.random.normal(0, 1, size=self.dim)\n                    norm = np.linalg.norm(u)\n                    if norm > 0:\n                        break\n                direction = u / norm\n                sample = self.x_opt + radius * direction * np.random.rand() # Scale by random value for variable exploration\n                \n                # Clip to bounds\n                sample = np.clip(sample, func.bounds.lb, func.bounds.ub)\n                new_samples[i] = sample\n                \n            new_fitness = np.array([func(x) for x in new_samples])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_samples[i].copy()\n            \n            # Shrink the radius (exploration vs. exploitation)\n            radius *= 0.99  # Reduce radius by 1% each iteration\n            \n            if radius < 1e-6: # prevent radius becoming too small\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm ShrinkingHypersphereSearch scored 0.351 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with a shrinking hypersphere, focusing on local exploration around the best solution found so far.\n# Code: \n```python\nimport numpy as np\n\nclass ShrinkingHypersphereSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_radius = initial_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population randomly\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        eval_count = self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        radius = self.initial_radius\n        \n        while eval_count < self.budget:\n            # Generate new samples within a shrinking hypersphere around the best solution\n            new_samples = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                # Generate a random vector within the hypersphere\n                while True:\n                    u = np.random.normal(0, 1, size=self.dim)\n                    norm = np.linalg.norm(u)\n                    if norm > 0:\n                        break\n                direction = u / norm\n                sample = self.x_opt + radius * direction * np.random.rand() # Scale by random value for variable exploration\n                \n                # Clip to bounds\n                sample = np.clip(sample, func.bounds.lb, func.bounds.ub)\n                new_samples[i] = sample\n                \n            new_fitness = np.array([func(x) for x in new_samples])\n            eval_count += self.pop_size\n            \n            # Update best solution\n            for i in range(self.pop_size):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_samples[i].copy()\n            \n            # Shrink the radius (exploration vs. exploitation)\n            radius *= 0.99  # Reduce radius by 1% each iteration\n            \n            if radius < 1e-6: # prevent radius becoming too small\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1329849963627947, 0.1933489049725302, 0.6385391265938744, 0.2580625505405313, 0.18302881675385585, 0.2308961137726938, 0.23273177603888517, 0.18211363178584083, 0.1636835159590797, 0.18641252035771172, 0.9388564448429614, 0.9936024437496771, 0.22452903546367065, 0.1563100223096342, 0.8582748742823402, 0.30017046897961264, 0.20847737252374987, 0.29808710296486274, 0.17289378250664755, 0.46739198046055097], "operator": "random_new", "theta_sampled": 0.16243822710112044, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "d5170cf0-2e4a-43a1-a938-b5704db8ed5e", "fitness": 0.0, "name": "HybridAdaptivePSO_DE_NM", "description": "Combines PSO and DE with adaptive parameter control and a local search based on Nelder-Mead to refine promising solutions, enhancing exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridAdaptivePSO_DE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, individual):\n        bounds = func.bounds\n        def obj_func(x):\n            return func(x)\n        \n        res = minimize(obj_func, individual, method='Nelder-Mead', bounds=[(bounds.lb[i], bounds.ub[i]) for i in range(self.dim)], options={'maxfev': self.budget // (self.pop_size * 5)  if (self.budget // (self.pop_size * 5)) > 0 else 1 })\n        \n        \n        if res.success:\n            n_eval = res.nfev\n            self.budget -= n_eval\n            return res.fun, res.x, n_eval\n        else:\n            return func(individual), individual, 1  # Use 1 evaluation for original point\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    f_new, new_individual, n_eval = self.local_search(func, self.population[i].copy())\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_individual\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                            if f_new < self.f_opt:\n                                self.f_opt = f_new\n                                self.x_opt = self.population[i].copy()\n                                self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["ed532357-4777-4c15-9e7c-90b0c6dbca9b"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO and DE with adaptive parameter control and a local search based on Nelder-Mead to refine promising solutions, enhancing exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridAdaptivePSO_DE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, individual):\n        bounds = func.bounds\n        def obj_func(x):\n            return func(x)\n        \n        res = minimize(obj_func, individual, method='Nelder-Mead', bounds=[(bounds.lb[i], bounds.ub[i]) for i in range(self.dim)], options={'maxfev': self.budget // (self.pop_size * 5)  if (self.budget // (self.pop_size * 5)) > 0 else 1 })\n        \n        \n        if res.success:\n            n_eval = res.nfev\n            self.budget -= n_eval\n            return res.fun, res.x, n_eval\n        else:\n            return func(individual), individual, 1  # Use 1 evaluation for original point\n        \n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    f_new, new_individual, n_eval = self.local_search(func, self.population[i].copy())\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_individual\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                            if f_new < self.f_opt:\n                                self.f_opt = f_new\n                                self.x_opt = self.population[i].copy()\n                                self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.32457035000426465, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "f20a2df8-a0cf-4ea8-be47-dcde44a92f8d", "fitness": 0.5759591097724988, "name": "AdaptiveHybridPSO_DE_v3", "description": "Adaptively combines PSO and DE, dynamically adjusting parameters and strategy weights based on success and remaining budget, while incorporating a linearly scaled mutation factor and crossover rate for DE.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, archive_size_factor=0.2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight_init (float): Initial weight for PSO.\n            de_weight_init (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual with adaptive F and CR.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update personal best and global best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i].copy()\n                        self.global_best_position = self.population[i].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3", "18151642-c8f0-4e17-8eb2-e2b31f0b6852"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE, dynamically adjusting parameters and strategy weights based on success and remaining budget, while incorporating a linearly scaled mutation factor and crossover rate for DE.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, archive_size_factor=0.2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight_init (float): Initial weight for PSO.\n            de_weight_init (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual with adaptive F and CR.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update personal best and global best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i].copy()\n                        self.global_best_position = self.population[i].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2095981713106183, 0.43817548541542173, 0.5261943367413957, 0.8761617171488916, 0.5339635630747694, 0.7479732506135516, 0.37545656633971436, 0.49244969589001686, 0.5602687931353061, 0.38697136369171503, 0.7028250061479786, 0.9968375903669747, 0.5461876000746032, 0.545656100131829, 0.9020325335179746, 0.6583079318295617, 0.5061809234628886, 0.6757311657875318, 0.32951979766638173, 0.5086906031028517], "operator": "crossover", "theta_sampled": 0.09844987288800741, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "92f981c8-f17e-4ece-84c3-7d4a597514e8", "fitness": 0.0, "name": "RestartCMAES", "description": "A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant that restarts with modified parameters when stagnation is detected, incorporating a simple diversity maintenance mechanism.", "code": "import numpy as np\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.2, popsize=None, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.stagnation_threshold = stagnation_threshold\n        self.best_f = np.inf\n        self.best_x = None\n\n    def __call__(self, func):\n        self.mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n        self.c_sigma = (self.popsize + 2) / (self.dim + self.popsize + 5)\n        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.weights = np.log(self.popsize + 1 / 2) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu_eff - 2 + 1 / self.mu_eff) / ((self.dim + 2.3)**2 + self.mu_eff))\n        self.evals = 0\n        self.stagnation_counter = 0\n        self.last_f = np.inf\n\n        while self.evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            B = np.linalg.cholesky(self.C)  # Efficiently compute C^(1/2)\n            x = self.mu[:, np.newaxis] + self.sigma * B @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n            \n            # Update best solution\n            for i in range(self.popsize):\n                if f[i] < self.best_f:\n                    self.best_f = f[i]\n                    self.best_x = x[:, i].copy()\n            \n            # Sort population\n            idx = np.argsort(f)\n            z = z[:, idx]\n            x = x[:, idx]\n            \n            # Update CMA-ES parameters\n            z_mean = np.sum(self.weights * z, axis=1)\n            y_mean = B @ z_mean\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * y_mean\n            \n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.evals / self.popsize)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * y_mean\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) \\\n                     + self.c_mu * (z[:, :self.popsize] @ np.diag(self.weights) @ z[:, :self.popsize].T)\n\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.mu = np.sum(self.weights * x[:, :self.popsize], axis=1)\n            \n            # Handle stagnation and restart with modified parameters\n            if self.best_f >= self.last_f:\n                self.stagnation_counter += self.popsize\n            else:\n                self.stagnation_counter = 0\n\n            self.last_f = self.best_f\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart with increased sigma and perturbed mean\n                self.sigma *= 1.5\n                self.mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim) + 0.1 * np.random.randn(self.dim) * (func.bounds.ub - func.bounds.lb)\n                self.mu = np.clip(self.mu, func.bounds.lb, func.bounds.ub) # keep within bounds\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                \n        return self.best_f, self.best_x", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: 'RestartCMAES' object has no attribute 'mu_eff'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A Covariance Matrix Adaptation Evolution Strategy (CMA-ES) variant that restarts with modified parameters when stagnation is detected, incorporating a simple diversity maintenance mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass RestartCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.2, popsize=None, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.stagnation_threshold = stagnation_threshold\n        self.best_f = np.inf\n        self.best_x = None\n\n    def __call__(self, func):\n        self.mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim)\n        self.sigma = self.sigma0\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (16 * self.dim**2))\n        self.c_sigma = (self.popsize + 2) / (self.dim + self.popsize + 5)\n        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.weights = np.log(self.popsize + 1 / 2) - np.log(np.arange(1, self.popsize + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mu_eff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu_eff)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu_eff - 2 + 1 / self.mu_eff) / ((self.dim + 2.3)**2 + self.mu_eff))\n        self.evals = 0\n        self.stagnation_counter = 0\n        self.last_f = np.inf\n\n        while self.evals < self.budget:\n            # Sample population\n            z = np.random.randn(self.dim, self.popsize)\n            B = np.linalg.cholesky(self.C)  # Efficiently compute C^(1/2)\n            x = self.mu[:, np.newaxis] + self.sigma * B @ z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            f = np.array([func(x[:, i]) for i in range(self.popsize)])\n            self.evals += self.popsize\n            \n            # Update best solution\n            for i in range(self.popsize):\n                if f[i] < self.best_f:\n                    self.best_f = f[i]\n                    self.best_x = x[:, i].copy()\n            \n            # Sort population\n            idx = np.argsort(f)\n            z = z[:, idx]\n            x = x[:, idx]\n            \n            # Update CMA-ES parameters\n            z_mean = np.sum(self.weights * z, axis=1)\n            y_mean = B @ z_mean\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * y_mean\n            \n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * self.evals / self.popsize)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c)) * y_mean\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) \\\n                     + self.c_mu * (z[:, :self.popsize] @ np.diag(self.weights) @ z[:, :self.popsize].T)\n\n            self.sigma = self.sigma * np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            self.mu = np.sum(self.weights * x[:, :self.popsize], axis=1)\n            \n            # Handle stagnation and restart with modified parameters\n            if self.best_f >= self.last_f:\n                self.stagnation_counter += self.popsize\n            else:\n                self.stagnation_counter = 0\n\n            self.last_f = self.best_f\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Restart with increased sigma and perturbed mean\n                self.sigma *= 1.5\n                self.mu = (func.bounds.ub + func.bounds.lb) / 2 * np.ones(self.dim) + 0.1 * np.random.randn(self.dim) * (func.bounds.ub - func.bounds.lb)\n                self.mu = np.clip(self.mu, func.bounds.lb, func.bounds.ub) # keep within bounds\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n                \n        return self.best_f, self.best_x\n```", "operator": "random_new", "theta_sampled": 0.17616889501547614, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "17adc6c6-6bc1-49d1-bfa0-f46bab47bd95", "fitness": 0.5760897555953839, "name": "HybridAdaptivePSO_DE_LocalSearch", "description": "A hybrid PSO-DE algorithm with adaptive parameter control, dynamic population scaling, and a local search operator to enhance exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Simple Gaussian perturbation\n        sigma = 0.01 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridAdaptivePSO_DE_LocalSearch scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ed532357-4777-4c15-9e7c-90b0c6dbca9b"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid PSO-DE algorithm with adaptive parameter control, dynamic population scaling, and a local search operator to enhance exploration and exploitation capabilities.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Simple Gaussian perturbation\n        sigma = 0.01 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.copy(self.population)\n            new_fitness = np.copy(self.fitness)\n            \n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19859841951816692, 0.5028746092205363, 0.5842540486649541, 0.8623594950704837, 0.6757889364410326, 0.7305316356985428, 0.385452576118549, 0.4955340773892216, 0.6137243226527969, 0.43686597313200914, 0.8576770372939994, 0.9950859943615663, 0.4528351958096978, 0.4570511868810969, 0.5855368702539624, 0.6840397138505929, 0.38253037018069735, 0.8202178623636448, 0.21614177068479878, 0.5846950163213294], "operator": "mutation", "theta_sampled": 0.28597242448155846, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "40182b4b-072f-45c1-97a0-69b9273ab62e", "fitness": 0.4675805286073501, "name": "AdaptiveHybridPSO_DE_v3", "description": "Adaptive Hybrid PSO-DE with improved DE mutation, velocity clamping, and parameter adaptation based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Rate to adapt F based on success.\n            CR_adapt_rate (float): Rate to adapt CR based on success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n\n                        # Clamp velocities\n                        max_velocity = 0.1 * (func.bounds.ub - func.bounds.lb)\n                        velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 4, replace=False)  # Choose 4 random indices\n                    x1, x2, x3, x4 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3) + self.F * (x4 - x1)  # Improved DE mutation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        # Adapt F and CR if improvement found\n                        self.F *= (1 - self.F_adapt_rate) + np.random.rand() * self.F_adapt_rate\n                        self.CR *= (1 - self.CR_adapt_rate) + np.random.rand() * self.CR_adapt_rate\n                        self.F = np.clip(self.F, 0.1, 1.0)\n                        self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.468 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with improved DE mutation, velocity clamping, and parameter adaptation based on fitness improvement.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Rate to adapt F based on success.\n            CR_adapt_rate (float): Rate to adapt CR based on success.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1 * (func.bounds.ub - func.bounds.lb)\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n\n                        # Clamp velocities\n                        max_velocity = 0.1 * (func.bounds.ub - func.bounds.lb)\n                        velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 4, replace=False)  # Choose 4 random indices\n                    x1, x2, x3, x4 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3) + self.F * (x4 - x1)  # Improved DE mutation\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        # Adapt F and CR if improvement found\n                        self.F *= (1 - self.F_adapt_rate) + np.random.rand() * self.F_adapt_rate\n                        self.CR *= (1 - self.CR_adapt_rate) + np.random.rand() * self.CR_adapt_rate\n                        self.F = np.clip(self.F, 0.1, 1.0)\n                        self.CR = np.clip(self.CR, 0.1, 1.0)\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14299082686012066, 0.16940826470958437, 0.48827837604503777, 0.19753795884404968, 0.530650641000415, 0.5146255246575215, 0.343047415683024, 0.5042052271946078, 0.4603913645861145, 0.206145244359207, 0.905684702578093, 0.99759517424884, 0.3195134933284367, 0.408034330823422, 0.8501166204803743, 0.5596037143284863, 0.4013405521239902, 0.6466249369203736, 0.2188284344346464, 0.48698776894065854], "operator": "mutation", "theta_sampled": 0.04591517053003366, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "5ba89d1a-67cf-4900-ac15-9f442c224b40", "fitness": 0.5174085987447168, "name": "AdaptiveHybridPSO_DE_v3", "description": "Dynamically adjusts PSO/DE balance and DE parameters based on success rates and remaining budget, while integrating an archive for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO.\n            archive_size_factor (float): Factor to determine archive size.\n            pso_weight_init (float): Initial PSO weight.\n            de_weight_init (float): Initial DE weight.\n            success_memory (int): Length of success history to remember.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                        if f_new < personal_best_fitness[i]:\n                            personal_best_fitness[i] = f_new\n                            personal_best_positions[i] = new_particle.copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.517 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3", "18151642-c8f0-4e17-8eb2-e2b31f0b6852"], "operator": "crossover", "metadata": {"llm_response": "# Description: Dynamically adjusts PSO/DE balance and DE parameters based on success rates and remaining budget, while integrating an archive for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO.\n            archive_size_factor (float): Factor to determine archive size.\n            pso_weight_init (float): Initial PSO weight.\n            de_weight_init (float): Initial DE weight.\n            success_memory (int): Length of success history to remember.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            remaining_ratio = self.budget / (self.budget + self.pop_size)\n            adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio\n            adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                        if f_new < personal_best_fitness[i]:\n                            personal_best_fitness[i] = f_new\n                            personal_best_positions[i] = new_particle.copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + adapted_F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < adapted_CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20091621630062395, 0.450386025004784, 0.5916049350461783, 0.17216621599940374, 0.39476484704878323, 0.6252477207799096, 0.3533139192995163, 0.4504171599497343, 0.6380015558294836, 0.5021641494790448, 0.8389595747093214, 0.9935957463430867, 0.4358366642570449, 0.3160935987093145, 0.89427665469261, 0.592833281839507, 0.4781418695223525, 0.6736796821102126, 0.2391408326869937, 0.5066313252864327], "operator": "crossover", "theta_sampled": -0.003472012831379479, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "cc079f89-5607-4979-a0c1-f48c783d43bc", "fitness": 0.5604605305204822, "name": "AdaptiveHybridPSO_DE_v3", "description": "Adaptively combines PSO and DE with success-based weighting and dynamic parameter adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9,\n                 local_search_prob = 0.05, local_search_radius = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and local search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            local_search_prob (float): Probability of performing a local search around the best solution.\n            local_search_radius (float): Radius of the local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n    def local_search(self, func):\n        \"\"\"Performs a local search around the best solution.\"\"\"\n        if np.random.rand() < self.local_search_prob and self.budget > self.dim * 10:\n            best_x = self.x_opt.copy()\n            for _ in range(self.dim * 10):\n                new_x = best_x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_x)\n                self.budget -= 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = new_x.copy()\n                    self.global_best_position = new_x.copy()\n                if self.budget <= 0:\n                    break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_DE_v3 scored 0.560 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3", "18151642-c8f0-4e17-8eb2-e2b31f0b6852"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with success-based weighting and dynamic parameter adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v3:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9,\n                 local_search_prob = 0.05, local_search_radius = 0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and local search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            local_search_prob (float): Probability of performing a local search around the best solution.\n            local_search_radius (float): Radius of the local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n    def local_search(self, func):\n        \"\"\"Performs a local search around the best solution.\"\"\"\n        if np.random.rand() < self.local_search_prob and self.budget > self.dim * 10:\n            best_x = self.x_opt.copy()\n            for _ in range(self.dim * 10):\n                new_x = best_x + np.random.uniform(-self.local_search_radius, self.local_search_radius, size=self.dim)\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                f_new = func(new_x)\n                self.budget -= 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = new_x.copy()\n                    self.global_best_position = new_x.copy()\n                if self.budget <= 0:\n                    break\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            self.local_search(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19533358709660487, 0.25831715852493076, 0.5171574780386421, 0.8704098494238519, 0.34393045845838677, 0.587174027330198, 0.32508844384635105, 0.4613120902031683, 0.6259701610932729, 0.627377938006163, 0.9180205566736152, 0.9980249236928866, 0.44772291369503237, 0.42571447640440396, 0.9011801506261654, 0.6905442821700711, 0.4748859635205671, 0.806943997036373, 0.1975921000159393, 0.5365100545530214], "operator": "crossover", "theta_sampled": -0.00733580981815684, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "01abb478-fcb0-4f3a-816d-dfc8f5debaf1", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Levy", "description": "Adaptive Hybrid PSO-DE with self-adaptive F and CR parameters for DE, fitness-aware strategy selection, and enhanced exploration using Lvy flights for PSO.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Levy:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 levy_exponent=1.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Lvy flights and adaptive F and CR.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            levy_exponent (float): Exponent for the Lvy flight distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.levy_exponent = levy_exponent\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.F_memory = np.ones(self.success_memory) * self.F\n        self.CR_memory = np.ones(self.success_memory) * self.CR\n        self.memory_idx = 0\n\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lvy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (\n            np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Levy flights and adaptive F and CR.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Fitness-aware strategy selection\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        # Exploration with Levy Flights\n                        levy_steps = self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                        velocities[i] = levy_steps\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with adaptive F and CR\n                    # Self-adaptive F and CR\n                    if len(self.F_memory) > 0:\n                        self.F = np.clip(np.random.normal(np.mean(self.F_memory), 0.1), 0.1, 1.0)\n                        self.CR = np.clip(np.random.normal(np.mean(self.CR_memory), 0.1), 0.1, 1.0)\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n\n                        # Update F and CR memory\n                        self.F_memory[self.memory_idx % self.success_memory] = self.F\n                        self.CR_memory[self.memory_idx % self.success_memory] = self.CR\n                        self.memory_idx +=1\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with self-adaptive F and CR parameters for DE, fitness-aware strategy selection, and enhanced exploration using Lvy flights for PSO.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_Levy:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 levy_exponent=1.5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with Lvy flights and adaptive F and CR.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            levy_exponent (float): Exponent for the Lvy flight distribution.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.levy_exponent = levy_exponent\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.F_memory = np.ones(self.success_memory) * self.F\n        self.CR_memory = np.ones(self.success_memory) * self.CR\n        self.memory_idx = 0\n\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generates Lvy flight steps.\n        \"\"\"\n        u = np.random.normal(0, 1, size=size)\n        v = np.random.normal(0, 1, size=size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) / (\n            np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / (np.abs(v) ** (1 / self.levy_exponent))\n        return step\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with Levy flights and adaptive F and CR.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Fitness-aware strategy selection\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        # Exploration with Levy Flights\n                        levy_steps = self.levy_flight(self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                        velocities[i] = levy_steps\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with adaptive F and CR\n                    # Self-adaptive F and CR\n                    if len(self.F_memory) > 0:\n                        self.F = np.clip(np.random.normal(np.mean(self.F_memory), 0.1), 0.1, 1.0)\n                        self.CR = np.clip(np.random.normal(np.mean(self.CR_memory), 0.1), 0.1, 1.0)\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n\n                        # Update F and CR memory\n                        self.F_memory[self.memory_idx % self.success_memory] = self.F\n                        self.CR_memory[self.memory_idx % self.success_memory] = self.CR\n                        self.memory_idx +=1\n\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.1537057928319174, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "d58cfa94-6212-4b03-8d25-6767cac52db0", "fitness": 0.6308955869022915, "name": "NichingDifferentialEvolution", "description": "Population-based search using a combination of differential evolution and a niching strategy to maintain diversity and explore multiple local optima.", "code": "import numpy as np\n\nclass NichingDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.niche_radius = niche_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                x_mutated = x_1 + self.F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                #Niche Comparison (Crowding Distance Approximation)\n                if self.evals > self.budget:\n                    break\n\n                dist = np.linalg.norm(self.population - x_trial, axis=1)\n                nearby_indices = np.where(dist < self.niche_radius)[0]\n                \n                if len(nearby_indices) > 0:\n                    #Replace the worst member in the niche\n                    worst_index = nearby_indices[np.argmax(self.fitness[nearby_indices])]\n                    if f_trial < self.fitness[worst_index]:\n                        self.population[worst_index] = x_trial\n                        self.fitness[worst_index] = f_trial\n                else:\n                    #If no niche replace worst overall\n                    worst_index = np.argmax(self.fitness)\n                    if f_trial < self.fitness[worst_index]:\n                        self.population[worst_index] = x_trial\n                        self.fitness[worst_index] = f_trial\n                \n                # Update best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm NichingDifferentialEvolution scored 0.631 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search using a combination of differential evolution and a niching strategy to maintain diversity and explore multiple local optima.\n# Code: \n```python\nimport numpy as np\n\nclass NichingDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.7, CR=0.9, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.niche_radius = niche_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.evals = self.pop_size\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                x_mutated = x_1 + self.F * (x_2 - x_3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = self.population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.evals += 1\n\n                #Niche Comparison (Crowding Distance Approximation)\n                if self.evals > self.budget:\n                    break\n\n                dist = np.linalg.norm(self.population - x_trial, axis=1)\n                nearby_indices = np.where(dist < self.niche_radius)[0]\n                \n                if len(nearby_indices) > 0:\n                    #Replace the worst member in the niche\n                    worst_index = nearby_indices[np.argmax(self.fitness[nearby_indices])]\n                    if f_trial < self.fitness[worst_index]:\n                        self.population[worst_index] = x_trial\n                        self.fitness[worst_index] = f_trial\n                else:\n                    #If no niche replace worst overall\n                    worst_index = np.argmax(self.fitness)\n                    if f_trial < self.fitness[worst_index]:\n                        self.population[worst_index] = x_trial\n                        self.fitness[worst_index] = f_trial\n                \n                # Update best\n                if f_trial < self.f_opt:\n                    self.f_opt = f_trial\n                    self.x_opt = x_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18013469325896891, 0.5723767050628092, 0.62906955632573, 0.848340492788645, 0.6629761100112861, 0.7793209479206586, 0.48649372060103346, 0.6076803208735404, 0.6947771710676002, 0.4323122707274528, 0.8137839062295477, 0.9994113113290495, 0.5632843477720801, 0.6578972947518708, 0.9083366678880566, 0.7595861379639085, 0.4832279998589598, 0.8327826457744558, 0.20920823388524823, 0.4969112039549275], "operator": "random_new", "theta_sampled": 0.2320145510931716, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "ef2e9ba6-80af-4104-8140-df0dbdd84a8e", "fitness": 0.0, "name": "HybridAdaptivePSO_DE_LocalSearch_Enhanced", "description": "Hybrid Adaptive PSO-DE with enhanced local search, population diversity maintenance, and adaptive parameter control based on success rates and remaining budget.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99,\n                 local_search_intensity=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.local_search_intensity = local_search_intensity # Controls local search step size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Adaptive Gaussian perturbation\n        sigma = self.local_search_intensity * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                method = np.random.choice([\"pso\", \"de\", \"local_search\"], p=[self.pso_weight, self.de_weight, self.local_search_prob])\n\n                if method == \"pso\" and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif method == \"de\" and self.budget > 0:\n                    self.de_step(func, i)\n\n                elif method == \"local_search\" and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: probabilities do not sum to 1", "parent_ids": ["17adc6c6-6bc1-49d1-bfa0-f46bab47bd95"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid Adaptive PSO-DE with enhanced local search, population diversity maintenance, and adaptive parameter control based on success rates and remaining budget.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch_Enhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99,\n                 local_search_intensity=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.local_search_intensity = local_search_intensity # Controls local search step size\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Adaptive Gaussian perturbation\n        sigma = self.local_search_intensity * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n            \n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                method = np.random.choice([\"pso\", \"de\", \"local_search\"], p=[self.pso_weight, self.de_weight, self.local_search_prob])\n\n                if method == \"pso\" and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif method == \"de\" and self.budget > 0:\n                    self.de_step(func, i)\n\n                elif method == \"local_search\" and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.24655650344399818, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "27d1d7b5-91d6-4725-85af-c64f6b58f57c", "fitness": 0.5706097134990206, "name": "AdaptiveHybridPSO_DE_v2", "description": "Adaptive Hybrid PSO-DE with dynamic parameter control based on success rates, using a larger archive and an enhanced DE mutation strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.5,  # Increased archive size\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adaptive=True, CR_adaptive=True):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adaptive (bool): Whether to adapt F.\n            CR_adaptive (bool): Whether to adapt CR.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with enhanced mutation strategy (DE/current-to-rand/1)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = population[idxs]\n                    rand_idx = np.random.randint(0, self.pop_size)\n                    mutant = population[i] + self.F * (x1 - x2) + self.F * (population[rand_idx] - population[i])  # Modified mutation\n\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Adaptive F and CR\n            if self.F_adaptive and generation % 5 == 0:  # Update every 5 generations\n                if self.de_success_history:\n                    success_rate = np.mean(self.de_success_history)\n                    self.F = np.clip(self.F * (1 + 0.2 * (success_rate - 0.5)), 0.1, 0.9)  # Adapt F\n            if self.CR_adaptive and generation % 5 == 0:\n                 if self.de_success_history:\n                    success_rate = np.mean(self.de_success_history)\n                    self.CR = np.clip(self.CR * (1 + 0.2 * (success_rate - 0.5)), 0.1, 0.9)  # Adapt CR\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DE_v2 scored 0.571 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with dynamic parameter control based on success rates, using a larger archive and an enhanced DE mutation strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.5,  # Increased archive size\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adaptive=True, CR_adaptive=True):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adaptive (bool): Whether to adapt F.\n            CR_adaptive (bool): Whether to adapt CR.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adaptive = F_adaptive\n        self.CR_adaptive = CR_adaptive\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with enhanced mutation strategy (DE/current-to-rand/1)\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    x1, x2 = population[idxs]\n                    rand_idx = np.random.randint(0, self.pop_size)\n                    mutant = population[i] + self.F * (x1 - x2) + self.F * (population[rand_idx] - population[i])  # Modified mutation\n\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Adaptive F and CR\n            if self.F_adaptive and generation % 5 == 0:  # Update every 5 generations\n                if self.de_success_history:\n                    success_rate = np.mean(self.de_success_history)\n                    self.F = np.clip(self.F * (1 + 0.2 * (success_rate - 0.5)), 0.1, 0.9)  # Adapt F\n            if self.CR_adaptive and generation % 5 == 0:\n                 if self.de_success_history:\n                    success_rate = np.mean(self.de_success_history)\n                    self.CR = np.clip(self.CR * (1 + 0.2 * (success_rate - 0.5)), 0.1, 0.9)  # Adapt CR\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20218411745135478, 0.30410638702039516, 0.4163833694478276, 0.9076099726010486, 0.5488854135472357, 0.7386551265872501, 0.3566606107059571, 0.4425105855827246, 0.7522211377668567, 0.3229197677643455, 0.9280542825302016, 0.9998311349690715, 0.2946239111033121, 0.5173676385831214, 0.781855332757402, 0.7400524681895789, 0.4372044696705928, 0.9035325196118834, 0.32088908648252124, 0.4966469376077298], "operator": "mutation", "theta_sampled": 0.029755982413927403, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "f1127016-71cf-4616-8cc4-b7ee47ad65e2", "fitness": 0.668791154302739, "name": "AdaptiveHybridPSO_DERestart", "description": "Adaptively adjusts PSO/DE weights based on success, enhances DE with JADE-inspired adaptation of F and CR, and incorporates a restart mechanism for stagnation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1, restart_patience=50, restart_threshold=1e-5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with JADE-inspired adaptation and restart mechanism.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Adaptation rate for F.\n            CR_adapt_rate (float): Adaptation rate for CR.\n            restart_patience (int): Number of iterations to wait before restarting if no improvement.\n            restart_threshold (float): Threshold for improvement to avoid restarts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.restart_patience = restart_patience\n        self.restart_threshold = restart_threshold\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with JADE-inspired adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        memory_F = []\n        memory_CR = []\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with JADE-inspired adaptation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Adapt CR for each individual\n                    CR_i = np.random.normal(self.CR, self.CR_adapt_rate)\n                    CR_i = np.clip(CR_i, 0, 1)\n\n                    crossover_mask = np.random.rand(self.dim) < CR_i\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        memory_F.append(self.F)\n                        memory_CR.append(CR_i)\n\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR (JADE-inspired)\n            if memory_F:\n                self.F = (1 - self.F_adapt_rate) * self.F + self.F_adapt_rate * np.mean(memory_F)\n                self.F = np.clip(self.F, 0.1, 1.0) # keep F within a reasonable range\n\n            if memory_CR:\n                 self.CR = (1 - self.CR_adapt_rate) * self.CR + self.CR_adapt_rate * np.mean(memory_CR)\n                 self.CR = np.clip(self.CR, 0.1, 1.0) # keep CR within a reasonable range\n            memory_F = []\n            memory_CR = []\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_patience:\n                # Check if there's been sufficient improvement\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_patience-1]) < self.restart_threshold:\n                    # Re-initialize population (restart)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n\n                    # Re-initialize PSO-specific variables\n                    velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                    personal_best_positions = population.copy()\n                    personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    global_best_position = population[global_best_index].copy()\n                    self.f_opt = personal_best_fitness[global_best_index].copy()\n                    self.x_opt = global_best_position.copy()\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                    self.best_fitness_history.append(self.f_opt)  #add to history after restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_DERestart scored 0.669 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively adjusts PSO/DE weights based on success, enhances DE with JADE-inspired adaptation of F and CR, and incorporates a restart mechanism for stagnation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1, restart_patience=50, restart_threshold=1e-5):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with JADE-inspired adaptation and restart mechanism.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Adaptation rate for F.\n            CR_adapt_rate (float): Adaptation rate for CR.\n            restart_patience (int): Number of iterations to wait before restarting if no improvement.\n            restart_threshold (float): Threshold for improvement to avoid restarts.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.restart_patience = restart_patience\n        self.restart_threshold = restart_threshold\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with JADE-inspired adaptation.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        memory_F = []\n        memory_CR = []\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with JADE-inspired adaptation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Adapt CR for each individual\n                    CR_i = np.random.normal(self.CR, self.CR_adapt_rate)\n                    CR_i = np.clip(CR_i, 0, 1)\n\n                    crossover_mask = np.random.rand(self.dim) < CR_i\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        memory_F.append(self.F)\n                        memory_CR.append(CR_i)\n\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR (JADE-inspired)\n            if memory_F:\n                self.F = (1 - self.F_adapt_rate) * self.F + self.F_adapt_rate * np.mean(memory_F)\n                self.F = np.clip(self.F, 0.1, 1.0) # keep F within a reasonable range\n\n            if memory_CR:\n                 self.CR = (1 - self.CR_adapt_rate) * self.CR + self.CR_adapt_rate * np.mean(memory_CR)\n                 self.CR = np.clip(self.CR, 0.1, 1.0) # keep CR within a reasonable range\n            memory_F = []\n            memory_CR = []\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Restart mechanism\n            if self.stagnation_counter > self.restart_patience:\n                # Check if there's been sufficient improvement\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_patience-1]) < self.restart_threshold:\n                    # Re-initialize population (restart)\n                    population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    self.budget -= self.pop_size\n\n                    # Re-initialize PSO-specific variables\n                    velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                    personal_best_positions = population.copy()\n                    personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    global_best_position = population[global_best_index].copy()\n                    self.f_opt = personal_best_fitness[global_best_index].copy()\n                    self.x_opt = global_best_position.copy()\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                    self.best_fitness_history.append(self.f_opt)  #add to history after restart\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21116849672030868, 0.2324401136250387, 0.7493809279717103, 0.9209077044045123, 0.7993726730666754, 0.8478884953210082, 0.7384888594543516, 0.7483632822586166, 0.6095586044897527, 0.37842007111200626, 0.919261631232369, 0.9974217158641172, 0.34162367705699914, 0.7781339667653301, 0.8602346735711459, 0.8490985952524394, 0.7428917090439372, 0.8734329121207918, 0.2464796990816659, 0.5312552776420032], "operator": "mutation", "theta_sampled": 0.018974024178535748, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "a1d8c838-184d-4ef0-9df2-f9a8cca81b35", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_v4", "description": "Adaptively combines PSO and DE with a shrinking population, archive-based learning, and dynamic parameter adjustments for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_v4:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 F_init=0.5, CR_init=0.9, local_search_prob=0.05,\n                 min_pop_size=10, pop_decay_rate=0.99, F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with shrinking population and archive-based learning.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The initial population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            local_search_prob (float): Probability of applying local search.\n            min_pop_size (int): Minimum population size allowed.\n            pop_decay_rate (float): Rate at which population size shrinks.\n            F_adapt_rate (float): Adaptation rate for DE mutation factor.\n            CR_adapt_rate (float): Adaptation rate for DE crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around the given solution.\"\"\"\n        sigma = 0.01 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE step.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + self.F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            # Improvement found, update DE parameters stochastically\n            self.F = self.F + self.F_adapt_rate * np.random.normal(0, 1)\n            self.CR = self.CR + self.CR_adapt_rate * np.random.normal(0, 0.1)\n            self.F = np.clip(self.F, 0.1, 0.9) # Bound mutation factor\n            self.CR = np.clip(self.CR, 0.1, 0.9) # Bound crossover rate\n\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, len(self.archive))\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO step.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size)\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n            \n            # Population shrinking\n            if self.current_pop_size > self.min_pop_size:\n                 new_pop_size = int(self.initial_pop_size * (self.pop_decay_rate**(1-self.budget/self.initial_pop_size)))\n                 new_pop_size = max(self.min_pop_size, new_pop_size)\n                 if new_pop_size < self.current_pop_size:\n                    # Sort by fitness and trim the population\n                    sorted_indices = np.argsort(self.fitness)\n                    self.population = self.population[sorted_indices[:new_pop_size]]\n                    self.fitness = self.fitness[sorted_indices[:new_pop_size]]\n                    self.personal_best_positions = self.personal_best_positions[sorted_indices[:new_pop_size]]\n                    self.personal_best_fitness = self.personal_best_fitness[sorted_indices[:new_pop_size]]\n                    self.velocities = self.velocities[sorted_indices[:new_pop_size]]\n                    self.pop_size = new_pop_size\n                    self.current_pop_size = new_pop_size\n                    self.archive_size = int(self.pop_size * archive_size_factor) #Update archive size\n                    if len(self.archive) > self.archive_size:\n                        self.archive = self.archive[:self.archive_size] #Trim the archive\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: name 'archive_size_factor' is not defined", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3", "17adc6c6-6bc1-49d1-bfa0-f46bab47bd95"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptively combines PSO and DE with a shrinking population, archive-based learning, and dynamic parameter adjustments for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_v4:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 F_init=0.5, CR_init=0.9, local_search_prob=0.05,\n                 min_pop_size=10, pop_decay_rate=0.99, F_adapt_rate=0.1, CR_adapt_rate=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with shrinking population and archive-based learning.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The initial population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            local_search_prob (float): Probability of applying local search.\n            min_pop_size (int): Minimum population size allowed.\n            pop_decay_rate (float): Rate at which population size shrinks.\n            F_adapt_rate (float): Adaptation rate for DE mutation factor.\n            CR_adapt_rate (float): Adaptation rate for DE crossover rate.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def local_search(self, func, x):\n        \"\"\"Performs a local search around the given solution.\"\"\"\n        sigma = 0.01 * (func.bounds.ub - func.bounds.lb)\n        new_x = x + np.random.normal(0, sigma, self.dim)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        return new_x, f_new\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE step.\"\"\"\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + self.F * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            # Improvement found, update DE parameters stochastically\n            self.F = self.F + self.F_adapt_rate * np.random.normal(0, 1)\n            self.CR = self.CR + self.CR_adapt_rate * np.random.normal(0, 0.1)\n            self.F = np.clip(self.F, 0.1, 0.9) # Bound mutation factor\n            self.CR = np.clip(self.CR, 0.1, 0.9) # Bound crossover rate\n\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, len(self.archive))\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO step.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size)\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n            \n            # Population shrinking\n            if self.current_pop_size > self.min_pop_size:\n                 new_pop_size = int(self.initial_pop_size * (self.pop_decay_rate**(1-self.budget/self.initial_pop_size)))\n                 new_pop_size = max(self.min_pop_size, new_pop_size)\n                 if new_pop_size < self.current_pop_size:\n                    # Sort by fitness and trim the population\n                    sorted_indices = np.argsort(self.fitness)\n                    self.population = self.population[sorted_indices[:new_pop_size]]\n                    self.fitness = self.fitness[sorted_indices[:new_pop_size]]\n                    self.personal_best_positions = self.personal_best_positions[sorted_indices[:new_pop_size]]\n                    self.personal_best_fitness = self.personal_best_fitness[sorted_indices[:new_pop_size]]\n                    self.velocities = self.velocities[sorted_indices[:new_pop_size]]\n                    self.pop_size = new_pop_size\n                    self.current_pop_size = new_pop_size\n                    self.archive_size = int(self.pop_size * archive_size_factor) #Update archive size\n                    if len(self.archive) > self.archive_size:\n                        self.archive = self.archive[:self.archive_size] #Trim the archive\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.0005369879276572228, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "8480a634-b369-42c1-99a0-7d0e4b3df47e", "fitness": 0.2913425966493137, "name": "AdaptiveGradientSearch", "description": "An adaptive search algorithm that combines gradient estimation with random exploration, dynamically adjusting step sizes based on local function behavior.", "code": "import numpy as np\n\nclass AdaptiveGradientSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.exploration_rate = exploration_rate\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.x_opt = x\n        self.f_opt = func(x)\n        eval_count = 1\n        \n        while eval_count < self.budget:\n            # Gradient estimation via finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = self.step_size # Perturbation size\n                \n                x_plus[i] = min(func.bounds.ub[i], x[i] + delta)\n                x_minus[i] = max(func.bounds.lb[i], x[i] - delta)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                \n                eval_count += 2\n                if eval_count >= self.budget:\n                    break\n\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n                \n            if eval_count >= self.budget:\n                break\n\n            # Adaptive step size adjustment\n            norm_grad = np.linalg.norm(gradient)\n            if norm_grad > 0:\n                direction = -gradient / norm_grad\n                x_new = x + self.step_size * direction\n            else:\n                x_new = x # No gradient, stay put\n\n            # Random Exploration\n            if np.random.rand() < self.exploration_rate:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)  # Ensure bounds are respected.\n            f_new = func(x_new)\n            eval_count += 1\n\n            if eval_count >= self.budget:\n                break\n\n            #Acceptance criterion (Greedy)\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new # Move to new position\n\n                # Reduce step size if progress is made\n                self.step_size *= 1.1\n            else:\n                # Increase step size if no progress\n                self.step_size *= 0.9\n            \n            self.step_size = np.clip(self.step_size, 1e-6, 1.0) #Bound step size.\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveGradientSearch scored 0.291 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive search algorithm that combines gradient estimation with random exploration, dynamically adjusting step sizes based on local function behavior.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGradientSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.exploration_rate = exploration_rate\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.x_opt = x\n        self.f_opt = func(x)\n        eval_count = 1\n        \n        while eval_count < self.budget:\n            # Gradient estimation via finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = self.step_size # Perturbation size\n                \n                x_plus[i] = min(func.bounds.ub[i], x[i] + delta)\n                x_minus[i] = max(func.bounds.lb[i], x[i] - delta)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                \n                eval_count += 2\n                if eval_count >= self.budget:\n                    break\n\n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n                \n            if eval_count >= self.budget:\n                break\n\n            # Adaptive step size adjustment\n            norm_grad = np.linalg.norm(gradient)\n            if norm_grad > 0:\n                direction = -gradient / norm_grad\n                x_new = x + self.step_size * direction\n            else:\n                x_new = x # No gradient, stay put\n\n            # Random Exploration\n            if np.random.rand() < self.exploration_rate:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)  # Ensure bounds are respected.\n            f_new = func(x_new)\n            eval_count += 1\n\n            if eval_count >= self.budget:\n                break\n\n            #Acceptance criterion (Greedy)\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new # Move to new position\n\n                # Reduce step size if progress is made\n                self.step_size *= 1.1\n            else:\n                # Increase step size if no progress\n                self.step_size *= 0.9\n            \n            self.step_size = np.clip(self.step_size, 1e-6, 1.0) #Bound step size.\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.0797542088227261, 0.14569170537243192, 0.21117653815518755, 0.15425166244102673, 0.13618291607907562, 0.15812082271738837, 0.2636491994600555, 0.17304115898846417, 0.21396936461293048, 0.14712794309878008, 0.19800192207352896, 0.9579832139923945, 0.25108512455362, 0.16327795836674008, 0.5821001132157435, 0.30998404635170596, 0.24905828763716786, 0.901997725731877, 0.12378194859868508, 0.4066160727167447], "operator": "random_new", "theta_sampled": 0.15203090589452428, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "3d502c84-eec7-4ccb-ac6d-7eb9248f1d89", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_CMAES", "description": "Adaptive Hybrid PSO-DE with population size reduction based on stagnation detection and CMA-ES-based local search.", "code": "import numpy as np\nimport cmalib\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, stagnation_threshold=10, pop_decay_rate=0.95, min_pop_size=10,\n                 cmaes_restarts=2, cmaes_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.pop_decay_rate = pop_decay_rate\n        self.min_pop_size = min_pop_size\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.cmaes_restarts = cmaes_restarts\n        self.cmaes_sigma = cmaes_sigma\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search_cmaes(self, func, x):\n        es = cmalib.CMAPopulation(self.dim, x, self.cmaes_sigma, func.bounds.lb, func.bounds.ub, seed=None)\n        best_f = np.inf\n        best_x = None\n        \n        for _ in range(self.cmaes_restarts):\n            es.sample()\n            solutions = es.ask()\n            \n            fitness_values = []\n            for sol in solutions:\n              f = func(sol)\n              fitness_values.append(f)\n              self.budget -= 1\n              if f < best_f:\n                  best_f = f\n                  best_x = sol\n              if self.budget <= 0:\n                return best_x, best_f\n\n            es.tell(fitness_values)\n            \n            if self.budget <= 0:\n                break\n        return best_x, best_f\n\n    def reduce_population_size(self):\n        if self.current_pop_size > self.min_pop_size:\n            new_pop_size = int(self.current_pop_size * self.pop_decay_rate)\n            new_pop_size = max(new_pop_size, self.min_pop_size)\n            \n            #Sort population by fitness and keep the best individuals\n            sorted_indices = np.argsort(self.fitness)\n            self.population = self.population[sorted_indices[:new_pop_size]]\n            self.fitness = self.fitness[sorted_indices[:new_pop_size]]\n            self.velocities = self.velocities[sorted_indices[:new_pop_size]]\n            self.personal_best_positions = self.personal_best_positions[sorted_indices[:new_pop_size]]\n            self.personal_best_fitness = self.personal_best_fitness[sorted_indices[:new_pop_size]]\n\n            self.pop_size = new_pop_size\n            self.current_pop_size = new_pop_size\n            self.archive_size = int(self.pop_size * 0.2)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search_cmaes(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            #Stagnation Detection and Population Size Reduction\n            if self.f_opt >= self.best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_threshold:\n                self.reduce_population_size()\n                self.stagnation_counter = 0\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: No module named 'cmalib'", "parent_ids": ["17adc6c6-6bc1-49d1-bfa0-f46bab47bd95"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with population size reduction based on stagnation detection and CMA-ES-based local search.\n# Code: \n```python\nimport numpy as np\nimport cmalib\n\nclass AdaptiveHybridPSO_DE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, stagnation_threshold=10, pop_decay_rate=0.95, min_pop_size=10,\n                 cmaes_restarts=2, cmaes_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.pop_decay_rate = pop_decay_rate\n        self.min_pop_size = min_pop_size\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.cmaes_restarts = cmaes_restarts\n        self.cmaes_sigma = cmaes_sigma\n        self.best_fitness_history = []\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search_cmaes(self, func, x):\n        es = cmalib.CMAPopulation(self.dim, x, self.cmaes_sigma, func.bounds.lb, func.bounds.ub, seed=None)\n        best_f = np.inf\n        best_x = None\n        \n        for _ in range(self.cmaes_restarts):\n            es.sample()\n            solutions = es.ask()\n            \n            fitness_values = []\n            for sol in solutions:\n              f = func(sol)\n              fitness_values.append(f)\n              self.budget -= 1\n              if f < best_f:\n                  best_f = f\n                  best_x = sol\n              if self.budget <= 0:\n                return best_x, best_f\n\n            es.tell(fitness_values)\n            \n            if self.budget <= 0:\n                break\n        return best_x, best_f\n\n    def reduce_population_size(self):\n        if self.current_pop_size > self.min_pop_size:\n            new_pop_size = int(self.current_pop_size * self.pop_decay_rate)\n            new_pop_size = max(new_pop_size, self.min_pop_size)\n            \n            #Sort population by fitness and keep the best individuals\n            sorted_indices = np.argsort(self.fitness)\n            self.population = self.population[sorted_indices[:new_pop_size]]\n            self.fitness = self.fitness[sorted_indices[:new_pop_size]]\n            self.velocities = self.velocities[sorted_indices[:new_pop_size]]\n            self.personal_best_positions = self.personal_best_positions[sorted_indices[:new_pop_size]]\n            self.personal_best_fitness = self.personal_best_fitness[sorted_indices[:new_pop_size]]\n\n            self.pop_size = new_pop_size\n            self.current_pop_size = new_pop_size\n            self.archive_size = int(self.pop_size * 0.2)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search_cmaes(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            #Stagnation Detection and Population Size Reduction\n            if self.f_opt >= self.best_fitness_history[-1]:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter >= self.stagnation_threshold:\n                self.reduce_population_size()\n                self.stagnation_counter = 0\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > self.stagnation_threshold:\n                self.best_fitness_history.pop(0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.4733618931150537, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "212dddcd-3899-4e28-8eac-35426aa46cd0", "fitness": 0.5142768235279556, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Enhanced Adaptive Hybrid PSO-DE with velocity clamping, archive-based mutation, and periodic local search for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight=0.5, de_weight=0.5, success_memory=10, archive_size_factor=0.2,\n                 velocity_clamp_factor=0.1, local_search_frequency=20):\n        \"\"\"\n        Initializes the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n            velocity_clamp_factor (float): Factor to clamp velocities in PSO.\n            local_search_frequency (int): Frequency of performing local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.local_search_frequency = local_search_frequency\n        self.iteration = 0\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n\n            # Velocity clamping\n            v_max = self.velocity_clamp_factor * (func.bounds.ub - func.bounds.lb)\n            self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        # Enhanced mutation: use archive with a probability\n        if np.random.rand() < 0.2 and len(self.archive) > 0:\n            xa = self.archive[np.random.randint(0, len(self.archive))]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutant = xa + adapted_F * (x1 - x2)  # Archive based mutation\n        else:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n    def local_search(self, func):\n        \"\"\"Performs local search around the best solution.\"\"\"\n        scale = 0.01 * (func.bounds.ub - func.bounds.lb)  # Define a scale for perturbation\n\n        for _ in range(5):  # Perform a few local search steps\n            perturbation = np.random.normal(0, scale, self.dim)\n            new_x = self.x_opt + perturbation\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_x)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_x.copy()\n                self.global_best_position = new_x.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.iteration += 1\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            # Perform local search periodically\n            if self.iteration % self.local_search_frequency == 0 and self.budget > 0:\n                self.local_search(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE scored 0.514 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["18151642-c8f0-4e17-8eb2-e2b31f0b6852"], "operator": "mutation", "metadata": {"llm_response": "# Description: Enhanced Adaptive Hybrid PSO-DE with velocity clamping, archive-based mutation, and periodic local search for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5, exploration_rate=0.1,\n                 min_F=0.1, max_F=0.9, min_CR=0.1, max_CR=0.9, pso_weight=0.5, de_weight=0.5, success_memory=10, archive_size_factor=0.2,\n                 velocity_clamp_factor=0.1, local_search_frequency=20):\n        \"\"\"\n        Initializes the Enhanced Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int): The population size.\n            inertia (float): Inertia weight for PSO.\n            cognitive_coeff (float): Cognitive coefficient for PSO.\n            social_coeff (float): Social coefficient for PSO.\n            exploration_rate (float): Exploration rate for PSO.\n            min_F (float): Minimum mutation factor for DE.\n            max_F (float): Maximum mutation factor for DE.\n            min_CR (float): Minimum crossover rate for DE.\n            max_CR (float): Maximum crossover rate for DE.\n            pso_weight (float): Initial weight for PSO.\n            de_weight (float): Initial weight for DE.\n            success_memory (int): How many iterations to remember the success rate.\n            archive_size_factor (float): Factor to determine the archive size for DE.\n            velocity_clamp_factor (float): Factor to clamp velocities in PSO.\n            local_search_frequency (int): Frequency of performing local search.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.min_F = min_F\n        self.max_F = max_F\n        self.min_CR = min_CR\n        self.max_CR = max_CR\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.success_memory = success_memory\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.velocity_clamp_factor = velocity_clamp_factor\n        self.local_search_frequency = local_search_frequency\n        self.iteration = 0\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def initialize_population(self, func):\n        \"\"\"Initializes the population with random values within the bounds.\"\"\"\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n\n    def pso_step(self, func, i):\n        \"\"\"Performs a PSO update step for a single particle.\"\"\"\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n\n            # Velocity clamping\n            v_max = self.velocity_clamp_factor * (func.bounds.ub - func.bounds.lb)\n            self.velocities[i] = np.clip(self.velocities[i], -v_max, v_max)\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func, i):\n        \"\"\"Performs a DE update step for a single individual.\"\"\"\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_F = self.min_F + (self.max_F - self.min_F) * remaining_ratio  # Linearly scale F\n        adapted_CR = self.min_CR + (self.max_CR - self.min_CR) * remaining_ratio  # Linearly scale CR\n\n        # Enhanced mutation: use archive with a probability\n        if np.random.rand() < 0.2 and len(self.archive) > 0:\n            xa = self.archive[np.random.randint(0, len(self.archive))]\n            idxs = np.random.choice(self.pop_size, 2, replace=False)\n            x1, x2 = self.population[idxs]\n            mutant = xa + adapted_F * (x1 - x2)  # Archive based mutation\n        else:\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.population[idxs]\n            mutant = x1 + adapted_F * (x2 - x3)\n\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_CR\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector\n                self.global_best_position = trial_vector.copy()\n\n    def local_search(self, func):\n        \"\"\"Performs local search around the best solution.\"\"\"\n        scale = 0.01 * (func.bounds.ub - func.bounds.lb)  # Define a scale for perturbation\n\n        for _ in range(5):  # Perform a few local search steps\n            perturbation = np.random.normal(0, scale, self.dim)\n            new_x = self.x_opt + perturbation\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            f_new = func(new_x)\n            self.budget -= 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = new_x.copy()\n                self.global_best_position = new_x.copy()\n\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func: The function to optimize.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.iteration += 1\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            # Adaptive weighting based on success history\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            self.pso_success = 0\n            self.de_success = 0\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                if np.random.rand() < self.pso_weight:\n                    self.pso_step(func, i)\n                else:\n                    self.de_step(func, i)\n\n                new_population[i] = self.population[i]\n                new_fitness[i] = self.fitness[i]\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            # Update population\n            self.population = new_population\n            self.fitness = new_fitness\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            # Perform local search periodically\n            if self.iteration % self.local_search_frequency == 0 and self.budget > 0:\n                self.local_search(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13150546826713838, 0.2629608789564438, 0.4949377988921042, 0.9038679644807907, 0.5127862434501027, 0.630114055981261, 0.315911418036829, 0.5378370475813893, 0.4783239019245842, 0.24722510363010186, 0.8201475996445319, 0.9926515344088637, 0.3500822005922345, 0.3067424815948223, 0.8788929601496874, 0.5448564360920716, 0.4591893376978473, 0.6890492231129264, 0.2245266168047909, 0.5039281992605923], "operator": "mutation", "theta_sampled": 0.00888874354844043, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "1d7883e3-1153-4543-a0eb-2133b44a9487", "fitness": 0.0, "name": "AdaptiveHybridPSONiche_DERestart", "description": "Implements a self-adaptive hybrid PSO-DE with a novel diversity maintenance strategy based on niching and a memory-based restart to escape local optima.", "code": "import numpy as np\n\nclass AdaptiveHybridPSONiche_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1, restart_patience=50, restart_threshold=1e-5,\n                 niche_radius=0.5, niche_selection_pressure=2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching for diversity and memory-based restart.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Adaptation rate for F.\n            CR_adapt_rate (float): Adaptation rate for CR.\n            restart_patience (int): Number of iterations to wait before restarting if no improvement.\n            restart_threshold (float): Threshold for improvement to avoid restarts.\n            niche_radius (float): Radius of the niche for crowding.\n            niche_selection_pressure (int): Selection pressure within a niche.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.restart_patience = restart_patience\n        self.restart_threshold = restart_threshold\n        self.niche_radius = niche_radius\n        self.niche_selection_pressure = niche_selection_pressure\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n        self.memory_population = None\n        self.memory_fitness = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with niching and memory-based restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        memory_F = []\n        memory_CR = []\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with JADE-inspired adaptation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Adapt CR for each individual\n                    CR_i = np.random.normal(self.CR, self.CR_adapt_rate)\n                    CR_i = np.clip(CR_i, 0, 1)\n\n                    crossover_mask = np.random.rand(self.dim) < CR_i\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        memory_F.append(self.F)\n                        memory_CR.append(CR_i)\n\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR (JADE-inspired)\n            if memory_F:\n                self.F = (1 - self.F_adapt_rate) * self.F + self.F_adapt_rate * np.mean(memory_F)\n                self.F = np.clip(self.F, 0.1, 1.0) # keep F within a reasonable range\n\n            if memory_CR:\n                 self.CR = (1 - self.CR_adapt_rate) * self.CR + self.CR_adapt_rate * np.mean(memory_CR)\n                 self.CR = np.clip(self.CR, 0.1, 1.0) # keep CR within a reasonable range\n            memory_F = []\n            memory_CR = []\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Niching implementation - Crowding based replacement\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(population - population[i], axis=1)\n                niche_members = np.where(distances < self.niche_radius)[0]\n\n                if len(niche_members) > 1:  # Niche is crowded\n                    # Sort niche members by fitness\n                    niche_fitnesses = fitness[niche_members]\n                    sorted_indices = np.argsort(niche_fitnesses)\n                    worst_index = niche_members[sorted_indices[-1]]  # Index of the worst member\n\n                    # Replace the worst member with a random particle\n                    if worst_index != i: #Don't replace the particle being evaluated.\n                      new_particle = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                      new_fitness_val = func(new_particle)\n                      self.budget -= 1\n\n                      if new_fitness_val < fitness[worst_index]:\n                          new_population[worst_index] = new_particle\n                          new_fitness[worst_index] = new_fitness_val\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Memory Saving\n            if self.memory_population is None:\n                self.memory_population = population.copy()\n                self.memory_fitness = fitness.copy()\n            else:\n                #Replace if better\n                for i in range(self.pop_size):\n                    if fitness[i] < self.memory_fitness[i]:\n                        self.memory_population[i] = population[i].copy()\n                        self.memory_fitness[i] = fitness[i]\n\n            # Restart mechanism with memory\n            if self.stagnation_counter > self.restart_patience:\n                # Check if there's been sufficient improvement\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_patience-1]) < self.restart_threshold:\n                    # Re-initialize population (restart) using memory\n                    population = self.memory_population.copy()  # Load from memory\n                    fitness = self.memory_fitness.copy()\n\n                    # Perturb population slightly (optional)\n                    for i in range(self.pop_size):\n                        population[i] += np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                        population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n                        fitness[i] = func(population[i])  # Re-evaluate fitness\n                        self.budget -= 1\n\n                    # Re-initialize PSO-specific variables\n                    velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                    personal_best_positions = population.copy()\n                    personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    global_best_position = population[global_best_index].copy()\n                    self.f_opt = personal_best_fitness[global_best_index].copy()\n                    self.x_opt = global_best_position.copy()\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                    self.best_fitness_history.append(self.f_opt)  #add to history after restart\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSONiche_DERestart scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f1127016-71cf-4616-8cc4-b7ee47ad65e2"], "operator": "mutation", "metadata": {"llm_response": "# Description: Implements a self-adaptive hybrid PSO-DE with a novel diversity maintenance strategy based on niching and a memory-based restart to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSONiche_DERestart:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10, F_init=0.5, CR_init=0.9,\n                 F_adapt_rate=0.1, CR_adapt_rate=0.1, restart_patience=50, restart_threshold=1e-5,\n                 niche_radius=0.5, niche_selection_pressure=2):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with niching for diversity and memory-based restart.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia (float): The inertia weight for PSO.\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt_rate (float): Adaptation rate for F.\n            CR_adapt_rate (float): Adaptation rate for CR.\n            restart_patience (int): Number of iterations to wait before restarting if no improvement.\n            restart_threshold (float): Threshold for improvement to avoid restarts.\n            niche_radius (float): Radius of the niche for crowding.\n            niche_selection_pressure (int): Selection pressure within a niche.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.restart_patience = restart_patience\n        self.restart_threshold = restart_threshold\n        self.niche_radius = niche_radius\n        self.niche_selection_pressure = niche_selection_pressure\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.best_fitness_history = []\n        self.stagnation_counter = 0\n        self.memory_population = None\n        self.memory_fitness = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm with niching and memory-based restart.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        self.best_fitness_history.append(self.f_opt)\n\n        memory_F = []\n        memory_CR = []\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = self.inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update with JADE-inspired adaptation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    # Adapt CR for each individual\n                    CR_i = np.random.normal(self.CR, self.CR_adapt_rate)\n                    CR_i = np.clip(CR_i, 0, 1)\n\n                    crossover_mask = np.random.rand(self.dim) < CR_i\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                        memory_F.append(self.F)\n                        memory_CR.append(CR_i)\n\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR (JADE-inspired)\n            if memory_F:\n                self.F = (1 - self.F_adapt_rate) * self.F + self.F_adapt_rate * np.mean(memory_F)\n                self.F = np.clip(self.F, 0.1, 1.0) # keep F within a reasonable range\n\n            if memory_CR:\n                 self.CR = (1 - self.CR_adapt_rate) * self.CR + self.CR_adapt_rate * np.mean(memory_CR)\n                 self.CR = np.clip(self.CR, 0.1, 1.0) # keep CR within a reasonable range\n            memory_F = []\n            memory_CR = []\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Niching implementation - Crowding based replacement\n            for i in range(self.pop_size):\n                distances = np.linalg.norm(population - population[i], axis=1)\n                niche_members = np.where(distances < self.niche_radius)[0]\n\n                if len(niche_members) > 1:  # Niche is crowded\n                    # Sort niche members by fitness\n                    niche_fitnesses = fitness[niche_members]\n                    sorted_indices = np.argsort(niche_fitnesses)\n                    worst_index = niche_members[sorted_indices[-1]]  # Index of the worst member\n\n                    # Replace the worst member with a random particle\n                    if worst_index != i: #Don't replace the particle being evaluated.\n                      new_particle = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                      new_fitness_val = func(new_particle)\n                      self.budget -= 1\n\n                      if new_fitness_val < fitness[worst_index]:\n                          new_population[worst_index] = new_particle\n                          new_fitness[worst_index] = new_fitness_val\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n                self.stagnation_counter = 0  # Reset stagnation counter\n            else:\n                self.stagnation_counter += 1\n\n            self.best_fitness_history.append(self.f_opt)\n\n            # Memory Saving\n            if self.memory_population is None:\n                self.memory_population = population.copy()\n                self.memory_fitness = fitness.copy()\n            else:\n                #Replace if better\n                for i in range(self.pop_size):\n                    if fitness[i] < self.memory_fitness[i]:\n                        self.memory_population[i] = population[i].copy()\n                        self.memory_fitness[i] = fitness[i]\n\n            # Restart mechanism with memory\n            if self.stagnation_counter > self.restart_patience:\n                # Check if there's been sufficient improvement\n                if abs(self.best_fitness_history[-1] - self.best_fitness_history[-self.restart_patience-1]) < self.restart_threshold:\n                    # Re-initialize population (restart) using memory\n                    population = self.memory_population.copy()  # Load from memory\n                    fitness = self.memory_fitness.copy()\n\n                    # Perturb population slightly (optional)\n                    for i in range(self.pop_size):\n                        population[i] += np.random.normal(0, 0.01, size=self.dim)  # Small perturbation\n                        population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n                        fitness[i] = func(population[i])  # Re-evaluate fitness\n                        self.budget -= 1\n\n                    # Re-initialize PSO-specific variables\n                    velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n                    personal_best_positions = population.copy()\n                    personal_best_fitness = fitness.copy()\n                    global_best_index = np.argmin(fitness)\n                    global_best_position = population[global_best_index].copy()\n                    self.f_opt = personal_best_fitness[global_best_index].copy()\n                    self.x_opt = global_best_position.copy()\n\n                    self.stagnation_counter = 0  # Reset stagnation counter\n                    self.best_fitness_history.append(self.f_opt)  #add to history after restart\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.19586538691978803, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "d0000c1f-8adf-46b1-ba76-ca13af8e8cc6", "fitness": 0.0, "name": "HybridAdaptivePSO_DE_LocalSearch2", "description": "Hybrid Adaptive PSO-DE with dynamic population size reduction and a more robust local search, incorporating a success rate based mutation factor adaptation.", "code": "import numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99, local_search_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.local_search_sigma = local_search_sigma\n        self.mutation_factor = de_mutation_factor # Initial mutation factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + self.mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Adaptive Gaussian perturbation\n        sigma = self.local_search_sigma * (func.bounds.ub - func.bounds.lb)\n        new_x = np.random.normal(x, sigma)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        if f_new < func(x):\n             return new_x, f_new\n        else:\n             return x, func(x)\n\n    def reduce_population(self):\n        if self.current_pop_size > self.min_pop_size:\n            num_to_remove = max(1, int((self.initial_pop_size - self.min_pop_size) * (1 - self.budget / self.budget))) #Remove individuals based on budget spent\n            \n            # Remove the worst individuals\n            worst_indices = np.argsort(self.fitness)[-num_to_remove:]\n            self.population = np.delete(self.population, worst_indices, axis=0)\n            self.fitness = np.delete(self.fitness, worst_indices)\n            self.velocities = np.delete(self.velocities, worst_indices, axis=0)\n            self.personal_best_positions = np.delete(self.personal_best_positions, worst_indices, axis=0)\n            self.personal_best_fitness = np.delete(self.personal_best_fitness, worst_indices)\n            self.pop_size = len(self.population)\n            self.current_pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n                # Adapt mutation factor based on success\n                self.mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * (1 - avg_de_success)\n\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            self.reduce_population() # Reduce population size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridAdaptivePSO_DE_LocalSearch2 scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["17adc6c6-6bc1-49d1-bfa0-f46bab47bd95"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid Adaptive PSO-DE with dynamic population size reduction and a more robust local search, incorporating a success rate based mutation factor adaptation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridAdaptivePSO_DE_LocalSearch2:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99, local_search_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.local_search_sigma = local_search_sigma\n        self.mutation_factor = de_mutation_factor # Initial mutation factor\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n        \n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n        \n\n    def de_step(self, func, i):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + self.mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < self.de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Adaptive Gaussian perturbation\n        sigma = self.local_search_sigma * (func.bounds.ub - func.bounds.lb)\n        new_x = np.random.normal(x, sigma)\n        new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_x)\n        self.budget -= 1\n        if f_new < func(x):\n             return new_x, f_new\n        else:\n             return x, func(x)\n\n    def reduce_population(self):\n        if self.current_pop_size > self.min_pop_size:\n            num_to_remove = max(1, int((self.initial_pop_size - self.min_pop_size) * (1 - self.budget / self.budget))) #Remove individuals based on budget spent\n            \n            # Remove the worst individuals\n            worst_indices = np.argsort(self.fitness)[-num_to_remove:]\n            self.population = np.delete(self.population, worst_indices, axis=0)\n            self.fitness = np.delete(self.fitness, worst_indices)\n            self.velocities = np.delete(self.velocities, worst_indices, axis=0)\n            self.personal_best_positions = np.delete(self.personal_best_positions, worst_indices, axis=0)\n            self.personal_best_fitness = np.delete(self.personal_best_fitness, worst_indices)\n            self.pop_size = len(self.population)\n            self.current_pop_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n                # Adapt mutation factor based on success\n                self.mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * (1 - avg_de_success)\n\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n                \n                if self.budget <= 0:\n                    break\n            \n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n            \n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            self.reduce_population() # Reduce population size\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.12234036196185732, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "551903b3-95bd-4b3d-9c3b-c787b52487c6", "fitness": 0.0, "name": "GMM_NelderMead", "description": "An algorithm that iteratively explores the search space by combining global search using a Gaussian Mixture Model and local search using Nelder-Mead, adapting the balance between them based on the success of each.", "code": "import numpy as np\nfrom scipy.stats import multivariate_normal\nfrom scipy.optimize import minimize\nfrom sklearn.mixture import GaussianMixture\n\nclass GMM_NelderMead:\n    def __init__(self, budget=10000, dim=10, n_components=5, gmm_batchsize=1000):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.gmm_batchsize = gmm_batchsize\n        self.gmm = None\n        self.exploration_rate = 0.5 #initial rate\n        self.exploration_decay = 0.995\n        self.min_exploration_rate = 0.05\n\n    def sample_from_gmm(self, n_samples):\n        if self.gmm is None:\n            # Initial sampling before GMM is trained\n            return np.random.uniform(self.bounds.lb, self.bounds.ub, size=(n_samples, self.dim))\n\n        samples = np.zeros((n_samples, self.dim))\n        for i in range(n_samples):\n            # Sample a component\n            component = np.random.choice(self.n_components, p=self.gmm.weights_)\n\n            # Sample from that component\n            samples[i, :] = np.random.multivariate_normal(self.gmm.means_[component], self.gmm.covariances_[component], size=1)\n\n        # Clip samples to respect bounds\n        samples = np.clip(samples, self.bounds.lb, self.bounds.ub)\n        return samples\n\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead', options={'maxiter': 50}) # Reduced maxiter\n        return res.fun, res.x\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n        X = []\n        F = []\n\n        # Initial sampling\n        init_samples = min(self.budget, self.gmm_batchsize)  # Use gmm_batchsize or budget, whichever is smaller\n        x = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(init_samples, self.dim))\n        f = np.array([func(xi) for xi in x])\n        evaluations += init_samples\n        X.extend(x)\n        F.extend(f)\n\n        if np.min(f) < self.f_opt:\n            self.f_opt = np.min(f)\n            self.x_opt = x[np.argmin(f)]\n\n        while evaluations < self.budget:\n            # Train GMM\n            try:\n                self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n                self.gmm.fit(X)\n            except ValueError as e:\n                # Handle the case where GMM fitting fails (e.g., due to insufficient data)\n                print(f\"GMM fitting failed: {e}\")\n                # Fallback strategy: sample uniformly\n                num_samples = min(self.budget - evaluations, self.gmm_batchsize)\n                x_new = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(num_samples, self.dim))\n                f_new = np.array([func(xi) for xi in x_new])\n                evaluations += num_samples\n                X.extend(x_new)\n                F.extend(f_new)\n                if np.min(f_new) < self.f_opt:\n                    self.f_opt = np.min(f_new)\n                    self.x_opt = x_new[np.argmin(f_new)]\n\n                continue\n\n\n            # Exploration with GMM\n            num_gmm_samples = int(self.exploration_rate * self.gmm_batchsize)\n            x_gmm = self.sample_from_gmm(num_gmm_samples)\n            f_gmm = np.array([func(xi) for xi in x_gmm])\n            evaluations += num_gmm_samples\n            X.extend(x_gmm)\n            F.extend(f_gmm)\n\n\n            # Local search around best point so far\n            num_local_searches = int((1-self.exploration_rate)* self.gmm_batchsize)\n            x_local_seeds = np.random.choice(len(X), size=num_local_searches, replace=False)\n            for seed_idx in x_local_seeds:\n                f_local, x_local = self.local_search(func, X[seed_idx])\n                evaluations += 51  # Account for Nelder-Mead evals (approximate)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                X.append(x_local)\n                F.append(f_local)\n\n\n            if np.min(F) < self.f_opt:\n                    self.f_opt = np.min(F)\n                    self.x_opt = X[np.argmin(F)]\n\n\n            # Adjust exploration rate\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, self.min_exploration_rate)\n\n            if evaluations > self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: name 'GaussianMixture' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An algorithm that iteratively explores the search space by combining global search using a Gaussian Mixture Model and local search using Nelder-Mead, adapting the balance between them based on the success of each.\n# Code:\n```python\nimport numpy as np\nfrom scipy.stats import multivariate_normal\nfrom scipy.optimize import minimize\nfrom sklearn.mixture import GaussianMixture\n\nclass GMM_NelderMead:\n    def __init__(self, budget=10000, dim=10, n_components=5, gmm_batchsize=1000):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.gmm_batchsize = gmm_batchsize\n        self.gmm = None\n        self.exploration_rate = 0.5 #initial rate\n        self.exploration_decay = 0.995\n        self.min_exploration_rate = 0.05\n\n    def sample_from_gmm(self, n_samples):\n        if self.gmm is None:\n            # Initial sampling before GMM is trained\n            return np.random.uniform(self.bounds.lb, self.bounds.ub, size=(n_samples, self.dim))\n\n        samples = np.zeros((n_samples, self.dim))\n        for i in range(n_samples):\n            # Sample a component\n            component = np.random.choice(self.n_components, p=self.gmm.weights_)\n\n            # Sample from that component\n            samples[i, :] = np.random.multivariate_normal(self.gmm.means_[component], self.gmm.covariances_[component], size=1)\n\n        # Clip samples to respect bounds\n        samples = np.clip(samples, self.bounds.lb, self.bounds.ub)\n        return samples\n\n\n    def local_search(self, func, x0):\n        res = minimize(func, x0, method='Nelder-Mead', options={'maxiter': 50}) # Reduced maxiter\n        return res.fun, res.x\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.f_opt = np.inf\n        self.x_opt = None\n        evaluations = 0\n        X = []\n        F = []\n\n        # Initial sampling\n        init_samples = min(self.budget, self.gmm_batchsize)  # Use gmm_batchsize or budget, whichever is smaller\n        x = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(init_samples, self.dim))\n        f = np.array([func(xi) for xi in x])\n        evaluations += init_samples\n        X.extend(x)\n        F.extend(f)\n\n        if np.min(f) < self.f_opt:\n            self.f_opt = np.min(f)\n            self.x_opt = x[np.argmin(f)]\n\n        while evaluations < self.budget:\n            # Train GMM\n            try:\n                self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=42)\n                self.gmm.fit(X)\n            except ValueError as e:\n                # Handle the case where GMM fitting fails (e.g., due to insufficient data)\n                print(f\"GMM fitting failed: {e}\")\n                # Fallback strategy: sample uniformly\n                num_samples = min(self.budget - evaluations, self.gmm_batchsize)\n                x_new = np.random.uniform(self.bounds.lb, self.bounds.ub, size=(num_samples, self.dim))\n                f_new = np.array([func(xi) for xi in x_new])\n                evaluations += num_samples\n                X.extend(x_new)\n                F.extend(f_new)\n                if np.min(f_new) < self.f_opt:\n                    self.f_opt = np.min(f_new)\n                    self.x_opt = x_new[np.argmin(f_new)]\n\n                continue\n\n\n            # Exploration with GMM\n            num_gmm_samples = int(self.exploration_rate * self.gmm_batchsize)\n            x_gmm = self.sample_from_gmm(num_gmm_samples)\n            f_gmm = np.array([func(xi) for xi in x_gmm])\n            evaluations += num_gmm_samples\n            X.extend(x_gmm)\n            F.extend(f_gmm)\n\n\n            # Local search around best point so far\n            num_local_searches = int((1-self.exploration_rate)* self.gmm_batchsize)\n            x_local_seeds = np.random.choice(len(X), size=num_local_searches, replace=False)\n            for seed_idx in x_local_seeds:\n                f_local, x_local = self.local_search(func, X[seed_idx])\n                evaluations += 51  # Account for Nelder-Mead evals (approximate)\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                X.append(x_local)\n                F.append(f_local)\n\n\n            if np.min(F) < self.f_opt:\n                    self.f_opt = np.min(F)\n                    self.x_opt = X[np.argmin(F)]\n\n\n            # Adjust exploration rate\n            self.exploration_rate *= self.exploration_decay\n            self.exploration_rate = max(self.exploration_rate, self.min_exploration_rate)\n\n            if evaluations > self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.2668254110796017, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "6943507b-6cca-4c15-9cd5-9d0804368e52", "fitness": 0.0, "name": "AdaptiveHybridPSO_DE_Simplex", "description": "Combines PSO and DE with adaptive population sizing and a simplex-based local search for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSO_DE_Simplex:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99, simplex_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.simplex_iterations = simplex_iterations  # Number of iterations for simplex local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Nelder-Mead Simplex local search\n        bounds = func.bounds\n        def func_wrapper(x):\n            if self.budget > 0:\n                f = func(x)\n                self.budget -= 1\n                return f\n            else:\n                return np.inf\n        \n        result = minimize(func_wrapper, x, method='Nelder-Mead', bounds=[(bounds.lb, bounds.ub)] * self.dim, options={'maxiter': self.simplex_iterations, 'maxfev': self.simplex_iterations})\n\n        if result.success:\n            return result.x, result.fun\n        else:\n            return x, func(x) # Return original point if optimization fails\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            # Adaptive population sizing (Linear decrease)\n            if self.budget > 0:\n                self.current_pop_size = max(self.min_pop_size, int(self.initial_pop_size * (self.budget / self.budget)))\n                if self.current_pop_size < self.pop_size:\n                        self.pop_size = self.current_pop_size\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["17adc6c6-6bc1-49d1-bfa0-f46bab47bd95"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines PSO and DE with adaptive population sizing and a simplex-based local search for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSO_DE_Simplex:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, cognitive_coeff=1.5, social_coeff=1.5,\n                 exploration_rate=0.1, de_mutation_factor=0.5, de_crossover_rate=0.7,\n                 pso_weight=0.5, de_weight=0.5, archive_size_factor=0.2, success_memory=10,\n                 local_search_prob=0.05, min_pop_size=10, pop_decay_rate=0.99, simplex_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.pso_weight = pso_weight\n        self.de_weight = de_weight\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.min_de_mutation_factor = 0.1\n        self.max_de_mutation_factor = 0.9\n        self.min_de_crossover_rate = 0.1\n        self.max_de_crossover_rate = 0.9\n        self.pso_success = 0\n        self.de_success = 0\n        self.success_memory = success_memory  # How many iterations to remember the success rate\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.local_search_prob = local_search_prob\n        self.min_pop_size = min_pop_size\n        self.pop_decay_rate = pop_decay_rate\n        self.initial_pop_size = pop_size\n        self.current_pop_size = pop_size\n        self.simplex_iterations = simplex_iterations  # Number of iterations for simplex local search\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        global_best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[global_best_index].copy()\n        self.f_opt = self.personal_best_fitness[global_best_index].copy()\n        self.x_opt = self.global_best_position.copy()\n\n    def pso_step(self, func, i):\n        if np.random.rand() < self.exploration_rate:\n            self.velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n        else:\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_component + social_component\n            self.velocities[i] = np.clip(self.velocities[i], func.bounds.lb - self.population[i], func.bounds.ub - self.population[i])\n\n        new_particle = self.population[i] + self.velocities[i]\n        new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n        f_new = func(new_particle)\n        self.budget -= 1\n\n        if f_new < self.fitness[i]:\n            self.population[i] = new_particle\n            self.fitness[i] = f_new\n            self.pso_success += 1\n\n            if f_new < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = f_new\n                self.personal_best_positions[i] = self.population[i].copy()\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = self.population[i].copy()\n                    self.global_best_position = self.population[i].copy()\n\n    def de_step(self, func, i):\n        remaining_ratio = self.budget / (self.budget + self.pop_size)  # Ratio of remaining budget\n        adapted_de_mutation_factor = self.min_de_mutation_factor + (self.max_de_mutation_factor - self.min_de_mutation_factor) * remaining_ratio  # Linearly scale F\n        adapted_de_crossover_rate = self.min_de_crossover_rate + (self.max_de_crossover_rate - self.min_de_crossover_rate) * remaining_ratio  # Linearly scale CR\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        mutant = x1 + adapted_de_mutation_factor * (x2 - x3)\n        mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n        crossover_mask = np.random.rand(self.dim) < adapted_de_crossover_rate\n        trial_vector = np.where(crossover_mask, mutant, self.population[i])\n        f_trial = func(trial_vector)\n        self.budget -= 1\n\n        if f_trial < self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = f_trial\n            self.de_success += 1\n            if f_trial < self.f_opt:\n                self.f_opt = f_trial\n                self.x_opt = trial_vector.copy()\n                self.global_best_position = trial_vector.copy()\n\n            if len(self.archive) < self.archive_size:\n                self.archive.append(self.population[i].copy())\n            else:\n                idx_to_replace = np.random.randint(0, self.archive_size)\n                self.archive[idx_to_replace] = self.population[i].copy()\n\n    def local_search(self, func, x):\n        # Nelder-Mead Simplex local search\n        bounds = func.bounds\n        def func_wrapper(x):\n            if self.budget > 0:\n                f = func(x)\n                self.budget -= 1\n                return f\n            else:\n                return np.inf\n        \n        result = minimize(func_wrapper, x, method='Nelder-Mead', bounds=[(bounds.lb, bounds.ub)] * self.dim, options={'maxiter': self.simplex_iterations, 'maxfev': self.simplex_iterations})\n\n        if result.success:\n            return result.x, result.fun\n        else:\n            return x, func(x) # Return original point if optimization fails\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive weighting\n            if len(self.pso_success_history) > 0 and len(self.de_success_history) > 0:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            indices = np.random.permutation(self.pop_size) # Shuffle the population indices\n\n            for i in indices:\n                if np.random.rand() < self.pso_weight and self.budget > 0:\n                    self.pso_step(func, i)\n\n                elif self.budget > 0:\n                    self.de_step(func, i)\n\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    new_x, f_new = self.local_search(func, self.population[i])\n                    if f_new < self.fitness[i]:\n                        self.population[i] = new_x\n                        self.fitness[i] = f_new\n                        if f_new < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_new\n                            self.personal_best_positions[i] = self.population[i].copy()\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = self.population[i].copy()\n                            self.global_best_position = self.population[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n            #Update the success rate\n            if len(self.pso_success_history) >= self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            self.pso_success = 0\n            self.de_success = 0\n\n            #Update the personal best of PSO part\n            for i in range(self.pop_size):\n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n\n            #Update the global best\n            best_index = np.argmin(self.fitness)\n            if self.fitness[best_index] < self.f_opt:\n                self.f_opt = self.fitness[best_index]\n                self.x_opt = self.population[best_index].copy()\n                self.global_best_position = self.population[best_index].copy()\n\n            # Adaptive population sizing (Linear decrease)\n            if self.budget > 0:\n                self.current_pop_size = max(self.min_pop_size, int(self.initial_pop_size * (self.budget / self.budget)))\n                if self.current_pop_size < self.pop_size:\n                        self.pop_size = self.current_pop_size\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.23263984157262285, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "28e85b32-98e7-412e-839b-320a1e97a15f", "fitness": 0.722935607599015, "name": "AdaptiveHybridPSO_DE_LocalSearch", "description": "Adaptive Hybrid PSO-DE with dynamic parameter control and a local search component using the archive.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=30,\n                 inertia_init=0.9, inertia_final=0.4,  # Dynamic Inertia\n                 cognitive_coeff=2.0, social_coeff=2.0,  # Increased PSO coefficients\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 F_init=0.5, CR_init=0.9, F_adapt=True, CR_adapt=True, local_search_freq=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and local search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia_init (float): Initial inertia weight for PSO.\n            inertia_final (float): Final inertia weight for PSO (linearly decreases).\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt (bool): Whether to adapt the F parameter based on success.\n            CR_adapt (bool): Whether to adapt the CR parameter based on success.\n            local_search_freq (float): Frequency of applying local search using the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_init = inertia_init\n        self.inertia_final = inertia_final\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.local_search_freq = local_search_freq\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.generation = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            self.generation += 1\n            inertia = self.inertia_init - (self.inertia_init - self.inertia_final) * (self.generation / (self.budget / self.pop_size))\n\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                            # Adaptive F and CR\n                            if self.F_adapt:\n                                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0) # Adjust F adaptively\n                            if self.CR_adapt:\n                                self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)  #Adjust CR adaptively\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Local Search\n            if np.random.rand() < self.local_search_freq and len(self.archive) > 0:\n                idx = np.random.randint(0, self.pop_size)\n                archive_idx = np.random.randint(0, len(self.archive))\n                search_point = self.archive[archive_idx].copy() # Search around archive member\n                step_size = 0.01 * (func.bounds.ub - func.bounds.lb) # Small step size\n\n                for _ in range(min(5, self.budget)):  # Limit local search evaluations\n                    neighbor = search_point + np.random.uniform(-step_size, step_size, self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.budget -= 1\n\n                    if f_neighbor < fitness[idx]:\n                        new_population[idx] = neighbor\n                        new_fitness[idx] = f_neighbor\n                        population[idx] = neighbor.copy()\n                        fitness[idx] = f_neighbor\n                        search_point = neighbor.copy() # Move search\n                    else:\n                        break  # Stop local search if no improvement\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSO_DE_LocalSearch scored 0.723 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["162a8d63-dd69-484e-b20c-ca59a99035e3"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid PSO-DE with dynamic parameter control and a local search component using the archive.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSO_DE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=30,\n                 inertia_init=0.9, inertia_final=0.4,  # Dynamic Inertia\n                 cognitive_coeff=2.0, social_coeff=2.0,  # Increased PSO coefficients\n                 exploration_rate=0.1, archive_size_factor=0.2,\n                 pso_weight_init=0.5, de_weight_init=0.5, success_memory=10,\n                 F_init=0.5, CR_init=0.9, F_adapt=True, CR_adapt=True, local_search_freq=0.1):\n        \"\"\"\n        Initializes the Adaptive Hybrid PSO-DE algorithm with dynamic parameter adaptation and local search.\n\n        Args:\n            budget (int): The budget of function evaluations.\n            dim (int): The dimensionality of the problem.\n            pop_size (int): The population size.\n            inertia_init (float): Initial inertia weight for PSO.\n            inertia_final (float): Final inertia weight for PSO (linearly decreases).\n            cognitive_coeff (float): The cognitive coefficient for PSO.\n            social_coeff (float): The social coefficient for PSO.\n            exploration_rate (float): The exploration rate for PSO (probability of random velocity reset).\n            archive_size_factor (float): Factor to determine the archive size based on population size.\n            pso_weight_init (float): Initial weight for PSO strategy.\n            de_weight_init (float): Initial weight for DE strategy.\n            success_memory (int): How many iterations to remember for success rate calculation.\n            F_init (float): Initial mutation factor for DE.\n            CR_init (float): Initial crossover rate for DE.\n            F_adapt (bool): Whether to adapt the F parameter based on success.\n            CR_adapt (bool): Whether to adapt the CR parameter based on success.\n            local_search_freq (float): Frequency of applying local search using the archive.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_init = inertia_init\n        self.inertia_final = inertia_final\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.exploration_rate = exploration_rate\n        self.archive_size = int(self.pop_size * archive_size_factor)\n        self.archive = []\n        self.pso_weight = pso_weight_init\n        self.de_weight = de_weight_init\n        self.success_memory = success_memory\n        self.F = F_init  # Mutation factor\n        self.CR = CR_init  # Crossover rate\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.local_search_freq = local_search_freq\n\n        self.pso_success = 0\n        self.de_success = 0\n        self.pso_success_history = []\n        self.de_success_history = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.generation = 0\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given function using the Adaptive Hybrid PSO-DE algorithm.\n\n        Args:\n            func (callable): The function to optimize.\n\n        Returns:\n            tuple: A tuple containing the best function value found and the corresponding solution.\n        \"\"\"\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize PSO-specific variables\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            self.generation += 1\n            inertia = self.inertia_init - (self.inertia_init - self.inertia_final) * (self.generation / (self.budget / self.pop_size))\n\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Adaptive weighting based on success history\n            if self.pso_success_history and self.de_success_history:\n                avg_pso_success = np.mean(self.pso_success_history)\n                avg_de_success = np.mean(self.de_success_history)\n                if avg_pso_success + avg_de_success > 0:\n                    self.pso_weight = avg_pso_success / (avg_pso_success + avg_de_success)\n                    self.de_weight = avg_de_success / (avg_pso_success + avg_de_success)\n                else:\n                    self.pso_weight = 0.5\n                    self.de_weight = 0.5\n\n            for i in range(self.pop_size):\n                # Choose between PSO and DE based on adaptive weights\n                if np.random.rand() < self.pso_weight:\n                    # PSO update\n                    if np.random.rand() < self.exploration_rate:\n                        velocities[i] = np.random.uniform(-1, 1, size=self.dim) * (func.bounds.ub - func.bounds.lb) * 0.05\n                    else:\n                        r1 = np.random.rand(self.dim)\n                        r2 = np.random.rand(self.dim)\n                        cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                        social_component = self.social_coeff * r2 * (global_best_position - population[i])\n                        velocities[i] = inertia * velocities[i] + cognitive_component + social_component\n                        velocities[i] = np.clip(velocities[i], func.bounds.lb - population[i], func.bounds.ub - population[i])\n\n                    new_particle = population[i] + velocities[i]\n                    new_particle = np.clip(new_particle, func.bounds.lb, func.bounds.ub)\n                    f_new = func(new_particle)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population[i] = new_particle\n                        new_fitness[i] = f_new\n                        self.pso_success += 1\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                else:\n                    # DE update\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + self.F * (x2 - x3)\n                    mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                    crossover_mask = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover_mask, mutant, population[i])\n                    f_trial = func(trial_vector)\n                    self.budget -= 1\n\n                    if f_trial < fitness[i]:\n                        new_population[i] = trial_vector\n                        new_fitness[i] = f_trial\n                        self.de_success += 1\n                        if len(self.archive) < self.archive_size:\n                            self.archive.append(population[i].copy())\n                        else:\n                            idx_to_replace = np.random.randint(0, len(self.archive))\n                            self.archive[idx_to_replace] = population[i].copy()\n\n                            # Adaptive F and CR\n                            if self.F_adapt:\n                                self.F = np.clip(np.random.normal(0.5, 0.3), 0.1, 1.0) # Adjust F adaptively\n                            if self.CR_adapt:\n                                self.CR = np.clip(np.random.normal(0.9, 0.1), 0.1, 1.0)  #Adjust CR adaptively\n\n                    else:\n                        new_population[i] = population[i]\n                        new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            # Local Search\n            if np.random.rand() < self.local_search_freq and len(self.archive) > 0:\n                idx = np.random.randint(0, self.pop_size)\n                archive_idx = np.random.randint(0, len(self.archive))\n                search_point = self.archive[archive_idx].copy() # Search around archive member\n                step_size = 0.01 * (func.bounds.ub - func.bounds.lb) # Small step size\n\n                for _ in range(min(5, self.budget)):  # Limit local search evaluations\n                    neighbor = search_point + np.random.uniform(-step_size, step_size, self.dim)\n                    neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n                    f_neighbor = func(neighbor)\n                    self.budget -= 1\n\n                    if f_neighbor < fitness[idx]:\n                        new_population[idx] = neighbor\n                        new_fitness[idx] = f_neighbor\n                        population[idx] = neighbor.copy()\n                        fitness[idx] = f_neighbor\n                        search_point = neighbor.copy() # Move search\n                    else:\n                        break  # Stop local search if no improvement\n\n            # Update success history\n            self.pso_success_history.append(self.pso_success / self.pop_size)\n            self.de_success_history.append(self.de_success / self.pop_size)\n            if len(self.pso_success_history) > self.success_memory:\n                self.pso_success_history.pop(0)\n                self.de_success_history.pop(0)\n            self.pso_success = 0\n            self.de_success = 0\n\n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update personal best for PSO individuals\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                global_best_position = population[best_index].copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.29056472134819045, 0.7417295187690038, 0.6918128245681494, 0.8953157883386945, 0.7979881149204997, 0.8080152833290966, 0.7148640015128613, 0.7397858719451512, 0.8043942661252994, 0.6459133124171348, 0.8590270713335488, 1.0, 0.6027250998279396, 0.7903239817124946, 0.8792183455797634, 0.8142920744446298, 0.6823785521611223, 0.8729326831831556, 0.30867894312660005, 0.5187516973369664], "operator": "mutation", "theta_sampled": 0.12462330583205361, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "6e4f3476-4908-4b21-98af-2cbd487e7650", "fitness": 0.34046083177453734, "name": "DynamicSubspaceEvolution", "description": "Population-based search with dynamic subspace exploration and adaptive mutation scaling.", "code": "import numpy as np\n\nclass DynamicSubspaceEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, subspace_size=5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.subspace_size = min(subspace_size, dim)  # Ensure subspace_size is not larger than dim\n        self.mutation_rate = mutation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Subspace selection\n            indices = np.random.choice(self.dim, self.subspace_size, replace=False)\n\n            # Mutation within the subspace\n            mutant = self.pop[i].copy()\n            mutation_scale = np.std(self.pop[:, indices]) # Adaptive Mutation Scale\n\n            mutant[indices] += self.mutation_rate * mutation_scale * np.random.normal(size=self.subspace_size)\n\n            # Ensure bounds\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f = func(mutant)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.pop[i] = mutant\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = mutant\n\n            if self.eval_count >= self.budget:\n                break\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm DynamicSubspaceEvolution scored 0.340 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with dynamic subspace exploration and adaptive mutation scaling.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicSubspaceEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, subspace_size=5, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.subspace_size = min(subspace_size, dim)  # Ensure subspace_size is not larger than dim\n        self.mutation_rate = mutation_rate\n        self.pop = None\n        self.fitness = None\n        self.eval_count = 0\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.pop[np.argmin(self.fitness)]\n\n    def evolve(self, func):\n        for i in range(self.pop_size):\n            # Subspace selection\n            indices = np.random.choice(self.dim, self.subspace_size, replace=False)\n\n            # Mutation within the subspace\n            mutant = self.pop[i].copy()\n            mutation_scale = np.std(self.pop[:, indices]) # Adaptive Mutation Scale\n\n            mutant[indices] += self.mutation_rate * mutation_scale * np.random.normal(size=self.subspace_size)\n\n            # Ensure bounds\n            mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n            # Evaluation\n            f = func(mutant)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.fitness[i] = f\n                self.pop[i] = mutant\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = mutant\n\n            if self.eval_count >= self.budget:\n                break\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            self.evolve(func)\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.121943014951718, 0.25348525202455496, 0.33797274596773985, 0.41838145528893933, 0.2439792532882059, 0.33565490653717966, 0.2551311262716468, 0.29513297067556343, 0.26055485012257873, 0.16522546085257306, 0.3080060454653819, 0.9218411120030321, 0.2812179715443117, 0.23317107296403594, 0.7049960033715015, 0.30936968656744734, 0.2806355872151505, 0.3938759623451429, 0.20293148021422436, 0.48571067781982025], "operator": "random_new", "theta_sampled": 0.15235368106951794, "reward": 0.0, "generation": 6}, "task_prompt": ""}
