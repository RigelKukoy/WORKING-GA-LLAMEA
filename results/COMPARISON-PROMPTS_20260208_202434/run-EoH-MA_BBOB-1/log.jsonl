{"id": "c97e72b6-5802-43ee-b236-012818654e37", "fitness": 0.16962949637544095, "name": "AdaptiveCoordinateDescent", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveCoordinateDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x_opt)\n        \n        step_size = np.full(self.dim, self.initial_step_size)\n        success_rate = np.zeros(self.dim)\n        eval_count = 1\n        \n        while eval_count < self.budget:\n            for i in range(self.dim):\n                if eval_count >= self.budget:\n                    break\n                    \n                # Perturb positively\n                x_plus = self.x_opt.copy()\n                x_plus[i] = np.clip(x_plus[i] + step_size[i], self.lb, self.ub)\n                f_plus = func(x_plus)\n                eval_count += 1\n\n                # Perturb negatively\n                x_minus = self.x_opt.copy()\n                x_minus[i] = np.clip(x_minus[i] - step_size[i], self.lb, self.ub)\n                f_minus = func(x_minus)\n                eval_count += 1\n                \n                if eval_count >= self.budget:\n                    f_plus = np.inf\n                    f_minus = np.inf\n\n                if f_plus < self.f_opt and f_plus <= f_minus:\n                    self.x_opt = x_plus\n                    self.f_opt = f_plus\n                    success_rate[i] += 1\n                elif f_minus < self.f_opt:\n                    self.x_opt = x_minus\n                    self.f_opt = f_minus\n                    success_rate[i] += 1\n                \n                # Adjust step size adaptively\n                if success_rate[i] > 5:\n                    step_size[i] *= 1.2\n                    success_rate[i] = 0\n                elif success_rate[i] < -5:\n                    step_size[i] *= 0.8\n                    success_rate[i] = 0\n                    \n                step_size[i] = np.clip(step_size[i], 1e-6, self.ub - self.lb)\n                \n            if eval_count < self.budget and np.random.rand() < 0.05: \n                # Restart with a small probability\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                eval_count += 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveCoordinateDescent scored 0.170 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07304334195493989, 0.1286060268511079, 0.2785831019745719, 0.16528779044883102, 0.17625865207998082, 0.20583390502270704, 0.24432589873685906, 0.25472675030997094, 0]}, "task_prompt": ""}
{"id": "7551369c-6277-4e24-90ae-9d1c86c19f2b", "fitness": 0.5969143363842091, "name": "HybridDEPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.9, de_f=0.8, pso_w=0.7, pso_c1=1.5, pso_c2=1.5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c1 = pso_c1\n        self.pso_c2 = pso_c2\n        self.local_search_prob = local_search_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                if np.random.rand() < 0.5:  # Apply DE with 50% probability\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    \n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else: # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                    self.pso_c2 * r2 * (global_best_position - population[i]))\n                    trial_vector = population[i] + velocities[i]\n                    \n                trial_vector = np.clip(trial_vector, self.lb, self.ub) # Clip to bounds\n\n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (self.ub - self.lb) # 1% of the range\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    trial_vector = trial_vector + step_size * random_direction\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n                    \n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial_vector.copy()\n\n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO scored 0.597 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19465354691424064, 0.5400365581698083, 0.5135560857410151, 0.8868409352029073, 0.5642224668016482, 0.7154593802711057, 0.44066738711973763, 0.5292714528821623, 0.672632797503104, 0.47315976594188125, 0.8109213293918367, 0.9974175811644312, 0.41865010364724553, 0.5464752142542364, 0.8719833777563069, 0.7489895002672875, 0.45005169326399885, 0.8190568229632513, 0.23101192445723095, 0.5132288039707463]}, "task_prompt": ""}
{"id": "6f697a2a-ca55-459c-a9eb-32777f114dbe", "fitness": 0.6081142969170094, "name": "AdaptiveRangeSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveRangeSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_range=2.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_range = initial_range\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        range_lb = np.maximum(lb, -self.initial_range)\n        range_ub = np.minimum(ub, self.initial_range)\n        \n        population = np.random.uniform(range_lb, range_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Adaptive range adjustment\n            std = np.std(population, axis=0)\n            adaptive_range = np.mean(std)\n\n            # Generate new solutions around the best solution\n            new_solutions = np.random.normal(loc=self.x_opt, scale=adaptive_range, size=(self.pop_size, self.dim))\n            new_solutions = np.clip(new_solutions, lb, ub)\n\n            new_fitness = np.array([func(x) for x in new_solutions])\n            evals += self.pop_size\n\n            # Update population\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    population[i] = new_solutions[i]\n                    fitness[i] = new_fitness[i]\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveRangeSearch scored 0.608 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1245166203341842, 0.2256582102456307, 0.8885134699129319, 0.9601869108413985, 0.9165794512640744, 0.9383485609509215, 0.29507304805225554, 0.759617751868242, 0.2757297011531056, 0.2224427032698605, 0.9337279591871526, 0.9946264230287345, 0.32978205455884935, 0.8498902922913575, 0.9456980668228614, 0.46201466110501743, 0.33911848924234933, 0.9511640989347745, 0.24238871486914326, 0.5072087504073403]}, "task_prompt": ""}
{"id": "906eb255-a4cb-41c2-95f4-29075ec71433", "fitness": 0.5970287388752642, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_counter = 0\n        self.stagnation_threshold = budget // 10  # Adjust as needed\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n        self.eval_count = self.pop_size\n        self.best_fitness_history.append(self.f_opt)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Selection\n                f = func(trial)\n                self.eval_count += 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # Stagnation Check and Restart\n            if abs(self.f_opt - self.best_fitness_history[-1]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.eval_count += self.pop_size # update the evaluation count.\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                self.stagnation_counter = 0\n\n            # Adaptive Parameter Control (Example: Adjust F based on success)\n            if len(self.best_fitness_history) > 1 and self.f_opt < self.best_fitness_history[-1]:\n                self.F = np.clip(self.F * 1.1, 0.1, 0.9) # increase F by 10%\n            else:\n                self.F = np.clip(self.F * 0.9, 0.1, 0.9) # decrease F by 10%\n\n            self.best_fitness_history.append(self.f_opt)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.597 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2379232495282637, 0.1980671157821583, 0.8057216279843001, 0.9455616523131596, 0.9116920721978533, 0.912035200328638, 0.251726304529294, 0.41286847104243496, 0.8918608832968993, 0.19814883980383513, 0.9586364960712022, 0.9989293875753533, 0.3070513076768766, 0.5145410888209618, 0.5439186126052523, 0.8873040218828483, 0.3408449662586037, 0.9177057240212703, 0.22274882920779815, 0.48328892657827904]}, "task_prompt": ""}
{"id": "103fb649-79ff-4d3d-ad5e-a5443b1b7f08", "fitness": 0.30735480784147085, "name": "AdaptiveLocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial random search to find a good starting point\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n        \n        step_size = self.initial_step_size\n\n        # Adaptive local search\n        while evals < self.budget:\n            \n            x_new = self.x_opt + np.random.normal(0, step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            evals += 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                step_size *= 1.1  # Increase step size if improvement\n            else:\n                step_size *= 0.9  # Decrease step size if no improvement\n                \n            step_size = np.clip(step_size, 1e-6, 1.0) # Prevent step_size from being to large or small\n            \n            if evals + 100 < self.budget:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                evals += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveLocalSearch scored 0.307 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1081634138515497, 0.1828486070768558, 0.40823848692863374, 0.22545400374268987, 0.22502264524981452, 0.23546132073811565, 0.2225287748802569, 0.21718678612346343, 0.2102668454725224, 0.1594876807116572, 0.22884213156648647, 0.9982064312092097, 0.29017716708258745, 0.2035206860780332, 0.5683466712578256, 0.2689322015100861, 0.2949933837165706, 0.4922644005544661, 0.15249046670934097, 0.45466405236925234]}, "task_prompt": ""}
{"id": "8d0b85ed-17f0-41f2-a569-8e573fac879c", "fitness": 0.46380810015288815, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.archive_size = archive_size\n        self.F = 0.5  # Crossover rate\n        self.CR = 0.7 # Mutation factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive = []\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        for i in range(self.pop_size):\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = self.population[i]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                candidates = list(range(self.pop_size))\n                candidates.remove(i)\n                if len(self.archive) > 0:\n                    use_archive = np.random.rand() < 0.1  # 10% chance to use archive\n                    if use_archive:\n                        rand_archive_idx = np.random.randint(len(self.archive))\n                        x_r1 = self.archive[rand_archive_idx]\n                    else:\n                        idx_1, idx_2, idx_3 = np.random.choice(candidates, 3, replace=False)\n                        x_r1 = self.population[idx_1]\n                        \n                else:\n                    idx_1, idx_2, idx_3 = np.random.choice(candidates, 3, replace=False)\n                    x_r1 = self.population[idx_1]\n                \n                idx_2, idx_3 = np.random.choice(candidates, 2, replace=False)\n                x_r2 = self.population[idx_2]\n                x_r3 = self.population[idx_3]\n                \n                v = self.population[i] + self.F * (x_r2 - x_r3)\n                \n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < fitness[i]:\n                    fitness[i] = f_u\n                    self.population[i] = u\n                    if f_u < self.f_opt:\n                        self.f_opt = f_u\n                        self.x_opt = u\n                    self.archive.append(self.population[i].copy())\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0) #remove oldest\n                        \n            # Random Restart\n            if np.random.rand() < 0.01:  # 1% chance of restart\n                idx_to_replace = np.random.randint(self.pop_size)\n                self.population[idx_to_replace] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                fitness[idx_to_replace] = func(self.population[idx_to_replace])\n                self.budget -= 1\n                if fitness[idx_to_replace] < self.f_opt:\n                        self.f_opt = fitness[idx_to_replace]\n                        self.x_opt = self.population[idx_to_replace]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.464 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16269107176559627, 0.303456104933025, 0.44349026800308866, 0.7507637335058929, 0.3577710400027181, 0.5504097691632057, 0.3112936198167924, 0.3790328041268074, 0.3880302060510322, 0.19355435233273877, 0.7416783738190127, 0.9991300451508938, 0.3563131634309874, 0.3311621649360762, 0.7793719261834262, 0.5344257991425505, 0.3664486996370425, 0.6545176506710905, 0.180022713519143, 0.49259849686664303]}, "task_prompt": ""}
{"id": "03a1e64d-123d-43dc-a426-fb0030170adc", "fitness": "-inf", "name": "SobolNelderMead", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.stats import qmc\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Sobol sequence for initialization\n        sampler = qmc.Sobol(d=self.dim, scramble=False)\n        sample = sampler.random(n=min(self.dim + 1, self.budget))\n        points = func.bounds.lb + (func.bounds.ub - func.bounds.lb) * sample\n        \n        # Evaluate initial points\n        evaluations = 0\n        fitness = []\n        for x in points:\n            f = func(x)\n            fitness.append(f)\n            evaluations += 1\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        simplex = points.copy()\n        fitness = np.array(fitness)\n\n        while evaluations < self.budget:\n            # Order the vertices\n            idx = np.argsort(fitness)\n            simplex = simplex[idx]\n            fitness = fitness[idx]\n            \n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            xr = centroid + 1.0 * (centroid - simplex[-1])\n            xr = np.clip(xr, func.bounds.lb, func.bounds.ub)\n            fr = func(xr)\n            evaluations += 1\n            if fr < self.f_opt:\n                self.f_opt = fr\n                self.x_opt = xr\n            \n            if fitness[0] <= fr < fitness[-2]:\n                simplex[-1] = xr\n                fitness[-1] = fr\n            else:\n                if fr < fitness[0]:\n                    # Expansion\n                    xe = centroid + 2.0 * (xr - centroid)\n                    xe = np.clip(xe, func.bounds.lb, func.bounds.ub)\n                    fe = func(xe)\n                    evaluations += 1\n                    if fe < self.f_opt:\n                        self.f_opt = fe\n                        self.x_opt = xe\n\n                    if fe < fr:\n                        simplex[-1] = xe\n                        fitness[-1] = fe\n                    else:\n                        simplex[-1] = xr\n                        fitness[-1] = fr\n                else:\n                    # Contraction\n                    xc = centroid + 0.5 * (simplex[-1] - centroid)\n                    xc = np.clip(xc, func.bounds.lb, func.bounds.ub)\n                    fc = func(xc)\n                    evaluations += 1\n                    if fc < self.f_opt:\n                        self.f_opt = fc\n                        self.x_opt = xc\n\n                    if fc < fitness[-1]:\n                        simplex[-1] = xc\n                        fitness[-1] = fc\n                    else:\n                        # Shrink\n                        for i in range(1, len(simplex)):\n                            simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            fitness[i] = func(simplex[i])\n                            evaluations += 1\n                            if fitness[i] < self.f_opt:\n                                self.f_opt = fitness[i]\n                                self.x_opt = simplex[i]\n                            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 15, in __call__, the following error occurred:\nNameError: name 'qmc' is not defined\nOn line: sampler = qmc.Sobol(d=self.dim, scramble=False)", "error": "In the code, line 15, in __call__, the following error occurred:\nNameError: name 'qmc' is not defined\nOn line: sampler = qmc.Sobol(d=self.dim, scramble=False)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "892ec4f4-58d9-4317-b2d5-340b4c7b23f4", "fitness": 0.0, "name": "AdaptiveLocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.f_opt:\n            self.f_opt = fitness[best_idx]\n            self.x_opt = population[best_idx]\n\n        # Main loop\n        while self.budget > 0:\n            # Selection: Select best individuals for local search\n            sorted_idx = np.argsort(fitness)\n            selected_idx = sorted_idx[:self.pop_size // 2]  # Select top half\n            \n            # Local search around selected individuals\n            for idx in selected_idx:\n                x_current = population[idx].copy()\n                f_current = fitness[idx]\n                \n                # Adaptive step size\n                step_size = (self.ub - self.lb) / 10.0\n                \n                for _ in range(self.local_steps):\n                    if self.budget <= 0:\n                        break\n                    \n                    # Generate a random move\n                    direction = np.random.uniform(-1, 1, size=self.dim)\n                    x_new = x_current + step_size * direction\n                    \n                    # Clip to bounds\n                    x_new = np.clip(x_new, self.lb, self.ub)\n                    \n                    f_new = func(x_new)\n                    self.budget -= 1\n                    \n                    if f_new < f_current:\n                        x_current = x_new\n                        f_current = f_new\n                    \n                    if f_current < self.f_opt:\n                        self.f_opt = f_current\n                        self.x_opt = x_current.copy()\n\n                # Update population with local search result\n                population[idx] = x_current\n                fitness[idx] = f_current\n\n            # Exploration: Replace worst individuals with random samples\n            worst_idx = sorted_idx[self.pop_size // 2:] # Select worst half\n            new_samples = np.random.uniform(self.lb, self.ub, size=(len(worst_idx), self.dim))\n            new_fitness = np.array([func(x) for x in new_samples])\n            self.budget -= len(worst_idx)\n                \n            population[worst_idx] = new_samples\n            fitness[worst_idx] = new_fitness\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "1090910e-ca2a-443e-aaad-8d48fe6d60e5", "fitness": "-inf", "name": "GPSurrogate", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogate:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma  # Upper Confidence Bound\n\n    def __call__(self, func):\n        # Initial sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.eval_count += self.n_initial_samples\n\n        self.X = X_init\n        self.y = y_init\n        \n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        while self.eval_count < self.budget:\n            # Fit GP model\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            x_next = self.find_next_point()\n\n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.eval_count += 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt\n\n    def find_next_point(self):\n        # Simple random search for the next point (can be replaced with a more sophisticated optimization)\n        best_x = None\n        best_acq = np.inf\n        for _ in range(100):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            acq = self.acquisition_function(x, self.gp)\n            if acq < best_acq:\n                best_acq = acq\n                best_x = x\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "47b64f81-c444-407d-a72f-643f72ab0d63", "fitness": 0.0, "name": "QuadraticModelSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass QuadraticModelSearch:\n    def __init__(self, budget=10000, dim=10, num_points=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_points = num_points\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random solution\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample points around the current best\n            points = np.random.normal(loc=self.x_opt, scale=0.1, size=(self.num_points, self.dim))\n            points = np.clip(points, lb, ub)\n            fitness = np.array([func(p) for p in points])\n            evals += self.num_points\n\n            # Fit a quadratic model\n            try:\n                H = np.zeros((self.dim, self.dim))\n                g = np.zeros(self.dim)\n\n                for i in range(self.num_points):\n                    diff = points[i] - self.x_opt\n                    H += np.outer(diff, diff) * (fitness[i] - f)\n                    g += diff * (fitness[i] - f)\n\n                H = H / self.num_points\n                g = g / self.num_points\n\n                # Move to the minimum of the model\n                if np.linalg.det(H) != 0:\n                    x_new = self.x_opt - np.linalg.solve(H, g) / 2\n                    x_new = np.clip(x_new, lb, ub)\n\n                    f_new = func(x_new)\n                    evals += 1\n\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                        f = f_new\n                        x = x_new\n                else:\n                    x = np.random.uniform(lb, ub, size=self.dim)\n                    f = func(x)\n                    if f < self.f_opt:\n                      self.f_opt = f\n                      self.x_opt = x\n                    evals += 1\n\n            except np.linalg.LinAlgError:\n                # If the quadratic model is ill-conditioned, sample a new point randomly\n                x = np.random.uniform(lb, ub, size=self.dim)\n                f = func(x)\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                evals += 1\n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm QuadraticModelSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "e7f32feb-5976-433b-8980-04c26b124ca9", "fitness": 0.14994898376300142, "name": "AdaptiveMultiStartLS", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveMultiStartLS:\n    def __init__(self, budget=10000, dim=10, num_starts=10, initial_step_size=1.0, step_size_reduction_factor=0.5, diversification_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_starts = num_starts\n        self.initial_step_size = initial_step_size\n        self.step_size_reduction_factor = step_size_reduction_factor\n        self.diversification_threshold = diversification_threshold\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for _ in range(self.num_starts):\n            if eval_count >= self.budget:\n                break\n\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            f = func(x)\n            eval_count += 1\n\n            step_size = self.initial_step_size\n\n            while step_size > 1e-6 and eval_count < self.budget:\n                # Generate a random direction\n                direction = np.random.randn(self.dim)\n                direction /= np.linalg.norm(direction)\n\n                # Take a step in that direction\n                x_new = x + step_size * direction\n                x_new = np.clip(x_new, self.lb, self.ub)\n                f_new = func(x_new)\n                eval_count += 1\n                \n                if f_new < f:\n                    x = x_new\n                    f = f_new\n                else:\n                    step_size *= self.step_size_reduction_factor  # Reduce step size if no improvement\n\n            # Diversification: Check if the current solution is too similar to the best solution found so far.\n            if self.x_opt is not None and np.linalg.norm(x - self.x_opt) < self.diversification_threshold:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                eval_count += 1\n                \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveMultiStartLS scored 0.150 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07101931575309939, 0.09622976335969902, 0.22374723141379427, 0.13523008070134546, 0.1263214851585821, 0.14657782866489266, 0.09734232522412678, 0.11999024688138615, 0.15602200124047938, 0.11942558193143216, 0.11799871281569108, 0.19555828099946626, 0.24634251359713466, 0.18739140752502992, 0.14592362123488456, 0.21701519445275896, 0.16778999168336106, 0.18377953685498183, 0.09499147513390749, 0.15028308063397489]}, "task_prompt": ""}
{"id": "336e255e-def8-4ac0-aa36-dbcde5ce0c64", "fitness": 0.40025207666784973, "name": "MomentumDescent", "description": "No description provided.", "code": "import numpy as np\n\nclass MomentumDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        self.f_opt = f\n        self.x_opt = x\n        \n        velocity = np.zeros(self.dim)\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Calculate gradient approximation (central difference)\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = step_size\n                x_plus[i] = min(ub[i], x[i] + delta)\n                x_minus[i] = max(lb[i], x[i] - delta)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                evals += 2\n                \n                gradient[i] = (f_plus - f_minus) / (x_plus[i] - x_minus[i])\n\n            # Update velocity and position with momentum\n            velocity = self.momentum_factor * velocity - step_size * gradient\n            x = x + velocity\n            x = np.clip(x, lb, ub)\n\n            f = func(x)\n            evals += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                \n            # Reduce step size\n            step_size *= 0.99\n            \n            if evals >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MomentumDescent scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05141866350376845, 0.20738683636202782, 0.6334560054937376, 0.1748658473084308, 0.21736937359714625, 0.8552896865746009, 0.24202713998875425, 0.30568583033758445, 0.1951131205847566, 0.14677811058487078, 0.49721154075571206, 0.9720265759421163, 0.2818989977541321, 0.22503042105981852, 0.5982383573538668, 0.3160062432760916, 0.6105139978706211, 0.8919244256112001, 0.15214425512334606, 0.43065610427441126]}, "task_prompt": ""}
{"id": "42d666cc-4fc2-4423-86ba-32585625f655", "fitness": "-inf", "name": "CMAESLocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAESLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, decay_rate=0.999):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.decay_rate = decay_rate\n        self.mean = None\n        self.C = None\n        self.step_size = None\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(self.bounds_lb, self.bounds_ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.step_size = self.initial_step_size\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Generate samples\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            samples = self.mean + self.step_size * z\n            samples = np.clip(samples, self.bounds_lb, self.bounds_ub)\n\n            # Evaluate samples\n            fitness = np.array([func(x) for x in samples])\n            eval_count += self.pop_size\n            if eval_count > self.budget:\n                 fitness = fitness[:self.pop_size - (eval_count - self.budget)]\n                 samples = samples[:self.pop_size - (eval_count - self.budget)]\n                 eval_count = self.budget\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = samples[best_idx]\n\n            # Sort samples and fitness\n            sorted_idx = np.argsort(fitness)\n            samples = samples[sorted_idx]\n            fitness = fitness[sorted_idx]\n\n            # Update mean\n            self.mean = np.mean(samples[:self.pop_size // 2], axis=0)\n\n            # Update covariance matrix (simplified)\n            d = samples[:self.pop_size // 2] - self.mean\n            self.C = np.cov(d.T)\n            if np.linalg.det(self.C) <= 0:\n                self.C = np.eye(self.dim)\n\n            # Decay step size\n            self.step_size *= self.decay_rate\n\n            # Local Search (on best solution)\n            if np.random.rand() < 0.1:\n                x_ls = self.local_search(func, samples[0], eval_count, self.budget)\n                f_ls = func(x_ls)\n                eval_count += 1\n\n                if f_ls < self.f_opt:\n                    self.f_opt = f_ls\n                    self.x_opt = x_ls\n\n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n\n    def local_search(self, func, x_start, eval_count, budget, radius=0.1, iterations=5):\n        x_best = x_start.copy()\n        f_best = func(x_start)\n        eval_count +=1\n\n        for _ in range(iterations):\n             if eval_count >= budget:\n                 break\n             x_neighbor = x_best + np.random.uniform(-radius, radius, size=self.dim)\n             x_neighbor = np.clip(x_neighbor, self.bounds_lb, self.bounds_ub)\n             f_neighbor = func(x_neighbor)\n             eval_count+=1\n\n             if f_neighbor < f_best:\n                 f_best = f_neighbor\n                 x_best = x_neighbor\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Traceback (most recent call last):\n  File \"C:\\Users\\Kukoy\\AppData\\Local\\Temp\\blade_env_vttbffww\\run_eval.py\", line 10, in <module>\n    result=problem.evaluate(solution)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Kukoy\\OneDrive\\Documents\\BLADE-WORKING\\BLADE\\iohblade\\problems\\mabbob.py\", line 153, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 64, in __call__\nTypeError: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\n\nInvoked with: <RealSingleObjectiveProblem 11. Discus (iid=1 dim=2)>, (np.float64(37686503.77195296), array([-3.68157706,  4.07510864]))", "error": "Traceback (most recent call last):\n  File \"C:\\Users\\Kukoy\\AppData\\Local\\Temp\\blade_env_vttbffww\\run_eval.py\", line 10, in <module>\n    result=problem.evaluate(solution)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Kukoy\\OneDrive\\Documents\\BLADE-WORKING\\BLADE\\iohblade\\problems\\mabbob.py\", line 153, in evaluate\n    algorithm(problem)\n  File \"<string>\", line 64, in __call__\nTypeError: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\n\nInvoked with: <RealSingleObjectiveProblem 11. Discus (iid=1 dim=2)>, (np.float64(37686503.77195296), array([-3.68157706,  4.07510864]))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "efed74f4-2eae-48e3-aa12-1ead51349a04", "fitness": 0.1485299868032651, "name": "GradientShrinkSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass GradientShrinkSearch:\n    def __init__(self, budget=10000, dim=10, num_starts=5, shrink_factor=0.9, gradient_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_starts = num_starts\n        self.shrink_factor = shrink_factor\n        self.gradient_samples = gradient_samples\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        for _ in range(self.num_starts):\n            lb = np.full(self.dim, self.lb)\n            ub = np.full(self.dim, self.ub)\n            center = np.random.uniform(lb, ub)\n\n            while eval_count < self.budget:\n                # Estimate Gradient\n                gradient = np.zeros(self.dim)\n                for i in range(self.dim):\n                    perturbations = np.random.normal(0, 0.01, size=self.gradient_samples)\n                    fitness_deltas = []\n                    for p in perturbations:\n                        x_perturbed = center.copy()\n                        x_perturbed[i] += p\n                        x_perturbed = np.clip(x_perturbed, lb[i], ub[i])\n                        f_perturbed = func(x_perturbed)\n                        eval_count += 1\n                        if eval_count >= self.budget:\n                            break\n                        fitness_deltas.append(f_perturbed)\n                    if eval_count >= self.budget:\n                        break\n                    gradient[i] = np.mean(fitness_deltas)\n\n                if eval_count >= self.budget:\n                    break\n                # Move towards the negative gradient direction\n                step = -0.01 * gradient\n                new_center = center + step\n                new_center = np.clip(new_center, lb, ub)\n\n                f = func(new_center)\n                eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = new_center.copy()\n\n                center = new_center\n\n                # Shrink search space\n                range_width = (ub - lb) * self.shrink_factor\n                lb = np.maximum(self.lb, center - range_width / 2)\n                ub = np.minimum(self.ub, center + range_width / 2)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GradientShrinkSearch scored 0.149 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09470712228097433, 0.1106091649364136, 0.24977602471833593, 0.09410974972236441, 0.09962535098997194, 0.15312671625598684, 0.021473260512474335, 0.15745702837111986, 0.1384225021411044, 0.09875263166123027, 0.14596894797339643, 0.19401532671400756, 0.047971292594370274, 0.1037336964798462, 0.13408926983147706, 0.22843291979091673, 0.16124592427783313, 0.162440314787334, 0.16986497641396492, 0.4047775156121798]}, "task_prompt": ""}
{"id": "044bc749-86d5-4608-8b6c-d6fb82e0a419", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, exploration_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.exploration_weight = exploration_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial samples\n        X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        y = np.array([func(x) for x in X])\n        self.budget -= self.n_initial_samples\n\n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n        \n        # Gaussian process model\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while self.budget > 0:\n            # Fit the GP model\n            gp.fit(X, y)\n\n            # Acquisition function (Upper Confidence Bound)\n            def acquisition(x):\n                x = x.reshape(1, -1)\n                mu, sigma = gp.predict(x, return_std=True)\n                return mu - self.exploration_weight * sigma\n\n            # Optimize acquisition function (simple random search within bounds)\n            x_new = None\n            best_acq = np.inf\n            for _ in range(100):\n                x_candidate = np.random.uniform(lb, ub, size=self.dim)\n                acq_value = acquisition(x_candidate)\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    x_new = x_candidate\n            \n            # Evaluate the new point\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            # Update data\n            X = np.vstack((X, x_new))\n            y = np.append(y, f_new)\n\n            # Update best solution\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4ffbbe89-98dc-4a4e-b9c1-245b9ba39c8b", "fitness": 0.3660261203359725, "name": "AdaptiveExplorationRefinement", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveExplorationRefinement:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_prob=0.5, refinement_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_prob = exploration_prob\n        self.refinement_step_size = refinement_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        exploration_success = 0\n        refinement_success = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration phase: Randomly perturb solution\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    new_solution = population[i] + np.random.rand() * (self.ub - self.lb) * random_direction\n                    new_solution = np.clip(new_solution, self.lb, self.ub)\n                else:\n                    # Refinement phase: Local search around the solution\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    new_solution = population[i] + self.refinement_step_size * random_direction\n                    new_solution = np.clip(new_solution, self.lb, self.ub)\n\n                f = func(new_solution)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_solution.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_solution.copy()\n                        if np.random.rand() < 0.5:\n                            exploration_success += 1\n                        else:\n                            refinement_success += 1\n\n\n            # Adjust exploration probability based on success rates\n            total_success = exploration_success + refinement_success\n            if total_success > 0:\n                exploration_rate = exploration_success / total_success\n                self.exploration_prob = 0.5 + 0.3 * (exploration_rate - 0.5)\n            exploration_success = 0\n            refinement_success = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveExplorationRefinement scored 0.366 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15214526578862975, 0.2922054752717158, 0.38146726235033634, 0.4353539676658571, 0.2513391248956498, 0.39664152064081504, 0.27558737194154215, 0.2895836242117632, 0.25716856897788887, 0.19195668096623653, 0.3727859956326377, 0.9927575909157309, 0.2851145578914176, 0.2565799834628151, 0.6881997826635882, 0.37068021385939076, 0.26250711227390766, 0.49602473894932075, 0.19237519487750976, 0.4800483734826969]}, "task_prompt": ""}
{"id": "33158f45-0fc6-4b6f-a1cd-803a1d2186ff", "fitness": 0.31890966549288213, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f_initial=0.5, f_adapt_rate=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f_initial\n        self.f_adapt_rate = f_adapt_rate\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            successful_mutations = 0\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                trial_vector = population[i] + self.f * (x2 - x3)\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    successful_mutations += 1\n                    population[i] = trial_vector\n                    fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n\n            # Adjust mutation factor\n            success_rate = successful_mutations / self.pop_size\n            if success_rate > 0.2:\n                self.f *= (1 - self.f_adapt_rate)\n            else:\n                self.f /= (1 - self.f_adapt_rate)\n            self.f = np.clip(self.f, 0.1, 1.0)\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.319 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1408869979370998, 0.23343315119964303, 0.32584837513346276, 0.3002213012433673, 0.24174973993062054, 0.2746843340589671, 0.24872444875995148, 0.2589880467931015, 0.2569599857919659, 0.1758968506338643, 0.24213001188816574, 0.9936613370006756, 0.3004485110881542, 0.22101347247486525, 0.6176562478827929, 0.32793377153944625, 0.2705101516552171, 0.2923232489805738, 0.17850776800563584, 0.47661555786007304]}, "task_prompt": ""}
{"id": "fbb54302-055a-4e54-8853-09ddb7f50da1", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.5, restart_trigger=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.restart_trigger = restart_trigger\n\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n\n        self.ccov = (1 / (self.mueff * min(self.dim, self.mueff**2))) * (1 + (2 / 3))\n        self.ccovmu = (2 / ((self.mueff + (self.dim + 1)**2))) * (1 + (2 / 3) * (self.mueff / (self.mueff + self.dim + 5)))\n        self.ccovsep = min(1, self.ccov * (self.dim / np.sqrt(self.mueff)))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * z @ np.linalg.cholesky(self.C).T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n            y = (self.mean - mean_old) / self.sigma\n\n            # Update evolution path\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * y\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.budget / self.pop_size))) / self.chiN < 1.4 + 2 / (self.dim + 1))\n            self.pc = (1 - self.ccov) * self.pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (z[idx[0:self.mu]] @ self.weights)\n\n            # Update covariance matrix\n            artmp = (1 / self.sigma) * (x[:self.mu] - mean_old)\n            self.C = (1 - self.ccov - self.ccovmu + self.ccov * (1 - hsig) * self.ccovsep) * self.C + self.ccovmu * artmp.T @ np.diag(self.weights) @ artmp + self.ccov * self.pc[:, None] @ self.pc[None, :]\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T  # enforce symmetry\n            \n            # Restart mechanism\n            if np.random.rand() < self.restart_trigger:\n                self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                self.sigma = self.initial_sigma\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 63, in __call__, the following error occurred:\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)\nOn line: self.pc = (1 - self.ccov) * self.pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (z[idx[0:self.mu]] @ self.weights)", "error": "In the code, line 63, in __call__, the following error occurred:\nValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)\nOn line: self.pc = (1 - self.ccov) * self.pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (z[idx[0:self.mu]] @ self.weights)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "0e612bae-5d98-424e-8933-5f5d76462960", "fitness": "-inf", "name": "PSODE", "description": "No description provided.", "code": "import numpy as np\n\nclass PSODE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, de_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.de_rate = de_rate # Differential Evolution Rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        self.f_opt = fitness[best_idx]\n        self.x_opt = global_best_position.copy()\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity using PSO\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Differential Evolution\n                if np.random.rand() < self.de_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    F = np.random.uniform(0, 1)\n                    j_rand = np.random.randint(self.dim)\n\n                    for j in range(self.dim):\n                        if np.random.rand() < F or j == j_rand:\n                            population[i][j] = x_r1[j] + F * (x_r2[j] - x_r3[j])\n                            population[i][j] = np.clip(population[i][j], lb, ub)\n\n                # Evaluate fitness\n                fitness_i = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if fitness_i < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_i\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if fitness_i < self.f_opt:\n                    self.f_opt = fitness_i\n                    self.x_opt = population[i].copy()\n                    global_best_position = population[i].copy()\n\n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 58, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: population[i][j] = np.clip(population[i][j], lb, ub)", "error": "In the code, line 58, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: population[i][j] = np.clip(population[i][j], lb, ub)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ca7bbbe8-acde-4204-90a1-58057256e12f", "fitness": 0.5224228694099611, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.7, lr_cr=0.1, lr_f=0.1, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lr_cr = lr_cr\n        self.lr_f = lr_f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.restart_threshold = restart_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize DE parameters\n        cr = np.full(self.pop_size, self.cr_init)\n        f = np.full(self.pop_size, self.f_init)\n        \n        success_cr = np.zeros(self.pop_size)\n        success_f = np.zeros(self.pop_size)\n        success_count = np.zeros(self.pop_size)\n        \n        no_improvement_count = 0\n        \n        while self.budget > 0:\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                \n                mutated_vector = population[i] + f[i] * (x2 - x3)\n                mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        trial_vector[j] = mutated_vector[j]\n                \n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < fitness[i]:\n                    success_cr[i] = cr[i]\n                    success_f[i] = f[i]\n                    success_count[i] += 1\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n                \n                # Parameter adaptation\n                if success_count[i] > 0:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.mean(success_cr[success_cr > 0]) if np.any(success_cr > 0) else self.cr_init\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.mean(success_f[success_f > 0]) if np.any(success_f > 0) else self.f_init\n                else:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.random.rand()\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.random.rand()\n                    \n                cr[i] = np.clip(cr[i], 0.1, 0.9)\n                f[i] = np.clip(f[i], 0.1, 0.9)\n            \n            if self.f_opt >= old_f_opt:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n                \n            if no_improvement_count > self.restart_threshold:\n                # Restart mechanism\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                \n                cr = np.full(self.pop_size, self.cr_init)\n                f = np.full(self.pop_size, self.f_init)\n                \n                success_cr = np.zeros(self.pop_size)\n                success_f = np.zeros(self.pop_size)\n                success_count = np.zeros(self.pop_size)\n                \n                no_improvement_count = 0\n                \n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.522 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1535936609388877, 0.27541095456524456, 0.5283833575514192, 0.8007525897649509, 0.46808519498912615, 0.685233023022618, 0.33566685419726394, 0.4852083876933241, 0.5628996977519305, 0.23010859489574575, 0.7827712507581777, 0.9922343952972583, 0.2848679260240098, 0.3618497389611448, 0.8579326254154405, 0.7021557401371514, 0.4292894714139175, 0.800985433878321, 0.20798268952492482, 0.5030458014183641]}, "task_prompt": ""}
{"id": "816f85ac-842f-432e-aec5-3d5a0268ae6d", "fitness": 0.4484719090818177, "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov_mean=None, c_cov_rank_one=None, c_cov_rank_mu=None, mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.mean = np.random.uniform(-5, 5, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.eval_count = 0\n\n        self.mu = mu if mu is not None else self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mu - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov_mean = c_cov_mean if c_cov_mean is not None else self.cs**2 * (self.mu / (self.dim + np.sqrt(self.mu/2)))\n        self.c_cov_rank_one = c_cov_rank_one if c_cov_rank_one is not None else 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_cov_rank_mu = c_cov_rank_mu if c_cov_rank_mu is not None else 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu)\n\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + (1 / (21 * self.dim**2)))\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.restart_threshold = self.budget // 10\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        while self.eval_count < self.budget:\n            # Generate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            try:\n                D = np.diag(np.sqrt(np.diag(self.C)))\n                x = self.mean + self.sigma * z @ D\n            except Exception as e:\n                print(f\"Error during population generation: {e}\")\n                break\n\n            x = np.clip(x, self.lb, self.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n            self.best_fitness_history.append(self.f_opt)\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Update evolution path\n            zmean = np.mean(z[:self.mu], axis=0)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * (np.linalg.inv(np.diag(np.sqrt(np.diag(self.C)))) @ (self.mean - mean_old)) / self.sigma\n            \n            c_hat = self.c_cov_rank_one #self.c_cov_rank_one*self.budget/self.eval_count\n\n            self.pc = (1 - self.c_cov_mean) * self.pc + np.sqrt(self.c_cov_mean * (2 - self.c_cov_mean)) * (self.mean - mean_old) / self.sigma\n\n            # Update covariance matrix\n            self.C = (1 - c_hat - self.c_cov_rank_mu) * self.C + c_hat * np.outer(self.pc, self.pc) + self.c_cov_rank_mu * np.sum(self.weights[:, None, None] * (z[:self.mu, :, None] @ z[:self.mu, None, :]), axis=0)\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            self.C = self.C / np.linalg.norm(self.C)\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.sigma = max(self.sigma, 1e-10)\n\n            #Stagnation and Restart\n            if len(self.best_fitness_history) > 1 and abs(self.best_fitness_history[-1] - self.best_fitness_history[-2]) < 1e-8:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n                self.C = np.eye(self.dim)\n                self.sigma = 0.5\n                self.ps = np.zeros(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.stagnation_counter = 0\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.448 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.029620148235337762, 0.1859752053611916, 0.9082925820563574, 0.20753332534615254, 0.6152675897576884, 0.22280679987901508, 0.303403970875353, 0.9324395173244151, 0.32641454134122583, 0.12554945604753998, 0.9021666498257294, 0.9994193122514945, 0.235718711103457, 0.20266794262510546, 0.8546504575105138, 0.3936690031817236, 0.24641883508257623, 0.9684573323106889, 0.15526021567082593, 0.15370658584996455]}, "task_prompt": ""}
{"id": "b0bb86d5-1c78-48b8-96bf-433b7b18a33b", "fitness": 0.1838736092882186, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr=0.9, f=0.5, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr = cr\n        self.f = f\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_success_rate = 0.5\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        success_history = []\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation strategy adaptation based on success rate\n                if np.random.rand() < self.mutation_success_rate:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    trial_vector = population[i] + self.f * (x2 - x3)\n\n                else:\n                    # Explore more if mutation rate is low\n                    trial_vector = population[i] + self.mutation_scale * np.random.normal(0, 1, self.dim)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() > self.cr and j != j_rand:\n                        trial_vector[j] = population[i, j]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    success_history.append(1)\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                else:\n                    success_history.append(0)\n\n                # Update mutation success rate\n                if len(success_history) > 50:\n                    success_rate = np.mean(success_history[-50:])\n                    self.mutation_success_rate = 0.8 * self.mutation_success_rate + 0.2 * success_rate\n                    self.mutation_scale = 0.1 * np.exp(-5 * (1 - self.mutation_success_rate))\n\n            # Restart mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                global_best_index = np.argmin(fitness)\n                if fitness[global_best_index] < self.f_opt:\n                    self.f_opt = fitness[global_best_index]\n                    self.x_opt = population[global_best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.184 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1309877892935587, 0.20873187689643868, 0.3111187412504801, 0.23642519097844938, 0.21597805731038477, 0]}, "task_prompt": ""}
{"id": "feaddc70-538a-4bca-b490-5278b1433357", "fitness": 0.3957264668363827, "name": "EnhancedSelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, cr_init=0.7, f_init=0.5, lr_cr=0.2, lr_f=0.2, archive_size=20, restart_threshold=500, aggressive_f_update=1.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lr_cr = lr_cr\n        self.lr_f = lr_f\n        self.lb = -5.0\n        self.ub = 5.0\n        self.archive_size = archive_size\n        self.restart_threshold = restart_threshold\n        self.aggressive_f_update = aggressive_f_update\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize Archive\n        archive = []\n        archive_fitness = []\n\n        # Initialize DE parameters\n        cr = np.full(self.pop_size, self.cr_init)\n        f = np.full(self.pop_size, self.f_init)\n\n        success_cr = np.zeros(self.pop_size)\n        success_f = np.zeros(self.pop_size)\n        success_count = np.zeros(self.pop_size)\n\n        no_improvement_count = 0\n\n        while self.budget > 0:\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = population[idxs]\n\n                if len(archive) > 0 and np.random.rand() < 0.1:\n                    idx_archive = np.random.randint(len(archive))\n                    x3 = archive[idx_archive]\n                else:\n                    idx = np.random.choice(self.pop_size, 1, replace=False)[0]\n                    x3 = population[idx]\n\n                mutated_vector = population[i] + f[i] * (x1 - x2)\n                mutated_vector = np.clip(mutated_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < cr[i] or j == j_rand:\n                        trial_vector[j] = mutated_vector[j]\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if f_trial < fitness[i]:\n                    success_cr[i] = cr[i]\n                    success_f[i] = f[i]\n                    success_count[i] += 1\n\n                    # Update archive\n                    if len(archive) < self.archive_size:\n                        archive.append(population[i].copy())\n                        archive_fitness.append(fitness[i])\n                    else:\n                        worst_archive_idx = np.argmax(archive_fitness)\n                        if fitness[i] < archive_fitness[worst_archive_idx]:\n                            archive[worst_archive_idx] = population[i].copy()\n                            archive_fitness[worst_archive_idx] = fitness[i]\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                # Parameter adaptation\n                if success_count[i] > 0:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.mean(success_cr[success_cr > 0]) if np.any(success_cr > 0) else self.cr_init\n                    f[i] = (1 - self.lr_f) * f[i] + self.lr_f * np.mean(success_f[success_f > 0]) if np.any(success_f > 0) else self.f_init\n                else:\n                    cr[i] = (1 - self.lr_cr) * cr[i] + self.lr_cr * np.random.rand()\n                    f[i] = f[i] * self.aggressive_f_update if np.random.rand() < 0.1 else (1 - self.lr_f) * f[i] + self.lr_f * np.random.rand()\n\n                cr[i] = np.clip(cr[i], 0.1, 0.9)\n                f[i] = np.clip(f[i], 0.1, 2.0)\n\n            if self.f_opt >= old_f_opt:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n\n            if no_improvement_count > self.restart_threshold:\n                # Restart mechanism\n                population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                archive = []\n                archive_fitness = []\n\n                cr = np.full(self.pop_size, self.cr_init)\n                f = np.full(self.pop_size, self.f_init)\n\n                success_cr = np.zeros(self.pop_size)\n                success_f = np.zeros(self.pop_size)\n                success_count = np.zeros(self.pop_size)\n\n                no_improvement_count = 0\n\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                    self.f_opt = fitness[best_index]\n                    self.x_opt = population[best_index].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedSelfAdaptiveDE scored 0.396 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1425633680745827, 0.24779995987299286, 0.3871576068967444, 0.39218767143595956, 0.302193138616482, 0.44767773255508736, 0.2947839028363669, 0.3343541744456926, 0.31112474966160675, 0.18371537038945596, 0.5201340038221987, 0.9999168080855206, 0.3108363376769995, 0.32749484542040086, 0.7464139114280555, 0.4274116838137827, 0.3246129247168006, 0.537806383562184, 0.18672278158245514, 0.4896219818342846]}, "task_prompt": ""}
{"id": "3142caa1-4689-4974-99ab-1d1e4dcf87e6", "fitness": "-inf", "name": "HybridDE_NM", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_mutation_factor=0.5, de_crossover_rate=0.7, nm_max_iter=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_mutation_factor = de_mutation_factor\n        self.de_crossover_rate = de_crossover_rate\n        self.nm_max_iter = nm_max_iter\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Calculate population diversity\n            diversity = np.std(fitness)\n            \n            # Adaptive switch between DE and NM\n            if diversity > 1e-3:  # High diversity: Exploration using DE\n                for i in range(self.pop_size):\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = population[idxs]\n                    \n                    # Mutation\n                    v = population[i] + self.de_mutation_factor * (x_r2 - x_r3)\n                    v = np.clip(v, lb, ub)\n                    \n                    # Crossover\n                    u = np.random.rand(self.dim)\n                    trial_vector = np.where(u <= self.de_crossover_rate, v, population[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    f_trial = func(trial_vector)\n                    evals += 1\n                    \n                    if f_trial < fitness[i]:\n                        population[i] = trial_vector\n                        fitness[i] = f_trial\n                        \n                        if f_trial < self.f_opt:\n                            self.f_opt = f_trial\n                            self.x_opt = trial_vector\n                            \n                    if evals >= self.budget:\n                        break\n\n            else:  # Low diversity: Exploitation using Nelder-Mead\n                for i in range(self.pop_size):\n                    # Nelder-Mead Simplex\n                    res = minimize(func, population[i], method='Nelder-Mead', options={'maxiter': self.nm_max_iter, 'disp': False})\n                    \n                    if res.success:\n                        x_nm = res.x\n                        f_nm = res.fun\n                        num_func_calls = res.nfev\n                        \n                        evals += num_func_calls\n                        \n                        if f_nm < fitness[i]:\n                            population[i] = x_nm\n                            fitness[i] = f_nm\n                            \n                            if f_nm < self.f_opt:\n                                self.f_opt = f_nm\n                                self.x_opt = x_nm\n                        \n                        if evals >= self.budget:\n                            break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 64, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: res = minimize(func, population[i], method='Nelder-Mead', options={'maxiter': self.nm_max_iter, 'disp': False})", "error": "In the code, line 64, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: res = minimize(func, population[i], method='Nelder-Mead', options={'maxiter': self.nm_max_iter, 'disp': False})", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "29c0aa7f-d867-4cec-b05d-b6848b5b72f4", "fitness": "-inf", "name": "GradientDescentOpt", "description": "No description provided.", "code": "import numpy as np\n\nclass GradientDescentOpt:\n    def __init__(self, budget=10000, dim=10, step_size=0.1, sampling_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.sampling_radius = sampling_radius\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Estimate gradient using finite differences\n            grad = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                x_plus[i] += self.sampling_radius\n                x_minus[i] -= self.sampling_radius\n                x_plus[i] = np.clip(x_plus[i], lb, ub)\n                x_minus[i] = np.clip(x_minus[i], lb, ub)\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                evals += 2\n                grad[i] = (f_plus - f_minus) / (2 * self.sampling_radius)\n                if evals >= self.budget:\n                  break\n            if evals >= self.budget:\n                  break\n            # Update solution\n            x_new = x - self.step_size * grad\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Accept new solution if it's better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.step_size *= 1.1  # Increase step size if successful\n            else:\n                self.step_size *= 0.5  # Decrease step size if unsuccessful\n\n            if self.step_size < 1e-6:\n                x = np.random.uniform(lb, ub, size=self.dim)  # Restart if step size too small\n                self.step_size = 0.1\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 29, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[i] = np.clip(x_plus[i], lb, ub)", "error": "In the code, line 29, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[i] = np.clip(x_plus[i], lb, ub)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "cbacd0b2-c822-486f-b6bb-32eec4a2f0cb", "fitness": 0.08880521908559107, "name": "SimpleCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.x = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.step_size = initial_step_size\n        self.success_prob = 0.5 # Start with 50% chance of a successful step\n\n    def __call__(self, func):\n        self.x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.f_opt = func(self.x)\n        self.x_opt = self.x.copy()\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a new solution by sampling from a normal distribution\n            z = np.random.normal(0, 1, size=self.dim)\n            x_new = self.x + self.step_size * z\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < self.f_opt:\n                # Successful step: Update the solution and adapt the step size\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                self.x = x_new.copy()\n                self.step_size *= np.exp(0.2 * (1 - 1/self.success_prob)) # increase step size\n                self.success_prob = 0.9\n\n            else:\n                # Unsuccessful step: Decrease the step size\n                self.step_size *= np.exp(-0.25 * (1/self.success_prob - 1))  # decrease step size\n                self.success_prob = 0.1\n            \n            self.step_size = np.clip(self.step_size, 1e-6, (self.ub - self.lb)/2)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimpleCMAES scored 0.089 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0130692850101497, 9.999999999998899e-05, 0.1826869159657769, 0.13393052614005518, 0.023997608234368584, 0.1389371050234749, 0.006879351979557802, 0.07729456617634334, 0.005753935969316948, 0.07334875664980012, 0.09277038698944506, 0.13387833641659963, 0.22822447119273825, 0.05996244933828965, 0.0861933424196144, 0.13319991238737872, 0.05061492358106223, 0.11235702158162808, 0.10340203402967674, 0.11950345262654505]}, "task_prompt": ""}
{"id": "e395b2e9-3e51-4544-a4bb-1c2319c485a6", "fitness": 0.0, "name": "AdaptiveSimplex", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimplex:\n    def __init__(self, budget=10000, dim=10, initial_simplex_size=1.0, reflection_coefficient=1.0, expansion_coefficient=2.0, contraction_coefficient=0.5, shrinkage_coefficient=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_simplex_size = initial_simplex_size\n        self.reflection_coefficient = reflection_coefficient\n        self.expansion_coefficient = expansion_coefficient\n        self.contraction_coefficient = contraction_coefficient\n        self.shrinkage_coefficient = shrinkage_coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize simplex\n        self.simplex = np.random.uniform(self.lb, self.ub, size=(self.dim + 1, self.dim))\n        self.simplex[0] = np.random.uniform(self.lb, self.ub, size=self.dim)\n        for i in range(1, self.dim + 1):\n          self.simplex[i] = self.simplex[0] + np.random.uniform(-self.initial_simplex_size, self.initial_simplex_size, size=self.dim)\n\n        self.fitness = np.array([func(x) for x in self.simplex])\n        self.eval_count = self.dim + 1\n\n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.simplex[best_idx]\n\n        while self.eval_count < self.budget:\n            # Order the simplex\n            order = np.argsort(self.fitness)\n            self.simplex = self.simplex[order]\n            self.fitness = self.fitness[order]\n\n            # Calculate centroid\n            centroid = np.mean(self.simplex[:-1], axis=0)\n\n            # Reflection\n            reflected_point = centroid + self.reflection_coefficient * (centroid - self.simplex[-1])\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            reflected_fitness = func(reflected_point)\n            self.eval_count += 1\n\n            if reflected_fitness < self.fitness[0]:\n                # Expansion\n                expanded_point = centroid + self.expansion_coefficient * (reflected_point - centroid)\n                expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                expanded_fitness = func(expanded_point)\n                self.eval_count += 1\n\n                if expanded_fitness < reflected_fitness:\n                    self.simplex[-1] = expanded_point\n                    self.fitness[-1] = expanded_fitness\n                else:\n                    self.simplex[-1] = reflected_point\n                    self.fitness[-1] = reflected_fitness\n            elif reflected_fitness < self.fitness[-2]:\n                self.simplex[-1] = reflected_point\n                self.fitness[-1] = reflected_fitness\n            else:\n                # Contraction\n                contracted_point = centroid + self.contraction_coefficient * (self.simplex[-1] - centroid)\n                contracted_point = np.clip(contracted_point, self.lb, self.ub)\n                contracted_fitness = func(contracted_point)\n                self.eval_count += 1\n\n                if contracted_fitness < self.fitness[-1]:\n                    self.simplex[-1] = contracted_point\n                    self.fitness[-1] = contracted_fitness\n                else:\n                    # Shrink\n                    for i in range(1, self.dim + 1):\n                        self.simplex[i] = self.simplex[0] + self.shrinkage_coefficient * (self.simplex[i] - self.simplex[0])\n                        self.simplex[i] = np.clip(self.simplex[i], self.lb, self.ub)\n                        self.fitness[i] = func(self.simplex[i])\n                        self.eval_count += 1\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.simplex[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimplex scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "00fd09c3-7c59-41b2-abfc-3ef8b2fb40c1", "fitness": 0.48344363776839794, "name": "AdaptiveNelderMead", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, simplex_size=None, reflection=1.0, expansion=2.0, contraction=0.5, shrink=0.5, restart_prob=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = simplex_size if simplex_size is not None else dim + 1\n        self.reflection = reflection\n        self.expansion = expansion\n        self.contraction = contraction\n        self.shrink = shrink\n        self.restart_prob = restart_prob\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_simplex(self, func):\n        simplex = np.random.uniform(self.lb, self.ub, size=(self.simplex_size, self.dim))\n        fitness = np.array([func(x) for x in simplex])\n        self.budget -= self.simplex_size\n        return simplex, fitness\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        simplex, fitness = self.initialize_simplex(func)\n\n        while self.budget > 0:\n            # Order the simplex vertices by fitness\n            order = np.argsort(fitness)\n            simplex = simplex[order]\n            fitness = fitness[order]\n\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = simplex[0].copy()\n\n            # Calculate the centroid of the best vertices\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected_point = centroid + self.reflection * (centroid - simplex[-1])\n            reflected_point = np.clip(reflected_point, self.lb, self.ub)\n            f_reflected = func(reflected_point)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n            \n            if fitness[0] <= f_reflected < fitness[-2]:\n                simplex[-1] = reflected_point\n                fitness[-1] = f_reflected\n            else:\n                # Expansion\n                if f_reflected < fitness[0]:\n                    expanded_point = centroid + self.expansion * (reflected_point - centroid)\n                    expanded_point = np.clip(expanded_point, self.lb, self.ub)\n                    f_expanded = func(expanded_point)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_expanded < f_reflected:\n                        simplex[-1] = expanded_point\n                        fitness[-1] = f_expanded\n                    else:\n                        simplex[-1] = reflected_point\n                        fitness[-1] = f_reflected\n                else:\n                    # Contraction\n                    contracted_point = centroid + self.contraction * (simplex[-1] - centroid)\n                    contracted_point = np.clip(contracted_point, self.lb, self.ub)\n                    f_contracted = func(contracted_point)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_contracted < fitness[-1]:\n                        simplex[-1] = contracted_point\n                        fitness[-1] = f_contracted\n                    else:\n                        # Shrink\n                        for i in range(1, self.simplex_size):\n                            simplex[i] = simplex[0] + self.shrink * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], self.lb, self.ub)\n                            fitness[i] = func(simplex[i])\n                            self.budget -= 1\n\n                            if self.budget <= 0:\n                                break\n                        if self.budget <= 0:\n                            break\n            if np.random.rand() < self.restart_prob:\n                simplex, fitness = self.initialize_simplex(func)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveNelderMead scored 0.483 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1609004691638003, 0.32705799685304426, 0.5165771203375018, 0.5049158411038377, 0.3295919220996284, 0.9317357249201119, 0.29538663867626824, 0.3364909357658218, 0.7334940973765398, 0.21170452737934342, 0.5604773018078036, 0.9987528984121483, 0.33434740487523285, 0.31915942161596367, 0.7812670651756008, 0.3900481750453647, 0.31740849034911367, 0.9123219710687994, 0.23084775103218713, 0.47638700230984665]}, "task_prompt": ""}
{"id": "3d0f380d-ce5a-4871-aa24-ee82d5e47b90", "fitness": 0.0, "name": "HybridDEGradient", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridDEGradient:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n        self.eval_count = 0\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def local_search(self, func, x, step_size=0.1):\n        \"\"\"Performs a simple gradient-based local search.\"\"\"\n        x_new = x.copy()\n        for i in range(self.dim):\n            # Calculate numerical gradient along each dimension\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += step_size\n            x_minus[i] -= step_size\n\n            #Clip to bounds\n            x_plus[i] = np.clip(x_plus[i], self.lb, self.ub)\n            x_minus[i] = np.clip(x_minus[i], self.lb, self.ub)\n                \n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n            self.eval_count += 2\n            gradient = (f_plus - f_minus) / (2 * step_size)\n\n            # Update the solution based on the gradient\n            x_new[i] -= step_size * gradient\n            x_new[i] = np.clip(x_new[i], self.lb, self.ub)  # Clip to bounds\n        return x_new, func(x_new)\n\n    def __call__(self, func):\n        # Initialization\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count = self.pop_size\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.population[i])\n\n                # Local Search with probability\n                if np.random.rand() < self.local_search_prob:\n                    trial, f_trial = self.local_search(func, trial)\n                else:\n                    f_trial = func(trial)\n                    self.eval_count += 1\n\n                # Selection\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEGradient scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "7765108a-b45e-4e96-a5f4-a5332be0a4f0", "fitness": 0.5399272833556932, "name": "CauchyAdaptation", "description": "No description provided.", "code": "import numpy as np\n\nclass CauchyAdaptation:\n    def __init__(self, budget=10000, dim=10, initial_scale=1.0, success_rate_window=100):\n        self.budget = budget\n        self.dim = dim\n        self.initial_scale = initial_scale\n        self.scale = initial_scale\n        self.success_rate_window = success_rate_window\n        self.successes = 0\n        self.attempts = 0\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample new solution from Cauchy distribution\n            z = np.random.standard_cauchy(size=self.dim)\n            new_x = self.x_opt + self.scale * z\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            evals += 1\n            self.attempts += 1\n\n            # Update if improvement\n            if new_f < self.f_opt:\n                self.f_opt = new_f\n                self.x_opt = new_x\n                self.successes += 1\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n            \n            # Adaptive scaling of Cauchy distribution\n            if self.attempts > self.success_rate_window:\n                self.attempts = 0\n                success_rate = np.mean(self.success_history[-self.success_rate_window:])\n                if success_rate > 0.2:\n                    self.scale *= 1.1  # Increase scale if success rate is high\n                else:\n                    self.scale *= 0.9  # Decrease scale if success rate is low\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyAdaptation scored 0.540 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.23011081048169613, 0.1962808113345884, 0.5551454821433651, 0.8233739368810716, 0.5512462391765562, 0.6028968524321208, 0.34060253074246005, 0.4743595218722717, 0.5440943294552403, 0.5072358323767019, 0.8185663350921046, 0.9976989114295193, 0.2570185076862598, 0.3077867941192084, 0.8693115272074488, 0.5985039227057589, 0.49805668927337166, 0.7268390844458592, 0.21067565770038732, 0.6887418905578775]}, "task_prompt": ""}
{"id": "82dbd9f3-6da2-4110-82d0-68cad64dc673", "fitness": "-inf", "name": "OrthogonalSearch", "description": "No description provided.", "code": "import numpy as np\nfrom pyDOE import lhs\n\nclass OrthogonalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, refinement_factor=0.5, oa_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.refinement_factor = refinement_factor\n        self.oa_size = oa_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while eval_count < self.budget:\n            # Refine search space around best solution\n            range_lb = np.maximum(lb, self.x_opt - self.refinement_factor * (ub - lb) / 2)\n            range_ub = np.minimum(ub, self.x_opt + self.refinement_factor * (ub - lb) / 2)\n\n            # Generate orthogonal array\n            oa = lhs(self.dim, samples=self.oa_size)\n            new_solutions = range_lb + oa * (range_ub - range_lb)\n\n            new_fitness = np.array([func(x) for x in new_solutions])\n            eval_count += self.oa_size\n\n            # Update best solution\n            best_idx_oa = np.argmin(new_fitness)\n            if new_fitness[best_idx_oa] < self.f_opt:\n                self.f_opt = new_fitness[best_idx_oa]\n                self.x_opt = new_solutions[best_idx_oa]\n\n            # Adapt refinement factor\n            if self.f_opt == np.min(fitness):\n                self.refinement_factor *= 0.9  # Reduce search volume if no improvement\n            else:\n                self.refinement_factor = min(0.5, self.refinement_factor * 1.1)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 2, in <module>, the following error occurred:\nModuleNotFoundError: No module named 'pyDOE'\nOn line: from pyDOE import lhs", "error": "In the code, line 2, in <module>, the following error occurred:\nModuleNotFoundError: No module named 'pyDOE'\nOn line: from pyDOE import lhs", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "7ab22060-3432-44b4-b8bd-75895f8b0653", "fitness": 0.0, "name": "AdaptiveExplorationExploitation", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveExplorationExploitation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, exploration_prob=0.5, lr=0.01, exploration_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.exploration_prob = exploration_prob\n        self.lr = lr\n        self.exploration_decay = exploration_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration: Random search around the current solution\n                    new_solution = population[i] + np.random.uniform(-self.lr, self.lr, size=self.dim) * (ub - lb)\n                    new_solution = np.clip(new_solution, lb, ub)\n                else:\n                    # Exploitation: Gradient-based refinement (simplified)\n                    gradient = np.zeros(self.dim)\n                    for j in range(self.dim):\n                        x_plus = population[i].copy()\n                        x_minus = population[i].copy()\n                        delta = 1e-4\n                        x_plus[j] += delta\n                        x_minus[j] -= delta\n                        x_plus = np.clip(x_plus, lb, ub)\n                        x_minus = np.clip(x_minus, lb, ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        evals += 2\n                        gradient[j] = (f_plus - f_minus) / (2 * delta)\n\n                    new_solution = population[i] - self.lr * gradient\n                    new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n                \n                if new_fitness < fitness[i]:\n                    new_population[i] = new_solution\n                    fitness[i] = new_fitness\n\n            # Update population\n            population = new_population\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            # Adaptive exploration probability\n            self.exploration_prob *= self.exploration_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveExplorationExploitation scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "cef98c3d-2f5a-46b9-88dc-b9eb4371e07c", "fitness": 0.1570381096916119, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Adaptive F and CR\n            std = np.std(population, axis=0)\n            adaptive_F = self.F * (1 + np.mean(std)) # Add some randomness with std\n            adaptive_CR = self.CR * (1 - np.mean(std))\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                mutant = population[i] + adaptive_F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < adaptive_CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n\n                # Evaluation\n                f = func(trial_vector)\n                evals += 1\n\n                # Selection\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    # Update best solution\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n                \n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.157 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0671699172871888, 0.14800628621706424, 0.21675403494790058, 0.12806993734294214, 0.1240068075790467, 0.1330455591614269, 0.16806959117705522, 0.12892738752645783, 0.13670371185274965, 0.1343513218230451, 0.13475860115906435, 0.18369376486172895, 0.07920171075446725, 0.1560103368218928, 0.14222326903317828, 0.21879186012779805, 0.16969259459470754, 0.16038360114791672, 0.10706056582903145, 0.4038413345875753]}, "task_prompt": ""}
{"id": "6a55ec59-9429-4935-ba7f-92a4e2169717", "fitness": 0.31479435091075586, "name": "MomentumSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass MomentumSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum_factor=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.momentum_factor = momentum_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        v = np.zeros(self.dim)  # Initialize velocity\n        \n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Calculate the gradient (approximation)\n            grad = np.zeros(self.dim)\n            delta = 1e-4\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_plus[i] += delta\n                f_plus = func(x_plus) if evals + 1 <= self.budget else np.inf\n                if f_plus == np.inf:\n                    break\n                evals += 1\n\n                x_minus = x.copy()\n                x_minus[i] -= delta\n                f_minus = func(x_minus) if evals + 1 <= self.budget else np.inf\n                if f_minus == np.inf:\n                    break\n                evals += 1\n                \n                grad[i] = (f_plus - f_minus) / (2 * delta)\n                \n\n            # Update velocity and position\n            v = self.momentum_factor * v - step_size * grad\n            x = x + v\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x) if evals + 1 <= self.budget else np.inf\n            if f == np.inf:\n                break\n            evals += 1\n\n            # Update best solution\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            # Decay step size\n            step_size *= 0.999\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MomentumSearch scored 0.315 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.005497901428534124, 0.16337936527999952, 0.2725144736680083, 0.11436498319697253, 0.08446845931678582, 0.17168745868804203, 0.22296974347958487, 0.26862664980062234, 0.19292786759809577, 0.10161116631348543, 0.889251166209266, 0.9783394513254685, 0.22837797459767128, 0.10420068109279546, 0.5486775731762752, 0.3301721639588172, 0.24436888817804814, 0.9160598386174157, 0.10085373145902177, 0.35753748083020687]}, "task_prompt": ""}
{"id": "14f06cb4-9ed6-464e-8ec0-dea256dfab95", "fitness": 0.6468021801400372, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.647 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.21024244638870282, 0.19986315419804856, 0.7119617680058776, 0.8736400828507248, 0.7902366401076156, 0.8374397836775997, 0.7300026075735604, 0.6855536208786943, 0.7793985396695778, 0.7754378041809628, 0.8567044565888007, 0.995900822335429, 0.28204056693063817, 0.3091976364567056, 0.8888748520647773, 0.8446882309259375, 0.5724591874847389, 0.8493781426604864, 0.22759178738224872, 0.5154314724396174]}, "task_prompt": ""}
{"id": "68b37114-7037-45e7-815c-8112a8c878dd", "fitness": 0.3392705510402353, "name": "CauchyAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass CauchyAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_scale=1.0, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_scale = initial_scale\n        self.scale = initial_scale\n        self.initial_temp = initial_temp\n        self.temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Sample new solution from Cauchy distribution\n            z = np.random.standard_cauchy(size=self.dim)\n            new_x = self.x_opt + self.scale * z\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            evals += 1\n\n            # Simulated Annealing acceptance criterion\n            delta_f = new_f - self.f_opt\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / self.temp):\n                self.f_opt = new_f\n                self.x_opt = new_x\n\n            #Cooling\n            self.temp *= self.cooling_rate\n\n            #Adaptive scaling\n            if evals % 1000 == 0: # Adjust every 1000 evaluations.\n                if new_f < self.f_opt:\n                   self.scale *= 1.05\n                else:\n                   self.scale *= 0.95\n                self.scale = np.clip(self.scale, 0.01, 10.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyAnnealing scored 0.339 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1467614414729409, 0.19616651502384197, 0.33542617329840096, 0.3255065286433845, 0.268780605105736, 0.33064992186284803, 0.2707981440112539, 0.27643373492788503, 0.24585583860473104, 0.20480877121789465, 0.31919796181332716, 0.9961618053237975, 0.27619340939160986, 0.26494142664620424, 0.6979243097270407, 0.3219624043486444, 0.28923589474011246, 0.350880915428021, 0.18689939955838586, 0.480825819658645]}, "task_prompt": ""}
{"id": "31f02264-5f0e-49df-b238-ed3951ebdcf3", "fitness": 0.680514634563359, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.archive_factor = 2.0 # Size of the archive relative to pop_size\n        self.archive = []\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + self.f * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                    \n                    self.archive.append(population[i].copy())\n                    if len(self.archive) > self.archive_factor * self.pop_size:\n                        self.archive.pop(0)  # Maintain archive size\n\n                    self.success_cr.append(self.cr)\n                    self.success_f.append(self.f)\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Update CR and F\n            if self.success_cr and self.success_f:\n                self.cr = np.mean(self.success_cr)\n                self.f = np.mean(self.success_f)\n                self.success_cr = []\n                self.success_f = []\n            else:\n                # No successful updates, increase exploration\n                self.cr = min(1.0, self.cr + 0.1)\n                self.f = min(1.0, self.f + 0.1)\n\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.f = np.clip(self.f, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.681 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2635680277900999, 0.5892418198629246, 0.6565497776167736, 0.8852955192513727, 0.709482071071958, 0.8324051709047893, 0.6196922968582365, 0.6892538648933455, 0.7117867994699185, 0.5784772942550773, 0.8393126618811098, 0.9944660023288822, 0.5975019903080107, 0.6707821061664825, 0.9133685110927552, 0.8406957674964461, 0.5408987587019054, 0.8748024002381479, 0.2792057162782773, 0.5235061348006715]}, "task_prompt": ""}
{"id": "496339ff-4697-4f1e-9186-53426376cd56", "fitness": "-inf", "name": "PSOWithMutation", "description": "No description provided.", "code": "import numpy as np\n\nclass PSOWithMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        self.f_opt = fitness[best_idx]\n        self.x_opt = global_best_position.copy()\n\n        while evals < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (self.w * velocities\n                          + self.c1 * r1 * (personal_best_positions - population)\n                          + self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n\n            # Apply boundary constraints\n            population = np.clip(population, lb, ub)\n\n            # Apply mutation\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < self.mutation_rate\n            population[mutation_mask] = np.random.uniform(lb, ub, size=np.sum(mutation_mask))\n\n            # Evaluate new solutions\n            new_fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n\n            # Update personal bests\n            for i in range(self.pop_size):\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i].copy()\n\n            # Update global best\n            best_idx = np.argmin(personal_best_fitness)\n            if personal_best_fitness[best_idx] < self.f_opt:\n                self.f_opt = personal_best_fitness[best_idx]\n                self.x_opt = personal_best_positions[best_idx].copy()\n                global_best_position = personal_best_positions[best_idx].copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 784, in numpy.PyArray_MultiIterNew3, the following error occurred:\nValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "error": "In the code, line 784, in numpy.PyArray_MultiIterNew3, the following error occurred:\nValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (0,) and arg 1 with shape (2,).", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "d923058c-ef4c-4a47-ab5f-c3d7d2b2141f", "fitness": 0.5398114437864463, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, cr_init=0.5, f_init=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.cr_init = cr_init\n        self.f_init = f_init\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cr_memory = np.ones(self.pop_size) * self.cr_init\n        self.f_memory = np.ones(self.pop_size) * self.f_init\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                cr = self.cr_memory[i]\n                f = self.f_memory[i]\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant_vector = population[i] + f * (x2 - x3)\n                mutant_vector = np.clip(mutant_vector, self.lb, self.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial_vector = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == j_rand:\n                        trial_vector[j] = mutant_vector[j]\n\n                # Evaluation\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    # Success!\n                    self.success_cr.append(cr)\n                    self.success_f.append(f)\n\n                    population[i] = trial_vector\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector.copy()\n\n                # Update CR and F\n                if len(self.success_cr) > 0:\n                    cr_mean = np.mean(self.success_cr)\n                    f_mean = np.mean(self.success_f)\n                    self.cr_memory[i] = 0.9 * self.cr_memory[i] + 0.1 * cr_mean # Exponential smoothing\n                    self.f_memory[i] = 0.9 * self.f_memory[i] + 0.1 * f_mean # Exponential smoothing\n                else:\n                    self.cr_memory[i] = np.clip(np.random.normal(self.cr_init, 0.1), 0, 1)\n                    self.f_memory[i] = np.clip(np.random.normal(self.f_init, 0.1), 0, 2)\n\n                if len(self.success_cr) > self.pop_size:\n                    self.success_cr = self.success_cr[-self.pop_size:]\n                    self.success_f = self.success_f[-self.pop_size:]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.540 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18697854008480497, 0.2644167661472475, 0.5104102133612352, 0.8035090219312309, 0.580844892970416, 0.7056709767436454, 0.3570982115679877, 0.4999577112594097, 0.617173496512043, 0.3017129771419882, 0.7453439336425283, 0.9873202528866639, 0.30650319692289585, 0.4105727024610535, 0.8683276400543876, 0.696357561196755, 0.41149029380763325, 0.7995192026379713, 0.2307897115426797, 0.5122315728563496]}, "task_prompt": ""}
{"id": "e3c7d37c-e32a-434e-8dd0-b504f3b15047", "fitness": 0.6330804826502475, "name": "AdaptiveHybridDEPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.6, pso_w=0.5, pso_c=1.0, local_search_init_prob=0.2, exploration_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c = pso_c\n        self.local_search_prob = local_search_init_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_threshold = exploration_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO (simplified - no individual best)\n        velocities = np.zeros((self.pop_size, self.dim))\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n            \n            # Adaptive parameter adjustment based on progress\n            if iteration % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std < self.exploration_threshold:\n                    self.local_search_prob *= 1.1  # Increase local search\n                    self.de_f *= 0.9 # Decrease differential weight\n                else:\n                    self.local_search_prob *= 0.9   # Decrease local search\n                    self.de_f *= 1.1 # Increase differential weight\n                self.local_search_prob = np.clip(self.local_search_prob, 0.05, 0.5)\n                self.de_f = np.clip(self.de_f, 0.4, 1.0)\n\n            for i in range(self.pop_size):\n                # Differential Evolution\n                if np.random.rand() < 0.5:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    \n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n                    \n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else: # Simplified Particle Swarm Optimization (no personal best)\n                    r = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c * r * (global_best_position - population[i]))\n                    trial_vector = population[i] + velocities[i]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                # Local search\n                if np.random.rand() < self.local_search_prob:\n                    step_size = 0.01 * (self.ub - self.lb)\n                    random_direction = np.random.uniform(-1, 1, size=self.dim)\n                    trial_vector = trial_vector + step_size * random_direction\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHybridDEPSO scored 0.633 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2562286340851163, 0.22626232147199754, 0.8623923828233521, 0.9584368082681431, 0.45029121755687884, 0.9216820686795982, 0.3369399744404966, 0.6861094845172732, 0.911390377914504, 0.20701133178923936, 0.9413607476432735, 0.9993214652401183, 0.3054184982951902, 0.683725468295177, 0.9440861929305389, 0.9172899504817571, 0.38582764715865636, 0.9425492544334821, 0.22097257441431872, 0.5043132525658394]}, "task_prompt": ""}
{"id": "0adbc501-0dd2-4498-9968-3014feee8d4b", "fitness": 0.40281573216945626, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95, min_temp=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.min_temp = min_temp\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.initial_temp\n        step_size = (ub - lb) / 10.0 \n\n        while self.budget > 0:\n            x_new = x + np.random.uniform(-step_size, step_size, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            delta_f = f_new - f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            temp *= self.cooling_rate\n            step_size *= self.cooling_rate**(1/self.dim) #Adapt step size\n\n            if temp < self.min_temp:\n                # Restart if temperature is too low\n                x = np.random.uniform(lb, ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                temp = self.initial_temp\n                step_size = (ub-lb) / 10.0\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.403 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12055072010675616, 0.2653968072046723, 0.42645192393264075, 0.5213409303483418, 0.3573687287921655, 0.4482622125644491, 0.2887908118563681, 0.3584673045295975, 0.34256625473445634, 0.174251030471137, 0.5073013616378721, 0.9788882935387058, 0.2833262880090519, 0.2987070025879066, 0.7445661195496095, 0.37979440031581446, 0.31980253701166617, 0.5556157533545034, 0.20402834945118964, 0.48083781339222076]}, "task_prompt": ""}
{"id": "197ef2b3-c413-4928-bddd-7f62d00aacd3", "fitness": 0.13579558948187812, "name": "AdaptiveGradientDescent", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveGradientDescent:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, momentum=0.9, finite_diff_delta=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.momentum = momentum\n        self.finite_diff_delta = finite_diff_delta\n        self.lb = -5.0\n        self.ub = 5.0\n        self.velocity = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize within bounds\n        self.f_opt = func(self.x_opt)\n        self.budget -= 1\n        \n        success_count = 0\n        iteration = 0\n\n        while self.budget > 0:\n            iteration += 1\n            \n            # Estimate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus_delta = self.x_opt.copy()\n                x_plus_delta[i] += self.finite_diff_delta\n                x_plus_delta = np.clip(x_plus_delta, self.lb, self.ub)\n                \n                f_plus_delta = func(x_plus_delta)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                x_minus_delta = self.x_opt.copy()\n                x_minus_delta[i] -= self.finite_diff_delta\n                x_minus_delta = np.clip(x_minus_delta, self.lb, self.ub)\n                \n                f_minus_delta = func(x_minus_delta)\n                self.budget -= 1\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n                gradient[i] = (f_plus_delta - f_minus_delta) / (2 * self.finite_diff_delta)\n            \n            # Update velocity with momentum\n            self.velocity = self.momentum * self.velocity - self.step_size * gradient\n            \n            # Update position\n            x_new = self.x_opt + self.velocity\n            x_new = np.clip(x_new, self.lb, self.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new.copy()\n                success_count += 1\n                # Increase step size if successful\n                if success_count > 5:\n                    self.step_size *= 1.1\n                    success_count = 0 # Reset the success count\n            else:\n                # Decrease step size if unsuccessful\n                self.step_size *= 0.5\n                success_count = 0 # Reset success count\n            \n            #Limit step size to avoid divergence\n            self.step_size = min(self.step_size, 1.0)\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGradientDescent scored 0.136 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.03462441739345612, 0.06316326010289508, 0.1319140131469465, 0.1789880471673998, 0.1618723799918862, 0.14110933249529756, 0.21133674287192838, 0.13987732690065313, 0.13936833093127066, 0.11883169866157461, 0.10389836714210632, 0.15461439307263247, 9.999999999998899e-05, 0.08832440544987452, 0.2286985205890958, 0.2228409174346525, 0.14618953401130452, 0.25653114371437236, 0.08722762682857488, 0.10640133173164068]}, "task_prompt": ""}
{"id": "e4ad0c3f-21f2-450b-9028-75cd5a1e5e76", "fitness": "-inf", "name": "HybridPSO_NM", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, c1=1.4, c2=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize PSO\n        particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/2, abs(ub-lb)/2, size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - particles) +\n                          self.c2 * r2 * (global_best_position - particles))\n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n\n            # Update personal best\n            for i in range(self.pop_size):\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness[i]\n                    personal_best_positions[i] = particles[i].copy()\n\n            # Update global best\n            global_best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[global_best_index] < self.f_opt:\n                self.f_opt = personal_best_fitness[global_best_index]\n                global_best_position = personal_best_positions[global_best_index].copy()\n                self.x_opt = global_best_position.copy()\n\n            if self.budget <= 0:\n                break\n\n        # Local search using Nelder-Mead around the global best found by PSO\n        nm_budget = min(500, self.budget) # limit local search budget\n        result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': nm_budget})\n        \n        if result.fun < self.f_opt:\n            self.f_opt = result.fun\n            self.x_opt = result.x\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 64, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': nm_budget})", "error": "In the code, line 64, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: result = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds, options={'maxfev': nm_budget})", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "1b2bc49d-0b37-4453-bee2-2843f7ba0a45", "fitness": 0.30602853266348906, "name": "PerturbationOptimization", "description": "No description provided.", "code": "import numpy as np\n\nclass PerturbationOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, perturbation_strength=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.perturbation_strength = perturbation_strength\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Perturbation\n                \n                # Weight other solutions based on fitness. Better solutions have more influence.\n                weights = np.exp(-(fitness - fitness[i]) / (np.std(fitness) + 1e-8))  # Softmax-like weighting\n                weights[i] = 0  # Don't consider the current solution itself.\n                weights = weights / np.sum(weights)\n\n                weighted_center = np.sum(population * weights[:, None], axis=0)\n\n                # Perturb based on distance from weighted center and random component\n                perturbation = self.perturbation_strength * (weighted_center - population[i]) + \\\n                              self.perturbation_strength * np.random.uniform(-1, 1, self.dim)\n\n                trial = population[i] + perturbation\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate\n                f_trial = func(trial)\n                evals += 1\n\n                # Update if better\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Decay perturbation strength\n            self.perturbation_strength = self.perturbation_strength * (1 - evals / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PerturbationOptimization scored 0.306 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.10354989051706176, 0.177711652743058, 0.4099855095244048, 0.19595603556441787, 0.23054606192317373, 0.18850074755769386, 0.2707022618599122, 0.30814318251341566, 0.2732393053203527, 0.2427938355688748, 0.2569962952738334, 0.9997396709047521, 0.23669720540915284, 0.22176864926808182, 0.17661548927498572, 0.27668447918882144, 0.2757808945836634, 0.6052739022195142, 0.19314408233415903, 0.4767415017204517]}, "task_prompt": ""}
{"id": "a493bbc8-c861-4b00-a349-68a44da05129", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.exploration_weight = exploration_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random samples\n        X = np.random.uniform(lb, ub, size=(self.n_initial, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial\n\n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        # Gaussian process model\n        kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3))\n        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n\n        while evals < self.budget:\n            # Fit the GP model\n            gp.fit(X, y)\n\n            # Acquisition function (Upper Confidence Bound)\n            def acquisition(x):\n                mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n                return mu - self.exploration_weight * sigma\n\n            # Optimize acquisition function (using a simple random search)\n            n_candidates = 100\n            X_candidates = np.random.uniform(lb, ub, size=(n_candidates, self.dim))\n            acq_values = np.array([acquisition(x) for x in X_candidates])\n            best_candidate_idx = np.argmin(acq_values)\n            x_new = X_candidates[best_candidate_idx]\n\n            # Evaluate the new point\n            f_new = func(x_new)\n            evals += 1\n\n            # Update the data\n            X = np.vstack((X, x_new))\n            y = np.append(y, f_new)\n\n            # Update best solution\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3))", "error": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "869af5d9-524f-4fed-8411-fb4dc313afae", "fitness": 0.2656997039044043, "name": "SelfOrganizingSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfOrganizingSearch:\n    def __init__(self, budget=10000, dim=10, num_points=20, initial_radius=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.num_points = num_points\n        self.radius = initial_radius\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize search points randomly\n        points = np.random.uniform(self.lb, self.ub, size=(self.num_points, self.dim))\n        fitness = np.array([func(x) for x in points])\n        self.budget -= self.num_points\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = points[best_index].copy()\n\n        while self.budget > 0:\n            # Sort points by fitness\n            sorted_indices = np.argsort(fitness)\n            points = points[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Concentrate search around best points\n            new_points = []\n            for i in range(self.num_points):\n                # Sample from a normal distribution centered around top solutions\n                center_index = min(i, self.num_points // 4) # Focus on top quarter\n                center = points[center_index]\n                \n                new_point = np.random.normal(center, self.radius, size=self.dim)\n                new_point = np.clip(new_point, self.lb, self.ub)\n                new_points.append(new_point)\n\n            new_points = np.array(new_points)\n            new_fitness = np.array([func(x) for x in new_points])\n            self.budget -= self.num_points\n\n            # Update best solution\n            for i in range(self.num_points):\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_points[i].copy()\n\n            # Combine old and new points\n            all_points = np.concatenate([points, new_points])\n            all_fitness = np.concatenate([fitness, new_fitness])\n            \n            # Select the best points for the next iteration\n            sorted_indices = np.argsort(all_fitness)[:self.num_points]\n            points = all_points[sorted_indices]\n            fitness = all_fitness[sorted_indices]\n\n            # Adjust search radius based on fitness distribution\n            std_dev = np.std(fitness)\n            self.radius = max(0.01, self.radius * (1 - std_dev / abs(self.f_opt + 1e-8)))  # Ensure division by zero is avoided\n            self.radius = min(self.radius, (self.ub - self.lb) / 2.0)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfOrganizingSearch scored 0.266 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17545358424958535, 0.15605246678753915, 0.5349482630008677, 0.1754864977152043, 0.15432413230270192, 0.1791758701360624, 0.21650165112884556, 0.16513026422629917, 0.23412358399497546, 0.1768055013951607, 0.2576661374814587, 0.24105349830173095, 0.2595382899685337, 0.19520044330233355, 0.5531321840433394, 0.2988242683120965, 0.246184065160858, 0.47877094605758386, 0.17828202647642954, 0.437340404046479]}, "task_prompt": ""}
{"id": "6029e9f9-1939-42f9-91d1-c59f48691da4", "fitness": 0.25906607441253215, "name": "AdaptiveStepSizeSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveStepSizeSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.6):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Generate a new solution by perturbing the current best\n            noise = np.random.normal(0, self.step_size, size=self.dim)\n            x_new = x + noise\n            x_new = np.clip(x_new, lb, ub)\n\n            f_new = func(x_new)\n            evals += 1\n\n            # Accept the new solution if it's better\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_count += 1\n\n            self.iteration_count += 1\n\n            # Adjust step size based on success rate\n            if self.iteration_count > 100:\n                success_rate = self.success_count / self.iteration_count\n                if success_rate > self.success_rate_threshold:\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n\n                self.step_size = np.clip(self.step_size, 1e-6, (ub-lb)/2) # Ensure step size does not become too small or too large\n                self.success_count = 0\n                self.iteration_count = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveStepSizeSearch scored 0.259 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.008763711144523567, 0.17226791689264942, 0.6812051581456751, 0.13174318602150248, 0.11833841563089009, 0.10843886840072281, 0.16280363681179866, 0.05660358303856461, 0.12887997315048216, 0.11207632522348254, 0.9136102186657822, 0.20907752665144574, 0.3235829566813999, 0.16802457873646814, 0.934939664109391, 0.3000230593087495, 0.16132532244148678, 0.24721473910568226, 0.09245966260037874, 0.14994298548956775]}, "task_prompt": ""}
{"id": "db21c4fb-6e2b-49d0-ad8a-56575da95730", "fitness": 0.1575275486583397, "name": "GradientGuidedSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass GradientGuidedSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        x = np.random.uniform(lb, ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        evals = 1\n\n        while evals < self.budget:\n            # Estimate gradient (simplified - random direction)\n            direction = np.random.normal(0, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)\n\n            # Take a step\n            x_new = x + self.step_size * direction\n            x_new = np.clip(x_new, lb, ub)\n            f_new = func(x_new)\n            evals += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                self.success_rate = 0.9 * self.success_rate + 0.1\n            else:\n                self.success_rate = 0.9 * self.success_rate\n\n            # Adjust step size\n            if self.success_rate > 0.5:\n                self.step_size *= 1.1\n            else:\n                self.step_size *= 0.9\n\n            self.step_size = np.clip(self.step_size, 1e-6, 1.0)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GradientGuidedSearch scored 0.158 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0924557337535934, 0.05548046101717641, 0.18624882750290672, 0.08491047381580374, 0.039416593232714736, 0.09185605972361588, 0.16293225998334926, 0.16960380239997686, 0.11896750056499872, 0.08466260438073991, 0.11829083898424719, 0.20733281358534628, 0.1908252385247886, 0.03241904505503024, 0.4201494133971877, 0.20161070334538822, 0.08618351356756959, 0.30633298809286635, 0.10095833643624885, 0.39991376580324556]}, "task_prompt": ""}
{"id": "590c6ab0-3462-4065-952f-b757d771cbc3", "fitness": "-inf", "name": "AdaptiveCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, lb=-5.0, ub=5.0, initial_sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.lb = lb\n        self.ub = ub\n        self.sigma = initial_sigma\n        self.mean = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.mu = self.pop_size // 2\n        self.weights = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize()\n\n    def initialize(self):\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.mean[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, self.lb, self.ub)\n            \n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[:, np.argmin(fitness)].copy()\n            \n            # Sort by fitness\n            indices = np.argsort(fitness)\n            x_sorted = x[:, indices]\n\n            # Update mean\n            mean_old = self.mean.copy()\n            self.mean = np.sum(x_sorted[:, :self.mu] * self.weights[np.newaxis, :], axis=1)\n\n            # Update evolution paths\n            B = np.linalg.cholesky(self.C)\n            z_mean = np.sum(z[:, indices[:self.mu]] * self.weights[np.newaxis, :], axis=1)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.dot(B, z_mean))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.mean - mean_old) / self.sigma\n            \n            # Update covariance matrix\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.budget / self.pop_size))) / self.chiN < 1.4 + 2/(self.dim + 1))\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.c_mu * np.sum(self.weights[np.newaxis, :] * (z[:, indices[:self.mu]] @ z[:, indices[:self.mu]].T), axis=1)\n            \n            # Adapt step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T # enforce symmetry\n            self.C = np.linalg.solve(np.tril(self.C), np.triu(self.C)) # enforce positive definiteness (not always correct)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 71, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (1,3) (2,2) \nOn line: self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.c_mu * np.sum(self.weights[np.newaxis, :] * (z[:, indices[:self.mu]] @ z[:, indices[:self.mu]].T), axis=1)", "error": "In the code, line 71, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (1,3) (2,2) \nOn line: self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, np.newaxis] @ self.pc[np.newaxis, :]) + self.c_mu * np.sum(self.weights[np.newaxis, :] * (z[:, indices[:self.mu]] @ z[:, indices[:self.mu]].T), axis=1)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "01bc85c3-0779-4994-b2bf-1ea545fc5eee", "fitness": 0.2428559870364652, "name": "AdaptiveDE_CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.7, de_f=0.6, cma_sigma=0.1, exploration_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.cma_sigma = cma_sigma\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_threshold = exploration_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        covariance = np.eye(self.dim)\n        \n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive parameter adjustment based on progress\n            if iteration % 10 == 0:\n                fitness_std = np.std(fitness)\n                if fitness_std < self.exploration_threshold:\n                    self.cma_sigma *= 0.9  # Reduce CMA-ES step size\n                    self.de_f *= 1.1  # Increase DE exploration\n                else:\n                    self.cma_sigma *= 1.1  # Increase CMA-ES step size\n                    self.de_f *= 0.9  # Reduce DE exploration\n                self.cma_sigma = np.clip(self.cma_sigma, 0.01, 1.0)\n                self.de_f = np.clip(self.de_f, 0.4, 1.0)\n\n            new_population = []\n            new_fitness = []\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n\n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                else:\n                    # CMA-ES Sample\n                    trial_vector = np.random.multivariate_normal(mean, self.cma_sigma * covariance)\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n                new_population.append(trial_vector)\n                new_fitness.append(f)\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = trial_vector.copy()\n\n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n            \n            # Update population\n            population = new_population\n            fitness = new_fitness\n\n            # Update CMA-ES mean\n            mean = np.mean(population, axis=0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE_CMAES scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07994012037836162, 0.1589026840130633, 0.299855278803947, 0.23132550412518305, 0.17145933386425882, 0.16062129519539337, 0.2083772494638051, 0.22484666091674255, 0.16996033187611825, 0.15947036873448306, 0.1598474156352837, 0.9994770467780839, 0.26576947044927723, 0.16131251447300587, 0.1697659718538702, 0.2505118107657962, 0.21292006657657647, 0.1696729443413808, 0.15759230260095447, 0.4454913698837192]}, "task_prompt": ""}
{"id": "b8e30704-d2cb-433e-8953-29a4d57c09af", "fitness": 0.5384783088167377, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover rate\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Differential Evolution\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                \n                # Mutation\n                v_trial = population[i] + self.F * (x_r1 - x_r2)\n                v_trial = np.clip(v_trial, lb, ub)\n                \n                # Crossover\n                u_trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u_trial[j] = v_trial[j]\n\n                f_trial = func(u_trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = u_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = u_trial\n                \n                # Local Search\n                elif np.random.rand() < self.local_search_prob:\n                    # Perform a small local search around the current solution\n                    local_x = np.random.normal(population[i], scale=0.05 * (ub - lb), size=self.dim)\n                    local_x = np.clip(local_x, lb, ub)\n                    local_f = func(local_x)\n                    evals += 1\n                    if local_f < fitness[i]:\n                        population[i] = local_x\n                        fitness[i] = local_f\n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_x\n                            \n                if evals >= self.budget:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.538 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16735108933753962, 0.3542710923989001, 0.5492238867238739, 0.7681428472026657, 0.5271037543226573, 0.7100239902307245, 0.3500572595183621, 0.5085635266055032, 0.5387644312508042, 0.2116412980533955, 0.8218192034080581, 0.9940654953802475, 0.4310277247517923, 0.40867926208546124, 0.8872967416781362, 0.6634949770143087, 0.4194708536502406, 0.7533738533933131, 0.19498829767625792, 0.5102065916525119]}, "task_prompt": ""}
{"id": "1cbd011a-dbea-43ec-8236-6030c427b290", "fitness": 0.6835146833945602, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, stagnation_limit=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n            \n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n              population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n              fitness = np.array([func(x) for x in population])\n              evals += self.pop_size\n              \n              best_idx = np.argmin(fitness)\n              self.f_opt = fitness[best_idx]\n              self.x_opt = population[best_idx]\n              self.stagnation_counter = 0 # Reset stagnation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.684 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19409795256107076, 0.28983754770201375, 0.7657677421482163, 0.9049721832064603, 0.8001615481000994, 0.8482747025134711, 0.7267188774923423, 0.7557274984140103, 0.8115423246020679, 0.7500706182427523, 0.8532304557311736, 0.9947624576583256, 0.32518951061246604, 0.8052515846622639, 0.9333864125797177, 0.8607582014810706, 0]}, "task_prompt": ""}
{"id": "002bc859-a2eb-46bc-9224-3936669bb3f7", "fitness": 0.3316269290012969, "name": "RankBasedGaussianMutation", "description": "No description provided.", "code": "import numpy as np\n\nclass RankBasedGaussianMutation:\n    def __init__(self, budget=10000, dim=10, pop_size=20, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Rank-based selection\n            ranked_indices = np.argsort(fitness)\n            selected_indices = ranked_indices[:self.pop_size // 2]  # Select top half\n\n            for i in range(self.pop_size):\n                # Mutation\n                if i in selected_indices or np.random.rand() < self.mutation_rate:\n                    mutant = population[i] + np.random.normal(0, 0.1, size=self.dim) * (ub - lb)\n                    mutant = np.clip(mutant, lb, ub)\n                else:\n                    mutant = np.copy(population[i])\n\n                # Evaluation\n                f_mutant = func(mutant)\n                evals += 1\n\n                # Selection: replace if better\n                if f_mutant < fitness[i]:\n                    population[i] = mutant\n                    fitness[i] = f_mutant\n\n                    if f_mutant < self.f_opt:\n                        self.f_opt = f_mutant\n                        self.x_opt = mutant\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm RankBasedGaussianMutation scored 0.332 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1418041134656498, 0.2284469035661577, 0.32754767877924473, 0.2760172167936181, 0.25481843814969485, 0.31397829033977764, 0.2615987390695974, 0.27713007040771176, 0.23595396135038704, 0.16307834273547173, 0.31061114459589656, 0.9987798682660516, 0.3332906879517462, 0.25344537826385827, 0.6583076301004155, 0.3179819893953316, 0.2831007828569746, 0.3448502764869188, 0.17360356251498432, 0.47819350493644885]}, "task_prompt": ""}
{"id": "f54083e4-613e-4b99-8ed2-1c5d31cd9bec", "fitness": "-inf", "name": "HybridDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_frequency=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.local_search_frequency = local_search_frequency\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Local Search using Nelder-Mead on best solution\n            if evals % self.local_search_frequency == 0:\n                res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds)\n                if res.fun < self.f_opt:\n                    self.f_opt = res.fun\n                    self.x_opt = res.x\n                    \n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 57, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds)", "error": "In the code, line 57, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: res = minimize(func, self.x_opt, method='Nelder-Mead', bounds=func.bounds)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "3ea6bba7-3c23-40cb-89e1-355413f44e24", "fitness": 0.33963664080921946, "name": "CauchyDE", "description": "No description provided.", "code": "import numpy as np\n\nclass CauchyDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, cauchy_scale=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                mutant = population[i] + self.cauchy_scale * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyDE scored 0.340 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15801244074720777, 0.23267257996537594, 0.32865101745387293, 0.334230111462239, 0.26210223795407317, 0.31238736154001656, 0.2730003166974738, 0.27069525210167444, 0.25159967351329926, 0.19789737555360065, 0.2861331100459559, 0.9944803799180351, 0.28015441504982974, 0.2828495713920024, 0.6856577897080824, 0.34234422262475817, 0.2775257423038884, 0.3575458095484122, 0.18604486783794427, 0.47874854076664686]}, "task_prompt": ""}
{"id": "427d677c-7809-4cf8-b249-be4d7faa8c3f", "fitness": 0.5830293835315078, "name": "EnhancedAdaptiveHybrid", "description": "No description provided.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybrid:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_cr=0.8, de_f=0.7, pso_w=0.6, pso_c=1.2, ls_init_prob=0.1, diversity_threshold=0.05, cma_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_cr = de_cr\n        self.de_f = de_f\n        self.pso_w = pso_w\n        self.pso_c = pso_c\n        self.ls_prob = ls_init_prob\n        self.lb = -5.0\n        self.ub = 5.0\n        self.diversity_threshold = diversity_threshold\n        self.cma_sigma = cma_sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize velocities for PSO\n        velocities = np.zeros((self.pop_size, self.dim))\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n\n        # Initialize CMA-ES-like covariance matrix (diagonal for simplicity)\n        covariance = np.eye(self.dim) * self.cma_sigma**2\n\n        iteration = 0\n        while self.budget > 0:\n            iteration += 1\n\n            # Adaptive parameter adjustment based on population diversity\n            diversity = np.std(population)\n            if diversity < self.diversity_threshold:\n                de_weight = 0.2  # Favor PSO (exploitation)\n                self.ls_prob = min(self.ls_prob * 1.2, 0.7)  # Increase local search\n            else:\n                de_weight = 0.8  # Favor DE (exploration)\n                self.ls_prob = max(self.ls_prob * 0.8, 0.05)  # Decrease local search\n\n            for i in range(self.pop_size):\n                # Adaptive DE/PSO selection\n                if np.random.rand() < de_weight:\n                    # Differential Evolution\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n\n                    trial_vector = population[i] + self.de_f * (x2 - x3)\n\n                    # Crossover\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() > self.de_cr and j != j_rand:\n                            trial_vector[j] = population[i, j]\n                else:\n                    # Particle Swarm Optimization\n                    r1 = np.random.rand(self.dim)\n                    r2 = np.random.rand(self.dim)\n                    velocities[i] = (self.pso_w * velocities[i] +\n                                    self.pso_c * r1 * (global_best_position - population[i]) +\n                                    self.pso_c * r2 * (population[np.random.randint(self.pop_size)] - population[i]))  # Adding social component\n                    trial_vector = population[i] + velocities[i]\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                # CMA-ES inspired local search\n                if np.random.rand() < self.ls_prob:\n                    z = np.random.normal(0, 1, self.dim)\n                    step = np.sqrt(np.diag(covariance)) * z # Scale each dimension by stdev\n                    trial_vector = population[i] + step\n                    trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                    # Simplified covariance adaptation (you could use a more sophisticated update rule)\n                    covariance = covariance * 0.99 + np.outer(step, step) * 0.01\n\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        global_best_position = trial_vector.copy()\n\n\n            global_best_index = np.argmin(fitness)\n            global_best_position = population[global_best_index].copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedAdaptiveHybrid scored 0.583 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17418874407708285, 0.4620225514254155, 0.5088719031241582, 0.8742396182440358, 0.617659213465287, 0.7168630950746004, 0.3797462182901292, 0.5270750720749984, 0.59950095322392, 0.42925728653854733, 0.810789632423292, 0.9968742906794388, 0.43429623483366264, 0.5579937347014274, 0.9050829387037013, 0.6861613570276184, 0.4336144036707974, 0.8323454995406299, 0.2042973122857873, 0.5097076112256274]}, "task_prompt": ""}
{"id": "86a42f76-3a57-49ee-9367-61690eb60cca", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.3, cs=0.8, damps=None, c_cov=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.cs\n        self.c_cov = c_cov if c_cov is not None else 2 / (self.pop_size + (self.dim + 1)**2)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        evals = 0\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize mean and covariance matrix\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        C = np.eye(self.dim)\n        P_c = np.zeros(self.dim)\n        P_sigma = np.zeros(self.dim)\n\n        while evals < self.budget:\n            # Sample population\n            Z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            population = np.array([mean + self.sigma * z for z in Z])\n            population = np.clip(population, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n\n            # Sort population and fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            population = population[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Update mean\n            mean_old = mean\n            mean = np.mean(population[:self.pop_size // 2], axis=0) # Use only the best individuals\n            \n            # Update evolution path\n            diff = (mean - mean_old) / self.sigma\n            P_sigma = (1 - self.cs) * P_sigma + np.sqrt(self.cs * (2 - self.cs)) * diff\n\n            # Adapt step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(P_sigma) - np.sqrt(self.dim)))\n\n            # Update covariance matrix\n            C = (1-self.c_cov) * C + self.c_cov * np.outer(P_sigma, P_sigma)\n\n            # Ensure positive definiteness\n            try:\n                L = np.linalg.cholesky(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim) # Reset covariance matrix\n                P_sigma = np.zeros(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 154, in _raise_linalgerror_svd_nonconvergence, the following error occurred:\nLinAlgError: SVD did not converge", "error": "In the code, line 154, in _raise_linalgerror_svd_nonconvergence, the following error occurred:\nLinAlgError: SVD did not converge", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "bc12bcfe-abd6-4654-a85f-712a3474b059", "fitness": 0.0, "name": "SimplexSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass SimplexSearch:\n    def __init__(self, budget=10000, dim=10, initial_step=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step = initial_step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize simplex\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n        self.x_opt = x0\n        self.f_opt = func(x0)\n        self.budget -= 1\n\n        simplex = [x0]\n        for i in range(self.dim):\n            x = np.copy(x0)\n            x[i] += self.initial_step\n            x = np.clip(x, lb, ub)\n            simplex.append(x)\n\n        while self.budget > 0:\n            fitness = np.array([func(x) if i>0 or self.budget < 9999 else self.f_opt for i, x in enumerate(simplex)])\n            self.budget -= self.dim\n            if self.budget <= 0:\n                break\n\n            best_idx = np.argmin(fitness)\n            worst_idx = np.argmax(fitness)\n            \n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = simplex[best_idx]\n            \n            # Centroid of all points except the worst\n            centroid = np.mean([simplex[i] for i in range(len(simplex)) if i != worst_idx], axis=0)\n\n            # Reflection\n            reflection = centroid + (centroid - simplex[worst_idx])\n            reflection = np.clip(reflection, lb, ub)\n\n            f_reflection = func(reflection)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n\n            if f_reflection < fitness[worst_idx]:\n                simplex[worst_idx] = reflection\n                fitness[worst_idx] = f_reflection\n                if f_reflection < self.f_opt:\n                    self.f_opt = f_reflection\n                    self.x_opt = reflection\n\n                # Expansion\n                expansion = centroid + 2 * (centroid - simplex[worst_idx])\n                expansion = np.clip(expansion, lb, ub)\n\n                f_expansion = func(expansion)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n                \n                if f_expansion < f_reflection:\n                    simplex[worst_idx] = expansion\n                    fitness[worst_idx] = f_expansion\n                    if f_expansion < self.f_opt:\n                        self.f_opt = f_expansion\n                        self.x_opt = expansion\n            else:\n                # Contraction\n                contraction = centroid + 0.5 * (simplex[worst_idx] - centroid)\n                contraction = np.clip(contraction, lb, ub)\n                \n                f_contraction = func(contraction)\n                self.budget -= 1\n\n                if self.budget <= 0:\n                    break\n\n                if f_contraction < fitness[worst_idx]:\n                    simplex[worst_idx] = contraction\n                    fitness[worst_idx] = f_contraction\n                    if f_contraction < self.f_opt:\n                        self.f_opt = f_contraction\n                        self.x_opt = contraction\n                else:\n                    # Shrink\n                    for i in range(len(simplex)):\n                        if i != best_idx:\n                            simplex[i] = simplex[best_idx] + 0.5 * (simplex[i] - simplex[best_idx])\n                            simplex[i] = np.clip(simplex[i], lb, ub)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimplexSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "b65f74b3-364c-404e-8948-31e37d4acd16", "fitness": "-inf", "name": "SobolNelderMead", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SobolNelderMead:\n    def __init__(self, budget=10000, dim=10, simplex_size=None, sobol_init_size=100, nm_max_iter=50):\n        self.budget = budget\n        self.dim = dim\n        self.simplex_size = dim + 1 if simplex_size is None else simplex_size\n        self.sobol_init_size = sobol_init_size\n        self.nm_max_iter = nm_max_iter\n        try:\n            from sobol_seq import i4_sobol_generate\n            self.sobol_generator = i4_sobol_generate\n        except ImportError:\n            print(\"sobol_seq package not found. Install it using: pip install sobol_seq\")\n            self.sobol_generator = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        evals = 0\n\n        if self.sobol_generator is None:\n            raise ImportError(\"Sobol sequence generator is not available. Please install 'sobol_seq' package.\")\n\n        # Sobol initialization\n        sobol_points = self.sobol_generator(self.dim, self.sobol_init_size)\n        initial_population = lb + (ub - lb) * sobol_points.T\n        initial_fitness = np.array([func(x) for x in initial_population])\n        evals += self.sobol_init_size\n\n        best_idx = np.argmin(initial_fitness)\n        self.f_opt = initial_fitness[best_idx]\n        self.x_opt = initial_population[best_idx]\n\n        while evals < self.budget:\n            # Initialize simplex with best Sobol point and some random variations\n            initial_simplex = np.zeros((self.simplex_size, self.dim))\n            initial_simplex[0] = self.x_opt\n            for i in range(1, self.simplex_size):\n                initial_simplex[i] = self.x_opt + np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), size=self.dim)\n                initial_simplex[i] = np.clip(initial_simplex[i], lb, ub)\n\n            # Nelder-Mead optimization\n            result = minimize(func, self.x_opt, method='Nelder-Mead',\n                               options={'initial_simplex': initial_simplex, 'maxiter': self.nm_max_iter, 'maxfev': self.budget - evals, 'xatol': 1e-6, 'fatol': 1e-6})\n            evals += result.nfev\n            \n            if result.fun < self.f_opt:\n                self.f_opt = result.fun\n                self.x_opt = result.x\n                \n            # Generate a new sobol point for the next iteration, if possible given the budget\n            if evals < self.budget:\n                new_sobol_point = self.sobol_generator(self.dim, 1).T[0]\n                new_x = lb + (ub - lb) * new_sobol_point\n                f_new = func(new_x)\n                evals += 1\n\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = new_x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 26, in __call__, the following error occurred:\nImportError: Sobol sequence generator is not available. Please install 'sobol_seq' package.\nOn line: raise ImportError(\"Sobol sequence generator is not available. Please install 'sobol_seq' package.\")", "error": "In the code, line 26, in __call__, the following error occurred:\nImportError: Sobol sequence generator is not available. Please install 'sobol_seq' package.\nOn line: raise ImportError(\"Sobol sequence generator is not available. Please install 'sobol_seq' package.\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "8f4de7aa-e667-457d-a3b4-325419ff66aa", "fitness": 0.19713414388151002, "name": "ConstrictionPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, omega=0.729, phi_p=1.49445, phi_g=1.49445, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.omega = omega  # Inertia weight\n        self.phi_p = phi_p  # Cognitive coefficient\n        self.phi_g = phi_g  # Social coefficient\n        self.k = 2 / abs(2 - (phi_p + phi_g) - np.sqrt((phi_p + phi_g)**2 - 4 * (phi_p + phi_g))) # Constriction factor\n        self.v_max_ratio = v_max_ratio\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        pbest_positions = population.copy()\n        pbest_fitness = np.array([func(x) for x in population])\n\n        # Find initial global best\n        best_idx = np.argmin(pbest_fitness)\n        self.f_opt = pbest_fitness[best_idx]\n        self.x_opt = pbest_positions[best_idx]\n        \n        evals = self.pop_size\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r_p = np.random.rand(self.dim)\n                r_g = np.random.rand(self.dim)\n                \n                cognitive_component = self.phi_p * r_p * (pbest_positions[i] - population[i])\n                social_component = self.phi_g * r_g * (self.x_opt - population[i])\n\n                velocities[i] = self.k * (self.omega * velocities[i] + cognitive_component + social_component)\n                \n                # Velocity clamping\n                v_max = abs(ub-lb) * self.v_max_ratio\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                fitness = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if fitness < pbest_fitness[i]:\n                    pbest_fitness[i] = fitness\n                    pbest_positions[i] = population[i].copy()\n                    \n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i]\n                \n                if evals >= self.budget:\n                    break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ConstrictionPSO scored 0.197 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.04325118185025645, 0.10226994633647557, 0.22829207899593307, 0.13078899755118922, 0.1371765397517376, 0.1644131839744869, 0.1930806467958056, 0.16476697579138377, 0.1799670238813369, 0.13453820999983623, 0.1520494989142499, 0.9999103141603619, 0.14358713453070104, 0.1558732189553802, 0.1338517888385311, 0.19752325789562275, 0.17185010565929992, 0.22841542315099994, 0.10388521999263545, 0.1771921306039761]}, "task_prompt": ""}
{"id": "aee433eb-ac8c-4326-9a2d-47b72ba71568", "fitness": 0.2880368091175886, "name": "ProbabilisticLearning", "description": "No description provided.", "code": "import numpy as np\n\nclass ProbabilisticLearning:\n    def __init__(self, budget=10000, dim=10, pop_size=20, learning_rate=0.1, exploration_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.learning_rate = learning_rate\n        self.exploration_prob = exploration_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Exploration: Randomly sample a new solution\n                    trial = np.random.uniform(lb, ub)\n                else:\n                    # Exploitation: Learn from the best individual\n                    direction = self.x_opt - population[i]\n                    trial = population[i] + self.learning_rate * direction\n                    trial = np.clip(trial, lb, ub)\n                \n                f_trial = func(trial)\n                evals += 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ProbabilisticLearning scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09942454009191859, 0.19750869200901844, 0.33966453073988867, 0.23263777766979887, 0.18262560580701848, 0.24283177386161847, 0.2229425362328986, 0.22526996634729834, 0.22298518656660815, 0.16410767998280829, 0.2559690679913117, 0.9810752171607903, 0.23410309430617382, 0.2047247393919872, 0.5451360329131076, 0.29175633322393213, 0.24865191312559942, 0.23001515587108057, 0.17172695368340318, 0.4675793853755108]}, "task_prompt": ""}
{"id": "c3cd90cd-096a-4851-ba67-a1f109b419a2", "fitness": "-inf", "name": "GaussianProcessUCB", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\n\nclass GaussianProcessUCB:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, exploration_weight=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.lb = -5.0\n        self.ub = 5.0\n        self.exploration_weight = exploration_weight\n        if kernel is None:\n            self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = []\n        self.y = []\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition(self, x, gp, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu[0] + self.exploration_weight * sigma[0]\n\n    def __call__(self, func):\n        # Initial random sampling\n        X_init = np.random.uniform(self.lb, self.ub, size=(self.n_initial, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        self.budget -= self.n_initial\n\n        self.X = X_init.tolist()\n        self.y = y_init.tolist()\n\n        best_index = np.argmin(self.y)\n        self.f_opt = self.y[best_index]\n        self.x_opt = self.X[best_index]\n\n        # Optimization loop\n        while self.budget > 0:\n            self.gp.fit(self.X, self.y)\n            \n            # Generate candidate points (random sampling)\n            X_candidate = np.random.uniform(self.lb, self.ub, size=(100, self.dim))\n            \n            # Select the best candidate based on acquisition function\n            acq_values = np.array([self.acquisition(x, self.gp) for x in X_candidate])\n            best_candidate_idx = np.argmin(acq_values)\n            x_new = X_candidate[best_candidate_idx]\n            \n            # Evaluate the new point\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Update lists\n            self.X.append(x_new.tolist())\n            self.y.append(f_new)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 15, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 15, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "b2c32ff7-aa41-42fc-837c-f005b765001a", "fitness": 0.4451602047682015, "name": "ParticleSwarmOptimization", "description": "No description provided.", "code": "import numpy as np\n\nclass ParticleSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1 # Cognitive coefficient\n        self.c2 = c2 # Social coefficient\n        self.kappa = 1 # Constriction factor denominator\n        self.phi = self.c1 + self.c2\n        if self.phi > 4:\n          self.kappa = 2 / abs(2 - self.phi - np.sqrt(self.phi**2 - 4 * self.phi))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), size=(self.pop_size, self.dim))  #Initialize velocities\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = np.copy(population)\n        personal_best_fitnesses = np.copy(fitness)\n        \n        # Find global best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.kappa * (self.w * velocities[i] +\n                                   self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                   self.c2 * r2 * (self.x_opt - population[i]))\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)  # Clip to bounds\n\n                # Evaluate fitness\n                f_trial = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f_trial < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = f_trial\n                    personal_best_positions[i] = np.copy(population[i])\n                    \n                    # Update global best\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = population[i]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ParticleSwarmOptimization scored 0.445 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16730370657531402, 0.23797660820397737, 0.6962793827942839, 0.25439255944603234, 0.29806112138443175, 0.24339064755889506, 0.33634827867809347, 0.681760884870368, 0.6449653851134467, 0.6680977740522083, 0.2832087135714434, 0.9979196182078511, 0.32672573641383884, 0.2606491450947104, 0.6461393312668032, 0.3510324783021769, 0.6627463810755505, 0.3780555476017893, 0.22834264389733472, 0.5398081512554798]}, "task_prompt": ""}
{"id": "f8213296-e3e7-472c-8f76-da2a1ef0c976", "fitness": 0.5055423518163794, "name": "AdaptiveSearchSpace", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSearchSpace:\n    def __init__(self, budget=10000, dim=10, initial_radius=1.0, shrink_factor=0.9, expand_factor=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.radius = initial_radius\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.success_threshold = success_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.evals = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial random solution\n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        self.evals += 1\n        self.f_opt = f\n        self.x_opt = x\n        \n        success_count = 0\n\n        while self.evals < self.budget:\n            # Generate new candidate solution within the current radius\n            x_new = np.random.uniform(np.maximum(lb, self.x_opt - self.radius), np.minimum(ub, self.x_opt + self.radius), size=self.dim)\n\n            f_new = func(x_new)\n            self.evals += 1\n\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                success_count += 1\n\n            # Adjust search space radius\n            if self.evals % 100 == 0:\n                success_rate = success_count / 100.0\n                if success_rate > self.success_threshold:\n                    self.radius *= self.expand_factor\n                    self.radius = min(self.radius, (ub[0]-lb[0])/2)\n                else:\n                    self.radius *= self.shrink_factor\n                success_count = 0\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSearchSpace scored 0.506 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16958669706956042, 0.6710624672693574, 0.586075170106132, 0.1960314670600305, 0.5916863575595793, 0.6435933935183593, 0.24360458775348837, 0.514210064557708, 0.5885599085846962, 0.186436482092329, 0.8571761846151547, 0.9955293854684096, 0.25961960330276557, 0.5964174153685198, 0.8140296045122712, 0.3542277193096489, 0.421486365987896, 0.7547618770806368, 0.1825193359783014, 0.4842329491327435]}, "task_prompt": ""}
{"id": "9189ddf0-e775-4d10-ac0b-07da125bdfbb", "fitness": 0.5044785687529612, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7, stagnation_threshold=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Initial crossover rate\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                    else:\n                        self.stagnation_counter +=1\n            \n            self.best_fitness_history.append(self.f_opt)\n            # Adaptive F and CR (simplified)\n            self.F = 0.5 + 0.5 * np.exp(-4 * evals / self.budget)\n            self.CR = 0.2 + 0.7 * np.exp(-4 * evals / self.budget)\n            \n            # Stagnation check and restart\n            if self.stagnation_counter > self.stagnation_threshold:\n                 # Reduce population size if stagnating\n                if self.pop_size > 10: #set a minimum population size\n                    self.pop_size = max(10, int(self.pop_size * 0.75)) #reduce pop size\n                else: \n                    self.pop_size = int(min(50, self.pop_size * 1.1)) # grow pop size if small\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                self.stagnation_counter = 0\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.504 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18354621891738465, 0.2599861228232938, 0.45475621088350315, 0.7187177444178066, 0.5014439457432802, 0.656303015205415, 0.3724417290597958, 0.44336400443675394, 0.546078137708824, 0.46619790223526514, 0.6365878555833344, 0.9978422847708781, 0.2625486321635583, 0.4207669804666243, 0.7551679445925491, 0.6733685760786905, 0.35886314457694213, 0.6896779555363547, 0.19058942132332135, 0.5013235485356479]}, "task_prompt": ""}
{"id": "c099ff71-04fd-4953-985e-ad2750126b23", "fitness": 0.6602256661853069, "name": "AdaptiveShrinkingDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveShrinkingDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            # Dynamically adjust population size based on remaining budget\n            remaining_evals = self.budget - evals\n            self.pop_size = max(10, int(self.initial_pop_size * (remaining_evals / self.budget)))\n\n            if self.pop_size < population.shape[0]:\n                 idx_to_keep = np.argsort(fitness)[:self.pop_size]\n                 population = population[idx_to_keep]\n                 fitness = fitness[idx_to_keep]\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) < 3:\n                    break # Handle edge case where population is too small\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.3 * np.random.rand()\n            self.CR = 0.4 + 0.5 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveShrinkingDE scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.27099888809472494, 0.6273683922382218, 0.6704491214700077, 0.8125702604970904, 0.734249976851973, 0.7534016897075142, 0.6244644804461592, 0.6434541387760953, 0.7042286172287222, 0.617646236859889, 0.7896485593273337, 0.9838269182644093, 0.46718388045313874, 0.694095946575843, 0.8997374952367501, 0.7801424224547471, 0.5738595303688372, 0.8207272547102958, 0.2149334591224884, 0.5215260550218983]}, "task_prompt": ""}
{"id": "cf775060-302c-4bbf-8cf4-c996ebfdae51", "fitness": "-inf", "name": "SelfAdaptiveDE_LocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE_LocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                \n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    x_local = np.copy(population[i])\n                    step_size = 0.1 * (ub - lb)  # Define step size for local search\n\n                    for j in range(self.dim):\n                        # Explore in both directions for each dimension\n                        x_plus = np.copy(x_local)\n                        x_minus = np.copy(x_local)\n                        x_plus[j] = np.clip(x_local[j] + step_size, lb, ub)\n                        x_minus[j] = np.clip(x_local[j] - step_size, lb, ub)\n\n                        f_plus = func(x_plus)\n                        f_minus = func(x_minus)\n                        evals += 2\n\n                        if f_plus < fitness[i] and f_plus < f_minus:\n                            population[i] = x_plus\n                            fitness[i] = f_plus\n                            if f_plus < self.f_opt:\n                                self.f_opt = f_plus\n                                self.x_opt = x_plus\n                        elif f_minus < fitness[i] and f_minus < f_plus:\n                            population[i] = x_minus\n                            fitness[i] = f_minus\n                            if f_minus < self.f_opt:\n                                self.f_opt = f_minus\n                                self.x_opt = x_minus\n                        \n                        if evals >= self.budget:\n                          return self.f_opt, self.x_opt #break early if budget exceeded\n\n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 63, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[j] = np.clip(x_local[j] + step_size, lb, ub)", "error": "In the code, line 63, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: x_plus[j] = np.clip(x_local[j] + step_size, lb, ub)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "623a8f4e-e836-4d91-b62b-03a3f45b252e", "fitness": 0.7644289626978404, "name": "AdaptiveDEwithLocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDEwithLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, local_search_prob=0.1, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.local_search_prob = local_search_prob\n        self.local_search_radius = local_search_radius\n        self.success_F = []\n        self.success_CR = []\n        self.archive_F = []\n        self.archive_CR = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Local Search\n                if np.random.rand() < self.local_search_prob:\n                    trial_ls = np.copy(trial)\n                    for j in range(self.dim):\n                        trial_ls[j] += np.random.uniform(-self.local_search_radius, self.local_search_radius)\n                    trial_ls = np.clip(trial_ls, lb, ub)\n                else:\n                    trial_ls = trial\n\n                # Selection\n                f_trial = func(trial_ls)\n                evals += 1\n                \n                if f_trial < fitness[i]:\n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    \n                    population[i] = trial_ls\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_ls\n\n            #Adapt F and CR\n            if self.success_F:\n                self.archive_F.extend(self.success_F)\n                self.archive_CR.extend(self.success_CR)\n                \n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                \n                self.success_F = []\n                self.success_CR = []\n            else:\n                self.F = 0.5 + 0.4 * np.random.rand()\n                self.CR = 0.1 + 0.9 * np.random.rand()\n                \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEwithLocalSearch scored 0.764 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.20946143191549638, 0.7990658410855147, 0.6994740307953053, 0.9323124118960899, 0.8559679919004227, 0.91355677683245, 0.8569257084835076, 0.8193934429015042, 0.8875942754848032, 0.8740212467052861, 0.9259025171945513, 0.9996578749394934, 0.6971560677696902, 0.540906577344353, 0.8961015467116016, 0.8982397201626016, 0.8263990178729803, 0.9193996587313132, 0.21306707197300734, 0.5239760432568357]}, "task_prompt": ""}
{"id": "45cfd10b-fe38-4446-91f4-69f8ec805243", "fitness": 0.10290478934335838, "name": "CMAES_Restart", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=4, sigma0=0.5, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma0 = sigma0\n        self.restarts = restarts\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        evals = 0\n\n        for _ in range(self.restarts):\n            mean = np.random.uniform(lb, ub, size=self.dim)\n            C = np.eye(self.dim)\n            sigma = self.sigma0\n\n            while evals < self.budget:\n                # Sample population\n                z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n                population = mean + sigma * z\n                population = np.clip(population, lb, ub)\n\n                # Evaluate population\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n\n                # Sort population\n                idx = np.argsort(fitness)\n                fitness = fitness[idx]\n                population = population[idx]\n\n                # Update best solution\n                if fitness[0] < self.f_opt:\n                    self.f_opt = fitness[0]\n                    self.x_opt = population[0]\n\n                # Update CMA-ES parameters (simplified)\n                mean = population[0]  # elitist selection\n                C = np.cov(population.T)  # update covariance matrix\n                sigma *= np.exp(0.5 * (fitness[0] - fitness[-1]) / self.dim)  # adapt step size\n\n                if evals >= self.budget:\n                    break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES_Restart scored 0.103 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [9.999999999998899e-05, 0.035035740385252034, 0.17241637951310007, 0.09454440929257868, 0.11264377988575469, 0.10735647940520265, 0.20148462943060685, 0.13166189310861665, 0.12615276587209956, 0.11730638862095999, 0.1065626412623063, 0.19024435352845803, 0.04162976361297355, 9.999999999998899e-05, 0.09242638283577731, 0.15936058217353544, 0.04712113403803109, 0.1448668230953566, 0.06849549116120701, 0.10858614964535152]}, "task_prompt": ""}
{"id": "f222f82c-d947-48b4-8baf-d350f87c6766", "fitness": 0.0, "name": "ModifiedDE", "description": "No description provided.", "code": "import numpy as np\n\nclass ModifiedDE:\n    def __init__(self, budget=10000, dim=10, pop_size=15, F=0.5, CR=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                #Dynamically adjust F\n                F_dynamic = self.F + 0.1 * np.random.randn()\n                F_dynamic = np.clip(F_dynamic, 0.1, 0.9)\n\n                mutant = population[a] + F_dynamic * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover - Simplified: Always perform crossover on one random dimension\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                trial[j_rand] = mutant[j_rand]\n\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ModifiedDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "1d193786-a856-4d3b-b1bd-ba48eb58292e", "fitness": 0.0, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=10, F=0.7, CR=0.3, stagnation_limit=300, pop_adjust_freq=1000):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.stagnation_limit = stagnation_limit\n        self.stagnation_counter = 0\n        self.best_fitness_history = []\n        self.pop_adjust_freq = pop_adjust_freq\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n        self.best_fitness_history.append(self.f_opt)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                        self.stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    self.stagnation_counter += 1\n            \n            # Adaptive F and CR\n            self.F = 0.5 + 0.5 * np.random.rand()\n            self.CR = 0.1 + 0.3 * np.random.rand()\n            \n            #Stagnation Check and Restart\n            if self.stagnation_counter > self.stagnation_limit:\n              population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n              fitness = np.array([func(x) for x in population])\n              evals += self.pop_size\n              \n              best_idx = np.argmin(fitness)\n              self.f_opt = fitness[best_idx]\n              self.x_opt = population[best_idx]\n              self.stagnation_counter = 0 # Reset stagnation counter\n            \n            # Adaptive Population size\n            if evals % self.pop_adjust_freq == 0:\n                if self.f_opt == np.min(self.best_fitness_history):\n                    self.pop_size = max(5, int(self.pop_size / 2))\n                else:\n                    self.pop_size = min(50, int(self.pop_size * 1.2))\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n\n            self.best_fitness_history.append(self.f_opt)\n            if len(self.best_fitness_history) > 10:\n                self.best_fitness_history.pop(0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "f446d277-f9ef-44b3-b1c3-193cec169df5", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.1, restart_trigger=1e-12):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.restart_trigger = restart_trigger\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_step_size\n        C = np.eye(self.dim)\n        \n        evals = 0\n        restart = False\n\n        while evals < self.budget:\n            if restart:\n                mean = np.random.uniform(lb, ub, size=self.dim)\n                sigma = self.initial_step_size\n                C = np.eye(self.dim)\n                restart = False\n            \n            # Sample population\n            Z = np.random.randn(self.pop_size, self.dim)\n            X = mean + sigma * Z @ np.linalg.cholesky(C).T\n            X = np.clip(X, lb, ub)\n\n            # Evaluate population\n            fitness = np.array([func(x) for x in X])\n            evals += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            X = X[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[0]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.mean(X[:self.mu], axis=0)\n\n            # Cumulation\n            ps = (mean - mean_old) / sigma\n            cs = np.linalg.norm(ps) / np.sqrt(1 - (1 - 0.33)**2) / np.sqrt(self.dim)\n            if cs > 0.7:\n                ps = np.zeros_like(ps)\n            \n            pc = (1 - 0.044) * ps + np.sqrt(0.044 * (2 - 0.044)) * (mean - mean_old) / sigma\n            \n            # Update covariance matrix\n            C = (1 - 0.044) * C + 0.044 / np.linalg.norm(pc)**2 * (np.outer(pc, pc) - C)\n            \n            # Update step size\n            sigma *= np.exp(0.2 * (np.linalg.norm(ps) / 1.414 - 1))\n            \n            # Check for stagnation and restart\n            if np.max(np.diag(C)) < self.restart_trigger:\n                restart = True\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 148, in _raise_linalgerror_nonposdef, the following error occurred:\nLinAlgError: Matrix is not positive definite", "error": "In the code, line 148, in _raise_linalgerror_nonposdef, the following error occurred:\nLinAlgError: Matrix is not positive definite", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "18295475-5ed4-414e-9d9e-5aa274de8e46", "fitness": 0.4563461876342999, "name": "DynamicPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w_max=0.9, w_min=0.4, c1=2, c2=2, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w_max = w_max\n        self.w_min = w_min\n        self.c1 = c1\n        self.c2 = c2\n        self.v_max_ratio = v_max_ratio\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize population and velocities\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.v_max_ratio, abs(ub-lb)*self.v_max_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitness\n        pbest_positions = population.copy()\n        fitness = np.array([func(x) for x in population])\n        pbest_fitness = fitness.copy()\n        evals = self.pop_size\n        \n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx].copy()\n        \n        while evals < self.budget:\n            # Update inertia weight (linearly decreasing)\n            w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n            \n            for i in range(self.pop_size):\n                # Update velocities\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = (w * velocities[i]\n                                 + self.c1 * r1 * (pbest_positions[i] - population[i])\n                                 + self.c2 * r2 * (self.x_opt - population[i]))\n                \n                # Velocity clamping\n                v_max = abs(ub - lb) * self.v_max_ratio\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                \n                # Update positions\n                population[i] = population[i] + velocities[i]\n                \n                # Boundary handling\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if f < pbest_fitness[i]:\n                    pbest_fitness[i] = f\n                    pbest_positions[i] = population[i].copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i].copy()\n            \n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicPSO scored 0.456 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12846350361986647, 0.43467288659277736, 0.5560276765481134, 0.24154839430853337, 0.2545445225983046, 0.7043846141071917, 0.3439390707056085, 0.4756918203762728, 0.6120804939894465, 0.22918662994229388, 0.755458534643085, 0.997061754131639, 0.27512555325543, 0.27163439707997594, 0.5845941150396439, 0.6727982299688137, 0.4892600930569526, 0.37740713960130523, 0.22387436836894037, 0.4991699547518057]}, "task_prompt": ""}
{"id": "720d8018-3f05-4e18-8051-687ed712105b", "fitness": "-inf", "name": "GPSurrogate", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogate:\n    def __init__(self, budget=10000, dim=10, lb=-5.0, ub=5.0, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = lb\n        self.ub = ub\n        self.n_initial_samples = n_initial_samples\n        self.x_samples = []\n        self.y_samples = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n    def acquisition_function(self, x):\n        mu, sigma = self.gp.predict(x.reshape(1, -1), return_std=True)\n        \n        if sigma == 0:\n           return 0\n        \n        improvement = (self.f_opt - mu) / sigma\n        return - (improvement * norm.cdf(improvement) + norm.pdf(improvement))\n\n    def suggest_next_point(self):\n        x_start = np.random.uniform(self.lb, self.ub, size=self.dim)\n        bounds = [(self.lb, self.ub)] * self.dim\n        result = minimize(self.acquisition_function, x_start, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        # Initial sampling\n        for i in range(self.n_initial_samples):\n            x = np.random.uniform(self.lb, self.ub, size=self.dim)\n            y = func(x)\n            self.x_samples.append(x)\n            self.y_samples.append(y)\n            self.budget -= 1\n\n            if y < self.f_opt:\n                self.f_opt = y\n                self.x_opt = x.copy()\n\n            if self.budget <= 0:\n                return self.f_opt, self.x_opt\n\n        self.x_samples = np.array(self.x_samples)\n        self.y_samples = np.array(self.y_samples)\n\n        # Optimization loop\n        while self.budget > 0:\n            # Fit GP model\n            self.gp.fit(self.x_samples, self.y_samples)\n\n            # Suggest next point\n            x_next = self.suggest_next_point()\n\n            # Evaluate function\n            y_next = func(x_next)\n            self.budget -= 1\n\n            # Update samples\n            self.x_samples = np.vstack((self.x_samples, x_next))\n            self.y_samples = np.append(self.y_samples, y_next)\n\n            # Update best\n            if y_next < self.f_opt:\n                self.f_opt = y_next\n                self.x_opt = x_next.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 18, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 18, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ce9d8aef-4c81-49ec-afc7-2e117c2e5b6f", "fitness": "-inf", "name": "GPSurrogateOptimizer", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogateOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel=None, acquisition_function='EI'):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.kernel = kernel if kernel is not None else C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        self.acquisition_function = acquisition_function\n\n    def expected_improvement(self, x, gp, f_best, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        sigma = np.maximum(sigma, 1e-9) \n        imp = f_best - mu - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def upper_confidence_bound(self, x, gp, kappa=1.96):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu + kappa * sigma\n    \n    def thompson_sampling(self, x, gp):\n        return gp.sample_y(x.reshape(1, -1), n_samples=1)[0][0]\n    \n    def acquisition(self, x, gp, f_best):\n        if self.acquisition_function == 'EI':\n            return self.expected_improvement(x, gp, f_best)\n        elif self.acquisition_function == 'UCB':\n            return self.upper_confidence_bound(x, gp)\n        elif self.acquisition_function == 'TS':\n            return self.thompson_sampling(x, gp)\n        else:\n            raise ValueError(\"Invalid acquisition function.\")\n\n    def optimize_acquisition(self, gp, f_best, lb, ub):\n        def neg_acquisition(x):\n            return -self.acquisition(x, gp, f_best)\n\n        x0 = np.random.uniform(lb, ub, size=self.dim)\n        bounds = [(lb, ub)] * self.dim\n        result = minimize(neg_acquisition, x0, method='L-BFGS-B', bounds=bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial sampling\n        X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial_samples\n        \n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        # Gaussian process regression\n        gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n        while evals < self.budget:\n            gp.fit(X, y)\n            \n            # Find next point to evaluate by maximizing the acquisition function\n            x_next = self.optimize_acquisition(gp, self.f_opt, lb, ub)\n            \n            # Evaluate the objective function\n            f_next = func(x_next)\n            evals += 1\n\n            # Add the new data to the training set\n            X = np.vstack((X, x_next))\n            y = np.append(y, f_next)\n            \n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = kernel if kernel is not None else C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = kernel if kernel is not None else C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "d8454d21-69f9-4666-9cb7-745d5c1b44c7", "fitness": "-inf", "name": "GPSurrogateOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GPSurrogateOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial=10, kernel=None, acq_func=\"EI\"):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.kernel = kernel if kernel is not None else ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.acq_func = acq_func\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def acquisition(self, x, gp, bounds):\n        x = x.reshape(-1, self.dim)\n        mu, sigma = gp.predict(x, return_std=True)\n        if self.acq_func == \"EI\":\n            imp = mu - self.f_opt\n            Z = imp / sigma\n            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n            return -ei\n        elif self.acq_func == \"UCB\":\n            kappa = 2.0\n            return -(mu + kappa * sigma)\n        else:\n            raise ValueError(\"Acquisition function not supported.\")\n\n    def propose_location(self, gp, bounds, n_restarts=25):\n        lb = bounds.lb\n        ub = bounds.ub\n        x_start = np.random.uniform(lb, ub, size=(n_restarts, self.dim))\n        min_val = np.inf\n        min_x = None\n        for x0 in x_start:\n            res = minimize(self.acquisition, x0, bounds=bounds, args=(gp, bounds), method=\"L-BFGS-B\")\n            if res.fun < min_val:\n                min_val = res.fun[0]\n                min_x = res.x\n        return min_x\n\n    def __call__(self, func):\n        X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial, self.dim))\n        y = np.array([func(x) for x in X])\n        evals = self.n_initial\n        \n        best_idx = np.argmin(y)\n        self.f_opt = y[best_idx]\n        self.x_opt = X[best_idx]\n\n        gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5)\n\n        while evals < self.budget:\n            gp.fit(X, y)\n            x_next = self.propose_location(gp, func.bounds)\n            f_next = func(x_next)\n            evals += 1\n            \n            X = np.vstack((X, x_next))\n            y = np.append(y, f_next)\n            \n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = kernel if kernel is not None else ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 12, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = kernel if kernel is not None else ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "f2520612-36ac-48a1-aa73-7a6a9ae38105", "fitness": 0.12248410277602736, "name": "SimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass SimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    # Description: A simulated annealing algorithm that probabilistically accepts worse solutions to escape local optima, with the acceptance probability decreasing as the temperature cools down.\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        current_x = np.random.uniform(lb, ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        temp = self.initial_temp\n\n        while self.budget > 0:\n            new_x = current_x + np.random.normal(0, temp/100, size=self.dim)\n            new_x = np.clip(new_x, lb, ub)\n            new_f = func(new_x)\n            self.budget -= 1\n            \n            if new_f < current_f:\n                current_x = new_x\n                current_f = new_f\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n            else:\n                acceptance_probability = np.exp((current_f - new_f) / temp)\n                if np.random.rand() < acceptance_probability:\n                    current_x = new_x\n                    current_f = new_f\n\n            temp *= self.cooling_rate\n            if self.budget <=0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimulatedAnnealing scored 0.122 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.04654425371585169, 0.1497369439119921, 0.19575241292539391, 0.07465337092863922, 0.07417288571839675, 0.09579142520848749, 0.02021359742018436, 0.09337581935997752, 0.14005876868286782, 0.10644747937575305, 0.11223756150311093, 0.12899946933964312, 0.2713779762266366, 0.04719597445839119, 0.12587751003511638, 0.1621324522293629, 0.1593658099260491, 0.15212762173195438, 0.11339212285465072, 0.18022859996808815]}, "task_prompt": ""}
{"id": "53a272d3-ef9e-4800-b339-a9d19dee36cc", "fitness": "-inf", "name": "GradientEnhancedGeneticAlgorithm", "description": "No description provided.", "code": "import numpy as np\n\nclass GradientEnhancedGeneticAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, crossover_rate=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            new_population = []\n            for i in range(self.pop_size):\n                # Selection (Tournament Selection)\n                idx1 = np.random.randint(self.pop_size)\n                idx2 = np.random.randint(self.pop_size)\n                if fitness[idx1] < fitness[idx2]:\n                    parent1 = population[idx1]\n                else:\n                    parent1 = population[idx2]\n                \n                idx1 = np.random.randint(self.pop_size)\n                idx2 = np.random.randint(self.pop_size)\n                if fitness[idx1] < fitness[idx2]:\n                    parent2 = population[idx1]\n                else:\n                    parent2 = population[idx2]\n\n                # Crossover\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(self.dim)\n                    child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n                else:\n                    child = parent1\n\n                # Mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        child[j] += np.random.uniform(-0.1, 0.1)  # Small perturbation\n                        child[j] = np.clip(child[j], lb, ub)\n\n                new_population.append(child)\n\n            new_population = np.array(new_population)\n\n            # Local Search (Gradient Descent) on best individual\n            best_idx = np.argmin(fitness)\n            x_ls = np.copy(population[best_idx])\n            \n            for _ in range(self.local_search_iterations):\n                # Estimate gradient (simplified finite difference)\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = np.copy(x_ls)\n                    x_minus = np.copy(x_ls)\n                    delta = 0.001  # Small step for gradient estimation\n                    x_plus[j] += delta\n                    x_minus[j] -= delta\n                    x_plus[j] = np.clip(x_plus[j], lb, ub)\n                    x_minus[j] = np.clip(x_minus[j], lb, ub)\n                    gradient[j] = (func(x_plus) - func(x_minus)) / (2 * delta)\n                    evals += 2 #account for function evaluations\n                    if evals >= self.budget:\n                        break\n\n                # Update position (gradient descent)\n                x_ls -= 0.01 * gradient\n                x_ls = np.clip(x_ls, lb, ub)\n                if evals >= self.budget:\n                    break\n                \n            f_ls = func(x_ls)\n            evals += 1\n\n            # Replace worst individual with locally optimized solution\n            worst_idx = np.argmax(fitness)\n            new_population[worst_idx] = x_ls\n            fitness_ls = f_ls #func(x_ls) #evals already updated\n\n            fitness_new = np.array([func(x) if i!=worst_idx else fitness_ls for i, x in enumerate(new_population)])\n            evals += (self.pop_size -1) if (evals < self.budget) else 0 \n            \n            population = new_population\n            fitness = fitness_new\n                \n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n                \n\n            if evals >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 55, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: child[j] = np.clip(child[j], lb, ub)", "error": "In the code, line 55, in __call__, the following error occurred:\nValueError: setting an array element with a sequence.\nOn line: child[j] = np.clip(child[j], lb, ub)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "85925152-bed5-4277-b15e-20001f67f9eb", "fitness": 0.3149804140835, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, initial_step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.initial_step_size = initial_step_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        x = np.random.uniform(lb, ub, size=self.dim)\n        f = func(x)\n        evals = 1\n        \n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            # Generate a neighbor solution\n            x_new = x + np.random.normal(0, step_size, size=self.dim)\n            x_new = np.clip(x_new, lb, ub)\n            \n            f_new = func(x_new)\n            evals += 1\n            \n            # Acceptance probability\n            delta_e = f_new - f\n            if delta_e < 0 or np.random.rand() < np.exp(-delta_e / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adaptive temperature and step size\n            temp *= self.cooling_rate\n            step_size *= 0.99  # Gradual step size reduction\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.315 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06509607429973252, 0.20565874600367928, 0.23256814074043164, 0.17228749433974022, 0.3093798997443975, 0.2014475809277596, 0.2466981976903092, 0.48083018754764395, 0.21423961941567193, 0.17823016558586968, 0.23243170445274153, 0.9967504087808499, 0.22818062059665079, 0.21974052352333817, 0.5388576125942045, 0.22789726650755626, 0.22511097656346557, 0.967219747004467, 0.15362932870844592, 0.20335398664304427]}, "task_prompt": ""}
{"id": "35f44edf-6f24-455c-807b-a550e3149820", "fitness": "-inf", "name": "HarmonySearch", "description": "No description provided.", "code": "import numpy as np\n\nclass HarmonySearch:\n    def __init__(self, budget=10000, dim=10, HMS=20, HMCR=0.9, PAR=0.3, bw=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.HMS = HMS  # Harmony Memory Size\n        self.HMCR = HMCR  # Harmony Memory Consideration Rate\n        self.PAR = PAR  # Pitch Adjusting Rate\n        self.bw = bw  # Bandwidth\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize Harmony Memory\n        HM = np.random.uniform(lb, ub, size=(self.HMS, self.dim))\n        HM_fitness = np.array([func(x) for x in HM])\n        self.budget -= self.HMS\n\n        # Find global best\n        best_index = np.argmin(HM_fitness)\n        self.f_opt = HM_fitness[best_index]\n        self.x_opt = HM[best_index].copy()\n\n        while self.budget > 0:\n            # Improvise a new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.HMCR:\n                    # Memory consideration\n                    new_harmony[i] = HM[np.random.randint(self.HMS), i]\n                    # Pitch adjustment\n                    if np.random.rand() < self.PAR:\n                        new_harmony[i] += np.random.uniform(-self.bw, self.bw)\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(lb, ub)\n                \n                new_harmony[i] = np.clip(new_harmony[i], lb, ub)\n            \n            # Evaluate new harmony\n            new_fitness = func(new_harmony)\n            self.budget -= 1\n            \n            # Update Harmony Memory\n            if new_fitness < np.max(HM_fitness):\n                worst_index = np.argmax(HM_fitness)\n                HM[worst_index] = new_harmony\n                HM_fitness[worst_index] = new_fitness\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_harmony.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt\n```\n\n# Description: This Harmony Search algorithm mimics the improvisation process of musicians, iteratively refining solutions by considering existing harmonies, adjusting pitches, and introducing randomness to discover better combinations within the search space.\n# Code: \n```python\nimport numpy as np\n\nclass HarmonySearch:\n    def __init__(self, budget=10000, dim=10, HMS=20, HMCR=0.9, PAR=0.3, bw=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.HMS = HMS  # Harmony Memory Size\n        self.HMCR = HMCR  # Harmony Memory Consideration Rate\n        self.PAR = PAR  # Pitch Adjusting Rate\n        self.bw = bw  # Bandwidth\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize Harmony Memory\n        HM = np.random.uniform(lb, ub, size=(self.HMS, self.dim))\n        HM_fitness = np.array([func(x) for x in HM])\n        self.budget -= self.HMS\n\n        # Find global best\n        best_index = np.argmin(HM_fitness)\n        self.f_opt = HM_fitness[best_index]\n        self.x_opt = HM[best_index].copy()\n\n        while self.budget > 0:\n            # Improvise a new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.HMCR:\n                    # Memory consideration\n                    new_harmony[i] = HM[np.random.randint(self.HMS), i]\n                    # Pitch adjustment\n                    if np.random.rand() < self.PAR:\n                        new_harmony[i] += np.random.uniform(-self.bw, self.bw)\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(lb, ub)\n                \n                new_harmony[i] = np.clip(new_harmony[i], lb, ub)\n            \n            # Evaluate new harmony\n            new_fitness = func(new_harmony)\n            self.budget -= 1\n            \n            # Update Harmony Memory\n            if new_fitness < np.max(HM_fitness):\n                worst_index = np.argmax(HM_fitness)\n                HM[worst_index] = new_harmony\n                HM_fitness[worst_index] = new_fitness\n\n                # Update global best\n                if new_fitness < self.f_opt:\n                    self.f_opt = new_fitness\n                    self.x_opt = new_harmony.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 143, in evaluate, the following error occurred:\nSyntaxError: invalid syntax", "error": "In the code, line 143, in evaluate, the following error occurred:\nSyntaxError: invalid syntax", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "58cd3945-e028-4578-b89c-a349c4cf9652", "fitness": 0.3581060275138306, "name": "ShrinkingDE", "description": "No description provided.", "code": "import numpy as np\n\nclass ShrinkingDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, shrink_factor=0.9, min_pop_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.shrink_factor = shrink_factor\n        self.min_pop_size = min_pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget and self.pop_size > self.min_pop_size:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n\n            # Shrink population\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices[:int(self.pop_size * self.shrink_factor)]]\n            fitness = fitness[sorted_indices[:int(self.pop_size * self.shrink_factor)]]\n            self.pop_size = len(population)\n            if self.pop_size > 0:\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n            \n        # Final Search with small population if budget remains\n        while evals < self.budget:\n            if self.pop_size == 0:\n                population = np.random.uniform(lb, ub, size=(self.min_pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.min_pop_size\n                self.pop_size = self.min_pop_size\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            else:\n                # Mutation\n                i = 0\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) >= 3:\n                  a, b, c = np.random.choice(idxs, 3, replace=False)\n                  mutant = population[a] + self.F * (population[b] - population[c])\n                  mutant = np.clip(mutant, lb, ub)\n\n                  # Crossover\n                  trial = np.copy(population[i])\n                  j_rand = np.random.randint(self.dim)\n                  for j in range(self.dim):\n                      if np.random.rand() < self.CR or j == j_rand:\n                          trial[j] = mutant[j]\n\n                  # Selection\n                  f_trial = func(trial)\n                  evals += 1\n\n                  if f_trial < fitness[i]:\n                      population[i] = trial\n                      fitness[i] = f_trial\n\n                      # Update best solution\n                      if f_trial < self.f_opt:\n                          self.f_opt = f_trial\n                          self.x_opt = trial\n                else:\n                    x = np.random.uniform(lb, ub)\n                    f = func(x)\n                    evals += 1\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ShrinkingDE scored 0.358 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1208901361824466, 0.19299764985010381, 0.33838892763592243, 0.34199838008193695, 0.26071880222282506, 0.30099300568161236, 0.28375764657014246, 0.27472827824448676, 0.3221872836701849, 0.23140582077808736, 0.4638910627436982, 0.9956206431952261, 0.2670364000230162, 0.28285209311351023, 0.6397914177798407, 0.42828763708536344, 0.2857097747870633, 0.4688537355449748, 0.17937081792417198, 0.482641037161999]}, "task_prompt": ""}
{"id": "05f67fd8-2001-4966-a98a-cf205bebae8d", "fitness": 0.35779078781457785, "name": "AdaptiveDECauchyRanking", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDECauchyRanking:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)\n                cauchy_sample = self.F * np.random.standard_cauchy(size=self.dim)\n                mutant = population[i] + cauchy_sample * (population[ranked_indices[0]] - population[ranked_indices[-1]]) #Cauchy mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection (ranking-based)\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            #Adapt F and CR\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.1 + 0.9 * np.random.rand()\n                \n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDECauchyRanking scored 0.358 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14147975320902006, 0.1945615918199909, 0.33183251405740644, 0.32525504450571274, 0.3335144639894476, 0.412700321719526, 0.2999443087797655, 0.33024112894364865, 0.2599680387346348, 0.20517701175042014, 0.28383386312497827, 0.9985663434557316, 0.29679604954832317, 0.29242244015234675, 0.6833085380078658, 0.397750061002789, 0.2993856303204616, 0.3770712969103359, 0.20107042639161354, 0.490936929867538]}, "task_prompt": ""}
{"id": "d43eb5f7-e69c-490d-98d6-e6d8e26ecb56", "fitness": 0.38584231932204177, "name": "RankAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass RankAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_f=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.f = initial_f\n        self.cr = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Rank the population\n            ranked_indices = np.argsort(fitness)\n\n            for i in range(self.pop_size):\n                # Select parents based on rank: Better ranked individuals have higher probability\n                probabilities = (ranked_indices.size - np.arange(ranked_indices.size)) / np.sum(np.arange(1, ranked_indices.size + 1))\n                parent_indices = np.random.choice(ranked_indices, 3, replace=False, p=probabilities)\n                x1, x2, x3 = population[parent_indices]\n\n                # Adjust mutation factor based on rank\n                rank = np.where(ranked_indices == i)[0][0]\n                mutation_factor = self.f * (1.0 - rank / self.pop_size) # Smaller f for better ranks\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + mutation_factor * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                \n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                    \n                if self.budget <= 0:\n                    break\n            \n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm RankAdaptiveDE scored 0.386 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.21553734962819482, 0.2141534494221391, 0.36799716291963824, 0.49590124541403713, 0.3599082956834443, 0.5652267152983035, 0.371641460512264, 0.29305702859261074, 0.2633440271524845, 0.23259358745984338, 0.16202600774250608, 0.9988498431590536, 0.25460567079689334, 0.25021070027529846, 0.6566379547779124, 0.6472306048108007, 0.3392490392693267, 0.3149579716356047, 0.21395690646564436, 0.4997613654248352]}, "task_prompt": ""}
{"id": "712281a7-ac14-4e5f-b9fe-1d64ec981d6f", "fitness": 0.6273612581003978, "name": "AdaptiveDEBest1", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDEBest1:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.archive_factor = 2.0 # Size of the archive relative to pop_size\n        self.archive = []\n        self.success_cr = []\n        self.success_f = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation - DE/best/1 strategy with adaptive F\n                idxs = np.random.choice(self.pop_size, 2, replace=False)\n                x1, x2 = population[idxs]\n\n                # Use best solution so far in mutation\n                trial_vector = self.x_opt + self.f * (x1 - x2)\n                \n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        new_population[i][j] = trial_vector[j]\n                    else:\n                        new_population[i][j] = population[i][j]\n\n                new_population[i] = np.clip(new_population[i], self.lb, self.ub)\n\n                f = func(new_population[i])\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_population[i].copy()\n                    \n                    self.archive.append(population[i].copy())\n                    if len(self.archive) > self.archive_factor * self.pop_size:\n                        self.archive.pop(0)  # Maintain archive size\n\n                    self.success_cr.append(self.cr)\n                    self.success_f.append(self.f)\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Update CR and F\n            if self.success_cr and self.success_f:\n                cr_mean = np.mean(self.success_cr)\n                f_mean = np.mean(self.success_f)\n\n                self.cr = 0.9 * self.cr + 0.1 * cr_mean  # Exponential smoothing\n                self.f = 0.9 * self.f + 0.1 * f_mean\n                \n                self.success_cr = []\n                self.success_f = []\n\n            else:\n                # No successful updates, increase exploration\n                self.cr = min(1.0, self.cr + 0.1)\n                self.f = min(1.0, self.f + 0.1)\n\n            self.cr = np.clip(self.cr, 0.1, 0.9)\n            self.f = np.clip(self.f, 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEBest1 scored 0.627 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15179916163512774, 0.7887646336092268, 0.8765529737062924, 0.9364753894082654, 0.2831688803229685, 0.2544065017645828, 0.37716694900781367, 0.8427609246012087, 0.8885559401098544, 0.8241628970846131, 0.28416425857588057, 0.998111753920288, 0.6806527112778077, 0.41179964539701297, 0.738994383082217, 0.3590080840054417, 0.8002065930961761, 0.9397794789937732, 0.24643023251498797, 0.8642637698944153]}, "task_prompt": ""}
{"id": "116d5d3b-a928-4ff0-9a62-e65bd07cc687", "fitness": "-inf", "name": "BudgetAwareCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_step_size = initial_step_size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cumcov = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cumsigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.dampsigma = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cumsigma\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_step_size\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        B = np.eye(self.dim)\n        D = np.ones(self.dim)\n        C = B @ np.diag(D**2) @ B.T\n        invsqrtC = B @ np.diag(D**-1) @ B.T\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.randn(self.dim, self.pop_size)\n            x = mean[:, None] + sigma * (B @ (D[:, None] * z))\n            x = np.clip(x, lb, ub)\n            fitness = np.array([func(xi) for xi in x.T])\n            evals += self.pop_size\n            \n            arindex = np.argsort(fitness)\n            xsorted = x[:, arindex]\n            fitness_sorted = fitness[arindex]\n\n            xmean = np.sum(xsorted[:, :self.mu] * self.weights[None, :], axis=1)\n            \n            if fitness_sorted[0] < self.f_opt:\n                self.f_opt = fitness_sorted[0]\n                self.x_opt = xsorted[:, 0]\n            \n            y = invsqrtC @ (xmean - mean)\n            ps = (1 - self.cumsigma) * ps + np.sqrt(self.cumsigma * (2 - self.cumsigma) * self.mueff) * y\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cumsigma)**(2 * evals / self.pop_size)) / self.chiN < 1.4 + 2 / (self.dim + 1)\n            pc = (1 - self.cumcov) * pc + hsig * np.sqrt(self.cumcov * (2 - self.cumcov) * self.mueff) * (xmean - mean)\n            mean = xmean\n\n            C = (1 - self.cumcov) * C + self.cumcov * (pc[:, None] @ pc[None, :] + (1 - hsig) * self.cumcov * (2 - self.cumcov) * C) + self.cumcov * np.sum(self.weights[None, :] * (xsorted[:, :self.mu] - mean[:, None]) @ (xsorted[:, :self.mu] - mean[:, None]).T, axis=1)\n            \n            try:\n                D, B = np.linalg.eigh(C)\n                D = np.sqrt(np.maximum(D, 1e-16))\n                invsqrtC = B @ np.diag(D**-1) @ B.T\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n                B = np.eye(self.dim)\n                D = np.ones(self.dim)\n                invsqrtC = np.eye(self.dim)\n            \n            sigma *= np.exp((self.cumsigma / self.dampsigma) * (np.linalg.norm(ps) / self.chiN - 1))\n            sigma = min(sigma, (ub - lb) / 2)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "e0983789-d830-4870-8f4d-af5fbed3fa98", "fitness": "-inf", "name": "AdaptiveDEwithRestart", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDEwithRestart:\n    def __init__(self, budget=10000, dim=10, pop_size_init=20, F=0.5, CR=0.7, restart_prob=0.05, pop_size_adapt_freq=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_init = pop_size_init\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.pop_size_adapt_freq = pop_size_adapt_freq\n        self.pop_size = pop_size_init\n        self.evals = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.evals < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.evals += 1\n                \n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Restart Mechanism\n            if np.random.rand() < self.restart_prob:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n\n            # Population Size Adaptation\n            if self.evals % self.pop_size_adapt_freq == 0:\n                if np.random.rand() < 0.5:\n                    self.pop_size = int(self.pop_size * 1.1)  # Increase population size\n                else:\n                    self.pop_size = int(self.pop_size * 0.9)  # Decrease population size\n                self.pop_size = max(10, min(self.pop_size, 50))\n                new_population = np.random.uniform(lb, ub, size=(self.pop_size - population.shape[0], self.dim))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.evals += new_population.shape[0]\n\n                population = np.vstack((population, new_population))\n                fitness = np.concatenate((fitness, new_fitness))\n\n                best_idx = np.argmin(fitness)\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 526, in numpy.random._common.cont_broadcast_2, the following error occurred:\nValueError: negative dimensions are not allowed", "error": "In the code, line 526, in numpy.random._common.cont_broadcast_2, the following error occurred:\nValueError: negative dimensions are not allowed", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "e6b9c083-14d4-487c-9f2d-8d2e2a889d2d", "fitness": 0.5756262659446729, "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.C = np.eye(dim)\n        self.mu = None\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.pop_size + 2) / (dim + self.pop_size + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.pop_size - 1)/(dim + 1)) - 1) + self.c_sigma\n        self.c_c = 4 / (dim + 4)\n        self.c_mu = 4\n        self.c_mu /= (dim + 10)\n        self.weights = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mueff)\n        self.c_mu_adapt = min(1 - self.c_1, self.c_mu * (self.mueff - 2 + 1/self.mueff) / ((dim + 2.0)**2 + self.mueff))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        self.mu = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.sigma0\n        evals = 0\n\n        while evals < self.budget:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mu + sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n            # Clipping\n            x = np.clip(x, lb, ub)\n\n            fitness = np.array([func(xi) for xi in x])\n            evals += self.pop_size\n\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            mu_old = self.mu.copy()\n            self.mu = np.sum(x[:self.pop_size] * self.weights[:, np.newaxis], axis=0)\n\n            # Update evolution path\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * np.linalg.solve(np.linalg.cholesky(self.C), (self.mu - mu_old)) / sigma\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (evals/self.pop_size))) / self.chiN) < (1.4 + 2/(self.dim + 1))\n            self.pc = (1 - self.c_c) * self.pc + hsig * np.sqrt(self.c_c * (2 - self.c_c) * self.mueff) * (self.mu - mu_old) / sigma\n\n            # Update covariance matrix\n            artmp = (x[:self.pop_size] - mu_old) / sigma\n            self.C = (1 - self.c_1 - self.c_mu_adapt) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + (1-hsig) * self.c_c * (2 - self.c_c) * self.C) + self.c_mu_adapt * np.sum(self.weights[:, np.newaxis, np.newaxis] * artmp[:, :, np.newaxis] * artmp[:, np.newaxis, :], axis=0)\n\n            # Update step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps)/self.chiN - 1))\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.576 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12735217567401103, 0.8685438377114978, 0.9370693771014746, 0.327399454702231, 0.9022931772504157, 0.1265510868745401, 0.29700941521911417, 0.9104201951474534, 0.17462150880192673, 0.09404140207337164, 0.9162332746691418, 0.9815846661543988, 0.4887407864536313, 0.9291428514769514, 0.5702897156660944, 0.9016376301386884, 0.40823125948706773, 0.9344470893654365, 0.11599084795949033, 0.5009255669665209]}, "task_prompt": ""}
{"id": "192169e6-1b74-4e65-8931-8e0c57ed0278", "fitness": 0.4677922804621383, "name": "CauchyRankDE", "description": "No description provided.", "code": "import numpy as np\n\nclass CauchyRankDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = initial_pop_size\n        self.pop_size = initial_pop_size\n        self.F = F\n        self.CR = CR\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            \n            ranks = np.argsort(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation using Cauchy distribution\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(idxs) < 3:\n                    break\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                cauchy_mutation = population[a] + self.F * (population[b] - population[c]) * np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(cauchy_mutation, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection (Rank-based)\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n            # Adaptive F and CR based on ranks\n            self.F = 0.5 + 0.3 * np.random.rand() * (1 - ranks[i]/self.pop_size) # F decreases for better ranked individuals\n            self.CR = 0.4 + 0.5 * np.random.rand() * (ranks[i]/self.pop_size)   # CR increases for better ranked individuals\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyRankDE scored 0.468 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18943358186942938, 0.2226302427187291, 0.42488574699839443, 0.7123107651417033, 0.4452252303323556, 0.552751696445841, 0.34373910772930427, 0.41942796483472256, 0.4796234571638699, 0.33934855993458746, 0.5375433263243619, 0.99620319390978, 0.2678841504660556, 0.4153492828297758, 0.7105103843334837, 0.5929014314136541, 0.3603393548695828, 0.6455026614800041, 0.20410704640590727, 0.49612842404122326]}, "task_prompt": ""}
{"id": "17b41ee1-a76e-4217-b055-491c368b37db", "fitness": "-inf", "name": "GPSurrogateOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GPSurrogateOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel=None):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        if kernel is None:\n            self.kernel = C(1.0, constant_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=9)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x, gp):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        return mu - 2 * sigma\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initial sampling\n        self.X = np.random.uniform(lb, ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        evals = self.n_initial_samples\n\n        best_idx = np.argmin(self.y)\n        self.f_opt = self.y[best_idx]\n        self.x_opt = self.X[best_idx]\n        \n        while evals < self.budget:\n            self.gp.fit(self.X, self.y)\n\n            # Find the next point to evaluate by maximizing the acquisition function\n            x_next = None\n            best_acq = np.inf\n            \n            for _ in range(100): # Try 100 random points\n                x_candidate = np.random.uniform(lb, ub, size=self.dim)\n                acq_value = self.acquisition_function(x_candidate, self.gp)\n\n                if acq_value < best_acq:\n                    best_acq = acq_value\n                    x_next = x_candidate\n\n            f_next = func(x_next)\n            evals += 1\n\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 11, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, constant_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 11, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, constant_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4285ee88-af51-4de5-b01b-6c57c12958b5", "fitness": 0.3326334015790959, "name": "AdaptiveMutationOptimizer", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveMutationOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.mutation_rate = initial_mutation_rate\n        self.success_history = []  # Store successful mutation rates\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation: Gaussian or Cauchy\n                if np.random.rand() < 0.5:  # 50% chance of Gaussian mutation\n                    mutation = np.random.normal(0, self.mutation_rate, size=self.dim)\n                else:  # 50% chance of Cauchy mutation\n                    mutation = np.random.standard_cauchy(size=self.dim) * self.mutation_rate\n                    \n                trial_vector = population[i] + mutation\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                        self.success_history.append(self.mutation_rate) # Store the mutation rate when successful\n\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adaptive mutation rate update\n            if self.success_history:\n                self.mutation_rate = np.mean(self.success_history)\n                self.success_history = [] # Reset history\n            else:\n                # If no improvements, increase the mutation rate to explore more\n                self.mutation_rate *= 1.1\n\n            self.mutation_rate = np.clip(self.mutation_rate, 0.001, 1.0) # Constrain the mutation rate\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveMutationOptimizer scored 0.333 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15483870765995167, 0.22093504877833614, 0.323560713234347, 0.34505024532627127, 0.2506080113811163, 0.3046858533292881, 0.26649507060658184, 0.2791915203870857, 0.22948044676693913, 0.18148541244844585, 0.3507165796693743, 0.9827231566079784, 0.25512980802436236, 0.26044475659742883, 0.6579308554355963, 0.30753181529694373, 0.27070903044339933, 0.34536597435579863, 0.18658451617197602, 0.47920050906069744]}, "task_prompt": ""}
{"id": "eb31861b-0182-446c-8f69-a78f2be2b575", "fitness": "-inf", "name": "GaussianProcessOptimizer", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimizer:\n    def __init__(self, budget=10000, dim=10, n_initial=10, xi=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial = n_initial\n        self.xi = xi\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n    def acquisition(self, X, gp, y_max, xi):\n        mu, sigma = gp.predict(X, return_std=True)\n        sigma = np.maximum(sigma, 1e-9)\n        imp = mu - y_max - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gp, y_max, bounds, xi, n_restarts=25):\n        def min_obj(X):\n            return -self.acquisition(X.reshape(-1, self.dim), gp, y_max, xi)\n\n        best_min = np.inf\n        best_x = None\n\n        for _ in range(n_restarts):\n            x0 = np.random.uniform(bounds.lb, bounds.ub, size=self.dim)\n            res = minimize(min_obj, x0, method='L-BFGS-B', bounds=bounds)\n            if res.fun < best_min:\n                best_min = res.fun\n                best_x = res.x\n\n        return best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        bounds = func.bounds\n\n        # Initial sampling\n        X_init = np.random.uniform(lb, ub, size=(self.n_initial, self.dim))\n        y_init = np.array([func(x) for x in X_init])\n        evals = self.n_initial\n\n        self.gp.fit(X_init, y_init)\n        y_max = y_init.min()\n        self.f_opt = y_max\n        self.x_opt = X_init[np.argmin(y_init)]\n\n        while evals < self.budget:\n            # Propose new location\n            x_new = self.propose_location(self.gp, y_max, bounds, self.xi)\n\n            # Evaluate function\n            f_new = func(x_new)\n            evals += 1\n\n            # Update GP\n            X_init = np.vstack((X_init, x_new))\n            y_init = np.append(y_init, f_new)\n            self.gp.fit(X_init, y_init)\n\n            # Update best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                y_max = f_new # Update y_max\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 13, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 13, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4cc39641-9338-4eb1-b0a3-cae8256fd2a0", "fitness": 0.0, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=30, inertia=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)/50, abs(ub-lb)/50, size=(self.pop_size, self.dim)) #Initialize small velocities\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        \n        global_best_idx = np.argmin(fitness)\n        self.f_opt = fitness[global_best_idx]\n        self.x_opt = population[global_best_idx]\n        global_best_position = np.copy(self.x_opt)\n\n        stagnation_counter = 0\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = np.copy(population[i])\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i]\n                        global_best_position = np.copy(self.x_opt)\n                        stagnation_counter = 0 #Reset stagnation counter\n            \n            stagnation_counter += self.pop_size\n            \n            # Stagnation Check and Restart\n            if stagnation_counter > self.stagnation_threshold:\n                # Restart a portion of the population\n                restart_indices = np.random.choice(self.pop_size, size=self.pop_size // 4, replace=False)\n                population[restart_indices] = np.random.uniform(lb, ub, size=(self.pop_size // 4, self.dim))\n                velocities[restart_indices] = np.random.uniform(-abs(ub-lb)/50, abs(ub-lb)/50, size=(self.pop_size // 4, self.dim))\n                fitness[restart_indices] = np.array([func(x) for x in population[restart_indices]])\n                evals += self.pop_size // 4\n                \n                #Update personal bests of the restarted population\n                for i in restart_indices:\n                    personal_best_positions[i] = np.copy(population[i])\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = population[i]\n                        global_best_position = np.copy(self.x_opt)\n                \n                stagnation_counter = 0\n\n            # Adaptive Inertia (Linear Decrease)\n            self.inertia = 0.7 - (0.7 - 0.2) * (evals / self.budget)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "4af710c1-0a2e-4040-bc6c-2c2e3e9ce543", "fitness": 0.29436284052851647, "name": "StochasticGradientSwarm", "description": "No description provided.", "code": "import numpy as np\n\nclass StochasticGradientSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, num_neighbors=5, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.num_neighbors = num_neighbors\n        self.momentum = momentum\n        self.velocities = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        if self.velocities is None:\n            self.velocities = np.zeros_like(population)\n\n        while evals < self.budget:\n            for i in range(self.pop_size):\n                # Estimate Gradient\n                grad_estimate = np.zeros(self.dim)\n                for _ in range(self.num_neighbors):\n                    delta = np.random.normal(0, self.step_size, self.dim)\n                    x_neighbor = np.clip(population[i] + delta, lb, ub)\n                    f_neighbor = func(x_neighbor)\n                    evals += 1\n\n                    grad_estimate += (f_neighbor - fitness[i]) * delta\n\n                    if f_neighbor < self.f_opt:\n                        self.f_opt = f_neighbor\n                        self.x_opt = x_neighbor\n\n                    if evals >= self.budget:\n                        return self.f_opt, self.x_opt\n\n                grad_estimate /= self.num_neighbors * self.step_size**2  #approximation of the gradient\n\n\n                # Update Velocity and Position\n                self.velocities[i] = self.momentum * self.velocities[i] - self.step_size * grad_estimate # Gradient Descent with Momentum\n                new_position = population[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                new_fitness = func(new_position)\n                evals += 1\n                \n                if new_fitness < fitness[i]:\n                    population[i] = new_position\n                    fitness[i] = new_fitness\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n\n                if evals >= self.budget:\n                    return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm StochasticGradientSwarm scored 0.294 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13337208061928518, 0.28314560570175407, 0.24303624345754482, 0.3732099796827093, 0.26513800022594314, 0.17706243518465326, 0.2379813360633869, 0.2475385705756875, 0.19454344263791634, 0.17518276887164008, 0.26577427396751696, 0.9992615846758195, 0.26386023375392675, 0.1993083935101566, 0.437509932269473, 0.2622436931610008, 0.24998007936939493, 0.27967244368710664, 0.19078354106767303, 0.4086521720877393]}, "task_prompt": ""}
{"id": "85af3c01-23b6-46d9-b632-8a853bb5bfa2", "fitness": 0.5249198248550899, "name": "PSO_CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass PSO_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, pso_inertia=0.7, pso_cognitive=1.4, pso_social=1.4, cmaes_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.pso_inertia = pso_inertia\n        self.pso_cognitive = pso_cognitive\n        self.pso_social = pso_social\n        self.cmaes_sigma = cmaes_sigma\n\n        self.particles = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = np.full(self.pop_size, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.cmaes_mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        self.cmaes_covariance = np.eye(self.dim)\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initialize PSO\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.particles[i])\n            self.budget -= 1\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.particles[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            # PSO update\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.velocities[i] = (self.pso_inertia * self.velocities[i] +\n                                      self.pso_cognitive * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.pso_social * r2 * (self.global_best_position - self.particles[i]))\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lb, self.ub)\n\n            # Evaluate PSO particles\n            for i in range(self.pop_size):\n                f = func(self.particles[i])\n                self.budget -= 1\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = self.particles[i].copy()\n                    self.f_opt = self.global_best_fitness\n                    self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n            # CMA-ES update (every few iterations)\n            if self.budget % (self.pop_size * 5) == 0:\n                # Sample new solutions from CMA-ES\n                new_solutions = np.random.multivariate_normal(self.cmaes_mean, self.cmaes_sigma * self.cmaes_covariance, size=self.pop_size)\n                new_solutions = np.clip(new_solutions, self.lb, self.ub)\n                new_fitness = np.zeros(self.pop_size)\n\n                for i in range(self.pop_size):\n                    new_fitness[i] = func(new_solutions[i])\n                    self.budget -= 1\n                    if new_fitness[i] < self.global_best_fitness:\n                        self.global_best_fitness = new_fitness[i]\n                        self.global_best_position = new_solutions[i].copy()\n                        self.f_opt = self.global_best_fitness\n                        self.x_opt = self.global_best_position\n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n\n                # Update CMA-ES parameters\n                best_index = np.argmin(new_fitness)\n                self.cmaes_mean = new_solutions[best_index]\n                # Simple covariance update (can be replaced with more sophisticated methods)\n                self.cmaes_covariance = np.cov(new_solutions.T)\n                if np.linalg.det(self.cmaes_covariance) <= 0:\n                    self.cmaes_covariance = np.eye(self.dim)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PSO_CMAES scored 0.525 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15262303313251924, 0.16534418830785802, 0.8413100116812267, 0.1977270109193795, 0.3043599400321464, 0.8821520830308971, 0.3466245042645363, 0.5461973813587144, 0.8749614088527058, 0.8397630756145812, 0.2822998653612574, 0.9995037604885082, 0.268660394890171, 0.3027683972180235, 0.738620921550499, 0.35543475170100713, 0.4086950993726962, 0.9307997415113825, 0.1880690784835144, 0.8724818493301757]}, "task_prompt": ""}
{"id": "ee83894e-e60e-473f-9bed-4e2c0581f42a", "fitness": 0.5074598323019786, "name": "ReinforcementLearningEA", "description": "No description provided.", "code": "import numpy as np\n\nclass ReinforcementLearningEA:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.1, gamma=0.9, exploration_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.gamma = gamma\n        self.exploration_rate = exploration_rate\n        self.Q = {}  # Q-table: Q[(state, action)] = value\n\n    def _get_state(self, population):\n        # State: average pairwise distance + best fitness\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        avg_distance = np.mean(distances) if distances else 0.0\n        return (round(avg_distance, 2), round(self.f_opt, 5))\n\n    def _get_reward(self, old_fitness, new_fitness, population, old_population):\n        fitness_improvement = np.mean(old_fitness) - np.mean(new_fitness)\n        diversity_reward = self._calculate_diversity_reward(population, old_population)\n        return fitness_improvement + 0.1 * diversity_reward\n\n    def _calculate_diversity_reward(self, population, old_population):\n        diversity_improvement = self._calculate_population_diversity(population) - self._calculate_population_diversity(old_population)\n        return diversity_improvement\n        \n    def _calculate_population_diversity(self, population):\n        distances = []\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        avg_distance = np.mean(distances) if distances else 0.0\n        return avg_distance\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            old_population = population.copy()\n            old_fitness = fitness.copy()\n            state = self._get_state(population)\n\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Epsilon-greedy action selection\n                if np.random.rand() < self.exploration_rate:\n                    action = np.random.choice(['mutation', 'crossover', 'random_restart'])\n                else:\n                    # Choose action with highest Q-value for the current state\n                    q_values = [self.Q.get((state, a), 0) for a in ['mutation', 'crossover', 'random_restart']]\n                    action = ['mutation', 'crossover', 'random_restart'][np.argmax(q_values)]\n\n                if action == 'mutation':\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = population[idxs]\n                    mutant = x1 + 0.5 * (x2 - x3)\n                    mutant = np.clip(mutant, lb, ub)\n                    trial = mutant\n\n                elif action == 'crossover':\n                    idxs = np.random.choice(self.pop_size, 2, replace=False)\n                    parent1, parent2 = population[idxs]\n                    alpha = np.random.rand(self.dim)\n                    trial = alpha * parent1 + (1 - alpha) * parent2\n                    trial = np.clip(trial, lb, ub)\n\n                elif action == 'random_restart':\n                    trial = np.random.uniform(lb, ub)\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n                \n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n\n            reward = self._get_reward(old_fitness, fitness, population, old_population)\n            new_state = self._get_state(population)\n\n            # Update Q-table for each individual\n            for i in range(self.pop_size):\n                if np.array_equal(population[i], new_population[i]):\n                    continue # Individual did not change, no reward to propagate\n                q_values = [self.Q.get((state, a), 0) for a in ['mutation', 'crossover', 'random_restart']]\n                action = ['mutation', 'crossover', 'random_restart'][np.argmax(q_values)]\n\n                old_value = self.Q.get((state, action), 0)\n                next_max = max([self.Q.get((new_state, a), 0) for a in ['mutation', 'crossover', 'random_restart']])\n\n                new_value = (1 - self.lr) * old_value + self.lr * (reward + self.gamma * next_max)\n                self.Q[(state, action)] = new_value\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ReinforcementLearningEA scored 0.507 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.7289117212093388, 0.8337619367385141, 0.6597978122235768, 0.36822661687825753, 0.2570650845590372, 0.4944604443192837, 0.6674430713421498, 0.3438273372012568, 0.5061798187504235, 0.2572338745586349, 0.2743671864414432, 0.9927675081429926, 0.5011501602610249, 0.6981979097639548, 0.6678129817805698, 0.38411189986224403, 0.40122202738263857, 0.24412438250126733, 0.3925162233431144, 0.4760186487798459]}, "task_prompt": ""}
{"id": "907839c6-20ec-4554-a581-4290a22b6065", "fitness": 0.0, "name": "MomentumPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass MomentumPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, momentum=0.9, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.momentum = momentum\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.zeros_like(population)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            global_best_idx = np.argmin(personal_best_fitness)\n            global_best_position = personal_best_positions[global_best_idx]\n\n            for i in range(self.pop_size):\n                # Update velocities with momentum\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n                velocities[i] = self.momentum * velocities[i] + self.w * velocities[i] + cognitive_component + social_component\n\n                # Update positions\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate fitness\n                f = func(population[i])\n                evals += 1\n\n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = population[i]\n\n                # Random Restart\n                if np.random.rand() < self.restart_prob:\n                    population[i] = np.random.uniform(lb, ub, size=(self.dim))\n                    velocities[i] = np.zeros(self.dim)\n                    f = func(population[i])\n                    evals += 1\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = population[i]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MomentumPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "95088182-27c0-45cc-b408-0fcf771996b5", "fitness": 0.8140174851604863, "name": "AdaptiveDEwithCMAandRestart", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDEwithCMAandRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_trigger=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_trigger = restart_trigger\n        self.cma_learning_rate = cma_learning_rate\n        self.mean = None\n        self.covariance = None\n        self.success_history = []\n        self.stagnation_counter = 0\n        self.restart_threshold = budget // 100 # Number of iterations without improvement before restart\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        self.mean = np.random.uniform(lb, ub, size=self.dim)\n        self.covariance = np.eye(self.dim) * ((ub - lb) / 2)**2  # Initialize with a diagonal covariance matrix\n\n        population = self.initialize_population(lb, ub)\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while evals < self.budget:\n            old_f_opt = self.f_opt\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                trial = np.clip(trial, lb, ub)\n\n                # Selection\n                f_trial = func(trial)\n                evals += 1\n\n                if f_trial < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = f_trial\n                    self.success_history.append(f_trial)\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # CMA-ES adaptation of search distribution\n            if self.success_history:\n                self.mean = np.mean(population, axis=0)\n                \n                # Sample a direction from the covariance matrix\n                z = np.random.normal(0, 1, self.dim)\n                direction = np.dot(np.linalg.cholesky(self.covariance), z)\n\n                # Update covariance matrix (simplified)\n                self.covariance = (1 - self.cma_learning_rate) * self.covariance + self.cma_learning_rate * np.outer(direction, direction)\n\n                self.success_history = []\n\n            # Stagnation detection and restart\n            if self.f_opt >= old_f_opt:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.restart_threshold:\n                population = self.initialize_population(lb, ub)\n                fitness = np.array([func(x) for x in population])\n                evals += self.pop_size\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < self.f_opt:\n                    self.f_opt = fitness[best_idx]\n                    self.x_opt = population[best_idx]\n                self.mean = np.random.uniform(lb, ub, size=self.dim)\n                self.covariance = np.eye(self.dim) * ((ub - lb) / 2)**2\n                self.stagnation_counter = 0\n\n            # Adapt F and CR (simplified)\n            self.F = 0.5 + 0.3 * np.random.rand()\n            self.CR = 0.6 + 0.4 * np.random.rand()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDEwithCMAandRestart scored 0.814 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.5742232608028877, 0.7074195554405274, 0.8025779860759539, 0.9418214600934147, 0.8847936320884473, 0.8853054550632304, 0.7855807645307248, 0.8066138982099847, 0.8630824657151296, 0.8485510740408876, 0.9151121723531493, 0.999648636354304, 0.5548114790622598, 0.8523001809594695, 0.9520544734481529, 0.8844136300408322, 0.808742195928672, 0.9051734439927706, 0.7990775682792264, 0.5090463707296994]}, "task_prompt": ""}
{"id": "069656b6-2efe-45f0-b938-4e86263216fa", "fitness": "-inf", "name": "AdaptiveCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_sigma=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.initial_sigma = initial_sigma\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize variables\n        mean = np.random.uniform(lb, ub, size=self.dim)\n        sigma = self.initial_sigma\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n        chiN = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n        # Parameters\n        c_sigma = (self.mu / self.dim) / 4\n        c_c = (4 + self.mu / self.dim) / (self.dim + 4)\n        c_mu = self.mu / (self.dim**2)\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim+1)) - 1) + c_sigma\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        c_mu_eff = min(1 - c_1, c_mu * (self.mu - 1 + 1/self.mu))\n        \n        evals = 0\n        while evals < self.budget:\n            # Generate and evaluate population\n            Z = np.random.multivariate_normal(np.zeros(self.dim), C, size=self.pop_size)\n            X = mean + sigma * Z\n            X = np.clip(X, lb, ub)\n            fitness = np.array([func(x) for x in X])\n            evals += self.pop_size\n\n            # Sort population\n            idx = np.argsort(fitness)\n            X = X[idx]\n            fitness = fitness[idx]\n\n            # Update mean\n            weights = np.log(self.mu + 1) - np.log(np.arange(1, self.mu + 1))\n            weights = weights / np.sum(weights)\n            mean_old = np.copy(mean)\n            mean = np.sum(weights[:, None] * X[:self.mu], axis=0)\n\n            # Update evolution paths\n            z_mean = np.mean(Z[idx[:self.mu]], axis=0)\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * c_mu_eff) * np.linalg.inv(np.linalg.cholesky(C)) @ (mean - mean_old) / sigma\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c) * c_mu_eff) * (mean - mean_old) / sigma\n            \n            # Adapt covariance matrix\n            C = (1 - c_1 - c_mu_eff) * C + c_1 * (pc[:, None] @ pc[None, :])\n            C += c_mu * np.sum(weights[:, None, None] * (Z[idx[:self.mu], :, None] @ Z[idx[:self.mu], None, :]), axis=0)\n\n            # Adapt step size\n            sigma *= np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps)/chiN - 1))\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = X[0]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 148, in _raise_linalgerror_nonposdef, the following error occurred:\nLinAlgError: Matrix is not positive definite", "error": "In the code, line 148, in _raise_linalgerror_nonposdef, the following error occurred:\nLinAlgError: Matrix is not positive definite", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "2999e15b-582a-447f-8abd-38279659847a", "fitness": "-inf", "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, initial_pop_size=50, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = initial_pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.learning_rate = learning_rate\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.min_pop_size = 10\n        self.max_pop_size = 100\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.update_best()\n\n    def update_best(self):\n        global_best_index = np.argmin(self.fitness)\n        if self.fitness[global_best_index] < self.f_opt:\n            self.f_opt = self.fitness[global_best_index]\n            self.x_opt = self.population[global_best_index].copy()\n\n    def adjust_population_size(self):\n        if np.random.rand() < 0.1:  # Adjust population size probabilistically\n            if np.random.rand() < 0.5:\n                self.pop_size = min(self.pop_size + 5, self.max_pop_size)\n            else:\n                self.pop_size = max(self.pop_size - 5, self.min_pop_size)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.adjust_population_size()\n            new_population = np.zeros_like(self.population)\n            new_fitness = np.zeros_like(self.fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + self.f * (x2[j] - x3[j])\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n\n                    # Parameter Adaptation\n                    if np.random.rand() < self.learning_rate:\n                        self.cr = np.random.uniform(0.1, 0.9)\n                        self.f = np.random.uniform(0.1, 0.9)\n\n                else:\n                    new_population[i] = self.population[i]\n                    new_fitness[i] = self.fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            self.population = new_population\n            self.fitness = new_fitness\n            self.update_best()\n\n            # Global Adaptation of Parameters\n            self.cr = np.clip(self.cr + np.random.normal(0, 0.05), 0.1, 0.9)\n            self.f = np.clip(self.f + np.random.normal(0, 0.05), 0.1, 0.9)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 52, in __call__, the following error occurred:\nIndexError: index 53 is out of bounds for axis 0 with size 50\nOn line: x1, x2, x3 = self.population[idxs]", "error": "In the code, line 52, in __call__, the following error occurred:\nIndexError: index 53 is out of bounds for axis 0 with size 50\nOn line: x1, x2, x3 = self.population[idxs]", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "b6b6e60a-8ddd-4eb2-ae1d-abb965ee65ae", "fitness": 0.45056656747359786, "name": "DiversityAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass DiversityAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lb=-5.0, ub=5.0, initial_cr=0.5, initial_f=0.7, exploration_decay=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = lb\n        self.ub = ub\n        self.cr = initial_cr\n        self.f = initial_f\n        self.exploration_decay = exploration_decay\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find global best\n        global_best_index = np.argmin(fitness)\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = population[global_best_index].copy()\n\n        exploration_rate = 1.0\n\n        while self.budget > 0:\n            new_population = np.zeros_like(population)\n            new_fitness = np.zeros_like(fitness)\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.pop_size):\n                # Mutation scaling based on diversity\n                mutation_scale = self.f * (1 + exploration_rate * diversity)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n\n                # Crossover\n                trial_vector = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == j_rand:\n                        trial_vector[j] = x1[j] + mutation_scale * (x2[j] - x3[j])\n                \n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n\n                f = func(trial_vector)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    new_population[i] = trial_vector\n                    new_fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector.copy()\n                    \n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            fitness = new_fitness\n            \n            # Decay exploration rate\n            exploration_rate *= self.exploration_decay\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DiversityAdaptiveDE scored 0.451 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1475168383241382, 0.24570561949055358, 0.573288089937637, 0.24503039518670278, 0.5487837174928474, 0.6517976165933673, 0.26713906169759427, 0.519075803555333, 0.5369604131304091, 0.40586763114516455, 0.5997750837338676, 0.9997376496072484, 0.2745199971922557, 0.2795071961838117, 0.6573218957230185, 0.34621057827113844, 0.41966253365954775, 0.6463292581640383, 0.203633139281584, 0.44346883110170054]}, "task_prompt": ""}
