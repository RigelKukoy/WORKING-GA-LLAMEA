{"id": "5442bcf1-43df-4ed0-8995-07f8f34e32ee", "fitness": 0.6146986337002502, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Scaling factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Adapt F and CR dynamically (example - based on fitness variance)\n            fitness_std = np.std(fitness)\n            if fitness_std > 0.1:  # Example threshold\n                self.F = np.clip(self.F + np.random.normal(0, 0.05), 0.1, 1.0)\n                self.CR = np.clip(self.CR + np.random.normal(0, 0.05), 0.1, 1.0)\n\n            if self.budget <= 0:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.615 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18463230184960544, 0.24755541611869336, 0.5628456741561187, 0.877153557297081, 0.7068040421737825, 0.5500413228783485, 0.6258457146955481, 0.3933954720534917, 0.5767536358348044, 0.7713132892195493, 0.8621167857365878, 0.9973504663209005, 0.2560441767526943, 0.7144088229939112, 0.9211038063735567, 0.7863676212352672, 0.5486588133524511, 0.8043227140756647, 0.35060669513524023, 0.5566523457517052]}, "task_prompt": ""}
{"id": "0d918742-a34b-4a11-bfdd-560878e0f0d5", "fitness": 0.7516026263664409, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)  # Adaptive population size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update mutation factor\n                    if np.random.rand() < 0.1:\n                        self.F = np.random.uniform(0.4, 0.9)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.752 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.38283632911825727, 0.6568865178998928, 0.768538130512967, 0.8888055138853795, 0.8057943008244519, 0.8606329819231074, 0.7655216656689707, 0.7498331737205386, 0.8426633368506004, 0.8045966951338211, 0.8961010337705239, 0.996654832592229, 0.6656359994838275, 0.8180546736690592, 0.9398551637779342, 0.8480707529976602, 0.7135896252836764, 0.8865045791791127, 0.21982743577499053, 0.52164978526182]}, "task_prompt": ""}
{"id": "86b52631-03f7-48d9-bf88-5b7ef64e25c5", "fitness": 0.3190470668502792, "name": "AdaptiveGaussianHillClimber", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveGaussianHillClimber:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, step_size_adaptation_factor=0.9, success_threshold=0.2, restart_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.step_size_adaptation_factor = step_size_adaptation_factor\n        self.success_threshold = success_threshold\n        self.restart_probability = restart_probability\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.f_opt = f\n        self.x_opt = x\n        successes = 0\n        evaluations = 1\n\n        while evaluations < self.budget:\n            # Generate a mutated solution\n            x_new = x + self.step_size * np.random.normal(0, 1, size=self.dim)\n\n            # Clip the solution to stay within bounds\n            x_new = np.clip(x_new, self.lb, self.ub)\n\n            # Evaluate the mutated solution\n            f_new = func(x_new)\n            evaluations += 1\n\n            if f_new < f:\n                # Accept the mutated solution\n                x = x_new\n                f = f_new\n                successes += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt step size\n            if evaluations % 100 == 0:\n                success_rate = successes / 100\n                if success_rate > self.success_threshold:\n                    self.step_size /= self.step_size_adaptation_factor # decrease step size\n                else:\n                    self.step_size *= self.step_size_adaptation_factor # increase step size\n                successes = 0\n\n            # Restart with a small probability\n            if np.random.rand() < self.restart_probability:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                evaluations +=1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianHillClimber scored 0.319 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15107310438852106, 0.20649372829331536, 0.2999936256021075, 0.28301936636539315, 0.23146480150145665, 0.26388171982529085, 0.2546560871835801, 0.2541528221886651, 0.23492116223189707, 0.16251904728974442, 0.32695898232487974, 0.9991871616513335, 0.2632633193323016, 0.23414801737596924, 0.6235271327039993, 0.3087372633709726, 0.2680418252872012, 0.33141342709442356, 0.20184339655202077, 0.48164534644251145]}, "task_prompt": ""}
{"id": "3a4f8936-b976-4765-a204-9885751e3b04", "fitness": "-inf", "name": "AdaptivePopulationSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n\n    def evaluate_population(self, func, population):\n        fitness = np.array([func(x) for x in population])\n        return fitness\n\n    def select_parents(self, population, fitness, num_parents=2):\n        # Fitness-based selection with diversity preservation\n        probabilities = np.exp(-fitness / np.std(fitness)) if np.std(fitness) > 0 else np.ones_like(fitness) / len(fitness)\n        probabilities /= np.sum(probabilities)\n\n        selected_indices = np.random.choice(len(population), size=num_parents, replace=False, p=probabilities)\n        return population[selected_indices]\n\n    def crossover(self, parents, crossover_rate=0.8):\n        if np.random.rand() < crossover_rate:\n            alpha = np.random.rand(self.dim)\n            child = alpha * parents[0] + (1 - alpha) * parents[1]\n        else:\n            child = parents[np.random.randint(0, 2)].copy()\n        return child\n\n    def mutate(self, child, mutation_rate=0.1):\n        for i in range(self.dim):\n            if np.random.rand() < mutation_rate:\n                child[i] += self.step_size * np.random.normal(0, 1)\n        child = np.clip(child, self.lb, self.ub)\n        return child\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n        \n        population = self.initialize_population()\n        fitness = self.evaluate_population(func, population)\n        eval_count += self.pop_size\n\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index].copy()\n                \n\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.pop_size):\n                parents = self.select_parents(population, fitness)\n                child = self.crossover(parents)\n                child = self.mutate(child)\n                new_population.append(child)\n\n            new_population = np.array(new_population)\n            new_fitness = self.evaluate_population(func, new_population)\n            eval_count += self.pop_size\n            \n            combined_population = np.vstack((population, new_population))\n            combined_fitness = np.concatenate((fitness, new_fitness))\n\n            #Elitism: Keep the best individual\n            best_idx = np.argmin(combined_fitness)\n            best_x = combined_population[best_idx]\n            best_f = combined_fitness[best_idx]\n            \n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x.copy()\n                \n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.pop_size]]\n            fitness = combined_fitness[sorted_indices[:self.pop_size]]\n            \n            self.step_size *= 0.99  # Adaptive step size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 995, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities contain NaN", "error": "In the code, line 995, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities contain NaN", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "fb810dfe-9b6e-4cec-9d14-ed055db037aa", "fitness": 0.4191853194413824, "name": "HybridPSO_DE", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, pso_weight=0.7, de_cross_rate=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.pso_weight = pso_weight\n        self.de_cross_rate = de_cross_rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n    def pso_step(self, func):\n        inertia_weight = self.pso_weight  # Inertia weight\n        cognitive_coeff = 2.0  # Cognitive coefficient\n        social_coeff = 2.0  # Social coefficient\n\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n\n        self.velocities = (inertia_weight * self.velocities +\n                           cognitive_coeff * r1 * (self.personal_best_positions - self.population) +\n                           social_coeff * r2 * (self.global_best_position - self.population))\n\n        self.population += self.velocities\n\n        # Clip to boundaries\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n        new_fitness = np.array([func(x) for x in self.population])\n        self.eval_count += self.pop_size\n        \n        for i in range(self.pop_size):\n            if new_fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = new_fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if new_fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = new_fitness[i]\n                self.global_best_position = self.population[i].copy()\n\n\n    def de_step(self, func):\n        mutation_factor = 0.5\n        crossover_rate = self.de_cross_rate\n\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x_r1, x_r2, x_r3 = self.population[idxs]\n\n            v_trial = x_r1 + mutation_factor * (x_r2 - x_r3)\n            v_trial = np.clip(v_trial, self.lb, self.ub)\n\n            u_trial = np.zeros(self.dim)\n            j_rand = np.random.randint(0, self.dim)\n\n            for j in range(self.dim):\n                if np.random.rand() <= crossover_rate or j == j_rand:\n                    u_trial[j] = v_trial[j]\n                else:\n                    u_trial[j] = self.population[i][j]\n            \n            f_trial = func(u_trial)\n            self.eval_count += 1\n            \n            if f_trial < self.fitness[i]:\n                self.population[i] = u_trial.copy()\n                self.fitness[i] = f_trial\n                if f_trial < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f_trial\n                    self.personal_best_positions[i] = u_trial.copy()\n                if f_trial < self.global_best_fitness:\n                    self.global_best_fitness = f_trial\n                    self.global_best_position = u_trial.copy()\n\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            if np.random.rand() < 0.5:\n                self.pso_step(func)\n            else:\n                self.de_step(func)\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.419 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.17052340834870106, 0.3160017155680894, 0.41217699852153755, 0.2594567495811907, 0.29315124081629707, 0.5316855798460904, 0.33575416583523265, 0.233094032928577, 0.3115649613030774, 0.29349769254985525, 0.7509011399180049, 0.9989202253893591, 0.2826893194438026, 0.47137188393660534, 0.6485559867625714, 0.3531939467137102, 0.3861567434341239, 0.6083880766759853, 0.21054968947031472, 0.5160728317845211]}, "task_prompt": ""}
{"id": "2d69992e-0f5f-4a8d-a40f-8fe2c9009b87", "fitness": 0.2618455810128969, "name": "AdaptiveRandomSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveRandomSearch:\n    def __init__(self, budget=10000, dim=10, local_search_prob = 0.7):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        lb = np.full(self.dim, self.lb)\n        ub = np.full(self.dim, self.ub)\n        \n        for i in range(self.budget):\n            if np.random.rand() < self.local_search_prob or self.x_opt is None:\n                x = np.random.uniform(lb, ub)\n            else:\n                # Local search around the current best\n                width = (ub - lb) / 10  # Adjust step size\n                new_lb = np.maximum(self.lb, self.x_opt - width)\n                new_ub = np.minimum(self.ub, self.x_opt + width)\n                x = np.random.uniform(new_lb, new_ub)  # Sample around best\n            \n            f = func(x)\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n                # Shrink bounds towards the current best\n                shrink_factor = 0.1 #How quickly the boundaries shrink\n                lb = np.maximum(self.lb, self.x_opt - shrink_factor*(self.x_opt - np.full(self.dim, self.lb))) \n                ub = np.minimum(self.ub, self.x_opt + shrink_factor*(np.full(self.dim, self.ub) - self.x_opt))\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveRandomSearch scored 0.262 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1095435439002509, 0.23534118149162297, 0.4571194996050304, 0.1975986579370128, 0.16925178171647604, 0.15419695961123014, 0.22101129890946514, 0.24897755605350058, 0.2436784988578934, 0.11876074681818538, 0.8828706828023086, 0.1948533328551152, 0.28771242588341117, 0.1871440948558315, 0.4103027252549927, 0.31867582897382074, 0.3476905928784302, 0.1688007177670413, 0.11018540784107467, 0.17319608624524463]}, "task_prompt": ""}
{"id": "da725011-bb4e-45ee-8cd4-b322363a4b69", "fitness": 0.0, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.Cr = Cr # Crossover rate\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        self.f_opt = self.fitness[best_idx]\n        self.x_opt = self.pop[best_idx]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.pop[idxs]\n                x_mutated = self.pop[i] + self.F * (x_r1 - x_r2)\n\n                # Ensure bounds\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.eval_count += 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.pop[i] = x_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n                # Adaptive Parameter Control (Example: Adjust F based on success)\n                if self.eval_count % self.pop_size == 0:\n                   success_rate = np.sum(self.fitness < np.array([func(x) for x in self.pop])) / self.pop_size\n                   if success_rate > 0.2:\n                        self.F *= 0.9  # Reduce F if too many improvements\n                   elif success_rate < 0.05:\n                        self.F *= 1.1 # Increase F if too few improvements\n                   self.F = np.clip(self.F, 0.1, 1.0) #Ensure F within range\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "e0eade61-f329-42b7-9857-d9f3cc7fe15f", "fitness": 0.25379483566499467, "name": "AdaptiveHillClimber", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveHillClimber:\n    def __init__(self, budget=10000, dim=10, sigma=0.1, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.restart_prob = restart_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        while self.budget > 0:\n            if np.random.rand() < self.restart_prob:\n                x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                f = func(x)\n                self.budget -= 1\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                continue\n\n            x_new = x + np.random.normal(0, self.sigma, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f:\n                x = x_new\n                f = f_new\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            else:\n                self.sigma *= 0.95  # Reduce step size if no improvement\n            \n            if self.budget <= 0:\n              break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHillClimber scored 0.254 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.10159134938625425, 0.1484127395582474, 0.25305050146385866, 0.17228005421860348, 0.18652898700988596, 0.20747391904085266, 0.20195841317877494, 0.18648491359255537, 0.17246088034825002, 0.1459280919632966, 0.20603522813172248, 0.987377541768039, 0.20233603100226716, 0.17705993643998008, 0.5098070746915035, 0.2488550402567168, 0.19110568108744508, 0.20565316395284183, 0.1415235029567793, 0.4299736632520179]}, "task_prompt": ""}
{"id": "4522cf10-ccf2-447e-b842-06813e3521ed", "fitness": 0.411375752512016, "name": "AdaptiveStochasticSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveStochasticSearch:\n    def __init__(self, budget=10000, dim=10, initial_step_size=1.0, success_rate_threshold=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n        if f < self.f_opt:\n            self.f_opt = f\n            self.x_opt = x\n\n        while self.budget > 0:\n            # Generate a random step\n            direction = np.random.normal(0, 1, size=self.dim)\n            direction = direction / np.linalg.norm(direction)  # Normalize\n\n            # Take a step in the random direction\n            x_new = x + self.step_size * direction\n            x_new = np.clip(x_new, self.lb, self.ub)  # Clip to boundaries\n\n            # Evaluate the new position\n            f_new = func(x_new)\n            self.budget -= 1\n            self.iteration_count += 1\n\n            # Check for improvement\n            if f_new < f:\n                self.success_count += 1\n                x = x_new\n                f = f_new\n\n                # Update best solution\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt step size based on success rate\n            if self.iteration_count % 100 == 0:\n                success_rate = self.success_count / 100\n                if success_rate > self.success_rate_threshold:\n                    self.step_size *= 1.1  # Increase step size\n                else:\n                    self.step_size *= 0.9  # Decrease step size\n                self.success_count = 0\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveStochasticSearch scored 0.411 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16975971157671954, 0.15317759423266253, 0.586849291944658, 0.8581802124149279, 0.5925019712465609, 0.6496165887084293, 0.2884853993587638, 0.44582936878982393, 0.6011138126813784, 0.13613362306656018, 0.8657577792149567, 0.1858349695675765, 0.22251410782618486, 0.34960924820742956, 0.5875480670205058, 0.641083320973944, 0.42428503102575543, 0.19821341745513887, 0.11556343889970122, 0.15545809602864136]}, "task_prompt": ""}
{"id": "db34d2c8-de65-4a1b-aa14-137ded2616ff", "fitness": 0.3095547671837679, "name": "SpiralDynamicAlgorithm", "description": "No description provided.", "code": "import numpy as np\n\nclass SpiralDynamicAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_param_a=0.1, spiral_param_r=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_param_a = spiral_param_a\n        self.spiral_param_r = spiral_param_r\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index].copy()\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Spiral movement\n                r = self.spiral_param_r\n                theta = np.random.uniform(-np.pi, np.pi, size=self.dim)\n                \n                # Ensure that theta has the correct shape for element-wise operations\n                spiral_move = self.spiral_param_a * np.exp(r * theta) * np.cos(theta) * (self.x_opt - population[i])\n                \n                new_position = population[i] + spiral_move\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                new_fitness = func(new_position)\n                self.budget -= 1\n                \n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    population[i] = new_position.copy()\n                    \n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position.copy()\n\n            # Update spiral parameters occasionally\n            if self.budget > 0 and self.budget % 500 == 0:\n                self.spiral_param_a *= 0.95  # Reduce spiral tightness\n                self.spiral_param_r *= 0.98  # Reduce spiral range\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SpiralDynamicAlgorithm scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08996932009129577, 0.19977733413324417, 0.3572270018307435, 0.2962251985496327, 0.21069809358143265, 0.21398012152435342, 0.23074149746768124, 0.22195865832261075, 0.2064293108042059, 0.16989680764464776, 0.2554725898676036, 0.9990927824317593, 0.2697036088224025, 0.19589888682678103, 0.6482474650800176, 0.31189736830791104, 0.2660927093760599, 0.3853290102096828, 0.19227124008915375, 0.4701863387141392]}, "task_prompt": ""}
{"id": "c86c25c7-6108-4ac2-a27c-81180db6ea1a", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, kernel='RBF'):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        if kernel == 'RBF':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        elif kernel == 'Matern':\n            self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * Matern(length_scale=1.0, length_scale_bounds=\"fixed\", nu=1.5)\n        else:\n            raise ValueError(\"Invalid kernel type. Choose 'RBF' or 'Matern'.\")\n\n    def acquisition_function(self, x, xi=0.01):\n        \"\"\"Expected Improvement acquisition function.\"\"\"\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        \n        # Avoid division by zero\n        sigma = np.maximum(sigma, 1e-9)\n        \n        imp = mu - self.y.min() - xi\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return -ei  # We want to maximize EI, but minimize function\n\n    def optimize_acquisition_function(self):\n        \"\"\"Optimizes the acquisition function to find the next sampling point.\"\"\"\n        bounds = [(self.lb, self.ub)] * self.dim\n        \n        # Start from multiple random points\n        x0 = np.random.uniform(self.lb, self.ub, size=(10, self.dim))\n        \n        best_x = None\n        best_acq = np.inf\n        \n        for start_point in x0:\n            res = minimize(self.acquisition_function, start_point, method='L-BFGS-B', bounds=bounds)\n            if res.fun < best_acq:\n                best_acq = res.fun\n                best_x = res.x\n        \n        return best_x\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_samples\n        \n        best_idx = np.argmin(self.y)\n        if self.y[best_idx] < self.f_opt:\n            self.f_opt = self.y[best_idx]\n            self.x_opt = self.X[best_idx]\n\n        # Gaussian process regression\n        self.gpr = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=0, alpha=1e-6) # Increased n_restarts_optimizer\n\n        while self.budget > 0:\n            # Fit the GP model\n            self.gpr.fit(self.X, self.y)\n\n            # Find the next point to sample using the acquisition function\n            x_next = self.optimize_acquisition_function()\n\n            # Evaluate the function at the new point\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 20, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 20, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "5ac063ef-e6e7-47a3-8255-8150a51d4a18", "fitness": "-inf", "name": "HybridPSO_NM", "description": "No description provided.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSO_NM:\n    def __init__(self, budget=10000, dim=10, swarm_size=10, pso_iters=100, nm_iters=5):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.pso_iters = pso_iters\n        self.nm_iters = nm_iters\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize PSO swarm\n        swarm = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_fitnesses = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n        self.budget -= self.swarm_size\n        \n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n\n        # PSO iterations\n        for i in range(self.pso_iters):\n            for j in range(self.swarm_size):\n                # Update velocity and position\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[j] = self.w * velocities[j] + \\\n                                 self.c1 * r1 * (personal_best_positions[j] - swarm[j]) + \\\n                                 self.c2 * r2 * (global_best_position - swarm[j])\n                swarm[j] = np.clip(swarm[j] + velocities[j], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluate fitness\n                fitness = func(swarm[j])\n                self.budget -= 1\n                \n                # Update personal best\n                if fitness < personal_best_fitnesses[j]:\n                    personal_best_fitnesses[j] = fitness\n                    personal_best_positions[j] = swarm[j].copy()\n                    \n                    # Update global best\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = swarm[j].copy()\n                        \n                        if fitness < self.f_opt:\n                            self.f_opt = fitness\n                            self.x_opt = swarm[j].copy()\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n\n        # Nelder-Mead refinement around the best solution found by PSO\n        if self.budget > 0:\n            nm_result = minimize(func, global_best_position, method='Nelder-Mead',\n                                 options={'maxiter': self.nm_iters, 'maxfev': self.budget})\n            \n            if nm_result.success:\n                if nm_result.fun < self.f_opt:\n                    self.f_opt = nm_result.fun\n                    self.x_opt = nm_result.x\n            \n            self.budget -= nm_result.nfev\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 69, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: nm_result = minimize(func, global_best_position, method='Nelder-Mead',", "error": "In the code, line 69, in __call__, the following error occurred:\nNameError: name 'minimize' is not defined\nOn line: nm_result = minimize(func, global_best_position, method='Nelder-Mead',", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "1533531f-e2af-4f38-a6a6-7340690fe1ec", "fitness": 0.5390885768375954, "name": "DiffusionSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass DiffusionSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.budget -= 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.population[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_velocity = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(self.population[i])\n                self.budget -= 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = self.population[i].copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DiffusionSearch scored 0.539 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.23270613182937894, 0.1846419564553733, 0.8748489000108567, 0.18066191903280016, 0.2547774415252878, 0.2844002526306354, 0.3136331448210318, 0.7321947947612752, 0.8961431373510309, 0.23722353289157816, 0.9371591986201088, 0.9970555193070274, 0.3513309417101307, 0.33126194362890404, 0.5883266765594515, 0.8902684131286358, 0.8209051213195123, 0.9406446071776503, 0.240455338558906, 0.4931325654323313]}, "task_prompt": ""}
{"id": "d237483e-bf0c-4583-8e8b-096d1858f38b", "fitness": 0.0, "name": "CMA_ES_NelderMead", "description": "No description provided.", "code": "import numpy as np\n\nclass CMA_ES_NelderMead:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=1.0, c_sigma=0.4, d_sigma=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.mean = None\n        self.lb = -5.0\n        self.ub = 5.0\n        self.path_sigma = np.zeros(dim)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(self.lb, self.ub, size=self.dim)\n        evals = 0\n\n        while evals < self.budget:\n            # Sample population\n            population = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n            population = np.clip(population, self.lb, self.ub)\n\n            fitness = np.array([func(x) for x in population])\n            evals += self.pop_size\n            if evals > self.budget:\n                fitness = fitness[:self.budget - (evals - self.pop_size)]\n                population = population[:self.budget - (evals - self.pop_size)]\n                evals = self.budget\n                \n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update CMA-ES parameters\n            sorted_indices = np.argsort(fitness)\n            selected_individuals = population[sorted_indices[:self.pop_size // 2]]\n            old_mean = self.mean.copy()\n            self.mean = np.mean(selected_individuals, axis=0)\n\n            self.path_sigma = (1 - self.c_sigma) * self.path_sigma + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (self.mean - old_mean) / self.sigma\n            self.sigma *= np.exp(self.d_sigma / 0.44 * (np.linalg.norm(self.path_sigma) - np.sqrt(self.dim)))\n            self.sigma = np.clip(self.sigma, 1e-6, 5)\n            \n            # Apply Nelder-Mead every few iterations\n            if evals % (self.pop_size * 5) == 0 and evals + self.dim + 1 < self.budget:\n                \n                def nm_func(x):\n                    val = func(x)\n                    return val\n                \n                import scipy.optimize\n                \n                try:\n                    res = scipy.optimize.minimize(nm_func, self.x_opt, method='Nelder-Mead', options={'maxfev': min(self.budget - evals, 200)})\n                    \n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                    evals += res.nfev\n                    \n                except:\n                    pass\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMA_ES_NelderMead scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "e1ba8690-f30d-4a28-a1da-2e92d8d1344e", "fitness": 0.5628207399280042, "name": "RingTopologyPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass RingTopologyPSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n\n        # Initialize neighborhood best positions (ring topology)\n        neighborhood_best_positions = np.zeros((self.num_particles, self.dim))\n        neighborhood_best_values = np.full(self.num_particles, np.inf)\n        \n        for i in range(self.num_particles):\n            left = (i - 1) % self.num_particles\n            right = (i + 1) % self.num_particles\n            \n            if personal_best_values[left] < personal_best_values[i]:\n                if personal_best_values[left] < personal_best_values[right]:\n                    neighborhood_best_positions[i] = personal_best_positions[left]\n                    neighborhood_best_values[i] = personal_best_values[left]\n                else:\n                    neighborhood_best_positions[i] = personal_best_positions[right]\n                    neighborhood_best_values[i] = personal_best_values[right]\n\n            elif personal_best_values[right] < personal_best_values[i]:\n                neighborhood_best_positions[i] = personal_best_positions[right]\n                neighborhood_best_values[i] = personal_best_values[right]\n            else:\n                neighborhood_best_positions[i] = personal_best_positions[i]\n                neighborhood_best_values[i] = personal_best_values[i]\n                    \n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            for i in range(self.num_particles):\n                # Update velocity\n                inertia_term = self.inertia * velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (neighborhood_best_positions[i] - particles[i])\n                velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update neighborhood best\n                    left = (i - 1) % self.num_particles\n                    right = (i + 1) % self.num_particles\n                    \n                    for neighbor_index in [i, left, right]:\n                        local_f_opt = np.inf\n                        local_x_opt = None\n\n                        left_neighbor = (neighbor_index - 1) % self.num_particles\n                        right_neighbor = (neighbor_index + 1) % self.num_particles\n                        \n                        for neighbor_index2 in [neighbor_index, left_neighbor, right_neighbor]:\n                            if personal_best_values[neighbor_index2] < local_f_opt:\n                                local_f_opt = personal_best_values[neighbor_index2]\n                                local_x_opt = personal_best_positions[neighbor_index2]\n                        \n                        neighborhood_best_values[neighbor_index] = local_f_opt\n                        neighborhood_best_positions[neighbor_index] = local_x_opt\n\n\n                # Update global best\n                if fitness < self.f_opt:\n                    self.f_opt = fitness\n                    self.x_opt = particles[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm RingTopologyPSO scored 0.563 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.21218904323927246, 0.1812978040919162, 0.7612443391865396, 0.8554624000621214, 0.8405400544724059, 0.8619510813884415, 0.3679656919397103, 0.6099945092138439, 0.21838399054251423, 0.2317280715401585, 0.8947176566182082, 0.9988448283332225, 0.24031365431351193, 0.2836735795180779, 0.7310195024667827, 0.8423874399594045, 0.4594016039569314, 0.8732735923667352, 0.2593321403086767, 0.5326938150416081]}, "task_prompt": ""}
{"id": "a4b56e29-ed10-4177-8f18-b3d9677b3d2f", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.X = None\n        self.y = None\n        self.gpr = None\n        self.eval_count = 0\n\n    def initialize(self, func):\n        self.X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.eval_count += self.n_initial_samples\n\n        kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n        self.gpr.fit(self.X, self.y)\n\n    def acquisition_function(self, x, xi=0.01):\n        mu, sigma = self.gpr.predict(x.reshape(1, -1), return_std=True)\n        return mu - xi * sigma\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize(func)\n\n        while self.eval_count < self.budget:\n            # Find the next point to evaluate by maximizing the acquisition function\n            from scipy.optimize import minimize\n            bounds = [(self.lb, self.ub)] * self.dim\n            \n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)\n\n            res = minimize(lambda x: -self.acquisition_function(x), x0,\n                           bounds=bounds, method='L-BFGS-B')  # Use L-BFGS-B to respect bounds\n            \n            x_next = res.x\n\n            # Evaluate the function at the new point\n            f_next = func(x_next)\n            self.eval_count += 1\n\n            # Update the Gaussian process model\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n            self.gpr.fit(self.X, self.y)\n            \n            # Update the best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next.copy()\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 22, in initialize, the following error occurred:\nNameError: name 'C' is not defined\nOn line: kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 22, in initialize, the following error occurred:\nNameError: name 'C' is not defined\nOn line: kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "590cdc39-4c64-4d48-a812-50b9d2c72fdd", "fitness": 0.11731012642072214, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, inertia_max=0.9, inertia_min=0.2, cognitive_coeff=2.0, social_coeff=2.0, velocity_clamp=1.0, stagnation_limit=50):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.velocity_clamp = velocity_clamp\n        self.stagnation_limit = stagnation_limit\n        self.lb = -5.0\n        self.ub = 5.0\n        self.stagnation_counter = 0\n        self.previous_best_fitness = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n        \n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n            self.previous_best_fitness = self.f_opt\n\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / (self.budget + self.num_particles))\n\n            for i in range(self.num_particles):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = inertia * velocities[i] + \\\n                                self.cognitive_coeff * r1 * (personal_best_positions[i] - particles[i]) + \\\n                                self.social_coeff * r2 * (self.x_opt - particles[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i]\n\n            # Stagnation detection and parameter adjustment\n            if abs(self.f_opt - self.previous_best_fitness) < 1e-6:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.stagnation_limit:\n                # Reset particles to explore new regions\n                particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n                velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, size=(self.num_particles, self.dim))\n                personal_best_positions = particles.copy()\n                personal_best_values = np.array([func(x) for x in particles])\n                self.budget -= self.num_particles\n                \n                if np.min(personal_best_values) < self.f_opt:\n                    self.f_opt = np.min(personal_best_values)\n                    self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n                \n                # Increase exploration by increasing inertia\n                self.inertia_max = min(0.95, self.inertia_max + 0.05) # Ensure it does not become bigger than 0.95\n                self.stagnation_counter = 0\n\n            self.previous_best_fitness = self.f_opt\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.117 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13459006184643763, 0.2173403174157288, 0]}, "task_prompt": ""}
{"id": "23bcfebd-05f9-43e8-b873-0a8a1235a062", "fitness": 0.4793865185008975, "name": "AdaptiveInertiaPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveInertiaPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_inertia=0.9, final_inertia=0.4, cognitive_coeff=1.4, social_coeff=1.4):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_inertia = initial_inertia\n        self.final_inertia = final_inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        self.fitness = np.array([np.inf] * self.pop_size)\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = np.array([np.inf] * self.pop_size)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n\n        # Initial evaluation\n        for i in range(self.pop_size):\n            self.fitness[i] = func(self.population[i])\n            self.budget -= 1\n            self.eval_count += 1\n\n            if self.fitness[i] < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = self.fitness[i]\n                self.personal_best_positions[i] = self.population[i].copy()\n\n            if self.fitness[i] < self.global_best_fitness:\n                self.global_best_fitness = self.fitness[i]\n                self.global_best_position = self.population[i].copy()\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position\n\n        while self.budget > 0:\n            # Calculate dynamic inertia weight\n            inertia = self.initial_inertia - (self.initial_inertia - self.final_inertia) * (self.eval_count / self.budget)\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.population[i])\n                social_velocity = self.social_coeff * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Update position\n                self.population[i] = self.population[i] + self.velocities[i]\n                self.population[i] = np.clip(self.population[i], self.lb, self.ub)\n\n                # Evaluate new position\n                f = func(self.population[i])\n                self.budget -= 1\n                self.eval_count += 1\n\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n\n                    if f < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                        if f < self.global_best_fitness:\n                            self.global_best_fitness = f\n                            self.global_best_position = self.population[i].copy()\n                            self.f_opt = self.global_best_fitness\n                            self.x_opt = self.global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveInertiaPSO scored 0.479 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19550296716840554, 0.2275142821538919, 0.7848844765687661, 0.20544242581681704, 0.2935398124597025, 0.8400757507352254, 0.7597200170814445, 0.4560395775255265, 0.7897929974144055, 0.23080595199227716, 0.23052523880182585, 0.9981968920488912, 0.25021804125041414, 0.2757185324962139, 0.7274101106034525, 0.8387927948110565, 0.4176817123652633, 0.379269058095576, 0.16408822947236446, 0.5225115011564294]}, "task_prompt": ""}
{"id": "a4cef0c4-a640-4bd6-8d33-d77b773641b9", "fitness": 0.6245444658021031, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, c1=2, c2=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        \n        self.budget -= self.pop_size\n\n        if np.min(personal_best_fitness) < self.f_opt:\n            self.f_opt = np.min(personal_best_fitness)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_fitness)]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        global_best_fitness = np.min(personal_best_fitness)\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / self.budget) # Linear decrease of inertia\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # Velocity clamping\n                v_max = 0.2*(func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = particles[i]\n                        \n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.625 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15204154342626353, 0.5593356309734614, 0.864710112871732, 0.901460441428029, 0.9171094192627064, 0.9255091055867768, 0.33646613326329966, 0.49038219869063826, 0.9173299527700091, 0.2102172684367961, 0.9533304134733958, 0.9988810023641529, 0.27672054915476296, 0.32075680587835353, 0.7397848208647033, 0.9140490690625775, 0.32713237509717574, 0.9204268743354981, 0.26706230344769644, 0.4981832956540335]}, "task_prompt": ""}
{"id": "751fd9d8-cc98-4211-b689-451a763c5e96", "fitness": 0.39451715605877524, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, num_particles=20, initial_inertia=0.9, initial_cognitive_coeff=2.0, initial_social_coeff=2.0, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia = initial_inertia\n        self.cognitive_coeff = initial_cognitive_coeff\n        self.social_coeff = initial_social_coeff\n        self.lb = -5.0\n        self.ub = 5.0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(self.lb, self.ub, size=(self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.num_particles, self.dim))\n\n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.num_particles\n\n        if np.min(personal_best_values) < self.f_opt:\n            self.f_opt = np.min(personal_best_values)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_values)]\n\n        # Iterate until budget is exhausted\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(particles)\n\n            # Adapt inertia weight and coefficients based on diversity\n            if diversity < self.diversity_threshold:\n                self.inertia = min(self.inertia + 0.01, 0.9)\n                self.cognitive_coeff = max(self.cognitive_coeff - 0.01, 1.5)\n                self.social_coeff = max(self.social_coeff - 0.01, 1.5)\n            else:\n                self.inertia = max(self.inertia - 0.01, 0.4)\n                self.cognitive_coeff = min(self.cognitive_coeff + 0.01, 2.5)\n                self.social_coeff = min(self.social_coeff + 0.01, 2.5)\n\n            for i in range(self.num_particles):\n                # Update velocity\n                inertia_term = self.inertia * velocities[i]\n                cognitive_term = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coeff * np.random.rand(self.dim) * (self.x_opt - particles[i]) # Using global best\n                velocities[i] = inertia_term + cognitive_term + social_term\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                # Evaluate new position\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_values[i]:\n                    personal_best_values[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.395 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.15107340820209425, 0.27301501625852775, 0.426897763356324, 0.7341272059210351, 0.29447607931456676, 0.4705167715579158, 0.252600935100173, 0.3923377545070649, 0.33965053153817504, 0.22702200211561363, 0.2342482834805628, 0.9981045347254139, 0.21684215764049586, 0.2626696874266309, 0.706841912120747, 0.3746496447590222, 0.31401406090311546, 0.5376096185345434, 0.20675213915201152, 0.4768936145614707]}, "task_prompt": ""}
{"id": "b1a1c9ef-4180-40e6-b184-b92041611891", "fitness": 0.5785630657991321, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F_min=0.1, F_max=0.9, CR_min=0.1, CR_max=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.CR_min = CR_min\n        self.CR_max = CR_max\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                # Adaptive F and CR based on population diversity\n                diversity = np.std(fitness)\n                F = self.F_min + (self.F_max - self.F_min) * diversity\n                CR = self.CR_min + (self.CR_max - self.CR_min) * diversity\n                F = np.clip(F, self.F_min, self.F_max)\n                CR = np.clip(CR, self.CR_min, self.CR_max)\n\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.579 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2001381703894829, 0.4328232485791783, 0.3482023795196274, 0.9059347346271901, 0.8479394944157285, 0.498814782695544, 0.7384942338247089, 0.36067200287935464, 0.6909331334389617, 0.6572688198629094, 0.7795335861176439, 0.9911864518460302, 0.31069470125541476, 0.5295495067453404, 0.8113182545547284, 0.40911955707597303, 0.557726735976414, 0.7043453741481243, 0.31186103192318126, 0.4847051161071042]}, "task_prompt": ""}
{"id": "7350eb88-4c0b-495e-bb30-07b4126b090f", "fitness": 0.48226792665786594, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find initial global best\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        self.f_opt = fitness[best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            # Update inertia weight (linearly decreasing)\n            inertia = self.inertia * (1 - (self.budget / 10000 if self.budget <= 10000 else 0)) #self.inertia * (self.budget / initial_budget)\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - population[i])\n                social_component = self.c2 * r2 * (global_best_position - population[i])\n                \n                velocities[i] = inertia * velocities[i] + cognitive_component + social_component\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluate new position\n                f_new = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f_new < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_new\n                    personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position.copy()\n                        global_best_position = new_position.copy()\n\n                population[i] = new_position.copy()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.482 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18676159983902807, 0.20250935138700643, 0.4376034714456648, 0.2071657752053948, 0.2520858942598829, 0.9522300107644831, 0.2778144811064941, 0.2821244531392024, 0.9522318971795221, 0.18768749869877077, 0.882636360419409, 0.9987583283346915, 0.24681715625671508, 0.21127209417651704, 0.729800031006417, 0.7452843610862944, 0.2774992160766232, 0.9625771053483044, 0.18770028735041133, 0.46479916007648703]}, "task_prompt": ""}
{"id": "5bdf6130-10fb-49d5-b3cf-0711c24811c4", "fitness": 0.37248324291603124, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find initial best\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        success_history = []\n\n        while self.budget > 0:\n            generation += 1\n\n            for i in range(self.pop_size):\n                # Mutation - Elitist strategy\n                elite_index = np.argmin(fitness)\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                indices = np.random.choice(indices, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                \n                mutant = population[elite_index] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lb, self.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n\n                # Evaluation\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < self.f_opt:\n                        self.f_opt = trial_fitness\n                        self.x_opt = trial_vector\n                        success_history.append(1)\n                    else:\n                        success_history.append(0)\n\n                else:\n                    success_history.append(0)\n\n                if len(success_history) > 50:\n                    success_rate = np.mean(success_history[-50:])\n                    self.F = np.clip(self.F + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n                    self.CR = np.clip(self.CR + 0.1 * (success_rate - 0.5), 0.1, 0.9)\n\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.372 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1785110330143238, 0.19154370519776642, 0.38942256774577166, 0.8258193322685787, 0.2745782911092435, 0.25283734806199887, 0.33163896541602, 0.2987107826877734, 0.2389886710230208, 0.17050582368279554, 0.2981155610477817, 0.9992720554543641, 0.26387738832410745, 0.21310781407035395, 0.670269688702053, 0.41997376661499086, 0.3073015550770998, 0.3916150884954449, 0.2372046364302962, 0.49637078389684064]}, "task_prompt": ""}
{"id": "e3cba523-64d2-48fe-9875-52dbb39887eb", "fitness": "-inf", "name": "BudgetAwareCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(4 + np.floor(3 * np.log(self.dim)))  # Dynamically adjust based on dim\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = np.random.uniform(-1, 1, self.dim)\n        self.sigma = initial_step_size  # Step-size\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.chiN = np.sqrt(self.dim) * (1 - (1 / (4 * self.dim)) + 1 / (21 * self.dim**2))\n        self.c_sigma = (self.mu / self.pop_size)\n        self.c_c = (4 + self.mu/self.dim) / (self.dim + 4 + 2*self.mu/self.dim)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(self.dim+1)) - 1) + self.c_sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            samples = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate\n            fitness = np.array([func(x) for x in samples.T])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget]\n                samples = samples[:, :self.pop_size + self.budget]\n                self.pop_size = self.pop_size + self.budget\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            samples = samples[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = samples[:, 0]\n\n            # Update mean\n            m_old = self.m.copy()\n            self.m = np.dot(samples[:, :self.mu], self.weights)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (self.m - m_old) / self.sigma)\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2*(self.budget//self.pop_size))) < self.chiN * (1.4 + 2/(self.dim + 1))\n            dhsig = (1-hsig) * self.c_c * (2-self.c_c)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (np.outer(self.pc, self.pc) + dhsig * self.C)\n            for i in range(self.mu):\n                self.C += self.c_mu * self.weights[i] * np.outer((samples[:, i] - m_old) / self.sigma, (samples[:, i] - m_old) / self.sigma)\n\n            # Update step-size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (np.linalg.norm(self.ps) / self.chiN - 1))\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4853965e-a809-4a79-9a48-110a56e85ec9", "fitness": 0.28779820855529314, "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + dim / 2\n        self.c_cov = c_cov\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.m = None\n        self.C = None\n        self.pc = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.pop_size, self.dim)\n            samples = self.m + self.sigma * z @ np.linalg.cholesky(self.C).T\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in samples])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[np.argmin(fitness)]\n\n            # Selection and Recombination\n            idx = np.argsort(fitness)\n            best_samples = samples[idx[:self.mu]]\n            self.m = np.sum(self.weights[:, None] * best_samples, axis=0)\n\n            # Update Evolution Path\n            z_mean = np.mean(z[idx[:self.mu]], axis=0)\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * z_mean\n            \n            # Update Covariance Matrix\n            self.C = (1 - self.c_cov) * self.C + self.c_cov * np.outer(self.pc, self.pc)\n\n            # Update Step Size\n            fitness_diff = np.max(fitness) - np.min(fitness)\n            self.sigma *= np.exp(0.5 * self.cs / self.damps * (fitness_diff / np.std(fitness) - 1))\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09420382731332233, 0.17966058581803046, 0.2904875984580787, 0.33368761843315, 0.20615846716819752, 0.2464489910491674, 0.24930258421587093, 0.24227327450916858, 0.18957380774341714, 0.1639983311086235, 0.22939455016603327, 0.9954652352806134, 0.22775999471068376, 0.21233220471798164, 0.5685332611785993, 0.26468060695149664, 0.20904187006299657, 0.2736860585248665, 0.13750381743828843, 0.4417714862572767]}, "task_prompt": ""}
{"id": "e57262e1-a603-4f84-b0f7-f1bec9e668e3", "fitness": 0.24424596250904534, "name": "SimplifiedCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=4, sigma=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = sigma\n        self.mean = None\n        self.C = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialization\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)  # Covariance matrix\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            population = self.mean + self.sigma * z\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            best_x = population[idx[0]]\n            best_f = fitness[idx[0]]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Update mean\n            self.mean = best_x\n\n            # Simplified rank-1 update for covariance matrix (adaptation)\n            diff = best_x - self.mean\n            self.C = (0.9 * self.C + 0.1 * np.outer(diff, diff))\n            \n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimplifiedCMAES scored 0.244 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.03861110304883042, 0.16456073335172694, 0.26422889361195434, 0.10515536597694752, 0.3664743898517301, 0.1552522260544994, 0.167436954368964, 0.16743138934496016, 0.16702764388193647, 0.14532385225295807, 0.20309155030725767, 0.9948400734902769, 0.22436700529304576, 0.16198877461734995, 0.4823362155770251, 0.2688740122468317, 0.3034398872299767, 0.17389258322646872, 0.15564952448486913, 0.174937071963298]}, "task_prompt": ""}
{"id": "0dab385a-5e48-43b3-ad8d-8c72d422ba3a", "fitness": 0.47824274251044596, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, step_size=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = step_size\n        self.success_rate = 0.0\n        self.success_counter = 0\n        self.iteration_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n        \n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = current_x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate neighbor solution\n            new_f = func(new_x)\n            self.budget -= 1\n            \n            # Acceptance probability\n            if new_f < current_f:\n                # Accept better solution\n                current_x = new_x\n                current_f = new_f\n                self.success_counter += 1\n\n                if new_f < self.f_opt:\n                    self.f_opt = new_f\n                    self.x_opt = new_x\n            else:\n                # Accept worse solution with probability\n                acceptance_prob = np.exp((current_f - new_f) / self.temp)\n                if np.random.rand() < acceptance_prob:\n                    current_x = new_x\n                    current_f = new_f\n\n            # Update temperature\n            self.temp *= self.cooling_rate\n            \n            #Adaptive step size\n            self.iteration_counter += 1\n            if self.iteration_counter % 100 == 0:\n                self.success_rate = self.success_counter / 100.0\n                self.success_counter = 0\n                if self.success_rate > 0.6:\n                    self.step_size *= 1.1\n                elif self.success_rate < 0.4:\n                    self.step_size *= 0.9\n                self.step_size = np.clip(self.step_size, 0.01, (func.bounds.ub - func.bounds.lb)/2) #Clamp the step size\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.478 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13152566193135096, 0.16020709588327375, 0.5085932158217599, 0.8535875045950019, 0.31004868325348967, 0.5817640443809722, 0.2935364010692805, 0.4434535857687213, 0.49806601697636155, 0.13183388849042954, 0.8486568670548478, 0.9987055777493584, 0.2652015395149371, 0.5354884174718829, 0.8985332632763017, 0.2728598948266159, 0.4611411010886275, 0.6950046635207037, 0.19091177741040788, 0.4857356501245943]}, "task_prompt": ""}
{"id": "71504a76-b300-4c87-87b1-399d0e1a4e7e", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.n_initial_samples = n_initial_samples\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def acquisition_function(self, x):\n        x = x.reshape(1, -1)\n        mu, sigma = self.gp.predict(x, return_std=True)\n        \n        if sigma == 0:\n            return 0\n        \n        improvement = self.f_opt - mu\n        Z = improvement / sigma\n        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return -ei  # We want to maximize EI, so minimize -EI\n\n    def __call__(self, func):\n        # Initial sampling\n        initial_X = np.random.uniform(self.lb, self.ub, size=(self.n_initial_samples, self.dim))\n        initial_y = np.array([func(x) for x in initial_X])\n        self.budget -= self.n_initial_samples\n\n        self.X = initial_X\n        self.y = initial_y\n\n        best_index = np.argmin(initial_y)\n        self.f_opt = initial_y[best_index]\n        self.x_opt = initial_X[best_index]\n\n        while self.budget > 0:\n            # Fit Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            # Find next point to evaluate using acquisition function\n            bounds = [(self.lb, self.ub)] * self.dim\n            x0 = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initial guess\n            result = minimize(self.acquisition_function, x0, bounds=bounds, method='L-BFGS-B')\n            x_next = result.x\n\n            # Evaluate the function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Add to data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update best solution\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 14, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "error": "In the code, line 14, in __init__, the following error occurred:\nNameError: name 'C' is not defined\nOn line: self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ad393c8e-5869-41a2-a6cd-7f5a64089992", "fitness": 0.30193444903586447, "name": "ShrinkingSearchSpace", "description": "No description provided.", "code": "import numpy as np\n\nclass ShrinkingSearchSpace:\n    def __init__(self, budget=10000, dim=10, pop_size=20, shrink_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.shrink_factor = shrink_factor\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_x = population[best_index]\n        best_f = fitness[best_index]\n\n        self.f_opt = best_f\n        self.x_opt = best_x\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Update best solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n\n            # Calculate the new search space based on the best solutions\n            center = np.mean(population[:self.pop_size // 2], axis=0) # Use the best half to define center\n\n            width = (ub - lb) * self.shrink_factor\n            new_lb = np.maximum(center - width / 2, func.bounds.lb)\n            new_ub = np.minimum(center + width / 2, func.bounds.ub)\n\n            # Generate new population within the shrunk search space\n            new_population = np.random.uniform(new_lb, new_ub, size=(self.pop_size, self.dim))\n\n            # Evaluate fitness of the new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Combine old and new populations (elitism)\n            combined_population = np.concatenate((population[:self.pop_size // 2], new_population)) #Keep half of the previous population\n            combined_fitness = np.concatenate((fitness[:self.pop_size // 2], new_fitness))\n            \n            population = combined_population\n            fitness = combined_fitness\n            \n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n            best_f = fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ShrinkingSearchSpace scored 0.302 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12383348590377063, 0.1769946041693382, 0.2780862567102047, 0.24993899160821298, 0.23156564439756278, 0.2510910412306865, 0.2387123304056179, 0.23889291231670495, 0.2167171561387733, 0.16309812725129014, 0.2730424871705419, 0.9960058714279371, 0.25111905825309244, 0.21587080038262207, 0.6514575648836249, 0.290473761323931, 0.25776404682937226, 0.3018581835623688, 0.16252971244067171, 0.46963694431096503]}, "task_prompt": ""}
{"id": "55f05885-83aa-47be-9fe2-443a9a35699a", "fitness": "-inf", "name": "BudgetAwareCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=None, restarts=3):\n        self.budget = budget\n        self.dim = dim\n        self.restarts = restarts\n        if pop_size is None:\n            self.pop_size = 4 + int(3 * np.log(self.dim))\n        else:\n            self.pop_size = pop_size\n        if sigma0 is None:\n            self.sigma0 = 0.5\n        else:\n            self.sigma0 = sigma0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        for _ in range(self.restarts):\n            self.f_opt_restart = np.inf\n            self.x_opt_restart = None\n            \n            # Initialization\n            mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n            sigma = self.sigma0\n            C = np.eye(self.dim)\n            pc = np.zeros(self.dim)\n            ps = np.zeros(self.dim)\n            chiN = np.mean(np.sqrt(np.sum(np.random.randn(self.pop_size, self.dim)**2, axis=1)))\n            mu = self.pop_size // 2\n            weights = np.log(mu+1/2) - np.log(np.arange(1, mu+1))\n            weights = weights / np.sum(weights)\n            mueff = np.sum(weights)**2 / np.sum(weights**2)\n            \n            c_sigma = (mueff + 2) / (self.dim + mueff + 5)\n            c_c = (4 + mueff / self.dim) / (self.dim + 4 + 2 * mueff / self.dim)\n            c_1 = 2 / ((self.dim + 1.3)**2 + mueff)\n            c_mu = min(1 - c_1, 2 * (mueff - 2 + 1 / mueff) / ((self.dim + 2)**2 + mueff))\n            d_sigma = 1 + 2 * max(0, np.sqrt((mueff - 1) / (self.dim + 1)) - 1) + c_sigma\n            \n            B = None\n            D = None\n            \n            evals_used = 0\n            while self.budget > 0 and evals_used < self.budget // self.restarts:\n                # Sampling\n                if B is None or D is None:\n                    eigenvalues, eigenvectors = np.linalg.eigh(C)\n                    B = eigenvectors\n                    D = np.diag(np.sqrt(eigenvalues))\n\n                z = np.random.randn(self.pop_size, self.dim)\n                x = mean + sigma * B @ D @ z.T\n                x = np.clip(x.T, func.bounds.lb, func.bounds.ub)\n                \n                fitness = np.array([func(xi) for xi in x])\n                evals_used += self.pop_size\n                self.budget -= self.pop_size\n                \n                if np.min(fitness) < self.f_opt_restart:\n                    self.f_opt_restart = np.min(fitness)\n                    self.x_opt_restart = x[np.argmin(fitness)]\n                \n                # Selection and Recombination\n                idx = np.argsort(fitness)\n                x_mu = x[idx[:mu]]\n                z_mu = z[idx[:mu]]\n                \n                mean_old = mean.copy()\n                mean = np.sum(weights[:, None] * x_mu, axis=0)\n                zmean = np.sum(weights[:, None] * z_mu, axis=0)\n\n                # Update Evolution Path\n                ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma) * mueff) * (B @ zmean)\n                hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - c_sigma)**(2 * evals_used / self.pop_size)) < (1.4 + 2 / (self.dim + 1)) * chiN\n                pc = (1 - c_c) * pc + hsig * np.sqrt(c_c * (2 - c_c) * mueff) * (mean - mean_old) / sigma\n                \n                # Update Covariance Matrix\n                C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :]) + c_mu * np.sum(weights[:, None, None] * (z_mu[:, :, None] @ z_mu[:, None, :]), axis=0)\n                \n                # Update Step Size\n                sigma = sigma * np.exp((c_sigma / d_sigma) * (np.linalg.norm(ps) / chiN - 1))\n\n                if self.budget <= 0:\n                    break\n            \n            if self.f_opt_restart < self.f_opt:\n                self.f_opt = self.f_opt_restart\n                self.x_opt = self.x_opt_restart\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 54, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = mean + sigma * B @ D @ z.T", "error": "In the code, line 54, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = mean + sigma * B @ D @ z.T", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "350c652a-7e0e-405d-8d62-90fb95074d90", "fitness": 0.6244087643110533, "name": "NicheDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass NicheDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, num_niches=5, F=0.5, CR=0.7, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.num_niches = num_niches\n        self.F = F\n        self.CR = CR\n        self.niche_radius = niche_radius\n\n        self.niches = []  # List to store niche centers\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        # Initialize niches randomly\n        for _ in range(self.num_niches):\n            self.niches.append(np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim))\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose a niche to focus on (either the closest or a random one)\n                distances = np.array([np.linalg.norm(population[i] - niche) for niche in self.niches])\n                closest_niche_index = np.argmin(distances)\n                \n                if np.random.rand() < 0.8: #Probability to exploit the nearest niche\n                    chosen_niche_index = closest_niche_index\n                else: #Otheriwse explore by picking random niche\n                    chosen_niche_index = np.random.randint(0, self.num_niches)\n\n                # Mutation (DE within the chosen niche)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update the chosen niche center if the new point is close enough\n                    if np.linalg.norm(trial - self.niches[chosen_niche_index]) < self.niche_radius:\n                        self.niches[chosen_niche_index] = trial.copy()\n\n                if self.budget <= 0:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm NicheDifferentialEvolution scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2111222422664112, 0.5761440454849608, 0.5768358640848312, 0.8384967676833271, 0.7040871227943615, 0.755324690842184, 0.5398486238261517, 0.5866163439946079, 0.6957552933278217, 0.5435791476682414, 0.7591496505072445, 0.9995868211043661, 0.33456688496882303, 0.6547332818685634, 0.8781833299983623, 0.7496976955780376, 0.5093001490922964, 0.8130714643182708, 0.23737082103180995, 0.524705045780396]}, "task_prompt": ""}
{"id": "54058487-38d2-4a03-a1a6-d76f1418d620", "fitness": 0.3603792483967954, "name": "DistanceWeightedExploration", "description": "No description provided.", "code": "import numpy as np\n\nclass DistanceWeightedExploration:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n\n            # Learn from top individuals\n            num_elites = max(1, self.pop_size // 5)\n            elites = population[:num_elites]\n\n            for i in range(self.pop_size):\n                # Distance-weighted average for exploration\n                distances = np.linalg.norm(elites - population[i], axis=1)\n                weights = np.exp(-distances)\n                weights /= np.sum(weights)  # Normalize weights\n\n                new_x = np.sum(elites * weights[:, np.newaxis], axis=0)\n                # Add a random exploration component\n                exploration_factor = 0.1\n                new_x += exploration_factor * np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n                \n                f = func(new_x)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_x\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_x\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DistanceWeightedExploration scored 0.360 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19472115691480119, 0.16997022654315463, 0.3789830030776794, 0.19831466252905583, 0.29298719283509045, 0.4008289855352607, 0.2931032141700489, 0.33102859820080643, 0.3097658214816357, 0.1784145617947559, 0.4527019594571461, 0.9968807023413513, 0.2770262507698683, 0.2277015092048671, 0.8059599372801376, 0.32290894406273407, 0.23604621257483616, 0.45234282908888335, 0.19193449939426455, 0.49596470067953047]}, "task_prompt": ""}
{"id": "84227f63-933b-485b-80c4-d34943746fa7", "fitness": 0.3179189133457331, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.velocity_clamp = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (1 - self.budget / self.budget)\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp * (func.bounds.ub - func.bounds.lb), self.velocity_clamp * (func.bounds.ub - func.bounds.lb))\n                \n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = population[i]\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i]\n                        global_best_position = population[i]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.318 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14196483482274946, 0.2101300883613162, 0.29651318319246556, 0.31052912276999445, 0.24986187776735924, 0.2608168199038763, 0.2649696360789504, 0.2590964322357664, 0.22138273676723397, 0.2002848151870915, 0.25185447904524283, 0.9977128455517601, 0.22047158304732695, 0.23935968911061778, 0.6405596194658337, 0.3212900503964502, 0.25410830906724646, 0.3486716622435152, 0.18498206022940078, 0.48381842167046407]}, "task_prompt": ""}
{"id": "018ea596-be0a-4ef7-a311-0a6fa53247a1", "fitness": "-inf", "name": "HybridDE", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridDE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5\n        self.CR = 0.9\n        self.local_search_prob = local_search_prob\n\n    def local_search(self, func, x, step_size):\n        x_new = x + np.random.normal(0, step_size, size=self.dim)\n        x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n        f_new = func(x_new)\n        self.budget -= 1\n        return f_new, x_new\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                # Local search\n                if np.random.rand() < self.local_search_prob and self.budget > 0:\n                    step_size = np.std(population[:, i]) if np.std(population[:, i]) > 0 else 0.1\n                    f_local, x_local = self.local_search(func, population[i], step_size)\n                    if f_local < fitness[i]:\n                        fitness[i] = f_local\n                        population[i] = x_local\n                        if f_local < self.f_opt:\n                            self.f_opt = f_local\n                            self.x_opt = x_local\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 55, in __call__, the following error occurred:\nIndexError: index 3 is out of bounds for axis 1 with size 2\nOn line: step_size = np.std(population[:, i]) if np.std(population[:, i]) > 0 else 0.1", "error": "In the code, line 55, in __call__, the following error occurred:\nIndexError: index 3 is out of bounds for axis 1 with size 2\nOn line: step_size = np.std(population[:, i]) if np.std(population[:, i]) > 0 else 0.1", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4ee7469e-db59-44b0-8e37-c2041656b557", "fitness": 0.0, "name": "AdaptiveSOMA", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = 0.1  # Initial step size\n        self.path_length = 2.0  # Initial path length\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Leader selection (find the best individual)\n                leader_idx = np.argmin(fitness)\n                leader = population[leader_idx]\n                \n                # Migration\n                for j in range(self.pop_size):\n                    if i == j:\n                        continue\n                    \n                    # Generate new candidate based on SOMA migration\n                    direction_vector = leader - population[j]\n                    num_steps = int(self.path_length / self.step_size)\n                    \n                    for step in range(1, num_steps + 1):\n                        new_position = population[j] + self.step_size * step * direction_vector\n                        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                        f = func(new_position)\n                        self.budget -= 1\n                        \n                        if f < fitness[j]:\n                            fitness[j] = f\n                            population[j] = new_position\n                            \n                            if f < self.f_opt:\n                                self.f_opt = f\n                                self.x_opt = new_position\n                        \n                        if self.budget <= 0:\n                            break\n                    if self.budget <= 0:\n                        break\n            # Adapt step size and path length (simple heuristic)\n            if np.random.rand() < 0.1:\n                self.step_size *= np.random.uniform(0.8, 1.2)\n                self.path_length *= np.random.uniform(0.8, 1.2)\n                self.step_size = np.clip(self.step_size, 0.01, 0.5)  # reasonable bounds\n                self.path_length = np.clip(self.path_length, 0.5, 3.0)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSOMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "f38dd0e8-cf01-4a1f-8eb9-d12935f1a95c", "fitness": 0.29623127867900056, "name": "DynamicParticleSwarm", "description": "No description provided.", "code": "import numpy as np\n\nclass DynamicParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = (self.ub - self.lb) * 0.2  # Clamp velocity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Find best initial global solution\n        best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[best_index].copy()\n        self.f_opt = personal_best_fitnesses[best_index]\n        self.x_opt = global_best_position.copy()\n\n        while self.budget > 0:\n            # Update inertia weight dynamically\n            inertia = self.inertia * (0.5 + 0.5 * np.exp(-np.std(personal_best_fitnesses)))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], self.lb, self.ub)\n\n                # Evaluate fitness\n                fitness = func(population[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = population[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = population[i].copy()\n            \n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicParticleSwarm scored 0.296 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.12493030631575897, 0.17847696042384664, 0.30391993664100847, 0.35361704433616237, 0.19855675474933865, 0.27221656410798456, 0.24182856887142412, 0.23040797586844908, 0.2096046682917908, 0.1512303845003491, 0.1846870599970295, 0.9939622735138672, 0.2699088965440163, 0.24265679881031177, 0.604944280518698, 0.2562300933679328, 0.24612580541922813, 0.21254919946554696, 0.17902030030433902, 0.46975170153292856]}, "task_prompt": ""}
{"id": "475fbe2e-2fe3-48e6-a0c0-056fb01637b5", "fitness": 0.5495924157897956, "name": "ClampedPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass ClampedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max_ratio * (self.ub - self.lb)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Find best initial solution\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n            self.f_opt = fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Update velocities and positions\n            for i in range(self.pop_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                # Find global best\n                global_best_index = np.argmin(personal_best_fitness)\n                global_best_position = personal_best_positions[global_best_index]\n\n                velocities[i] = self.inertia * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                \n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -self.v_max, self.v_max)\n\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, self.lb, self.ub)\n\n                # Evaluate new position\n                new_fitness = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness\n                    personal_best_positions[i] = new_position\n\n                    # Update global best\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_position\n                \n                population[i] = new_position\n\n            # Adapt inertia dynamically (example - based on fitness variance)\n            fitness_std = np.std(personal_best_fitness)\n            if fitness_std > 0.1:  # Example threshold\n                self.inertia = np.clip(self.inertia + np.random.normal(0, 0.02), 0.4, 0.9)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ClampedPSO scored 0.550 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2165801290335343, 0.7575854097080693, 0.6698814490177677, 0.9110299181329021, 0.29832397445937897, 0.8361191405920539, 0.32685800201406645, 0.6509449956164253, 0.784118029591117, 0.18134561449483855, 0.8594328872304361, 0.9972506022284345, 0.2738822766560003, 0.26586810268052885, 0.7336321736962923, 0.7826555932679183, 0.3957588646116721, 0.3776618141744218, 0.21412634992308788, 0.4587929886669635]}, "task_prompt": ""}
{"id": "80b0b8fb-3867-470a-8357-9d7af9798ea0", "fitness": 0.4763645733528222, "name": "EnhancedDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, Cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.Cr = Cr\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        best_position = population[best_index]\n        best_fitness = fitness[best_index]\n\n        self.f_opt = best_fitness\n        self.x_opt = best_position\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Choose three distinct individuals\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                np.random.shuffle(indices)\n                a, b, c = indices[:3]\n\n                # Create a trial vector\n                trial_vector = population[i].copy()\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                         trial_vector[j] = population[i][j] + self.F * (best_position[j] - population[i][j]) + self.F * (population[a][j] - population[b][j])\n\n                # Clip the trial vector to the bounds\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the trial vector\n                trial_fitness = func(trial_vector)\n                self.budget -= 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial_vector\n\n                    # Update best solution found so far\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_position = trial_vector\n                        self.f_opt = best_fitness\n                        self.x_opt = best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedDifferentialEvolution scored 0.476 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.3440212807371733, 0.24775947186016378, 0.37601388822450443, 0.49885392216013824, 0.3619679652698926, 0.5323724881591023, 0.9018356704940719, 0.346184273562791, 0.36580737307264155, 0.19024067557811908, 0.4403377651096475, 0.9998285351266929, 0.4582029261037853, 0.35188372062075923, 0.710049774352459, 0.33080660319820954, 0.404551034700975, 0.40654509356534063, 0.7457463724804723, 0.5142826326795025]}, "task_prompt": ""}
{"id": "2cf7f9d1-48cd-4819-8eb1-16e690db6f35", "fitness": 0.24458962085175345, "name": "ModifiedPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass ModifiedPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.7, c1=1.5, c2=1.5, v_max=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.v_max = v_max  # Maximum velocity\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocities\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.v_max, self.v_max, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Find best initial solution (global best)\n        best_index = np.argmin(personal_best_fitness)\n        if personal_best_fitness[best_index] < self.f_opt:\n            self.f_opt = personal_best_fitness[best_index]\n            self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            # Calculate global best position\n            global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n            \n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                new_velocity = (self.inertia * velocities[i]\n                                + self.c1 * r1 * (personal_best_positions[i] - population[i])\n                                + self.c2 * r2 * (global_best_position - population[i]))\n                \n                # Velocity clamping\n                new_velocity = np.clip(new_velocity, -self.v_max, self.v_max)\n                velocities[i] = new_velocity\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                \n                # Boundary handling\n                new_position = np.clip(new_position, self.lb, self.ub)\n                \n                # Evaluate fitness\n                f_new = func(new_position)\n                self.budget -= 1\n\n                # Update personal best\n                if f_new < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f_new\n                    personal_best_positions[i] = new_position\n                    \n                    # Update global best\n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = new_position\n\n            # Dynamic inertia weight adjustment (based on swarm diversity)\n            diversity = np.std(personal_best_fitness)\n            if diversity < 0.1:  # If swarm is converging\n                self.inertia *= 0.95  # Reduce inertia to encourage exploration\n            else:\n                self.inertia = min(self.inertia * 1.05, 0.9) #Increase inertia to encourage exploration\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ModifiedPSO scored 0.245 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.098563575422002, 0.16291187818754804, 0.24563662195977343, 0.18611141863798653, 0.2053367937041427, 0.25185851600578213, 0.21140669565278625, 0.19575550800848207, 0.17802390694960646, 0.15394840506160168, 0.16607623196764942, 0.9950779126472465, 0.22677949320035284, 0.19586964705052456, 0.15773722422637804, 0.23940610337803414, 0.224841430903163, 0.20061314257230844, 0.14835306137937732, 0.4474848501203238]}, "task_prompt": ""}
{"id": "758e868c-bd53-4a1a-af40-f43ba6d5f10c", "fitness": 0.16148576566393216, "name": "SimpleCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimpleCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=1.0, cs=0.3, c_cov=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma  # Overall standard deviation\n        self.mean = np.zeros(dim)  # Mean of the search distribution\n        self.lb = -5.0\n        self.ub = 5.0\n        self.cs = cs\n        self.c_cov = c_cov\n        self.pc = np.zeros(dim)  # Evolution path for the mean\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.budget > 0:\n            # Sample population\n            population = np.random.normal(self.mean, self.sigma, size=(self.pop_size, self.dim))\n            population = np.clip(population, self.lb, self.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget]\n                population = population[:self.pop_size + self.budget]\n            \n            # Find best solution in population\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n            # Update distribution parameters\n            \n            # Weighted recombination\n            weights = np.sort(np.random.rand(len(fitness)))[::-1]  #random weights for recombination (can be adapted)\n            weights = weights / np.sum(weights)\n            x_mean = np.sum(population * weights[:, None], axis=0)\n\n            # Update evolution path\n            self.pc = (1 - self.cs) * self.pc + np.sqrt(self.cs * (2 - self.cs)) * (x_mean - self.mean) / self.sigma\n\n            # Update mean\n            self.mean = x_mean\n            \n            # Simple variance adaptation based on path length\n            self.sigma *= np.exp(self.c_cov/2 * (np.linalg.norm(self.pc)**2 - self.dim)/self.dim)\n            self.sigma = max(min(self.sigma,10), 0.001) # Clip sigma\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimpleCMAES scored 0.161 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.047542233877044926, 0.17061138196022452, 0.26560504038022426, 0.11166285203863702, 0.11938762602270458, 0.14293117631101526, 0.1884139852924337, 0.1438114762382463, 0.1637022698998799, 0.13565527416115142, 0.14677401951028746, 0.19016252756179164, 0.2524063298044821, 0.12782945936235923, 0.12105027998788698, 0.2707337064174994, 0.19272035466567194, 0.1535332246812804, 0.12983469620330712, 0.1553473989025148]}, "task_prompt": ""}
{"id": "d2e3c7dc-c85d-4d23-8482-5436c59238bb", "fitness": 0.738130546171825, "name": "CMAES_Restart", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES_Restart:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, stagnation_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        while self.budget > 0:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter +=1\n\n            if self.budget <= 0:\n                break\n                \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n            \n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n            \n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n            \n            # Update covariance matrix\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n            for i in range(self.mu):\n                C += self.ccov * self.weights[i] * (z[i, :, None] @ z[i, None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = self.sigma0\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CMAES_Restart scored 0.738 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2518492896622858, 0.28399714319124747, 0.9319079176962248, 0.9680526628928394, 0.9522379689642824, 0.9499929244465875, 0.3343051996485584, 0.9305045846781684, 0.9398354147541047, 0.9337593600348902, 0.9542274184628167, 0.9800616981926307, 0.27948921226394485, 0.9448928632411846, 0.9559566939370914, 0.7343390893829578, 0.8547011521006834, 0.9650507899560902, 0.11104913390388682, 0.5064004060260263]}, "task_prompt": ""}
{"id": "33532166-81be-480c-bf44-92e7cc12d3f5", "fitness": 0.27541276776748524, "name": "AdaptiveGaussianSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveGaussianSearch:\n    def __init__(self, budget=10000, dim=10, initial_std=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.initial_std = initial_std\n        self.cooling_rate = cooling_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n\n        std = self.initial_std\n        temperature = 1.0\n\n        while self.budget > 0:\n            # Mutation\n            x_new = np.clip(x + np.random.normal(0, std, size=self.dim), self.lb, self.ub)\n\n            # Evaluate new solution\n            f_new = func(x_new)\n            self.budget -= 1\n\n            # Acceptance criterion (Simulated Annealing)\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                x = x_new\n                f = f_new\n            else:\n                delta = f_new - f\n                acceptance_probability = np.exp(-delta / temperature)\n                if np.random.rand() < acceptance_probability:\n                    x = x_new\n                    f = f_new\n            \n            # Reduce standard deviation and temperature\n            std *= self.cooling_rate\n            temperature *= self.cooling_rate\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveGaussianSearch scored 0.275 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11730350411069324, 0.17379891689068905, 0.21566450710580465, 0.39330684211293987, 0.25681005289921566, 0.3047705355143554, 0.2393258856182221, 0.2402047246924508, 0.22883006246813042, 0.1824412392507403, 0.352007680487053, 0.2021444369327754, 0.2372346362401131, 0.31980549670873093, 0.5557491831638565, 0.2326318945414697, 0.25027948117924803, 0.3372967719420902, 0.22871780930985697, 0.4399316941812691]}, "task_prompt": ""}
{"id": "74f96db4-0b6d-4525-a6c3-faa1796e8e53", "fitness": 0.17308875966271603, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95, temp_min=1e-5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.temp_min = temp_min\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize solution\n        current_x = np.random.uniform(self.lb, self.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n        \n        temp = self.initial_temp\n        acceptance_rate = 0.0\n        acceptance_count = 0\n\n        while self.budget > 0 and temp > self.temp_min:\n            # Generate neighbor solution\n            new_x = current_x + np.random.normal(0, 0.1, size=self.dim)  # Small perturbation\n            new_x = np.clip(new_x, self.lb, self.ub)  # Clip to bounds\n            \n            new_f = func(new_x)\n            self.budget -= 1\n            \n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                current_x = new_x\n                current_f = new_f\n                acceptance_count +=1\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n\n            #Adaptive Temperature Cooling\n            acceptance_rate = acceptance_count / (self.budget + acceptance_count) if (self.budget + acceptance_count) > 0 else 0.0\n            if acceptance_rate > 0.5:\n                temp *= 0.9 #cool more slowly\n            else:\n                temp *= self.cooling_rate #cool faster\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.173 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08168255761970244, 0.08834468209075019, 0.22430834411873324, 0.1227308312527392, 0.17509917129391395, 0.10404832577990442, 0.1670016442203207, 0.11687866119176937, 0.14442687973530077, 0.11120665781349126, 0.19046248577470581, 0.18264157782558665, 0.24546684977741295, 0.1140999669754228, 0.5735211584421576, 0.21283061687281124, 0.15469708674837435, 0.14724976308898352, 0.1411190814349922, 0.1639588511972484]}, "task_prompt": ""}
{"id": "525a1b91-6404-4fb4-a439-9bd4d9c89b23", "fitness": 0.4699849133770977, "name": "SimplifiedCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma0\n        self.mean = None\n        self.C = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.restart_trigger = 100  # Threshold for stagnation detection\n        self.stagnation_counter = 0\n    \n    def initialize(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n\n    def sample_population(self):\n        z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n        return self.mean + self.sigma * np.dot(z, np.linalg.cholesky(self.C).T)\n\n    def __call__(self, func):\n        self.initialize(func)\n        \n        weights = np.log(self.pop_size + 1) - np.log(np.arange(1, self.pop_size + 1))\n        weights = weights / np.sum(weights)\n        mu = self.pop_size // 4\n\n        while self.budget > 0:\n            # Sample population\n            population = self.sample_population()\n            population = np.clip(population, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate fitness\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            population = population[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = population[0]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n                \n            # Update mean\n            delta_mean = np.sum(weights[:mu, None] * (population[:mu] - self.mean), axis=0)\n            self.mean += delta_mean\n\n            # Rank-one update of covariance matrix\n            self.C = (1 - 0.1) * self.C + 0.1 * delta_mean[:, None] @ delta_mean[None, :] / (self.sigma**2)\n\n            # Update step size\n            self.sigma *= np.exp(0.2 * (np.mean(fitness) - fitness[0]) / np.std(fitness))\n            self.sigma = np.clip(self.sigma, 1e-10, 1) # Avoid sigma explosion\n\n            # Check for stagnation and restart\n            if self.stagnation_counter > self.restart_trigger:\n                self.initialize(func)\n                self.stagnation_counter = 0\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimplifiedCMAES scored 0.470 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19392683913775954, 0.18905485320557525, 0.9109181715362855, 0.2572288027048574, 0.23767081637731202, 0.9303426298423146, 0.22995442476520322, 0.8908582369289929, 0.17781583250110544, 0.9126481458036465, 0.19600058520514507, 0.19910980066309913, 0.2796857468021845, 0.9160009246411286, 0.5431765174099341, 0.43750731870073356, 0.3322933601505058, 0.9456725805170968, 0.12796139809381057, 0.4918712825552629]}, "task_prompt": ""}
{"id": "7a6f68d1-6f72-4ff2-884b-5f92889c3684", "fitness": 0.30089585461761237, "name": "AdaptiveHyperrectangleSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveHyperrectangleSearch:\n    def __init__(self, budget=10000, dim=10, num_elite=5, initial_side_length=1.0, shrink_factor=0.9, expand_factor=1.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_elite = num_elite\n        self.initial_side_length = initial_side_length\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.elite_solutions = []\n        self.elite_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize with random samples\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.num_elite, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.num_elite\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        self.elite_solutions = population.tolist()\n        self.elite_fitness = fitness.tolist()\n\n        side_lengths = np.full(self.dim, self.initial_side_length)\n\n        while self.budget > 0:\n            # Sort elite solutions by fitness\n            sorted_indices = np.argsort(self.elite_fitness)\n            self.elite_solutions = [self.elite_solutions[i] for i in sorted_indices]\n            self.elite_fitness = [self.elite_fitness[i] for i in sorted_indices]\n\n            # Sample within hyperrectangles around elite solutions\n            for i in range(self.num_elite):\n                center = self.elite_solutions[i]\n                lb = np.clip(center - side_lengths / 2, func.bounds.lb, func.bounds.ub)\n                ub = np.clip(center + side_lengths / 2, func.bounds.lb, func.bounds.ub)\n                \n                x = np.random.uniform(lb, ub)\n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n                # Update elite solutions if better\n                if f < self.elite_fitness[-1]:\n                    self.elite_fitness[-1] = f\n                    self.elite_solutions[-1] = x.tolist()\n                    \n                    #Adjust the hyperrectangle side length if improvement is found\n                    side_lengths *= self.shrink_factor #Shrink the hyperrectangle\n\n                else:\n                    side_lengths *= self.expand_factor # Expand the hyperrectangle if no improvement is found\n                    \n                side_lengths = np.clip(side_lengths, 1e-6, func.bounds.ub - func.bounds.lb)  # Avoid zero side length\n                    \n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveHyperrectangleSearch scored 0.301 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1143047188915034, 0.19786535148227136, 0.2690486231502677, 0.2500887137374661, 0.2230411747426706, 0.2690955071762241, 0.2539322882865749, 0.22364594390375048, 0.21857502178202626, 0.17609199357385497, 0.24374804802638528, 0.9953444377091424, 0.26090239945229343, 0.23095516297564367, 0.5671518322352456, 0.30399790911725477, 0.24764024852698807, 0.31158694309235124, 0.18092464055765423, 0.47997613393267935]}, "task_prompt": ""}
{"id": "614143cf-3ec6-489e-9de0-a0c775bc0ebf", "fitness": 0.5584795577238172, "name": "PSO_DE", "description": "No description provided.", "code": "import numpy as np\n\nclass PSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, w=0.7, c1=1.5, c2=1.5, F=0.8, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.F = F # Mutation factor\n        self.CR = CR # Crossover rate\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and fitnesses\n        personal_best_positions = population.copy()\n        personal_best_fitnesses = np.array([func(x) for x in population])\n        \n        # Find global best position and fitness\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitnesses[global_best_index]\n\n        self.budget -= self.pop_size\n        \n        if global_best_fitness < self.f_opt:\n            self.f_opt = global_best_fitness\n            self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                              self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                              self.c2 * r2 * (global_best_position - population[i])\n\n                # Update position\n                population[i] = np.clip(population[i] + velocities[i], func.bounds.lb, func.bounds.ub)\n\n                # Differential Evolution part\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate fitness\n                fitness = func(trial)\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = trial\n\n                    # Update global best\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = trial\n                        \n                        if fitness < self.f_opt:\n                            self.f_opt = fitness\n                            self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PSO_DE scored 0.558 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19718028016117894, 0.3218688460810959, 0.5245781321485012, 0.824916251593099, 0.28418462369700004, 0.6492698195759208, 0.49078926888302943, 0.4674144222233074, 0.5642552166140276, 0.5866952602696585, 0.7864827688424824, 0.9995753780946827, 0.2859379755612482, 0.6208356854986895, 0.8119883652380144, 0.6784705006295355, 0.45961275667237855, 0.7777404053020696, 0.3084450606290361, 0.529350136761388]}, "task_prompt": ""}
{"id": "4d2e5eb4-8026-45e7-9e64-73ed06475c5d", "fitness": 0.6668344652954767, "name": "AdaptiveSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, initial_sigma=0.5, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = initial_sigma\n        self.adaptation_rate = adaptation_rate\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n         self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.population])\n         self.budget -= self.pop_size\n         if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n                \n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            # Generate offspring by sampling from a normal distribution around each parent\n            offspring = self.population + np.random.normal(0, self.sigma, size=(self.pop_size, self.dim))\n            offspring = np.clip(offspring, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate the offspring\n            offspring_fitness = np.array([func(x) for x in offspring])\n            self.budget -= self.pop_size\n\n            # Select the best individuals from the parent and offspring populations\n            combined_population = np.concatenate((self.population, offspring))\n            combined_fitness = np.concatenate((self.fitness, offspring_fitness))\n            \n            idx = np.argsort(combined_fitness)[:self.pop_size]\n            self.population = combined_population[idx]\n            self.fitness = combined_fitness[idx]\n\n            # Update the best solution found so far\n            if np.min(self.fitness) < self.f_opt:\n                self.f_opt = np.min(self.fitness)\n                self.x_opt = self.population[np.argmin(self.fitness)]\n\n            # Adapt the step size based on the success rate\n            success_rate = np.sum(offspring_fitness < self.fitness) / self.pop_size\n            if success_rate > 0.2:\n                self.sigma *= (1 + self.adaptation_rate)\n            elif success_rate < 0.1:\n                self.sigma *= (1 - self.adaptation_rate)\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSearch scored 0.667 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.177232685288625, 0.848407323516943, 0.7887255417521876, 0.8832247442964053, 0.8197533252402149, 0.8391310644984584, 0.34147862131792606, 0.7422310972431583, 0.8008374443623989, 0.48195320280375253, 0.9025344435258754, 0.9990869875404783, 0.2615885480960568, 0.7866953896294722, 0.7405197394215011, 0.8440311461777159, 0.41823113602033923, 0.8858038148076497, 0.24624402025582626, 0.5289790301145507]}, "task_prompt": ""}
{"id": "e85b3b2d-53d0-4a54-b403-bbe74bfe0bcf", "fitness": 0.5377645096478052, "name": "AdaptiveSampling", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSampling:\n    def __init__(self, budget=10000, dim=10, initial_radius=0.5, radius_decay=0.95, radius_increase=1.1, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_radius = initial_radius\n        self.radius_decay = radius_decay\n        self.radius_increase = radius_increase\n        self.success_threshold = success_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize\n        x_best = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f_best = func(x_best)\n        self.budget -= 1\n        self.f_opt = f_best\n        self.x_opt = x_best\n        radius = self.initial_radius\n        successes = 0\n        iterations = 0\n\n        while self.budget > 0:\n            # Sample around the best solution\n            x_new = np.clip(np.random.normal(x_best, radius, size=self.dim), func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n            iterations += 1\n\n            # Update best solution\n            if f_new < f_best:\n                f_best = f_new\n                x_best = x_new\n                successes += 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n                \n\n            # Adjust the sampling radius\n            if iterations > 10:\n                success_rate = successes / iterations\n                if success_rate > self.success_threshold:\n                    radius *= self.radius_increase  # Increase radius if successful\n                else:\n                    radius *= self.radius_decay  # Decrease radius if not successful\n                successes = 0\n                iterations = 0\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSampling scored 0.538 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07808654939297599, 0.15811226571774528, 0.8803084464393146, 0.9477238393320951, 0.37663392300919674, 0.9042254597356233, 0.24653011593469765, 0.48230769734278456, 0.8876111597562515, 0.16285996684025272, 0.956095512291404, 0.9996956005251335, 0.22315746189984143, 0.21805893378524277, 0.916020276077865, 0.3260069728537157, 0.6736105177373586, 0.9361627677015716, 0.16736333105363577, 0.214719395529399]}, "task_prompt": ""}
{"id": "53772d07-aaec-4188-a25e-36d53a20e1da", "fitness": 0.7483078356646484, "name": "ModifiedDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass ModifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F_initial = 0.7  # Initial mutation factor\n        self.F_final = 0.2    # Final mutation factor\n        self.CR = 0.9  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            F = self.F_initial + (self.F_final - self.F_initial) * generation / (self.budget + generation)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Tournament selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                else:\n                    # Tournament: Replace with a better random individual with certain probability.\n                    if np.random.rand() < 0.1:\n                        rand_idx = np.random.randint(0, self.pop_size)\n                        if fitness[rand_idx] < fitness[i]:\n                            fitness[i] = fitness[rand_idx]\n                            population[i] = population[rand_idx]\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ModifiedDifferentialEvolution scored 0.748 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.22177289451527982, 0.3959487718044077, 0.8046781034196905, 0.9341898394275456, 0.8492282087557768, 0.8756756458865483, 0.8026457087279577, 0.7695575096777669, 0.8471790877526947, 0.8204237122060771, 0.9073339827255196, 0.9906586265763004, 0.7128937479560145, 0.84442517626047, 0.9400776226774994, 0.8574054508452468, 0.7745465044703433, 0.9068853996587329, 0.1757935194157988, 0.5348372005332954]}, "task_prompt": ""}
{"id": "9f5cd520-b581-4de4-9f0e-7e3104054cbf", "fitness": 0.5813868578060772, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = x_r1 + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < self.fitness[i]:\n                    self.population[i] = x_trial\n                    self.fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n            \n            # Adapt F and CR based on population diversity\n            if self.budget <= 0:\n                break\n\n            diversity = np.std(self.fitness)\n            if diversity > 0.1:  # Example threshold, adjust as needed\n                self.F = np.clip(self.F + 0.01, 0.1, 0.9)\n                self.CR = np.clip(self.CR - 0.01, 0.1, 0.9)\n            else:\n                self.F = np.clip(self.F - 0.01, 0.1, 0.9)\n                self.CR = np.clip(self.CR + 0.01, 0.1, 0.9)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.581 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.21514681896290455, 0.3557226969708006, 0.39967204589489624, 0.9288387970252596, 0.5968767497500753, 0.695204864561713, 0.4440201885455677, 0.5290722495658988, 0.7878717545257443, 0.655137952035909, 0.9272763648410994, 0.9894054692530507, 0.2858110405191686, 0.5749642446338554, 0.7016002245320045, 0.5729928101012622, 0.40361330261102313, 0.8034183198844704, 0.24647613388079237, 0.5146151280260503]}, "task_prompt": ""}
{"id": "558aac66-7915-4ee2-94b2-ba161e7740cd", "fitness": 0.4623496600878395, "name": "ConstrictionPSO", "description": "No description provided.", "code": "import numpy as np\n\nclass ConstrictionPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, c1=2.05, c2=2.05, mutation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n\n        phi = self.c1 + self.c2\n        if phi > 4:\n            self.K = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi))\n        else:\n            self.K = 1  # No constriction if phi is not greater than 4\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        if np.min(personal_best_fitness) < self.f_opt:\n            self.f_opt = np.min(personal_best_fitness)\n            self.x_opt = personal_best_positions[np.argmin(personal_best_fitness)]\n\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        global_best_fitness = np.min(personal_best_fitness)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = self.K * (velocities[i] +\n                                         self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                         self.c2 * r2 * (global_best_position - particles[i]))\n\n                # Velocity clamping\n                v_max = 0.2 * (func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                \n                # Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.uniform(-0.1 * (func.bounds.ub - func.bounds.lb), 0.1 * (func.bounds.ub - func.bounds.lb), size=self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = particles[i]\n\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = particles[i]\n                        \n                        self.f_opt = global_best_fitness\n                        self.x_opt = global_best_position\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ConstrictionPSO scored 0.462 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18359930094794807, 0.412561706042061, 0.4251906947906947, 0.7828869299544581, 0.3735951410999343, 0.5076994565165645, 0.33683958015775983, 0.38687669991511664, 0.3621637396664873, 0.2067087246175635, 0.44782958283918783, 0.9955217947776662, 0.2464573728358499, 0.39407956537647537, 0.8104690311013192, 0.6160032443801624, 0.3665801636222008, 0.5584905582613426, 0.3170447705511269, 0.5163951443028725]}, "task_prompt": ""}
{"id": "018e9259-f725-4b19-9afe-82d1f5ab0572", "fitness": 0.4103066897463689, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, F_adapt_rate=0.1, CR_adapt_rate=0.1, success_history_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.F_adapt_rate = F_adapt_rate\n        self.CR_adapt_rate = CR_adapt_rate\n        self.success_history_size = success_history_size\n        self.success_F_history = []\n        self.success_CR_history = []\n        self.success_count = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                mutant = population[i] + self.F * (x_r2 - x_r3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant, population[i])\n                \n                # Selection\n                f = func(trial_vector)\n                self.budget -= 1\n                if f < fitness[i]:\n                    self.success_count += 1\n                    \n                    self.success_F_history.append(self.F)\n                    self.success_CR_history.append(self.CR)\n                    \n                    population[i] = trial_vector\n                    fitness[i] = f\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial_vector\n\n                if self.budget <= 0:\n                    break\n                    \n            #Adapt parameters every generation after the initial burn-in of 10 generations\n            if len(self.success_F_history) >= self.success_history_size:\n                #Adapt F parameter\n                success_F_mean = np.mean(self.success_F_history[-self.success_history_size:])\n                self.F = self.F + self.F_adapt_rate * (success_F_mean - self.F)\n                self.F = np.clip(self.F, 0.1, 0.9)\n                \n                #Adapt CR parameter\n                success_CR_mean = np.mean(self.success_CR_history[-self.success_history_size:])\n                self.CR = self.CR + self.CR_adapt_rate * (success_CR_mean - self.CR)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.410 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16056351605801267, 0.2620589115612414, 0.38994951032152314, 0.5987574936687312, 0.3309365145865486, 0.4325140509627249, 0.2975759885146031, 0.3463329394474315, 0.31739679604576065, 0.18859197205005085, 0.5242723592089875, 0.999659194530618, 0.3033692687816294, 0.3176599727338215, 0.7745946482820923, 0.4470511890743645, 0.33363882324995564, 0.5160094244115618, 0.17717444952541517, 0.48802677191230404]}, "task_prompt": ""}
{"id": "e90db770-e6f1-4103-b985-099fbc31717f", "fitness": 0.36080143256589714, "name": "AdaptiveSOMA", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSOMA:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = 0.1  # Initial step size\n        self.path_length = 2.0 # Initial path length\n        self.PRT = 0.1 # perturbation probability\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Find the leader (best individual)\n            leader_idx = np.argmin(fitness)\n            leader = population[leader_idx]\n\n            new_population = np.copy(population)\n\n            for i in range(self.pop_size):\n                if i == leader_idx:\n                    continue\n\n                # Migrate towards the leader\n                for j in range(1, int(self.path_length / self.step_size) + 1):\n                    new_position = population[i] + j * self.step_size * (leader - population[i])\n                    \n                    # Perturbation\n                    perturb_mask = np.random.rand(self.dim) < self.PRT\n                    new_position = np.where(perturb_mask, np.random.uniform(func.bounds.lb, func.bounds.ub, size = self.dim), new_position)\n                    \n                    new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                    f = func(new_position)\n                    self.budget -= 1\n                    if f < fitness[i]:\n                        fitness[i] = f\n                        new_population[i] = new_position\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = new_position\n                    if self.budget <= 0:\n                        break\n                if self.budget <= 0:\n                    break\n\n            population = new_population\n            #Adapt step size\n            self.step_size *= 0.99\n            self.path_length *= 0.99\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSOMA scored 0.361 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14325930187185054, 0.19198203524318846, 0.33859924569654154, 0.4646048194857624, 0.26932524771990207, 0.40819458375852213, 0.30024833407208784, 0.2966272605080358, 0.2897185849936341, 0.17992166003329368, 0.3241950252430723, 0.9991668285465656, 0.2760527945042942, 0.2657983105538255, 0.6773869787871699, 0.39626245327774834, 0.2872117569475334, 0.42459828155677193, 0.1951032705510971, 0.4877718779670449]}, "task_prompt": ""}
{"id": "eede4f41-9bba-4cdd-962e-fd88dc610916", "fitness": 0.6023721480095029, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 15 * dim\n        self.F = F\n        self.CR = CR\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Store best solution\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation: Self-adaptive F and CR\n                F_i = np.random.normal(self.F, 0.1, 1)[0]\n                F_i = np.clip(F_i, 0.1, 1.0)\n                CR_i = np.random.normal(self.CR, 0.1, 1)[0]\n                CR_i = np.clip(CR_i, 0.1, 1.0)\n\n                # Select three random indices, different from each other and i\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                r1, r2, r3 = idxs\n\n                # Create mutant vector\n                mutant = population[r1] + F_i * (population[r2] - population[r3])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR_i\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluation\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    # Update best solution\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.602 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2321289265145492, 0.5423951656403126, 0.5349355880627416, 0.816602703005023, 0.6601193582180891, 0.6781474183652249, 0.4486814690062151, 0.5291617271919469, 0.6265748421562475, 0.5015895812623513, 0.8078030162589716, 0.9994190064112399, 0.4893643042585232, 0.6211090200277352, 0.8887294479369734, 0.6761138947854043, 0.47162408683819845, 0.7749078784088784, 0.23017322748187163, 0.5178622983595589]}, "task_prompt": ""}
{"id": "34380b54-1e2f-4043-a5fb-537f7e2f3841", "fitness": 0.5641693889434721, "name": "ModifiedDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass ModifiedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 20, dim * pop_multiplier)  # Smaller adaptive population size\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            # Rank the population based on fitness\n            ranked_indices = np.argsort(fitness)\n            \n            for i in range(self.pop_size):\n                # Mutation (Cauchy distribution)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                #Cauchy distributed mutation factor\n                cauchy_F = self.F * np.random.standard_cauchy()\n                mutant = np.clip(a + cauchy_F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                #Rank-based selection: only update if better than the worst in top half\n                cutoff_rank = self.pop_size // 2\n                worst_in_top_half_idx = ranked_indices[cutoff_rank]\n                \n                if f < fitness[worst_in_top_half_idx]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ModifiedDifferentialEvolution scored 0.564 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.20890467530124357, 0.39494660660264347, 0.7639405003970338, 0.8624429002212253, 0.2854654951626884, 0.5368024469070309, 0.325566670690169, 0.5027114277112128, 0.8271046611777542, 0.8286451833164564, 0.33836896600047284, 0.9992444673099492, 0.2881164646770794, 0.8700556067534604, 0.5887131314688392, 0.8957277030176036, 0.28491944557886806, 0.2241072365542991, 0.7824915622169137, 0.4751126278045009]}, "task_prompt": ""}
{"id": "f759ff22-9a54-48ef-8470-3a1ad028e767", "fitness": 0.3079372922549944, "name": "SelfAdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=20, F=0.5, CR=0.7, restart_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.restart_prob = restart_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n            \n    def __call__(self, func):\n        self.initialize_population(func)\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                # Restart mechanism\n                if np.random.rand() < self.restart_prob:\n                    self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    self.budget -= 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDE scored 0.308 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14497336798893123, 0.21597875775611086, 0.3107947103838743, 0.28020562785436, 0.24253928222812215, 0.2765618578205912, 0.2734996550973082, 0.2635309865709248, 0.237181936896937, 0.17877662884791246, 0.2787908859110012, 0.9974322579361081, 0.30842463947008314, 0.2564001960273934, 0.661905885290252, 0]}, "task_prompt": ""}
{"id": "864024ff-6b1a-44db-b050-2282d93856e4", "fitness": 0.2053127354574225, "name": "SimplifiedCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mean = None\n        self.sigma = 1.0\n        self.C = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim) if self.mean is None else self.mean\n        self.C = np.eye(self.dim) if self.C is None else self.C\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.mean + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            # Selection and update\n            idx = np.argsort(fitness)\n            x_sorted = x[idx[:self.mu]]\n            z_sorted = z[idx[:self.mu]]\n\n            self.mean = np.sum(self.weights[:, None] * x_sorted, axis=0)\n            \n            # Simplified covariance matrix adaptation\n            C_temp = np.sum(self.weights[:, None, None] * (z_sorted[:, :, None] @ z_sorted[:, None, :]), axis=0)\n            self.C = (1 - 0.1) * self.C + 0.1 * C_temp\n\n            # Update step size\n            self.sigma *= np.exp(0.2 * (np.mean(fitness[idx[:self.mu]]) - np.mean(fitness)) / np.std(fitness)) # Adjust step size adaptively\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SimplifiedCMAES scored 0.205 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08030773976973082, 0.15581393742576255, 0.2775729375301358, 0.13081225320416834, 0.21636723628347776, 0.15583575727083865, 0.22995595565109705, 0.24854317071653587, 0.16538893750515193, 0.16503030205691216, 0.1540862621542608, 0.156004873640897, 0.2299142061083006, 0.16402756815583397, 0.544154910245087, 0.26821081694340587, 0.3010774117010585, 0.15360939073941282, 0.13320688130713132, 0.17633416073925223]}, "task_prompt": ""}
{"id": "8b63a1a6-810b-4177-91ea-6e0110efe681", "fitness": 0.5197250256726667, "name": "AdaptiveNelderMead", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveNelderMead:\n    def __init__(self, budget=10000, dim=10, alpha=1.0, beta=0.5, gamma=2.0, sigma=0.1, restart_threshold=100):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha  # Reflection coefficient\n        self.beta = beta    # Contraction coefficient\n        self.gamma = gamma  # Expansion coefficient\n        self.sigma = sigma  # Shrink coefficient\n        self.restart_threshold = restart_threshold\n        self.restart_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_simplex(self, func):\n        simplex = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim + 1, self.dim))\n        fitness = np.array([func(x) for x in simplex])\n        self.budget -= self.dim + 1\n        return simplex, fitness\n\n    def __call__(self, func):\n        simplex, fitness = self.initialize_simplex(func)\n        \n        while self.budget > 0:\n            # Order the simplex\n            idx = np.argsort(fitness)\n            simplex = simplex[idx]\n            fitness = fitness[idx]\n            \n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = simplex[0]\n                self.restart_counter = 0\n            else:\n                self.restart_counter += 1\n            \n            if self.budget <= 0:\n                break\n\n            # Centroid of the best n points\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            reflected = centroid + self.alpha * (centroid - simplex[-1])\n            reflected = np.clip(reflected, func.bounds.lb, func.bounds.ub)\n            f_reflected = func(reflected)\n            self.budget -= 1\n\n            if self.budget <= 0:\n                break\n            \n            if fitness[0] <= f_reflected < fitness[-2]:\n                simplex[-1] = reflected\n                fitness[-1] = f_reflected\n            else:\n                # Expansion\n                if f_reflected < fitness[0]:\n                    expanded = centroid + self.gamma * (reflected - centroid)\n                    expanded = np.clip(expanded, func.bounds.lb, func.bounds.ub)\n                    f_expanded = func(expanded)\n                    self.budget -= 1\n\n                    if self.budget <= 0:\n                        break\n\n                    if f_expanded < f_reflected:\n                        simplex[-1] = expanded\n                        fitness[-1] = f_expanded\n                    else:\n                        simplex[-1] = reflected\n                        fitness[-1] = f_reflected\n                else:\n                    # Contraction\n                    contracted = centroid + self.beta * (simplex[-1] - centroid)\n                    contracted = np.clip(contracted, func.bounds.lb, func.bounds.ub)\n                    f_contracted = func(contracted)\n                    self.budget -= 1\n                    \n                    if self.budget <= 0:\n                        break\n\n                    if f_contracted < fitness[-1]:\n                        simplex[-1] = contracted\n                        fitness[-1] = f_contracted\n                    else:\n                        # Shrink\n                        for i in range(1, self.dim + 1):\n                            simplex[i] = simplex[0] + self.sigma * (simplex[i] - simplex[0])\n                            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n                            fitness[i] = func(simplex[i])\n                            self.budget -= 1\n\n                            if self.budget <= 0:\n                                break\n                        if self.budget <= 0:\n                            break\n\n            if self.restart_counter > self.restart_threshold:\n                simplex, fitness = self.initialize_simplex(func)\n                self.restart_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveNelderMead scored 0.520 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13757469088531837, 0.37382228682264707, 0.47451951997039354, 0.4893812095931238, 0.3755570271232852, 0.9804985369283684, 0.30769007486964683, 0.3000022993168511, 0.30792557003077536, 0.1904708415669505, 0.867552607928719, 0.9992641455795968, 0.5777001023566842, 0.6877828827594736, 0.9416102271532201, 0.4332270064127971, 0.32116111894188837, 0.988527555836689, 0.16646062696073427, 0.4737721824161687]}, "task_prompt": ""}
{"id": "0cfd50ff-f941-4cde-84b6-3c24cc5e7754", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=None, ccov1=None, ccovmu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = sigma\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Strategy parameter setting: Selection\n        self.mu = self.pop_size // 2  # Number of parents/individuals for recombination\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        # Strategy parameter setting: Adaptation\n        self.cs = cs\n        self.damps = damps if damps is not None else 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov1 = ccov1 if ccov1 is not None else 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.ccovmu = ccovmu if ccovmu is not None else 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2.0)**2 + self.mueff)\n        self.ccov1 = min(1, self.ccov1 * (self.dim + 1.5) / (3 + (self.dim + 1.5) * self.ccovmu))\n        self.chiN = self.dim**0.5 * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))\n\n    def __call__(self, func):\n        # Initialize dynamic (internal) strategy parameters and constants\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Mean value\n        P_sigma = np.zeros(self.dim)  # Evolution path for sigma\n        P_C = np.zeros(self.dim)  # Evolution path for C\n        C = np.eye(self.dim)      # Covariance matrix\n        invC = np.linalg.inv(C)    # Inverse covariance matrix\n\n        while self.budget > 0:\n            # Generate and evaluate lambda offspring\n            Z = np.random.normal(0, 1, size=(self.pop_size, self.dim))  # iid Gaussian samples\n            Y = np.dot(Z, np.linalg.cholesky(C).T) # Samples from multivariate normal\n            X = mean + self.sigma * Y                 # Add mean\n            X = np.clip(X, func.bounds.lb, func.bounds.ub)\n\n            fitness = np.array([func(x) for x in X])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = X[np.argmin(fitness)]\n\n            # Sort by fitness and compute weighted mean into mean\n            idx = np.argsort(fitness)\n            x_mu = X[idx[:self.mu]]\n            weights = self.weights\n            mean_new = np.sum(x_mu * weights[:, None], axis=0)\n\n            # Cumulation: Update evolution paths\n            y_mu = Y[idx[:self.mu]]\n            zmean = np.sum(y_mu * weights[:, None], axis=0)\n            P_sigma = (1 - self.cs) * P_sigma + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * zmean\n            hsig = np.linalg.norm(P_sigma)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.budget)) / self.chiN < 1 + 2/(self.dim+1)\n\n            dC = np.outer(P_sigma, P_sigma)\n            P_C = (1-self.ccov1) * P_C + hsig * np.sqrt(self.ccov1 * (2-self.ccov1) * self.mueff) * zmean\n            C = (1 - self.ccov1 - self.ccovmu) * C + self.ccov1 * dC + self.ccovmu * np.dot(y_mu.T, np.diag(weights)).dot(y_mu)\n\n            # Adapt step size sigma\n            self.sigma = self.sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(P_sigma)/self.chiN - 1))\n\n            # Update mean\n            mean = mean_new\n\n            # Repair covariance matrix\n            C = np.triu(C) + np.triu(C, 1).T\n            C = (C + C.T) / 2\n            try:\n                np.linalg.cholesky(C)\n                invC = np.linalg.inv(C)\n            except np.linalg.LinAlgError:\n                C = np.eye(self.dim)\n                invC = np.eye(self.dim)\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 58, in __call__, the following error occurred:\nZeroDivisionError: division by zero\nOn line: hsig = np.linalg.norm(P_sigma)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.budget)) / self.chiN < 1 + 2/(self.dim+1)", "error": "In the code, line 58, in __call__, the following error occurred:\nZeroDivisionError: division by zero\nOn line: hsig = np.linalg.norm(P_sigma)/np.sqrt(1-(1-self.cs)**(2*self.budget/self.budget)) / self.chiN < 1 + 2/(self.dim+1)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "0f004103-6446-47e3-9266-9146bf81ef8f", "fitness": 0.21852934561187087, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100, cooling_rate=0.95, reannealing_prob=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.reannealing_prob = reannealing_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        if current_f < self.f_opt:\n            self.f_opt = current_f\n            self.x_opt = current_x\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = current_x + np.random.normal(0, 0.1, size=self.dim)  # Adjust step size as needed\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                current_x = new_x\n                current_f = new_f\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n\n            # Temperature update\n            temperature *= self.cooling_rate\n\n            # Re-annealing\n            if np.random.rand() < self.reannealing_prob:\n                temperature = self.initial_temp\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.219 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08610420059994739, 0.15986560946068507, 0.2265956238527268, 0.1424399697665667, 0.159339985995397, 0.21106694873670384, 0.19727539126716154, 0.1850587510646695, 0.1803590479945706, 0.1140769908373852, 0.21098179573288556, 0.5569688217635651, 0.28656535000027783, 0.11994012249377484, 0.49946753529174015, 0.17075148390373018, 0.261059324147331, 0.16729652898087077, 0.13964170699715306, 0.2957317233502744]}, "task_prompt": ""}
{"id": "0ff93d4c-4287-47ce-8e13-c7027aece092", "fitness": 0.29457612576635317, "name": "GlobalLocalSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass GlobalLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.step_size = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        if fitness[best_idx] < self.f_opt:\n            self.f_opt = fitness[best_idx]\n            self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Global search: Randomly select a solution and perturb it\n            idx = np.random.randint(0, self.pop_size)\n            x = population[idx] + self.step_size * np.random.normal(0, 1, self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            f = func(x)\n            self.budget -= 1\n\n            if f < fitness[idx]:\n                fitness[idx] = f\n                population[idx] = x\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    self.step_size *= 0.95 # reduce step size when finding better solution\n\n            # Local search around the best solution\n            for _ in range(self.local_steps):\n                x_local = self.x_opt + self.step_size * np.random.normal(0, 1, self.dim)\n                x_local = np.clip(x_local, func.bounds.lb, func.bounds.ub)\n                f_local = func(x_local)\n                self.budget -= 1\n\n                if f_local < self.f_opt:\n                    self.f_opt = f_local\n                    self.x_opt = x_local\n                    self.step_size *= 0.95  # reduce step size when finding better solution\n\n                if self.budget <= 0:\n                    break\n\n            if self.budget <= 0:\n                break\n\n            if self.step_size < 1e-5:\n                self.step_size = 0.1\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm GlobalLocalSearch scored 0.295 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0920438556783747, 0.1782144107877468, 0.24761930600499837, 0.2538983278197373, 0.17542024014083268, 0.16258472047250938, 0.24601850891546306, 0.16740165500985382, 0.15160939189772638, 0.13753390584961822, 0.49736488970088644, 0.9992428897976122, 0.2640005876919129, 0.14141334707532083, 0.6837046557997938, 0.3285529877345882, 0.18471069745504265, 0.3784473269986969, 0.17421419087069667, 0.4275266196256521]}, "task_prompt": ""}
{"id": "c69d7824-7ac1-4770-997e-db38aa4b9ad9", "fitness": 0.13383745619327533, "name": "HybridSearch", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_steps=5, exploration_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_steps = local_steps\n        self.exploration_prob = exploration_prob\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        if np.min(self.fitness) < self.f_opt:\n            self.f_opt = np.min(self.fitness)\n            self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def local_refinement(self, func, x, steps):\n        x_current = x.copy()\n        f_current = func(x_current)\n        self.budget -= 1\n        if f_current < self.f_opt:\n            self.f_opt = f_current\n            self.x_opt = x_current\n        \n        for _ in range(steps):\n            gradient = np.random.uniform(-0.1, 0.1, size=self.dim)\n            x_new = np.clip(x_current - 0.01 * gradient, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            if f_new < f_current:\n                x_current = x_new\n                f_current = f_new\n                if f_current < self.f_opt:\n                    self.f_opt = f_current\n                    self.x_opt = x_current\n            else:\n                break\n\n            if self.budget <= 0:\n                break\n        return x_current, f_current\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_prob:\n                    # Global Search: Replace with a random point\n                    x_new = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                    f_new = func(x_new)\n                    self.budget -= 1\n\n                    if f_new < self.fitness[i]:\n                        self.fitness[i] = f_new\n                        self.population[i] = x_new\n                        if f_new < self.f_opt:\n                            self.f_opt = f_new\n                            self.x_opt = x_new\n                else:\n                    # Local Search: Gradient-based refinement\n                    self.population[i], self.fitness[i] = self.local_refinement(func, self.population[i], self.local_steps)\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i]\n\n                if self.budget <= 0:\n                    break\n            if self.budget <= 0:\n                break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridSearch scored 0.134 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09201943740121754, 0.15250406125940552, 0.24465412521296714, 0.1800096570927865, 0]}, "task_prompt": ""}
{"id": "238b19ab-9bf2-4d57-96e3-f96d0e28f2c2", "fitness": 0.29588889531318807, "name": "StochasticRankingEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass StochasticRankingEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, rank_probability=0.45):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.rank_probability = rank_probability\n        self.F = 0.7\n        self.CR = 0.7\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Stochastic Ranking Selection\n                if (f < fitness[i] or np.random.rand() < self.rank_probability):\n                    new_fitness[i] = f\n                    new_population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            population = np.copy(new_population)\n            fitness = np.copy(new_fitness)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm StochasticRankingEvolution scored 0.296 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11635800508246408, 0.1828665618416604, 0.26834896237723393, 0.23584834778785657, 0.21873635726671403, 0.24125333858704034, 0.24629881099474638, 0.219371005602362, 0.21579660121219302, 0.1638866373896315, 0.2490606459447232, 0.9933597699892716, 0.2885417805281456, 0.2318879665877227, 0.6212959666333977, 0.28054126216456776, 0.23117279928475865, 0.29079102981905924, 0.1535991001210959, 0.46876295704911697]}, "task_prompt": ""}
{"id": "4a5f1a07-5e22-4306-bcc6-629c43f361e4", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_samples=10, acquisition_function='ucb', kappa=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_samples = n_initial_samples\n        self.acquisition_function = acquisition_function\n        self.kappa = kappa\n        self.X = None\n        self.y = None\n        self.gpr = None\n\n    def acquisition(self, X, gpr):\n        mu, sigma = gpr.predict(X, return_std=True)\n        if self.acquisition_function == 'ucb':\n            return mu - self.kappa * sigma  # Minimize -ucb for maximization\n        elif self.acquisition_function == 'ei':\n            from scipy.stats import norm\n            best = np.min(self.y)\n            z = (best - mu) / sigma\n            return mu + sigma * norm.pdf(z) / norm.cdf(z) # Minimize -EI\n        else:\n            return mu\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initial sampling\n        X_initial = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_samples, self.dim))\n        y_initial = np.array([func(x) for x in X_initial])\n        self.budget -= self.n_initial_samples\n        \n        self.X = X_initial\n        self.y = y_initial\n        \n        if np.min(self.y) < self.f_opt:\n            self.f_opt = np.min(self.y)\n            self.x_opt = self.X[np.argmin(self.y)]\n\n        # Gaussian process regression\n        kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        self.gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n        self.gpr.fit(self.X, self.y)\n        \n        while self.budget > 0:\n            # Find next point to evaluate\n            from scipy.optimize import minimize\n            \n            def acquisition_wrapper(x):\n                return self.acquisition(x.reshape(1, -1), self.gpr)[0]\n\n            x0 = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.dim))\n            bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n            res = minimize(acquisition_wrapper, x0, bounds=bounds, method='L-BFGS-B')\n            x_new = res.x\n            \n            # Evaluate the function\n            f_new = func(x_new)\n            self.budget -= 1\n            \n            # Update data\n            self.X = np.vstack((self.X, x_new))\n            self.y = np.append(self.y, f_new)\n            \n            # Update Gaussian process\n            self.gpr.fit(self.X, self.y)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 45, in __call__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 45, in __call__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "89928f2b-1f86-4c16-90b4-943ac6cebac8", "fitness": 0.0, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.archive_size = archive_size\n        self.archive = []\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.success_F = []\n        self.success_CR = []\n        self.success_history = []\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Update optimal solution\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = np.copy(population)\n            new_fitness = np.zeros(self.pop_size)\n            success_count = 0\n\n            for i in range(self.pop_size):\n                # Mutation\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                j_rand = np.random.randint(self.dim)\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n                \n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_trial < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = f_trial\n                    fitness[i] = f_trial\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n                    \n                    self.success_F.append(self.F)\n                    self.success_CR.append(self.CR)\n                    self.success_history.append(True)\n                    success_count+=1\n                    # Archive successful mutants\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(trial)\n                    else:\n                        idx = np.random.randint(self.archive_size)\n                        self.archive[idx] = trial\n\n                else:\n                     self.success_history.append(False)\n                     new_population[i] = population[i] # Keep parent\n                     new_fitness[i] = fitness[i]\n\n            population = new_population\n            fitness = new_fitness\n\n            # Adapt parameters\n            if len(self.success_F) > 0:\n                self.F = np.mean(self.success_F)\n                self.CR = np.mean(self.success_CR)\n                self.success_F = []\n                self.success_CR = []\n                # Adjust bounds to avoid infeasible parameters\n                self.F = np.clip(self.F, 0.1, 0.9)\n                self.CR = np.clip(self.CR, 0.1, 0.9)\n\n            #Diversity Maintenance\n            if len(self.archive) > 0:\n                for i in range(self.pop_size):\n                    if np.random.rand() < 0.1:  # Low probability to add archive element\n                        archived_individual = self.archive[np.random.randint(len(self.archive))]\n                        population[i] = archived_individual\n                        fitness[i] = func(archived_individual)\n                        self.budget -=1\n\n                        if fitness[i] < self.f_opt:\n                           self.f_opt = fitness[i]\n                           self.x_opt = archived_individual\n            \n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "b76fa1d7-5281-47d8-8f18-d6e15f487613", "fitness": 0.5714511509133876, "name": "AdaptivePSO", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia_max=0.9, inertia_min=0.4, cognitive_coeff=2.0, social_coeff=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population and velocities\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(func.bounds.ub - func.bounds.lb), abs(func.bounds.ub - func.bounds.lb), size=(self.pop_size, self.dim)) * 0.1\n        personal_best_positions = population.copy()\n        personal_best_fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitness[global_best_index]\n        self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            # Adaptive inertia weight\n            inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.budget / (self.budget + self.pop_size))\n\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                social_velocity = self.social_coeff * r2 * (global_best_position - population[i])\n                velocities[i] = inertia * velocities[i] + cognitive_velocity + social_velocity\n                \n                # Velocity clamping (optional, but can improve stability)\n                max_velocity = 0.1 * abs(func.bounds.ub - func.bounds.lb)\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n\n                # Update position\n                new_position = population[i] + velocities[i]\n                new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate fitness\n                f = func(new_position)\n                self.budget -= 1\n\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = new_position\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_position\n                        global_best_position = new_position.copy()  # Update global best position\n\n                population[i] = new_position\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO scored 0.571 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.126273799261705, 0.16711745393913102, 0.9069908684315161, 0.18208215816193007, 0.2379476275443434, 0.93253221735436, 0.878784109568648, 0.6627545124870411, 0.9061987364344345, 0.17755982798845138, 0.9311186439476347, 0.9946173433555292, 0.2536175858768849, 0.24115262369519552, 0.7360936871807644, 0.9344877535170815, 0.4937156677927734, 0.9579128991581526, 0.20163865380500123, 0.5064268487671725]}, "task_prompt": ""}
{"id": "55e665f8-9c41-4cc0-a179-daa005506f6a", "fitness": 0.4660510561708408, "name": "AdaptiveDifferentialEvolutionRestart", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionRestart:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, restart_trigger=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5\n        self.CR = 0.9\n        self.restart_trigger = restart_trigger\n        self.stagnation_counter = 0\n        self.max_stagnation = 50\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n            self.stagnation_counter = 0\n        else:\n            self.stagnation_counter +=1\n        \n        while self.budget > 0:\n            best_fitness_before_gen = self.f_opt\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if np.random.rand() < 0.1:\n                        self.F = np.random.uniform(0.4, 0.9)\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                        self.stagnation_counter = 0\n                        self.CR = min(0.99, self.CR + 0.02)\n                else:\n                    self.CR = max(0.1, self.CR - 0.01)\n            \n                if self.budget <= 0:\n                    break\n\n            if self.f_opt >= best_fitness_before_gen:\n                self.stagnation_counter +=1\n            \n            if self.stagnation_counter > self.max_stagnation and self.budget > self.pop_size:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                self.stagnation_counter = 0\n                if np.min(fitness) < self.f_opt:\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = population[np.argmin(fitness)]\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolutionRestart scored 0.466 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16317766469785455, 0.21458447788227797, 0.46562250733708554, 0.6650732858999407, 0.37451933610188104, 0.7573962888883154, 0.3203312892396507, 0.4607367409709685, 0.4833884315845989, 0.20823855783923362, 0.4114477755910423, 0.9994942016262602, 0.2594136773402337, 0.3589486882761457, 0.7444162261860561, 0.7614041952406536, 0.35229933972954297, 0.620632696519391, 0.19952790222645855, 0.5003678402392265]}, "task_prompt": ""}
{"id": "66f5684a-bede-45c3-8a01-0d5613b83171", "fitness": 0.6009904692508169, "name": "DecayingDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass DecayingDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=20, decay_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = 0.7  # Initial mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.decay_rate = decay_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection (Tournament)\n                f = func(trial)\n                self.budget -= 1\n\n                j = np.random.randint(0, self.pop_size)\n                if f < fitness[j]:\n                    if f < fitness[i]:\n                        fitness[i] = f\n                        population[i] = trial\n                        if f < self.f_opt:\n                            self.f_opt = f\n                            self.x_opt = trial\n\n\n            self.F *= self.decay_rate # Decay mutation factor\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DecayingDifferentialEvolution scored 0.601 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2565670864874984, 0.2168266303133618, 0.42612681139138675, 0.9409340530808289, 0.6528787276320671, 0.7768647749807149, 0.8189172933110148, 0.35874446658220616, 0.6949653565670406, 0.2417264965123801, 0.9159508169922911, 0.997780822786535, 0.33495826234369397, 0.6862674810230192, 0.7853131181230826, 0.6011823982134508, 0.5735041856191679, 0.9242584235662462, 0.29439887895724437, 0.5216433005331049]}, "task_prompt": ""}
{"id": "ce4b9c49-3690-4b55-85bd-8feb090d85b5", "fitness": "-inf", "name": "SimplifiedCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass SimplifiedCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, cs=0.3, damps=1.0, cc=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma = 0.5  # Overall step size\n        self.C = np.eye(dim)  # Covariance matrix\n        self.cs = cs  # Step-size damping factor\n        self.damps = damps  # Damping for step-size\n        self.cc = cc  # Time constant for cumulation\n        self.pc = np.zeros(dim)  # Evolution path for C\n        self.mean = np.zeros(dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        self.mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n        while self.budget > 0:\n            # Sample population\n            z = np.random.randn(self.dim, self.pop_size)\n            y = self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean[:, np.newaxis] + y\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n            x = x.T\n\n            # Evaluate fitness\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n\n            # Update mean\n            xmean = np.mean(x[:self.pop_size // 2], axis=0)\n            ymean = xmean - self.mean\n            zmean = np.linalg.solve(np.linalg.cholesky(self.C), ymean * (1/self.sigma))\n            self.mean = xmean\n            \n\n            # Update evolution path\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * zmean\n\n            # Simplified rank-one update\n            self.C = (1 - self.cc) * self.C + self.cc * np.outer(self.pc, self.pc)\n\n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = self.C + 1e-6 * np.eye(self.dim)\n\n\n            # Update step size\n            self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.pc) / np.sqrt(self.dim) - 1))\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "19695713-800c-4e46-bff9-6ce92eec0ffb", "fitness": 0.5925552287653851, "name": "SelfAdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.5  # Initial crossover rate\n        self.F_memory = np.full(self.pop_size, self.F)\n        self.CR_memory = np.full(self.pop_size, self.CR)\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        success_F = []\n        success_CR = []\n        success_count = 0\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Adapt F and CR\n                self.F = self.F_memory[i]\n                self.CR = self.CR_memory[i]\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    success_count += 1\n                    success_F.append(self.F)\n                    success_CR.append(self.CR)\n\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Update F and CR memories\n            if success_count > 0:\n                mean_F = np.mean(success_F)\n                mean_CR = np.mean(success_CR)\n\n                self.F_memory = np.clip(np.random.normal(mean_F, 0.1, self.pop_size), 0.1, 1.0)\n                self.CR_memory = np.clip(np.random.normal(mean_CR, 0.1, self.pop_size), 0.0, 1.0)\n\n                success_F = []\n                success_CR = []\n                success_count = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDifferentialEvolution scored 0.593 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.23273466311954094, 0.4689071149597088, 0.4669220541054405, 0.8931955752827151, 0.7525511763285913, 0.8576063517957316, 0.43042850876212, 0.4901912830387448, 0.7841768227141377, 0.46771832214871, 0.48044902116039034, 0.9963715910157404, 0.32935832184665725, 0.3786648181460711, 0.7860611911910269, 0.8727182934460139, 0.6375409176527491, 0.7493985964882146, 0.24679675871857965, 0.529313193386818]}, "task_prompt": ""}
{"id": "feaa753b-d62d-4287-8e52-bf29397ba9bd", "fitness": 0.660101809572285, "name": "SelfAdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.archive_size = archive_size\n        self.F_mean = 0.5\n        self.CR_mean = 0.5\n        self.archive = []\n        self.p_selection = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Parameter adaptation\n                F = np.random.normal(self.F_mean, 0.1)\n                CR = np.random.normal(self.CR_mean, 0.1)\n                F = np.clip(F, 0.1, 1.0)\n                CR = np.clip(CR, 0.1, 1.0)\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                if len(self.archive) > 0 and np.random.rand() < self.p_selection:\n                    donor_vector = self.archive[np.random.randint(len(self.archive))]\n                    a = population[np.random.choice(idxs, 1, replace=False)][0]\n                    b, c = population[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(a + F * (donor_vector - a) + F * (b - c), func.bounds.lb, func.bounds.ub)\n                else:\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    # Update archive\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(population[i].copy())\n                    else:\n                        self.archive[np.random.randint(self.archive_size)] = population[i].copy()\n\n                    # Update population and fitness\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                    # Update adaptation parameters\n                    self.F_mean = 0.9 * self.F_mean + 0.1 * F\n                    self.CR_mean = 0.9 * self.CR_mean + 0.1 * CR\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDifferentialEvolution scored 0.660 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.24078257422697313, 0.7466090888013391, 0.3707868440968024, 0.7863456720323023, 0.6811214466499489, 0.8782253082948644, 0.6865599711901126, 0.6676981025209083, 0.6674606645001931, 0.6598419267458986, 0.8824591515015416, 0.9847313744718725, 0.315845142769241, 0.7539525359465105, 0.7222447387809432, 0.8568243451534616, 0.6190187743856498, 0.9205175276073375, 0.25887939464768506, 0.5021316071221126]}, "task_prompt": ""}
{"id": "d5008371-f520-4373-9c83-7ea4e86c7e7d", "fitness": 0.6820003484017821, "name": "EnhancedDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.7  # Initial mutation factor\n        self.CR = 0.5  # Initial Crossover rate\n        self.CR_memory = []  # Memory for successful CR values\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            # Decay mutation factor\n            self.F = 0.7 * (0.99 ** generation) # Decaying F\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    self.CR_memory.append(self.CR) # Store successful CR value\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n                \n                if self.budget <= 0:\n                    break\n                    \n            # Adjust CR based on memory\n            if self.CR_memory:\n                self.CR = np.mean(self.CR_memory)\n                self.CR_memory = [] # Reset memory after update\n            else:\n                self.CR = 0.5 # Default value if no successful CRs recorded\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnhancedDifferentialEvolution scored 0.682 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.22768405301781336, 0.5994140086981219, 0.5928263911263724, 0.8890370103944495, 0.816529638122367, 0.851472736885875, 0.7927928561083409, 0.5842268246096612, 0.8311012758901787, 0.752040401202605, 0.8367707827439769, 0.9955690304934621, 0.2988081481775543, 0.6237467776897035, 0.9264326415585308, 0.8793832972627718, 0.47995062483895257, 0.8844661461749093, 0.2544529851407039, 0.523301337899293]}, "task_prompt": ""}
{"id": "6971699e-ebf3-4d55-8d04-995017a6dda6", "fitness": "-inf", "name": "GaussianProcessOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel\nfrom scipy.stats import norm\nfrom scipy.optimize import minimize\n\nclass GaussianProcessOptimization:\n    def __init__(self, budget=10000, dim=10, n_initial_points=10, kernel=None, exploration_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.n_initial_points = n_initial_points\n        self.exploration_factor = exploration_factor # Controls exploration-exploitation trade-off\n\n        if kernel is None:\n           self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")\n        else:\n            self.kernel = kernel\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=5, alpha=1e-6)\n\n        self.X = None\n        self.y = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def expected_improvement(self, x, gp, evaluated_loss, xi=0.01):\n        mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n        sigma = np.maximum(sigma, 1e-9) # avoid division by zero\n        imp = evaluated_loss - mu\n        Z = imp / sigma\n        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n        return ei\n\n    def propose_location(self, gp, evaluated_loss, bounds, n_restarts=25):\n        def min_obj(x):\n            return -self.expected_improvement(x, gp, evaluated_loss)\n\n        best_location = None\n        best_ei = -np.inf\n\n        for _ in range(n_restarts):\n            start_point = np.random.uniform(bounds.lb, bounds.ub, size=self.dim)\n            res = minimize(min_obj, start_point, bounds=bounds, method='L-BFGS-B') # Changed to L-BFGS-B\n            if -res.fun > best_ei:\n                best_ei = -res.fun\n                best_location = res.x\n\n        return best_location\n\n    def __call__(self, func):\n        # Initial sampling\n        self.X = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_initial_points, self.dim))\n        self.y = np.array([func(x) for x in self.X])\n        self.budget -= self.n_initial_points\n\n        if np.min(self.y) < self.f_opt:\n            self.f_opt = np.min(self.y)\n            self.x_opt = self.X[np.argmin(self.y)]\n\n        self.gp.fit(self.X, self.y)\n\n        # Bayesian optimization loop\n        while self.budget > 0:\n            # Find next point to evaluate\n            x_next = self.propose_location(self.gp, np.min(self.y), func.bounds)\n\n            # Evaluate the objective function\n            f_next = func(x_next)\n            self.budget -= 1\n\n            # Update the data\n            self.X = np.vstack((self.X, x_next))\n            self.y = np.append(self.y, f_next)\n\n            # Update Gaussian process\n            self.gp.fit(self.X, self.y)\n\n            if f_next < self.f_opt:\n                self.f_opt = f_next\n                self.x_opt = x_next\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 15, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "error": "In the code, line 15, in __init__, the following error occurred:\nNameError: name 'ConstantKernel' is not defined\nOn line: self.kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=1.0, length_scale_bounds=\"fixed\")", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "669719c1-8672-41b1-a87a-d06c80f1666f", "fitness": 0.2969940911262322, "name": "ParticleSwarmOptimizer", "description": "No description provided.", "code": "import numpy as np\n\nclass ParticleSwarmOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, inertia=0.729, c1=1.49445, c2=1.49445, vmax_ratio=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.c1 = c1\n        self.c2 = c2\n        self.vmax_ratio = vmax_ratio\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb)*self.vmax_ratio, abs(ub-lb)*self.vmax_ratio, size=(self.pop_size, self.dim))\n        \n        # Initialize personal best positions and values\n        personal_best_positions = particles.copy()\n        personal_best_values = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n        \n        # Initialize global best position and value\n        global_best_index = np.argmin(personal_best_values)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        self.f_opt = personal_best_values[global_best_index].copy()\n        self.x_opt = global_best_position.copy()\n        \n        # PSO iterations\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            velocities = self.inertia * velocities + \\\n                         self.c1 * r1 * (personal_best_positions - particles) + \\\n                         self.c2 * r2 * (global_best_position - particles)\n\n            # Velocity clamping\n            vmax = abs(ub - lb) * self.vmax_ratio\n            velocities = np.clip(velocities, -vmax, vmax)\n            \n            particles += velocities\n\n            # Boundary handling\n            particles = np.clip(particles, lb, ub)\n            \n            # Evaluate particles\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n            \n            # Update personal best positions and values\n            improved_indices = fitness < personal_best_values\n            personal_best_positions[improved_indices] = particles[improved_indices].copy()\n            personal_best_values[improved_indices] = fitness[improved_indices].copy()\n            \n            # Update global best position and value\n            if np.min(personal_best_values) < self.f_opt:\n                self.f_opt = np.min(personal_best_values)\n                global_best_index = np.argmin(personal_best_values)\n                self.x_opt = personal_best_positions[global_best_index].copy()\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ParticleSwarmOptimizer scored 0.297 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.16809103051563357, 0.21610173041530256, 0.34402754330402663, 0.2615872290797445, 0.2245510554823088, 0.28984348677320915, 0.26200374910006663, 0.2635330247588521, 0.2388888752179631, 0.1753900757872774, 0.3409173738176059, 0.9951035137425142, 0.24321761866059888, 0.21307186821604318, 0.1640037985690902, 0.30087085479193887, 0.265397327502476, 0.3355772179027151, 0.1574088297882048, 0.4802956190990727]}, "task_prompt": ""}
{"id": "175f3738-a6c3-4701-a9d5-30a80df80cc6", "fitness": 0.37573042222813735, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=100.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.perturbation_range = 1.0  # Initial perturbation range\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize solution\n        current_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        current_f = func(current_x)\n        self.budget -= 1\n\n        self.f_opt = current_f\n        self.x_opt = current_x\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            # Generate neighbor solution\n            new_x = np.clip(current_x + np.random.uniform(-self.perturbation_range, self.perturbation_range, size=self.dim), func.bounds.lb, func.bounds.ub)\n            new_f = func(new_x)\n            self.budget -= 1\n\n            # Acceptance probability\n            delta_f = new_f - current_f\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temperature):\n                current_x = new_x\n                current_f = new_f\n                self.success_history.append(True)\n\n                if current_f < self.f_opt:\n                    self.f_opt = current_f\n                    self.x_opt = current_x\n            else:\n                self.success_history.append(False)\n\n            # Adaptive temperature schedule\n            temperature *= self.cooling_rate\n\n            # Adaptive perturbation range\n            if len(self.success_history) > 50:\n                success_rate = np.mean(self.success_history[-50:])\n                if success_rate > 0.6:\n                    self.perturbation_range *= 1.1  # Increase perturbation range if too many successes\n                elif success_rate < 0.4:\n                    self.perturbation_range *= 0.9  # Decrease perturbation range if too few successes\n                self.perturbation_range = np.clip(self.perturbation_range, 0.01, 2.0)  # Limit the perturbation range\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.376 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18759067336739477, 0.17437181267033997, 0.5910496385469345, 0.16478078327020718, 0.20254855384608672, 0.6459452056965517, 0.2952629023661244, 0.22082652122552904, 0.21183156252516766, 0.19562733205557947, 0.23709701195760735, 0.9993441202998508, 0.28624130612182663, 0.2322846176900777, 0.918287941197094, 0.33216927388337303, 0.24961879503670392, 0.8081816972636764, 0.08221502993329, 0.47933366560933144]}, "task_prompt": ""}
{"id": "09a58bbe-2763-48c6-ac11-01012fc60318", "fitness": 0.5175634842848775, "name": "ConstrictionParticleSwarm", "description": "No description provided.", "code": "import numpy as np\n\nclass ConstrictionParticleSwarm:\n    def __init__(self, budget=10000, dim=10, pop_size=40, w=0.729, c1=1.49445, c2=1.49445):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.w = w  # Inertia weight\n        self.c1 = c1  # Cognitive coefficient\n        self.c2 = c2  # Social coefficient\n        self.kappa = 1  # Constriction factor denominator\n        self.phi = self.c1 + self.c2\n        self.chi = 2 * self.kappa / abs(2 - self.phi - np.sqrt(self.phi**2 - 4 * self.phi)) if self.phi > 4 else 1\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        personal_best_positions = particles.copy()\n        personal_best_fitnesses = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        global_best_index = np.argmin(personal_best_fitnesses)\n        global_best_position = personal_best_positions[global_best_index]\n        self.f_opt = personal_best_fitnesses[global_best_index]\n        self.x_opt = global_best_position\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                cognitive_component = self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                social_component = self.c2 * r2 * (global_best_position - particles[i])\n                \n                velocities[i] = self.chi * (self.w * velocities[i] + cognitive_component + social_component)\n\n                # Update position\n                particles[i] = particles[i] + velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n                # Evaluate fitness\n                fitness = func(particles[i])\n                self.budget -= 1\n\n                # Update personal best\n                if fitness < personal_best_fitnesses[i]:\n                    personal_best_fitnesses[i] = fitness\n                    personal_best_positions[i] = particles[i].copy()\n\n                    # Update global best\n                    if fitness < self.f_opt:\n                        self.f_opt = fitness\n                        self.x_opt = particles[i].copy()\n                        global_best_position = particles[i].copy()\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ConstrictionParticleSwarm scored 0.518 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2202421102536578, 0.19938006503307326, 0.7288427926928147, 0.8672469503661463, 0.2958936340257262, 0.7861053554239128, 0.32349036077067905, 0.6613584994153372, 0.7485880548641165, 0.23584100141830844, 0.894419993730179, 0.9988670000336761, 0.2582576872959892, 0.2511942292467183, 0.6463732581092103, 0.7666570876585308, 0.3949499459904189, 0.37757946287446664, 0.21497637010339676, 0.48100582639119327]}, "task_prompt": ""}
{"id": "be69d0d8-f616-4504-b8ef-eec230cb1fdb", "fitness": "-inf", "name": "GaussianMixtureOptimisation", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimisation:\n    def __init__(self, budget=10000, dim=10, n_components=5, n_samples=50):\n        self.budget = budget\n        self.dim = dim\n        self.n_components = n_components\n        self.n_samples = n_samples\n        self.gmm = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n\n        # Initial sampling\n        initial_samples = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.n_samples, self.dim))\n        initial_fitness = np.array([func(x) for x in initial_samples])\n        self.budget -= self.n_samples\n        \n        if np.min(initial_fitness) < self.f_opt:\n            self.f_opt = np.min(initial_fitness)\n            self.x_opt = initial_samples[np.argmin(initial_fitness)]\n\n        # Initialize GMM\n        self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)\n        self.gmm.fit(initial_samples, sample_weight = np.exp(-initial_fitness))\n\n        while self.budget > 0:\n            # Sample from GMM\n            samples, _ = self.gmm.sample(self.n_samples)\n            samples = np.clip(samples, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluate samples\n            fitness = np.array([func(x) for x in samples])\n            self.budget -= self.n_samples\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = samples[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n            \n            # Update GMM\n            all_samples = np.vstack((initial_samples, samples))\n            all_fitness = np.hstack((initial_fitness, fitness))\n            \n            self.gmm.fit(all_samples, sample_weight = np.exp(-all_fitness))\n            \n            initial_samples = all_samples\n            initial_fitness = all_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 26, in __call__, the following error occurred:\nNameError: name 'GaussianMixture' is not defined\nOn line: self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)", "error": "In the code, line 26, in __call__, the following error occurred:\nNameError: name 'GaussianMixture' is not defined\nOn line: self.gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', max_iter=100, random_state=0)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "7e4820f5-573d-4507-8b4b-065badc31208", "fitness": "-inf", "name": "HybridDEGradient", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridDEGradient:\n    def __init__(self, budget=10000, dim=10, pop_size=20, lr=0.01, de_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr\n        self.de_weight = de_weight\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(population[i] + 0.5 * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Gradient Descent\n                x = population[i].copy()\n                grad = self.estimate_gradient(func, x)\n                descent = np.clip(x - self.lr * grad, func.bounds.lb, func.bounds.ub)\n\n                # Hybrid Move\n                trial = self.de_weight * mutant + (1 - self.de_weight) * descent\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n\n    def estimate_gradient(self, func, x, h=1e-5):\n        grad = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus_h = x.copy()\n            x_minus_h = x.copy()\n            x_plus_h[i] += h\n            x_minus_h[i] -= h\n            grad[i] = (func(x_plus_h) - func(x_minus_h)) / (2 * h)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 32, in __call__, the following error occurred:\nTypeError: can't multiply sequence by non-int of type 'float'\nOn line: descent = np.clip(x - self.lr * grad, func.bounds.lb, func.bounds.ub)", "error": "In the code, line 32, in __call__, the following error occurred:\nTypeError: can't multiply sequence by non-int of type 'float'\nOn line: descent = np.clip(x - self.lr * grad, func.bounds.lb, func.bounds.ub)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "bf775f96-9824-4f63-bc90-f51f02be5c5d", "fitness": 0.32269378007380284, "name": "AdaptiveSamplingOptimization", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSamplingOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.sigma = 1.0  # Initial sampling variance\n        self.success_rate = 0.0\n        self.success_history = []\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Find the best individual\n            best_index = np.argmin(fitness)\n            best_x = population[best_index]\n\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                # Sample from a Gaussian distribution centered around the best individual\n                x = np.random.normal(best_x, self.sigma, size=self.dim)\n                x = np.clip(x, func.bounds.lb, func.bounds.ub)\n                \n                f = func(x)\n                self.budget -= 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n                    \n                new_population.append(x)\n                new_fitness.append(f)\n\n                if self.budget <= 0:\n                    break\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array(new_fitness)\n\n            # Calculate success rate\n            successful_indices = new_fitness < fitness\n            success_count = np.sum(successful_indices)\n            self.success_rate = success_count / self.pop_size\n\n            # Update sampling variance adaptively\n            self.sigma *= np.exp(self.learning_rate * (self.success_rate - 0.2))  # Adjust sigma\n            self.sigma = max(0.01, min(self.sigma, 2.0)) # Clip sigma\n\n            # Replace old population with new population\n            population = new_population\n            fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSamplingOptimization scored 0.323 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13336447841264687, 0.20440292274143457, 0.317957253391867, 0.28074676100797213, 0.24618908828764174, 0.2910006465153617, 0.25440294397304963, 0.25381446550165987, 0.22047918396877975, 0.19202863744552479, 0.3108775647910076, 0.9966381227873045, 0.277525924285115, 0.2499728208508103, 0.6583179251388361, 0.30069851709216877, 0.2600542364805345, 0.3515205435094445, 0.176620950943141, 0.4772626143517569]}, "task_prompt": ""}
{"id": "eb2a11f9-2333-4662-abae-95c0d8f37c52", "fitness": 0.2621787028150683, "name": "HybridEvolutionaryAlgorithm", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridEvolutionaryAlgorithm:\n    def __init__(self, budget=10000, dim=10, pop_size=None, alpha=0.8, beta=0.1, gamma=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.diversity_threshold = diversity_threshold\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Sort population by fitness\n            idx = np.argsort(fitness)\n            population = population[idx]\n            fitness = fitness[idx]\n\n            # Generate new population\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Select random individuals\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_rand1, x_rand2, x_rand3 = population[idxs]\n\n                # Create new individual\n                new_individual = self.alpha * population[0] + self.beta * x_rand1 + self.gamma * (x_rand2 - x_rand3)\n                new_individual = np.clip(new_individual, func.bounds.lb, func.bounds.ub)\n\n                new_population[i] = new_individual\n\n            # Evaluate new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Selection: replace if better\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i]\n\n                    if new_fitness[i] < self.f_opt:\n                        self.f_opt = new_fitness[i]\n                        self.x_opt = new_population[i]\n\n            # Diversity check and update parameters\n            if self.budget > 0:\n                diversity = np.std(population)\n                if diversity < self.diversity_threshold:\n                    # Increase exploration\n                    self.beta += 0.05\n                    self.gamma += 0.05\n                    self.alpha -= 0.1\n\n                else:\n                    # Increase exploitation\n                    self.beta -= 0.025\n                    self.gamma -= 0.025\n                    self.alpha += 0.05\n\n                self.alpha = np.clip(self.alpha, 0.0, 1.0)\n                self.beta = np.clip(self.beta, 0.0, 1.0)\n                self.gamma = np.clip(self.gamma, 0.0, 1.0)\n                \n                if np.abs(np.sum([self.alpha, self.beta, self.gamma]) - 1.0) > 1e-5:\n                  self.gamma = 1.0 - self.alpha - self.beta\n                  self.gamma = np.clip(self.gamma, 0.0, 1.0)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridEvolutionaryAlgorithm scored 0.262 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07025936766116359, 0.20432585049385465, 0.387778905036241, 0.2460963143816678, 0.23207712274182024, 0.17229082400641016, 0.23894338377879343, 0.2220423661321509, 0.26463235308282806, 0.1616867220348287, 0.15265910762155233, 0.995449595833771, 0.22986289118045866, 0.19038123146645491, 0.14776282004536556, 0.27966687930542544, 0.19435680695069146, 0.21642867336537108, 0.17228044729582492, 0.46459239388669105]}, "task_prompt": ""}
{"id": "5d668a68-3521-4162-ae78-a78ec161b700", "fitness": 0.43179811393253076, "name": "AdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.7  # Initial crossover rate\n        self.F_adaptive_factor = 0.1\n        self.CR_adaptive_factor = 0.1\n        self.diversity_threshold = 0.01\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n\n            # Calculate population diversity\n            diversity = np.std(population)\n\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR based on diversity\n            if diversity < self.diversity_threshold:\n                self.F += self.F_adaptive_factor\n                self.CR += self.CR_adaptive_factor\n            else:\n                self.F -= self.F_adaptive_factor / 2\n                self.CR -= self.CR_adaptive_factor / 2\n            self.F = np.clip(self.F, 0.1, 0.9)\n            self.CR = np.clip(self.CR, 0.1, 0.9)\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.432 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14828778478114268, 0.24576929692738692, 0.3843151581643408, 0.7249377494402878, 0.3230518148521554, 0.2800365015760793, 0.4839972019010178, 0.5200056372714893, 0.27508046142621256, 0.28267979719161374, 0.44162413411391144, 0.9996643058027304, 0.2680932896262421, 0.34573540545326464, 0.6694001998498608, 0.38682188921128513, 0.4534717015798466, 0.6661626359595414, 0.2408957209267213, 0.49593159259548636]}, "task_prompt": ""}
{"id": "e9fe44f7-6d86-4c40-b2e0-63c7a906093b", "fitness": 0.5168867096950047, "name": "ParticleSwarmOptimization", "description": "No description provided.", "code": "import numpy as np\n\nclass ParticleSwarmOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=20, inertia=0.7, cognitive_coeff=1.4, social_coeff=1.4, clamp_factor=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.inertia = inertia\n        self.cognitive_coeff = cognitive_coeff\n        self.social_coeff = social_coeff\n        self.clamp_factor = clamp_factor\n        self.constriction_factor = 1.0  # No constriction by default initially\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize particles and velocities\n        particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        \n        # Personal best positions and fitness values\n        personal_best_positions = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in particles])\n        self.budget -= self.pop_size\n\n        # Global best position and fitness\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        self.f_opt = global_best_fitness\n        self.x_opt = global_best_position\n\n        while self.budget > 0:\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - particles) +\n                          self.social_coeff * r2 * (global_best_position - particles))\n\n            # Velocity clamping\n            v_max = self.clamp_factor * (func.bounds.ub - func.bounds.lb) / 2\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            particles = particles + velocities\n            particles = np.clip(particles, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(x) for x in particles])\n            self.budget -= self.pop_size\n            \n            # Update personal best positions\n            improved_mask = fitness < personal_best_fitness\n            personal_best_fitness[improved_mask] = fitness[improved_mask]\n            personal_best_positions[improved_mask] = particles[improved_mask]\n\n            # Update global best position\n            best_index = np.argmin(personal_best_fitness)\n            if personal_best_fitness[best_index] < global_best_fitness:\n                global_best_fitness = personal_best_fitness[best_index]\n                global_best_position = personal_best_positions[best_index]\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position\n\n            if self.budget <= 0:\n                break\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ParticleSwarmOptimization scored 0.517 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14791327974871837, 0.17911011948468403, 0.5997262929701881, 0.9542854285868778, 0.26206615083320717, 0.9146276973699667, 0.36191122670842546, 0.8539643320415097, 0.8914683981861886, 0.22394506800223912, 0.9485147536366977, 0.9994908430542937, 0.2535097012426266, 0.2953691700726142, 0.647910906007569, 0.36321326643694696, 0.4337677113861864, 0.2884249718630012, 0.21216267226593177, 0.5063522040022228]}, "task_prompt": ""}
{"id": "75b06f98-ad6c-4341-8bf2-a83c7ddd4fe6", "fitness": 0.2540503558951885, "name": "Simplified_CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass Simplified_CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size_factor=3, sigma0=0.5, stagnation_threshold=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size_factor = pop_size_factor\n        self.pop_size = 4 + int(self.pop_size_factor * np.log(dim))  # Initial population size\n        self.sigma0 = sigma0\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        \n        while self.budget > 0:\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = mean + sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n\n            if self.budget <= 0:\n                break\n\n            idx = np.argsort(fitness)\n            mean = x[idx[0]]\n\n            sigma *= np.exp(0.5 * (np.mean(fitness) - self.f_opt) / self.f_opt)\n\n            if self.stagnation_counter > self.stagnation_threshold:\n                mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n                sigma = self.sigma0\n                self.stagnation_counter = 0\n                self.pop_size = 4 + int(self.pop_size_factor * np.log(self.dim)) #Adjust population size\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm Simplified_CMAES scored 0.254 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.07947196804912604, 0.140671074116829, 0.3020062705001757, 0.17766722222623343, 0.18029221646644056, 0.20563594726454326, 0.2253441385582441, 0.1599686325611963, 0.17157301651219337, 0.15128026439680287, 0.1800472705684828, 0.9958081810125203, 0.15103862697321235, 0.17208518226691072, 0.5447620032653471, 0.23330388148412573, 0.19338343640020395, 0.24794047184582024, 0.13005707690397394, 0.43867023653138926]}, "task_prompt": ""}
{"id": "9121eb2e-349c-4e4b-8199-166b592dc814", "fitness": 0.0, "name": "DynamicCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass DynamicCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma0=0.5, mu_factor=0.25, success_threshold=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.sigma0 = sigma0\n        self.mu = int(self.pop_size * mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.success_threshold = success_threshold\n        self.success_rate = 0.0\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        archive_fitness = []\n\n        while self.budget - self.eval_count > 0:\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.eval_count += self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            archive_fitness.append(np.min(fitness))\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n\n            # Update covariance matrix (simplified)\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            # Dynamic population size adjustment\n            if len(archive_fitness) > 10:\n                improvements = [archive_fitness[i] - archive_fitness[i-1] for i in range(1, len(archive_fitness))]\n                self.success_rate = sum([i < 0 for i in improvements[-10:]]) / 10\n                \n                if self.success_rate > self.success_threshold and self.pop_size < 2 * (4 + int(3 * np.log(self.dim))): #Upper limit to pop size\n                    self.pop_size = min(self.pop_size + 2, 2 * (4 + int(3 * np.log(self.dim))))\n                    self.mu = int(self.pop_size * 0.25)\n                    self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                    self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                    self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                elif self.success_rate < (1 - self.success_threshold) and self.pop_size > 4: #Lower limit to pop size\n                    self.pop_size = max(self.pop_size - 2, 4)\n                    self.mu = int(self.pop_size * 0.25)\n                    self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                    self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                    self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "1e4eed3b-6194-42dd-85a1-198d1b9597b8", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.zeros(dim)\n        self.C = np.eye(dim)\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.cs = (self.mu + 2) / (dim + self.mu + 5)\n        self.ds = 1 + 2 * max(0, np.sqrt((self.mu - 1)/(dim + 1)) - 1) + self.cs\n        self.cc = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.cmu = min(1 - self.c1, 2 * (self.mu - 2 + 1/self.mu) / ((dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        while self.budget > 0:\n            # Generate population\n            z = np.random.randn(self.dim, self.pop_size)\n            x = self.m[:, np.newaxis] + self.sigma * np.dot(np.linalg.cholesky(self.C), z)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate population\n            fitness = np.array([func(xi) for xi in x.T])\n            self.budget -= self.pop_size\n            if self.budget <= 0:\n                fitness = fitness[:self.pop_size + self.budget] # Truncate evaluations\n                x = x[:, :self.pop_size + self.budget]\n\n\n            # Sort population\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[:, idx]\n\n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[:, 0]\n\n            # Update distribution parameters\n            xmean = np.sum(x[:, :self.mu] * self.weights, axis=1)\n            self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs)) * np.dot(np.linalg.inv(np.linalg.cholesky(self.C)), (xmean - self.m) / self.sigma)\n            self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc)) * (xmean - self.m) / self.sigma\n            self.m = xmean\n\n            hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * self.budget / self.pop_size)) < self.chiN * (1.4 + 2 / (self.dim + 1))\n            dhsig = (1 - hsig) * self.cc * (2 - self.cc)\n            self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc) + dhsig * self.C) + self.cmu * np.dot((x[:, :self.mu] - self.m[:, np.newaxis]) * self.weights, (x[:, :self.mu] - self.m[:, np.newaxis]).T) / self.sigma**2\n\n            self.sigma *= np.exp((self.cs / self.ds) * (np.linalg.norm(self.ps) / self.chiN - 1))\n\n            # Ensure C is positive definite\n            try:\n                np.linalg.cholesky(self.C)\n            except np.linalg.LinAlgError:\n                self.C = np.eye(self.dim)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "error": "In the code, line 113, in _clip, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,6) (2,) (2,) ", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "b2e8e1e1-d6b9-4cb8-afad-e71e957be7fa", "fitness": 0.4988143992305855, "name": "BudgetAwareCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass BudgetAwareCMAES:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 20, 4 + int(3 * np.log(dim)))  # Budget-aware population size\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = np.random.uniform(-1, 1, size=dim)  # Initialize mean\n        self.sigma = 0.5  # Initialize step size\n        self.C = np.eye(dim)  # Initialize covariance matrix\n        self.pc = np.zeros(dim)\n        self.ps = np.zeros(dim)\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sig = (self.mu / (dim + self.mu**2))**0.5\n        self.d_sig = 1 + 2*max(0, ((self.mu-1)/(dim+1) - 1)) + self.c_sig\n        self.c_c = (4 + self.mu/dim) / (dim + 4 + 2*self.mu/dim)\n        self.c_1 = 2 / ((dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 2 + 1/self.mu) / ((dim + 2)**2 + self.mu))\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n\n    def __call__(self, func):\n        \n        while self.budget > 0:\n            # Generate and evaluate lambda offspring\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            if np.any(fitness < self.f_opt):\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n            \n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n            \n            # Update mean\n            m_old = self.m\n            self.m = np.sum(self.weights[:, None] * x[:self.mu], axis=0)\n\n            # Cumulation\n            self.ps = (1 - self.c_sig) * self.ps + (self.c_sig * (self.dim)**0.5) * (np.linalg.inv(np.linalg.cholesky(self.C)) @ (self.m - m_old) / self.sigma)\n            hsig = np.linalg.norm(self.ps) / (1 - (1 - self.c_sig)**(self.budget / self.pop_size)) / self.chiN < 1.4 + 2/(self.dim+1)\n            self.pc = (1 - self.c_c) * self.pc + hsig * (self.c_c * (self.dim)**0.5) * ((self.m - m_old) / self.sigma)\n\n            # Adapt covariance matrix\n            artmp = (1/self.sigma) * (x[:self.mu] - m_old).T\n            self.C = (1 - self.c_1 - self.c_mu + self.c_1 * self.c_c * (2 - hsig**2)) * self.C + self.c_1 * self.pc[:, None] @ self.pc[None, :] + self.c_mu * artmp @ np.diag(self.weights) @ artmp.T\n\n            # Adapt step size\n            self.sigma = self.sigma * np.exp((self.c_sig / self.d_sig) * (np.linalg.norm(self.ps)/self.chiN - 1))\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm BudgetAwareCMAES scored 0.499 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1345493668841442, 0.17462230256211553, 0.9271313163390557, 0.18011273736936506, 0.37289128287363404, 0.19598382387265023, 0.3519772817803819, 0.4624677913946099, 0.9637440417994325, 0.16335203816652688, 0.9656132983838864, 0.9915073939267175, 0.7995161801038384, 0.2670145742197255, 0.9528582713004831, 0.8293087374167509, 0.4616126017394483, 0.1700666849958158, 0.16327170848398787, 0.44868655099914245]}, "task_prompt": ""}
{"id": "7aced9bc-9afa-4720-b70f-4042cf9b655e", "fitness": "-inf", "name": "CMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass CMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None, sigma=0.5, cs=0.3, damps=1, c_cov_rank_one=None, c_cov_mu=0.0):\n        self.budget = budget\n        self.dim = dim\n        self.sigma = sigma\n        self.cs = cs\n        self.damps = damps\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.pop_size // 2\n\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c_cov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + self.mueff + 5))\n        if c_cov_rank_one is None:\n            self.c_cov_rank_one = 1 / ((self.mueff + 2) / (self.dim + self.mueff + 5))\n        else:\n            self.c_cov_rank_one = c_cov_rank_one\n\n        self.c_cov_mu = c_cov_mu\n\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.c_sigma\n\n        self.mean = np.random.uniform(low=-2, high=2, size=self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.B = None\n        self.D = None\n        self.invsqrtC = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def update_decomposition(self):\n        self.C = (self.C + self.C.T) / 2  # Ensure symmetry\n        self.D, self.B = np.linalg.eigh(self.C)  # Eigen decomposition\n        self.D = np.sqrt(np.maximum(self.D, 1e-16))  # Ensure positive values\n        self.invsqrtC = self.B @ np.diag(1 / self.D) @ self.B.T  # Inverse square root of C\n\n    def __call__(self, func):\n        self.update_decomposition()\n        while self.budget > 0:\n            # Generate samples\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T\n\n            # Clip x to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Evaluate fitness\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n            \n            # Sort by fitness\n            idx = np.argsort(fitness)\n            fitness = fitness[idx]\n            x = x[idx]\n            \n            # Update optimal solution\n            if fitness[0] < self.f_opt:\n                self.f_opt = fitness[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            y = self.invsqrtC @ (xmean - self.mean)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * self.invsqrtC @ (xmean - self.mean)\n            hsig = (np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.c_sigma)**(2 * (self.budget / (self.pop_size*2)))) / np.sqrt(self.dim+1) < 1.4 + 2/(self.dim+1))\n            self.pc = (1 - self.cs) * self.pc + hsig * np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (xmean - self.mean)\n\n            # Update covariance matrix\n            rank_one = np.outer(self.pc, self.pc)\n            self.C = (1 - self.c_cov - self.c_cov_mu) * self.C + self.c_cov_rank_one * rank_one + self.c_cov_mu * np.sum(self.weights[:, None, None] * (x[:self.mu] - self.mean)[:, :, None] * (x[:self.mu] - self.mean)[:, None, :], axis=0)\n            \n            # Update step size\n            self.sigma *= np.exp((self.c_sigma / self.damps) * (np.linalg.norm(self.ps) / 0.817 - 1))\n            self.mean = xmean\n            self.update_decomposition()\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 49, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T", "error": "In the code, line 49, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x = self.mean + self.sigma * (self.B @ (self.D * z.T)).T", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ff944054-60b1-497a-a86e-2606542e927d", "fitness": 0.7343984773474403, "name": "SelfAdaptiveDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass SelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, F_init=0.5, CR_init=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.F = F_init  # Initial mutation factor\n        self.CR = CR_init  # Initial Crossover rate\n        self.F_memory = []\n        self.CR_memory = []\n        self.success_threshold = 0.1\n        self.restart_trigger = 50 #restart if no improvement in n generations\n        self.no_improvement_counter = 0\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            \n            old_f_opt = self.f_opt\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    self.F_memory.append(self.F)\n                    self.CR_memory.append(self.CR)\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Adapt F and CR\n            if self.F_memory:\n                self.F = np.clip(np.mean(self.F_memory), 0.1, 0.9)\n                self.CR = np.clip(np.mean(self.CR_memory), 0.1, 0.9)\n                self.F_memory = []\n                self.CR_memory = []\n            else:\n                self.F = 0.5\n                self.CR = 0.9\n                \n            #Restart mechanism\n            if self.f_opt >= old_f_opt:\n                self.no_improvement_counter += 1\n            else:\n                self.no_improvement_counter = 0\n                \n            if self.no_improvement_counter > self.restart_trigger:\n                population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                best_index = np.argmin(fitness)\n                if fitness[best_index] < self.f_opt:\n                  self.f_opt = fitness[best_index]\n                  self.x_opt = population[best_index]\n                self.no_improvement_counter = 0\n                self.F = 0.5\n                self.CR = 0.9\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SelfAdaptiveDifferentialEvolution scored 0.734 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.422682362476554, 0.3362323695248297, 0.5948387379842944, 0.9274093304554776, 0.8585343095068354, 0.851602559030144, 0.8348905231975967, 0.8022421774096086, 0.8688204331020526, 0.8471136360213317, 0.927277922981851, 0.9956981561460992, 0.26995307988975814, 0.8898979421858701, 0.8310776202067842, 0.8976218779372331, 0.8198248326525559, 0.902079287605838, 0.3385431800083445, 0.47162920862574986]}, "task_prompt": ""}
{"id": "f63c0f13-dace-4026-ac6f-54a9c0670614", "fitness": 0.3417329252987546, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_factor=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.temp = initial_temp\n        self.cooling_factor = cooling_factor\n        self.x_current = None\n        self.f_current = np.inf\n        self.acceptance_rate = 0.0\n        self.acceptance_history = []\n\n    def __call__(self, func):\n        self.x_current = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_current = func(self.x_current)\n        self.budget -= 1\n        self.f_opt = self.f_current\n        self.x_opt = self.x_current\n        \n        accepted = 0\n        total = 0\n\n        while self.budget > 0:\n            x_new = self.x_current + np.random.normal(0, 0.1, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            self.budget -= 1\n\n            delta_e = f_new - self.f_current\n\n            if delta_e < 0:\n                self.x_current = x_new\n                self.f_current = f_new\n                accepted += 1\n                if f_new < self.f_opt:\n                    self.f_opt = f_new\n                    self.x_opt = x_new\n            else:\n                try:\n                    acceptance_probability = np.exp(-delta_e / self.temp)\n                except OverflowError:\n                    acceptance_probability = 0.0\n                if np.random.rand() < acceptance_probability:\n                    self.x_current = x_new\n                    self.f_current = f_new\n                    accepted += 1\n            total +=1\n            \n            #Adaptive Temperature Adjustment\n            self.acceptance_rate = accepted / total if total > 0 else 0.0\n            self.acceptance_history.append(self.acceptance_rate)\n            \n            if len(self.acceptance_history) > 10:\n                avg_acceptance_rate = np.mean(self.acceptance_history[-10:])\n                if avg_acceptance_rate > 0.5:\n                    self.temp *= 1.05 #Slow down cooling\n                elif avg_acceptance_rate < 0.1:\n                    self.temp *= 0.9 #Speed up cooling\n            \n            self.temp *= self.cooling_factor\n            self.temp = max(self.temp, 1e-6)\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.342 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06692793345392134, 0.20877849989605024, 0.42567947464841616, 0.7658553166561544, 0.11321785740743018, 0.4656075960796351, 0.28539534083319107, 0.3865117475143658, 0.38260590403902206, 0.12803406179539, 0.8084496655086189, 0.14314902094125792, 0.25111406746762654, 0.21975210447926818, 0.717303332244114, 0.2927225875175449, 0.36945051401558526, 0.5028804240696746, 0.11684002964057671, 0.1843830277672489]}, "task_prompt": ""}
{"id": "e1813e81-62f7-48ba-8945-fb5a2f6f3776", "fitness": 0.49309559407459175, "name": "DifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass DifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.8, CR=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR  # Crossover rate\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = population[a] + self.F * (population[b] - population[c])\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n        # Find best solution in the final population\n        best_index = np.argmin(fitness)\n        if fitness[best_index] < self.f_opt:\n          self.f_opt = fitness[best_index]\n          self.x_opt = population[best_index]\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DifferentialEvolution scored 0.493 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1675246592190036, 0.2918729860088668, 0.4484811714366339, 0.7193481654791901, 0.5172545333934795, 0.5617053829494085, 0.32863472858937426, 0.4164387199401881, 0.5291549551666606, 0.31871409405233875, 0.6676261581550482, 0.9970615150085624, 0.3220985119436165, 0.38736624344446613, 0.8266728394642517, 0.5690691745118328, 0.3813947598246561, 0.7175277188797422, 0.20292529097146694, 0.4910402730530483]}, "task_prompt": ""}
{"id": "6ca2f475-7dc6-429e-9cfc-46885fedaf46", "fitness": 0.2882386334815382, "name": "AdaptiveSimulatedAnnealing", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveSimulatedAnnealing:\n    def __init__(self, budget=10000, dim=10, initial_temp=1.0, cooling_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.step_size = 0.1\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        self.budget -= 1\n\n        self.f_opt = f\n        self.x_opt = x\n        \n        temp = self.initial_temp\n        success_count = 0\n        total_count = 0\n\n        while self.budget > 0:\n            x_new = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            \n            f_new = func(x_new)\n            self.budget -= 1\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n            delta_e = f_new - f\n            if delta_e < 0:\n                x = x_new\n                f = f_new\n                success_count += 1\n            else:\n                if np.random.rand() < np.exp(-delta_e / temp):\n                    x = x_new\n                    f = f_new\n            \n            total_count += 1\n            \n            if total_count % 100 == 0:\n                success_rate = success_count / total_count\n                if success_rate > 0.4:\n                    self.step_size *= 1.1\n                elif success_rate < 0.1:\n                    self.step_size *= 0.9\n                success_count = 0\n                total_count = 0\n\n            temp *= self.cooling_rate\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSimulatedAnnealing scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.042874381888513335, 0.17901309499403673, 0.22453513664719982, 0.9424736937998386, 0.1573466939397744, 0.24732900488636334, 0.2214788314820828, 0.0914528093067114, 0.13400711645369212, 0.16641259728247715, 0.8972187961514781, 0.1494008536831719, 0.2166681756442601, 0.14609370104596042, 0.17572023872354836, 0.3018284292114124, 0.1640885818768787, 0.8218769495823863, 0.09351172112111839, 0.3914418619098605]}, "task_prompt": ""}
{"id": "285e62a1-3991-4ef5-a213-a59c0aa7bba5", "fitness": 0.2096577378175924, "name": "BudgetCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass BudgetCMAES:\n    def __init__(self, budget=10000, dim=10, pop_size=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else int(4 + np.floor(3 * np.log(dim)))\n        self.mu = self.pop_size // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.m = None\n        self.sigma = 0.3\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.chiN = dim**0.5 * (1 - 1/(4*dim) + 1/(21*dim**2))\n        self.c_sigma = (self.mu + 2) / (self.dim + self.mu + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mu - 1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = 4/(self.dim + 4)\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.mu)\n        self.c_mu = min(1 - self.c_1, 2 * (self.mu - 1 + 1/self.mu) / ((self.dim + 2)**2 + self.mu))\n\n    def latin_hypercube_sampling(self, n_samples, bounds):\n        lower_bounds, upper_bounds = bounds.lb, bounds.ub\n        n_dim = len(lower_bounds)\n        samples = np.zeros((n_samples, n_dim))\n        for i in range(n_dim):\n            p = (np.random.permutation(n_samples) + np.random.rand(n_samples)) / n_samples\n            samples[:, i] = lower_bounds[i] + p * (upper_bounds[i] - lower_bounds[i])\n        return samples\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.m = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # Initialize population using LHS\n        population = self.latin_hypercube_sampling(self.pop_size, func.bounds)\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            z = np.random.multivariate_normal(np.zeros(self.dim), self.C, size=self.pop_size)\n            x = self.m + self.sigma * z\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = x[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n\n            idx = np.argsort(fitness)\n            x_sorted = x[idx]\n            z_sorted = z[idx]\n\n            m_old = self.m.copy()\n            self.m = np.sum(self.weights[:, None] * x_sorted[:self.mu], axis=0)\n            z_mean = np.sum(self.weights[:, None] * z_sorted[:self.mu], axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * z_mean\n            norm_ps = np.linalg.norm(self.ps)\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * (norm_ps / self.chiN - 1))\n\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * (self.m - m_old) / self.sigma\n\n            h_sigma = norm_ps/np.sqrt(1-(1-self.c_sigma)**(2*(self.budget/self.pop_size))) < (1.4 + 2/(self.dim + 1))*self.chiN\n\n            delta = (1 - h_sigma) * self.c_c * (2 - self.c_c)\n\n            self.C = (1 - self.c_1 - self.c_mu + self.c_1 * delta) * self.C + \\\n                       self.c_1 * np.outer(self.pc, self.pc)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm BudgetCMAES scored 0.210 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.10572929754762317, 0.1819975488604676, 0.20847634244391944, 0.17294061962553975, 0.11573825292469642, 0.12358842380300827, 0.23392600571779099, 0.14427049760651733, 0.1551077193876419, 0.11090497745599825, 0.1420253313775116, 0.999483611301431, 0.2909893700367341, 0.1356578370292938, 0.159890007188084, 0.2049832679185647, 0.2064832855754839, 0.19854176621442698, 0.11573227092030935, 0.1866883234168052]}, "task_prompt": ""}
{"id": "b3f0b2b9-5e12-489a-a900-4578b55c0053", "fitness": "-inf", "name": "GaussianMixtureOptimization", "description": "No description provided.", "code": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\nclass GaussianMixtureOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, n_components=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.n_components = n_components\n        self.bounds_lb = -5.0\n        self.bounds_ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            # Fit Gaussian Mixture Model\n            gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', random_state=0, max_iter=10, n_init=1)\n            gmm.fit(population)\n\n            # Sample new candidate solutions\n            new_population = gmm.sample(self.pop_size)[0]\n            new_population = np.clip(new_population, self.bounds_lb, self.bounds_ub)\n\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Elitism: Keep the best individual from the previous population\n            best_index = np.argmin(fitness)\n            worst_index = np.argmax(new_fitness)\n            if fitness[best_index] < new_fitness[worst_index]:\n                new_fitness[worst_index] = fitness[best_index]\n                new_population[worst_index] = population[best_index]\n\n            # Update population and fitness\n            population = new_population\n            fitness = new_fitness\n\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'GaussianMixture' is not defined\nOn line: gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', random_state=0, max_iter=10, n_init=1)", "error": "In the code, line 28, in __call__, the following error occurred:\nNameError: name 'GaussianMixture' is not defined\nOn line: gmm = GaussianMixture(n_components=self.n_components, covariance_type='full', random_state=0, max_iter=10, n_init=1)", "parent_ids": [], "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "55e999d7-4055-4efa-ace9-71ae67251f86", "fitness": 0.28830517945737516, "name": "StochasticBlend", "description": "No description provided.", "code": "import numpy as np\n\nclass StochasticBlend:\n    def __init__(self, budget=10000, dim=10, pop_size=20, blend_rate=0.1, perturb_std=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.blend_rate = blend_rate\n        self.perturb_std = perturb_std\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initial best\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = population[best_idx]\n\n        while self.budget > 0:\n            # Blend with best and perturb\n            for i in range(self.pop_size):\n                if np.random.rand() < self.blend_rate:\n                    population[i] = (1 - self.blend_rate) * population[i] + self.blend_rate * self.x_opt + np.random.normal(0, self.perturb_std, size=self.dim)\n                else:\n                    population[i] = population[i] + np.random.normal(0, self.perturb_std, size=self.dim)\n\n                population[i] = np.clip(population[i], func.bounds.lb, func.bounds.ub)  # Clip to bounds\n\n            # Evaluate\n            fitness = np.array([func(x) for x in population])\n            self.budget -= self.pop_size\n\n            # Update best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n\n            if self.budget <= 0:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm StochasticBlend scored 0.288 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1186635925935523, 0.23680278745333538, 0.2842364831795532, 0.1852856653246986, 0.217173832517507, 0.29276160559823405, 0.2413867821771456, 0.25518004850166653, 0.2173814852381084, 0.16126805433774516, 0.17917596423436533, 0.9999127776376361, 0.2718706373220905, 0.17541167133379398, 0.5512335202353005, 0.27086967283071484, 0.23004712652386228, 0.2451454119931029, 0.1565669345704559, 0.4757295355446354]}, "task_prompt": ""}
{"id": "e8fec131-0963-4c98-9f73-67208c9ca8fb", "fitness": 0.40804145357816807, "name": "PerturbationBasedOptimization", "description": "No description provided.", "code": "import numpy as np\n\nclass PerturbationBasedOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=None, local_ratio=0.5, success_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 20\n        self.local_ratio = local_ratio\n        self.success_threshold = success_threshold\n        self.perturbation_strength = 0.1\n        self.success_history = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Select a solution to perturb\n                x = population[i].copy()\n                f = fitness[i]\n\n                # Perturb the solution using a combination of global and local search\n                if np.random.rand() < self.local_ratio:\n                    # Local search: perturb each dimension with a small random value\n                    perturbation = np.random.normal(0, self.perturbation_strength, size=self.dim)\n                    x_new = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n                \n                else:\n                    # Global search: select another random solution and move towards it\n                    j = np.random.randint(self.pop_size)\n                    x_other = population[j]\n                    x_new = np.clip(x + self.perturbation_strength * (x_other - x), func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the new solution\n                f_new = func(x_new)\n                self.budget -= 1\n                \n                # Accept the new solution if it's better\n                if f_new < f:\n                    fitness[i] = f_new\n                    population[i] = x_new\n                    \n                    # Update success history\n                    self.success_history.append(True)\n                    \n                    if f_new < self.f_opt:\n                        self.f_opt = f_new\n                        self.x_opt = x_new\n                else:\n                    self.success_history.append(False)\n\n                # Adjust perturbation strength based on success rate\n                if len(self.success_history) > 50:\n                    success_rate = np.mean(self.success_history[-50:])\n                    if success_rate > self.success_threshold:\n                        self.perturbation_strength *= 1.1  # Increase perturbation strength\n                    else:\n                        self.perturbation_strength *= 0.9  # Decrease perturbation strength\n                    self.perturbation_strength = np.clip(self.perturbation_strength, 0.01, 1.0)  # Limit range\n\n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PerturbationBasedOptimization scored 0.408 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13944857313587633, 0.18674073936966784, 0.41891785644760327, 0.8226658491327952, 0.3130886455754619, 0.5485183756849084, 0.28387656868624445, 0.3623372837977352, 0.2814174040585067, 0.19672414693870766, 0.3920157634479938, 0.9890133901497664, 0.2366553644753333, 0.28305634817944836, 0.7625165495797013, 0.420248260323716, 0.2952188781092705, 0.6088769213152725, 0.1535203238548669, 0.46597182930048564]}, "task_prompt": ""}
{"id": "3e142f5a-e043-4102-b8c8-2ff5f081bbde", "fitness": 0.30547030885897836, "name": "AdaptiveRandomWalk", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveRandomWalk:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, success_rate_threshold=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = initial_step_size\n        self.success_rate_threshold = success_rate_threshold\n        self.success_count = 0\n        self.iteration = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        self.f_opt = func(x)\n        self.x_opt = x\n        self.budget -= 1\n        \n        while self.budget > 0:\n            self.iteration += 1\n            # Random Walk\n            x_new_rw = x + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n            x_new_rw = np.clip(x_new_rw, func.bounds.lb, func.bounds.ub)\n            \n            # Gaussian Perturbation\n            x_new_gauss = x + np.random.normal(0, self.step_size, size=self.dim)\n            x_new_gauss = np.clip(x_new_gauss, func.bounds.lb, func.bounds.ub)\n            \n            f_rw = func(x_new_rw)\n            self.budget -= 1\n            \n            if f_rw < self.f_opt:\n                self.f_opt = f_rw\n                self.x_opt = x_new_rw\n                x = x_new_rw\n                self.success_count += 1\n                \n            elif self.budget > 0:\n                f_gauss = func(x_new_gauss)\n                self.budget -= 1\n            \n                if f_gauss < self.f_opt:\n                    self.f_opt = f_gauss\n                    self.x_opt = x_new_gauss\n                    x = x_new_gauss\n                    self.success_count += 1\n                else:\n                    pass\n            \n            # Adapt step size\n            success_rate = self.success_count / self.iteration if self.iteration > 0 else 0\n            if success_rate > self.success_rate_threshold:\n                self.step_size *= 1.1  # Increase step size\n            else:\n                self.step_size *= 0.9  # Decrease step size\n            \n            self.step_size = np.clip(self.step_size, 1e-6, (func.bounds.ub - func.bounds.lb)[0])  # Limit step size\n\n            if self.budget <= 0:\n                break\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveRandomWalk scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [9.999999999998899e-05, 0.19852666370602146, 0.3462782135542599, 0.24948088048496997, 0.13232818032978955, 0.9272380409339503, 0.266962216813853, 0.3809102317477636, 0.15108421221077828, 0.13790524309875274, 0.19149352199922565, 0.1410597826116593, 0.24059303275435429, 0.339007677765616, 0.5552646756382495, 0.35767150224442334, 0.27394463324872254, 0.9705057944167738, 0.13007165430841416, 0.11898001931198887]}, "task_prompt": ""}
{"id": "058aae85-755c-4bec-bb03-dcc2125f2b49", "fitness": 0.5040323930811679, "name": "HybridPSO_DE", "description": "No description provided.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(budget // 10, dim * pop_multiplier)\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover rate\n        self.velocity = None\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population and velocity\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocity = np.random.uniform(-1, 1, size=(self.pop_size, self.dim)) * (func.bounds.ub - func.bounds.lb) / 2\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        # Find initial global best\n        global_best_index = np.argmin(fitness)\n        global_best_position = population[global_best_index].copy()\n        self.f_opt = fitness[global_best_index]\n        self.x_opt = global_best_position.copy()\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Velocity update with PSO and DE components\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                \n                # DE Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                \n                self.velocity[i] = self.w * self.velocity[i] + \\\n                                    self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                    self.c2 * r2 * (global_best_position - population[i]) + \\\n                                    0.1 * (mutant - population[i]) # Add a small DE component\n                \n                # Update position\n                trial = np.clip(population[i] + self.velocity[i], func.bounds.lb, func.bounds.ub)\n                \n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Update personal best\n                if f < personal_best_fitness[i]:\n                    personal_best_fitness[i] = f\n                    personal_best_positions[i] = trial.copy()\n                    \n                    # Update global best\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial.copy()\n                        global_best_position = trial.copy() # update global best position as well\n                \n                # Update population\n                population[i] = trial.copy() # Always update the population\n\n                if self.budget <= 0:\n                    break\n\n            # Adaptive parameter adjustment\n            self.w = 0.7 - (0.7 - 0.4) * (self.budget / (self.budget + self.pop_size)) # linearlly decrease inertia weight\n            self.F = 0.5 + 0.3 * np.random.rand() # Adapt F to diversify mutation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE scored 0.504 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.22440961634771905, 0.16447603718671866, 0.922726296561435, 0.21781480534482167, 0.2581785053896596, 0.9495849028004157, 0.3506804166149654, 0.45310352815814137, 0.8930701151885259, 0.2339575149191916, 0.9533497061973637, 0.9977016096148411, 0.3323678078822342, 0.9086148562870665, 0.5886996594451683, 0.33513027039955745, 0.29850699282305027, 0.29875624589032856, 0.25194156275818236, 0.44757741181397204]}, "task_prompt": ""}
{"id": "432c71a4-1d79-49b3-8788-e7b70fa6ca9b", "fitness": 0.5509269456946169, "name": "CauchyDifferentialEvolution", "description": "No description provided.", "code": "import numpy as np\n\nclass CauchyDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_multiplier=5, initial_pop_fraction=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = int(min(budget // 10, dim * pop_multiplier * initial_pop_fraction))\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5\n        self.CR = 0.9\n        self.shrink_factor = 0.99  # Population shrink rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        \n        self.budget -= self.pop_size\n        \n        if np.min(fitness) < self.f_opt:\n            self.f_opt = np.min(fitness)\n            self.x_opt = population[np.argmin(fitness)]\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation (Cauchy)\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                cauchy_noise = np.random.standard_cauchy(size=self.dim)\n                mutant = np.clip(a + self.F * (b - c) + 0.01 * cauchy_noise, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Selection\n                f = func(trial)\n                self.budget -= 1\n\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n                if self.budget <= 0:\n                    break\n\n            # Shrink population (reduce exploration, focus on exploitation)\n            self.pop_size = max(int(self.pop_size * self.shrink_factor), 1)\n            if self.pop_size < self.initial_pop_size and self.budget > 0:\n\n                new_population_size = min(self.initial_pop_size, self.budget)\n\n                if new_population_size > self.pop_size:\n                    new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(new_population_size - self.pop_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    self.budget -= (new_population_size - self.pop_size)\n\n                    population = np.concatenate((population, new_population))\n                    fitness = np.concatenate((fitness, new_fitness))\n                    self.pop_size = new_population_size\n\n                    if np.min(fitness) < self.f_opt:\n                        self.f_opt = np.min(fitness)\n                        self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CauchyDifferentialEvolution scored 0.551 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.2119016258827865, 0.4702633257987845, 0.5222617076802558, 0.9515977794774374, 0.5460520382657681, 0.5874409250613142, 0.47781449697576295, 0.4692683679380574, 0.556069708369506, 0.19986989400748623, 0.8827324136781902, 0.9944525315510555, 0.24336503744738047, 0.532145382865983, 0.922306592663612, 0.5935195390724219, 0.43873904759123195, 0.7640858730092324, 0.17728515513691712, 0.47736747141915226]}, "task_prompt": ""}
{"id": "4c140282-3a6c-4107-b9c7-2bb2e94105e1", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, sigma0=0.5, mu_factor=0.25, initial_pop_size=None, pop_size_adaptation_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.sigma0 = sigma0\n        self.mu_factor = mu_factor\n        self.initial_pop_size = initial_pop_size if initial_pop_size is not None else 4 + int(3 * np.log(dim))\n        self.pop_size = self.initial_pop_size\n        self.pop_size_adaptation_rate = pop_size_adaptation_rate\n        self.mu = int(self.pop_size * self.mu_factor)\n        self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n        self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n        self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.ccov = (1 / self.mueff) * ((self.mueff + 2) / (self.dim + 2)**2 + (1 - 1 / self.mueff) * (2 - self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.chiN = self.dim**0.5 * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.last_improvement = 0\n        self.improvement_threshold = 0.01 #threshold to check if improvement is significant\n        \n\n    def __call__(self, func):\n        # Initialize variables\n        mean = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        sigma = self.sigma0\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Generate and evaluate population\n            z = np.random.normal(0, 1, size=(self.pop_size, self.dim))\n            A = np.linalg.cholesky(C)\n            x = mean + sigma * z @ A.T\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            fitness = np.array([func(xi) for xi in x])\n            self.budget -= self.pop_size\n\n            if np.min(fitness) < self.f_opt:\n                improvement = (self.f_opt - np.min(fitness))/np.abs(self.f_opt)\n                if(np.abs(self.f_opt) < 1e-9):\n                  improvement = self.f_opt - np.min(fitness) # if near zero use absolute difference for improvement\n                if improvement > self.improvement_threshold: #significant improvement?\n                    self.f_opt = np.min(fitness)\n                    self.x_opt = x[np.argmin(fitness)]\n                    self.last_improvement = generation #update generation of last improvement\n\n            if self.budget <= 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            x = x[idx]\n            z = z[idx]\n\n            # Update mean\n            mean_old = mean.copy()\n            mean = np.sum(self.weights[:self.mu, None] * x[:self.mu], axis=0)\n\n            # Update evolution paths\n            ps = (1 - self.cs) * ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (mean - mean_old) / sigma @ np.linalg.inv(A).T\n            hsig = np.linalg.norm(ps) / np.sqrt(1 - (1 - self.cs)**2)**0.5 < self.chiN * (self.dim + 2)/self.dim\n            pc = (1 - self.ccov) * pc + hsig * np.sqrt(self.ccov * (2 - self.ccov) * self.mueff) * (mean - mean_old) / sigma\n\n            # Update covariance matrix\n            C = (1 - self.ccov) * C + self.ccov * (pc[:, None] @ pc[None, :])\n            for i in range(self.mu):\n                C += self.ccov * self.weights[i] * (z[i, :, None] @ z[i, None, :])\n\n            # Update step size\n            sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(ps) / self.chiN - 1))\n            \n            #Adaptive population size\n            if generation - self.last_improvement > 50: #if no improvement for some time, reduce pop size\n                self.pop_size = max(4, int(self.pop_size * (1 - self.pop_size_adaptation_rate)))\n                self.mu = int(self.pop_size * self.mu_factor)\n                self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n                self.last_improvement = generation\n            elif generation - self.last_improvement < 10 and self.pop_size < self.initial_pop_size * 2: #increase pop size if improvement is fast\n                self.pop_size = min(self.initial_pop_size * 2, int(self.pop_size * (1 + self.pop_size_adaptation_rate)))\n                self.mu = int(self.pop_size * self.mu_factor)\n                self.weights = np.log(self.pop_size + 1e-9) - np.log(np.arange(1, self.pop_size + 1))\n                self.weights = self.weights[:self.mu] / np.sum(self.weights[:self.mu])\n                self.mueff = np.sum(self.weights[:self.mu])**2 / np.sum(self.weights[:self.mu]**2)\n                self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n\n            # Simplified Restart mechanism: Reset to best location with smaller sigma if stagnated\n            if generation - self.last_improvement > 100:\n                mean = self.x_opt + np.random.normal(0, 0.1, size=self.dim) #around best, small variation\n                mean = np.clip(mean, func.bounds.lb, func.bounds.ub)\n                sigma = self.sigma0 * 0.5 # smaller sigma after restart\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.last_improvement = generation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveCMAES scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "a537818d-2853-439a-82a0-b661cfd5466a", "fitness": 0.5677146982111162, "name": "AdaptiveDE", "description": "No description provided.", "code": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, adaptive_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10 * dim\n        self.F = F\n        self.CR = CR\n        self.adaptive_factor = adaptive_factor\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.pop = None\n        self.fitness = None\n\n    def initialize_population(self, func):\n        self.pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.pop])\n        self.budget -= self.pop_size\n        \n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.f_opt:\n            self.f_opt = self.fitness[best_idx]\n            self.x_opt = self.pop[best_idx]\n        \n    def __call__(self, func):\n        self.initialize_population(func)\n        \n        while self.budget > 0:\n            new_pop = np.zeros_like(self.pop)\n            new_fitness = np.zeros_like(self.fitness)\n            \n            num_improvements = 0\n            \n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.pop[idxs]\n                \n                v = x1 + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                jrand = np.random.randint(self.dim)\n                u = np.copy(self.pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        u[j] = v[j]\n                \n                # Evaluation\n                f = func(u)\n                self.budget -= 1\n                \n                if f < self.fitness[i]:\n                    new_pop[i] = u\n                    new_fitness[i] = f\n                    num_improvements += 1\n                else:\n                    new_pop[i] = self.pop[i]\n                    new_fitness[i] = self.fitness[i]\n                \n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = u\n                \n                if self.budget <= 0:\n                    break\n            \n            if self.budget <= 0:\n                break\n\n            #Adapt F and CR\n            success_rate = num_improvements / self.pop_size\n            self.F = np.clip(self.F + self.adaptive_factor * (success_rate - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.adaptive_factor * (success_rate - 0.5), 0.1, 1.0)\n            \n            # Update population\n            self.pop = new_pop\n            self.fitness = new_fitness\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE scored 0.568 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.19775904556154167, 0.20847699662609864, 0.5110539320149297, 0.8113086257780162, 0.6268119232888438, 0.7800941532731002, 0.5149407639997183, 0.39875033858307174, 0.6641475658442476, 0.4682960480449949, 0.7018967584444572, 0.9982658624412797, 0.2777743771916896, 0.5576601489105252, 0.7235090411098366, 0.810257289618461, 0.5211514838086732, 0.8393175887530624, 0.24454258156124997, 0.49827943936852725]}, "task_prompt": ""}
