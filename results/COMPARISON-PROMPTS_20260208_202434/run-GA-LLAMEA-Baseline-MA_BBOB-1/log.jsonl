{"id": "5b3506f9-81f1-4a84-a87c-823c80682ecc", "fitness": 0.0, "name": "CooperativeEnsembleGradientSearch", "description": "Cooperative Ensemble of Gradient-based Local Search with Restart and Adaptive Step Size, guided by the population mean.", "code": "import numpy as np\n\nclass CooperativeEnsembleGradientSearch:\n    def __init__(self, budget=10000, dim=10, ensemble_size=5, step_size=0.1, adaptation_rate=0.1, restart_prob=0.05):\n        \"\"\"\n        Initializes the Cooperative Ensemble Gradient Search optimizer.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            ensemble_size (int): The number of search agents in the ensemble.\n            step_size (float): Initial step size for gradient descent.\n            adaptation_rate (float): Rate at which step size is adapted.\n            restart_prob (float): Probability of restarting a search agent.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.ensemble_size = ensemble_size\n        self.step_size = step_size\n        self.adaptation_rate = adaptation_rate\n        self.restart_prob = restart_prob\n        self.x = None\n        self.f = None\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function using the cooperative ensemble gradient search.\n\n        Args:\n            func (callable): The black-box function to optimize.  Must have attributes `bounds` containing `lb` and `ub`.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n\n        # Initialize the ensemble\n        ensemble_x = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.ensemble_size, self.dim))\n        ensemble_f = np.array([func(x) for x in ensemble_x])\n        self.budget -= self.ensemble_size\n\n        # Update the best solution\n        best_index = np.argmin(ensemble_f)\n        if ensemble_f[best_index] < self.f_opt:\n            self.f_opt = ensemble_f[best_index]\n            self.x_opt = ensemble_x[best_index]\n\n        while self.budget > 0:\n            # Calculate the population mean\n            population_mean = np.mean(ensemble_x, axis=0)\n\n            for i in range(self.ensemble_size):\n                # Possibly restart the agent\n                if np.random.rand() < self.restart_prob:\n                    ensemble_x[i] = np.random.uniform(self.bounds_lb, self.bounds_ub)\n                    ensemble_f[i] = func(ensemble_x[i])\n                    self.budget -= 1\n                    if ensemble_f[i] < self.f_opt:\n                        self.f_opt = ensemble_f[i]\n                        self.x_opt = ensemble_x[i]\n                    continue\n                \n                # Estimate gradient using a central difference\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = ensemble_x[i].copy()\n                    x_minus = ensemble_x[i].copy()\n                    delta = 1e-4  # Small perturbation\n                    x_plus[j] = min(self.bounds_ub, x_plus[j] + delta)\n                    x_minus[j] = max(self.bounds_lb, x_minus[j] - delta)\n                    \n                    f_plus = func(x_plus)\n                    f_minus = func(x_minus)\n                    self.budget -= 2  # Count the extra function evaluations\n                    if (f_plus < self.f_opt):\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus\n                    if (f_minus < self.f_opt):\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus    \n                        \n                    gradient[j] = (f_plus - f_minus) / (2 * delta)\n                    \n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                # Gradient descent step, guided by population mean (attraction to the mean)\n                new_x = ensemble_x[i] - self.step_size * gradient + self.adaptation_rate * (population_mean - ensemble_x[i])\n\n                # Clip to bounds\n                new_x = np.clip(new_x, self.bounds_lb, self.bounds_ub)\n\n                # Evaluate the new solution\n                new_f = func(new_x)\n                self.budget -= 1\n\n                # Accept the new solution if it's better\n                if new_f < ensemble_f[i]:\n                    ensemble_x[i] = new_x\n                    ensemble_f[i] = new_f\n\n                    # Update best solution\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                else:\n                     # Adaptive step size reduction\n                     self.step_size *= 0.95  # Reduce step size if no improvement\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: Cooperative Ensemble of Gradient-based Local Search with Restart and Adaptive Step Size, guided by the population mean.\n# Code: \n```python\nimport numpy as np\n\nclass CooperativeEnsembleGradientSearch:\n    def __init__(self, budget=10000, dim=10, ensemble_size=5, step_size=0.1, adaptation_rate=0.1, restart_prob=0.05):\n        \"\"\"\n        Initializes the Cooperative Ensemble Gradient Search optimizer.\n\n        Args:\n            budget (int): The total budget of function evaluations.\n            dim (int): The dimensionality of the search space.\n            ensemble_size (int): The number of search agents in the ensemble.\n            step_size (float): Initial step size for gradient descent.\n            adaptation_rate (float): Rate at which step size is adapted.\n            restart_prob (float): Probability of restarting a search agent.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.ensemble_size = ensemble_size\n        self.step_size = step_size\n        self.adaptation_rate = adaptation_rate\n        self.restart_prob = restart_prob\n        self.x = None\n        self.f = None\n        self.bounds_lb = None\n        self.bounds_ub = None\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimizes the given black-box function using the cooperative ensemble gradient search.\n\n        Args:\n            func (callable): The black-box function to optimize.  Must have attributes `bounds` containing `lb` and `ub`.\n\n        Returns:\n            tuple: The best function value found and the corresponding solution vector.\n        \"\"\"\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.bounds_lb = func.bounds.lb\n        self.bounds_ub = func.bounds.ub\n\n        # Initialize the ensemble\n        ensemble_x = np.random.uniform(self.bounds_lb, self.bounds_ub, size=(self.ensemble_size, self.dim))\n        ensemble_f = np.array([func(x) for x in ensemble_x])\n        self.budget -= self.ensemble_size\n\n        # Update the best solution\n        best_index = np.argmin(ensemble_f)\n        if ensemble_f[best_index] < self.f_opt:\n            self.f_opt = ensemble_f[best_index]\n            self.x_opt = ensemble_x[best_index]\n\n        while self.budget > 0:\n            # Calculate the population mean\n            population_mean = np.mean(ensemble_x, axis=0)\n\n            for i in range(self.ensemble_size):\n                # Possibly restart the agent\n                if np.random.rand() < self.restart_prob:\n                    ensemble_x[i] = np.random.uniform(self.bounds_lb, self.bounds_ub)\n                    ensemble_f[i] = func(ensemble_x[i])\n                    self.budget -= 1\n                    if ensemble_f[i] < self.f_opt:\n                        self.f_opt = ensemble_f[i]\n                        self.x_opt = ensemble_x[i]\n                    continue\n                \n                # Estimate gradient using a central difference\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    x_plus = ensemble_x[i].copy()\n                    x_minus = ensemble_x[i].copy()\n                    delta = 1e-4  # Small perturbation\n                    x_plus[j] = min(self.bounds_ub, x_plus[j] + delta)\n                    x_minus[j] = max(self.bounds_lb, x_minus[j] - delta)\n                    \n                    f_plus = func(x_plus)\n                    f_minus = func(x_minus)\n                    self.budget -= 2  # Count the extra function evaluations\n                    if (f_plus < self.f_opt):\n                        self.f_opt = f_plus\n                        self.x_opt = x_plus\n                    if (f_minus < self.f_opt):\n                        self.f_opt = f_minus\n                        self.x_opt = x_minus    \n                        \n                    gradient[j] = (f_plus - f_minus) / (2 * delta)\n                    \n                    if self.budget <= 0:\n                        return self.f_opt, self.x_opt\n                    \n                # Gradient descent step, guided by population mean (attraction to the mean)\n                new_x = ensemble_x[i] - self.step_size * gradient + self.adaptation_rate * (population_mean - ensemble_x[i])\n\n                # Clip to bounds\n                new_x = np.clip(new_x, self.bounds_lb, self.bounds_ub)\n\n                # Evaluate the new solution\n                new_f = func(new_x)\n                self.budget -= 1\n\n                # Accept the new solution if it's better\n                if new_f < ensemble_f[i]:\n                    ensemble_x[i] = new_x\n                    ensemble_f[i] = new_f\n\n                    # Update best solution\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n                else:\n                     # Adaptive step size reduction\n                     self.step_size *= 0.95  # Reduce step size if no improvement\n\n                if self.budget <= 0:\n                    return self.f_opt, self.x_opt\n\n        return self.f_opt, self.x_opt\n```"}, "task_prompt": ""}
{"id": "37953516-7cba-4ad5-9a75-657c7839f233", "fitness": 0.6238358059022353, "name": "HybridDEPSO", "description": "A population-based algorithm that combines aspects of differential evolution and particle swarm optimization with a restart mechanism based on stagnation detection.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO scored 0.624 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution and particle swarm optimization with a restart mechanism based on stagnation detection.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3631144797288627, 0.40206810324485553, 0.8295616766299847, 0.8958708674528275, 0.7860701014753444, 0.9142004271524564, 0.29346018864315593, 0.5863730243311368, 0.8964537490202021, 0.21879302158185232, 0.9270899071313176, 0.9968099303370621, 0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "3c970d5c-02c6-4ba6-b5e7-d0e0c562eb0e", "fitness": 0.0, "name": "HybridPSO_DE", "description": "A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), using a dynamic population size and adaptive parameter control to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, inertia_weight=0.7, c1=1.5, c2=1.5, mutation_rate=0.5, crossover_rate=0.7):\n        \"\"\"\n        Initialize the Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, defaults to 10*dim.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            mutation_rate (float): Mutation rate for DE.\n            crossover_rate (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10*dim\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions and velocities.\"\"\"\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_population(self, func):\n        \"\"\"Update the population using PSO and DE principles.\"\"\"\n\n        # PSO update\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions - self.particles)\n        social_component = self.c2 * r2 * (self.global_best_position - self.particles)\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n\n        # Limit velocities to avoid excessive jumps\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb)  # Example limit\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        self.particles += self.velocities\n\n        # DE update\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.particles[idxs]\n            mutant = x1 + self.mutation_rate * (x2 - x3)\n\n            # Crossover\n            trial_vector = self.particles[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate or j == j_rand:\n                    trial_vector[j] = mutant[j]\n\n            # Clip the particles to stay within bounds\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluation\n            f = func(trial_vector)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.particles[i] = trial_vector\n                self.fitness[i] = f\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = trial_vector.copy()\n\n                # Update global best\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial_vector.copy()\n\n            if self.eval_count >= self.budget:\n                return\n\n        # Adjust population size (Example: reduce if stagnating)\n        if self.eval_count % 1000 == 0:\n            if np.std(self.fitness) < 1e-6 and self.pop_size > 10: # Simple stagnation detection\n               self.pop_size = max(10, int(self.pop_size * 0.9))\n               # Re-initialize a portion of the population\n               num_reinit = int(self.pop_size * 0.1)\n               reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n               self.particles[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n               self.fitness[reinit_indices] = np.array([func(x) for x in self.particles[reinit_indices]])\n               self.eval_count += num_reinit\n               for i in reinit_indices:\n                 self.personal_best_positions[i] = self.particles[i].copy()\n                 self.personal_best_fitness[i] = self.fitness[i].copy()\n               \n               if np.min(self.fitness) < self.global_best_fitness:\n                 self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n                 self.global_best_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n\n        Args:\n            func: The black box function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_population(func)\n\n        return self.global_best_fitness, self.global_best_position", "configspace": "", "generation": 0, "feedback": "", "error": "Evaluation error: operands could not be broadcast together with shapes (45,5) (50,5) ", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of particle swarm optimization (PSO) and differential evolution (DE), using a dynamic population size and adaptive parameter control to balance exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget=10000, dim=10, pop_size=None, inertia_weight=0.7, c1=1.5, c2=1.5, mutation_rate=0.5, crossover_rate=0.7):\n        \"\"\"\n        Initialize the Hybrid PSO-DE optimizer.\n\n        Args:\n            budget (int): The maximum number of function evaluations.\n            dim (int): The dimensionality of the search space.\n            pop_size (int, optional): The initial population size. If None, defaults to 10*dim.\n            inertia_weight (float): Inertia weight for PSO.\n            c1 (float): Cognitive coefficient for PSO.\n            c2 (float): Social coefficient for PSO.\n            mutation_rate (float): Mutation rate for DE.\n            crossover_rate (float): Crossover rate for DE.\n        \"\"\"\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 10*dim\n        self.inertia_weight = inertia_weight\n        self.c1 = c1\n        self.c2 = c2\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n\n        self.particles = None\n        self.velocities = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.eval_count = 0\n\n\n    def initialize_population(self, func):\n        \"\"\"Initialize the population with random positions and velocities.\"\"\"\n        self.particles = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, size=(self.pop_size, self.dim))  # Initialize velocities\n        self.fitness = np.array([func(x) for x in self.particles])\n        self.eval_count += self.pop_size\n\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def update_population(self, func):\n        \"\"\"Update the population using PSO and DE principles.\"\"\"\n\n        # PSO update\n        r1 = np.random.rand(self.pop_size, self.dim)\n        r2 = np.random.rand(self.pop_size, self.dim)\n        cognitive_component = self.c1 * r1 * (self.personal_best_positions - self.particles)\n        social_component = self.c2 * r2 * (self.global_best_position - self.particles)\n        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n\n        # Limit velocities to avoid excessive jumps\n        v_max = 0.1 * (func.bounds.ub - func.bounds.lb)  # Example limit\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        self.particles += self.velocities\n\n        # DE update\n        for i in range(self.pop_size):\n            # Mutation\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            x1, x2, x3 = self.particles[idxs]\n            mutant = x1 + self.mutation_rate * (x2 - x3)\n\n            # Crossover\n            trial_vector = self.particles[i].copy()\n            j_rand = np.random.randint(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate or j == j_rand:\n                    trial_vector[j] = mutant[j]\n\n            # Clip the particles to stay within bounds\n            trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n            \n            # Evaluation\n            f = func(trial_vector)\n            self.eval_count += 1\n\n            # Selection\n            if f < self.fitness[i]:\n                self.particles[i] = trial_vector\n                self.fitness[i] = f\n\n                # Update personal best\n                if f < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = f\n                    self.personal_best_positions[i] = trial_vector.copy()\n\n                # Update global best\n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = trial_vector.copy()\n\n            if self.eval_count >= self.budget:\n                return\n\n        # Adjust population size (Example: reduce if stagnating)\n        if self.eval_count % 1000 == 0:\n            if np.std(self.fitness) < 1e-6 and self.pop_size > 10: # Simple stagnation detection\n               self.pop_size = max(10, int(self.pop_size * 0.9))\n               # Re-initialize a portion of the population\n               num_reinit = int(self.pop_size * 0.1)\n               reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n               self.particles[reinit_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_reinit, self.dim))\n               self.fitness[reinit_indices] = np.array([func(x) for x in self.particles[reinit_indices]])\n               self.eval_count += num_reinit\n               for i in reinit_indices:\n                 self.personal_best_positions[i] = self.particles[i].copy()\n                 self.personal_best_fitness[i] = self.fitness[i].copy()\n               \n               if np.min(self.fitness) < self.global_best_fitness:\n                 self.global_best_position = self.particles[np.argmin(self.fitness)].copy()\n                 self.global_best_fitness = np.min(self.fitness)\n\n\n    def __call__(self, func):\n        \"\"\"\n        Optimize the given function.\n\n        Args:\n            func: The black box function to optimize.\n\n        Returns:\n            tuple: The best fitness value and the corresponding position.\n        \"\"\"\n        self.initialize_population(func)\n        while self.eval_count < self.budget:\n            self.update_population(func)\n\n        return self.global_best_fitness, self.global_best_position\n```"}, "task_prompt": ""}
{"id": "f3ab068d-d176-407c-a715-21f2805ecd12", "fitness": 0.5977841817460965, "name": "HybridDECMAS", "description": "A population-based algorithm that combines aspects of differential evolution and covariance matrix adaptation evolution strategy, adapting the search distribution by learning from successful individuals.", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDECMAS scored 0.598 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "init", "metadata": {"llm_response": "# Description: A population-based algorithm that combines aspects of differential evolution and covariance matrix adaptation evolution strategy, adapting the search distribution by learning from successful individuals.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20035798523983916, 0.7105415533109243, 0.849359499046784, 0.9404607033358012, 0.7493475900292941, 0.9186859912820876, 0.4135201317240411, 0], "generation": 0, "operator": "init"}, "task_prompt": ""}
{"id": "cfb75808-028b-4262-b292-5ba82a53407f", "fitness": 0.1405827591803447, "name": "HybridDECMAPSOS", "description": "A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO velocity updates and a restart mechanism for enhanced exploration and exploitation in continuous optimization.", "code": "import numpy as np\n\nclass HybridDECMAPSOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n                \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 \n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDECMAPSOS scored 0.141 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO velocity updates and a restart mechanism for enhanced exploration and exploitation in continuous optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSOS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n                \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 \n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19113104162040595, 0.23061723592062822, 0], "operator": "crossover", "theta_sampled": 0.33129292292454254, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "05e1d88f-5985-456d-8dbf-0b8172721696", "fitness": 0.4013177882077698, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES-inspired adaptation, and a restart mechanism for robust global search.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        \n        # CMA-ES parameters (inspired) - simplified adaptation\n        self.c_sigma = c_sigma if c_sigma is not None else (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = d_sigma if d_sigma is not None else 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = c_c if c_c is not None else (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = c_1 if c_1 is not None else 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = c_mu if c_mu is not None else min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        self.sigma = 0.3 # Step size adaptation parameter\n        \n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional)\n                if np.random.rand() < self.local_search_probability:\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = local_f\n                            self.personal_best_positions[i] = local_trial.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n            # CMA-ES-inspired step size adaptation (simplified)\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            mean_new = np.mean(self.population[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (mean_new - np.mean(self.population, axis=0)) / self.sigma\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSOCMA scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES-inspired adaptation, and a restart mechanism for robust global search.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        \n        # CMA-ES parameters (inspired) - simplified adaptation\n        self.c_sigma = c_sigma if c_sigma is not None else (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = d_sigma if d_sigma is not None else 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = c_c if c_c is not None else (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = c_1 if c_1 is not None else 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = c_mu if c_mu is not None else min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        self.sigma = 0.3 # Step size adaptation parameter\n        \n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional)\n                if np.random.rand() < self.local_search_probability:\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = local_f\n                            self.personal_best_positions[i] = local_trial.copy()\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n            # CMA-ES-inspired step size adaptation (simplified)\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            mean_new = np.mean(self.population[:self.mu], axis=0)\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (mean_new - np.mean(self.population, axis=0)) / self.sigma\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1912651937002664, 0.3489319046775652, 0.4115780696683161, 0.418217351257146, 0.4370429409872161, 0.45476354420331355, 0.29168898594648374, 0.34063499455184576, 0.3746351233175246, 0.28172418586995907, 0.4401149790395632, 0.9915855750458117, 0.2620643750767312, 0.32974263941398285, 0.7487939365073948, 0.39966384987914894, 0.31892546025613455, 0.5836648665492226, 0], "operator": "crossover", "theta_sampled": 0.3947438188266561, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "a726d6fa-08c0-4341-8d9e-4138bb030883", "fitness": 0.07060070897015797, "name": "AdaptiveHybridDEPSO", "description": "Combines Differential Evolution (DE) and Particle Swarm Optimization (PSO) with adaptive parameter control, orthogonal learning, and a modified restart strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.orthogonal_samples = orthogonal_samples # Number of samples for orthogonal learning\n        self.adaptive_F = F\n        self.adaptive_CR = CR\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            success_count = 0\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.adaptive_F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.adaptive_CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    success_count += 1\n                    successful_F.append(self.adaptive_F)\n                    successful_CR.append(self.adaptive_CR)\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n            # Adaptive F and CR update (using success history)\n            if successful_F:\n                self.adaptive_F = np.mean(successful_F)\n            else:\n                self.adaptive_F = np.random.uniform(0.1, 0.9) # Reset if no success\n\n            if successful_CR:\n                self.adaptive_CR = np.mean(successful_CR)\n            else:\n                self.adaptive_CR = np.random.uniform(0.1, 0.9) # Reset if no success\n\n\n            # Orthogonal Learning\n            if self.budget > self.orthogonal_samples * self.dim:\n                best_index = np.argmin(self.fitness)\n                center = self.population[best_index].copy()\n                orthogonal_matrix = np.random.randn(self.orthogonal_samples, self.dim)\n                orthogonal_points = center + 0.01 * orthogonal_matrix  # Scale down the perturbation\n                orthogonal_points = np.clip(orthogonal_points, func.bounds.lb, func.bounds.ub)\n                \n                orthogonal_fitness = np.array([func(x) for x in orthogonal_points])\n                self.budget -= self.orthogonal_samples\n                \n                best_orthogonal_index = np.argmin(orthogonal_fitness)\n                if orthogonal_fitness[best_orthogonal_index] < self.global_best_fitness:\n                    self.global_best_fitness = orthogonal_fitness[best_orthogonal_index]\n                    self.global_best_position = orthogonal_points[best_orthogonal_index].copy()\n                    self.stagnation_counter = 0\n\n\n\n            # Restart mechanism - Modified: Only restart a portion of the population\n            if self.stagnation_counter > self.stagnation_threshold:\n                 num_to_restart = int(0.3 * self.pop_size)  # Restart 30% of the population\n                 indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                 \n                 for i in indices_to_restart:\n                     self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                     self.fitness[i] = func(self.population[i])\n                     self.budget -= 1\n                     self.personal_best_positions[i] = self.population[i].copy()\n                     self.personal_best_fitness[i] = self.fitness[i]\n\n\n                 self.best_index = np.argmin(self.fitness)\n                 if self.fitness[self.best_index] < self.global_best_fitness:\n                     self.global_best_fitness = self.fitness[self.best_index]\n                     self.global_best_position = self.population[self.best_index].copy()\n                 self.stagnation_counter = 0\n            \n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridDEPSO scored 0.071 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) and Particle Swarm Optimization (PSO) with adaptive parameter control, orthogonal learning, and a modified restart strategy.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.orthogonal_samples = orthogonal_samples # Number of samples for orthogonal learning\n        self.adaptive_F = F\n        self.adaptive_CR = CR\n        self.success_F = []\n        self.success_CR = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            success_count = 0\n            successful_F = []\n            successful_CR = []\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.adaptive_F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.adaptive_CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    success_count += 1\n                    successful_F.append(self.adaptive_F)\n                    successful_CR.append(self.adaptive_CR)\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n            # Adaptive F and CR update (using success history)\n            if successful_F:\n                self.adaptive_F = np.mean(successful_F)\n            else:\n                self.adaptive_F = np.random.uniform(0.1, 0.9) # Reset if no success\n\n            if successful_CR:\n                self.adaptive_CR = np.mean(successful_CR)\n            else:\n                self.adaptive_CR = np.random.uniform(0.1, 0.9) # Reset if no success\n\n\n            # Orthogonal Learning\n            if self.budget > self.orthogonal_samples * self.dim:\n                best_index = np.argmin(self.fitness)\n                center = self.population[best_index].copy()\n                orthogonal_matrix = np.random.randn(self.orthogonal_samples, self.dim)\n                orthogonal_points = center + 0.01 * orthogonal_matrix  # Scale down the perturbation\n                orthogonal_points = np.clip(orthogonal_points, func.bounds.lb, func.bounds.ub)\n                \n                orthogonal_fitness = np.array([func(x) for x in orthogonal_points])\n                self.budget -= self.orthogonal_samples\n                \n                best_orthogonal_index = np.argmin(orthogonal_fitness)\n                if orthogonal_fitness[best_orthogonal_index] < self.global_best_fitness:\n                    self.global_best_fitness = orthogonal_fitness[best_orthogonal_index]\n                    self.global_best_position = orthogonal_points[best_orthogonal_index].copy()\n                    self.stagnation_counter = 0\n\n\n\n            # Restart mechanism - Modified: Only restart a portion of the population\n            if self.stagnation_counter > self.stagnation_threshold:\n                 num_to_restart = int(0.3 * self.pop_size)  # Restart 30% of the population\n                 indices_to_restart = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                 \n                 for i in indices_to_restart:\n                     self.population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                     self.fitness[i] = func(self.population[i])\n                     self.budget -= 1\n                     self.personal_best_positions[i] = self.population[i].copy()\n                     self.personal_best_fitness[i] = self.fitness[i]\n\n\n                 self.best_index = np.argmin(self.fitness)\n                 if self.fitness[self.best_index] < self.global_best_fitness:\n                     self.global_best_fitness = self.fitness[self.best_index]\n                     self.global_best_position = self.population[self.best_index].copy()\n                 self.stagnation_counter = 0\n            \n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14120141794031593, 0], "operator": "mutation", "theta_sampled": -0.05356430972196714, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "5f7f8c61-481d-4758-aada-ca74a99729e2", "fitness": 0.18994491594273555, "name": "HybridDECMAPSO", "description": "A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO velocity updates, and a restart mechanism for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7,\n                 local_search_probability=0.1, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        global_best_fitness = fitness[best_idx]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection and update\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO velocity update\n                velocity = self.w * (population[i] - population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                population[i] = np.clip(population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n            personal_best_positions = personal_best_positions[idx_sorted]\n            personal_best_fitness = personal_best_fitness[idx_sorted]\n\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma ** 2)\n\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    personal_best_fitness[best_idx] = local_f\n                    personal_best_positions[best_idx] = local_trial.copy()\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n                        \n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_idx = np.argmin(fitness)\n                global_best_position = population[best_idx].copy()\n                global_best_fitness = fitness[best_idx]\n                self.stagnation_counter = 0\n                \n            # Global best update at the end of each generation.\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDECMAPSO scored 0.190 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO velocity updates, and a restart mechanism for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7,\n                 local_search_probability=0.1, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n        \n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # Find initial global best\n        best_idx = np.argmin(fitness)\n        global_best_position = population[best_idx].copy()\n        global_best_fitness = fitness[best_idx]\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection and update\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO velocity update\n                velocity = self.w * (population[i] - population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                population[i] = np.clip(population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n            personal_best_positions = personal_best_positions[idx_sorted]\n            personal_best_fitness = personal_best_fitness[idx_sorted]\n\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma ** 2)\n\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    personal_best_fitness[best_idx] = local_f\n                    personal_best_positions[best_idx] = local_trial.copy()\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n                        \n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_idx = np.argmin(fitness)\n                global_best_position = population[best_idx].copy()\n                global_best_fitness = fitness[best_idx]\n                self.stagnation_counter = 0\n                \n            # Global best update at the end of each generation.\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20289221806800128, 0.17868137588357658, 0.3200873796448921, 0.22491722801698688, 0.22256930551305099, 0.18046690447264113, 0], "operator": "crossover", "theta_sampled": 0.2017255267427276, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "3ca81d51-8da4-4f32-a531-17523690d734", "fitness": 0.09646621901374697, "name": "HybridDEPSOCMA", "description": "Integrates DE, PSO, CMA-ES adaptation, and a local search component for robust global optimization.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, local_search_probability=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters (initialized in __call__)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants (if not set in init)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.mean = np.mean(self.population, axis=0)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSOCMA scored 0.096 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates DE, PSO, CMA-ES adaptation, and a local search component for robust global optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, local_search_probability=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters (initialized in __call__)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants (if not set in init)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.mean = np.mean(self.population, axis=0)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19293243802749394, 0], "operator": "crossover", "theta_sampled": 0.2706451160499949, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "009bdf1b-f6d6-400b-95d7-aef978f498a5", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "An adaptive CMA-ES variant that dynamically adjusts its parameters based on the function evaluations and a diversity metric.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, cs=0.3, c_cov=0.03):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigenspace = None\n        self.eigenvalues = None\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu = int(dim / 2)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.count = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eigenspace = np.eye(self.dim)\n        self.eigenvalues = np.ones(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, self.dim)\n        x = self.mean + self.sigma * self.eigenspace @ (self.eigenvalues * z)\n        return x\n\n    def update(self, x, f):\n        x_sorted = [x_ for _, x_ in sorted(zip(f, x))]\n        self.x_mu = x_sorted[:self.mu]\n        y_k = [(xi - self.mean) / self.sigma for xi in self.x_mu]\n        y_w = np.sum([wk * yk for wk, yk in zip(self.weights, y_k)], axis=0)\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (self.eigenspace @ y_w)\n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((self.cs / self.d_sigma) * (norm_ps / np.sqrt(self.dim) - 1))\n\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_w\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n        artw_ij = np.zeros((self.dim, self.dim))\n        for k in range(self.mu):\n            artw_ij += self.weights[k] * (y_k[k][:, None] @ y_k[k][None, :])\n\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * artw_ij\n\n        self.eigenvalues, self.eigenspace = np.linalg.eigh(self.C)\n        self.eigenvalues = np.sqrt(np.maximum(self.eigenvalues, 1e-16))\n\n        self.mean = np.sum([wk * xi for wk, xi in zip(self.weights, self.x_mu)], axis=0)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize()\n\n        x_vals = []\n        f_vals = []\n        \n        for i in range(self.budget):\n            x = self.sample()\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x)\n            \n            x_vals.append(x)\n            f_vals.append(f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n            \n            if (i+1) % (self.dim*2) == 0:\n                self.update(x_vals, f_vals)\n                x_vals = []\n                f_vals = []\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive CMA-ES variant that dynamically adjusts its parameters based on the function evaluations and a diversity metric.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, cs=0.3, c_cov=0.03):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.eigenspace = None\n        self.eigenvalues = None\n        self.cs = cs\n        self.c_cov = c_cov\n        self.mu = int(dim / 2)\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.c_sigma = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.d_sigma = 1 + 2*max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.c_sigma\n        self.count = 0\n\n    def initialize(self):\n        self.mean = np.random.uniform(-5.0, 5.0, self.dim)\n        self.sigma = self.initial_sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.eigenspace = np.eye(self.dim)\n        self.eigenvalues = np.ones(self.dim)\n\n    def sample(self):\n        z = np.random.normal(0, 1, self.dim)\n        x = self.mean + self.sigma * self.eigenspace @ (self.eigenvalues * z)\n        return x\n\n    def update(self, x, f):\n        x_sorted = [x_ for _, x_ in sorted(zip(f, x))]\n        self.x_mu = x_sorted[:self.mu]\n        y_k = [(xi - self.mean) / self.sigma for xi in self.x_mu]\n        y_w = np.sum([wk * yk for wk, yk in zip(self.weights, y_k)], axis=0)\n        self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma) * self.mueff) * (self.eigenspace @ y_w)\n        norm_ps = np.linalg.norm(self.ps)\n        self.sigma *= np.exp((self.cs / self.d_sigma) * (norm_ps / np.sqrt(self.dim) - 1))\n\n        self.pc = (1 - self.cc) * self.pc + np.sqrt(self.cc * (2 - self.cc) * self.mueff) * y_w\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * (self.pc[:, None] @ self.pc[None, :])\n\n        artw_ij = np.zeros((self.dim, self.dim))\n        for k in range(self.mu):\n            artw_ij += self.weights[k] * (y_k[k][:, None] @ y_k[k][None, :])\n\n        self.C = (1 - self.c_cov) * self.C + self.c_cov * artw_ij\n\n        self.eigenvalues, self.eigenspace = np.linalg.eigh(self.C)\n        self.eigenvalues = np.sqrt(np.maximum(self.eigenvalues, 1e-16))\n\n        self.mean = np.sum([wk * xi for wk, xi in zip(self.weights, self.x_mu)], axis=0)\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize()\n\n        x_vals = []\n        f_vals = []\n        \n        for i in range(self.budget):\n            x = self.sample()\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x)\n            \n            x_vals.append(x)\n            f_vals.append(f)\n\n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n            \n            if (i+1) % (self.dim*2) == 0:\n                self.update(x_vals, f_vals)\n                x_vals = []\n                f_vals = []\n        \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.3077065372812377, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "9a6ce910-a76f-4950-a113-488d42c0de9b", "fitness": 0.0, "name": "HybridDEPSOSA", "description": "Combines Differential Evolution (DE) for exploration, Particle Swarm Optimization (PSO) for exploitation, and Simulated Annealing (SA) for escaping local optima, incorporating dynamic parameter adjustments and a local search to fine-tune solutions.", "code": "import numpy as np\n\nclass HybridDEPSOSA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, temp_start=1.0, temp_end=0.0001, stagnation_threshold=500, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.temp_start = temp_start # Initial temperature for SA\n        self.temp_end = temp_end # Final temperature for SA\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Dynamic inertia weight and temperature\n            w = self.w_start - (self.w_start - self.w_end) * (generation / self.budget)  # Linear decay\n            temp = self.temp_start - (self.temp_start - self.temp_end) * (generation / self.budget)\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                delta_f = f_u - self.fitness[i]\n\n                # Simulated Annealing acceptance criterion\n                if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n                #Local search\n                if np.random.rand() < self.local_search_prob:\n                    x_local = self.population[i].copy()\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    for j in range(self.dim):\n                        x_local[j] += np.random.uniform(-step_size[j], step_size[j])\n                        x_local[j] = np.clip(x_local[j], func.bounds.lb[j], func.bounds.ub[j])\n\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local\n                        if f_local < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_local\n                            self.personal_best_positions[i] = x_local.copy()\n                        if f_local < self.global_best_fitness:\n                            self.global_best_fitness = f_local\n                            self.global_best_position = x_local.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSOSA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) for exploration, Particle Swarm Optimization (PSO) for exploitation, and Simulated Annealing (SA) for escaping local optima, incorporating dynamic parameter adjustments and a local search to fine-tune solutions.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDEPSOSA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, temp_start=1.0, temp_end=0.0001, stagnation_threshold=500, local_search_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.temp_start = temp_start # Initial temperature for SA\n        self.temp_end = temp_end # Final temperature for SA\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_prob = local_search_prob\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Dynamic inertia weight and temperature\n            w = self.w_start - (self.w_start - self.w_end) * (generation / self.budget)  # Linear decay\n            temp = self.temp_start - (self.temp_start - self.temp_end) * (generation / self.budget)\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                v = np.clip(v, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                delta_f = f_u - self.fitness[i]\n\n                # Simulated Annealing acceptance criterion\n                if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n                #Local search\n                if np.random.rand() < self.local_search_prob:\n                    x_local = self.population[i].copy()\n                    step_size = 0.01 * (func.bounds.ub - func.bounds.lb)\n                    for j in range(self.dim):\n                        x_local[j] += np.random.uniform(-step_size[j], step_size[j])\n                        x_local[j] = np.clip(x_local[j], func.bounds.lb[j], func.bounds.ub[j])\n\n                    f_local = func(x_local)\n                    self.budget -= 1\n\n                    if f_local < self.fitness[i]:\n                        self.fitness[i] = f_local\n                        self.population[i] = x_local\n                        if f_local < self.personal_best_fitness[i]:\n                            self.personal_best_fitness[i] = f_local\n                            self.personal_best_positions[i] = x_local.copy()\n                        if f_local < self.global_best_fitness:\n                            self.global_best_fitness = f_local\n                            self.global_best_position = x_local.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.26770704250211536, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "7e735517-aa55-4d43-8038-a4a44f71e236", "fitness": 0.4756411378296039, "name": "HybridDECMAS", "description": "Hybrid DECMAS with adaptive parameter control and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, adaptive_mutation=True, orthogonal_learning=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.adaptive_mutation = adaptive_mutation\n        self.orthogonal_learning = orthogonal_learning\n\n        self.mutation_factor_history = []\n        self.crossover_rate_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        def orthogonal_design(n):\n            H = np.array([[1, 1], [1, -1]])\n            while H.shape[0] < n:\n                H = np.kron(H, np.array([[1, 1], [1, -1]]))\n            return H[:n, :n]\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Adaptive Mutation Factor\n            if self.adaptive_mutation:\n                success_rate = np.mean(fitness < np.roll(fitness, 1))\n                if success_rate > 0.3:\n                    self.mutation_factor *= 1.1  # Increase if doing well\n                else:\n                    self.mutation_factor *= 0.9  # Decrease if not improving\n                self.mutation_factor = np.clip(self.mutation_factor, 0.1, 1.0)\n                self.mutation_factor_history.append(self.mutation_factor)\n            \n\n            # Orthogonal Learning\n            if self.orthogonal_learning:\n                if self.budget > self.pop_size and np.random.rand() < 0.1:  # 10% probability\n                    orthogonal_matrix = orthogonal_design(min(self.pop_size, self.dim))\n                    num_samples = orthogonal_matrix.shape[0]\n\n                    for k in range(num_samples):\n                        if self.budget <= 0:\n                            break\n                        sample = mean + sigma * orthogonal_matrix[k, :]\n                        sample = np.clip(sample, lb, ub)\n                        f_sample = func(sample)\n                        self.budget -= 1\n                        if f_sample < self.f_opt:\n                            self.f_opt = f_sample\n                            self.x_opt = sample\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDECMAS scored 0.476 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid DECMAS with adaptive parameter control and orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, adaptive_mutation=True, orthogonal_learning=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.adaptive_mutation = adaptive_mutation\n        self.orthogonal_learning = orthogonal_learning\n\n        self.mutation_factor_history = []\n        self.crossover_rate_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        def orthogonal_design(n):\n            H = np.array([[1, 1], [1, -1]])\n            while H.shape[0] < n:\n                H = np.kron(H, np.array([[1, 1], [1, -1]]))\n            return H[:n, :n]\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Adaptive Mutation Factor\n            if self.adaptive_mutation:\n                success_rate = np.mean(fitness < np.roll(fitness, 1))\n                if success_rate > 0.3:\n                    self.mutation_factor *= 1.1  # Increase if doing well\n                else:\n                    self.mutation_factor *= 0.9  # Decrease if not improving\n                self.mutation_factor = np.clip(self.mutation_factor, 0.1, 1.0)\n                self.mutation_factor_history.append(self.mutation_factor)\n            \n\n            # Orthogonal Learning\n            if self.orthogonal_learning:\n                if self.budget > self.pop_size and np.random.rand() < 0.1:  # 10% probability\n                    orthogonal_matrix = orthogonal_design(min(self.pop_size, self.dim))\n                    num_samples = orthogonal_matrix.shape[0]\n\n                    for k in range(num_samples):\n                        if self.budget <= 0:\n                            break\n                        sample = mean + sigma * orthogonal_matrix[k, :]\n                        sample = np.clip(sample, lb, ub)\n                        f_sample = func(sample)\n                        self.budget -= 1\n                        if f_sample < self.f_opt:\n                            self.f_opt = f_sample\n                            self.x_opt = sample\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10488582788858081, 0.3712511862107507, 0.6653737897443341, 0.5982360761716026, 0.18970443269063808, 0.5643799754579772, 0.26228656944253836, 0.4092585718141014, 0.34709051758095644, 0.18232283725613163, 0.8564715932051159, 0.9980603265539417, 0.4893875085169318, 0.1968818727043501, 0.7058470141635874, 0.675046776373845, 0.3778853854585009, 0.8227732259228475, 0.19967597902969414, 0.49600329040565116], "operator": "mutation", "theta_sampled": 0.14948718722458093, "reward": 0.0, "generation": 1}, "task_prompt": ""}
{"id": "4588e81f-018f-45cd-8beb-89716d27faa5", "fitness": 0.18260888444317963, "name": "HybridDEPSOCMA", "description": "Integrates Differential Evolution, Particle Swarm Optimization with CMA-ES-inspired adaptation and local search, employing a dynamic population and adaptive parameter control.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES-like parameters (simplified)\n        sigma = 0.3 * (ub - lb)\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update with adaptive inertia weight\n                self.w = 0.9 - (0.5 * (self.budget / 10000)) # Linearly decrease inertia weight\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n            \n            # CMA-ES like adaptation of step size (simplified)\n            if np.random.rand() < 0.2:  # Apply this with a probability to save evaluations\n                sigma *= np.exp(0.1 * (np.mean(self.fitness) - self.global_best_fitness) / (np.abs(self.global_best_fitness)+1e-8))\n                sigma = np.clip(sigma, 1e-6 * (ub-lb), 0.5*(ub-lb)) # Keep sigma within reasonable bounds\n\n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.normal(0, sigma, size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDEPSOCMA scored 0.183 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Differential Evolution, Particle Swarm Optimization with CMA-ES-inspired adaptation and local search, employing a dynamic population and adaptive parameter control.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES-like parameters (simplified)\n        sigma = 0.3 * (ub - lb)\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update with adaptive inertia weight\n                self.w = 0.9 - (0.5 * (self.budget / 10000)) # Linearly decrease inertia weight\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n            \n            # CMA-ES like adaptation of step size (simplified)\n            if np.random.rand() < 0.2:  # Apply this with a probability to save evaluations\n                sigma *= np.exp(0.1 * (np.mean(self.fitness) - self.global_best_fitness) / (np.abs(self.global_best_fitness)+1e-8))\n                sigma = np.clip(sigma, 1e-6 * (ub-lb), 0.5*(ub-lb)) # Keep sigma within reasonable bounds\n\n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.normal(0, sigma, size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.12255398894252867, 0.20549212521969473, 0.4023894236104951, 0], "operator": "crossover", "theta_sampled": 0.17232185528710048, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "d9eee6b7-6850-46cf-af0e-a48cde3af934", "fitness": 0.0, "name": "AdaptiveGaussianSampling", "description": "Adaptively samples around promising regions using a Gaussian distribution, adjusting the variance based on success rate.", "code": "import numpy as np\n\nclass AdaptiveGaussianSampling:\n    def __init__(self, budget=10000, dim=10, initial_variance=1.0, exploration_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_variance = initial_variance\n        self.variance = initial_variance\n        self.success_rate = 0.0\n        self.success_count = 0\n        self.total_samples = 0\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x_current = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        f_current = func(x_current)\n        self.f_opt = f_current\n        self.x_opt = x_current\n        \n        for i in range(self.budget):\n            # Exploration vs Exploitation\n            if np.random.rand() < self.exploration_rate:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            else:\n                x_new = np.random.normal(x_current, np.sqrt(self.variance), self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                \n            if f_new < f_current:\n                self.success_count += 1\n                x_current = x_new\n                f_current = f_new\n            \n            self.total_samples += 1\n            self.success_rate = self.success_count / self.total_samples if self.total_samples > 0 else 0.0\n\n            # Adjust variance based on success rate\n            if self.success_rate > 0.2:\n                self.variance *= 1.1  # Increase variance if doing well\n            elif self.success_rate < 0.1:\n                self.variance *= 0.9  # Decrease variance if not improving\n            \n            self.variance = np.clip(self.variance, 1e-6, 10.0)  # Ensure variance stays within reasonable bounds\n        \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveGaussianSampling scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptively samples around promising regions using a Gaussian distribution, adjusting the variance based on success rate.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveGaussianSampling:\n    def __init__(self, budget=10000, dim=10, initial_variance=1.0, exploration_rate = 0.1):\n        self.budget = budget\n        self.dim = dim\n        self.initial_variance = initial_variance\n        self.variance = initial_variance\n        self.success_rate = 0.0\n        self.success_count = 0\n        self.total_samples = 0\n        self.exploration_rate = exploration_rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x_current = np.random.uniform(func.bounds.lb, func.bounds.ub)\n        f_current = func(x_current)\n        self.f_opt = f_current\n        self.x_opt = x_current\n        \n        for i in range(self.budget):\n            # Exploration vs Exploitation\n            if np.random.rand() < self.exploration_rate:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n            else:\n                x_new = np.random.normal(x_current, np.sqrt(self.variance), self.dim)\n                x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n\n            f_new = func(x_new)\n            \n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n                \n            if f_new < f_current:\n                self.success_count += 1\n                x_current = x_new\n                f_current = f_new\n            \n            self.total_samples += 1\n            self.success_rate = self.success_count / self.total_samples if self.total_samples > 0 else 0.0\n\n            # Adjust variance based on success rate\n            if self.success_rate > 0.2:\n                self.variance *= 1.1  # Increase variance if doing well\n            elif self.success_rate < 0.1:\n                self.variance *= 0.9  # Decrease variance if not improving\n            \n            self.variance = np.clip(self.variance, 1e-6, 10.0)  # Ensure variance stays within reasonable bounds\n        \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.39893277668886784, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "4a955603-411b-47b8-86a5-4d38b2fdc532", "fitness": 0.5357710879587331, "name": "HybridDEPSOCMA", "description": "A hybrid Differential Evolution, Particle Swarm Optimization and Covariance Matrix Adaptation Evolution Strategy (DEPSOCMA) algorithm with adaptive parameter control and a local search mechanism.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDEPSOCMA scored 0.536 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid Differential Evolution, Particle Swarm Optimization and Covariance Matrix Adaptation Evolution Strategy (DEPSOCMA) algorithm with adaptive parameter control and a local search mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt\n```", "aucs": [0.35370934864472514, 0.28157126219764317, 0.4744422046393503, 0.9501510019585588, 0.8762908383977288, 0.5209178332833696, 0.30966201691509265, 0.7590981267348824, 0.4366601570399363, 0.9309791777347768, 0], "operator": "crossover", "theta_sampled": -0.07574277501202298, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "5c577b3e-d512-4f40-a3ae-601e1b9487a1", "fitness": 0.0, "name": "HybridDECMASBFGS", "description": "A hybrid optimization algorithm combining Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), orthogonal learning and a repair strategy that dynamically adjusts parameters and integrates a quasi-Newton method (BFGS) for local search.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASBFGS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, adaptive_mutation=True, orthogonal_learning=True, bfgs_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.adaptive_mutation = adaptive_mutation\n        self.orthogonal_learning = orthogonal_learning\n        self.bfgs_probability = bfgs_probability\n        self.mutation_factor_history = []\n        self.crossover_rate_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        def orthogonal_design(n):\n            H = np.array([[1, 1], [1, -1]])\n            while H.shape[0] < n:\n                H = np.kron(H, np.array([[1, 1], [1, -1]]))\n            return H[:n, :n]\n        \n        def repair_solution(x):\n            \"\"\"Repair solution to lie within bounds.\"\"\"\n            return np.clip(x, lb, ub)\n\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = repair_solution(trial)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Adaptive Mutation Factor\n            if self.adaptive_mutation:\n                success_rate = np.mean(fitness < np.roll(fitness, 1))\n                if success_rate > 0.3:\n                    self.mutation_factor *= 1.1  # Increase if doing well\n                else:\n                    self.mutation_factor *= 0.9  # Decrease if not improving\n                self.mutation_factor = np.clip(self.mutation_factor, 0.1, 1.0)\n                self.mutation_factor_history.append(self.mutation_factor)\n            \n\n            # Orthogonal Learning\n            if self.orthogonal_learning:\n                if self.budget > self.pop_size and np.random.rand() < 0.1:  # 10% probability\n                    orthogonal_matrix = orthogonal_design(min(self.pop_size, self.dim))\n                    num_samples = orthogonal_matrix.shape[0]\n\n                    for k in range(num_samples):\n                        if self.budget <= 0:\n                            break\n                        sample = mean + sigma * orthogonal_matrix[k, :]\n                        sample = repair_solution(sample)\n                        f_sample = func(sample)\n                        self.budget -= 1\n                        if f_sample < self.f_opt:\n                            self.f_opt = f_sample\n                            self.x_opt = sample\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = repair_solution(local_trial)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            \n            # BFGS Local Search\n            if np.random.rand() < self.bfgs_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                def bfgs_objective(x):\n                    # Repair x to lie within bounds during BFGS\n                    x_repaired = repair_solution(x)  # Repair before function evaluation\n                    return func(x_repaired)\n\n                # Use minimize with bounds\n                bounds = [(lb, ub)] * self.dim\n                result = minimize(bfgs_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(50, self.budget)}) # Limit BFGS function evaluations\n                n_evaluations = result.nfev\n                self.budget -= n_evaluations # Discount the number of function evaluations performed by BFGS.\n                \n                if self.budget <= 0:\n                    break\n\n                if result.fun < fitness[best_idx]:\n                    fitness[best_idx] = result.fun\n                    population[best_idx] = result.x\n                    \n                    if result.fun < self.f_opt:\n                        self.f_opt = result.fun\n                        self.x_opt = result.x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["7e735517-aa55-4d43-8038-a4a44f71e236"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid optimization algorithm combining Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), orthogonal learning and a repair strategy that dynamically adjusts parameters and integrates a quasi-Newton method (BFGS) for local search.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASBFGS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, adaptive_mutation=True, orthogonal_learning=True, bfgs_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.adaptive_mutation = adaptive_mutation\n        self.orthogonal_learning = orthogonal_learning\n        self.bfgs_probability = bfgs_probability\n        self.mutation_factor_history = []\n        self.crossover_rate_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        def orthogonal_design(n):\n            H = np.array([[1, 1], [1, -1]])\n            while H.shape[0] < n:\n                H = np.kron(H, np.array([[1, 1], [1, -1]]))\n            return H[:n, :n]\n        \n        def repair_solution(x):\n            \"\"\"Repair solution to lie within bounds.\"\"\"\n            return np.clip(x, lb, ub)\n\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = repair_solution(trial)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Adaptive Mutation Factor\n            if self.adaptive_mutation:\n                success_rate = np.mean(fitness < np.roll(fitness, 1))\n                if success_rate > 0.3:\n                    self.mutation_factor *= 1.1  # Increase if doing well\n                else:\n                    self.mutation_factor *= 0.9  # Decrease if not improving\n                self.mutation_factor = np.clip(self.mutation_factor, 0.1, 1.0)\n                self.mutation_factor_history.append(self.mutation_factor)\n            \n\n            # Orthogonal Learning\n            if self.orthogonal_learning:\n                if self.budget > self.pop_size and np.random.rand() < 0.1:  # 10% probability\n                    orthogonal_matrix = orthogonal_design(min(self.pop_size, self.dim))\n                    num_samples = orthogonal_matrix.shape[0]\n\n                    for k in range(num_samples):\n                        if self.budget <= 0:\n                            break\n                        sample = mean + sigma * orthogonal_matrix[k, :]\n                        sample = repair_solution(sample)\n                        f_sample = func(sample)\n                        self.budget -= 1\n                        if f_sample < self.f_opt:\n                            self.f_opt = f_sample\n                            self.x_opt = sample\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = repair_solution(local_trial)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            \n            # BFGS Local Search\n            if np.random.rand() < self.bfgs_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                def bfgs_objective(x):\n                    # Repair x to lie within bounds during BFGS\n                    x_repaired = repair_solution(x)  # Repair before function evaluation\n                    return func(x_repaired)\n\n                # Use minimize with bounds\n                bounds = [(lb, ub)] * self.dim\n                result = minimize(bfgs_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxfun': min(50, self.budget)}) # Limit BFGS function evaluations\n                n_evaluations = result.nfev\n                self.budget -= n_evaluations # Discount the number of function evaluations performed by BFGS.\n                \n                if self.budget <= 0:\n                    break\n\n                if result.fun < fitness[best_idx]:\n                    fitness[best_idx] = result.fun\n                    population[best_idx] = result.x\n                    \n                    if result.fun < self.f_opt:\n                        self.f_opt = result.fun\n                        self.x_opt = result.x\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.2520060607645561, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "1fb111c8-c6ce-40ae-ac9f-1b148480fe53", "fitness": 0.0, "name": "AdaptiveCMAES", "description": "An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that adjusts its parameters based on the success rate of its search.", "code": "import numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.1, damp=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.c1a = self.c1\n        self.cmua = self.cmu\n\n        self.sigma = 0.3\n        self.mean = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.P_sigma = np.zeros(self.dim)\n        self.P_c = np.zeros(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n        self.success_rate = 0.0\n        self.success_history = []\n\n\n    def __call__(self, func):\n        while self.func_evals < self.budget:\n            # Generate samples\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean[:, np.newaxis] + self.sigma * y\n            x = x.T\n            \n            # Evaluate samples\n            f = np.array([func(xi) for xi in x])\n            self.func_evals += self.popsize\n            \n            # Sort samples\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            ymean = xmean - self.mean\n            ymean = ymean / self.sigma\n            self.mean = xmean\n\n            # Update evolution path\n            self.P_sigma = (1-self.cs) * self.P_sigma + np.sqrt(self.cs * (2-self.cs) * self.mueff) * ymean\n            hsig = np.linalg.norm(self.P_sigma) / np.sqrt(1-(1-self.cs)**(2*self.func_evals/self.popsize))/self.chiN < 1.4 + 2/(self.dim + 1)\n            self.P_c = (1-self.cc) * self.P_c + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * ymean\n            \n            # Update covariance matrix\n            rankone = np.outer(self.P_c, self.P_c)\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * rankone\n            \n            y_k = y[:, idx[:self.mu]]\n            rankmu = np.sum(np.array([w * np.outer(y_k[:,i], y_k[:,i]) for i, w in enumerate(self.weights)]), axis=0)\n            self.C = self.C + self.cmu * rankmu\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Ensure positive definiteness (only when needed)\n            if np.min(np.linalg.eigvalsh(self.C)) <= 0:\n                self.C = self.C + (1e-8 - np.min(np.linalg.eigvalsh(self.C))) * np.eye(self.dim)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(self.P_sigma)/self.chiN - 1))\n            \n            # Adaptive parameter adjustment based on success rate\n            if len(self.success_history) > 10:\n              recent_success_rate = np.mean(self.success_history[-10:])\n              if recent_success_rate > 0.7:\n                  self.sigma *= 1.1 # Increase exploration\n                  self.cs *= 0.9\n              elif recent_success_rate < 0.3:\n                  self.sigma *= 0.9 # Decrease exploration\n                  self.cs *= 1.1\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: Eigenvalues did not converge", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive covariance matrix adaptation evolution strategy (CMA-ES) that adjusts its parameters based on the success rate of its search.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveCMAES:\n    def __init__(self, budget=10000, dim=10, popsize=None, cs=0.1, damp=None):\n        self.budget = budget\n        self.dim = dim\n        self.popsize = popsize if popsize is not None else 4 + int(3 * np.log(self.dim))\n        self.mu = self.popsize // 2\n        self.weights = np.log(self.mu + 1/2) - np.log(np.arange(1, self.mu + 1))\n        self.weights = self.weights / np.sum(self.weights)\n        self.mueff = np.sum(self.weights)**2 / np.sum(self.weights**2)\n        \n        self.cs = cs\n        self.damps = damp if damp is not None else 1 + 2 * max(0, np.sqrt((self.mueff-1)/(self.dim+1)) - 1) + self.cs\n        self.cc = (4 + self.mueff/self.dim) / (self.dim + 4 + 2*self.mueff/self.dim)\n        self.chiN = self.dim**0.5 * (1 - (1/(4*self.dim)) + 1/(21*self.dim**2))\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.c1a = self.c1\n        self.cmua = self.cmu\n\n        self.sigma = 0.3\n        self.mean = np.zeros(self.dim)\n        self.C = np.eye(self.dim)\n        self.P_sigma = np.zeros(self.dim)\n        self.P_c = np.zeros(self.dim)\n\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n        self.success_rate = 0.0\n        self.success_history = []\n\n\n    def __call__(self, func):\n        while self.func_evals < self.budget:\n            # Generate samples\n            z = np.random.normal(0, 1, size=(self.dim, self.popsize))\n            y = np.dot(np.linalg.cholesky(self.C), z)\n            x = self.mean[:, np.newaxis] + self.sigma * y\n            x = x.T\n            \n            # Evaluate samples\n            f = np.array([func(xi) for xi in x])\n            self.func_evals += self.popsize\n            \n            # Sort samples\n            idx = np.argsort(f)\n            x = x[idx]\n            f = f[idx]\n            \n            # Update optimal solution\n            if f[0] < self.f_opt:\n                self.f_opt = f[0]\n                self.x_opt = x[0]\n\n            # Update mean\n            xmean = np.sum(x[:self.mu].T * self.weights, axis=1)\n            ymean = xmean - self.mean\n            ymean = ymean / self.sigma\n            self.mean = xmean\n\n            # Update evolution path\n            self.P_sigma = (1-self.cs) * self.P_sigma + np.sqrt(self.cs * (2-self.cs) * self.mueff) * ymean\n            hsig = np.linalg.norm(self.P_sigma) / np.sqrt(1-(1-self.cs)**(2*self.func_evals/self.popsize))/self.chiN < 1.4 + 2/(self.dim + 1)\n            self.P_c = (1-self.cc) * self.P_c + hsig * np.sqrt(self.cc * (2-self.cc) * self.mueff) * ymean\n            \n            # Update covariance matrix\n            rankone = np.outer(self.P_c, self.P_c)\n            self.C = (1-self.c1-self.cmu) * self.C + self.c1 * rankone\n            \n            y_k = y[:, idx[:self.mu]]\n            rankmu = np.sum(np.array([w * np.outer(y_k[:,i], y_k[:,i]) for i, w in enumerate(self.weights)]), axis=0)\n            self.C = self.C + self.cmu * rankmu\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n\n            # Ensure positive definiteness (only when needed)\n            if np.min(np.linalg.eigvalsh(self.C)) <= 0:\n                self.C = self.C + (1e-8 - np.min(np.linalg.eigvalsh(self.C))) * np.eye(self.dim)\n\n            # Update step size\n            self.sigma = self.sigma * np.exp((self.cs/self.damps) * (np.linalg.norm(self.P_sigma)/self.chiN - 1))\n            \n            # Adaptive parameter adjustment based on success rate\n            if len(self.success_history) > 10:\n              recent_success_rate = np.mean(self.success_history[-10:])\n              if recent_success_rate > 0.7:\n                  self.sigma *= 1.1 # Increase exploration\n                  self.cs *= 0.9\n              elif recent_success_rate < 0.3:\n                  self.sigma *= 0.9 # Decrease exploration\n                  self.cs *= 1.1\n            self.success_history.append(1 if f[0] < self.f_opt else 0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.05426290315552319, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "32858e06-50ca-4e21-a177-63603e98973a", "fitness": 0.5151521410579016, "name": "HybridDEPSOCMA", "description": "Integrates DE, PSO, CMA-ES, and a restart mechanism for robust global optimization.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial sigma for CMA-ES\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDEPSOCMA scored 0.515 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates DE, PSO, CMA-ES, and a restart mechanism for robust global optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial sigma for CMA-ES\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14818611079990007, 0.7302197065577438, 0.2764244495932482, 0.9785719838405553, 0.9594395933298402, 0.8043891127781155, 0.31673082716782874, 0.2570433866302767, 0.9413439100669898, 0.23693416425325564, 0.4260873222892757, 0.9974743105696204, 0.3136154456063983, 0.5299232421759914, 0.7956612822258174, 0.30911220132265116, 0.3110447441155907, 0.24848769631580936, 0.2090060097489721, 0.5133473217701534], "operator": "crossover", "theta_sampled": 0.31977447275204707, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "4bd1faa7-e73f-4081-9b6a-9b17f51106ac", "fitness": 0.03564562420539308, "name": "LevySimplex", "description": "A population-based algorithm that uses a combination of Lvy flights for global exploration and a simplified Nelder-Mead simplex for local exploitation.", "code": "import numpy as np\n\nclass LevySimplex:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.simplex_size = simplex_size\n        self.population_size = min(dim + 1, 20)  # Use a small population for Nelder-Mead\n\n    def levy_flight(self, step_size_scale=0.01):\n        \"\"\"Generate a Lvy flight step.\"\"\"\n        s = (np.random.gamma(1 + self.levy_exponent)\n             * np.sin(np.pi * self.levy_exponent / 2)) / (\n                    np.random.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent *\n                    (2 ** ((self.levy_exponent - 1) / 2)))\n        step_size = step_size_scale * s * np.random.randn(self.dim) / (np.abs(np.random.randn(self.dim)) ** (1 / self.levy_exponent))\n        return step_size\n\n\n    def create_initial_simplex(self, x_center, func):\n        \"\"\"Create an initial simplex around x_center.\"\"\"\n        simplex = [x_center]\n        fvals = [func(x_center)]\n        \n        for i in range(1, self.population_size):\n            x = x_center + np.random.normal(0, self.simplex_size, self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            simplex.append(x)\n            fvals.append(func(x))\n        \n        return simplex, fvals\n\n    def nelder_mead_iteration(self, simplex, fvals, func):\n        \"\"\"Perform one iteration of the Nelder-Mead simplex algorithm.\"\"\"\n        \n        # 1. Order the vertices\n        sorted_indices = np.argsort(fvals)\n        simplex = [simplex[i] for i in sorted_indices]\n        fvals = [fvals[i] for i in sorted_indices]\n        \n        # 2. Calculate centroid (excluding the worst point)\n        centroid = np.mean(simplex[:-1], axis=0)\n        \n        # 3. Reflection\n        x_r = centroid + 1.0 * (centroid - simplex[-1])\n        x_r = np.clip(x_r, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n        f_r = func(x_r)\n\n        if fvals[0] <= f_r < fvals[-2]:\n            simplex[-1] = x_r\n            fvals[-1] = f_r\n            return simplex, fvals\n\n        # 4. Expansion\n        if f_r < fvals[0]:\n            x_e = centroid + 2.0 * (x_r - centroid)\n            x_e = np.clip(x_e, func.bounds.lb, func.bounds.ub)\n            f_e = func(x_e)\n            if f_e < f_r:\n                simplex[-1] = x_e\n                fvals[-1] = f_e\n            else:\n                simplex[-1] = x_r\n                fvals[-1] = f_r\n            return simplex, fvals\n\n        # 5. Contraction\n        x_c = centroid + 0.5 * (simplex[-1] - centroid)\n        x_c = np.clip(x_c, func.bounds.lb, func.bounds.ub)\n        f_c = func(x_c)\n        if f_c < fvals[-1]:\n            simplex[-1] = x_c\n            fvals[-1] = f_c\n            return simplex, fvals\n\n        # 6. Shrink\n        for i in range(1, len(simplex)):\n            simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n            fvals[i] = func(simplex[i])\n        \n        return simplex, fvals\n    \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        x_start = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        simplex, fvals = self.create_initial_simplex(x_start, func)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Global Exploration: Lvy Flight\n            x_new = simplex[0] + self.levy_flight()\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < np.min(fvals):\n                worst_index = np.argmax(fvals)\n                simplex[worst_index] = x_new\n                fvals[worst_index] = f_new\n                \n            # Local Exploitation: Nelder-Mead\n            if eval_count + self.population_size < self.budget: # make sure at least one NM iteration can be done\n                simplex, fvals = self.nelder_mead_iteration(simplex, fvals, func)\n                eval_count += self.population_size -1 #each iteration calls func n-1 times where n is the number of vertices in the simplex.\n            \n            best_index = np.argmin(fvals)\n            if fvals[best_index] < self.f_opt:\n                self.f_opt = fvals[best_index]\n                self.x_opt = simplex[best_index]\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "The algorithm LevySimplex scored 0.036 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm that uses a combination of Lvy flights for global exploration and a simplified Nelder-Mead simplex for local exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass LevySimplex:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, simplex_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.simplex_size = simplex_size\n        self.population_size = min(dim + 1, 20)  # Use a small population for Nelder-Mead\n\n    def levy_flight(self, step_size_scale=0.01):\n        \"\"\"Generate a Lvy flight step.\"\"\"\n        s = (np.random.gamma(1 + self.levy_exponent)\n             * np.sin(np.pi * self.levy_exponent / 2)) / (\n                    np.random.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent *\n                    (2 ** ((self.levy_exponent - 1) / 2)))\n        step_size = step_size_scale * s * np.random.randn(self.dim) / (np.abs(np.random.randn(self.dim)) ** (1 / self.levy_exponent))\n        return step_size\n\n\n    def create_initial_simplex(self, x_center, func):\n        \"\"\"Create an initial simplex around x_center.\"\"\"\n        simplex = [x_center]\n        fvals = [func(x_center)]\n        \n        for i in range(1, self.population_size):\n            x = x_center + np.random.normal(0, self.simplex_size, self.dim)\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            simplex.append(x)\n            fvals.append(func(x))\n        \n        return simplex, fvals\n\n    def nelder_mead_iteration(self, simplex, fvals, func):\n        \"\"\"Perform one iteration of the Nelder-Mead simplex algorithm.\"\"\"\n        \n        # 1. Order the vertices\n        sorted_indices = np.argsort(fvals)\n        simplex = [simplex[i] for i in sorted_indices]\n        fvals = [fvals[i] for i in sorted_indices]\n        \n        # 2. Calculate centroid (excluding the worst point)\n        centroid = np.mean(simplex[:-1], axis=0)\n        \n        # 3. Reflection\n        x_r = centroid + 1.0 * (centroid - simplex[-1])\n        x_r = np.clip(x_r, func.bounds.lb, func.bounds.ub)  # Ensure bounds\n        f_r = func(x_r)\n\n        if fvals[0] <= f_r < fvals[-2]:\n            simplex[-1] = x_r\n            fvals[-1] = f_r\n            return simplex, fvals\n\n        # 4. Expansion\n        if f_r < fvals[0]:\n            x_e = centroid + 2.0 * (x_r - centroid)\n            x_e = np.clip(x_e, func.bounds.lb, func.bounds.ub)\n            f_e = func(x_e)\n            if f_e < f_r:\n                simplex[-1] = x_e\n                fvals[-1] = f_e\n            else:\n                simplex[-1] = x_r\n                fvals[-1] = f_r\n            return simplex, fvals\n\n        # 5. Contraction\n        x_c = centroid + 0.5 * (simplex[-1] - centroid)\n        x_c = np.clip(x_c, func.bounds.lb, func.bounds.ub)\n        f_c = func(x_c)\n        if f_c < fvals[-1]:\n            simplex[-1] = x_c\n            fvals[-1] = f_c\n            return simplex, fvals\n\n        # 6. Shrink\n        for i in range(1, len(simplex)):\n            simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n            simplex[i] = np.clip(simplex[i], func.bounds.lb, func.bounds.ub)\n            fvals[i] = func(simplex[i])\n        \n        return simplex, fvals\n    \n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialization\n        x_start = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        simplex, fvals = self.create_initial_simplex(x_start, func)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Global Exploration: Lvy Flight\n            x_new = simplex[0] + self.levy_flight()\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub)\n            f_new = func(x_new)\n            eval_count += 1\n            \n            if f_new < np.min(fvals):\n                worst_index = np.argmax(fvals)\n                simplex[worst_index] = x_new\n                fvals[worst_index] = f_new\n                \n            # Local Exploitation: Nelder-Mead\n            if eval_count + self.population_size < self.budget: # make sure at least one NM iteration can be done\n                simplex, fvals = self.nelder_mead_iteration(simplex, fvals, func)\n                eval_count += self.population_size -1 #each iteration calls func n-1 times where n is the number of vertices in the simplex.\n            \n            best_index = np.argmin(fvals)\n            if fvals[best_index] < self.f_opt:\n                self.f_opt = fvals[best_index]\n                self.x_opt = simplex[best_index]\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07129124841078616, 0], "operator": "random_new", "theta_sampled": 0.3801205136580299, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "f03baa40-68e3-4437-8146-1599c0385dda", "fitness": 0.0, "name": "LevyGradientSearch", "description": "Exploration-Exploitation using Lvy flights for global exploration and a local search gradient-based approach for exploitation, with dynamic adjustment of weights.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy\n\nclass LevyGradientSearch:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, local_search_iterations=5, exploration_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.local_search_iterations = local_search_iterations\n        self.exploration_weight = exploration_weight\n        self.exploitation_weight = 1.0 - self.exploration_weight\n        self.eval_count = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def levy_flight(self, size):\n        \"\"\"Generate Levy distribution samples.\"\"\"\n        u = np.random.normal(0, scale=np.power(1.0, 1/self.levy_exponent), size=size)\n        v = np.random.normal(0, scale=1.0, size=size)\n        return u / np.power(np.abs(v), (1/self.levy_exponent))\n\n    def local_search(self, func, x0):\n        \"\"\"Perform local search using gradient-based optimization.\"\"\"\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n\n        result = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': self.local_search_iterations})\n        return result.fun, result.x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.eval_count < self.budget:\n            # Exploration using Levy flights\n            if np.random.rand() < self.exploration_weight and self.eval_count < self.budget:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim) + self.levy_flight(self.dim) * 0.1  # scale the levy flight\n\n                # Clip to bounds\n                x = np.clip(x, self.lb, self.ub)\n\n                f = func(x)\n                self.eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Exploitation using local search\n            elif self.x_opt is not None and self.eval_count < self.budget:\n                f_local, x_local = self.local_search(func, self.x_opt)\n                self.eval_count += self.local_search_iterations # Approximating evaluations\n                if f_local < self.f_opt:\n                     self.f_opt = f_local\n                     self.x_opt = x_local\n            \n            # If no previous solution, start from random point.\n            elif self.x_opt is None and self.eval_count < self.budget:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt weights linearly\n            self.exploration_weight = max(0.1, self.exploration_weight - 0.0001)\n            self.exploitation_weight = min(0.9, self.exploitation_weight + 0.0001)\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 2, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Exploration-Exploitation using Lvy flights for global exploration and a local search gradient-based approach for exploitation, with dynamic adjustment of weights.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy\n\nclass LevyGradientSearch:\n    def __init__(self, budget=10000, dim=10, levy_exponent=1.5, local_search_iterations=5, exploration_weight=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.levy_exponent = levy_exponent\n        self.local_search_iterations = local_search_iterations\n        self.exploration_weight = exploration_weight\n        self.exploitation_weight = 1.0 - self.exploration_weight\n        self.eval_count = 0\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def levy_flight(self, size):\n        \"\"\"Generate Levy distribution samples.\"\"\"\n        u = np.random.normal(0, scale=np.power(1.0, 1/self.levy_exponent), size=size)\n        v = np.random.normal(0, scale=1.0, size=size)\n        return u / np.power(np.abs(v), (1/self.levy_exponent))\n\n    def local_search(self, func, x0):\n        \"\"\"Perform local search using gradient-based optimization.\"\"\"\n        bounds = [(self.lb, self.ub) for _ in range(self.dim)]\n\n        result = minimize(func, x0, method='L-BFGS-B', bounds=bounds, options={'maxiter': self.local_search_iterations})\n        return result.fun, result.x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        while self.eval_count < self.budget:\n            # Exploration using Levy flights\n            if np.random.rand() < self.exploration_weight and self.eval_count < self.budget:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim) + self.levy_flight(self.dim) * 0.1  # scale the levy flight\n\n                # Clip to bounds\n                x = np.clip(x, self.lb, self.ub)\n\n                f = func(x)\n                self.eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n            # Exploitation using local search\n            elif self.x_opt is not None and self.eval_count < self.budget:\n                f_local, x_local = self.local_search(func, self.x_opt)\n                self.eval_count += self.local_search_iterations # Approximating evaluations\n                if f_local < self.f_opt:\n                     self.f_opt = f_local\n                     self.x_opt = x_local\n            \n            # If no previous solution, start from random point.\n            elif self.x_opt is None and self.eval_count < self.budget:\n                x = np.random.uniform(self.lb, self.ub, size=self.dim)\n                f = func(x)\n                self.eval_count += 1\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n            # Adapt weights linearly\n            self.exploration_weight = max(0.1, self.exploration_weight - 0.0001)\n            self.exploitation_weight = min(0.9, self.exploitation_weight + 0.0001)\n\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.4321174920289781, "reward": 0.0, "generation": 2}, "task_prompt": ""}
{"id": "d2a91b2b-26af-4cf5-b791-495f72808b86", "fitness": 0.0, "name": "AdaptiveHybridDEPSOCMA", "description": "Integrates DE, PSO, CMA-ES with a self-adaptive local search probability and dynamic parameter adjustments based on stagnation and diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, initial_local_search_probability=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial sigma for CMA-ES\n        self.local_search_probability = initial_local_search_probability\n        self.initial_local_search_probability = initial_local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(self.population)\n            \n            # Adjust local search probability based on diversity\n            if diversity < self.diversity_threshold:\n                self.local_search_probability = min(1.0, self.local_search_probability + 0.01)  # Increase probability if diversity is low\n            else:\n                self.local_search_probability = max(0.01, self.local_search_probability - 0.005)  # Decrease probability if diversity is high\n            \n            # Adjust DE parameters based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold // 2:\n                self.F = min(1.0, self.F + 0.01)  # Increase F to explore more\n                self.CR = max(0.1, self.CR - 0.01)  # Decrease CR to exploit more\n            else:\n                self.F = max(0.1, self.F - 0.005)  # Decrease F to exploit more\n                self.CR = min(0.9, self.CR + 0.005)  # Increase CR to explore more\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Adaptive perturbation size based on CMA-ES sigma\n                perturbation_size = 0.01 * self.sigma\n                perturbation = np.random.uniform(-perturbation_size, perturbation_size, size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n                 self.local_search_probability = self.initial_local_search_probability\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: Range exceeds valid bounds", "parent_ids": ["32858e06-50ca-4e21-a177-63603e98973a"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE, PSO, CMA-ES with a self-adaptive local search probability and dynamic parameter adjustments based on stagnation and diversity.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, initial_local_search_probability=0.1, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial sigma for CMA-ES\n        self.local_search_probability = initial_local_search_probability\n        self.initial_local_search_probability = initial_local_search_probability\n        self.diversity_threshold = diversity_threshold\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Calculate population diversity\n            diversity = np.std(self.population)\n            \n            # Adjust local search probability based on diversity\n            if diversity < self.diversity_threshold:\n                self.local_search_probability = min(1.0, self.local_search_probability + 0.01)  # Increase probability if diversity is low\n            else:\n                self.local_search_probability = max(0.01, self.local_search_probability - 0.005)  # Decrease probability if diversity is high\n            \n            # Adjust DE parameters based on stagnation\n            if self.stagnation_counter > self.stagnation_threshold // 2:\n                self.F = min(1.0, self.F + 0.01)  # Increase F to explore more\n                self.CR = max(0.1, self.CR - 0.01)  # Decrease CR to exploit more\n            else:\n                self.F = max(0.1, self.F - 0.005)  # Decrease F to exploit more\n                self.CR = min(0.9, self.CR + 0.005)  # Increase CR to explore more\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Adaptive perturbation size based on CMA-ES sigma\n                perturbation_size = 0.01 * self.sigma\n                perturbation = np.random.uniform(-perturbation_size, perturbation_size, size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n                 self.local_search_probability = self.initial_local_search_probability\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.17171669231040368, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "7ede11e9-dec9-4651-8c4c-416d13f79c64", "fitness": 0.0, "name": "NAGAdaptiveSearch", "description": "An adaptive gradient-based search algorithm with dynamic step size and momentum inspired by Nesterov accelerated gradient descent.", "code": "import numpy as np\n\nclass NAGAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.lr = learning_rate\n        self.momentum = momentum\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        v = np.zeros(self.dim)  # Initialize velocity\n\n        for i in range(self.budget):\n            # Look-ahead point (Nesterov acceleration)\n            x_lookahead = x + self.momentum * v\n\n            # Clip lookahead point to boundaries\n            x_lookahead = np.clip(x_lookahead, func.bounds.lb, func.bounds.ub)\n\n            f_lookahead = func(x_lookahead)\n\n            if f_lookahead < self.f_opt:\n                self.f_opt = f_lookahead\n                self.x_opt = x_lookahead\n\n            # Approximate gradient using finite difference\n            gradient = np.zeros(self.dim)\n            delta = 1e-5  # Small perturbation for gradient estimation\n            for j in range(self.dim):\n                x_plus_delta = x_lookahead.copy()\n                x_plus_delta[j] += delta\n                x_plus_delta = np.clip(x_plus_delta, func.bounds.lb, func.bounds.ub)  # Clip after perturbation\n                f_plus_delta = func(x_plus_delta)\n\n                x_minus_delta = x_lookahead.copy()\n                x_minus_delta[j] -= delta\n                x_minus_delta = np.clip(x_minus_delta, func.bounds.lb, func.bounds.ub) # Clip after perturbation\n                f_minus_delta = func(x_minus_delta)\n                gradient[j] = (f_plus_delta - f_minus_delta) / (2 * delta)\n\n            # Update velocity with momentum\n            v = self.momentum * v - self.lr * gradient\n\n            # Update position\n            x = x + v\n\n            # Clip x to boundaries\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Dynamic learning rate adaptation (simple heuristic)\n            if i % 100 == 0:\n                self.lr *= 0.99  # Reduce learning rate slowly over time\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm NAGAdaptiveSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive gradient-based search algorithm with dynamic step size and momentum inspired by Nesterov accelerated gradient descent.\n\n# Code:\n```python\nimport numpy as np\n\nclass NAGAdaptiveSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, momentum=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.lr = learning_rate\n        self.momentum = momentum\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)\n        v = np.zeros(self.dim)  # Initialize velocity\n\n        for i in range(self.budget):\n            # Look-ahead point (Nesterov acceleration)\n            x_lookahead = x + self.momentum * v\n\n            # Clip lookahead point to boundaries\n            x_lookahead = np.clip(x_lookahead, func.bounds.lb, func.bounds.ub)\n\n            f_lookahead = func(x_lookahead)\n\n            if f_lookahead < self.f_opt:\n                self.f_opt = f_lookahead\n                self.x_opt = x_lookahead\n\n            # Approximate gradient using finite difference\n            gradient = np.zeros(self.dim)\n            delta = 1e-5  # Small perturbation for gradient estimation\n            for j in range(self.dim):\n                x_plus_delta = x_lookahead.copy()\n                x_plus_delta[j] += delta\n                x_plus_delta = np.clip(x_plus_delta, func.bounds.lb, func.bounds.ub)  # Clip after perturbation\n                f_plus_delta = func(x_plus_delta)\n\n                x_minus_delta = x_lookahead.copy()\n                x_minus_delta[j] -= delta\n                x_minus_delta = np.clip(x_minus_delta, func.bounds.lb, func.bounds.ub) # Clip after perturbation\n                f_minus_delta = func(x_minus_delta)\n                gradient[j] = (f_plus_delta - f_minus_delta) / (2 * delta)\n\n            # Update velocity with momentum\n            v = self.momentum * v - self.lr * gradient\n\n            # Update position\n            x = x + v\n\n            # Clip x to boundaries\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n\n            # Dynamic learning rate adaptation (simple heuristic)\n            if i % 100 == 0:\n                self.lr *= 0.99  # Reduce learning rate slowly over time\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.318402057298867, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "ce5a0052-90ba-47d0-8e5e-87b6a609d030", "fitness": 0.12902907327087063, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution (DE) for exploration, Particle Swarm Optimization (PSO) for exploitation, Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for adaptation, and a local search for refinement, incorporating a stagnation check for population diversity.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_sigma_init=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_init = cma_sigma_init\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_init * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                \n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.mean = np.mean(self.population, axis=0)\n\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSOCMA scored 0.129 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) for exploration, Particle Swarm Optimization (PSO) for exploitation, Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for adaptation, and a local search for refinement, incorporating a stagnation check for population diversity.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_sigma_init=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_init = cma_sigma_init\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_init * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                \n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.mean = np.mean(self.population, axis=0)\n\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1312785635488699, 0.25580865626374194, 0], "operator": "crossover", "theta_sampled": 0.19546730455538927, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "dfc0110c-2f79-434c-b1c0-a589f7328c12", "fitness": 0.1512403589841818, "name": "AdaptiveGaussianCMA", "description": "Adaptive Gaussian Mutation with Covariance Matrix Adaptation and shrinking search space to converge faster.", "code": "import numpy as np\n\nclass AdaptiveGaussianCMA:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, shrink_factor=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.shrink_factor = shrink_factor\n        self.C = np.eye(dim)  # Covariance matrix\n        self.mu = None\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mu = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize mean randomly\n\n        for i in range(self.budget):\n            # Sample a new solution from a multivariate Gaussian distribution\n            x = np.random.multivariate_normal(self.mu, self.sigma**2 * self.C)\n            \n            # Clip the solution to the bounds\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = func(x)\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n            \n            # Update the mean based on the current solution\n            self.mu = 0.9 * self.mu + 0.1 * x\n            \n            # Update the covariance matrix (simple update, can be improved)\n            diff = (x - self.mu).reshape(-1, 1)\n            self.C = 0.9 * self.C + 0.1 * (diff @ diff.T)\n            \n            # Shrink the search space and sigma\n            self.lb = max(self.lb, min(x) + 0.001)\n            self.ub = min(self.ub, max(x) - 0.001)\n            self.sigma *= self.shrink_factor\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveGaussianCMA scored 0.151 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Gaussian Mutation with Covariance Matrix Adaptation and shrinking search space to converge faster.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianCMA:\n    def __init__(self, budget=10000, dim=10, initial_sigma=0.5, shrink_factor=0.995):\n        self.budget = budget\n        self.dim = dim\n        self.initial_sigma = initial_sigma\n        self.sigma = initial_sigma\n        self.shrink_factor = shrink_factor\n        self.C = np.eye(dim)  # Covariance matrix\n        self.mu = None\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.mu = np.random.uniform(self.lb, self.ub, size=self.dim)  # Initialize mean randomly\n\n        for i in range(self.budget):\n            # Sample a new solution from a multivariate Gaussian distribution\n            x = np.random.multivariate_normal(self.mu, self.sigma**2 * self.C)\n            \n            # Clip the solution to the bounds\n            x = np.clip(x, self.lb, self.ub)\n            \n            f = func(x)\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n            \n            # Update the mean based on the current solution\n            self.mu = 0.9 * self.mu + 0.1 * x\n            \n            # Update the covariance matrix (simple update, can be improved)\n            diff = (x - self.mu).reshape(-1, 1)\n            self.C = 0.9 * self.C + 0.1 * (diff @ diff.T)\n            \n            # Shrink the search space and sigma\n            self.lb = max(self.lb, min(x) + 0.001)\n            self.ub = min(self.ub, max(x) - 0.001)\n            self.sigma *= self.shrink_factor\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0.05167864592162974, 0.08398450502756727, 0.21832517944944796, 0.14832447860818354, 0.08033162264687765, 0.14197423071782944, 0.1297709615324889, 0.12215344173814757, 0.13382223658038006, 0.120126047983518, 0.15648483720440454, 0.17467036297579652, 0.17478130032757688, 0.08454075209450307, 0.10710924872562022, 0.2351879759922848, 0.10864776716171021, 0.14590325916033398, 0.15136702373435107, 0.45562330210098445], "operator": "random_new", "theta_sampled": 0.2021458740007642, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "b907584c-875c-4965-a031-224beee20829", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Combines DE, PSO, and CMA-ES for efficient exploration and exploitation with adaptive parameter control and population diversity mechanisms.", "code": "import numpy as np\nimport cma\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.5, de_proportion=0.4, pso_proportion=0.3, cma_proportion=0.3, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma\n        self.de_proportion = de_proportion\n        self.pso_proportion = pso_proportion\n        self.cma_proportion = cma_proportion\n        self.archive_size = archive_size\n        self.archive = [] # Store potentially good solutions for CMA-ES initialization\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES initialization\n        self.es = cma.CMAEvolutionStrategy(self.global_best_position, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': int(self.cma_proportion * self.pop_size)}\n                                          )\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Linear decreasing inertia weight\n\n\n            # Split population for DE, PSO, and CMA-ES\n            de_count = int(self.de_proportion * self.pop_size)\n            pso_count = int(self.pso_proportion * self.pop_size)\n            cma_count = int(self.cma_proportion * self.pop_size)\n\n            # Differential Evolution\n            for i in range(de_count):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((u, f_u))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f_u < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (u, f_u)\n\n\n            # Particle Swarm Optimization\n            for i in range(de_count, de_count + pso_count):\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                f_i = func(self.population[i])\n                self.budget -= 1\n\n                if f_i < self.fitness[i]:\n                    self.fitness[i] = f_i\n                    if f_i < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_i\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_i < self.global_best_fitness:\n                        self.global_best_fitness = f_i\n                        self.global_best_position = self.population[i].copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((self.population[i], f_i))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f_i < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (self.population[i], f_i)\n\n            # CMA-ES\n            solutions = []\n            for i in range(cma_count):\n                x = self.es.ask(1)[0]\n                f = func(x)\n                self.budget -= 1\n                solutions.append((x,f))\n                \n                if len(self.archive) < self.archive_size:\n                    self.archive.append((x, f))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (x, f)\n                        \n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = x.copy()\n                    self.stagnation_counter = 0\n            \n            self.es.tell( [s[0] for s in solutions], [s[1] for s in solutions])\n            \n            \n            # Update population based on fitness (replace worst individuals)\n            sorted_indices = np.argsort(self.fitness)[::-1] # Sort in descending order (worst first)\n            for i in range(len(solutions)):\n                self.population[sorted_indices[i + de_count + pso_count]] = solutions[i][0]\n                self.fitness[sorted_indices[i + de_count + pso_count]] = solutions[i][1]\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Re-initialize population (or part of it)\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.es = cma.CMAEvolutionStrategy(self.global_best_position, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': int(self.cma_proportion * self.pop_size)}\n                                          )\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: No module named 'cma'", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines DE, PSO, and CMA-ES for efficient exploration and exploitation with adaptive parameter control and population diversity mechanisms.\n# Code: \n```python\nimport numpy as np\nimport cma\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.5, de_proportion=0.4, pso_proportion=0.3, cma_proportion=0.3, archive_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma\n        self.de_proportion = de_proportion\n        self.pso_proportion = pso_proportion\n        self.cma_proportion = cma_proportion\n        self.archive_size = archive_size\n        self.archive = [] # Store potentially good solutions for CMA-ES initialization\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES initialization\n        self.es = cma.CMAEvolutionStrategy(self.global_best_position, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': int(self.cma_proportion * self.pop_size)}\n                                          )\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Linear decreasing inertia weight\n\n\n            # Split population for DE, PSO, and CMA-ES\n            de_count = int(self.de_proportion * self.pop_size)\n            pso_count = int(self.pso_proportion * self.pop_size)\n            cma_count = int(self.cma_proportion * self.pop_size)\n\n            # Differential Evolution\n            for i in range(de_count):\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((u, f_u))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f_u < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (u, f_u)\n\n\n            # Particle Swarm Optimization\n            for i in range(de_count, de_count + pso_count):\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                f_i = func(self.population[i])\n                self.budget -= 1\n\n                if f_i < self.fitness[i]:\n                    self.fitness[i] = f_i\n                    if f_i < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_i\n                        self.personal_best_positions[i] = self.population[i].copy()\n\n                    if f_i < self.global_best_fitness:\n                        self.global_best_fitness = f_i\n                        self.global_best_position = self.population[i].copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((self.population[i], f_i))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f_i < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (self.population[i], f_i)\n\n            # CMA-ES\n            solutions = []\n            for i in range(cma_count):\n                x = self.es.ask(1)[0]\n                f = func(x)\n                self.budget -= 1\n                solutions.append((x,f))\n                \n                if len(self.archive) < self.archive_size:\n                    self.archive.append((x, f))\n                else:\n                    #Replace the worst element in archive\n                    worst_index = np.argmax([item[1] for item in self.archive])\n                    if f < self.archive[worst_index][1]:\n                        self.archive[worst_index] = (x, f)\n                        \n                if f < self.global_best_fitness:\n                    self.global_best_fitness = f\n                    self.global_best_position = x.copy()\n                    self.stagnation_counter = 0\n            \n            self.es.tell( [s[0] for s in solutions], [s[1] for s in solutions])\n            \n            \n            # Update population based on fitness (replace worst individuals)\n            sorted_indices = np.argsort(self.fitness)[::-1] # Sort in descending order (worst first)\n            for i in range(len(solutions)):\n                self.population[sorted_indices[i + de_count + pso_count]] = solutions[i][0]\n                self.fitness[sorted_indices[i + de_count + pso_count]] = solutions[i][1]\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Re-initialize population (or part of it)\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.es = cma.CMAEvolutionStrategy(self.global_best_position, self.cma_sigma,\n                                           {'bounds': [func.bounds.lb, func.bounds.ub], 'popsize': int(self.cma_proportion * self.pop_size)}\n                                          )\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.34946108330052866, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "633d33c1-ceff-4ba0-bec9-c38df2244ffa", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Integrates a diversity-enhancing mutation strategy, adaptive parameter control, and a more robust local search within a hybrid Differential Evolution, Particle Swarm Optimization, and CMA-ES framework.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500, perturb_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start # Initial inertia weight (PSO)\n        self.w_end = w_end # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.perturb_prob = perturb_prob # Probability of applying perturbation to DE\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget / self.pop_size + generation)) # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation with perturbation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                # Add a small perturbation to increase diversity\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)\n                    v = self.population[i] + self.F * (x2 - x3) + perturbation\n                else:\n                     v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # More intensive local search using CMA-ES sampling\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                local_trial = best_individual + sigma * z\n                local_trial = np.clip(local_trial, lb, ub)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "", "error": "Evaluation error: SVD did not converge", "parent_ids": ["4a955603-411b-47b8-86a5-4d38b2fdc532"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a diversity-enhancing mutation strategy, adaptive parameter control, and a more robust local search within a hybrid Differential Evolution, Particle Swarm Optimization, and CMA-ES framework.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500, perturb_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start # Initial inertia weight (PSO)\n        self.w_end = w_end # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.perturb_prob = perturb_prob # Probability of applying perturbation to DE\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget / self.pop_size + generation)) # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation with perturbation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                \n                # Add a small perturbation to increase diversity\n                if np.random.rand() < self.perturb_prob:\n                    perturbation = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb), size=self.dim)\n                    v = self.population[i] + self.F * (x2 - x3) + perturbation\n                else:\n                     v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # More intensive local search using CMA-ES sampling\n                z = np.random.multivariate_normal(np.zeros(self.dim), self.C)\n                local_trial = best_individual + sigma * z\n                local_trial = np.clip(local_trial, lb, ub)\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.24231672645799535, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "d3e72433-c46b-483b-809c-901dfd6a234c", "fitness": 0.2507769797462697, "name": "HybridDEPSOCMA", "description": "A hybrid algorithm combining Differential Evolution, PSO, CMA-ES adaptation, and local search with dynamic parameter adjustments and a restart mechanism.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_final=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma_init=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init  # Initial inertia weight (PSO)\n        self.w_final = w_final  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_init = cma_sigma_init\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_init * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive Inertia Weight (PSO)\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget + generation)) #linear decreasing\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.sigma = self.cma_sigma_init * (ub - lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n                 self.mean = np.mean(self.population, axis=0)\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSOCMA scored 0.251 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, PSO, CMA-ES adaptation, and local search with dynamic parameter adjustments and a restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_final=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma_init=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init  # Initial inertia weight (PSO)\n        self.w_final = w_final  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_init = cma_sigma_init\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_init * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive Inertia Weight (PSO)\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget + generation)) #linear decreasing\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.sigma = self.cma_sigma_init * (ub - lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n                 self.mean = np.mean(self.population, axis=0)\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2083502977344749, 0.30242714160258544, 0.49233047964801857, 0], "operator": "crossover", "theta_sampled": 0.14358387557271676, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "946a7f46-4548-4be7-8baa-ce240550259c", "fitness": 0.3553168057223925, "name": "HybridSaDEPSOCMA", "description": "Integrates a self-adaptive Differential Evolution (SaDE) mutation strategy with Particle Swarm Optimization (PSO) and Covariance Matrix Adaptation Evolution Strategy (CMA-ES), enhanced with a Cauchy mutation based local search and a population diversity maintenance mechanism.", "code": "import numpy as np\n\nclass HybridSaDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None,\n                 w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500,\n                 mutation_strategies = None, crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.crossover_rate = crossover_rate\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n        # SaDE parameters\n        if mutation_strategies is None:\n            self.mutation_strategies = [self.de_rand1_bin, self.de_currenttobest1_bin, self.de_rand2_bin]\n        else:\n            self.mutation_strategies = mutation_strategies\n\n        self.mutation_success = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.mutation_memory = np.zeros(len(self.mutation_strategies))\n        self.learning_rate = 0.1\n        self.p_crossover = 0.5\n\n    def de_rand1_bin(self, population, i, F, lb, ub):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = population[idxs]\n        v = population[i] + F * (x2 - x3)\n        return np.clip(v, lb, ub)\n\n    def de_currenttobest1_bin(self, population, i, F, lb, ub, global_best_position):\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x1, x2 = population[idxs]\n         v = population[i] + F * (global_best_position - population[i]) + F * (x1 - x2)\n         return np.clip(v, lb, ub)\n\n    def de_rand2_bin(self, population, i, F, lb, ub):\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x1, x2, x3, x4, x5 = population[idxs]\n        v = x1 + F * (x2 - x3) + F * (x4 - x5)\n        return np.clip(v, lb, ub)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Self-Adaptive DE Mutation\n                mutation_index = np.random.choice(len(self.mutation_strategies), p=self.mutation_success)\n                mutation_strategy = self.mutation_strategies[mutation_index]\n                \n                F = np.random.uniform(0.1, 0.9)\n\n                if mutation_strategy == self.de_currenttobest1_bin:\n                    v = mutation_strategy(self.population, i, F, lb, ub, self.global_best_position)\n                else:\n                    v = mutation_strategy(self.population, i, F, lb, ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.mutation_memory[mutation_index] = 1\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.mutation_memory[mutation_index] = 0\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # Update mutation strategy probabilities\n            self.mutation_success = (1 - self.learning_rate) * self.mutation_success + self.learning_rate * self.mutation_memory / np.sum(self.mutation_memory) if np.sum(self.mutation_memory) > 0 else np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n            self.mutation_memory = np.zeros(len(self.mutation_strategies))\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Cauchy mutation based local search\n                scale = 0.01 * (ub - lb)  # Scale parameter for Cauchy distribution\n                perturbation = scale * np.random.standard_cauchy(size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 3, "feedback": "The algorithm HybridSaDEPSOCMA scored 0.355 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["4a955603-411b-47b8-86a5-4d38b2fdc532"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive Differential Evolution (SaDE) mutation strategy with Particle Swarm Optimization (PSO) and Covariance Matrix Adaptation Evolution Strategy (CMA-ES), enhanced with a Cauchy mutation based local search and a population diversity maintenance mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass HybridSaDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None,\n                 w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None, initial_sigma=0.3,\n                 local_search_probability=0.1, stagnation_threshold=500,\n                 mutation_strategies = None, crossover_rate=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Adaptive pop size\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.initial_sigma = initial_sigma\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.crossover_rate = crossover_rate\n\n        # CMA-ES parameters (initialized in __call__ to use function bounds)\n        self.C = None  # Covariance matrix\n        self.pc = None  # Evolution path for C\n        self.ps = None  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu = self.pop_size // 2\n\n        # SaDE parameters\n        if mutation_strategies is None:\n            self.mutation_strategies = [self.de_rand1_bin, self.de_currenttobest1_bin, self.de_rand2_bin]\n        else:\n            self.mutation_strategies = mutation_strategies\n\n        self.mutation_success = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.mutation_memory = np.zeros(len(self.mutation_strategies))\n        self.learning_rate = 0.1\n        self.p_crossover = 0.5\n\n    def de_rand1_bin(self, population, i, F, lb, ub):\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = population[idxs]\n        v = population[i] + F * (x2 - x3)\n        return np.clip(v, lb, ub)\n\n    def de_currenttobest1_bin(self, population, i, F, lb, ub, global_best_position):\n         idxs = np.random.choice(self.pop_size, 2, replace=False)\n         x1, x2 = population[idxs]\n         v = population[i] + F * (global_best_position - population[i]) + F * (x1 - x2)\n         return np.clip(v, lb, ub)\n\n    def de_rand2_bin(self, population, i, F, lb, ub):\n        idxs = np.random.choice(self.pop_size, 5, replace=False)\n        x1, x2, x3, x4, x5 = population[idxs]\n        v = x1 + F * (x2 - x3) + F * (x4 - x5)\n        return np.clip(v, lb, ub)\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize global best\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants (adaptive)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Self-Adaptive DE Mutation\n                mutation_index = np.random.choice(len(self.mutation_strategies), p=self.mutation_success)\n                mutation_strategy = self.mutation_strategies[mutation_index]\n                \n                F = np.random.uniform(0.1, 0.9)\n\n                if mutation_strategy == self.de_currenttobest1_bin:\n                    v = mutation_strategy(self.population, i, F, lb, ub, self.global_best_position)\n                else:\n                    v = mutation_strategy(self.population, i, F, lb, ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.mutation_memory[mutation_index] = 1\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.mutation_memory[mutation_index] = 0\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # Update mutation strategy probabilities\n            self.mutation_success = (1 - self.learning_rate) * self.mutation_success + self.learning_rate * self.mutation_memory / np.sum(self.mutation_memory) if np.sum(self.mutation_memory) > 0 else np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n            self.mutation_memory = np.zeros(len(self.mutation_strategies))\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - mean) / sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Cauchy mutation based local search\n                scale = 0.01 * (ub - lb)  # Scale parameter for Cauchy distribution\n                perturbation = scale * np.random.standard_cauchy(size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n                 mean = np.mean(self.population, axis=0)\n                 sigma = self.initial_sigma * (ub - lb)  # overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n                 \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2133182431106896, 0.34869112727838203, 0.45513317518174934, 0.976779877454548, 0.2622174970299732, 0.4788726384104399, 0.28623264717167607, 0.47696573205453374, 0.22232183404797634, 0.18795209120634937, 0], "operator": "mutation", "theta_sampled": 0.49834750938465827, "reward": 0.0, "generation": 3}, "task_prompt": ""}
{"id": "204cf850-b1d7-44d4-a17c-80664b180509", "fitness": 0.4154643061290786, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES principles with adaptive parameter control and a restart strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, sigma_init_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.sigma_init_factor = sigma_init_factor\n        self.generation = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.sigma_init_factor * (ub - lb)  #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget + self.generation))  # Linearly decreasing inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.sigma_init_factor * (ub - lb)  #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSOCMA scored 0.415 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES principles with adaptive parameter control and a restart strategy for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, sigma_init_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.sigma_init_factor = sigma_init_factor\n        self.generation = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.sigma_init_factor * (ub - lb)  #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget + self.generation))  # Linearly decreasing inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.sigma_init_factor * (ub - lb)  #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim)  # Evolution path for C\n                 self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23651675529320015, 0.6162480731698079, 0.8090923960533063, 0], "operator": "crossover", "theta_sampled": 0.20998643839712652, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "a47ca03b-476b-452b-9767-e7a5fd655f16", "fitness": 0.28704727235026584, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and local search with dynamic parameter adjustment and a restart mechanism for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_es_active=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end    # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_es_active = cma_es_active # Flag to turn on or off CMA-ES adaptation.\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget+generation))\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            if self.cma_es_active:\n                # Sort by fitness\n                idx_sorted = np.argsort(self.fitness)\n                self.population = self.population[idx_sorted]\n                self.fitness = self.fitness[idx_sorted]\n\n                # Selection and update mean\n                x_mu = self.population[:self.mu]\n                mean_new = np.mean(x_mu, axis=0)\n\n                # Update evolution paths\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (\n                    np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n                self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n                # Update covariance matrix\n                self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n                for j in range(self.mu):\n                    self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n                # Adjust step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n                self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDEPSOCMA scored 0.287 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and local search with dynamic parameter adjustment and a restart mechanism for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_es_active=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end    # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_es_active = cma_es_active # Flag to turn on or off CMA-ES adaptation.\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget+generation))\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            if self.cma_es_active:\n                # Sort by fitness\n                idx_sorted = np.argsort(self.fitness)\n                self.population = self.population[idx_sorted]\n                self.fitness = self.fitness[idx_sorted]\n\n                # Selection and update mean\n                x_mu = self.population[:self.mu]\n                mean_new = np.mean(x_mu, axis=0)\n\n                # Update evolution paths\n                self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (\n                    np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n                self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n                # Update covariance matrix\n                self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n                for j in range(self.mu):\n                    self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n                # Adjust step size\n                self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n                self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.22216010900166705, 0.21438275130511242, 0.711646229094284, 0], "operator": "crossover", "theta_sampled": 0.19127516982866052, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "6fc0f758-5144-4981-8bd6-ba379552fc37", "fitness": 0.0, "name": "VoronoiOptimization", "description": "Population-based algorithm using Voronoi tessellations to define neighborhood structures and guide search direction.", "code": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\nclass VoronoiOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def voronoi_guided_search(self, func):\n        if self.dim > 1:\n           vor = Voronoi(self.population)\n        \n        for i in range(self.pop_size):\n            if self.dim > 1:\n              region = vor.regions[vor.point_region[i]]\n              if not -1 in region and len(region) > 0:\n                 vertices = vor.vertices[region]\n                 center = np.mean(vertices, axis=0)\n\n                 # Project back to feasible space\n                 center = np.clip(center, func.bounds.lb, func.bounds.ub)\n\n                 # Exploration/Exploitation: Move towards Voronoi center or random\n                 if np.random.rand() < 0.7: # Probability of moving towards center\n                     x_new = self.population[i] + 0.1 * (center - self.population[i]) \n                 else:\n                     x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n\n              else:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub) # Region is infinite\n            else:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub) #If dim is one, just do random sample\n\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) \n            f_new = func(x_new)\n\n            # Update individual if better\n            if f_new < self.fitness[i]:\n                self.fitness[i] = f_new\n                self.population[i] = x_new\n\n            # Update global best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            self.voronoi_guided_search(func)\n            eval_count += self.pop_size # each voronoi search call does pop_size evaluations.\n\n            #Early stopping condition if budget is exceeded\n            if eval_count > self.budget:\n                eval_count = self.budget\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'Voronoi' is not defined", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using Voronoi tessellations to define neighborhood structures and guide search direction.\n# Code: \n```python\nimport numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\nclass VoronoiOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.population = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def voronoi_guided_search(self, func):\n        if self.dim > 1:\n           vor = Voronoi(self.population)\n        \n        for i in range(self.pop_size):\n            if self.dim > 1:\n              region = vor.regions[vor.point_region[i]]\n              if not -1 in region and len(region) > 0:\n                 vertices = vor.vertices[region]\n                 center = np.mean(vertices, axis=0)\n\n                 # Project back to feasible space\n                 center = np.clip(center, func.bounds.lb, func.bounds.ub)\n\n                 # Exploration/Exploitation: Move towards Voronoi center or random\n                 if np.random.rand() < 0.7: # Probability of moving towards center\n                     x_new = self.population[i] + 0.1 * (center - self.population[i]) \n                 else:\n                     x_new = np.random.uniform(func.bounds.lb, func.bounds.ub)\n\n              else:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub) # Region is infinite\n            else:\n                x_new = np.random.uniform(func.bounds.lb, func.bounds.ub) #If dim is one, just do random sample\n\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) \n            f_new = func(x_new)\n\n            # Update individual if better\n            if f_new < self.fitness[i]:\n                self.fitness[i] = f_new\n                self.population[i] = x_new\n\n            # Update global best\n            if f_new < self.f_opt:\n                self.f_opt = f_new\n                self.x_opt = x_new\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        eval_count = self.pop_size  # Account for initial population evaluation\n\n        while eval_count < self.budget:\n            self.voronoi_guided_search(func)\n            eval_count += self.pop_size # each voronoi search call does pop_size evaluations.\n\n            #Early stopping condition if budget is exceeded\n            if eval_count > self.budget:\n                eval_count = self.budget\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.15398237376413107, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "6c6870a0-8bb4-4310-909d-fe2ca4ddc7b8", "fitness": 0.0, "name": "HybridDECMASEnhanced", "description": "Integrates Differential Evolution, CMA-ES, and a gradient-based local search, employing adaptive parameter control and a restart mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_lr=0.1, de_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.cma_lr = cma_lr # Learning rate for CMA-ES mean update\n        self.de_lr = de_lr # Learning rate for DE individual update\n\n        self.restart_criterion = 1e-12 # Restart if variance is below this threshold\n        self.stagnation_counter = 0\n        self.max_stagnation = 5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = (1-self.de_lr)*population[i] + self.de_lr*trial  # Weighted update\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n            \n            mean = (1-self.cma_lr)*mean + self.cma_lr*mean_new # Weighted Mean Update\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Gradient-based local search using scipy.optimize.minimize\n                def local_objective(x):\n                    return func(x)  # Define the objective function\n\n                bounds = [(lb, ub) for _ in range(self.dim)]\n                result = minimize(local_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limit iterations for budget reasons\n                local_trial = result.x\n                local_f = result.fun\n\n                num_evals = result.nfev\n                self.budget -= num_evals\n                \n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Adaptive Parameter Control (example: adjusting mutation factor)\n            if generation % 10 == 0:\n              self.mutation_factor = 0.4 + 0.2*np.random.rand()  # Exploration-exploitation balance\n\n            # Restart mechanism\n            if np.var(fitness) < self.restart_criterion:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation:\n                # Reset population and CMA-ES parameters\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                mean = np.mean(population, axis=0)\n                sigma = 0.3 * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates Differential Evolution, CMA-ES, and a gradient-based local search, employing adaptive parameter control and a restart mechanism for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASEnhanced:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_lr=0.1, de_lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.cma_lr = cma_lr # Learning rate for CMA-ES mean update\n        self.de_lr = de_lr # Learning rate for DE individual update\n\n        self.restart_criterion = 1e-12 # Restart if variance is below this threshold\n        self.stagnation_counter = 0\n        self.max_stagnation = 5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = (1-self.de_lr)*population[i] + self.de_lr*trial  # Weighted update\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n            \n            mean = (1-self.cma_lr)*mean + self.cma_lr*mean_new # Weighted Mean Update\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Gradient-based local search using scipy.optimize.minimize\n                def local_objective(x):\n                    return func(x)  # Define the objective function\n\n                bounds = [(lb, ub) for _ in range(self.dim)]\n                result = minimize(local_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limit iterations for budget reasons\n                local_trial = result.x\n                local_f = result.fun\n\n                num_evals = result.nfev\n                self.budget -= num_evals\n                \n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Adaptive Parameter Control (example: adjusting mutation factor)\n            if generation % 10 == 0:\n              self.mutation_factor = 0.4 + 0.2*np.random.rand()  # Exploration-exploitation balance\n\n            # Restart mechanism\n            if np.var(fitness) < self.restart_criterion:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            if self.stagnation_counter > self.max_stagnation:\n                # Reset population and CMA-ES parameters\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n\n                mean = np.mean(population, axis=0)\n                sigma = 0.3 * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.25098134495255814, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "6d235113-5e5c-44a2-a310-1762be3b2e67", "fitness": 0.0, "name": "GaussianCauchyTournament", "description": "A population-based algorithm employing a combination of Gaussian mutation and Cauchy flight for exploration, and a tournament selection inspired crossover for exploitation.", "code": "import numpy as np\n\nclass GaussianCauchyTournament:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size # Keep track of function evaluations\n\n        while eval_count < self.budget:\n            # Selection (Tournament Selection)\n            parents_idx = np.random.choice(self.pop_size, size=(self.pop_size, 2), replace=True)\n            selected_indices = np.array([i if fitness[i] < fitness[j] else j for i, j in parents_idx])\n            parents = population[selected_indices]\n\n            # Crossover (Inspired by differential evolution, but using selected parents)\n            offspring = np.zeros_like(parents)\n            for i in range(self.pop_size):\n                j = np.random.randint(self.dim) # Random index to ensure at least one element is exchanged\n                for k in range(self.dim):\n                    if np.random.rand() < 0.5 or k == j:\n                        offspring[i, k] = parents[i, k] # Use elements from first parent\n                    else:\n                        offspring[i, k] = population[np.random.randint(self.pop_size),k] # Use elements from a random element of the population.\n\n            # Mutation (Gaussian and Cauchy combined)\n            for i in range(self.pop_size):\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        if np.random.rand() < 0.5:\n                            offspring[i, j] += np.random.normal(0, 1) * (func.bounds.ub - func.bounds.lb) * 0.01 # Gaussian Mutation\n                        else:\n                            offspring[i, j] += np.random.standard_cauchy() * self.cauchy_scale * (func.bounds.ub - func.bounds.lb) # Cauchy Flight\n                        \n                        # Clip to bounds\n                        offspring[i, j] = np.clip(offspring[i, j], func.bounds.lb[j], func.bounds.ub[j])\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            eval_count += self.pop_size\n\n            # Replacement (Replace worst individuals)\n            worst_idx = np.argsort(fitness)[-self.pop_size:]\n            for i in range(self.pop_size):\n                 if offspring_fitness[i] < fitness[worst_idx[i]]:\n                      fitness[worst_idx[i]] = offspring_fitness[i]\n                      population[worst_idx[i]] = offspring[i]\n\n            # Update best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "", "error": "Evaluation error: setting an array element with a sequence.", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm employing a combination of Gaussian mutation and Cauchy flight for exploration, and a tournament selection inspired crossover for exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass GaussianCauchyTournament:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, cauchy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.cauchy_scale = cauchy_scale\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size # Keep track of function evaluations\n\n        while eval_count < self.budget:\n            # Selection (Tournament Selection)\n            parents_idx = np.random.choice(self.pop_size, size=(self.pop_size, 2), replace=True)\n            selected_indices = np.array([i if fitness[i] < fitness[j] else j for i, j in parents_idx])\n            parents = population[selected_indices]\n\n            # Crossover (Inspired by differential evolution, but using selected parents)\n            offspring = np.zeros_like(parents)\n            for i in range(self.pop_size):\n                j = np.random.randint(self.dim) # Random index to ensure at least one element is exchanged\n                for k in range(self.dim):\n                    if np.random.rand() < 0.5 or k == j:\n                        offspring[i, k] = parents[i, k] # Use elements from first parent\n                    else:\n                        offspring[i, k] = population[np.random.randint(self.pop_size),k] # Use elements from a random element of the population.\n\n            # Mutation (Gaussian and Cauchy combined)\n            for i in range(self.pop_size):\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        if np.random.rand() < 0.5:\n                            offspring[i, j] += np.random.normal(0, 1) * (func.bounds.ub - func.bounds.lb) * 0.01 # Gaussian Mutation\n                        else:\n                            offspring[i, j] += np.random.standard_cauchy() * self.cauchy_scale * (func.bounds.ub - func.bounds.lb) # Cauchy Flight\n                        \n                        # Clip to bounds\n                        offspring[i, j] = np.clip(offspring[i, j], func.bounds.lb[j], func.bounds.ub[j])\n\n            # Evaluation\n            offspring_fitness = np.array([func(x) for x in offspring])\n            eval_count += self.pop_size\n\n            # Replacement (Replace worst individuals)\n            worst_idx = np.argsort(fitness)[-self.pop_size:]\n            for i in range(self.pop_size):\n                 if offspring_fitness[i] < fitness[worst_idx[i]]:\n                      fitness[worst_idx[i]] = offspring_fitness[i]\n                      population[worst_idx[i]] = offspring[i]\n\n            # Update best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < self.f_opt:\n                self.f_opt = fitness[best_idx]\n                self.x_opt = population[best_idx]\n            \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.3383938586038025, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "f01e402e-4a1b-42dd-87f9-4a42eadf8b71", "fitness": 0.2837204709074148, "name": "LandscapeAwareOptimizer", "description": "Population-based algorithm with dynamic local search based on fitness landscape analysis and gradient estimation.", "code": "import numpy as np\n\nclass LandscapeAwareOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_radius = local_search_radius\n        self.population = None\n        self.fitness = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n\n    def local_search(self, func, x, radius):\n        best_x = x\n        best_f = func(x)\n        self.func_evals += 1\n\n        for _ in range(5 * self.dim): # Number of samples proportional to dimensionality\n            dx = np.random.uniform(-radius, radius, size=self.dim)\n            new_x = x + dx\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            new_f = func(new_x)\n            self.func_evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n\n        return best_f, best_x\n\n    def gradient_estimation(self, func, x, h=0.01):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += h\n            x_minus[i] -= h\n\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n\n            self.func_evals += 2\n            grad[i] = (f_plus - f_minus) / (2 * h)\n            if self.func_evals >= self.budget:\n                return grad\n\n        return grad\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n        self.initialize_population(func)\n        \n        if self.func_evals >= self.budget:\n           self.f_opt = np.min(self.fitness)\n           self.x_opt = self.population[np.argmin(self.fitness)]\n           return self.f_opt, self.x_opt\n\n        while self.func_evals < self.budget:\n            # Selection: Select the best individuals for reproduction and local search.\n            best_indices = np.argsort(self.fitness)[:self.pop_size // 5] # Select top 20%\n            \n            # Reproduction (Simplified): Create new individuals by perturbing the best ones.\n            for i in range(self.pop_size):\n              if i not in best_indices: # Replace the worst individuals\n                  idx = np.random.choice(best_indices)\n                  self.population[i] = self.population[idx] + np.random.normal(0, 0.05, self.dim) # Perturb\n                  self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n                  self.fitness[i] = func(self.population[i])\n                  self.func_evals += 1\n                  if self.func_evals >= self.budget:\n                     break\n            \n            if self.func_evals >= self.budget:\n               break\n\n\n            # Local Search and Gradient Descent: Apply local search to the best individuals.\n            for idx in best_indices:\n                if self.func_evals >= self.budget:\n                   break\n\n                # Adaptive radius for local search based on fitness\n                radius = self.local_search_radius * (1 + np.exp(-self.fitness[idx]))\n\n                best_f, best_x = self.local_search(func, self.population[idx], radius)\n\n                if best_f < self.fitness[idx]:\n                    self.fitness[idx] = best_f\n                    self.population[idx] = best_x\n            \n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm LandscapeAwareOptimizer scored 0.284 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with dynamic local search based on fitness landscape analysis and gradient estimation.\n# Code: \n```python\nimport numpy as np\n\nclass LandscapeAwareOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, local_search_radius=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_radius = local_search_radius\n        self.population = None\n        self.fitness = None\n        self.func_evals = 0\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.func_evals += self.pop_size\n\n    def local_search(self, func, x, radius):\n        best_x = x\n        best_f = func(x)\n        self.func_evals += 1\n\n        for _ in range(5 * self.dim): # Number of samples proportional to dimensionality\n            dx = np.random.uniform(-radius, radius, size=self.dim)\n            new_x = x + dx\n            new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Keep within bounds\n\n            new_f = func(new_x)\n            self.func_evals += 1\n\n            if new_f < best_f:\n                best_f = new_f\n                best_x = new_x\n\n            if self.func_evals >= self.budget:\n                return best_f, best_x\n\n        return best_f, best_x\n\n    def gradient_estimation(self, func, x, h=0.01):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            x_plus = x.copy()\n            x_minus = x.copy()\n            x_plus[i] += h\n            x_minus[i] -= h\n\n            x_plus = np.clip(x_plus, func.bounds.lb, func.bounds.ub)\n            x_minus = np.clip(x_minus, func.bounds.lb, func.bounds.ub)\n\n            f_plus = func(x_plus)\n            f_minus = func(x_minus)\n\n            self.func_evals += 2\n            grad[i] = (f_plus - f_minus) / (2 * h)\n            if self.func_evals >= self.budget:\n                return grad\n\n        return grad\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.func_evals = 0\n\n        self.initialize_population(func)\n        \n        if self.func_evals >= self.budget:\n           self.f_opt = np.min(self.fitness)\n           self.x_opt = self.population[np.argmin(self.fitness)]\n           return self.f_opt, self.x_opt\n\n        while self.func_evals < self.budget:\n            # Selection: Select the best individuals for reproduction and local search.\n            best_indices = np.argsort(self.fitness)[:self.pop_size // 5] # Select top 20%\n            \n            # Reproduction (Simplified): Create new individuals by perturbing the best ones.\n            for i in range(self.pop_size):\n              if i not in best_indices: # Replace the worst individuals\n                  idx = np.random.choice(best_indices)\n                  self.population[i] = self.population[idx] + np.random.normal(0, 0.05, self.dim) # Perturb\n                  self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n                  self.fitness[i] = func(self.population[i])\n                  self.func_evals += 1\n                  if self.func_evals >= self.budget:\n                     break\n            \n            if self.func_evals >= self.budget:\n               break\n\n\n            # Local Search and Gradient Descent: Apply local search to the best individuals.\n            for idx in best_indices:\n                if self.func_evals >= self.budget:\n                   break\n\n                # Adaptive radius for local search based on fitness\n                radius = self.local_search_radius * (1 + np.exp(-self.fitness[idx]))\n\n                best_f, best_x = self.local_search(func, self.population[idx], radius)\n\n                if best_f < self.fitness[idx]:\n                    self.fitness[idx] = best_f\n                    self.population[idx] = best_x\n            \n\n        self.f_opt = np.min(self.fitness)\n        self.x_opt = self.population[np.argmin(self.fitness)]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1413153685580668, 0.1939418119706635, 0.3691143443245304, 0.1728790727161279, 0.19230696460073082, 0.19004656297576283, 0.20916068708275382, 0.2037584955066315, 0.2229393229501947, 0.15978932305995985, 0.18349901679729574, 0.9991692262355686, 0.2440748215932358, 0.17691204518255654, 0.3887331409406658, 0.42294953091957477, 0.2259776613713077, 0.38385371270013735, 0.17074427645776213, 0.4232440322047689], "operator": "random_new", "theta_sampled": 0.09497882666135707, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "3d119641-ae6b-4523-8501-7e6b68bba6fb", "fitness": 0.0, "name": "HybridDECMAPSO", "description": "Combines Differential Evolution with CMA-ES and PSO-inspired velocity updates, enhanced with adaptive parameter control and stagnation handling, for robust global optimization.", "code": "import numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, c_sigma_factor=1.0, c_c_factor=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = self.c_sigma_factor * (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = self.c_c_factor * (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                # Reset CMA-ES parameters after restart to avoid premature convergence.\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = 0.3 * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDECMAPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution with CMA-ES and PSO-inspired velocity updates, enhanced with adaptive parameter control and stagnation handling, for robust global optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, c_sigma_factor=1.0, c_c_factor=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = self.c_sigma_factor * (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = self.c_c_factor * (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                # Reset CMA-ES parameters after restart to avoid premature convergence.\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = 0.3 * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": -0.01371617001369356, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "7f2d5c99-c92b-4e5b-9faa-2ac757cdb46d", "fitness": 0.0, "name": "GradientEnhancedPopulationSearch", "description": "Population-based search with gradient-based refinement and adaptive exploration rates.", "code": "import numpy as np\n\nclass GradientEnhancedPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for gradient descent\n        self.exploration_rate = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Find best individual in the population\n            best_index = np.argmin(self.fitness)\n            best_x = self.population[best_index]\n            best_f = self.fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Generate new population members\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random sampling\n                    new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # Exploitation: Gradient-based refinement around best solution\n                    gradient = self._approximate_gradient(func, best_x)\n                    new_x = best_x - self.lr * gradient\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                    new_population[i] = new_x\n\n            # Evaluate fitness of new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update population: Elitism and replacement\n            combined_population = np.concatenate((self.population, new_population), axis=0)\n            combined_fitness = np.concatenate((self.fitness, new_fitness))\n\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Adaptive exploration rate\n            self.exploration_rate = 0.95 * self.exploration_rate if self.f_opt == best_f else min(0.95 * self.exploration_rate + 0.05,1.0)\n\n\n        return self.f_opt, self.x_opt\n\n    def _approximate_gradient(self, func, x, delta=1e-5):\n        \"\"\"Approximates the gradient using finite differences.\"\"\"\n        gradient = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus_delta = x.copy()\n            x_minus_delta = x.copy()\n            x_plus_delta[i] += delta\n            x_minus_delta[i] -= delta\n            gradient[i] = (func(x_plus_delta) - func(x_minus_delta)) / (2 * delta)\n        return gradient", "configspace": "", "generation": 4, "feedback": "The algorithm GradientEnhancedPopulationSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based search with gradient-based refinement and adaptive exploration rates.\n# Code:\n```python\nimport numpy as np\n\nclass GradientEnhancedPopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for gradient descent\n        self.exploration_rate = 0.5\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        while self.budget > 0:\n            # Find best individual in the population\n            best_index = np.argmin(self.fitness)\n            best_x = self.population[best_index]\n            best_f = self.fitness[best_index]\n\n            if best_f < self.f_opt:\n                self.f_opt = best_f\n                self.x_opt = best_x\n\n            # Generate new population members\n            new_population = np.zeros_like(self.population)\n            for i in range(self.pop_size):\n                if np.random.rand() < self.exploration_rate:\n                    # Exploration: Random sampling\n                    new_population[i] = np.random.uniform(func.bounds.lb, func.bounds.ub)\n                else:\n                    # Exploitation: Gradient-based refinement around best solution\n                    gradient = self._approximate_gradient(func, best_x)\n                    new_x = best_x - self.lr * gradient\n                    new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                    new_population[i] = new_x\n\n            # Evaluate fitness of new population\n            new_fitness = np.array([func(x) for x in new_population])\n            self.budget -= self.pop_size\n\n            # Update population: Elitism and replacement\n            combined_population = np.concatenate((self.population, new_population), axis=0)\n            combined_fitness = np.concatenate((self.fitness, new_fitness))\n\n            sorted_indices = np.argsort(combined_fitness)\n            self.population = combined_population[sorted_indices[:self.pop_size]]\n            self.fitness = combined_fitness[sorted_indices[:self.pop_size]]\n\n            # Adaptive exploration rate\n            self.exploration_rate = 0.95 * self.exploration_rate if self.f_opt == best_f else min(0.95 * self.exploration_rate + 0.05,1.0)\n\n\n        return self.f_opt, self.x_opt\n\n    def _approximate_gradient(self, func, x, delta=1e-5):\n        \"\"\"Approximates the gradient using finite differences.\"\"\"\n        gradient = np.zeros_like(x)\n        for i in range(self.dim):\n            x_plus_delta = x.copy()\n            x_minus_delta = x.copy()\n            x_plus_delta[i] += delta\n            x_minus_delta[i] -= delta\n            gradient[i] = (func(x_plus_delta) - func(x_minus_delta)) / (2 * delta)\n        return gradient\n```", "aucs": [0], "operator": "random_new", "theta_sampled": -0.04789569201173176, "reward": 0.0, "generation": 4}, "task_prompt": ""}
{"id": "7e7d2fae-6c90-4d69-88e6-6ab7c2a9f274", "fitness": 0.2550646735295414, "name": "AdaptiveHybridDEPSONiche", "description": "Combines Differential Evolution (DE) with Particle Swarm Optimization (PSO), adaptive parameter control, and a niching strategy to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSONiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, CR_initial=0.9, w_initial=0.7, c1_initial=1.5, c2_initial=1.5, stagnation_threshold=500, niche_radius=0.5, F_adapt=0.1, CR_adapt=0.1, w_adapt=0.1, c1_adapt=0.1, c2_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Differential evolution parameter\n        self.CR = CR_initial  # Crossover rate\n        self.w = w_initial  # Inertia weight (PSO)\n        self.c1 = c1_initial  # Cognitive coefficient (PSO)\n        self.c2 = c2_initial  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.niche_radius = niche_radius\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.w_adapt = w_adapt\n        self.c1_adapt = c1_adapt\n        self.c2_adapt = c2_adapt\n\n        self.archive_size = pop_size  # Size of the archive for storing successful solutions\n        self.archive = []\n        self.archive_fitness = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                    # Archive successful solutions\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(u.copy())\n                        self.archive_fitness.append(f_u)\n                    else:\n                        # Replace worst solution in archive if new solution is better\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = u.copy()\n                            self.archive_fitness[max_archive_index] = f_u\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n                # Niche Enforcement (Crowding Distance)\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(self.population[i] - self.population[j]) < self.niche_radius:\n                        # Move individuals away from each other\n                        direction = self.population[i] - self.population[j]\n                        self.population[i] = np.clip(self.population[i] + 0.1 * direction, func.bounds.lb, func.bounds.ub)\n                        self.population[j] = np.clip(self.population[j] - 0.1 * direction, func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Parameter Control\n            self.F = np.clip(self.F + self.F_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.CR_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.w = np.clip(self.w + self.w_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.c1 = np.clip(self.c1 + self.c1_adapt * np.random.normal(0, 1), 0.1, 3.0)\n            self.c2 = np.clip(self.c2 + self.c2_adapt * np.random.normal(0, 1), 0.1, 3.0)\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridDEPSONiche scored 0.255 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Particle Swarm Optimization (PSO), adaptive parameter control, and a niching strategy to enhance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSONiche:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_initial=0.5, CR_initial=0.9, w_initial=0.7, c1_initial=1.5, c2_initial=1.5, stagnation_threshold=500, niche_radius=0.5, F_adapt=0.1, CR_adapt=0.1, w_adapt=0.1, c1_adapt=0.1, c2_adapt=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_initial  # Differential evolution parameter\n        self.CR = CR_initial  # Crossover rate\n        self.w = w_initial  # Inertia weight (PSO)\n        self.c1 = c1_initial  # Cognitive coefficient (PSO)\n        self.c2 = c2_initial  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.niche_radius = niche_radius\n        self.F_adapt = F_adapt\n        self.CR_adapt = CR_adapt\n        self.w_adapt = w_adapt\n        self.c1_adapt = c1_adapt\n        self.c2_adapt = c2_adapt\n\n        self.archive_size = pop_size  # Size of the archive for storing successful solutions\n        self.archive = []\n        self.archive_fitness = []\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                    # Archive successful solutions\n                    if len(self.archive) < self.archive_size:\n                        self.archive.append(u.copy())\n                        self.archive_fitness.append(f_u)\n                    else:\n                        # Replace worst solution in archive if new solution is better\n                        max_archive_index = np.argmax(self.archive_fitness)\n                        if f_u < self.archive_fitness[max_archive_index]:\n                            self.archive[max_archive_index] = u.copy()\n                            self.archive_fitness[max_archive_index] = f_u\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n                # Niche Enforcement (Crowding Distance)\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(self.population[i] - self.population[j]) < self.niche_radius:\n                        # Move individuals away from each other\n                        direction = self.population[i] - self.population[j]\n                        self.population[i] = np.clip(self.population[i] + 0.1 * direction, func.bounds.lb, func.bounds.ub)\n                        self.population[j] = np.clip(self.population[j] - 0.1 * direction, func.bounds.lb, func.bounds.ub)\n\n            # Adaptive Parameter Control\n            self.F = np.clip(self.F + self.F_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.CR_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.w = np.clip(self.w + self.w_adapt * np.random.normal(0, 1), 0.1, 1.0)\n            self.c1 = np.clip(self.c1 + self.c1_adapt * np.random.normal(0, 1), 0.1, 3.0)\n            self.c2 = np.clip(self.c2 + self.c2_adapt * np.random.normal(0, 1), 0.1, 3.0)\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.18500047029245137, 0.24021074057036407, 0.36898278293923736, 0.4289787811032447, 0.3072152662719507, 0], "operator": "mutation", "theta_sampled": -0.1042407212896641, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2e4f8cfe-3390-43c5-b71a-572dcd1c242f", "fitness": 0.0, "name": "AdaptiveHybridDECMAS", "description": "Combines Differential Evolution, CMA-ES, and a gradient-based local search with adaptive parameter control for robust optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, gradient_local_search=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.gradient_local_search = gradient_local_search # Flag to use gradient based local search\n        self.adaptive_mutation = True # Adaptive mutation factor\n        self.adaptive_crossover = True # Adaptive Crossover rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive parameter control\n            if self.adaptive_mutation:\n                 self.mutation_factor = 0.5 + 0.3 * np.sin(2 * np.pi * generation / 100) # Oscillating mutation\n            if self.adaptive_crossover:\n                 self.crossover_rate = 0.7 + 0.2 * np.cos(2 * np.pi * generation / 100) # Oscillating crossover\n           \n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                if self.gradient_local_search:\n                    # Gradient-based local search\n                    def local_objective(x):\n                        f = func(x)\n                        self.budget -= 1\n                        return f\n\n                    bounds = [(lb, ub) for _ in range(self.dim)]\n                    res = minimize(local_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limited iterations to save budget\n                    local_f = res.fun\n                    local_trial = res.x\n\n                    if self.budget <= 0:\n                        break\n                    \n                    if local_f < fitness[best_idx]:\n                        fitness[best_idx] = local_f\n                        population[best_idx] = local_trial\n                        \n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_trial\n\n                else:\n\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = best_individual + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if local_f < fitness[best_idx]:\n                        fitness[best_idx] = local_f\n                        population[best_idx] = local_trial\n                        \n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution, CMA-ES, and a gradient-based local search with adaptive parameter control for robust optimization.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, gradient_local_search=True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.gradient_local_search = gradient_local_search # Flag to use gradient based local search\n        self.adaptive_mutation = True # Adaptive mutation factor\n        self.adaptive_crossover = True # Adaptive Crossover rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive parameter control\n            if self.adaptive_mutation:\n                 self.mutation_factor = 0.5 + 0.3 * np.sin(2 * np.pi * generation / 100) # Oscillating mutation\n            if self.adaptive_crossover:\n                 self.crossover_rate = 0.7 + 0.2 * np.cos(2 * np.pi * generation / 100) # Oscillating crossover\n           \n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                if self.gradient_local_search:\n                    # Gradient-based local search\n                    def local_objective(x):\n                        f = func(x)\n                        self.budget -= 1\n                        return f\n\n                    bounds = [(lb, ub) for _ in range(self.dim)]\n                    res = minimize(local_objective, best_individual, method='L-BFGS-B', bounds=bounds, options={'maxiter': 5})  # Limited iterations to save budget\n                    local_f = res.fun\n                    local_trial = res.x\n\n                    if self.budget <= 0:\n                        break\n                    \n                    if local_f < fitness[best_idx]:\n                        fitness[best_idx] = local_f\n                        population[best_idx] = local_trial\n                        \n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_trial\n\n                else:\n\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = best_individual + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if local_f < fitness[best_idx]:\n                        fitness[best_idx] = local_f\n                        population[best_idx] = local_trial\n                        \n                        if local_f < self.f_opt:\n                            self.f_opt = local_f\n                            self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.2743362505427666, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "7a173663-c594-4c8a-a991-c0f271456d84", "fitness": 0.0, "name": "AdaptiveDifferentialEvolutionLocalSearch", "description": "Population-based algorithm employing a differential evolution-inspired mutation operator with adaptive scaling and a local search refinement step.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r1 - x_r2) #removed x_r3, as it was not used\n                \n                # Clipping\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                    \n            #Local Search: Applying on the best solution\n            for _ in range(self.local_search_iterations):\n                #Generate random perturbation\n                perturbation = np.random.normal(0, 0.01, self.dim) # Small perturbation\n                x_local_search = self.x_opt + perturbation\n                x_local_search = np.clip(x_local_search, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                f_local_search = func(x_local_search)\n                eval_count += 1\n                \n                if f_local_search < self.f_opt:\n                    self.f_opt = f_local_search\n                    self.x_opt = x_local_search\n\n                if eval_count >= self.budget:\n                    break #Important: budget check inside the inner loop.\n            if eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveDifferentialEvolutionLocalSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm employing a differential evolution-inspired mutation operator with adaptive scaling and a local search refinement step.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolutionLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Mutation factor\n        self.CR = CR # Crossover rate\n        self.local_search_iterations = local_search_iterations\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        eval_count = self.pop_size\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = population[idxs]\n                x_mutated = population[i] + self.F * (x_r1 - x_r2) #removed x_r3, as it was not used\n                \n                # Clipping\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = population[i].copy()\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = x_trial\n                    \n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n                    \n            #Local Search: Applying on the best solution\n            for _ in range(self.local_search_iterations):\n                #Generate random perturbation\n                perturbation = np.random.normal(0, 0.01, self.dim) # Small perturbation\n                x_local_search = self.x_opt + perturbation\n                x_local_search = np.clip(x_local_search, func.bounds.lb, func.bounds.ub)  # Clip to bounds\n                \n                f_local_search = func(x_local_search)\n                eval_count += 1\n                \n                if f_local_search < self.f_opt:\n                    self.f_opt = f_local_search\n                    self.x_opt = x_local_search\n\n                if eval_count >= self.budget:\n                    break #Important: budget check inside the inner loop.\n            if eval_count >= self.budget:\n              break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.09723067467144297, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "4484cfab-2150-4f0f-a871-4900feb0f812", "fitness": 0.0, "name": "HybridDEPSOCMA_Adaptive", "description": "Integrates DE, PSO, and CMA-ES elements with self-adaptive parameter control and a neighborhood-based communication strategy to balance exploration and exploitation.", "code": "import numpy as np\nimport cmalib\nfrom scipy.spatial.distance import cdist\n\n\nclass HybridDEPSOCMA_Adaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.neighborhood_size = neighborhood_size\n        self.archive = []  # Archive for CMA-ES-like recombination\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (generation / (self.budget + generation))\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                else:\n                    self.stagnation_counter += 1\n                    \n                # Neighborhood best selection\n                distances = cdist(self.population[i].reshape(1, -1), self.population, metric='euclidean').flatten()\n                neighbors_idx = np.argsort(distances)[:self.neighborhood_size]\n                neighborhood_best_idx = neighbors_idx[np.argmin(self.fitness[neighbors_idx])]\n                neighborhood_best_position = self.population[neighborhood_best_idx]\n\n                # PSO update using neighborhood best\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (neighborhood_best_position - self.population[i])  # Use neighborhood best\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n                # Archive the solution for CMA-ES-like recombination\n                if len(self.archive) < self.pop_size:\n                    self.archive.append(u.copy())\n                    self.archive_fitness.append(f_u)\n                else:\n                    if f_u < np.max(self.archive_fitness):\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = u.copy()\n                        self.archive_fitness[worst_index] = f_u\n            \n            # CMA-ES-like recombination using the archive\n            if len(self.archive) == self.pop_size:\n                mean_archive = np.mean(self.archive, axis=0)\n                for i in range(self.pop_size):\n                    self.population[i] = np.clip(0.5 * self.population[i] + 0.5 * mean_archive, func.bounds.lb, func.bounds.ub)  # Adjust recombination factor as needed\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.archive = [] # Clear archive after restart\n                self.archive_fitness = []\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: No module named 'cmalib'", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE, PSO, and CMA-ES elements with self-adaptive parameter control and a neighborhood-based communication strategy to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\nimport cmalib\nfrom scipy.spatial.distance import cdist\n\n\nclass HybridDEPSOCMA_Adaptive:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, neighborhood_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.neighborhood_size = neighborhood_size\n        self.archive = []  # Archive for CMA-ES-like recombination\n        self.archive_fitness = []\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight (linearly decreasing)\n            w = self.w_init - (self.w_init - self.w_end) * (generation / (self.budget + generation))\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                else:\n                    self.stagnation_counter += 1\n                    \n                # Neighborhood best selection\n                distances = cdist(self.population[i].reshape(1, -1), self.population, metric='euclidean').flatten()\n                neighbors_idx = np.argsort(distances)[:self.neighborhood_size]\n                neighborhood_best_idx = neighbors_idx[np.argmin(self.fitness[neighbors_idx])]\n                neighborhood_best_position = self.population[neighborhood_best_idx]\n\n                # PSO update using neighborhood best\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (neighborhood_best_position - self.population[i])  # Use neighborhood best\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n                # Archive the solution for CMA-ES-like recombination\n                if len(self.archive) < self.pop_size:\n                    self.archive.append(u.copy())\n                    self.archive_fitness.append(f_u)\n                else:\n                    if f_u < np.max(self.archive_fitness):\n                        worst_index = np.argmax(self.archive_fitness)\n                        self.archive[worst_index] = u.copy()\n                        self.archive_fitness[worst_index] = f_u\n            \n            # CMA-ES-like recombination using the archive\n            if len(self.archive) == self.pop_size:\n                mean_archive = np.mean(self.archive, axis=0)\n                for i in range(self.pop_size):\n                    self.population[i] = np.clip(0.5 * self.population[i] + 0.5 * mean_archive, func.bounds.lb, func.bounds.ub)  # Adjust recombination factor as needed\n\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.archive = [] # Clear archive after restart\n                self.archive_fitness = []\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.4948019501328557, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "f74f2b41-9c37-4e26-b485-4069dfe530b4", "fitness": 0.24262605961036288, "name": "BiogeographyBasedOptimization", "description": "Biogeography-based optimization with adaptive mutation rates, blending exploration and exploitation.", "code": "import numpy as np\n\nclass BiogeographyBasedOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate  # Initial mutation rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.immigration_rates = None\n        self.emigration_rates = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.immigration_rates = np.zeros(self.pop_size)\n        self.emigration_rates = np.zeros(self.pop_size)\n\n\n    def calculate_migration_rates(self):\n        # Linear ranking based migration rates\n        sorted_indices = np.argsort(self.fitness)\n        self.immigration_rates[sorted_indices] = np.linspace(1, 0, self.pop_size)\n        self.emigration_rates[sorted_indices] = np.linspace(0, 1, self.pop_size)\n\n    def migrate(self):\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.immigration_rates[i]:\n                    emigrating_island = np.random.randint(0, self.pop_size)\n                    if np.random.rand() < self.emigration_rates[emigrating_island]:\n                        self.population[i, j] = self.population[emigrating_island, j]\n\n\n    def mutate(self):\n        # Adapt the mutation rate based on the diversity of the population\n        diversity = np.std(self.fitness)\n        adaptive_mutation_rate = self.mutation_rate * (1 + diversity)  # Increase mutation if low diversity, decrease otherwise\n        adaptive_mutation_rate = np.clip(adaptive_mutation_rate, 0.001, 0.1)  # Ensure rate stays within reasonable bounds\n\n        for i in range(self.pop_size):\n            if np.random.rand() < adaptive_mutation_rate:\n                j = np.random.randint(0, self.dim)\n                self.population[i, j] = self.lb + np.random.rand() * (self.ub - self.lb)\n\n\n\n    def __call__(self, func):\n        self.initialize_population()\n\n        # Initial Evaluation\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i, :])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i, :].copy()\n            else:\n                break\n\n        while self.eval_count < self.budget:\n            self.calculate_migration_rates()\n            self.migrate()\n            self.mutate()\n\n            for i in range(self.pop_size):\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.population[i, :])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i, :].copy()\n                else:\n                    break\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm BiogeographyBasedOptimization scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Biogeography-based optimization with adaptive mutation rates, blending exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass BiogeographyBasedOptimization:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate  # Initial mutation rate\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n        self.immigration_rates = None\n        self.emigration_rates = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        self.immigration_rates = np.zeros(self.pop_size)\n        self.emigration_rates = np.zeros(self.pop_size)\n\n\n    def calculate_migration_rates(self):\n        # Linear ranking based migration rates\n        sorted_indices = np.argsort(self.fitness)\n        self.immigration_rates[sorted_indices] = np.linspace(1, 0, self.pop_size)\n        self.emigration_rates[sorted_indices] = np.linspace(0, 1, self.pop_size)\n\n    def migrate(self):\n        for i in range(self.pop_size):\n            for j in range(self.dim):\n                if np.random.rand() < self.immigration_rates[i]:\n                    emigrating_island = np.random.randint(0, self.pop_size)\n                    if np.random.rand() < self.emigration_rates[emigrating_island]:\n                        self.population[i, j] = self.population[emigrating_island, j]\n\n\n    def mutate(self):\n        # Adapt the mutation rate based on the diversity of the population\n        diversity = np.std(self.fitness)\n        adaptive_mutation_rate = self.mutation_rate * (1 + diversity)  # Increase mutation if low diversity, decrease otherwise\n        adaptive_mutation_rate = np.clip(adaptive_mutation_rate, 0.001, 0.1)  # Ensure rate stays within reasonable bounds\n\n        for i in range(self.pop_size):\n            if np.random.rand() < adaptive_mutation_rate:\n                j = np.random.randint(0, self.dim)\n                self.population[i, j] = self.lb + np.random.rand() * (self.ub - self.lb)\n\n\n\n    def __call__(self, func):\n        self.initialize_population()\n\n        # Initial Evaluation\n        for i in range(self.pop_size):\n            if self.eval_count < self.budget:\n                self.fitness[i] = func(self.population[i, :])\n                self.eval_count += 1\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i, :].copy()\n            else:\n                break\n\n        while self.eval_count < self.budget:\n            self.calculate_migration_rates()\n            self.migrate()\n            self.mutate()\n\n            for i in range(self.pop_size):\n                if self.eval_count < self.budget:\n                    self.fitness[i] = func(self.population[i, :])\n                    self.eval_count += 1\n                    if self.fitness[i] < self.f_opt:\n                        self.f_opt = self.fitness[i]\n                        self.x_opt = self.population[i, :].copy()\n                else:\n                    break\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07117667647972581, 0.14804610663957685, 0.2243414116107173, 0.1295649718506815, 0.14424333149891588, 0.22700915348846762, 0.18797901454877375, 0.19068483682863913, 0.1676688464207471, 0.1295388140329342, 0.1566724896980075, 0.998205875092922, 0.2357144823140055, 0.1586496485349559, 0.5308912760599587, 0.21067417939151023, 0.20959441854061822, 0.1755067244356482, 0.1246817710475403, 0.431677163692912], "operator": "random_new", "theta_sampled": 0.26905883028259786, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "709f0c28-4f91-4056-9a36-ca17779474d0", "fitness": 0.0, "name": "AdaptivePopulationSizeDE", "description": "Population-based algorithm with fitness-dependent population shrinking and expanding to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptivePopulationSizeDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, shrink_factor=0.5, expand_factor=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    self.population[i] = x_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Adjust population size based on fitness improvement\n            improvement = np.mean(fitness) - np.mean(np.array([func(x) for x in self.population]))\n            \n            if improvement > 0 and self.pop_size * self.expand_factor <= 200:  # Expand if improving significantly and below max size\n                self.pop_size = int(self.pop_size * self.expand_factor)\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n                self.population = np.vstack((self.population, new_population))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= len(new_fitness)\n                fitness = np.concatenate((fitness, new_fitness))\n\n            elif improvement <= 0 and self.pop_size * self.shrink_factor >= 10:  # Shrink if not improving and above min size\n                self.pop_size = int(self.pop_size * self.shrink_factor)\n                # Keep the best individuals when shrinking\n                sorted_indices = np.argsort(fitness)\n                self.population = self.population[sorted_indices[:self.pop_size]]\n                fitness = fitness[sorted_indices[:self.pop_size]]\n\n\n            if self.budget <= 0 :\n                break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptivePopulationSizeDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with fitness-dependent population shrinking and expanding to balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePopulationSizeDE:\n    def __init__(self, budget=10000, dim=10, pop_size_init=50, shrink_factor=0.5, expand_factor=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size_init\n        self.shrink_factor = shrink_factor\n        self.expand_factor = expand_factor\n        self.F = 0.5  # Differential evolution parameter\n        self.CR = 0.7 # Crossover rate\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n                x_mutated = self.population[i] + self.F * (x_r2 - x_r3)\n                x_mutated = np.clip(x_mutated, func.bounds.lb, func.bounds.ub)\n\n                # Crossover\n                x_trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        x_trial[j] = x_mutated[j]\n\n                # Selection\n                f_trial = func(x_trial)\n                self.budget -= 1\n                if f_trial < fitness[i]:\n                    self.population[i] = x_trial\n                    fitness[i] = f_trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = x_trial\n\n            # Adjust population size based on fitness improvement\n            improvement = np.mean(fitness) - np.mean(np.array([func(x) for x in self.population]))\n            \n            if improvement > 0 and self.pop_size * self.expand_factor <= 200:  # Expand if improving significantly and below max size\n                self.pop_size = int(self.pop_size * self.expand_factor)\n                new_population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size - len(self.population), self.dim))\n                self.population = np.vstack((self.population, new_population))\n                new_fitness = np.array([func(x) for x in new_population])\n                self.budget -= len(new_fitness)\n                fitness = np.concatenate((fitness, new_fitness))\n\n            elif improvement <= 0 and self.pop_size * self.shrink_factor >= 10:  # Shrink if not improving and above min size\n                self.pop_size = int(self.pop_size * self.shrink_factor)\n                # Keep the best individuals when shrinking\n                sorted_indices = np.argsort(fitness)\n                self.population = self.population[sorted_indices[:self.pop_size]]\n                fitness = fitness[sorted_indices[:self.pop_size]]\n\n\n            if self.budget <= 0 :\n                break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.2135500601265815, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "ba50a976-ce83-4a41-8087-33c4bc11a8f1", "fitness": 0.3432577123206149, "name": "AntColonyOptimization", "description": "A population-based algorithm inspired by the foraging behavior of ants, employing pheromone laying and following, combined with a local search operator to intensify exploitation around promising solutions.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, ant_count=20, evaporation_rate=0.1, pheromone_influence=1.0, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.ant_count = ant_count\n        self.evaporation_rate = evaporation_rate\n        self.pheromone_influence = pheromone_influence\n        self.local_search_probability = local_search_probability\n\n        self.pheromone_matrix = np.ones(dim)  # Initialize pheromone trails for each dimension\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.ant_count, self.dim))\n        ant_fitness = np.zeros(self.ant_count)\n        for i in range(self.ant_count):\n            ant_fitness[i] = func(ants[i])\n            eval_count += 1\n            if ant_fitness[i] < self.f_opt:\n                self.f_opt = ant_fitness[i]\n                self.x_opt = ants[i].copy()\n\n        while eval_count < self.budget:\n            # Pheromone update based on best solution found by each ant\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.ant_count):\n                if eval_count >= self.budget:\n                    break\n\n                # Construct solution based on pheromone trails\n                probabilities = self.pheromone_matrix / np.sum(self.pheromone_matrix)\n                new_ant = np.zeros(self.dim)\n                for j in range(self.dim):\n                     new_ant[j] = ants[i][j] + np.random.normal(0, probabilities[j], 1)\n                     new_ant[j] = np.clip(new_ant[j], func.bounds.lb[j], func.bounds.ub[j]) # ensure bounds\n                \n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    # Perform a small random perturbation around the current solution\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Adjust step size as needed\n                    new_ant = ants[i] + perturbation\n                    new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)\n                   \n\n                f = func(new_ant)\n                eval_count += 1\n                if f < ant_fitness[i]:\n                    ant_fitness[i] = f\n                    ants[i] = new_ant.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_ant.copy()\n                        delta_pheromone += (self.f_opt / f) * np.abs(new_ant - ants[i])\n                                                                       \n\n            # Evaporate pheromones\n            self.pheromone_matrix *= (1 - self.evaporation_rate)\n            self.pheromone_matrix = np.maximum(self.pheromone_matrix, 0.01)\n\n            # Deposit pheromones\n            self.pheromone_matrix += delta_pheromone\n            \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "The algorithm AntColonyOptimization scored 0.343 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm inspired by the foraging behavior of ants, employing pheromone laying and following, combined with a local search operator to intensify exploitation around promising solutions.\n# Code:\n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, ant_count=20, evaporation_rate=0.1, pheromone_influence=1.0, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.ant_count = ant_count\n        self.evaporation_rate = evaporation_rate\n        self.pheromone_influence = pheromone_influence\n        self.local_search_probability = local_search_probability\n\n        self.pheromone_matrix = np.ones(dim)  # Initialize pheromone trails for each dimension\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        eval_count = 0\n\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.ant_count, self.dim))\n        ant_fitness = np.zeros(self.ant_count)\n        for i in range(self.ant_count):\n            ant_fitness[i] = func(ants[i])\n            eval_count += 1\n            if ant_fitness[i] < self.f_opt:\n                self.f_opt = ant_fitness[i]\n                self.x_opt = ants[i].copy()\n\n        while eval_count < self.budget:\n            # Pheromone update based on best solution found by each ant\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.ant_count):\n                if eval_count >= self.budget:\n                    break\n\n                # Construct solution based on pheromone trails\n                probabilities = self.pheromone_matrix / np.sum(self.pheromone_matrix)\n                new_ant = np.zeros(self.dim)\n                for j in range(self.dim):\n                     new_ant[j] = ants[i][j] + np.random.normal(0, probabilities[j], 1)\n                     new_ant[j] = np.clip(new_ant[j], func.bounds.lb[j], func.bounds.ub[j]) # ensure bounds\n                \n\n                # Local Search\n                if np.random.rand() < self.local_search_probability:\n                    # Perform a small random perturbation around the current solution\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Adjust step size as needed\n                    new_ant = ants[i] + perturbation\n                    new_ant = np.clip(new_ant, func.bounds.lb, func.bounds.ub)\n                   \n\n                f = func(new_ant)\n                eval_count += 1\n                if f < ant_fitness[i]:\n                    ant_fitness[i] = f\n                    ants[i] = new_ant.copy()\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = new_ant.copy()\n                        delta_pheromone += (self.f_opt / f) * np.abs(new_ant - ants[i])\n                                                                       \n\n            # Evaporate pheromones\n            self.pheromone_matrix *= (1 - self.evaporation_rate)\n            self.pheromone_matrix = np.maximum(self.pheromone_matrix, 0.01)\n\n            # Deposit pheromones\n            self.pheromone_matrix += delta_pheromone\n            \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10268911932563662, 0.19890711981896902, 0.37638504535395134, 0.1973545369942452, 0.22432460702679313, 0.3889009544405966, 0.2668522020228362, 0.3214236819072256, 0.32294517878285944, 0.14805061252127705, 0.39528507335417784, 0.9988202653761057, 0.3021234095422427, 0.19866762799000814, 0.6969460069477136, 0.3713223307583029, 0.2910613223833931, 0.4487228917886027, 0.1782312866842769, 0.43614097339308466], "operator": "random_new", "theta_sampled": 0.2665657317787723, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "2eff4b5a-ebc8-4309-ada0-8ba564ee5ead", "fitness": 0.0, "name": "OrthogonalAdaptiveStepSize", "description": "Population-based algorithm with adaptive step size based on function value improvement, incorporating orthogonal exploration to enhance diversity.", "code": "import numpy as np\n\nclass OrthogonalAdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.orthogonal_samples = orthogonal_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == 0:\n                self.fitness[i] = func(self.population[i])\n        return func.nevals\n\n    def orthogonal_exploration(self, x, func):\n        best_f = np.inf\n        best_x = None\n\n        # Generate orthogonal directions\n        orthogonal_basis = np.random.randn(self.dim, self.orthogonal_samples)\n        orthogonal_basis = orthogonal_basis / np.linalg.norm(orthogonal_basis, axis=0)\n\n        for i in range(self.orthogonal_samples):\n            direction = orthogonal_basis[:, i]\n            new_x = x + self.step_size * direction\n            new_x = np.clip(new_x, self.lb, self.ub)  # Keep within bounds\n\n            f = func(new_x)\n            if f < best_f:\n                best_f = f\n                best_x = new_x\n        return best_f, best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population()\n        evals = self.evaluate_population(func)\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n\n                # Generate a new solution with adaptive step size\n                new_x = self.population[i] + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n                new_x = np.clip(new_x, self.lb, self.ub)  # Keep within bounds\n                \n                new_f = func(new_x)\n                evals += 1\n\n                if new_f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = new_f\n                    self.step_size *= 1.05 # Increase step size if improvement\n\n                else:\n                    # Orthogonal Exploration to escape local optima\n                    ortho_f, ortho_x = self.orthogonal_exploration(self.population[i], func)\n                    evals += self.orthogonal_samples\n                    if ortho_f < self.fitness[i]:\n                        self.population[i] = ortho_x\n                        self.fitness[i] = ortho_f\n                        self.step_size *= 1.05 # Increase step size if improvement\n                    else:\n                         self.step_size *= 0.95 # Decrease step size if no improvement\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n                if self.step_size > 0.5:\n                    self.step_size = 0.5\n                if self.step_size < 0.0001:\n                    self.step_size = 0.0001\n                \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 5, "feedback": "", "error": "Evaluation error: 'ioh.iohcpp.problem.Discus' object has no attribute 'nevals'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive step size based on function value improvement, incorporating orthogonal exploration to enhance diversity.\n# Code:\n```python\nimport numpy as np\n\nclass OrthogonalAdaptiveStepSize:\n    def __init__(self, budget=10000, dim=10, pop_size=20, step_size=0.1, orthogonal_samples=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.step_size = step_size\n        self.orthogonal_samples = orthogonal_samples\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population = None\n        self.fitness = None\n\n    def initialize_population(self):\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n\n    def evaluate_population(self, func):\n        for i in range(self.pop_size):\n            if self.fitness[i] == 0:\n                self.fitness[i] = func(self.population[i])\n        return func.nevals\n\n    def orthogonal_exploration(self, x, func):\n        best_f = np.inf\n        best_x = None\n\n        # Generate orthogonal directions\n        orthogonal_basis = np.random.randn(self.dim, self.orthogonal_samples)\n        orthogonal_basis = orthogonal_basis / np.linalg.norm(orthogonal_basis, axis=0)\n\n        for i in range(self.orthogonal_samples):\n            direction = orthogonal_basis[:, i]\n            new_x = x + self.step_size * direction\n            new_x = np.clip(new_x, self.lb, self.ub)  # Keep within bounds\n\n            f = func(new_x)\n            if f < best_f:\n                best_f = f\n                best_x = new_x\n        return best_f, best_x\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population()\n        evals = self.evaluate_population(func)\n        \n        while evals < self.budget:\n            for i in range(self.pop_size):\n                if evals >= self.budget:\n                    break\n\n                # Generate a new solution with adaptive step size\n                new_x = self.population[i] + np.random.uniform(-self.step_size, self.step_size, size=self.dim)\n                new_x = np.clip(new_x, self.lb, self.ub)  # Keep within bounds\n                \n                new_f = func(new_x)\n                evals += 1\n\n                if new_f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = new_f\n                    self.step_size *= 1.05 # Increase step size if improvement\n\n                else:\n                    # Orthogonal Exploration to escape local optima\n                    ortho_f, ortho_x = self.orthogonal_exploration(self.population[i], func)\n                    evals += self.orthogonal_samples\n                    if ortho_f < self.fitness[i]:\n                        self.population[i] = ortho_x\n                        self.fitness[i] = ortho_f\n                        self.step_size *= 1.05 # Increase step size if improvement\n                    else:\n                         self.step_size *= 0.95 # Decrease step size if no improvement\n\n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n                if self.step_size > 0.5:\n                    self.step_size = 0.5\n                if self.step_size < 0.0001:\n                    self.step_size = 0.0001\n                \n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.011237491296359167, "reward": 0.0, "generation": 5}, "task_prompt": ""}
{"id": "29b68a0b-be54-4691-bc09-8033dbe0a9c1", "fitness": 0.24337620110042074, "name": "AntColonyOptimization", "description": "An adaptive population-based algorithm inspired by the foraging behavior of ants, dynamically adjusting step sizes based on pheromone trails and local gradient information.", "code": "import numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, pheromone_decay=0.9, alpha=1.0, beta=2.0, q=10.0, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.pheromone_decay = pheromone_decay\n        self.alpha = alpha  # Pheromone influence\n        self.beta = beta    # Heuristic influence\n        self.q = q          # Pheromone deposit constant\n        self.initial_step_size = initial_step_size\n        self.pheromone = np.ones(dim) * 1e-6  # Initialize pheromone levels for each dimension\n        self.step_size = np.ones(dim) * self.initial_step_size # Initialize step sizes\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.function_calls = 0\n\n        # Initialize ant positions randomly within the bounds\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            self.function_calls += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n        while self.function_calls < self.budget:\n            # Move ants based on pheromone and heuristic information\n            for i in range(self.colony_size):\n                probabilities = (self.pheromone**self.alpha) * ((1.0 / (self.step_size + 1e-8))**self.beta) # Heuristic based on stepsize\n                probabilities /= np.sum(probabilities)\n\n                # Select dimensions to modify based on probabilities\n                chosen_dims = np.random.choice(self.dim, size=max(1,int(self.dim*0.2)), replace=False, p=probabilities) #select a subset to update\n\n                # Take a step in the chosen dimensions\n                step = np.random.normal(0, self.step_size[chosen_dims], size=len(chosen_dims))\n                new_pos = ants[i].copy()\n                new_pos[chosen_dims] += step\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                new_fitness = func(new_pos)\n                self.function_calls += 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    ants[i] = new_pos\n\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_pos\n\n            # Update pheromone levels\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (fitness[i] + 1e-8)) * (np.abs(ants[i] - self.x_opt) < self.step_size) # Deposit pheromone near the best solution, scaled by fitness\n            self.pheromone = (1 - self.pheromone_decay) * self.pheromone + self.pheromone_decay * delta_pheromone\n\n            #Adapt Step Size\n            self.step_size = np.clip(self.step_size * np.exp(np.random.normal(0, 0.1, self.dim)), 1e-6, 1) #log-normal random walk\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AntColonyOptimization scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm inspired by the foraging behavior of ants, dynamically adjusting step sizes based on pheromone trails and local gradient information.\n# Code:\n```python\nimport numpy as np\n\nclass AntColonyOptimization:\n    def __init__(self, budget=10000, dim=10, colony_size=50, pheromone_decay=0.9, alpha=1.0, beta=2.0, q=10.0, initial_step_size=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.colony_size = colony_size\n        self.pheromone_decay = pheromone_decay\n        self.alpha = alpha  # Pheromone influence\n        self.beta = beta    # Heuristic influence\n        self.q = q          # Pheromone deposit constant\n        self.initial_step_size = initial_step_size\n        self.pheromone = np.ones(dim) * 1e-6  # Initialize pheromone levels for each dimension\n        self.step_size = np.ones(dim) * self.initial_step_size # Initialize step sizes\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.function_calls = 0\n\n        # Initialize ant positions randomly within the bounds\n        ants = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.colony_size, self.dim))\n        fitness = np.zeros(self.colony_size)\n\n        for i in range(self.colony_size):\n            fitness[i] = func(ants[i])\n            self.function_calls += 1\n            if fitness[i] < self.f_opt:\n                self.f_opt = fitness[i]\n                self.x_opt = ants[i]\n\n        while self.function_calls < self.budget:\n            # Move ants based on pheromone and heuristic information\n            for i in range(self.colony_size):\n                probabilities = (self.pheromone**self.alpha) * ((1.0 / (self.step_size + 1e-8))**self.beta) # Heuristic based on stepsize\n                probabilities /= np.sum(probabilities)\n\n                # Select dimensions to modify based on probabilities\n                chosen_dims = np.random.choice(self.dim, size=max(1,int(self.dim*0.2)), replace=False, p=probabilities) #select a subset to update\n\n                # Take a step in the chosen dimensions\n                step = np.random.normal(0, self.step_size[chosen_dims], size=len(chosen_dims))\n                new_pos = ants[i].copy()\n                new_pos[chosen_dims] += step\n                new_pos = np.clip(new_pos, func.bounds.lb, func.bounds.ub) # Clip to bounds\n\n                new_fitness = func(new_pos)\n                self.function_calls += 1\n\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    ants[i] = new_pos\n\n                    if new_fitness < self.f_opt:\n                        self.f_opt = new_fitness\n                        self.x_opt = new_pos\n\n            # Update pheromone levels\n            delta_pheromone = np.zeros(self.dim)\n            for i in range(self.colony_size):\n                delta_pheromone += (self.q / (fitness[i] + 1e-8)) * (np.abs(ants[i] - self.x_opt) < self.step_size) # Deposit pheromone near the best solution, scaled by fitness\n            self.pheromone = (1 - self.pheromone_decay) * self.pheromone + self.pheromone_decay * delta_pheromone\n\n            #Adapt Step Size\n            self.step_size = np.clip(self.step_size * np.exp(np.random.normal(0, 0.1, self.dim)), 1e-6, 1) #log-normal random walk\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0.1133593800863062, 0.16940266668297477, 0.2769767115365488, 0.15060264724908412, 0.1488864597455185, 0.21404694278770786, 0.17328308585273045, 0.19186221817647975, 0.16138990125483, 0.14376654116970744, 0.17260911871038298, 0.9807226566603587, 0.23959438824743717, 0.15790055293855598, 0.28891141998359127, 0.237980922788259, 0.1939087977667242, 0.21035906888215594, 0.21120516883050244, 0.43075537265855957], "operator": "random_new", "theta_sampled": 0.35564335056388874, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "e1f211f6-b6d1-4594-a4c7-f5532399da2f", "fitness": 0.0, "name": "AdaptiveHybridOptimizer", "description": "Population-based algorithm using a combination of Gaussian mutation, differential evolution, and local search, adaptively adjusting exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, de_rate=0.5, local_search_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.de_rate = de_rate\n        self.local_search_rate = local_search_rate\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n         self.lb = func.bounds.lb\n         self.ub = func.bounds.ub\n         self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.population])\n         self.budget -= self.pop_size\n         self.f_opt = np.min(self.fitness)\n         self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def gaussian_mutation(self):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.mutation_rate:\n                mutation = np.random.normal(0, 0.1, self.dim)\n                self.population[i] = np.clip(self.population[i] + mutation, self.lb, self.ub)\n        return\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                trial_vector = self.population[i] + 0.8 * (x_r2 - x_r3)\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n        return\n    \n    def local_search(self, func):\n         for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_rate:\n                step_size = 0.01 * (self.ub - self.lb)\n                new_x = self.population[i] + np.random.uniform(-step_size, step_size, self.dim)\n                new_x = np.clip(new_x, self.lb, self.ub)\n                new_f = func(new_x)\n                self.budget -= 1\n\n                if new_f < self.fitness[i]:\n                    self.fitness[i] = new_f\n                    self.population[i] = new_x\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n         return\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.gaussian_mutation()\n            self.differential_evolution(func)\n            self.local_search(func)\n\n            #Adaptive Adjustment of Rates (optional)\n            if np.random.rand() < 0.1:  # Adjust every 10% of iterations\n               self.mutation_rate = np.clip(self.mutation_rate + np.random.uniform(-0.05, 0.05), 0.05, 0.5)\n               self.de_rate = np.clip(self.de_rate + np.random.uniform(-0.05, 0.05), 0.2, 0.8)\n               self.local_search_rate = np.clip(self.local_search_rate + np.random.uniform(-0.05, 0.05), 0.05, 0.5)\n\n\n            # Evaluate mutated population\n            for i in range(self.pop_size):\n                f = func(self.population[i])\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.population[i]\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of Gaussian mutation, differential evolution, and local search, adaptively adjusting exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, mutation_rate=0.1, de_rate=0.5, local_search_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.mutation_rate = mutation_rate\n        self.de_rate = de_rate\n        self.local_search_rate = local_search_rate\n        self.population = None\n        self.fitness = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_population(self, func):\n         self.lb = func.bounds.lb\n         self.ub = func.bounds.ub\n         self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n         self.fitness = np.array([func(x) for x in self.population])\n         self.budget -= self.pop_size\n         self.f_opt = np.min(self.fitness)\n         self.x_opt = self.population[np.argmin(self.fitness)]\n\n    def gaussian_mutation(self):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.mutation_rate:\n                mutation = np.random.normal(0, 0.1, self.dim)\n                self.population[i] = np.clip(self.population[i] + mutation, self.lb, self.ub)\n        return\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.de_rate:\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[idxs]\n\n                trial_vector = self.population[i] + 0.8 * (x_r2 - x_r3)\n\n                trial_vector = np.clip(trial_vector, self.lb, self.ub)\n                f_trial = func(trial_vector)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial_vector\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial_vector\n        return\n    \n    def local_search(self, func):\n         for i in range(self.pop_size):\n            if np.random.rand() < self.local_search_rate:\n                step_size = 0.01 * (self.ub - self.lb)\n                new_x = self.population[i] + np.random.uniform(-step_size, step_size, self.dim)\n                new_x = np.clip(new_x, self.lb, self.ub)\n                new_f = func(new_x)\n                self.budget -= 1\n\n                if new_f < self.fitness[i]:\n                    self.fitness[i] = new_f\n                    self.population[i] = new_x\n\n                    if new_f < self.f_opt:\n                        self.f_opt = new_f\n                        self.x_opt = new_x\n         return\n\n\n    def __call__(self, func):\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            self.gaussian_mutation()\n            self.differential_evolution(func)\n            self.local_search(func)\n\n            #Adaptive Adjustment of Rates (optional)\n            if np.random.rand() < 0.1:  # Adjust every 10% of iterations\n               self.mutation_rate = np.clip(self.mutation_rate + np.random.uniform(-0.05, 0.05), 0.05, 0.5)\n               self.de_rate = np.clip(self.de_rate + np.random.uniform(-0.05, 0.05), 0.2, 0.8)\n               self.local_search_rate = np.clip(self.local_search_rate + np.random.uniform(-0.05, 0.05), 0.05, 0.5)\n\n\n            # Evaluate mutated population\n            for i in range(self.pop_size):\n                f = func(self.population[i])\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = self.population[i]\n                \n                if self.budget <= 0:\n                    break\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.15899333640157545, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "148e899d-e82e-4a62-8a07-f7547864b297", "fitness": 0.08853944136948866, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution (DE), Particle Swarm Optimization (PSO) with CMA-ES adaptation and a focused local search to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, cma_sigma_initial=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_initial = cma_sigma_initial\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_initial * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n                \n                # Selection based on DE\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n\n                # PSO update (applied after DE)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n            self.mean = mean_new\n            \n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    #Update personal best\n                    if local_f < self.personal_best_fitness[best_idx]:\n                        self.personal_best_fitness[best_idx] = local_f\n                        self.personal_best_positions[best_idx] = local_trial.copy()\n\n                    # Update global best\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n            \n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSOCMA scored 0.089 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Particle Swarm Optimization (PSO) with CMA-ES adaptation and a focused local search to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, cma_sigma_initial=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.cma_sigma_initial = cma_sigma_initial\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma_initial * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n                \n                # Selection based on DE\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n\n                # PSO update (applied after DE)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n            self.mean = mean_new\n            \n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    #Update personal best\n                    if local_f < self.personal_best_fitness[best_idx]:\n                        self.personal_best_fitness[best_idx] = local_f\n                        self.personal_best_positions[best_idx] = local_trial.copy()\n\n                    # Update global best\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n            \n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.17707888273897732, 0], "operator": "crossover", "theta_sampled": 0.15629470851813898, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "f9315a4c-6e84-4367-a488-bf457f7b6c85", "fitness": 0.2760064176677373, "name": "SpiralSearch", "description": "Population-based algorithm with a spiral dynamic search strategy around the best solutions found so far, incorporating random jumps to enhance exploration.", "code": "import numpy as np\n\nclass SpiralSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_intensity=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_intensity = spiral_intensity\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluations\n\n        # Find initial best solution\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx].copy()  # Store a copy to avoid modification\n\n        while self.budget > 0:\n            new_pop = np.zeros_like(pop)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Spiral movement around the best solution\n                r = np.random.rand() * self.spiral_intensity\n                theta = np.random.rand(self.dim) * 2 * np.pi\n                dx = r * np.cos(theta) * (self.x_opt - pop[i])\n\n                new_x = pop[i] + dx\n\n                # Random jump with probability proportional to fitness rank\n                if np.random.rand() < (i / self.pop_size): # Higher ranked agents jump less often\n                    new_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n                # Clip to respect bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate if possible within budget\n                if self.budget > 0:\n                    new_fitness[i] = func(new_x)\n                    self.budget -= 1\n                else:\n                    new_fitness[i] = np.inf # Assign a very bad fitness if no budget left\n                new_pop[i] = new_x\n                # Update best solution if improved\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_x.copy()\n\n            # Update population\n            pop = new_pop\n            fitness = new_fitness\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm SpiralSearch scored 0.276 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with a spiral dynamic search strategy around the best solutions found so far, incorporating random jumps to enhance exploration.\n# Code:\n```python\nimport numpy as np\n\nclass SpiralSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, spiral_intensity=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.spiral_intensity = spiral_intensity\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size  # Update budget after initial evaluations\n\n        # Find initial best solution\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx].copy()  # Store a copy to avoid modification\n\n        while self.budget > 0:\n            new_pop = np.zeros_like(pop)\n            new_fitness = np.zeros_like(fitness)\n\n            for i in range(self.pop_size):\n                # Spiral movement around the best solution\n                r = np.random.rand() * self.spiral_intensity\n                theta = np.random.rand(self.dim) * 2 * np.pi\n                dx = r * np.cos(theta) * (self.x_opt - pop[i])\n\n                new_x = pop[i] + dx\n\n                # Random jump with probability proportional to fitness rank\n                if np.random.rand() < (i / self.pop_size): # Higher ranked agents jump less often\n                    new_x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n\n                # Clip to respect bounds\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate if possible within budget\n                if self.budget > 0:\n                    new_fitness[i] = func(new_x)\n                    self.budget -= 1\n                else:\n                    new_fitness[i] = np.inf # Assign a very bad fitness if no budget left\n                new_pop[i] = new_x\n                # Update best solution if improved\n                if new_fitness[i] < self.f_opt:\n                    self.f_opt = new_fitness[i]\n                    self.x_opt = new_x.copy()\n\n            # Update population\n            pop = new_pop\n            fitness = new_fitness\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11252746719550688, 0.16921084158603206, 0.2592039903689277, 0.195946599714113, 0.20492155354723907, 0.21974125588900362, 0.22120941194803234, 0.19438795281180787, 0.20875235773000345, 0.15678353248636123, 0.20387951785262204, 0.9998293766898376, 0.2430278830521373, 0.1961978405396948, 0.5697448757557267, 0.2762534607078362, 0.2389373165771309, 0.2345489826122582, 0.1614005180659127, 0.4536236182245622], "operator": "random_new", "theta_sampled": 0.07399333134638045, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "3c7a740a-0bec-4756-ab2e-f59a12959eec", "fitness": 0.5947452276774454, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and local search with dynamic parameter adaptation and restart mechanisms for robust optimization.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma  # Initial CMA-ES step size\n        self.success_rate = 0.0 #Success rate for adaptive parameter control\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        num_improvements = 0 #For success rate calculation\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness #Store previous best fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            #Parameter Adaptation\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1 #Increment number of improvements\n            \n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSOCMA scored 0.595 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and local search with dynamic parameter adaptation and restart mechanisms for robust optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma  # Initial CMA-ES step size\n        self.success_rate = 0.0 #Success rate for adaptive parameter control\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        num_improvements = 0 #For success rate calculation\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness #Store previous best fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            #Parameter Adaptation\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1 #Increment number of improvements\n            \n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.16208732237247003, 0.32452758409683746, 0.25107141705762825, 0.9262608260984314, 0.9567571021904857, 0.9639606561232021, 0.3423980594295569, 0.45590584572949755, 0.7794580890166718, 0.2080761238179074, 0.6775625838168251, 0.9975506880660067, 0.282684774765826, 0.3673866747393736, 0.7511600272050413, 0.8806024949564862, 0.6512993744937756, 0.9581390231447249, 0.25154617062008977, 0.7064697158080695], "operator": "crossover", "theta_sampled": 0.04340950905576166, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "1955d084-8a08-4301-b6d3-e962a4a9a84e", "fitness": 0.5394513791725368, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and local search with adaptive parameter control and a restart mechanism.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_factor=1.0, c_c_factor=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (self.c_sigma_factor * np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (self.c_c_factor * np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSOCMA scored 0.539 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and local search with adaptive parameter control and a restart mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_factor=1.0, c_c_factor=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (self.c_sigma_factor * np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (self.c_c_factor * np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb)\n                 self.C = np.eye(self.dim)\n                 self.pc = np.zeros(self.dim)\n                 self.ps = np.zeros(self.dim)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.23414279862079568, 0.35982956556930035, 0.4896738925385923, 0.17764653757924265, 0.37047728279975733, 0.4314701419473279, 0.56411546827645, 0.49089967823198477, 0.765401127097986, 0.28966000810705705, 0.942619600781392, 0.9981201382743625, 0.27394123015239225, 0.7043948629673507, 0.805116106235089, 0.859631539520786, 0.3047692079643842, 0.9462349012294018, 0.2609670931837097, 0.5199164023733738], "operator": "crossover", "theta_sampled": 0.15019897567579366, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "4c0578f7-7876-4b9b-a70d-5cabe7b2020d", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES-inspired adaptation, and a local search, with dynamic parameter adjustment and stagnation detection for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_decay = 0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_start = w_start  # Initial inertia weight\n        self.w_end = w_end      # Final inertia weight\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_decay = cma_decay\n\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.mu = None\n\n\n    def initialize_cmaes(self, lb, ub, population):\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n    def update_cmaes(self, population, fitness, lb, ub):\n        # Sort by fitness\n        idx_sorted = np.argsort(fitness)\n        population = population[idx_sorted]\n        fitness = fitness[idx_sorted]\n\n        # Selection and update mean\n        x_mu = population[:self.mu]\n        mean_new = np.mean(x_mu, axis=0)\n        \n        # Update evolution paths\n        self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n        self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n        # Update covariance matrix\n        self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n        for j in range(self.mu):\n            self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n        \n        # Adjust step size\n        self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n        self.sigma = max(self.sigma, 1e-10 * (ub - lb)) # Avoid sigma becoming too small.\n\n        self.mean = mean_new\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n        \n        # Initialize CMA-ES\n        self.initialize_cmaes(lb, ub, population)\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive inertia weight (PSO)\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget//self.pop_size + generation))  # Linearly decreasing\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = w * (population[i] - population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                trial_pso = np.clip(population[i] + velocity, lb, ub)\n\n                # Evaluation\n                f_de = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break\n                f_pso = func(trial_pso)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break\n                \n                # Selection - select the best from DE and PSO\n                if f_de < f_pso:\n                  f = f_de\n                  new_position = trial\n                else:\n                  f = f_pso\n                  new_position = trial_pso\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_position\n\n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = new_position.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n            \n            # CMA-ES adaptation\n            self.update_cmaes(population, fitness, lb, ub)\n            self.F *= self.cma_decay\n            self.CR *= self.cma_decay\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial.copy()\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 fitness = np.array([func(x) for x in population])\n                 self.budget -= self.pop_size\n                 best_index = np.argmin(fitness)\n                 global_best_position = population[best_index].copy()\n                 global_best_fitness = fitness[best_index]\n\n                 personal_best_positions = population.copy()\n                 personal_best_fitness = fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.initialize_cmaes(lb, ub, population) # Reinitialize CMA-ES\n            \n            # Global best update at the end of each generation.\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES-inspired adaptation, and a local search, with dynamic parameter adjustment and stagnation detection for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_decay = 0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_start = w_start  # Initial inertia weight\n        self.w_end = w_end      # Final inertia weight\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_decay = cma_decay\n\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.c_sigma = None\n        self.d_sigma = None\n        self.c_c = None\n        self.c_1 = None\n        self.c_mu = None\n        self.mu = None\n\n\n    def initialize_cmaes(self, lb, ub, population):\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n    def update_cmaes(self, population, fitness, lb, ub):\n        # Sort by fitness\n        idx_sorted = np.argsort(fitness)\n        population = population[idx_sorted]\n        fitness = fitness[idx_sorted]\n\n        # Selection and update mean\n        x_mu = population[:self.mu]\n        mean_new = np.mean(x_mu, axis=0)\n        \n        # Update evolution paths\n        self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n        self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n        # Update covariance matrix\n        self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n        for j in range(self.mu):\n            self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n        \n        # Adjust step size\n        self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n        self.sigma = max(self.sigma, 1e-10 * (ub - lb)) # Avoid sigma becoming too small.\n\n        self.mean = mean_new\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize personal best positions and fitness\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n\n        # Initialize global best\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n        \n        # Initialize CMA-ES\n        self.initialize_cmaes(lb, ub, population)\n        \n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive inertia weight (PSO)\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget//self.pop_size + generation))  # Linearly decreasing\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Particle Swarm Optimization Velocity Update\n                velocity = w * (population[i] - population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                trial_pso = np.clip(population[i] + velocity, lb, ub)\n\n                # Evaluation\n                f_de = func(trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break\n                f_pso = func(trial_pso)\n                self.budget -= 1\n                if self.budget <= 0:\n                  break\n                \n                # Selection - select the best from DE and PSO\n                if f_de < f_pso:\n                  f = f_de\n                  new_position = trial\n                else:\n                  f = f_pso\n                  new_position = trial_pso\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = new_position\n\n                    # Update personal best\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = new_position.copy()\n\n                    # Update global best\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = new_position.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n            \n            # CMA-ES adaptation\n            self.update_cmaes(population, fitness, lb, ub)\n            self.F *= self.cma_decay\n            self.CR *= self.cma_decay\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial.copy()\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 fitness = np.array([func(x) for x in population])\n                 self.budget -= self.pop_size\n                 best_index = np.argmin(fitness)\n                 global_best_position = population[best_index].copy()\n                 global_best_fitness = fitness[best_index]\n\n                 personal_best_positions = population.copy()\n                 personal_best_fitness = fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.initialize_cmaes(lb, ub, population) # Reinitialize CMA-ES\n            \n            # Global best update at the end of each generation.\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.031445995443600015, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "a69d166f-6a1d-4c1a-a11f-85ccea0320d5", "fitness": 0.0, "name": "GaussianLevyAdaptation", "description": "A population-based algorithm using a combination of Gaussian mutation and Lvy flight exploration, adapting the mutation strength based on the population fitness variance.", "code": "import numpy as np\n\nclass GaussianLevyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.5\n        self.levy_flight_probability = 0.1\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            # Calculate population variance\n            fitness_var = np.var(fitness)\n            # Adjust mutation strength based on fitness variance\n            mutation_strength = 0.1 * (1 + np.exp(-fitness_var)) # Sigmoid-like adaptation\n\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    new_solution = population[i] + mutation\n                else:\n                    new_solution = population[i].copy()\n\n                # Lvy Flight Exploration\n                if np.random.rand() < self.levy_flight_probability:\n                    levy_step = self.levy_flight()\n                    new_solution += levy_step\n\n                # Boundary Handling\n                new_solution = np.clip(new_solution, self.lb, self.ub)\n                new_population[i] = new_solution\n\n\n            new_fitness = np.array([func(x) for x in new_population])\n            evals += self.pop_size\n\n            # Selection (replace if better)\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 6, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm using a combination of Gaussian mutation and Lvy flight exploration, adapting the mutation strength based on the population fitness variance.\n# Code: \n```python\nimport numpy as np\n\nclass GaussianLevyAdaptation:\n    def __init__(self, budget=10000, dim=10, pop_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lb = -5.0\n        self.ub = 5.0\n        self.mutation_rate = 0.5\n        self.levy_flight_probability = 0.1\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        evals = self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        while evals < self.budget:\n            # Calculate population variance\n            fitness_var = np.var(fitness)\n            # Adjust mutation strength based on fitness variance\n            mutation_strength = 0.1 * (1 + np.exp(-fitness_var)) # Sigmoid-like adaptation\n\n            new_population = np.zeros_like(population)\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    new_solution = population[i] + mutation\n                else:\n                    new_solution = population[i].copy()\n\n                # Lvy Flight Exploration\n                if np.random.rand() < self.levy_flight_probability:\n                    levy_step = self.levy_flight()\n                    new_solution += levy_step\n\n                # Boundary Handling\n                new_solution = np.clip(new_solution, self.lb, self.ub)\n                new_population[i] = new_solution\n\n\n            new_fitness = np.array([func(x) for x in new_population])\n            evals += self.pop_size\n\n            # Selection (replace if better)\n            for i in range(self.pop_size):\n                if new_fitness[i] < fitness[i]:\n                    fitness[i] = new_fitness[i]\n                    population[i] = new_population[i]\n\n            # Update best solution\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < self.f_opt:\n                self.f_opt = fitness[best_index]\n                self.x_opt = population[best_index]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": -0.026840409626027895, "reward": 0.0, "generation": 6}, "task_prompt": ""}
{"id": "b40690e2-2653-44f6-87c1-8d4f0d0bf5fc", "fitness": 0.0, "name": "HybridSaDEPSOCMA", "description": "Integrates a self-adaptive Differential Evolution (SaDE) strategy and a simplified CMA-ES update with a population-based PSO, enhancing exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridSaDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_factor=1.0, c_c_factor=1.0,\n                 num_strategies=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n        self.num_strategies = num_strategies  # Number of DE strategies\n        self.success_rates = np.ones(self.num_strategies) / self.num_strategies # Initialize success rates\n        self.memory_F = np.ones(self.num_strategies) * self.F\n        self.memory_CR = np.ones(self.num_strategies) * self.CR\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters (simplified)\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n\n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Adaptive inertia weight\n            \n            successful_strategies = 0\n            strategy_successes = np.zeros(self.num_strategies)\n            F_memory = []\n            CR_memory = []\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Strategy Selection (SaDE)\n                strategy_index = np.random.choice(self.num_strategies, p=self.success_rates)\n\n                # Generate DE parameters based on the selected strategy\n                F = np.clip(np.random.normal(self.memory_F[strategy_index], 0.1), 0.1, 1.0)\n                CR = np.clip(np.random.normal(self.memory_CR[strategy_index], 0.1), 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n\n                    strategy_successes[strategy_index] += 1  # Increment success counter for the strategy\n                    successful_strategies += 1\n                    F_memory.append(F)\n                    CR_memory.append(CR)\n\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # Update strategy success rates (SaDE adaptation)\n            if successful_strategies > 0:\n                 self.success_rates = 0.9 * self.success_rates + 0.1 * (strategy_successes / successful_strategies)\n            else:\n                self.success_rates = np.ones(self.num_strategies) / self.num_strategies\n\n            self.success_rates /= np.sum(self.success_rates)\n\n            # Memory update\n            if F_memory:\n                self.memory_F[strategy_index] = 0.9 * self.memory_F[strategy_index] + 0.1 * np.mean(F_memory)\n            if CR_memory:\n                self.memory_CR[strategy_index] = 0.9 * self.memory_CR[strategy_index] + 0.1 * np.mean(CR_memory)\n\n\n            # CMA-ES adaptation (simplified - only mean adaptation)\n            self.mean = np.mean(self.population, axis=0)\n            # Adjust step size - simplified version\n            if self.global_best_fitness < self.f_opt:\n                self.sigma *= 0.995\n            else:\n                self.sigma *= 1.005\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridSaDEPSOCMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["1955d084-8a08-4301-b6d3-e962a4a9a84e"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive Differential Evolution (SaDE) strategy and a simplified CMA-ES update with a population-based PSO, enhancing exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass HybridSaDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_factor=1.0, c_c_factor=1.0,\n                 num_strategies=3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) - start value\n        self.w_end = w_end # Inertia weight (PSO) - end value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor\n        self.c_c_factor = c_c_factor\n        self.num_strategies = num_strategies  # Number of DE strategies\n        self.success_rates = np.ones(self.num_strategies) / self.num_strategies # Initialize success rates\n        self.memory_F = np.ones(self.num_strategies) * self.F\n        self.memory_CR = np.ones(self.num_strategies) * self.CR\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters (simplified)\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n\n        generation = 0\n\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget + generation)) # Adaptive inertia weight\n            \n            successful_strategies = 0\n            strategy_successes = np.zeros(self.num_strategies)\n            F_memory = []\n            CR_memory = []\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Strategy Selection (SaDE)\n                strategy_index = np.random.choice(self.num_strategies, p=self.success_rates)\n\n                # Generate DE parameters based on the selected strategy\n                F = np.clip(np.random.normal(self.memory_F[strategy_index], 0.1), 0.1, 1.0)\n                CR = np.clip(np.random.normal(self.memory_CR[strategy_index], 0.1), 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + F * (x2 - x3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n\n                    strategy_successes[strategy_index] += 1  # Increment success counter for the strategy\n                    successful_strategies += 1\n                    F_memory.append(F)\n                    CR_memory.append(CR)\n\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # Update strategy success rates (SaDE adaptation)\n            if successful_strategies > 0:\n                 self.success_rates = 0.9 * self.success_rates + 0.1 * (strategy_successes / successful_strategies)\n            else:\n                self.success_rates = np.ones(self.num_strategies) / self.num_strategies\n\n            self.success_rates /= np.sum(self.success_rates)\n\n            # Memory update\n            if F_memory:\n                self.memory_F[strategy_index] = 0.9 * self.memory_F[strategy_index] + 0.1 * np.mean(F_memory)\n            if CR_memory:\n                self.memory_CR[strategy_index] = 0.9 * self.memory_CR[strategy_index] + 0.1 * np.mean(CR_memory)\n\n\n            # CMA-ES adaptation (simplified - only mean adaptation)\n            self.mean = np.mean(self.population, axis=0)\n            # Adjust step size - simplified version\n            if self.global_best_fitness < self.f_opt:\n                self.sigma *= 0.995\n            else:\n                self.sigma *= 1.005\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = 0.3 * (ub - lb)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "mutation", "theta_sampled": 0.27360488071239014, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "8da52d4a-3b60-4182-b857-befd9204b581", "fitness": 0.0, "name": "HybridDECMAPSO", "description": "Integrates Differential Evolution with CMA-ES and PSO-inspired velocity updates along with adaptive parameter control and a local search strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_initial=None, c_c_initial=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability  # Probability of performing a local search step\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters - initialized here, may be adapted later\n        self.sigma = 0.3  # Overall standard deviation, can be adapted\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = c_sigma_initial if c_sigma_initial is not None else (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = c_c_initial if c_c_initial is not None else (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        self.adaptive_F = True  # Adaptive F parameter\n        self.adaptive_CR = True #Adaptive CR parameter\n        self.F_memory = [self.F] * 10  # Memory for adaptive F\n        self.CR_memory = [self.CR] * 10 # Memory for adaptive CR\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive F and CR\n                if self.adaptive_F:\n                    self.F = np.clip(np.random.normal(np.mean(self.F_memory), 0.1), 0.1, 1.0)\n                if self.adaptive_CR:\n                    self.CR = np.clip(np.random.normal(np.mean(self.CR_memory), 0.1), 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO-inspired velocity update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - np.mean(self.population, axis=0)) / self.sigma)) # Changed mean to full population mean.\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - np.mean(self.population, axis=0)) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - np.mean(self.population, axis=0))[:, None] @ (x_mu[j] - np.mean(self.population, axis=0))[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            # Stagnation Restart Mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            # Keep track of F and CR values for adaptation\n            self.F_memory.append(self.F)\n            self.F_memory.pop(0)\n            self.CR_memory.append(self.CR)\n            self.CR_memory.pop(0)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDECMAPSO scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Differential Evolution with CMA-ES and PSO-inspired velocity updates along with adaptive parameter control and a local search strategy for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 local_search_probability=0.1, stagnation_threshold=500, c_sigma_initial=None, c_c_initial=None):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # Dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability  # Probability of performing a local search step\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n\n        # CMA-ES parameters - initialized here, may be adapted later\n        self.sigma = 0.3  # Overall standard deviation, can be adapted\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = c_sigma_initial if c_sigma_initial is not None else (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = c_c_initial if c_c_initial is not None else (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        self.adaptive_F = True  # Adaptive F parameter\n        self.adaptive_CR = True #Adaptive CR parameter\n        self.F_memory = [self.F] * 10  # Memory for adaptive F\n        self.CR_memory = [self.CR] * 10 # Memory for adaptive CR\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive F and CR\n                if self.adaptive_F:\n                    self.F = np.clip(np.random.normal(np.mean(self.F_memory), 0.1), 0.1, 1.0)\n                if self.adaptive_CR:\n                    self.CR = np.clip(np.random.normal(np.mean(self.CR_memory), 0.1), 0.1, 1.0)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant = self.population[i] + self.F * (x2 - x3)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluate trial vector\n                f_trial = func(trial)\n                self.budget -= 1\n\n                if f_trial < self.fitness[i]:\n                    self.fitness[i] = f_trial\n                    self.population[i] = trial\n\n                    # Update personal best\n                    if f_trial < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_trial\n                        self.personal_best_positions[i] = trial.copy()\n\n                    # Update global best\n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO-inspired velocity update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - np.mean(self.population, axis=0)) / self.sigma)) # Changed mean to full population mean.\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - np.mean(self.population, axis=0)) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - np.mean(self.population, axis=0))[:, None] @ (x_mu[j] - np.mean(self.population, axis=0))[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            # Stagnation Restart Mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n            # Keep track of F and CR values for adaptation\n            self.F_memory.append(self.F)\n            self.F_memory.pop(0)\n            self.CR_memory.append(self.CR)\n            self.CR_memory.pop(0)\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.12772045235646987, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "e1f98060-57dc-4164-8ec6-38231f294306", "fitness": 0.3195832313358666, "name": "AdaptivePopulationSearch", "description": "Adaptive Population-Based Search with Gaussian Perturbation and Simulated Annealing-inspired Acceptance.", "code": "import numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate a candidate solution using Gaussian perturbation\n                std_dev = 0.1 * (func.bounds.ub - func.bounds.lb)  # Adaptive step size\n                candidate = population[i] + np.random.normal(0, std_dev, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the candidate solution\n                f_candidate = func(candidate)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Simulated Annealing-inspired acceptance criterion\n                delta = f_candidate - fitness[i]\n                if delta < 0 or np.random.rand() < np.exp(-delta / temperature):\n                    population[i] = candidate\n                    fitness[i] = f_candidate\n\n                    # Update the best solution found so far\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n            if self.budget <= 0:\n                break\n            # Cool the temperature\n            temperature *= self.cooling_rate\n            if temperature < 0.0001:\n                temperature = 0.0001 #avoid temperature going to zero\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePopulationSearch scored 0.320 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Population-Based Search with Gaussian Perturbation and Simulated Annealing-inspired Acceptance.\n\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePopulationSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=50, initial_temp=1.0, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n\n    def __call__(self, func):\n        # Initialize population within bounds\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        best_index = np.argmin(fitness)\n        self.f_opt = fitness[best_index]\n        self.x_opt = population[best_index]\n\n        temperature = self.initial_temp\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Generate a candidate solution using Gaussian perturbation\n                std_dev = 0.1 * (func.bounds.ub - func.bounds.lb)  # Adaptive step size\n                candidate = population[i] + np.random.normal(0, std_dev, size=self.dim)\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the candidate solution\n                f_candidate = func(candidate)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                # Simulated Annealing-inspired acceptance criterion\n                delta = f_candidate - fitness[i]\n                if delta < 0 or np.random.rand() < np.exp(-delta / temperature):\n                    population[i] = candidate\n                    fitness[i] = f_candidate\n\n                    # Update the best solution found so far\n                    if f_candidate < self.f_opt:\n                        self.f_opt = f_candidate\n                        self.x_opt = candidate\n            if self.budget <= 0:\n                break\n            # Cool the temperature\n            temperature *= self.cooling_rate\n            if temperature < 0.0001:\n                temperature = 0.0001 #avoid temperature going to zero\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13793480804438663, 0.22804634586822536, 0.27904409962003196, 0.3164894277320467, 0.23140865405178146, 0.2741794355673154, 0.2513141110852368, 0.26453436429386334, 0.23444133383439203, 0.18391496291976084, 0.2869577553209782, 0.9988634385872337, 0.2722718271586012, 0.24376435751178993, 0.6371496628873421, 0.29704334138349053, 0.27227256675301537, 0.32599173064224374, 0.1836144511237201, 0.47242795233187607], "operator": "random_new", "theta_sampled": 0.322507164603568, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "eadb4dc9-b9d2-4a47-9cac-abd9dfd4b6c1", "fitness": 0.5648245479047291, "name": "EllipsoidalLocalSearch", "description": "Population-based algorithm with ellipsoidal exploration and adaptive covariance matrix adaptation, focusing on local search intensification.", "code": "import numpy as np\n\nclass EllipsoidalLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations  # Local search intensification\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.archive_x.extend(population)\n        self.archive_f.extend(fitness)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Select best individual as center\n            best_index = np.argmin(fitness)\n            center = population[best_index]\n            \n            # Estimate covariance matrix (or use identity matrix if population is degenerate)\n            if np.std(population, axis=0).sum() < 1e-6:\n                 cov = np.eye(self.dim)\n            else:\n                cov = np.cov(population.T)\n                #Regularize covariance matrix\n                cov = cov + 1e-6 * np.eye(self.dim)\n\n            # Generate new samples from ellipsoidal distribution\n            for _ in range(self.local_search_iterations): # Intensify local search\n                if eval_count >= self.budget:\n                  break\n\n                z = np.random.normal(0, 1, size=self.dim)\n                x = center + np.dot(np.linalg.cholesky(cov), z)\n\n                # Clip to bounds\n                x = np.clip(x, self.lb, self.ub)\n                \n                f = func(x)\n                eval_count += 1\n\n                self.archive_x.append(x)\n                self.archive_f.append(f)\n\n                # Update population (replace worst with new if better)\n                worst_index = np.argmax(fitness)\n                if f < fitness[worst_index]:\n                    population[worst_index] = x\n                    fitness[worst_index] = f\n                    \n                # Update overall best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm EllipsoidalLocalSearch scored 0.565 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with ellipsoidal exploration and adaptive covariance matrix adaptation, focusing on local search intensification.\n# Code:\n```python\nimport numpy as np\n\nclass EllipsoidalLocalSearch:\n    def __init__(self, budget=10000, dim=10, pop_size=20, local_search_iterations=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.local_search_iterations = local_search_iterations  # Local search intensification\n        self.lb = -5.0\n        self.ub = 5.0\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.archive_x = []\n        self.archive_f = []\n        \n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.archive_x.extend(population)\n        self.archive_f.extend(fitness)\n        \n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Select best individual as center\n            best_index = np.argmin(fitness)\n            center = population[best_index]\n            \n            # Estimate covariance matrix (or use identity matrix if population is degenerate)\n            if np.std(population, axis=0).sum() < 1e-6:\n                 cov = np.eye(self.dim)\n            else:\n                cov = np.cov(population.T)\n                #Regularize covariance matrix\n                cov = cov + 1e-6 * np.eye(self.dim)\n\n            # Generate new samples from ellipsoidal distribution\n            for _ in range(self.local_search_iterations): # Intensify local search\n                if eval_count >= self.budget:\n                  break\n\n                z = np.random.normal(0, 1, size=self.dim)\n                x = center + np.dot(np.linalg.cholesky(cov), z)\n\n                # Clip to bounds\n                x = np.clip(x, self.lb, self.ub)\n                \n                f = func(x)\n                eval_count += 1\n\n                self.archive_x.append(x)\n                self.archive_f.append(f)\n\n                # Update population (replace worst with new if better)\n                worst_index = np.argmax(fitness)\n                if f < fitness[worst_index]:\n                    population[worst_index] = x\n                    fitness[worst_index] = f\n                    \n                # Update overall best\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.11584458897981764, 0.6492941810164716, 0.702463975200461, 0.9768049451323263, 0.7150129237303909, 0.2002907910858116, 0.3495029553684088, 0.3552433816411602, 0.25092383130822127, 0.35363498222373113, 0.9773113744008982, 0.9997608026009789, 0.5648150008606108, 0.3757084440534103, 0.9256402644067144, 0.6946927580489903, 0.41935024318018777, 0.9504225150413177, 0.23617598882305602, 0.4835970109916162], "operator": "random_new", "theta_sampled": 0.20720338025607543, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "da0982cc-88ed-445c-8191-a277431cf608", "fitness": 0.0, "name": "HybridDEPSOCMANM", "description": "A hybrid algorithm combining Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and adaptive parameter control, with Nelder-Mead local search as a refinement step.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPSOCMANM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 success_rate_window=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate_window = success_rate_window\n        self.success_history = []\n        self.adaptive_F = F\n        self.adaptive_CR = CR\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.adaptive_F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.adaptive_CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search with Nelder-Mead for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > self.dim + 1:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                def local_objective(x):\n                    return func(x)\n\n                bounds = [(lb, ub)] * self.dim\n                result = minimize(local_objective, best_individual, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget // 10})  # Reduce budget for local search\n                \n                if result.success:\n                    local_f = result.fun\n                    local_trial = result.x\n\n                    self.budget -= result.nfev  # reduce budget\n                    \n                    if local_f < self.fitness[best_idx]:\n                        self.fitness[best_idx] = local_f\n                        self.population[best_idx] = local_trial\n\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial\n                else:\n                    self.budget -= (self.budget // 10)\n\n            # Adaptive F and CR using success history\n            if len(self.success_history) >= self.success_rate_window:\n                success_rate = np.mean(self.success_history[-self.success_rate_window:])\n                if success_rate > 0.2:\n                    self.adaptive_F *= 0.95\n                    self.adaptive_CR *= 1.05\n                else:\n                    self.adaptive_F *= 1.05\n                    self.adaptive_CR *= 0.95\n\n                self.adaptive_F = np.clip(self.adaptive_F, 0.1, 0.9)\n                self.adaptive_CR = np.clip(self.adaptive_CR, 0.1, 0.99)\n\n            # Update success history\n            self.success_history.append(self.global_best_fitness < old_best_fitness)\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                self.success_history = []  # Reset success history after restart\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["3c7a740a-0bec-4756-ab2e-f59a12959eec"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and adaptive parameter control, with Nelder-Mead local search as a refinement step.\n\n# Code:\n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPSOCMANM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 success_rate_window=50):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate_window = success_rate_window\n        self.success_history = []\n        self.adaptive_F = F\n        self.adaptive_CR = CR\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.adaptive_F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.adaptive_CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search with Nelder-Mead for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > self.dim + 1:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                def local_objective(x):\n                    return func(x)\n\n                bounds = [(lb, ub)] * self.dim\n                result = minimize(local_objective, best_individual, method='Nelder-Mead', bounds=bounds, options={'maxfev': self.budget // 10})  # Reduce budget for local search\n                \n                if result.success:\n                    local_f = result.fun\n                    local_trial = result.x\n\n                    self.budget -= result.nfev  # reduce budget\n                    \n                    if local_f < self.fitness[best_idx]:\n                        self.fitness[best_idx] = local_f\n                        self.population[best_idx] = local_trial\n\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial\n                else:\n                    self.budget -= (self.budget // 10)\n\n            # Adaptive F and CR using success history\n            if len(self.success_history) >= self.success_rate_window:\n                success_rate = np.mean(self.success_history[-self.success_rate_window:])\n                if success_rate > 0.2:\n                    self.adaptive_F *= 0.95\n                    self.adaptive_CR *= 1.05\n                else:\n                    self.adaptive_F *= 1.05\n                    self.adaptive_CR *= 0.95\n\n                self.adaptive_F = np.clip(self.adaptive_F, 0.1, 0.9)\n                self.adaptive_CR = np.clip(self.adaptive_CR, 0.1, 0.99)\n\n            # Update success history\n            self.success_history.append(self.global_best_fitness < old_best_fitness)\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                self.success_history = []  # Reset success history after restart\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.014573128874029496, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "f9dfe81b-26a6-456b-a042-7dbca69d0439", "fitness": 0.5282245363310991, "name": "HybridDEPSOCMA", "description": "A hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n            \n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEPSOCMA scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n            \n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability and self.budget > 0:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget > 0 and local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20352861837989122, 0.26029361384477323, 0.5913227155449101, 0.17597345558945965, 0.46003019555711566, 0.9358408999881804, 0.7397747064838148, 0.49619691939447164, 0.6737411056607836, 0.24200304056480382, 0.37362703941394837, 0.9987550341225085, 0.30853425893475606, 0.35124363127420877, 0.90125218846303, 0.7576405088545489, 0.41011134775323865, 0.9636630695382379, 0.22199451328905484, 0.49896386397024595], "operator": "crossover", "theta_sampled": 0.30112070538654284, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "79f154cf-0af4-4ad5-ba84-6f74fef1c40f", "fitness": 0.37685869919516274, "name": "HybridDEPSOCMA", "description": "A hybrid DE-PSO-CMA-ES algorithm that combines differential evolution, particle swarm optimization, covariance matrix adaptation evolution strategy, and a local search for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, sigma_init_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.sigma_init_factor = sigma_init_factor # Factor for initializing CMA-ES sigma\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.sigma_init_factor * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation (applied after DE and PSO)\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.mean = np.mean(self.population, axis=0)\n                 self.stagnation_counter = 0 # Reset stagnation counter\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEPSOCMA scored 0.377 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid DE-PSO-CMA-ES algorithm that combines differential evolution, particle swarm optimization, covariance matrix adaptation evolution strategy, and a local search for improved exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 local_search_probability=0.1, stagnation_threshold=500, sigma_init_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.local_search_probability = local_search_probability\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.sigma_init_factor = sigma_init_factor # Factor for initializing CMA-ES sigma\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.sigma_init_factor * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation (applied after DE and PSO)\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.mean = np.mean(self.population, axis=0)\n                 self.stagnation_counter = 0 # Reset stagnation counter\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20829437715881238, 0.3603162675163568, 0.5544226680091606, 0.9644660418777316, 0.37056334480505737, 0.24535112212860433, 0.31145577206557884, 0], "operator": "crossover", "theta_sampled": 0.24943684613009234, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "3e45a4fb-04cb-4883-a3f7-0ad2fc41ba40", "fitness": 0.0, "name": "HybridDECMANM", "description": "Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and Nelder-Mead local search for enhanced exploration and exploitation, adaptively adjusting parameters based on fitness landscape.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMANM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_frequency=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.cma_frequency = cma_frequency  # Frequency of CMA-ES updates\n        self.nm_options = {'maxiter': 5, 'maxfev': 5}\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            generation += 1\n            if generation % self.cma_frequency == 0:\n                # Sort by fitness\n                idx_sorted = np.argsort(fitness)\n                population = population[idx_sorted]\n                fitness = fitness[idx_sorted]\n\n                # Selection and update mean\n                x_mu = population[:mu]\n                mean_new = np.mean(x_mu, axis=0)\n                \n                # Update evolution paths\n                ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n                pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n                # Update covariance matrix\n                C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n                for j in range(mu):\n                    C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n                \n                # Adjust step size\n                sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n                mean = mean_new\n                \n            # Local search (optional) for the best individual using Nelder-Mead\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Nelder-Mead local search\n                res = minimize(func, best_individual, method='Nelder-Mead', bounds=func.bounds, options=self.nm_options)\n\n                if res.fun < fitness[best_idx]:\n                    fitness[best_idx] = res.fun\n                    population[best_idx] = res.x\n                    self.budget -= res.nfev\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n\n            # Adjust mutation factor and crossover rate adaptively (optional)\n            self.mutation_factor = 0.2 + 0.6 * np.exp(-5 * generation / (self.budget + generation))  # Example adaptation\n            self.crossover_rate = 0.1 + 0.8 * np.exp(-5 * generation / (self.budget + generation)) # Example adaptation\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 7, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE) with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and Nelder-Mead local search for enhanced exploration and exploitation, adaptively adjusting parameters based on fitness landscape.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMANM:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_frequency=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.cma_frequency = cma_frequency  # Frequency of CMA-ES updates\n        self.nm_options = {'maxiter': 5, 'maxfev': 5}\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            generation += 1\n            if generation % self.cma_frequency == 0:\n                # Sort by fitness\n                idx_sorted = np.argsort(fitness)\n                population = population[idx_sorted]\n                fitness = fitness[idx_sorted]\n\n                # Selection and update mean\n                x_mu = population[:mu]\n                mean_new = np.mean(x_mu, axis=0)\n                \n                # Update evolution paths\n                ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n                pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n                # Update covariance matrix\n                C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n                for j in range(mu):\n                    C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n                \n                # Adjust step size\n                sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n                mean = mean_new\n                \n            # Local search (optional) for the best individual using Nelder-Mead\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Nelder-Mead local search\n                res = minimize(func, best_individual, method='Nelder-Mead', bounds=func.bounds, options=self.nm_options)\n\n                if res.fun < fitness[best_idx]:\n                    fitness[best_idx] = res.fun\n                    population[best_idx] = res.x\n                    self.budget -= res.nfev\n\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n\n            # Adjust mutation factor and crossover rate adaptively (optional)\n            self.mutation_factor = 0.2 + 0.6 * np.exp(-5 * generation / (self.budget + generation))  # Example adaptation\n            self.crossover_rate = 0.1 + 0.8 * np.exp(-5 * generation / (self.budget + generation)) # Example adaptation\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.4097280805759992, "reward": 0.0, "generation": 7}, "task_prompt": ""}
{"id": "44a96255-1f43-44e3-bad5-7a9bea43b4e6", "fitness": 0.20671869338873128, "name": "HybridDERankCMAS", "description": "Integrates Differential Evolution with Covariance Matrix Adaptation using a rank-mu update strategy for the covariance matrix, incorporating a self-adaptive mutation factor and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDERankCMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 4 # Rank-mu update, selecting top 25%\n\n        # Adaptive Mutation Factor\n        mutation_factor_history = [self.mutation_factor]\n        adaptive_mutation_probability = 0.1  # Probability of adapting mutation factor\n\n        # Orthogonal Learning parameters\n        orthogonal_learning_probability = 0.1\n        num_samples_ol = 5  # Number of samples for orthogonal learning\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive Mutation Factor\n                if np.random.rand() < adaptive_mutation_probability:\n                    self.mutation_factor = np.random.uniform(0.1, 1.0) # Adapt the mutation factor\n                    mutation_factor_history.append(self.mutation_factor)\n                    if len(mutation_factor_history) > 10:\n                        mutation_factor_history.pop(0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean (Rank-mu update)\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix (Rank-mu update)\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            # Adjust step size\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Orthogonal Learning for the best individual\n            if np.random.rand() < orthogonal_learning_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                # Generate orthogonal samples around the best individual\n                H = np.random.randn(self.dim, self.dim)\n                Q, _ = np.linalg.qr(H)  # Orthogonal matrix\n\n                for k in range(num_samples_ol):\n                    direction = Q[:, k % self.dim]\n                    step_size = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb)) # Smaller step size\n                    orthogonal_trial = best_individual + step_size * direction\n                    orthogonal_trial = np.clip(orthogonal_trial, lb, ub)\n\n                    orthogonal_f = func(orthogonal_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if orthogonal_f < fitness[best_idx]:\n                        fitness[best_idx] = orthogonal_f\n                        population[best_idx] = orthogonal_trial\n\n                        if orthogonal_f < self.f_opt:\n                            self.f_opt = orthogonal_f\n                            self.x_opt = orthogonal_trial\n                            \n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDERankCMAS scored 0.207 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates Differential Evolution with Covariance Matrix Adaptation using a rank-mu update strategy for the covariance matrix, incorporating a self-adaptive mutation factor and orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDERankCMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 4 # Rank-mu update, selecting top 25%\n\n        # Adaptive Mutation Factor\n        mutation_factor_history = [self.mutation_factor]\n        adaptive_mutation_probability = 0.1  # Probability of adapting mutation factor\n\n        # Orthogonal Learning parameters\n        orthogonal_learning_probability = 0.1\n        num_samples_ol = 5  # Number of samples for orthogonal learning\n\n        while self.budget > 0:\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Adaptive Mutation Factor\n                if np.random.rand() < adaptive_mutation_probability:\n                    self.mutation_factor = np.random.uniform(0.1, 1.0) # Adapt the mutation factor\n                    mutation_factor_history.append(self.mutation_factor)\n                    if len(mutation_factor_history) > 10:\n                        mutation_factor_history.pop(0)\n\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n\n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean (Rank-mu update)\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix (Rank-mu update)\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            # Adjust step size\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Orthogonal Learning for the best individual\n            if np.random.rand() < orthogonal_learning_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                # Generate orthogonal samples around the best individual\n                H = np.random.randn(self.dim, self.dim)\n                Q, _ = np.linalg.qr(H)  # Orthogonal matrix\n\n                for k in range(num_samples_ol):\n                    direction = Q[:, k % self.dim]\n                    step_size = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb)) # Smaller step size\n                    orthogonal_trial = best_individual + step_size * direction\n                    orthogonal_trial = np.clip(orthogonal_trial, lb, ub)\n\n                    orthogonal_f = func(orthogonal_trial)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n\n                    if orthogonal_f < fitness[best_idx]:\n                        fitness[best_idx] = orthogonal_f\n                        population[best_idx] = orthogonal_trial\n\n                        if orthogonal_f < self.f_opt:\n                            self.f_opt = orthogonal_f\n                            self.x_opt = orthogonal_trial\n                            \n            # Local search (optional)\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20528387243825208, 0.41487220772794176, 0], "operator": "mutation", "theta_sampled": 0.08833083591965432, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "6107a88d-97a8-4b92-9002-e78e4d6f1fc3", "fitness": 0.0, "name": "AdaptiveGradientSearch", "description": "An adaptive gradient-based search algorithm with dynamic step size and exploration noise.", "code": "import numpy as np\n\nclass AdaptiveGradientSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, exploration_noise=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = learning_rate\n        self.exploration_noise = exploration_noise\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            # Calculate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = 1e-4  # Step size for finite differences\n                x_plus[i] += delta\n                x_minus[i] -= delta\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                eval_count += 2\n                \n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n            # Normalize gradient\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                gradient = gradient / gradient_norm\n\n            # Update position with adaptive step size and exploration noise\n            step_size = self.learning_rate * np.exp(-eval_count / self.budget * 5) # Decay learning rate\n            x = x - step_size * gradient + self.exploration_noise * np.random.normal(0, 1, self.dim) # Add noise\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x)\n            eval_count += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            if eval_count >= self.budget:\n                break\n            \n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveGradientSearch scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive gradient-based search algorithm with dynamic step size and exploration noise.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGradientSearch:\n    def __init__(self, budget=10000, dim=10, learning_rate=0.1, exploration_noise=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = learning_rate\n        self.exploration_noise = exploration_noise\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            # Calculate gradient using finite differences\n            gradient = np.zeros(self.dim)\n            for i in range(self.dim):\n                x_plus = x.copy()\n                x_minus = x.copy()\n                delta = 1e-4  # Step size for finite differences\n                x_plus[i] += delta\n                x_minus[i] -= delta\n                \n                f_plus = func(x_plus)\n                f_minus = func(x_minus)\n                eval_count += 2\n                \n                gradient[i] = (f_plus - f_minus) / (2 * delta)\n\n            # Normalize gradient\n            gradient_norm = np.linalg.norm(gradient)\n            if gradient_norm > 0:\n                gradient = gradient / gradient_norm\n\n            # Update position with adaptive step size and exploration noise\n            step_size = self.learning_rate * np.exp(-eval_count / self.budget * 5) # Decay learning rate\n            x = x - step_size * gradient + self.exploration_noise * np.random.normal(0, 1, self.dim) # Add noise\n            \n            # Clip to bounds\n            x = np.clip(x, func.bounds.lb, func.bounds.ub)\n            \n            f = func(x)\n            eval_count += 1\n            \n            if f < self.f_opt:\n                self.f_opt = f\n                self.x_opt = x\n\n            if eval_count >= self.budget:\n                break\n            \n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": 0.1481913997364883, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "a32800ec-5446-4896-8011-31f5643b169d", "fitness": 0.0, "name": "AdaptiveLvyPerturbation", "description": "Exploration-Exploitation with Lvy flights and Gaussian perturbations, adjusting search range based on success.", "code": "import numpy as np\n\nclass AdaptiveLvyPerturbation:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.levy_exponent = levy_exponent\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_history = []\n\n\n    def levy_flight(self, beta):\n        \"\"\"\n        Generate a Lvy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        \n        for i in range(self.budget):\n            # Exploration with Lvy flight\n            levy_step = self.levy_flight(self.levy_exponent) * self.step_size\n            x_new_levy = self.x_opt + levy_step\n            x_new_levy = np.clip(x_new_levy, self.lb, self.ub)  # Ensure within bounds\n\n            f_new_levy = func(x_new_levy)\n\n            if f_new_levy < self.f_opt:\n                self.f_opt = f_new_levy\n                self.x_opt = x_new_levy\n                self.success_history.append(True)\n            else:\n                self.success_history.append(False)\n\n            # Exploitation with Gaussian perturbation\n            x_new_gauss = self.x_opt + np.random.normal(0, self.step_size/5, self.dim) #Smaller step\n            x_new_gauss = np.clip(x_new_gauss, self.lb, self.ub)\n\n            f_new_gauss = func(x_new_gauss)\n\n            if f_new_gauss < self.f_opt:\n                self.f_opt = f_new_gauss\n                self.x_opt = x_new_gauss\n                self.success_history.append(True)\n            else:\n                self.success_history.append(False)\n            \n            #Adaptive step size\n            if len(self.success_history) > 50:\n                success_rate = np.mean(self.success_history[-50:])\n                if success_rate > 0.4:\n                    self.step_size *= 1.1  # Increase step size if successful\n                elif success_rate < 0.1:\n                    self.step_size *= 0.8  # Decrease step size if unsuccessful\n                self.step_size = np.clip(self.step_size, self.initial_step_size/10, 1.0) #Limit stepsize\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Exploration-Exploitation with Lvy flights and Gaussian perturbations, adjusting search range based on success.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveLvyPerturbation:\n    def __init__(self, budget=10000, dim=10, initial_step_size=0.1, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.initial_step_size = initial_step_size\n        self.step_size = initial_step_size\n        self.levy_exponent = levy_exponent\n        self.lb = -5.0\n        self.ub = 5.0\n        self.success_history = []\n\n\n    def levy_flight(self, beta):\n        \"\"\"\n        Generate a Lvy flight step.\n        \"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = np.random.uniform(self.lb, self.ub, self.dim)\n        self.f_opt = func(self.x_opt)\n        \n        for i in range(self.budget):\n            # Exploration with Lvy flight\n            levy_step = self.levy_flight(self.levy_exponent) * self.step_size\n            x_new_levy = self.x_opt + levy_step\n            x_new_levy = np.clip(x_new_levy, self.lb, self.ub)  # Ensure within bounds\n\n            f_new_levy = func(x_new_levy)\n\n            if f_new_levy < self.f_opt:\n                self.f_opt = f_new_levy\n                self.x_opt = x_new_levy\n                self.success_history.append(True)\n            else:\n                self.success_history.append(False)\n\n            # Exploitation with Gaussian perturbation\n            x_new_gauss = self.x_opt + np.random.normal(0, self.step_size/5, self.dim) #Smaller step\n            x_new_gauss = np.clip(x_new_gauss, self.lb, self.ub)\n\n            f_new_gauss = func(x_new_gauss)\n\n            if f_new_gauss < self.f_opt:\n                self.f_opt = f_new_gauss\n                self.x_opt = x_new_gauss\n                self.success_history.append(True)\n            else:\n                self.success_history.append(False)\n            \n            #Adaptive step size\n            if len(self.success_history) > 50:\n                success_rate = np.mean(self.success_history[-50:])\n                if success_rate > 0.4:\n                    self.step_size *= 1.1  # Increase step size if successful\n                elif success_rate < 0.1:\n                    self.step_size *= 0.8  # Decrease step size if unsuccessful\n                self.step_size = np.clip(self.step_size, self.initial_step_size/10, 1.0) #Limit stepsize\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.10579057509919526, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "ccec7503-1355-4368-99e4-ae9d5159c3a5", "fitness": 0.4876261072264997, "name": "HybridDEPSOCMAOL", "description": "A hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES with adaptive parameter control and orthogonal learning to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMAOL:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 success_rate_window=50, ortho_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate_window = success_rate_window\n        self.success_history = []\n        self.ortho_trials = ortho_trials\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        num_improvements = 0\n        generation = 0\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n\n            # Orthogonal Learning\n            if generation % 5 == 0:\n                best_idx = np.argmin(self.fitness)\n                center = self.population[best_idx]\n                \n                # Generate orthogonal array (simplified for demonstration)\n                H = self.generate_orthogonal_array(self.dim, self.ortho_trials)\n                \n                for i in range(self.ortho_trials):\n                    trial_point = center + self.sigma * H[i]\n                    trial_point = np.clip(trial_point, lb, ub)\n                    \n                    f_trial = func(trial_point)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial_point.copy()\n                        self.stagnation_counter = 0\n\n            # Parameter Adaptation\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n\n            if len(self.success_history) > self.success_rate_window:\n                self.success_history.pop(0)\n\n            success_rate = np.mean(self.success_history) if self.success_history else 0\n\n            # Adjust parameters based on success rate\n            if success_rate > 0.6:\n                self.F = min(self.F + 0.01, 0.9)\n                self.CR = min(self.CR + 0.01, 1.0)\n                self.w = min(self.w + 0.01, 0.9)\n            elif success_rate < 0.3:\n                self.F = max(self.F - 0.01, 0.1)\n                self.CR = max(self.CR - 0.01, 0.1)\n                self.w = max(self.w - 0.01, 0.1)\n                self.sigma *= 1.1 #Increase exploration if success rate is low\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            generation += 1\n\n        return self.f_opt, self.x_opt\n    \n    def generate_orthogonal_array(self, dim, num_trials):\n        # In practice, use a proper orthogonal array generator\n        # This is a placeholder for demonstration purposes only.\n        return np.random.normal(0, 1, size=(num_trials, dim))", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDEPSOCMAOL scored 0.488 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["3c7a740a-0bec-4756-ab2e-f59a12959eec"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES with adaptive parameter control and orthogonal learning to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMAOL:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 success_rate_window=50, ortho_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate_window = success_rate_window\n        self.success_history = []\n        self.ortho_trials = ortho_trials\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        num_improvements = 0\n        generation = 0\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n\n            # Orthogonal Learning\n            if generation % 5 == 0:\n                best_idx = np.argmin(self.fitness)\n                center = self.population[best_idx]\n                \n                # Generate orthogonal array (simplified for demonstration)\n                H = self.generate_orthogonal_array(self.dim, self.ortho_trials)\n                \n                for i in range(self.ortho_trials):\n                    trial_point = center + self.sigma * H[i]\n                    trial_point = np.clip(trial_point, lb, ub)\n                    \n                    f_trial = func(trial_point)\n                    self.budget -= 1\n                    if self.budget <= 0:\n                        break\n                    \n                    if f_trial < self.global_best_fitness:\n                        self.global_best_fitness = f_trial\n                        self.global_best_position = trial_point.copy()\n                        self.stagnation_counter = 0\n\n            # Parameter Adaptation\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1\n                self.success_history.append(1)\n            else:\n                self.success_history.append(0)\n\n            if len(self.success_history) > self.success_rate_window:\n                self.success_history.pop(0)\n\n            success_rate = np.mean(self.success_history) if self.success_history else 0\n\n            # Adjust parameters based on success rate\n            if success_rate > 0.6:\n                self.F = min(self.F + 0.01, 0.9)\n                self.CR = min(self.CR + 0.01, 1.0)\n                self.w = min(self.w + 0.01, 0.9)\n            elif success_rate < 0.3:\n                self.F = max(self.F - 0.01, 0.1)\n                self.CR = max(self.CR - 0.01, 0.1)\n                self.w = max(self.w - 0.01, 0.1)\n                self.sigma *= 1.1 #Increase exploration if success rate is low\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n            \n            generation += 1\n\n        return self.f_opt, self.x_opt\n    \n    def generate_orthogonal_array(self, dim, num_trials):\n        # In practice, use a proper orthogonal array generator\n        # This is a placeholder for demonstration purposes only.\n        return np.random.normal(0, 1, size=(num_trials, dim))\n```", "aucs": [0.1495841780773155, 0.20136470703854825, 0.4781374740657557, 0.8965030217615015, 0.30108400912830435, 0.4838596990835652, 0.3469094874089538, 0.39213478581013295, 0.3740345177440735, 0.1935512319368483, 0.9557819478937392, 0.9972111363603535, 0.2915099142718356, 0.2639431832772339, 0.8940005391692224, 0.6808292551318174, 0.27976435660014587, 0.9218288533121881, 0.1986520745524385, 0.45183777190602137], "operator": "mutation", "theta_sampled": 0.3036388921104278, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "1f771e8d-c615-47b8-ac7b-7a63ac437593", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "A hybrid optimization algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES with adaptive parameter control, local search, and population diversity maintenance through a crowding distance mechanism.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3, crowding_distance_flag = True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma  # Initial CMA-ES step size\n        self.success_rate = 0.0 #Success rate for adaptive parameter control\n        self.crowding_distance_flag = crowding_distance_flag #Flag to enable crowding distance\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        num_improvements = 0 #For success rate calculation\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness #Store previous best fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            #Parameter Adaptation - Adaptive F and CR\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1 #Increment number of improvements\n                self.F = 0.5 + 0.4 * np.random.rand() # Adapt F\n                self.CR = 0.9 + 0.1 * np.random.rand() # Adapt CR\n            else:\n                 self.F = 0.5 #Revert back to original values\n                 self.CR = 0.9\n                 \n            # Crowding distance calculation and population maintenance\n            if self.crowding_distance_flag:\n                distances = self.calculate_crowding_distances(self.population)\n                min_dist_index = np.argmin(distances)\n                \n                # Replace the most crowded individual with a random one\n                self.population[min_dist_index] = np.random.uniform(lb, ub, size=self.dim)\n                f_rand = func(self.population[min_dist_index])\n                self.budget -= 1\n                self.fitness[min_dist_index] = f_rand\n                \n                if f_rand < self.personal_best_fitness[min_dist_index]:\n                    self.personal_best_fitness[min_dist_index] = f_rand\n                    self.personal_best_positions[min_dist_index] = self.population[min_dist_index].copy()\n\n                if f_rand < self.global_best_fitness:\n                        self.global_best_fitness = f_rand\n                        self.global_best_position = self.population[min_dist_index].copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n\n    def calculate_crowding_distances(self, population):\n        \"\"\"\n        Calculates the crowding distance for each individual in the population.\n        \"\"\"\n        distances = np.zeros(len(population))\n        for i in range(self.dim):\n            # Sort population based on the i-th dimension\n            sorted_indices = np.argsort(population[:, i])\n            \n            # Boundary individuals have maximum crowding distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            \n            # Calculate crowding distance for the remaining individuals\n            for j in range(1, len(population) - 1):\n                distances[sorted_indices[j]] += (population[sorted_indices[j+1], i] - population[sorted_indices[j-1], i]) / (self.ub - self.lb)\n        \n        return distances", "configspace": "", "generation": 8, "feedback": "", "error": "Evaluation error: 'HybridDEPSOCMA' object has no attribute 'ub'", "parent_ids": ["3c7a740a-0bec-4756-ab2e-f59a12959eec"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid optimization algorithm combining Differential Evolution, Particle Swarm Optimization, CMA-ES with adaptive parameter control, local search, and population diversity maintenance through a crowding distance mechanism.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3, crowding_distance_flag = True):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma  # Initial CMA-ES step size\n        self.success_rate = 0.0 #Success rate for adaptive parameter control\n        self.crowding_distance_flag = crowding_distance_flag #Flag to enable crowding distance\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        num_improvements = 0 #For success rate calculation\n\n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness #Store previous best fitness\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            #Parameter Adaptation - Adaptive F and CR\n            if self.global_best_fitness < old_best_fitness:\n                num_improvements += 1 #Increment number of improvements\n                self.F = 0.5 + 0.4 * np.random.rand() # Adapt F\n                self.CR = 0.9 + 0.1 * np.random.rand() # Adapt CR\n            else:\n                 self.F = 0.5 #Revert back to original values\n                 self.CR = 0.9\n                 \n            # Crowding distance calculation and population maintenance\n            if self.crowding_distance_flag:\n                distances = self.calculate_crowding_distances(self.population)\n                min_dist_index = np.argmin(distances)\n                \n                # Replace the most crowded individual with a random one\n                self.population[min_dist_index] = np.random.uniform(lb, ub, size=self.dim)\n                f_rand = func(self.population[min_dist_index])\n                self.budget -= 1\n                self.fitness[min_dist_index] = f_rand\n                \n                if f_rand < self.personal_best_fitness[min_dist_index]:\n                    self.personal_best_fitness[min_dist_index] = f_rand\n                    self.personal_best_positions[min_dist_index] = self.population[min_dist_index].copy()\n\n                if f_rand < self.global_best_fitness:\n                        self.global_best_fitness = f_rand\n                        self.global_best_position = self.population[min_dist_index].copy()\n                        self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n\n    def calculate_crowding_distances(self, population):\n        \"\"\"\n        Calculates the crowding distance for each individual in the population.\n        \"\"\"\n        distances = np.zeros(len(population))\n        for i in range(self.dim):\n            # Sort population based on the i-th dimension\n            sorted_indices = np.argsort(population[:, i])\n            \n            # Boundary individuals have maximum crowding distance\n            distances[sorted_indices[0]] = np.inf\n            distances[sorted_indices[-1]] = np.inf\n            \n            # Calculate crowding distance for the remaining individuals\n            for j in range(1, len(population) - 1):\n                distances[sorted_indices[j]] += (population[sorted_indices[j+1], i] - population[sorted_indices[j-1], i]) / (self.ub - self.lb)\n        \n        return distances\n```", "operator": "mutation", "theta_sampled": 0.32999105875630674, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "33c25d2e-b7ea-4c3f-9e9b-85d643397e90", "fitness": 0.3752102322320434, "name": "HybridDECMAPSO", "description": "Combines Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), Particle Swarm Optimization (PSO), and a restart mechanism to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.mean = None  # Initialize mean for CMA-ES\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n                \n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - self.mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - self.mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDECMAPSO scored 0.375 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), Particle Swarm Optimization (PSO), and a restart mechanism to balance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.mean = None  # Initialize mean for CMA-ES\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n                \n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - self.mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - self.mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.mean = np.mean(self.population, axis=0)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19248869641477673, 0.3270283092115269, 0.8370394716167276, 0.16926811933219454, 0.725436796817035, 0], "operator": "crossover", "theta_sampled": 0.0012941033113034698, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "ab2b1e28-af32-41c4-9c15-108c53784913", "fitness": 0.5810980636994965, "name": "HybridDECMAPSO", "description": "A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO-inspired velocity updates, and a restart mechanism for robust black box optimization.", "code": "import numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update (velocity clamping may be needed)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDECMAPSO scored 0.581 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution, CMA-ES adaptation, PSO-inspired velocity updates, and a restart mechanism for robust black box optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update (velocity clamping may be needed)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19380270871222083, 0.26223354372614205, 0.6341986554768974, 0.4518890524162459, 0.5706173620810266, 0.9478039095691724, 0.3451914972838379, 0.6407115026210912, 0.5457345387105874, 0.19949752250458141, 0.9441864346464336, 0.9986430163534131, 0.27740634949556087, 0.7290104560344055, 0.9138121170739428, 0.9042440120132165, 0.7028529924979685, 0.6542786562120853, 0.19893474419189938, 0.5069122023692028], "operator": "crossover", "theta_sampled": 0.059118550833637463, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "bcb803a5-e33d-4569-a752-40fdf3cbdb01", "fitness": 0.1631397305144383, "name": "HybridDECMAAdaptiveLS", "description": "A hybrid Differential Evolution and CMA-ES algorithm with adaptive parameter control and a local search component for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDECMAAdaptiveLS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, stagnation_threshold=500, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # PSO initialization\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n        velocities = np.zeros_like(population)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget/self.pop_size + generation))\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution part\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial.copy()\n\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                    \n                else:\n                    self.stagnation_counter +=1 #Increment stagnation\n\n\n                # PSO update\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                velocities[i] = inertia + cognitive + social\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                # Evaluate updated position\n                f_pso = func(population[i])\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_pso < fitness[i]:\n                    fitness[i] = f_pso\n                    if f_pso < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_pso\n                        personal_best_positions[i] = population[i].copy()\n                    if f_pso < global_best_fitness:\n                        global_best_fitness = f_pso\n                        global_best_position = population[i].copy()\n                        self.stagnation_counter = 0\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial\n                        self.stagnation_counter = 0\n            \n            #Restart Mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_index = np.argmin(fitness)\n                global_best_position = population[best_index].copy()\n                global_best_fitness = fitness[best_index]\n                velocities = np.zeros_like(population)\n                self.stagnation_counter = 0\n                mean = np.mean(population, axis=0)\n                sigma = 0.3 * (ub - lb) #overall standard deviation\n                C = np.eye(self.dim)  # Covariance matrix\n                pc = np.zeros(self.dim) # Evolution path for C\n                ps = np.zeros(self.dim)\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDECMAAdaptiveLS scored 0.163 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid Differential Evolution and CMA-ES algorithm with adaptive parameter control and a local search component for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDECMAAdaptiveLS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, stagnation_threshold=500, w_init=0.9, w_final=0.4, c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.w_init = w_init\n        self.w_final = w_final\n        self.c1 = c1\n        self.c2 = c2\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # PSO initialization\n        personal_best_positions = population.copy()\n        personal_best_fitness = fitness.copy()\n        best_index = np.argmin(fitness)\n        global_best_position = population[best_index].copy()\n        global_best_fitness = fitness[best_index]\n        velocities = np.zeros_like(population)\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_final) * (generation / (self.budget/self.pop_size + generation))\n            \n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution part\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f\n                        personal_best_positions[i] = trial.copy()\n\n                    if f < global_best_fitness:\n                        global_best_fitness = f\n                        global_best_position = trial.copy()\n                        self.stagnation_counter = 0\n                    \n                else:\n                    self.stagnation_counter +=1 #Increment stagnation\n\n\n                # PSO update\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i])\n                social = self.c2 * np.random.rand(self.dim) * (global_best_position - population[i])\n                \n                velocities[i] = inertia + cognitive + social\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                # Evaluate updated position\n                f_pso = func(population[i])\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_pso < fitness[i]:\n                    fitness[i] = f_pso\n                    if f_pso < personal_best_fitness[i]:\n                        personal_best_fitness[i] = f_pso\n                        personal_best_positions[i] = population[i].copy()\n                    if f_pso < global_best_fitness:\n                        global_best_fitness = f_pso\n                        global_best_position = population[i].copy()\n                        self.stagnation_counter = 0\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < global_best_fitness:\n                        global_best_fitness = local_f\n                        global_best_position = local_trial\n                        self.stagnation_counter = 0\n            \n            #Restart Mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                self.budget -= self.pop_size\n                personal_best_positions = population.copy()\n                personal_best_fitness = fitness.copy()\n                best_index = np.argmin(fitness)\n                global_best_position = population[best_index].copy()\n                global_best_fitness = fitness[best_index]\n                velocities = np.zeros_like(population)\n                self.stagnation_counter = 0\n                mean = np.mean(population, axis=0)\n                sigma = 0.3 * (ub - lb) #overall standard deviation\n                C = np.eye(self.dim)  # Covariance matrix\n                pc = np.zeros(self.dim) # Evolution path for C\n                ps = np.zeros(self.dim)\n\n            if global_best_fitness < self.f_opt:\n                self.f_opt = global_best_fitness\n                self.x_opt = global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14994542363671937, 0.17508045551660745, 0.3275330429044264, 0], "operator": "crossover", "theta_sampled": 0.2089832740319825, "reward": 0.0, "generation": 8}, "task_prompt": ""}
{"id": "933a7d7a-59c2-48f3-9e37-8b28ed2e263a", "fitness": 0.0, "name": "AdaDELevyRestart", "description": "Adaptive Differential Evolution with Lvy Flight mutation and a population restart mechanism.", "code": "import numpy as np\n\nclass AdaDELevyRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, levy_exponent=1.5, restart_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.levy_exponent = levy_exponent\n        self.restart_factor = restart_factor\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generate Lvy distribution samples.\n        \"\"\"\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v)**(1 / self.levy_exponent)\n        return step\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation using DE and Lvy flight\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                levy_step = self.levy_flight(self.dim)\n                mutant = pop[i] + self.F * (x_r1 - x_r2) + 0.01 * levy_step  # Add small levy flight component\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Restart mechanism\n            if generation % int(1 / self.restart_factor) == 0:  # Restart every few generations\n                # Replace a portion of the population with new random individuals\n                num_to_restart = int(self.restart_factor * self.pop_size)\n                restart_indices = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_restart, self.dim))\n                \n                # Evaluate the fitness of the restarted individuals\n                for i in restart_indices:\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with Lvy Flight mutation and a population restart mechanism.\n# Code:\n```python\nimport numpy as np\n\nclass AdaDELevyRestart:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.7, levy_exponent=1.5, restart_factor=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F\n        self.CR = CR\n        self.levy_exponent = levy_exponent\n        self.restart_factor = restart_factor\n\n    def levy_flight(self, size):\n        \"\"\"\n        Generate Lvy distribution samples.\n        \"\"\"\n        u = np.random.randn(size)\n        v = np.random.randn(size)\n        sigma = (np.math.gamma(1 + self.levy_exponent) * np.sin(np.pi * self.levy_exponent / 2) /\n                 (np.math.gamma((1 + self.levy_exponent) / 2) * self.levy_exponent * (2 ** ((self.levy_exponent - 1) / 2)))) ** (1 / self.levy_exponent)\n        step = sigma * u / abs(v)**(1 / self.levy_exponent)\n        return step\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n\n        best_idx = np.argmin(fitness)\n        self.f_opt = fitness[best_idx]\n        self.x_opt = pop[best_idx]\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            for i in range(self.pop_size):\n                # Mutation using DE and Lvy flight\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                levy_step = self.levy_flight(self.dim)\n                mutant = pop[i] + self.F * (x_r1 - x_r2) + 0.01 * levy_step  # Add small levy flight component\n\n                # Crossover\n                cross_mask = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_mask, mutant, pop[i])\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.budget -= 1\n                \n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    pop[i] = trial\n\n                    if f_trial < self.f_opt:\n                        self.f_opt = f_trial\n                        self.x_opt = trial\n            \n            # Restart mechanism\n            if generation % int(1 / self.restart_factor) == 0:  # Restart every few generations\n                # Replace a portion of the population with new random individuals\n                num_to_restart = int(self.restart_factor * self.pop_size)\n                restart_indices = np.random.choice(self.pop_size, num_to_restart, replace=False)\n                pop[restart_indices] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_restart, self.dim))\n                \n                # Evaluate the fitness of the restarted individuals\n                for i in restart_indices:\n                    fitness[i] = func(pop[i])\n                    self.budget -= 1\n                    if fitness[i] < self.f_opt:\n                        self.f_opt = fitness[i]\n                        self.x_opt = pop[i]\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.18703508915976774, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "0a3d648e-9923-4551-a955-e4b8bccda866", "fitness": 0.24733593180980698, "name": "HybridDEPSOCMA", "description": "Combines DE and PSO with CMA-ES adaptation, incorporating a local search and adaptive parameter control for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight for PSO\n            w = self.w_init - (self.w_init - self.w_end) * (generation / (self.budget / self.pop_size + generation))\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                    \n                # PSO Update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n            mean = mean_new\n\n            # Local Search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                mean = np.mean(self.population, axis=0)  # Reset CMA-ES mean too\n                \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm HybridDEPSOCMA scored 0.247 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE and PSO with CMA-ES adaptation, incorporating a local search and adaptive parameter control for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            # Adaptive inertia weight for PSO\n            w = self.w_init - (self.w_init - self.w_end) * (generation / (self.budget / self.pop_size + generation))\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                    \n                # PSO Update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n            mean = mean_new\n\n            # Local Search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                mean = np.mean(self.population, axis=0)  # Reset CMA-ES mean too\n                \n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.19599172414451882, 0.34097739966476015, 0.45237460342994895, 0], "operator": "crossover", "theta_sampled": 0.03360057565543672, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "dc0f06c0-495b-4cb6-90bf-8caab4b8978a", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a restart mechanism with adaptive parameter control based on stagnation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_initial=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_initial = w_initial # Initial inertia weight (PSO)\n        self.w_final = w_final # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial CMA-ES sigma\n        self.generation = 0  # Track the generation count\n        self.local_search_probability = 0.1 # Chance of local search\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # CMA-ES Initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = self.cma_sigma * (ub - lb)\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            self.generation += 1\n            # Adaptive inertia weight (PSO)\n            w = self.w_initial - (self.w_initial - self.w_final) * (self.generation / (self.budget / self.pop_size + self.generation))\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            # Adjust step size\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold or np.isnan(self.global_best_fitness): # Added NaN check\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                \n                # Reset CMA-ES parameters as well\n                mean = np.mean(self.population, axis=0)\n                sigma = self.cma_sigma * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n\n            # Global best update\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm HybridDEPSOCMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a restart mechanism with adaptive parameter control based on stagnation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_initial=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_initial = w_initial # Initial inertia weight (PSO)\n        self.w_final = w_final # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma # Initial CMA-ES sigma\n        self.generation = 0  # Track the generation count\n        self.local_search_probability = 0.1 # Chance of local search\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # CMA-ES Initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = self.cma_sigma * (ub - lb)\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            self.generation += 1\n            # Adaptive inertia weight (PSO)\n            w = self.w_initial - (self.w_initial - self.w_final) * (self.generation / (self.budget / self.pop_size + self.generation))\n\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            ps = (1 - c_sigma) * ps + np.sqrt(c_sigma * (2 - c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - c_c) * pc + np.sqrt(c_c * (2 - c_c)) * ((mean_new - mean) / sigma)\n\n            # Update covariance matrix\n            C = (1 - c_1 - c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            # Adjust step size\n            sigma *= np.exp((c_sigma / d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold or np.isnan(self.global_best_fitness): # Added NaN check\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                \n                # Reset CMA-ES parameters as well\n                mean = np.mean(self.population, axis=0)\n                sigma = self.cma_sigma * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n\n            # Global best update\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.2583722605524236, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "b89c5820-2068-41f0-afe3-8ce0aa2442c8", "fitness": 0.21840182564645402, "name": "AdaptiveHybridDECMAS", "description": "Adaptively adjusts mutation factor and crossover rate in DE based on population diversity and CMA-ES step size, integrating a simplified IPOP-CMA-ES restart strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_mutation_factor=0.5, initial_crossover_rate=0.7, local_search_probability=0.1, ipop_factor=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = initial_mutation_factor\n        self.crossover_rate = initial_crossover_rate\n        self.local_search_probability = local_search_probability\n        self.ipop_factor = ipop_factor\n        self.sub_population_size = self.pop_size\n        self.population = None\n        self.fitness = None\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_cmaes_parameters(self):\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.c_sigma = (np.sqrt(self.sub_population_size)/(np.sqrt(self.sub_population_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.sub_population_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.sub_population_size)/(np.sqrt(self.sub_population_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.sub_population_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.sub_population_size - 2 + 1/(self.sub_population_size))/( (self.dim + 2)**2 + self.sub_population_size))\n        self.mu = self.sub_population_size // 2\n        \n    def update_cmaes(self):\n        idx_sorted = np.argsort(self.fitness)\n        self.population = self.population[idx_sorted]\n        self.fitness = self.fitness[idx_sorted]\n\n        x_mu = self.population[:self.mu]\n        mean_new = np.mean(x_mu, axis=0)\n        \n        self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n        self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n        self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n        for j in range(self.mu):\n            self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n        \n        self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n        self.mean = mean_new\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.initialize_cmaes_parameters()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive Mutation Factor and Crossover Rate\n            diversity = np.std(self.fitness)  # Population diversity\n            self.mutation_factor = 0.2 + 0.6 * np.exp(-5 * diversity) # Mutation decreases with better fitness\n            self.crossover_rate = 0.1 + 0.8 * np.exp(-5 * diversity) # Crossover also decreases with better fitness\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = self.population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, self.lb, self.ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            self.update_cmaes()\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (self.ub - self.lb), 0.01 * (self.ub - self.lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, self.lb, self.ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            #IPOP strategy based on stagnation (simplified)\n            if generation % 50 == 0 and diversity < 1e-5:\n                # Restart with increased population size\n                self.pop_size = int(self.pop_size * self.ipop_factor)\n                self.sub_population_size = self.pop_size\n                \n                # Limit the population size to avoid excessive memory usage\n                self.pop_size = min(self.pop_size, 50 * self.dim)\n                self.sub_population_size = self.pop_size\n                \n\n                # Reinitialize the population\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.initialize_cmaes_parameters()\n\n                if self.budget <= 0:\n                    break\n        \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridDECMAS scored 0.218 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptively adjusts mutation factor and crossover rate in DE based on population diversity and CMA-ES step size, integrating a simplified IPOP-CMA-ES restart strategy.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, initial_mutation_factor=0.5, initial_crossover_rate=0.7, local_search_probability=0.1, ipop_factor=2):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = initial_mutation_factor\n        self.crossover_rate = initial_crossover_rate\n        self.local_search_probability = local_search_probability\n        self.ipop_factor = ipop_factor\n        self.sub_population_size = self.pop_size\n        self.population = None\n        self.fitness = None\n        self.mean = None\n        self.sigma = None\n        self.C = None\n        self.pc = None\n        self.ps = None\n        self.lb = None\n        self.ub = None\n\n    def initialize_cmaes_parameters(self):\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.c_sigma = (np.sqrt(self.sub_population_size)/(np.sqrt(self.sub_population_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.sub_population_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.sub_population_size)/(np.sqrt(self.sub_population_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.sub_population_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.sub_population_size - 2 + 1/(self.sub_population_size))/( (self.dim + 2)**2 + self.sub_population_size))\n        self.mu = self.sub_population_size // 2\n        \n    def update_cmaes(self):\n        idx_sorted = np.argsort(self.fitness)\n        self.population = self.population[idx_sorted]\n        self.fitness = self.fitness[idx_sorted]\n\n        x_mu = self.population[:self.mu]\n        mean_new = np.mean(x_mu, axis=0)\n        \n        self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n        self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n        self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n        for j in range(self.mu):\n            self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n        \n        self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n        self.mean = mean_new\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        \n        self.initialize_cmaes_parameters()\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Adaptive Mutation Factor and Crossover Rate\n            diversity = np.std(self.fitness)  # Population diversity\n            self.mutation_factor = 0.2 + 0.6 * np.exp(-5 * diversity) # Mutation decreases with better fitness\n            self.crossover_rate = 0.1 + 0.8 * np.exp(-5 * diversity) # Crossover also decreases with better fitness\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = self.population[idxs]\n                mutant = self.population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, self.lb, self.ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < self.fitness[i]:\n                    self.fitness[i] = f\n                    self.population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            \n            self.update_cmaes()\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (self.ub - self.lb), 0.01 * (self.ub - self.lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, self.lb, self.ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            #IPOP strategy based on stagnation (simplified)\n            if generation % 50 == 0 and diversity < 1e-5:\n                # Restart with increased population size\n                self.pop_size = int(self.pop_size * self.ipop_factor)\n                self.sub_population_size = self.pop_size\n                \n                # Limit the population size to avoid excessive memory usage\n                self.pop_size = min(self.pop_size, 50 * self.dim)\n                self.sub_population_size = self.pop_size\n                \n\n                # Reinitialize the population\n                self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.initialize_cmaes_parameters()\n\n                if self.budget <= 0:\n                    break\n        \n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.08821909150651897, 0.19770637508837297, 0.567888445942512, 0.2483372969632507, 0.2082597443780695, 0], "operator": "mutation", "theta_sampled": 0.05049405172166871, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "5f30b9b8-a8dc-4770-be7f-538ae70d7b46", "fitness": 0.3031444303626907, "name": "AdaDECMAS", "description": "A population-based algorithm with adaptive exploration-exploitation balance using a combination of differential evolution and covariance matrix adaptation evolution strategy.", "code": "import numpy as np\n\nclass AdaDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_strategy=\"rand1bin\", cma_sigma=0.1, cma_lr=0.2, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_strategy = de_strategy\n        self.cma_sigma = cma_sigma\n        self.cma_lr = cma_lr\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        covariance = np.eye(self.dim)\n        \n        # Initialize adaptive parameter\n        exploration_prob = 0.5  # Initial probability of using DE\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if np.random.rand() < exploration_prob:  # Differential Evolution\n                    # DE mutation and crossover\n                    if self.de_strategy == \"rand1bin\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_r1, x_r2, x_r3 = population[idxs]\n                        mutant = x_r1 + 0.8 * (x_r2 - x_r3)\n                        \n                        j_rand = np.random.randint(self.dim)\n                        trial = np.copy(population[i])\n                        for j in range(self.dim):\n                            if np.random.rand() < 0.9 or j == j_rand:\n                                trial[j] = mutant[j]\n                                \n                    else: # other strategies can be added\n                        trial = np.copy(population[i])\n                    \n                    trial = np.clip(trial, self.lb, self.ub)\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    \n                    if f_trial < fitness[i]:\n                        new_population.append(trial)\n                        new_fitness.append(f_trial)\n                    else:\n                        new_population.append(population[i])\n                        new_fitness.append(fitness[i])\n                        \n                else:  # CMA-ES\n                    # CMA-ES sampling\n                    z = np.random.multivariate_normal(np.zeros(self.dim), covariance)\n                    x_new = mean + self.cma_sigma * z\n                    x_new = np.clip(x_new, self.lb, self.ub)\n                    f_new = func(x_new)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population.append(x_new)\n                        new_fitness.append(f_new)\n                        \n                        # Update CMA-ES parameters\n                        mean = (1 - self.cma_lr) * mean + self.cma_lr * x_new\n                        covariance = (1 - self.cma_lr) * covariance + self.cma_lr * np.outer(x_new - mean, x_new - mean) / (self.cma_sigma**2)\n\n                    else:\n                        new_population.append(population[i])\n                        new_fitness.append(fitness[i])\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n            # Adaptive adjustment of exploration probability\n            improvement_ratio = np.sum(new_fitness < fitness) / self.pop_size\n            exploration_prob = max(0.1, min(0.9, exploration_prob + self.adaptation_rate * (improvement_ratio - 0.5))) # Adjust exploration prob\n            \n            #Update optimal values\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaDECMAS scored 0.303 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A population-based algorithm with adaptive exploration-exploitation balance using a combination of differential evolution and covariance matrix adaptation evolution strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=20, de_strategy=\"rand1bin\", cma_sigma=0.1, cma_lr=0.2, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.de_strategy = de_strategy\n        self.cma_sigma = cma_sigma\n        self.cma_lr = cma_lr\n        self.adaptation_rate = adaptation_rate\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        covariance = np.eye(self.dim)\n        \n        # Initialize adaptive parameter\n        exploration_prob = 0.5  # Initial probability of using DE\n\n        self.f_opt = np.min(fitness)\n        self.x_opt = population[np.argmin(fitness)]\n\n        while self.budget > 0:\n            new_population = []\n            new_fitness = []\n\n            for i in range(self.pop_size):\n                if np.random.rand() < exploration_prob:  # Differential Evolution\n                    # DE mutation and crossover\n                    if self.de_strategy == \"rand1bin\":\n                        idxs = np.random.choice(self.pop_size, 3, replace=False)\n                        x_r1, x_r2, x_r3 = population[idxs]\n                        mutant = x_r1 + 0.8 * (x_r2 - x_r3)\n                        \n                        j_rand = np.random.randint(self.dim)\n                        trial = np.copy(population[i])\n                        for j in range(self.dim):\n                            if np.random.rand() < 0.9 or j == j_rand:\n                                trial[j] = mutant[j]\n                                \n                    else: # other strategies can be added\n                        trial = np.copy(population[i])\n                    \n                    trial = np.clip(trial, self.lb, self.ub)\n                    f_trial = func(trial)\n                    self.budget -= 1\n                    \n                    if f_trial < fitness[i]:\n                        new_population.append(trial)\n                        new_fitness.append(f_trial)\n                    else:\n                        new_population.append(population[i])\n                        new_fitness.append(fitness[i])\n                        \n                else:  # CMA-ES\n                    # CMA-ES sampling\n                    z = np.random.multivariate_normal(np.zeros(self.dim), covariance)\n                    x_new = mean + self.cma_sigma * z\n                    x_new = np.clip(x_new, self.lb, self.ub)\n                    f_new = func(x_new)\n                    self.budget -= 1\n\n                    if f_new < fitness[i]:\n                        new_population.append(x_new)\n                        new_fitness.append(f_new)\n                        \n                        # Update CMA-ES parameters\n                        mean = (1 - self.cma_lr) * mean + self.cma_lr * x_new\n                        covariance = (1 - self.cma_lr) * covariance + self.cma_lr * np.outer(x_new - mean, x_new - mean) / (self.cma_sigma**2)\n\n                    else:\n                        new_population.append(population[i])\n                        new_fitness.append(fitness[i])\n\n            population = np.array(new_population)\n            fitness = np.array(new_fitness)\n\n            # Adaptive adjustment of exploration probability\n            improvement_ratio = np.sum(new_fitness < fitness) / self.pop_size\n            exploration_prob = max(0.1, min(0.9, exploration_prob + self.adaptation_rate * (improvement_ratio - 0.5))) # Adjust exploration prob\n            \n            #Update optimal values\n            if np.min(fitness) < self.f_opt:\n                self.f_opt = np.min(fitness)\n                self.x_opt = population[np.argmin(fitness)]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13850866463772016, 0.17679388165952004, 0.3136657006308514, 0.23324101149488607, 0.23790378941235812, 0.31432796455707346, 0.2559348216167794, 0.2720761211928264, 0.23158788355682258, 0.15977163488831814, 0.15813515282979862, 0.9795735779375193, 0.26140783770316034, 0.241011034999295, 0.6352404089436605, 0.3045337384188399, 0.2464273852034793, 0.2883407420444549, 0.15250392144678027, 0.4619033340796683], "operator": "random_new", "theta_sampled": 0.1320928679624136, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "fb8c8032-b46d-47c6-9d34-970f4be5794b", "fitness": 0.4311791188056392, "name": "HybridDEPSOCMA", "description": "Combines DE, PSO, CMA-ES adaptation, and a local search strategy with dynamic parameter adjustment and population diversity maintenance for robust optimization.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.lb = None\n        self.ub = None\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, self.lb, self.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, self.lb, self.ub)\n\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (self.ub - self.lb), 0.01 * (self.ub - self.lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, self.lb, self.ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm HybridDEPSOCMA scored 0.431 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE, PSO, CMA-ES adaptation, and a local search strategy with dynamic parameter adjustment and population diversity maintenance for robust optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.lb = None\n        self.ub = None\n\n\n    def __call__(self, func):\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters initialization\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (self.ub - self.lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, self.lb, self.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, self.lb, self.ub)\n\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (self.ub - self.lb), 0.01 * (self.ub - self.lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, self.lb, self.ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2487107923999522, 0.21713354612929558, 0.616143690519175, 0.19836902267339673, 0.921822315423563, 0.9230323177192881, 0.23796020097024262, 0.51744018341584, 0], "operator": "crossover", "theta_sampled": 0.20174172025444556, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "ce119624-961f-4ed5-8568-98efa8b5b797", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, c_sigma_factor = 1.0, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor #scaling factor for c_sigma\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = self.c_sigma_factor * (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n            \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 \n                 # Reset CMA-ES parameters\n                 mean = np.mean(self.population, axis=0)\n                 sigma = 0.3 * (ub - lb)\n                 C = np.eye(self.dim)\n                 pc = np.zeros(self.dim)\n                 ps = np.zeros(self.dim)\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "", "error": "Evaluation error: 'NoneType' object cannot be interpreted as an integer", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for robust exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, c_sigma_factor = 1.0, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.c_sigma_factor = c_sigma_factor #scaling factor for c_sigma\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = self.c_sigma_factor * (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n            \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 \n                 # Reset CMA-ES parameters\n                 mean = np.mean(self.population, axis=0)\n                 sigma = 0.3 * (ub - lb)\n                 C = np.eye(self.dim)\n                 pc = np.zeros(self.dim)\n                 ps = np.zeros(self.dim)\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.25520111886246905, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "11daa6ae-d0db-4ff1-8a4d-3dd5b058da69", "fitness": 0.3223180244058523, "name": "AdaptiveHybridOptimizer", "description": "An adaptive population-based algorithm that combines aspects of differential evolution with local search, adjusting its search strategy based on performance feedback.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for strategy adaptation\n        self.population = None\n        self.fitness = None\n        self.strategy = 'DE'  # Initial strategy: DE or LocalSearch\n        self.success_rate = 0.5\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n\n            mutated = a + 0.5 * (b - c)\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            cross_points = np.random.rand(self.dim) < 0.1\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutated, self.population[i])\n\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = f\n                return True  # Indicate success\n        return False  # Indicate failure\n\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            x = self.population[i].copy()\n            step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n            for _ in range(5):  # Perform a few local search steps\n                direction = np.random.uniform(-1, 1, size=self.dim)\n                direction /= np.linalg.norm(direction)  # Normalize\n                new_x = x + step_size * direction\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f = func(new_x)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f\n                    return True  # Indicate success\n                else:\n                    step_size *= 0.9  # Reduce step size if no improvement\n        return False  # Indicate failure\n\n    def adapt_strategy(self, success):\n        if success:\n            self.success_rate = 0.9 * self.success_rate + 0.1\n        else:\n            self.success_rate = 0.9 * self.success_rate\n\n        if self.success_rate > 0.6 and self.strategy == 'LocalSearch':\n            self.strategy = 'DE'\n        elif self.success_rate < 0.4 and self.strategy == 'DE':\n            self.strategy = 'LocalSearch'\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            if self.strategy == 'DE':\n                success = self.differential_evolution(func)\n            else:\n                success = self.local_search(func)\n\n            self.adapt_strategy(success)\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridOptimizer scored 0.322 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive population-based algorithm that combines aspects of differential evolution with local search, adjusting its search strategy based on performance feedback.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget=10000, dim=10, pop_size=50, lr=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.lr = lr  # Learning rate for strategy adaptation\n        self.population = None\n        self.fitness = None\n        self.strategy = 'DE'  # Initial strategy: DE or LocalSearch\n        self.success_rate = 0.5\n\n    def initialize_population(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def differential_evolution(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n\n            mutated = a + 0.5 * (b - c)\n            mutated = np.clip(mutated, func.bounds.lb, func.bounds.ub)\n\n            cross_points = np.random.rand(self.dim) < 0.1\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n\n            trial = np.where(cross_points, mutated, self.population[i])\n\n            f = func(trial)\n            self.budget -= 1\n            if f < self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = f\n                return True  # Indicate success\n        return False  # Indicate failure\n\n\n    def local_search(self, func):\n        for i in range(self.pop_size):\n            if self.budget <= 0:\n                break\n\n            x = self.population[i].copy()\n            step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n            for _ in range(5):  # Perform a few local search steps\n                direction = np.random.uniform(-1, 1, size=self.dim)\n                direction /= np.linalg.norm(direction)  # Normalize\n                new_x = x + step_size * direction\n                new_x = np.clip(new_x, func.bounds.lb, func.bounds.ub)\n\n                f = func(new_x)\n                self.budget -= 1\n                if f < self.fitness[i]:\n                    self.population[i] = new_x\n                    self.fitness[i] = f\n                    return True  # Indicate success\n                else:\n                    step_size *= 0.9  # Reduce step size if no improvement\n        return False  # Indicate failure\n\n    def adapt_strategy(self, success):\n        if success:\n            self.success_rate = 0.9 * self.success_rate + 0.1\n        else:\n            self.success_rate = 0.9 * self.success_rate\n\n        if self.success_rate > 0.6 and self.strategy == 'LocalSearch':\n            self.strategy = 'DE'\n        elif self.success_rate < 0.4 and self.strategy == 'DE':\n            self.strategy = 'LocalSearch'\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            if self.strategy == 'DE':\n                success = self.differential_evolution(func)\n            else:\n                success = self.local_search(func)\n\n            self.adapt_strategy(success)\n\n            best_idx = np.argmin(self.fitness)\n            if self.fitness[best_idx] < self.f_opt:\n                self.f_opt = self.fitness[best_idx]\n                self.x_opt = self.population[best_idx]\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15505645195544437, 0.20043227578269696, 0.3907616752494615, 0.31920337570616486, 0.3192777449916784, 0.38891087625071064, 0.27794813795368756, 0.3376970265275899, 0.3046206793322803, 0.1925774002587184, 0.3043045378251087, 0.9993441354425383, 0], "operator": "random_new", "theta_sampled": 0.07684269585324655, "reward": 0.0, "generation": 9}, "task_prompt": ""}
{"id": "fb091806-44ca-4299-8ce5-6d97257b78ae", "fitness": 0.30972869973022404, "name": "HybridSANMS", "description": "A novel hybrid algorithm combining a modified Simulated Annealing with Nelder-Mead Simplex for efficient local search, periodically re-initialized to escape local optima.", "code": "import numpy as np\nimport scipy.optimize as spo\n\nclass HybridSANMS:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, temp_min=0.001, alpha=0.99, nm_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.temp_min = temp_min\n        self.alpha = alpha\n        self.nm_trials = nm_trials # number of Nelder-Mead trials\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        n_evals = 0\n        \n        # Initial solution\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        n_evals += 1\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.temp_init\n\n        while n_evals < self.budget:\n\n            # Simulated Annealing Step\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # Respect boundaries\n\n            f_new = func(x_new)\n            n_evals += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n            # Periodically apply Nelder-Mead Simplex for refinement\n            if n_evals % (self.budget // self.nm_trials) == 0:\n                try:\n                    res = spo.minimize(func, x, method='Nelder-Mead', options={'maxfev': (self.budget - n_evals)//self.nm_trials, 'maxiter': (self.budget - n_evals)//self.nm_trials})  # Smaller budget\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                    n_evals += res.nfev\n                    x = res.x\n                    f = res.fun\n                except Exception as e:\n                    print(f\"Nelder Mead Failed: {e}\")\n                    pass # Continue even if Nelder-Mead fails\n\n            temp *= self.alpha\n            temp = max(temp, self.temp_min)  # Ensure temperature doesn't go below minimum\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridSANMS scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: A novel hybrid algorithm combining a modified Simulated Annealing with Nelder-Mead Simplex for efficient local search, periodically re-initialized to escape local optima.\n# Code: \n```python\nimport numpy as np\nimport scipy.optimize as spo\n\nclass HybridSANMS:\n    def __init__(self, budget=10000, dim=10, temp_init=1.0, temp_min=0.001, alpha=0.99, nm_trials=5):\n        self.budget = budget\n        self.dim = dim\n        self.temp_init = temp_init\n        self.temp_min = temp_min\n        self.alpha = alpha\n        self.nm_trials = nm_trials # number of Nelder-Mead trials\n        self.x_opt = None\n        self.f_opt = np.inf\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        n_evals = 0\n        \n        # Initial solution\n        x = np.random.uniform(func.bounds.lb, func.bounds.ub, size=self.dim)\n        f = func(x)\n        n_evals += 1\n        self.f_opt = f\n        self.x_opt = x\n\n        temp = self.temp_init\n\n        while n_evals < self.budget:\n\n            # Simulated Annealing Step\n            x_new = x + np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n            x_new = np.clip(x_new, func.bounds.lb, func.bounds.ub) # Respect boundaries\n\n            f_new = func(x_new)\n            n_evals += 1\n\n            delta_f = f_new - f\n\n            if delta_f < 0 or np.random.rand() < np.exp(-delta_f / temp):\n                x = x_new\n                f = f_new\n\n                if f < self.f_opt:\n                    self.f_opt = f\n                    self.x_opt = x\n            \n\n            # Periodically apply Nelder-Mead Simplex for refinement\n            if n_evals % (self.budget // self.nm_trials) == 0:\n                try:\n                    res = spo.minimize(func, x, method='Nelder-Mead', options={'maxfev': (self.budget - n_evals)//self.nm_trials, 'maxiter': (self.budget - n_evals)//self.nm_trials})  # Smaller budget\n                    if res.fun < self.f_opt:\n                        self.f_opt = res.fun\n                        self.x_opt = res.x\n                    n_evals += res.nfev\n                    x = res.x\n                    f = res.fun\n                except Exception as e:\n                    print(f\"Nelder Mead Failed: {e}\")\n                    pass # Continue even if Nelder-Mead fails\n\n            temp *= self.alpha\n            temp = max(temp, self.temp_min)  # Ensure temperature doesn't go below minimum\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.04125172416895617, 0.18827695217184204, 0.4356345831737475, 0.197874060806428, 0.09689723974323172, 0.10887208455533892, 0.26472003344186146, 0.3834328162042341, 0.3805682826677691, 0.11205765349620511, 0.8309078167961619, 0.1945897728753727, 0.2617071096991326, 0.2626586400297506, 0.6255674254885327, 0.3833161299860236, 0.22485828765103788, 0.534457015996153, 0.17497184487174766, 0.4919545207809529], "operator": "random_new", "theta_sampled": 0.24768017251195174, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "2b66f153-bc69-4e15-9875-a9c23f86f2d7", "fitness": 0.0, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for robust global search and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSOCMA scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution, Particle Swarm Optimization, CMA-ES adaptation, and a restart mechanism for robust global search and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, cma_sigma=0.3, local_search_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.cma_sigma = cma_sigma\n        self.local_search_probability = local_search_probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n            \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0], "operator": "crossover", "theta_sampled": 0.19295344613782575, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "87c954a0-60e4-4bc5-b764-c9638027c9a5", "fitness": 0.2809191783366384, "name": "HybridDEPSOCMA", "description": "A hybrid algorithm combining Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a local search mechanism with dynamic parameter adaptation and restart strategies to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.generation = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget + self.generation)) # Dynamic inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                    \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n                u = np.clip(u, lb, ub)\n\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                \n                # Reset CMA-ES parameters\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = 0.3 * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSOCMA scored 0.281 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: A hybrid algorithm combining Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and a local search mechanism with dynamic parameter adaptation and restart strategies to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Initial inertia weight (PSO)\n        self.w_end = w_end  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.generation = 0\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        \n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget + self.generation)) # Dynamic inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                    \n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n                u = np.clip(u, lb, ub)\n\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.stagnation_counter = 0\n                \n                # Reset CMA-ES parameters\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = 0.3 * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1509435453016682, 0.37439330887079936, 0.598339859174086, 0], "operator": "crossover", "theta_sampled": 0.039540390114139665, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "d6fed248-023c-4f9e-ab24-82b0eec7c966", "fitness": 0.0862145213576676, "name": "HybridDEPSOCMA", "description": "Synergistically combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and restarts with local search to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None,\n                 mu_ratio=0.5,  # Ratio for selecting top individuals in CMA-ES\n                 stagnation_threshold=500, local_search_probability=0.1, local_search_sigma_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n\n        # CMA-ES parameters (dynamic calculation if None)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu_ratio = mu_ratio\n\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_sigma_scale = local_search_sigma_scale\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES Initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)  # Overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants (calculate if not provided)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        mu = int(self.pop_size * self.mu_ratio)\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1 - self.c_sigma) * ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - self.c_c) * pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            C = (1 - self.c_1 - self.c_mu) * C + self.c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n            mean = mean_new\n\n            # Local Search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.normal(0, self.local_search_sigma_scale * (ub - lb), size=self.dim) # Gaussian perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                # Reset CMA-ES parameters on restart\n                mean = np.mean(self.population, axis=0)\n                sigma = 0.3 * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSOCMA scored 0.086 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Synergistically combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and restarts with local search to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5,\n                 c_sigma=None, d_sigma=None, c_c=None, c_1=None, c_mu=None,\n                 mu_ratio=0.5,  # Ratio for selecting top individuals in CMA-ES\n                 stagnation_threshold=500, local_search_probability=0.1, local_search_sigma_scale=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n\n        # CMA-ES parameters (dynamic calculation if None)\n        self.c_sigma = c_sigma\n        self.d_sigma = d_sigma\n        self.c_c = c_c\n        self.c_1 = c_1\n        self.c_mu = c_mu\n        self.mu_ratio = mu_ratio\n\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.local_search_sigma_scale = local_search_sigma_scale\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # CMA-ES Initialization\n        mean = np.mean(self.population, axis=0)\n        sigma = 0.3 * (ub - lb)  # Overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim)  # Evolution path for C\n        ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants (calculate if not provided)\n        if self.c_sigma is None:\n            self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.d_sigma is None:\n            self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        if self.c_c is None:\n            self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        if self.c_1 is None:\n            self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        if self.c_mu is None:\n            self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        mu = int(self.pop_size * self.mu_ratio)\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES Adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            ps = (1 - self.c_sigma) * ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean) / sigma))\n            pc = (1 - self.c_c) * pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - mean) / sigma)\n\n            C = (1 - self.c_1 - self.c_mu) * C + self.c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += self.c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n\n            sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(ps) / np.sqrt(self.dim)) - 1))\n            mean = mean_new\n\n            # Local Search\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                perturbation = np.random.normal(0, self.local_search_sigma_scale * (ub - lb), size=self.dim) # Gaussian perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial.copy()\n                        self.stagnation_counter = 0\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                # Reset CMA-ES parameters on restart\n                mean = np.mean(self.population, axis=0)\n                sigma = 0.3 * (ub - lb)\n                C = np.eye(self.dim)\n                pc = np.zeros(self.dim)\n                ps = np.zeros(self.dim)\n                self.stagnation_counter = 0\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1724290427153352, 0], "operator": "crossover", "theta_sampled": -0.016282606026924964, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "a24735d8-990c-43ee-8493-78d82a97bbbd", "fitness": 0.5880234431248667, "name": "AdaptiveHybridDECMAPSO", "description": "A hybrid algorithm that combines Differential Evolution, CMA-ES, and Particle Swarm Optimization with adaptive parameter control and a covariance matrix adaptation guided mutation to improve exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) start\n        self.w_end = w_end  # Inertia weight (PSO) end\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_learning_rate = cma_learning_rate # Learning rate for CMA adaptation\n\n        self.best_fitness_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget / self.pop_size + generation)) # Adaptive inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update (velocity clamping may be needed)\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # CMA-ES guided mutation for local search\n                    z = np.random.randn(self.dim)\n                    perturbation = self.sigma * np.dot(np.linalg.cholesky(self.C), z)  # CMA-ES mutation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            self.best_fitness_history.append(self.f_opt)  # Store best fitness over time\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridDECMAPSO scored 0.588 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ab2b1e28-af32-41c4-9c15-108c53784913"], "operator": "mutation", "metadata": {"llm_response": "# Description: A hybrid algorithm that combines Differential Evolution, CMA-ES, and Particle Swarm Optimization with adaptive parameter control and a covariance matrix adaptation guided mutation to improve exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_start = w_start  # Inertia weight (PSO) start\n        self.w_end = w_end  # Inertia weight (PSO) end\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_learning_rate = cma_learning_rate # Learning rate for CMA adaptation\n\n        self.best_fitness_history = []\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        generation = 0\n        while self.budget > 0:\n            generation += 1\n            w = self.w_start - (self.w_start - self.w_end) * (generation / (self.budget / self.pop_size + generation)) # Adaptive inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update (velocity clamping may be needed)\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # CMA-ES guided mutation for local search\n                    z = np.random.randn(self.dim)\n                    perturbation = self.sigma * np.dot(np.linalg.cholesky(self.C), z)  # CMA-ES mutation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            self.best_fitness_history.append(self.f_opt)  # Store best fitness over time\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.35247422791425664, 0.40862941371546335, 0.908364375828258, 0.9837980855458246, 0.31759463199308025, 0.9511038712004246, 0.3872469974780456, 0.549808146979801, 0.3216430835487323, 0.22496029164173192, 0.9442245101259781, 0.9986195946382596, 0.2492541511481975, 0.5799478289185394, 0.7013558188219227, 0.891311286166809, 0.37332899045370993, 0.9200239641956466, 0.21109998415793707, 0.4856796080247162], "operator": "mutation", "theta_sampled": 0.2530148496910862, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "b40db985-d15c-418c-a3d9-cfa3db7f9cd2", "fitness": 0.5209146604714714, "name": "HybridDEPSO", "description": "Hybrid DEPSO with adaptive parameter control, velocity clipping, and a niching strategy to maintain diversity.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_max=0.9, w_min=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, velocity_clip=0.1, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_max = w_max  # Inertia weight (PSO) max value\n        self.w_min = w_min  # Inertia weight (PSO) min value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.velocity_clip = velocity_clip # Clip velocities to this fraction of search space\n        self.niche_radius = niche_radius # Radius for niching\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.velocities = np.zeros((self.pop_size, self.dim)) # Initialize velocities\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / self.budget)\n            \n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                self.velocities[i] = w * self.velocities[i] + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                # Velocity clipping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clip * (ub - lb), self.velocity_clip * (ub - lb))\n                \n                self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n\n                # Niching: Reduce fitness if too close to other particles\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(self.population[i] - self.population[j]) < self.niche_radius:\n                        self.fitness[i] *= 1.1  # Penalize fitness\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.velocities = np.zeros((self.pop_size, self.dim))\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSO scored 0.521 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Hybrid DEPSO with adaptive parameter control, velocity clipping, and a niching strategy to maintain diversity.\n# Code:\n```python\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F=0.5, CR=0.9, w_max=0.9, w_min=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, velocity_clip=0.1, niche_radius=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_max = w_max  # Inertia weight (PSO) max value\n        self.w_min = w_min  # Inertia weight (PSO) min value\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.velocity_clip = velocity_clip # Clip velocities to this fraction of search space\n        self.niche_radius = niche_radius # Radius for niching\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        self.velocities = np.zeros((self.pop_size, self.dim)) # Initialize velocities\n\n        while self.budget > 0:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.budget / self.budget)\n            \n            for i in range(self.pop_size):\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                self.velocities[i] = w * self.velocities[i] + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                # Velocity clipping\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clip * (ub - lb), self.velocity_clip * (ub - lb))\n                \n                self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n\n                # Niching: Reduce fitness if too close to other particles\n                for j in range(self.pop_size):\n                    if i != j and np.linalg.norm(self.population[i] - self.population[j]) < self.niche_radius:\n                        self.fitness[i] *= 1.1  # Penalize fitness\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.velocities = np.zeros((self.pop_size, self.dim))\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.2294585563646927, 0.42875234895292225, 0.4823551819151516, 0.8067356374018279, 0.5240998169476385, 0.6225012900315401, 0.3308122954251649, 0.43120974465338835, 0.49239865966937246, 0.19682915165552461, 0.8513287249958168, 0.9989279062741168, 0.2833865673120183, 0.4264475140263436, 0.8498818249679884, 0.5561648893220419, 0.4172705550108674, 0.713228651307265, 0.2721871317522315, 0.5043167614435144], "operator": "mutation", "theta_sampled": 0.24514035626366068, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "c5aa3fc3-1171-4188-a4dc-522826feb186", "fitness": 0.3728831649506386, "name": "AdaptiveHybridDECMAPSO", "description": "Adaptive Hybrid DE-CMA-PSO with Velocity Clamping and Aging, adjusting exploration/exploitation based on stagnation and fitness variance.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, velocity_clamp_factor=0.1, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init # Initial inertia weight (PSO)\n        self.w_final = w_final # Final inertia weight (PSO)\n        self.w = w_init\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.velocity_clamp_factor = velocity_clamp_factor  # Clamp velocity to this fraction of the search space\n        self.aging_rate = aging_rate # Rate at which fitness degrades\n        self.age = np.zeros(self.pop_size) # Age of each particle\n        self.exploration_rate = 0.5 # Probability of exploration vs exploitation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight (linearly decreasing)\n            self.w = self.w_init - (self.w_init - self.w_final) * (1 - self.budget / self.budget) # Normalized budget\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Exploration vs Exploitation using exploration_rate parameter\n                if np.random.rand() < self.exploration_rate:\n                    # Differential Evolution Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x2 - x3)\n\n                    # Crossover\n                    u = np.zeros(self.dim)\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            u[j] = v[j]\n                        else:\n                            u[j] = self.population[i][j]\n\n                    u = np.clip(u, lb, ub)\n                else:\n                    u = self.population[i].copy()\n                \n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0 # Reset age\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n                    self.age[i] += self.aging_rate  # Increase the age\n\n                # PSO update (velocity clamping may be needed)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                # Velocity clamping\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                velocity = np.clip(velocity, -max_velocity, max_velocity)\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        self.age[i] = 0 # Reset age\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n            # Age-based fitness degradation\n            self.fitness += self.age\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Stagnation detection using fitness variance\n            fitness_variance = np.var(self.fitness)\n\n            # Adaptive Exploration Rate Adjustment\n            if fitness_variance < 1e-6:\n                self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n            else:\n                self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.age = np.zeros(self.pop_size) # Reset ages\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridDECMAPSO scored 0.373 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["ab2b1e28-af32-41c4-9c15-108c53784913"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid DE-CMA-PSO with Velocity Clamping and Aging, adjusting exploration/exploitation based on stagnation and fitness variance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMAPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_init=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, velocity_clamp_factor=0.1, aging_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_init = w_init # Initial inertia weight (PSO)\n        self.w_final = w_final # Final inertia weight (PSO)\n        self.w = w_init\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.velocity_clamp_factor = velocity_clamp_factor  # Clamp velocity to this fraction of the search space\n        self.aging_rate = aging_rate # Rate at which fitness degrades\n        self.age = np.zeros(self.pop_size) # Age of each particle\n        self.exploration_rate = 0.5 # Probability of exploration vs exploitation\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n\n        while self.budget > 0:\n            # Adaptive Inertia Weight (linearly decreasing)\n            self.w = self.w_init - (self.w_init - self.w_final) * (1 - self.budget / self.budget) # Normalized budget\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Exploration vs Exploitation using exploration_rate parameter\n                if np.random.rand() < self.exploration_rate:\n                    # Differential Evolution Mutation\n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    v = self.population[i] + self.F * (x2 - x3)\n\n                    # Crossover\n                    u = np.zeros(self.dim)\n                    j_rand = np.random.randint(self.dim)\n                    for j in range(self.dim):\n                        if np.random.rand() < self.CR or j == j_rand:\n                            u[j] = v[j]\n                        else:\n                            u[j] = self.population[i][j]\n\n                    u = np.clip(u, lb, ub)\n                else:\n                    u = self.population[i].copy()\n                \n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n                    self.age[i] = 0 # Reset age\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n                    self.age[i] += self.aging_rate  # Increase the age\n\n                # PSO update (velocity clamping may be needed)\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                # Velocity clamping\n                max_velocity = self.velocity_clamp_factor * (ub - lb)\n                velocity = np.clip(velocity, -max_velocity, max_velocity)\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n                # Local search (optional) for the current individual\n                if np.random.rand() < self.local_search_probability and self.budget > 0:\n                    # Simple random perturbation local search\n                    perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                    local_trial = self.population[i] + perturbation\n                    local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                    \n                    local_f = func(local_trial)\n                    self.budget -= 1\n                    if local_f < self.fitness[i]:\n                        self.fitness[i] = local_f\n                        self.population[i] = local_trial\n                        self.age[i] = 0 # Reset age\n                        if local_f < self.global_best_fitness:\n                            self.global_best_fitness = local_f\n                            self.global_best_position = local_trial.copy()\n                            self.stagnation_counter = 0\n\n            # Age-based fitness degradation\n            self.fitness += self.age\n\n            # CMA-ES adaptation\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Stagnation detection using fitness variance\n            fitness_variance = np.var(self.fitness)\n\n            # Adaptive Exploration Rate Adjustment\n            if fitness_variance < 1e-6:\n                self.exploration_rate = min(1.0, self.exploration_rate + 0.1)  # Increase exploration\n            else:\n                self.exploration_rate = max(0.1, self.exploration_rate - 0.05)  # Decrease exploration\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.age = np.zeros(self.pop_size) # Reset ages\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.10968971732841015, 0.24907899028810243, 0.47526785349289236, 0.566833639152011, 0.19945773094425778, 0.31151477583276577, 0.28016425925480815, 0.3972309425003465, 0.22713627642223078, 0.16968071421489694, 0.5789800000754457, 1.0, 0.2919847242597312, 0.26203830943709583, 0.7128648400917931, 0.2897796877817036, 0.2726970588716062, 0.684268686116717, 0.18051796796346387, 0.19847712498449366], "operator": "mutation", "theta_sampled": 0.33430096072493287, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "2f0f0f2f-c391-4d6c-bf3d-cabd4d94e9af", "fitness": 0.40239766868753757, "name": "HybridDEPSOCMA", "description": "Combines DE, PSO, CMA-ES, and a local search strategy with adaptive parameter control and restart mechanisms to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate = 0.5  # Initialize success rate for adaptive parameter control\n        self.history_length = 10\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.success_history = [] #History of success rate\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        def update_success_rate(success):\n            self.success_history.append(success)\n            if len(self.success_history) > self.history_length:\n                self.success_history.pop(0)\n            return np.mean(self.success_history)\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                improvement = False\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                        improvement = True\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n                \n                self.success_rate = update_success_rate(improvement)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDEPSOCMA scored 0.402 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines DE, PSO, CMA-ES, and a local search strategy with adaptive parameter control and restart mechanisms to enhance exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.success_rate = 0.5  # Initialize success rate for adaptive parameter control\n        self.history_length = 10\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n        self.success_history = [] #History of success rate\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / self.pop_size) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        def update_success_rate(success):\n            self.success_history.append(success)\n            if len(self.success_history) > self.history_length:\n                self.success_history.pop(0)\n            return np.mean(self.success_history)\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation and Crossover\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                improvement = False\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                        improvement = True\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n                \n                self.success_rate = update_success_rate(improvement)\n\n            # CMA-ES adaptation\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n            \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n\n\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.1362170824069051, 0.2329944839575393, 0.7199148535629156, 0.9228619235103277, 0], "operator": "crossover", "theta_sampled": 0.26203094989032993, "reward": 0.0, "generation": 10}, "task_prompt": ""}
{"id": "45a46b02-1b23-4b63-9847-7ce71f53c68b", "fitness": 0.28251112715906235, "name": "HybridDECMASBFGS", "description": "Integrates DE, CMA-ES, and a gradient-based local search (BFGS) to exploit function structure more effectively, with adaptive parameter control.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASBFGS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, bfgs_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.bfgs_probability = bfgs_probability # Probability of BFGS local search\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # Adaptive parameter control\n        adaptive_mutation_factor = self.mutation_factor\n        adaptive_crossover_rate = self.crossover_rate\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + adaptive_mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < adaptive_crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n                        \n            # BFGS Local Search\n            if np.random.rand() < self.bfgs_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                def bfgs_objective(x):\n                    return func(x)\n                \n                # Perform BFGS optimization\n                try:\n                    res = minimize(bfgs_objective, best_individual, method='L-BFGS-B', bounds=func.bounds)\n                    \n                    if res.success:\n                        bfgs_f = res.fun\n                        bfgs_x = res.x\n                        \n                        num_func_evals = res.nfev\n                        self.budget -= num_func_evals\n                        \n                        if self.budget <= 0:\n                            break\n                        \n                        if bfgs_f < fitness[best_idx]:\n                            fitness[best_idx] = bfgs_f\n                            population[best_idx] = bfgs_x\n                            \n                            if bfgs_f < self.f_opt:\n                                self.f_opt = bfgs_f\n                                self.x_opt = bfgs_x\n                except Exception as e:\n                    pass  # Handle potential BFGS errors\n\n            # Adaptive parameter control (example - adjust mutation factor)\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-6:  # Stagnation detection\n                    adaptive_mutation_factor = min(1.0, adaptive_mutation_factor * 1.2)  # Increase exploration\n                else:\n                    adaptive_mutation_factor = max(0.1, adaptive_mutation_factor * 0.9)  # Reduce exploration\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDECMASBFGS scored 0.283 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE, CMA-ES, and a gradient-based local search (BFGS) to exploit function structure more effectively, with adaptive parameter control.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDECMASBFGS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, bfgs_probability=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.bfgs_probability = bfgs_probability # Probability of BFGS local search\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        # Adaptive parameter control\n        adaptive_mutation_factor = self.mutation_factor\n        adaptive_crossover_rate = self.crossover_rate\n        \n        generation = 0\n        while self.budget > 0:\n            generation += 1\n\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + adaptive_mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < adaptive_crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n                        \n            # BFGS Local Search\n            if np.random.rand() < self.bfgs_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                def bfgs_objective(x):\n                    return func(x)\n                \n                # Perform BFGS optimization\n                try:\n                    res = minimize(bfgs_objective, best_individual, method='L-BFGS-B', bounds=func.bounds)\n                    \n                    if res.success:\n                        bfgs_f = res.fun\n                        bfgs_x = res.x\n                        \n                        num_func_evals = res.nfev\n                        self.budget -= num_func_evals\n                        \n                        if self.budget <= 0:\n                            break\n                        \n                        if bfgs_f < fitness[best_idx]:\n                            fitness[best_idx] = bfgs_f\n                            population[best_idx] = bfgs_x\n                            \n                            if bfgs_f < self.f_opt:\n                                self.f_opt = bfgs_f\n                                self.x_opt = bfgs_x\n                except Exception as e:\n                    pass  # Handle potential BFGS errors\n\n            # Adaptive parameter control (example - adjust mutation factor)\n            if generation % 10 == 0:\n                if np.std(fitness) < 1e-6:  # Stagnation detection\n                    adaptive_mutation_factor = min(1.0, adaptive_mutation_factor * 1.2)  # Increase exploration\n                else:\n                    adaptive_mutation_factor = max(0.1, adaptive_mutation_factor * 0.9)  # Reduce exploration\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.20256514792116964, 0.231117120611127, 0.6963622401039526, 0], "operator": "mutation", "theta_sampled": 0.07883429526848901, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "f3932941-63da-4e5e-9bec-058fdea3a7fd", "fitness": 0.7443153056254244, "name": "AdaptiveDifferentialEvolution", "description": "An adaptive differential evolution algorithm with a self-adaptive mutation strategy based on past successful mutations.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.744 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: An adaptive differential evolution algorithm with a self-adaptive mutation strategy based on past successful mutations.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.4177728900147888, 0.6681226570121215, 0.7680453175996205, 0.9062006934042364, 0.7894557262027403, 0.8135699863860395, 0.6933299890558412, 0.7158298436010855, 0.7959743372798131, 0.7293332129350873, 0.8812357307002863, 0.9868405352464259, 0.6949688898598834, 0.7394213037352129, 0.9212213117806005, 0.8222681448184765, 0.6988379501250104, 0.8649922106290007, 0.3356852702605343, 0.643200111861683], "operator": "random_new", "theta_sampled": 0.21825376313800834, "reward": 0.12047949972318905, "generation": 11}, "task_prompt": ""}
{"id": "497532ce-321f-4e64-83f6-24a576b6247b", "fitness": 0.0, "name": "AdaptiveGaussianLevy", "description": "Population-based algorithm using a combination of Gaussian mutation and Lvy flight exploration with adaptive scaling.", "code": "import numpy as np\n\nclass AdaptiveGaussianLevy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.mutation_scale = 0.1  # Initial mutation scale\n        self.levy_scale = 0.1 # Initial levy scale\n\n    def levy_flight(self, size, beta):\n        \"\"\"Generate Levy distribution samples.\"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        z = u / (np.abs(v) ** (1 / beta))\n        return z\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = np.inf # initialize with inf\n    \n\n    def __call__(self, func):\n        self.initialize_population()\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                x_mutated_gauss = self.pop[i] + self.mutation_scale * np.random.normal(0, 1, size=self.dim)\n                x_mutated_gauss = np.clip(x_mutated_gauss, self.lb, self.ub)  # Keep within bounds\n\n                # Levy Flight Exploration\n                levy_step = self.levy_scale * self.levy_flight(self.dim, self.levy_exponent)\n                x_mutated_levy = self.pop[i] + levy_step\n                x_mutated_levy = np.clip(x_mutated_levy, self.lb, self.ub)  # Keep within bounds\n                \n                # Evaluate both mutated solutions\n                f_gauss = func(x_mutated_gauss)\n                self.eval_count += 1\n                if f_gauss < self.fitness[i]:\n                  self.pop[i] = x_mutated_gauss\n                  self.fitness[i] = f_gauss\n                \n                if f_gauss < self.f_opt:\n                    self.f_opt = f_gauss\n                    self.x_opt = x_mutated_gauss\n                \n                if self.eval_count >= self.budget:\n                    break\n                \n                f_levy = func(x_mutated_levy)\n                self.eval_count += 1\n                if f_levy < self.fitness[i]:\n                  self.pop[i] = x_mutated_levy\n                  self.fitness[i] = f_levy\n                \n                if f_levy < self.f_opt:\n                    self.f_opt = f_levy\n                    self.x_opt = x_mutated_levy\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive scaling: Reduce mutation if no improvement, increase if stagnant\n            improvement_rate = np.sum(self.fitness < np.inf) / self.pop_size\n            if improvement_rate < 0.1:  # Low improvement\n                self.mutation_scale *= 0.9  # Reduce exploration\n                self.levy_scale *= 0.9\n\n            elif improvement_rate > 0.5:\n                self.mutation_scale *= 1.1  # Increase exploration\n                self.levy_scale *= 1.1\n                \n            self.mutation_scale = np.clip(self.mutation_scale, 0.0001, 1.0) # ensure mutation scale stays in reasonable range\n            self.levy_scale = np.clip(self.levy_scale, 0.0001, 1.0)\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: module 'numpy' has no attribute 'math'", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm using a combination of Gaussian mutation and Lvy flight exploration with adaptive scaling.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianLevy:\n    def __init__(self, budget=10000, dim=10, pop_size=50, levy_exponent=1.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.levy_exponent = levy_exponent\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop = None\n        self.fitness = None\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.eval_count = 0\n        self.mutation_scale = 0.1  # Initial mutation scale\n        self.levy_scale = 0.1 # Initial levy scale\n\n    def levy_flight(self, size, beta):\n        \"\"\"Generate Levy distribution samples.\"\"\"\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        z = u / (np.abs(v) ** (1 / beta))\n        return z\n\n    def initialize_population(self):\n        self.pop = np.random.uniform(self.lb, self.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.zeros(self.pop_size)\n        for i in range(self.pop_size):\n            self.fitness[i] = np.inf # initialize with inf\n    \n\n    def __call__(self, func):\n        self.initialize_population()\n\n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                # Gaussian Mutation\n                x_mutated_gauss = self.pop[i] + self.mutation_scale * np.random.normal(0, 1, size=self.dim)\n                x_mutated_gauss = np.clip(x_mutated_gauss, self.lb, self.ub)  # Keep within bounds\n\n                # Levy Flight Exploration\n                levy_step = self.levy_scale * self.levy_flight(self.dim, self.levy_exponent)\n                x_mutated_levy = self.pop[i] + levy_step\n                x_mutated_levy = np.clip(x_mutated_levy, self.lb, self.ub)  # Keep within bounds\n                \n                # Evaluate both mutated solutions\n                f_gauss = func(x_mutated_gauss)\n                self.eval_count += 1\n                if f_gauss < self.fitness[i]:\n                  self.pop[i] = x_mutated_gauss\n                  self.fitness[i] = f_gauss\n                \n                if f_gauss < self.f_opt:\n                    self.f_opt = f_gauss\n                    self.x_opt = x_mutated_gauss\n                \n                if self.eval_count >= self.budget:\n                    break\n                \n                f_levy = func(x_mutated_levy)\n                self.eval_count += 1\n                if f_levy < self.fitness[i]:\n                  self.pop[i] = x_mutated_levy\n                  self.fitness[i] = f_levy\n                \n                if f_levy < self.f_opt:\n                    self.f_opt = f_levy\n                    self.x_opt = x_mutated_levy\n                \n                if self.eval_count >= self.budget:\n                    break\n\n            # Adaptive scaling: Reduce mutation if no improvement, increase if stagnant\n            improvement_rate = np.sum(self.fitness < np.inf) / self.pop_size\n            if improvement_rate < 0.1:  # Low improvement\n                self.mutation_scale *= 0.9  # Reduce exploration\n                self.levy_scale *= 0.9\n\n            elif improvement_rate > 0.5:\n                self.mutation_scale *= 1.1  # Increase exploration\n                self.levy_scale *= 1.1\n                \n            self.mutation_scale = np.clip(self.mutation_scale, 0.0001, 1.0) # ensure mutation scale stays in reasonable range\n            self.levy_scale = np.clip(self.levy_scale, 0.0001, 1.0)\n\n        return self.f_opt, self.x_opt\n```", "operator": "random_new", "theta_sampled": 0.06138837725527316, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "d3f61856-3e9c-4793-bbb9-4cf8c0f50283", "fitness": 0.3392436267473903, "name": "HybridDEPSOCMA", "description": "Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and Local Search with adaptive parameter control and a restart mechanism for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_initial=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_initial = w_initial  # Initial inertia weight (PSO)\n        self.w_final = w_final  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.generation = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        self.velocities = np.zeros_like(self.population)\n\n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_initial - (self.w_initial - self.w_final) * (self.generation / (self.budget + self.generation))\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                self.velocities[i] = w * self.velocities[i] + \\\n                                   self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                                   self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n            \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.velocities = np.zeros_like(self.population)\n                 # Reset CMA-ES\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDEPSOCMA scored 0.339 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Differential Evolution (DE), Particle Swarm Optimization (PSO), Covariance Matrix Adaptation Evolution Strategy (CMA-ES), and Local Search with adaptive parameter control and a restart mechanism for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_initial=0.9, w_final=0.4, c1=1.5, c2=1.5, stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F  # Differential evolution parameter\n        self.CR = CR  # Crossover rate\n        self.w_initial = w_initial  # Initial inertia weight (PSO)\n        self.w_final = w_final  # Final inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.generation = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim) # Evolution path for C\n        self.ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        self.velocities = np.zeros_like(self.population)\n\n        while self.budget > 0:\n            self.generation += 1\n            w = self.w_initial - (self.w_initial - self.w_final) * (self.generation / (self.budget + self.generation))\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                self.velocities[i] = w * self.velocities[i] + \\\n                                   self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                                   self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n            \n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            self.ps = (1-self.c_sigma)*self.ps + np.sqrt(self.c_sigma*(2-self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean)/self.sigma))\n            self.pc = (1-self.c_c) * self.pc + np.sqrt(self.c_c*(2-self.c_c)) * ((mean_new - self.mean)/self.sigma)\n\n            # Update covariance matrix\n            self.C = (1-self.c_1-self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n            \n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma/self.d_sigma) * ((np.linalg.norm(self.ps)/np.sqrt(self.dim)) - 1))\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.velocities = np.zeros_like(self.population)\n                 # Reset CMA-ES\n                 self.mean = np.mean(self.population, axis=0)\n                 self.sigma = self.cma_sigma * (ub - lb) #overall standard deviation\n                 self.C = np.eye(self.dim)  # Covariance matrix\n                 self.pc = np.zeros(self.dim) # Evolution path for C\n                 self.ps = np.zeros(self.dim) # Evolution path for sigma\n\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.13616638694403993, 0.22012535583964232, 0.2982974306886027, 0.4016389901882369, 0.24855865735511729, 0.3145921563082159, 0.26918189923913727, 0.26991114884316114, 0.24168955394156766, 0.20733796948356498, 0.3020336370318515, 0.9983877248984483, 0.2744401093017451, 0.29524227732522923, 0.6684354469038143, 0.3367210366521155, 0.28202100185468026, 0.36394896178551783, 0.1758303945612686, 0.4803123958018495], "operator": "crossover", "theta_sampled": 0.08703521636470778, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "3b20016a-9e07-43e4-a6bd-7a329f0e69c9", "fitness": 0.4790287514556715, "name": "HybridDEPSOCMA", "description": "Integrates Differential Evolution, PSO, CMA-ES adaptation, and a local search strategy with dynamic parameter adjustments and stagnation handling for robust global optimization.", "code": "import numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_decay = 0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_decay = cma_decay # Decay factor for CMA-ES step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.generation = 0  # Track the number of generations\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget / self.pop_size + self.generation)) # Dynamic inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n            self.sigma *= self.cma_decay  # Apply decay to step size\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                      self.global_best_fitness = local_f\n                      self.global_best_position = local_trial.copy()\n                      self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.sigma = 0.3 * (ub - lb) # Reset sigma after restart\n                self.C = np.eye(self.dim) #Reset covariance matrix\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            self.generation += 1  # Increment generation counter\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDEPSOCMA scored 0.479 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233", "f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Differential Evolution, PSO, CMA-ES adaptation, and a local search strategy with dynamic parameter adjustments and stagnation handling for robust global optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w_start=0.9, w_end=0.4, c1=1.5, c2=1.5,\n                 stagnation_threshold=500, local_search_probability=0.1, cma_decay = 0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w_start = w_start\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_decay = cma_decay # Decay factor for CMA-ES step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.generation = 0  # Track the number of generations\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = 0.3 * (ub - lb)  # overall standard deviation\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3) ** 2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2) ** 2 + self.pop_size))\n        self.mu = self.pop_size // 2\n\n        while self.budget > 0:\n            w = self.w_start - (self.w_start - self.w_end) * (self.generation / (self.budget / self.pop_size + self.generation)) # Dynamic inertia weight\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n                v = np.clip(v, lb, ub)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma ** 2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n            self.sigma *= self.cma_decay  # Apply decay to step size\n\n            self.mean = mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                      self.global_best_fitness = local_f\n                      self.global_best_position = local_trial.copy()\n                      self.stagnation_counter = 0\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                self.stagnation_counter = 0\n                self.sigma = 0.3 * (ub - lb) # Reset sigma after restart\n                self.C = np.eye(self.dim) #Reset covariance matrix\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n            self.generation += 1  # Increment generation counter\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14799461922397672, 0.648342271692175, 0.806770202549103, 0.9777933452042129, 0.31429367471491343, 0.4580071468053192, 0], "operator": "crossover", "theta_sampled": -0.006115923991303406, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "e2a07b9c-7cf2-412c-b97b-539378f8651f", "fitness": 0.0, "name": "AdaptiveLandscapeExplorer", "description": "Population-based algorithm with adaptive landscape exploration, using a combination of gradient estimation and differential evolution-like perturbation, adjusted based on local search landscape characteristics.", "code": "import numpy as np\n\nclass AdaptiveLandscapeExplorer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, grad_samples=5, de_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.grad_samples = grad_samples\n        self.de_rate = de_rate\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        f_opt = np.min(fitness)\n        x_opt = pop[np.argmin(fitness)]\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Gradient estimation (simplified)\n                grad = np.zeros(self.dim)\n                for _ in range(self.grad_samples):\n                    if self.budget <= 0:\n                        break\n                    delta = np.random.normal(0, 0.1, size=self.dim)\n                    x_perturbed = np.clip(pop[i] + delta, func.bounds.lb, func.bounds.ub)\n                    f_perturbed = func(x_perturbed)\n                    self.budget -= 1\n                    grad += (f_perturbed - fitness[i]) * delta \n                grad /= self.grad_samples\n                \n                # Differential Evolution-like mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                mutant = pop[i] + self.de_rate * (x_r1 - x_r2) + 0.01 * grad  # Add gradient info\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate mutant\n                f_mutant = func(mutant)\n                self.budget -= 1\n                \n                # Selection\n                if f_mutant < fitness[i]:\n                    pop[i] = mutant\n                    fitness[i] = f_mutant\n                    \n                    if f_mutant < f_opt:\n                        f_opt = f_mutant\n                        x_opt = mutant\n\n        return f_opt, x_opt", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveLandscapeExplorer scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": [], "operator": "random_new", "metadata": {"llm_response": "# Description: Population-based algorithm with adaptive landscape exploration, using a combination of gradient estimation and differential evolution-like perturbation, adjusted based on local search landscape characteristics.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveLandscapeExplorer:\n    def __init__(self, budget=10000, dim=10, pop_size=20, grad_samples=5, de_rate=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.grad_samples = grad_samples\n        self.de_rate = de_rate\n\n    def __call__(self, func):\n        # Initialization\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        self.budget -= self.pop_size\n        \n        f_opt = np.min(fitness)\n        x_opt = pop[np.argmin(fitness)]\n\n        # Main loop\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Gradient estimation (simplified)\n                grad = np.zeros(self.dim)\n                for _ in range(self.grad_samples):\n                    if self.budget <= 0:\n                        break\n                    delta = np.random.normal(0, 0.1, size=self.dim)\n                    x_perturbed = np.clip(pop[i] + delta, func.bounds.lb, func.bounds.ub)\n                    f_perturbed = func(x_perturbed)\n                    self.budget -= 1\n                    grad += (f_perturbed - fitness[i]) * delta \n                grad /= self.grad_samples\n                \n                # Differential Evolution-like mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = pop[idxs]\n                \n                mutant = pop[i] + self.de_rate * (x_r1 - x_r2) + 0.01 * grad  # Add gradient info\n                mutant = np.clip(mutant, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate mutant\n                f_mutant = func(mutant)\n                self.budget -= 1\n                \n                # Selection\n                if f_mutant < fitness[i]:\n                    pop[i] = mutant\n                    fitness[i] = f_mutant\n                    \n                    if f_mutant < f_opt:\n                        f_opt = f_mutant\n                        x_opt = mutant\n\n        return f_opt, x_opt\n```", "aucs": [0], "operator": "random_new", "theta_sampled": -0.008897724766179727, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "d6046169-0e3c-4777-80cd-5d929c3a0d9a", "fitness": 0.0, "name": "AdaptiveHybridDECMAS", "description": "Integrates DE, CMA-ES, and a gradient-based local search, dynamically adjusting parameters based on performance feedback.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_decay = 0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.cma_decay = cma_decay\n\n        self.de_success_rate = 0.5\n        self.cma_success_rate = 0.5\n        self.local_success_rate = 0.5\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        success_de = 0\n        success_cma = 0\n        success_local = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            total_iterations += 1\n\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    success_de += 1\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search (optional) for the best individual with gradient information\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Gradient-based local search using scipy.optimize.minimize\n                def obj_func(x):\n                    val = func(x)\n                    return val if self.budget >= 1 else np.inf # early termination\n\n                if self.budget > 0:\n                    res = minimize(obj_func, best_individual, method='L-BFGS-B', bounds=func.bounds, options={'maxfun': self.budget // 10}) # Limit function evaluations\n                    \n                    if res.fun < fitness[best_idx]:\n                        success_local += 1\n                        fitness[best_idx] = res.fun\n                        population[best_idx] = res.x\n                        \n                        if res.fun < self.f_opt:\n                            self.f_opt = res.fun\n                            self.x_opt = res.x\n                    self.budget -= res.nfev\n\n            # Adaptive parameter adjustment based on success rates\n            self.de_success_rate = 0.9 * self.de_success_rate + 0.1 * (success_de / (self.pop_size)) if total_iterations > 1 else 0.5\n            self.cma_success_rate = 0.9 * self.cma_success_rate + 0.1 * (len(np.unique(fitness)) / self.pop_size) if total_iterations > 1 else 0.5  # diversity as CMA success proxy\n            self.local_success_rate = 0.9 * self.local_success_rate + 0.1 * (success_local / (self.local_search_probability * total_iterations)) if total_iterations > 1 and (self.local_search_probability * total_iterations) > 0 else 0.5\n\n            # Adjust probabilities/rates\n            self.mutation_factor = np.clip(self.mutation_factor + 0.1 * (self.de_success_rate - 0.5), 0.1, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + 0.1 * (self.de_success_rate - 0.5), 0.1, 1.0)\n\n            if self.cma_success_rate > 0.5:\n                sigma *= np.exp(0.1 * (self.cma_success_rate - 0.5))\n            else:\n                 sigma *= np.exp(0.1 * (self.cma_success_rate - 0.5))\n            sigma = sigma * self.cma_decay\n\n            self.local_search_probability = np.clip(self.local_search_probability + 0.1 * (self.local_success_rate - 0.3), 0.01, 0.5) # Bias to be less frequent due to budget\n\n            success_de = 0\n            success_cma = 0\n            success_local = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: name 'minimize' is not defined", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates DE, CMA-ES, and a gradient-based local search, dynamically adjusting parameters based on performance feedback.\n# Code: \n```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, cma_decay = 0.99):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))  # dynamically adjust population size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability # Probability of performing a local search step\n        self.cma_decay = cma_decay\n\n        self.de_success_rate = 0.5\n        self.cma_success_rate = 0.5\n        self.local_success_rate = 0.5\n\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb) #overall standard deviation\n        C = np.eye(self.dim)  # Covariance matrix\n        pc = np.zeros(self.dim) # Evolution path for C\n        ps = np.zeros(self.dim) # Evolution path for sigma\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        success_de = 0\n        success_cma = 0\n        success_local = 0\n        total_iterations = 0\n\n        while self.budget > 0:\n            total_iterations += 1\n\n            # Differential Evolution part\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    success_de += 1\n                    fitness[i] = f\n                    population[i] = trial\n\n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n\n            # Local search (optional) for the best individual with gradient information\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Gradient-based local search using scipy.optimize.minimize\n                def obj_func(x):\n                    val = func(x)\n                    return val if self.budget >= 1 else np.inf # early termination\n\n                if self.budget > 0:\n                    res = minimize(obj_func, best_individual, method='L-BFGS-B', bounds=func.bounds, options={'maxfun': self.budget // 10}) # Limit function evaluations\n                    \n                    if res.fun < fitness[best_idx]:\n                        success_local += 1\n                        fitness[best_idx] = res.fun\n                        population[best_idx] = res.x\n                        \n                        if res.fun < self.f_opt:\n                            self.f_opt = res.fun\n                            self.x_opt = res.x\n                    self.budget -= res.nfev\n\n            # Adaptive parameter adjustment based on success rates\n            self.de_success_rate = 0.9 * self.de_success_rate + 0.1 * (success_de / (self.pop_size)) if total_iterations > 1 else 0.5\n            self.cma_success_rate = 0.9 * self.cma_success_rate + 0.1 * (len(np.unique(fitness)) / self.pop_size) if total_iterations > 1 else 0.5  # diversity as CMA success proxy\n            self.local_success_rate = 0.9 * self.local_success_rate + 0.1 * (success_local / (self.local_search_probability * total_iterations)) if total_iterations > 1 and (self.local_search_probability * total_iterations) > 0 else 0.5\n\n            # Adjust probabilities/rates\n            self.mutation_factor = np.clip(self.mutation_factor + 0.1 * (self.de_success_rate - 0.5), 0.1, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + 0.1 * (self.de_success_rate - 0.5), 0.1, 1.0)\n\n            if self.cma_success_rate > 0.5:\n                sigma *= np.exp(0.1 * (self.cma_success_rate - 0.5))\n            else:\n                 sigma *= np.exp(0.1 * (self.cma_success_rate - 0.5))\n            sigma = sigma * self.cma_decay\n\n            self.local_search_probability = np.clip(self.local_search_probability + 0.1 * (self.local_success_rate - 0.3), 0.01, 0.5) # Bias to be less frequent due to budget\n\n            success_de = 0\n            success_cma = 0\n            success_local = 0\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.1150276454016404, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "5dfe16ab-5a64-404d-92d5-8091bf2b9863", "fitness": 0.0, "name": "AdaptiveHybridDEPSO", "description": "Integrates a self-adaptive mechanism for DE parameters, a velocity clamping strategy for PSO, and a diversity maintenance scheme using a distance metric.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, CR_init=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, velocity_clamp=0.5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init  # Initial Differential evolution parameter, will be adapted\n        self.CR = CR_init  # Initial Crossover rate, will be adapted\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.velocity_clamp = velocity_clamp # Maximum velocity for PSO\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.F_memory = []\n        self.CR_memory = []\n        self.archive_size = 10\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Self-Adaptive DE parameters\n                if np.random.rand() < 0.1: # 10% chance to change F and CR\n                    self.F = np.random.uniform(0.3, 0.9)\n                    self.CR = np.random.uniform(0.1, 0.9)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                # Velocity clamping\n                velocity = np.clip(velocity, -self.velocity_clamp, self.velocity_clamp)\n\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n            # Diversity Check and Maintenance\n            if not self.is_diverse():\n                # Introduce diversity by re-initializing some particles\n                num_to_reinitialize = int(0.2 * self.pop_size)\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n                self.population[indices_to_reinitialize] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_reinitialize, self.dim))\n                self.fitness[indices_to_reinitialize] = np.array([func(x) for x in self.population[indices_to_reinitialize]])\n                self.budget -= num_to_reinitialize\n                for i in indices_to_reinitialize:\n                    self.personal_best_positions[i] = self.population[i].copy()\n                    self.personal_best_fitness[i] = self.fitness[i]\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n\n    def is_diverse(self):\n        # Calculate the average distance between particles\n        total_distance = 0\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                total_distance += np.linalg.norm(self.population[i] - self.population[j])\n        average_distance = total_distance / (self.pop_size * (self.pop_size - 1) / 2)\n\n        # Normalize the average distance by the search space range\n        normalized_distance = average_distance / (func.bounds.ub[0] - func.bounds.lb[0])  # Assuming uniform bounds\n\n        return normalized_distance > self.diversity_threshold", "configspace": "", "generation": 11, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "mutation", "metadata": {"llm_response": "# Description: Integrates a self-adaptive mechanism for DE parameters, a velocity clamping strategy for PSO, and a diversity maintenance scheme using a distance metric.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=50, F_init=0.5, CR_init=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, velocity_clamp=0.5, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F_init  # Initial Differential evolution parameter, will be adapted\n        self.CR = CR_init  # Initial Crossover rate, will be adapted\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.velocity_clamp = velocity_clamp # Maximum velocity for PSO\n        self.diversity_threshold = diversity_threshold # Threshold for population diversity\n\n        self.F_memory = []\n        self.CR_memory = []\n        self.archive_size = 10\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                # Self-Adaptive DE parameters\n                if np.random.rand() < 0.1: # 10% chance to change F and CR\n                    self.F = np.random.uniform(0.3, 0.9)\n                    self.CR = np.random.uniform(0.1, 0.9)\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)  # Ensure mutation respects bounds\n\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, func.bounds.lb, func.bounds.ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1 # Increment stagnation if no improvement\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                # Velocity clamping\n                velocity = np.clip(velocity, -self.velocity_clamp, self.velocity_clamp)\n\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n            # Diversity Check and Maintenance\n            if not self.is_diverse():\n                # Introduce diversity by re-initializing some particles\n                num_to_reinitialize = int(0.2 * self.pop_size)\n                indices_to_reinitialize = np.random.choice(self.pop_size, num_to_reinitialize, replace=False)\n                self.population[indices_to_reinitialize] = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(num_to_reinitialize, self.dim))\n                self.fitness[indices_to_reinitialize] = np.array([func(x) for x in self.population[indices_to_reinitialize]])\n                self.budget -= num_to_reinitialize\n                for i in indices_to_reinitialize:\n                    self.personal_best_positions[i] = self.population[i].copy()\n                    self.personal_best_fitness[i] = self.fitness[i]\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n\n    def is_diverse(self):\n        # Calculate the average distance between particles\n        total_distance = 0\n        for i in range(self.pop_size):\n            for j in range(i + 1, self.pop_size):\n                total_distance += np.linalg.norm(self.population[i] - self.population[j])\n        average_distance = total_distance / (self.pop_size * (self.pop_size - 1) / 2)\n\n        # Normalize the average distance by the search space range\n        normalized_distance = average_distance / (func.bounds.ub[0] - func.bounds.lb[0])  # Assuming uniform bounds\n\n        return normalized_distance > self.diversity_threshold\n```", "operator": "mutation", "theta_sampled": 0.31884338109601634, "reward": 0.0, "generation": 11}, "task_prompt": ""}
{"id": "a09d2c9c-3f8f-43dc-9e22-5ae63b5300b7", "fitness": 0.0, "name": "ADEPSODynamic", "description": "Combines Adaptive Differential Evolution with Particle Swarm Optimization, using a dynamic adaptation strategy for balancing exploration and exploitation, and incorporating a restart mechanism to escape local optima.", "code": "import numpy as np\n\nclass ADEPSODynamic:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, stagnation_threshold=500, de_portion=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.de_portion = de_portion # portion of individuals to apply DE\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.best_index = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def pso_update(self, i, iteration, max_iterations):\n        w = self.w_init - (self.w_init - self.w_end) * (iteration / max_iterations)\n        velocity = w * (self.population[i] - self.population[i]) + \\\n                   self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                   self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n        new_position = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n        return new_position\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n        max_iterations = self.budget // self.pop_size\n        iteration = 0\n\n        while self.budget > 0:\n            iteration += 1\n            for i in range(self.pop_size):\n                x = self.population[i]\n                \n                # Apply DE or PSO based on de_portion\n                if np.random.rand() < self.de_portion:\n                    v = self.mutate(x, func)\n                    u = self.crossover(x, v)\n                else:\n                    u = self.pso_update(i, iteration, max_iterations)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    if np.random.rand() < self.de_portion:  #Only archive if DE\n                         self.archive.append(self.F)\n                         if len(self.archive) > self.archive_size:\n                             self.archive.pop(0)\n                    \n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: name 'func' is not defined", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd", "37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines Adaptive Differential Evolution with Particle Swarm Optimization, using a dynamic adaptation strategy for balancing exploration and exploitation, and incorporating a restart mechanism to escape local optima.\n# Code: \n```python\nimport numpy as np\n\nclass ADEPSODynamic:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w_init=0.9, w_end=0.4, c1=2.0, c2=2.0, stagnation_threshold=500, de_portion=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w_init = w_init\n        self.w_end = w_end\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.de_portion = de_portion # portion of individuals to apply DE\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.best_index = None\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def pso_update(self, i, iteration, max_iterations):\n        w = self.w_init - (self.w_init - self.w_end) * (iteration / max_iterations)\n        velocity = w * (self.population[i] - self.population[i]) + \\\n                   self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                   self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n        new_position = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n        return new_position\n\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n        max_iterations = self.budget // self.pop_size\n        iteration = 0\n\n        while self.budget > 0:\n            iteration += 1\n            for i in range(self.pop_size):\n                x = self.population[i]\n                \n                # Apply DE or PSO based on de_portion\n                if np.random.rand() < self.de_portion:\n                    v = self.mutate(x, func)\n                    u = self.crossover(x, v)\n                else:\n                    u = self.pso_update(i, iteration, max_iterations)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    if np.random.rand() < self.de_portion:  #Only archive if DE\n                         self.archive.append(self.F)\n                         if len(self.archive) > self.archive_size:\n                             self.archive.pop(0)\n                    \n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.stagnation_counter = 0\n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.01420826534563177, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "e5524238-875c-443b-8bed-5fd0d8d97fe8", "fitness": 0.07924317158602023, "name": "AdaptiveHybridDECMAS", "description": "An adaptive hybrid DE and CMA-ES algorithm, where DE explores and CMA-ES refines, with adaptive parameter control using success history.", "code": "import numpy as np\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, de_proportion=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.de_proportion = de_proportion  # Proportion of population updated by DE\n\n        # Success history for adapting mutation factor and crossover rate\n        self.archive = []\n        self.archive_max_size = 10\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Adaptive DE parameters based on success history\n            if self.archive:\n                mf_vals = [s[0] for s in self.archive]\n                cr_vals = [s[1] for s in self.archive]\n                self.mutation_factor = np.mean(mf_vals)\n                self.crossover_rate = np.mean(cr_vals)\n                \n            # Differential Evolution part (applied to a proportion of the population)\n            num_de = int(self.de_proportion * self.pop_size)\n            for i in range(num_de):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    delta_f = fitness[i] - f\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update success history\n                    self.archive.append((self.mutation_factor, self.crossover_rate, delta_f))\n                    if len(self.archive) > self.archive_max_size:\n                        self.archive.pop(0) # FIFO\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridDECMAS scored 0.079 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3ab068d-d176-407c-a715-21f2805ecd12"], "operator": "mutation", "metadata": {"llm_response": "# Description: An adaptive hybrid DE and CMA-ES algorithm, where DE explores and CMA-ES refines, with adaptive parameter control using success history.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDECMAS:\n    def __init__(self, budget=10000, dim=10, pop_size=None, mutation_factor=0.5, crossover_rate=0.7, local_search_probability=0.1, de_proportion=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.local_search_probability = local_search_probability\n        self.de_proportion = de_proportion  # Proportion of population updated by DE\n\n        # Success history for adapting mutation factor and crossover rate\n        self.archive = []\n        self.archive_max_size = 10\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        # Initialize population\n        population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.budget -= self.pop_size\n\n        # Initialize CMA-ES parameters\n        mean = np.mean(population, axis=0)\n        sigma = 0.3 * (ub - lb)\n        C = np.eye(self.dim)\n        pc = np.zeros(self.dim)\n        ps = np.zeros(self.dim)\n        \n        # CMA-ES constants\n        c_sigma = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size-1)/(self.dim + 1)) - 1) + c_sigma\n        c_c = (np.sqrt(self.pop_size)/(np.sqrt(self.pop_size) + self.dim))\n        c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        c_mu = min(1 - c_1, 2 * (self.pop_size - 2 + 1/(self.pop_size))/( (self.dim + 2)**2 + self.pop_size))\n        mu = self.pop_size // 2\n\n        while self.budget > 0:\n            # Adaptive DE parameters based on success history\n            if self.archive:\n                mf_vals = [s[0] for s in self.archive]\n                cr_vals = [s[1] for s in self.archive]\n                self.mutation_factor = np.mean(mf_vals)\n                self.crossover_rate = np.mean(cr_vals)\n                \n            # Differential Evolution part (applied to a proportion of the population)\n            num_de = int(self.de_proportion * self.pop_size)\n            for i in range(num_de):\n                if self.budget <= 0:\n                    break\n                # Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x_1, x_2, x_3 = population[idxs]\n                mutant = population[i] + self.mutation_factor * (x_2 - x_3)\n\n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial[j] = mutant[j]\n\n                # Boundary Handling (clip to bounds)\n                trial = np.clip(trial, lb, ub)\n\n                # Evaluation\n                f = func(trial)\n                self.budget -= 1\n                \n                # Selection\n                if f < fitness[i]:\n                    delta_f = fitness[i] - f\n                    fitness[i] = f\n                    population[i] = trial\n                    \n                    # Update success history\n                    self.archive.append((self.mutation_factor, self.crossover_rate, delta_f))\n                    if len(self.archive) > self.archive_max_size:\n                        self.archive.pop(0) # FIFO\n                    \n                    if f < self.f_opt:\n                        self.f_opt = f\n                        self.x_opt = trial\n            # CMA-ES adaptation\n            \n            # Sort by fitness\n            idx_sorted = np.argsort(fitness)\n            population = population[idx_sorted]\n            fitness = fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = population[:mu]\n            mean_new = np.mean(x_mu, axis=0)\n            \n            # Update evolution paths\n            ps = (1-c_sigma)*ps + np.sqrt(c_sigma*(2-c_sigma)) * (np.linalg.solve(np.sqrt(C), (mean_new - mean)/sigma))\n            pc = (1-c_c) * pc + np.sqrt(c_c*(2-c_c)) * ((mean_new - mean)/sigma)\n\n            # Update covariance matrix\n            C = (1-c_1-c_mu) * C + c_1 * (pc[:, None] @ pc[None, :])\n            for j in range(mu):\n                C += c_mu * ((x_mu[j] - mean)[:, None] @ (x_mu[j] - mean)[None, :]) / (sigma**2)\n            \n            # Adjust step size\n            sigma *= np.exp((c_sigma/d_sigma) * ((np.linalg.norm(ps)/np.sqrt(self.dim)) - 1))\n\n            mean = mean_new\n                \n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(fitness)\n                best_individual = population[best_idx]\n                \n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n                \n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < fitness[best_idx]:\n                    fitness[best_idx] = local_f\n                    population[best_idx] = local_trial\n                    \n                    if local_f < self.f_opt:\n                        self.f_opt = local_f\n                        self.x_opt = local_trial\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.15848634317204047, 0], "operator": "mutation", "theta_sampled": 0.14840587059607913, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "0d17d15c-0060-4e56-8b85-56b71f895f06", "fitness": 0.4795819040894296, "name": "AdaptiveHybridDEPSO", "description": "Adaptive Differential Evolution with PSO-inspired velocity updates and a self-adaptive crossover rate based on stagnation.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v, current_cr):\n        mask = np.random.rand(self.dim) < current_cr\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive Crossover Rate (CR) based on stagnation\n            current_cr = self.CR * (1 - (self.stagnation_counter / self.stagnation_threshold))\n            current_cr = np.clip(current_cr, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v, current_cr)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                    \n                    # Archive the successful mutation factor\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO-inspired velocity update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                self.fitness[i] = func(self.population[i]) # Evaluate immediately\n                self.budget -=1\n                if self.budget <= 0:\n                    break\n                \n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if self.fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = self.fitness[i]\n                    self.global_best_position = self.population[i].copy()\n                    self.stagnation_counter = 0\n                 \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n                self.global_best_fitness = np.min(self.fitness)\n                self.stagnation_counter = 0\n\n            #Global best update\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridDEPSO scored 0.480 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd", "37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with PSO-inspired velocity updates and a self-adaptive crossover rate based on stagnation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Initial Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n        self.global_best_fitness = np.min(self.fitness)\n\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v, current_cr):\n        mask = np.random.rand(self.dim) < current_cr\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            # Adaptive Crossover Rate (CR) based on stagnation\n            current_cr = self.CR * (1 - (self.stagnation_counter / self.stagnation_threshold))\n            current_cr = np.clip(current_cr, 0.1, 0.9)\n\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v, current_cr)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                    \n                    # Archive the successful mutation factor\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO-inspired velocity update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                self.fitness[i] = func(self.population[i]) # Evaluate immediately\n                self.budget -=1\n                if self.budget <= 0:\n                    break\n                \n                if self.fitness[i] < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = self.fitness[i]\n                    self.personal_best_positions[i] = self.population[i].copy()\n                if self.fitness[i] < self.global_best_fitness:\n                    self.global_best_fitness = self.fitness[i]\n                    self.global_best_position = self.population[i].copy()\n                    self.stagnation_counter = 0\n                 \n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n                self.global_best_position = self.population[np.argmin(self.fitness)].copy()\n                self.global_best_fitness = np.min(self.fitness)\n                self.stagnation_counter = 0\n\n            #Global best update\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.21455489016835827, 0.21732709876088696, 0.5297818886293517, 0.1848451423095374, 0.9482809918526993, 0.9498819398793723, 0.3110057850947019, 0.36676765799736355, 0.3101269286520042, 0.18567177297048565, 0.29522485949255406, 0.9985965520105622, 0.30234947767281306, 0.30027068810597823, 0.7714620490706255, 0.7913983469178621, 0.28613063538040906, 0.9577445348823929, 0.17615872860529125, 0.4940581133353432], "operator": "crossover", "theta_sampled": 0.05470213137186111, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "740303e3-16bd-4967-8742-53bb11331ef8", "fitness": 0.21887986458630188, "name": "AdaptiveHybridDEPSO", "description": "Combines adaptive mutation from DE with PSO's velocity update and a CMA-ES-inspired covariance adaptation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, archive_size=10, stagnation_threshold=500, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.archive = []  # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.learning_rate = learning_rate # Learning rate for covariance adaptation\n        self.covariance = np.eye(dim)  # Initialize covariance matrix\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        \n        # Apply covariance adaptation\n        v = x + np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n        \n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n\n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update covariance matrix\n                    diff = u - x\n                    self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(diff, diff)\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation if no improvement\n                \n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.covariance = np.eye(self.dim)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridDEPSO scored 0.219 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd", "37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "crossover", "metadata": {"llm_response": "# Description: Combines adaptive mutation from DE with PSO's velocity update and a CMA-ES-inspired covariance adaptation for enhanced exploration and exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, archive_size=10, stagnation_threshold=500, learning_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR  # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.archive = []  # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.learning_rate = learning_rate # Learning rate for covariance adaptation\n        self.covariance = np.eye(dim)  # Initialize covariance matrix\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        \n        # Apply covariance adaptation\n        v = x + np.random.multivariate_normal(np.zeros(self.dim), self.covariance)\n        \n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n\n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Archive the successful mutation factor (simple version for demonstration)\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update covariance matrix\n                    diff = u - x\n                    self.covariance = (1 - self.learning_rate) * self.covariance + self.learning_rate * np.outer(diff, diff)\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1  # Increment stagnation if no improvement\n                \n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n\n\n            # Restart mechanism\n            if self.stagnation_counter > self.stagnation_threshold:\n                 self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n                 self.fitness = np.array([func(x) for x in self.population])\n                 self.budget -= self.pop_size\n                 self.best_index = np.argmin(self.fitness)\n                 self.global_best_position = self.population[self.best_index].copy()\n                 self.global_best_fitness = self.fitness[self.best_index]\n\n                 self.personal_best_positions = self.population.copy()\n                 self.personal_best_fitness = self.fitness.copy()\n\n                 self.stagnation_counter = 0\n                 self.covariance = np.eye(self.dim)\n\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.14231476527899634, 0.22555466277888003, 0.3929602741216639, 0.33356962075196916, 0], "operator": "crossover", "theta_sampled": 0.06234097825592886, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "a800530b-50f8-4288-b83c-ae2dbab4f09b", "fitness": 0.0, "name": "AdaptiveHybridDEPSOCMA", "description": "Adaptive Hybrid algorithm combining DE, PSO, CMA-ES with success-history based parameter adaptation and covariance matrix adaptation restart strategy.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.memory_size = memory_size\n\n        # Success history for F and CR\n        self.F_memory = np.full(self.memory_size, self.F)\n        self.CR_memory = np.full(self.memory_size, self.CR)\n        self.archive = []\n        self.memory_index = 0\n        self.success_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n            \n            #Update F and CR\n            self.F = np.random.choice(self.F_memory)\n            self.CR = np.random.choice(self.CR_memory)\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.success_count += 1\n                    delta = np.abs(self.fitness[i] - f_u)\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                        # Update success history\n                        self.F_memory[self.memory_index] = self.F\n                        self.CR_memory[self.memory_index] = self.CR\n                        self.memory_index = (self.memory_index + 1) % self.memory_size\n\n                        self.archive.append((u, delta))  # Store successful individuals\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            # Restart mechanism based on CMA-ES covariance matrix\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Option 1: Reinitialize population around the mean\n                # self.population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.pop_size)\n                # self.population = np.clip(self.population, lb, ub)\n                \n                # Option 2: Reinitialize population using a combination of archive and random\n                num_archive = min(len(self.archive), self.pop_size // 2)\n                archive_indices = np.random.choice(len(self.archive), num_archive, replace=False)\n                new_population = np.array([self.archive[i][0] for i in archive_indices])\n                remaining = self.pop_size - num_archive\n                new_population = np.vstack([new_population, np.random.uniform(lb, ub, size=(remaining, self.dim))])\n                self.population = new_population\n                \n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                #Reset CMA-ES parameters\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = self.cma_sigma * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n                self.stagnation_counter = 0\n                self.archive = [] #Clear the archive after restart\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 5", "parent_ids": ["3c7a740a-0bec-4756-ab2e-f59a12959eec"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Hybrid algorithm combining DE, PSO, CMA-ES with success-history based parameter adaptation and covariance matrix adaptation restart strategy.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=None, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, \n                 stagnation_threshold=500, local_search_probability=0.1, cma_sigma=0.3,\n                 memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size if pop_size is not None else 4 + int(3 * np.log(dim))\n        self.F = F\n        self.CR = CR\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.local_search_probability = local_search_probability\n        self.cma_sigma = cma_sigma\n        self.memory_size = memory_size\n\n        # Success history for F and CR\n        self.F_memory = np.full(self.memory_size, self.F)\n        self.CR_memory = np.full(self.memory_size, self.CR)\n        self.archive = []\n        self.memory_index = 0\n        self.success_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.f_opt = np.inf\n        self.x_opt = None\n\n        # Initialize population\n        self.population = np.random.uniform(lb, ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n        # Initialize CMA-ES parameters\n        self.mean = np.mean(self.population, axis=0)\n        self.sigma = self.cma_sigma * (ub - lb)\n        self.C = np.eye(self.dim)  # Covariance matrix\n        self.pc = np.zeros(self.dim)  # Evolution path for C\n        self.ps = np.zeros(self.dim)  # Evolution path for sigma\n\n        # CMA-ES constants\n        self.c_sigma = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.d_sigma = 1 + 2 * max(0, np.sqrt((self.pop_size - 1) / (self.dim + 1)) - 1) + self.c_sigma\n        self.c_c = (np.sqrt(self.pop_size) / (np.sqrt(self.pop_size) + self.dim))\n        self.c_1 = 2 / ((self.dim + 1.3)**2 + self.pop_size)\n        self.c_mu = min(1 - self.c_1, 2 * (self.pop_size - 2 + 1 / (self.pop_size)) / ((self.dim + 2)**2 + self.pop_size))\n        self.mu = self.pop_size // 2\n        \n        while self.budget > 0:\n            old_best_fitness = self.global_best_fitness\n            \n            #Update F and CR\n            self.F = np.random.choice(self.F_memory)\n            self.CR = np.random.choice(self.CR_memory)\n\n            for i in range(self.pop_size):\n                if self.budget <= 0:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.pop_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                v = self.population[i] + self.F * (x2 - x3)\n\n                # Crossover\n                u = np.zeros(self.dim)\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        u[j] = v[j]\n                    else:\n                        u[j] = self.population[i][j]\n\n                u = np.clip(u, lb, ub)\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n\n                if f_u < self.fitness[i]:\n                    self.success_count += 1\n                    delta = np.abs(self.fitness[i] - f_u)\n                    self.fitness[i] = f_u\n                    self.population[i] = u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n\n                        # Update success history\n                        self.F_memory[self.memory_index] = self.F\n                        self.CR_memory[self.memory_index] = self.CR\n                        self.memory_index = (self.memory_index + 1) % self.memory_size\n\n                        self.archive.append((u, delta))  # Store successful individuals\n                else:\n                    self.stagnation_counter += 1\n\n                # PSO update\n                velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n                \n                self.population[i] = np.clip(self.population[i] + velocity, lb, ub)\n\n            # CMA-ES adaptation\n\n            # Sort by fitness\n            idx_sorted = np.argsort(self.fitness)\n            self.population = self.population[idx_sorted]\n            self.fitness = self.fitness[idx_sorted]\n\n            # Selection and update mean\n            x_mu = self.population[:self.mu]\n            self.mean_new = np.mean(x_mu, axis=0)\n\n            # Update evolution paths\n            self.ps = (1 - self.c_sigma) * self.ps + np.sqrt(self.c_sigma * (2 - self.c_sigma)) * (np.linalg.solve(np.sqrt(self.C), (self.mean_new - self.mean) / self.sigma))\n            self.pc = (1 - self.c_c) * self.pc + np.sqrt(self.c_c * (2 - self.c_c)) * ((self.mean_new - self.mean) / self.sigma)\n\n            # Update covariance matrix\n            self.C = (1 - self.c_1 - self.c_mu) * self.C + self.c_1 * (self.pc[:, None] @ self.pc[None, :])\n            for j in range(self.mu):\n                self.C += self.c_mu * ((x_mu[j] - self.mean)[:, None] @ (x_mu[j] - self.mean)[None, :]) / (self.sigma**2)\n\n            # Adjust step size\n            self.sigma *= np.exp((self.c_sigma / self.d_sigma) * ((np.linalg.norm(self.ps) / np.sqrt(self.dim)) - 1))\n\n            self.mean = self.mean_new\n\n            # Local search (optional) for the best individual\n            if np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(self.fitness)\n                best_individual = self.population[best_idx]\n\n                # Simple random perturbation local search\n                perturbation = np.random.uniform(-0.01 * (ub - lb), 0.01 * (ub - lb), size=self.dim)  # Small perturbation\n                local_trial = best_individual + perturbation\n                local_trial = np.clip(local_trial, lb, ub)  # Boundary handling\n\n                local_f = func(local_trial)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if local_f < self.fitness[best_idx]:\n                    self.fitness[best_idx] = local_f\n                    self.population[best_idx] = local_trial\n\n                    if local_f < self.global_best_fitness:\n                        self.global_best_fitness = local_f\n                        self.global_best_position = local_trial\n            \n            # Restart mechanism based on CMA-ES covariance matrix\n            if self.stagnation_counter > self.stagnation_threshold:\n                # Option 1: Reinitialize population around the mean\n                # self.population = np.random.multivariate_normal(self.mean, self.sigma**2 * self.C, size=self.pop_size)\n                # self.population = np.clip(self.population, lb, ub)\n                \n                # Option 2: Reinitialize population using a combination of archive and random\n                num_archive = min(len(self.archive), self.pop_size // 2)\n                archive_indices = np.random.choice(len(self.archive), num_archive, replace=False)\n                new_population = np.array([self.archive[i][0] for i in archive_indices])\n                remaining = self.pop_size - num_archive\n                new_population = np.vstack([new_population, np.random.uniform(lb, ub, size=(remaining, self.dim))])\n                self.population = new_population\n                \n                self.fitness = np.array([func(x) for x in self.population])\n                self.budget -= self.pop_size\n\n                self.best_index = np.argmin(self.fitness)\n                self.global_best_position = self.population[self.best_index].copy()\n                self.global_best_fitness = self.fitness[self.best_index]\n                self.personal_best_positions = self.population.copy()\n                self.personal_best_fitness = self.fitness.copy()\n\n                #Reset CMA-ES parameters\n                self.mean = np.mean(self.population, axis=0)\n                self.sigma = self.cma_sigma * (ub - lb)\n                self.C = np.eye(self.dim)\n                self.pc = np.zeros(self.dim)\n                self.ps = np.zeros(self.dim)\n                \n                self.stagnation_counter = 0\n                self.archive = [] #Clear the archive after restart\n\n            # Global best update at the end of each generation.\n            if self.global_best_fitness < self.f_opt:\n                self.f_opt = self.global_best_fitness\n                self.x_opt = self.global_best_position.copy()\n\n        return self.f_opt, self.x_opt\n```", "operator": "mutation", "theta_sampled": 0.3970414467714658, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "d3078f05-c4f7-4f99-b633-78d901dbc431", "fitness": 0.7520742068295887, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with momentum-based population update and self-adaptive crossover rate.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors and CR values\n        self.archive_size = 10\n        self.momentum = momentum\n        self.velocity = None # Momentum term for population update\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocity = np.zeros_like(self.population)\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F_vals = [item[0] for item in self.archive]\n            F = np.random.choice(F_vals)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        # Self-adaptive crossover rate\n        if self.archive:\n            CR_vals = [item[1] for item in self.archive]\n            CR = np.random.choice(CR_vals)\n        else:\n            CR = self.CR\n            \n        mask = np.random.rand(self.dim) < CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    delta = u - self.population[i]\n                    self.velocity[i] = self.momentum * self.velocity[i] + (1 - self.momentum) * delta\n                    self.population[i] = self.population[i] + self.velocity[i]\n                    self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor and CR\n                    self.archive.append((self.F, self.CR))  # Store both F and CR\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDifferentialEvolution scored 0.752 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd"], "operator": "mutation", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with momentum-based population update and self-adaptive crossover rate.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, momentum=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.population = None\n        self.fitness = None\n        self.archive = [] # Archive of successful mutation factors and CR values\n        self.archive_size = 10\n        self.momentum = momentum\n        self.velocity = None # Momentum term for population update\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.velocity = np.zeros_like(self.population)\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F_vals = [item[0] for item in self.archive]\n            F = np.random.choice(F_vals)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        # Self-adaptive crossover rate\n        if self.archive:\n            CR_vals = [item[1] for item in self.archive]\n            CR = np.random.choice(CR_vals)\n        else:\n            CR = self.CR\n            \n        mask = np.random.rand(self.dim) < CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    delta = u - self.population[i]\n                    self.velocity[i] = self.momentum * self.velocity[i] + (1 - self.momentum) * delta\n                    self.population[i] = self.population[i] + self.velocity[i]\n                    self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)\n\n                    self.fitness[i] = f_u\n\n                    # Archive the successful mutation factor and CR\n                    self.archive.append((self.F, self.CR))  # Store both F and CR\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.3732147045537516, 0.7521416401002037, 0.7370265421332944, 0.906162174655273, 0.8324243966906475, 0.8590757576729151, 0.7186861525990511, 0.7333547564615659, 0.8328038666160118, 0.7824620203871142, 0.8985798481362637, 0.9922324693675679, 0.7136101424869846, 0.7821534271718849, 0.9394216102575037, 0.822719747455078, 0.7290028222796688, 0.8825970895482876, 0.22499766484801087, 0.5288173031706924], "operator": "mutation", "theta_sampled": 0.04867092848399234, "reward": 0.007758901204164337, "generation": 12}, "task_prompt": ""}
{"id": "d40a5ae3-f342-4f80-9b1a-38a2f0fb92ee", "fitness": 0.0, "name": "AdaptiveDEPSOCMA", "description": "Adaptive Differential Evolution with PSO-inspired velocity updates and a covariance matrix adaptation based restart.", "code": "import numpy as np\n\nclass AdaptiveDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES inspired restarts\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def pso_velocity_update(self, i):\n        velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n        return velocity\n\n    def cma_es_restart(self, func):\n        # Sample new population using covariance matrix\n        mean = self.global_best_position\n        eigenvalues, eigenvectors = np.linalg.eig(self.C)\n        A = eigenvectors @ np.diag(np.sqrt(eigenvalues))  # Transformation matrix\n        z = np.random.randn(self.pop_size, self.dim)  # Random Gaussian samples\n        self.population = mean + z @ A.T\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Archive the successful mutation factor\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                \n                # PSO inspired velocity update\n                velocity = self.pso_velocity_update(i)\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n            # Restart mechanism with CMA-ES inspired sampling\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.C = np.cov(self.population.T)  # Update covariance matrix\n                self.cma_es_restart(func)\n                \n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "", "error": "Evaluation error: Array must not contain infs or NaNs", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd", "37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "crossover", "metadata": {"llm_response": "# Description: Adaptive Differential Evolution with PSO-inspired velocity updates and a covariance matrix adaptation based restart.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEPSOCMA:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, stagnation_threshold=500, archive_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.stagnation_threshold = stagnation_threshold\n        self.stagnation_counter = 0\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = archive_size\n        self.population = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.C = np.eye(dim)  # Covariance matrix for CMA-ES inspired restarts\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def pso_velocity_update(self, i):\n        velocity = self.w * (self.population[i] - self.population[i]) + \\\n                           self.c1 * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i]) + \\\n                           self.c2 * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n        return velocity\n\n    def cma_es_restart(self, func):\n        # Sample new population using covariance matrix\n        mean = self.global_best_position\n        eigenvalues, eigenvectors = np.linalg.eig(self.C)\n        A = eigenvectors @ np.diag(np.sqrt(eigenvalues))  # Transformation matrix\n        z = np.random.randn(self.pop_size, self.dim)  # Random Gaussian samples\n        self.population = mean + z @ A.T\n        self.population = np.clip(self.population, func.bounds.lb, func.bounds.ub)\n        self.fitness = np.array([func(x) for x in self.population])\n        self.budget -= self.pop_size\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n        self.best_index = np.argmin(self.fitness)\n        self.global_best_position = self.population[self.best_index].copy()\n        self.global_best_fitness = self.fitness[self.best_index]\n        self.stagnation_counter = 0\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                v = self.mutate(x, func)\n                u = self.crossover(x, v)\n                \n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    # Update personal best\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    # Archive the successful mutation factor\n                    self.archive.append(self.F)\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    # Update global best\n                    if f_u < self.global_best_fitness:\n                        self.global_best_fitness = f_u\n                        self.global_best_position = u.copy()\n                        self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n                \n                # PSO inspired velocity update\n                velocity = self.pso_velocity_update(i)\n                self.population[i] = np.clip(self.population[i] + velocity, func.bounds.lb, func.bounds.ub)\n                \n                if self.fitness[i] < self.f_opt:\n                    self.f_opt = self.fitness[i]\n                    self.x_opt = self.population[i]\n\n            # Restart mechanism with CMA-ES inspired sampling\n            if self.stagnation_counter > self.stagnation_threshold:\n                self.C = np.cov(self.population.T)  # Update covariance matrix\n                self.cma_es_restart(func)\n                \n\n        return self.f_opt, self.x_opt\n```", "operator": "crossover", "theta_sampled": 0.2881614742865088, "reward": 0.0, "generation": 12}, "task_prompt": ""}
{"id": "298a402b-4bae-4898-85f0-20c8f10a360b", "fitness": 0.30842589233755485, "name": "AdaptiveDEPSO", "description": "Integrates Adaptive Differential Evolution with a modified Particle Swarm Optimization featuring velocity clamping and a success-history-based mutation factor adaptation from DE to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AdaptiveDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, v_max=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.v_max = v_max # Maximum velocity\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.budget -= self.pop_size\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n        global_best_index = np.argmin(self.fitness)\n        global_best_position = self.population[global_best_index].copy()\n        global_best_fitness = self.fitness[global_best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                \n                # DE Mutation and Crossover\n                v_de = self.mutate(x, func)\n                u = self.crossover(x, v_de)\n                \n                # PSO velocity update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - x)\n                social_component = self.c2 * r2 * (global_best_position - x)\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)  # Clamp velocity\n\n                # Update position using velocity, ensure bounds are respected.\n                u = np.clip(x + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    \n                    # Archive the successful mutation factor (simple version for demonstration)\n                    if self.archive:\n                        F_success = np.random.choice(self.archive)\n                    else:\n                        F_success = self.F\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    v = x1 + F_success * (x2 - x3)\n\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    self.archive.append(self.F)\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < global_best_fitness:\n                        global_best_fitness = f_u\n                        global_best_position = u.copy()\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDEPSO scored 0.308 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": ["f3932941-63da-4e5e-9bec-058fdea3a7fd", "37953516-7cba-4ad5-9a75-657c7839f233"], "operator": "crossover", "metadata": {"llm_response": "# Description: Integrates Adaptive Differential Evolution with a modified Particle Swarm Optimization featuring velocity clamping and a success-history-based mutation factor adaptation from DE to balance exploration and exploitation effectively.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveDEPSO:\n    def __init__(self, budget=10000, dim=10, pop_size=40, F=0.5, CR=0.9, w=0.7, c1=1.5, c2=1.5, v_max=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.F = F  # Initial mutation factor\n        self.CR = CR # Crossover rate\n        self.w = w  # Inertia weight (PSO)\n        self.c1 = c1  # Cognitive coefficient (PSO)\n        self.c2 = c2  # Social coefficient (PSO)\n        self.v_max = v_max # Maximum velocity\n        self.population = None\n        self.fitness = None\n        self.velocities = None\n        self.archive = [] # Archive of successful mutation factors\n        self.archive_size = 10\n\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n\n\n    def initialize_population(self, func):\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, size=(self.pop_size, self.dim))\n        self.fitness = np.array([func(x) for x in self.population])\n        self.velocities = np.zeros((self.pop_size, self.dim))\n        self.budget -= self.pop_size\n\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def mutate(self, x, func):\n        # Adaptive mutation factor based on past successes\n        if self.archive:\n            F = np.random.choice(self.archive)\n        else:\n            F = self.F\n\n        idxs = np.random.choice(self.pop_size, 3, replace=False)\n        x1, x2, x3 = self.population[idxs]\n        v = x1 + F * (x2 - x3)\n        v = np.clip(v, func.bounds.lb, func.bounds.ub)\n        return v\n    \n    def crossover(self, x, v):\n        mask = np.random.rand(self.dim) < self.CR\n        u = np.where(mask, v, x)\n        return u\n\n    def __call__(self, func):\n        self.f_opt = np.inf\n        self.x_opt = None\n        \n        self.initialize_population(func)\n        global_best_index = np.argmin(self.fitness)\n        global_best_position = self.population[global_best_index].copy()\n        global_best_fitness = self.fitness[global_best_index]\n\n\n        while self.budget > 0:\n            for i in range(self.pop_size):\n                x = self.population[i]\n                \n                # DE Mutation and Crossover\n                v_de = self.mutate(x, func)\n                u = self.crossover(x, v_de)\n                \n                # PSO velocity update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - x)\n                social_component = self.c2 * r2 * (global_best_position - x)\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.v_max, self.v_max)  # Clamp velocity\n\n                # Update position using velocity, ensure bounds are respected.\n                u = np.clip(x + self.velocities[i], func.bounds.lb, func.bounds.ub)\n\n\n                # Evaluate trial vector\n                f_u = func(u)\n                self.budget -= 1\n                if self.budget <= 0:\n                    break\n\n\n                if f_u < self.fitness[i]:\n                    # Update population and fitness\n                    \n                    # Archive the successful mutation factor (simple version for demonstration)\n                    if self.archive:\n                        F_success = np.random.choice(self.archive)\n                    else:\n                        F_success = self.F\n                    \n                    idxs = np.random.choice(self.pop_size, 3, replace=False)\n                    x1, x2, x3 = self.population[idxs]\n                    v = x1 + F_success * (x2 - x3)\n\n                    if len(self.archive) > self.archive_size:\n                        self.archive.pop(0)\n                    \n                    self.population[i] = u\n                    self.fitness[i] = f_u\n\n                    self.archive.append(self.F)\n\n                    if f_u < self.personal_best_fitness[i]:\n                        self.personal_best_fitness[i] = f_u\n                        self.personal_best_positions[i] = u.copy()\n\n                    if f_u < global_best_fitness:\n                        global_best_fitness = f_u\n                        global_best_position = u.copy()\n                \n                if f_u < self.f_opt:\n                    self.f_opt = f_u\n                    self.x_opt = u\n\n        return self.f_opt, self.x_opt\n```", "aucs": [0.07835265314123319, 0.1542319291754246, 0.49797228821917816, 0.14321819820253245, 0.16169775412835174, 0.17746373452594855, 0.1977681833942525, 0.18822658164824457, 0.18787869886962827, 0.1524454970635961, 0.23376332500037122, 0.9991497727711193, 0.22118416970988652, 0.18946070424716377, 0.6792613493369664, 0.6352698422671839, 0.23873446405134569, 0.6899209155794541, 0.14786203518490892, 0.19465575023430692], "operator": "crossover", "theta_sampled": 0.10347235325103613, "reward": 0.0, "generation": 12}, "task_prompt": ""}
